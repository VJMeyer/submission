% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  11pt,
  letterpaper,
]{book}
\usepackage{xcolor}
\usepackage[margin=2.5cm,paper=a4paper]{geometry}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother





\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 
\usepackage[]{biblatex}
\addbibresource{ref/MAref.bib}


% AMTAIR Thesis Preamble - Zero package conflicts
% Only formatting commands, no package loading

% Line spacing for academic work
\usepackage{setspace}
\onehalfspacing

% Custom chapter formatting (remove "Chapter N" prefix) but unfortunately leaves blank space
\usepackage{titlesec}
\titleformat{\chapter}[display]
  {\normalfont\huge\bfseries}  % format
  {}                           % label (empty = no "Chapter N")
  {0pt}                        % sep
  {\Huge}                      % before-code



% Page formatting and headers
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\slshape\nouppercase{\rightmark}}
\fancyhead[LO,RE]{\slshape\nouppercase{\leftmark}}
\fancyfoot[C]{\thepage}

% % Fix page breaks after title page
% \newcommand{\cleartitlepage}{
%   \clearpage
%   \thispagestyle{empty}
%   \mbox{}
%   \clearpage
% }



\renewcommand{\maketitle}{}

%  Citation customization
% \usepackage[style=authoryear,backend=biber,natbib=true]{biblatex}

% % Custom citation commands for different contexts
% \newcommand{\citeauthor}[1]{\textcite{#1}}           % Author (year)
% \newcommand{\citeyear}[1]{(\citeyear*{#1})}         % (year)
% \newcommand{\citealt}[1]{\citeauthor{#1} \citeyear{#1}}  % Author year
% \newcommand{\citep}[1]{(\cite{#1})}                 # (Author, year)

% Page reference styling
% \DeclareFieldFormat{postnote}{#1}                    # No "p." prefix
% \DeclareFieldFormat{multipostnote}{#1}               # No "pp." prefix


% % Page numbering control
% \usepackage{afterpage}

% % Command to start front matter (roman numerals)
% \newcommand{\frontmatter}{
%   \cleardoublepage
%   \pagenumbering{roman}
%   \setcounter{page}{1}
% }

% % Command to start main matter (arabic numerals)
% \newcommand{\mainmatter}{
%   \cleardoublepage
%   \pagenumbering{arabic}
%   \setcounter{page}{1}
% }

% % Command to start back matter (continue arabic)
% \newcommand{\backmatter}{
%   \cleardoublepage
%   % Keep arabic numbering but could change style if needed
% }

% % Suppress page numbers on title page
% \newcommand{\titlepage}{
%   \thispagestyle{empty}
% }



% Commands for custom title page
% \newcommand{\thesistitle}{Automating the Modelling of Transformative Artificial Intelligence Risks}
% \newcommand{\thesisauthor}{Valentin Jakob Meyer}
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\definecolor{QuartoInternalColor2}{rgb}{0,0,0}
\definecolor{QuartoInternalColor1}{rgb}{0.70,0.17,0.19}
\definecolor{QuartoInternalColor5}{rgb}{0.00,0.40,0.79}
\definecolor{QuartoInternalColor6}{rgb}{0.00,0.64,0.31}
\definecolor{QuartoInternalColor3}{rgb}{0.00,0.45,0.15}
\definecolor{QuartoInternalColor4}{rgb}{0.15,0.56,0.56}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Automating the Modelling of Transformative Artificial Intelligence Risks},
  pdfauthor={Valentin Jakob Meyer},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}


\title{Automating the Modelling of Transformative Artificial
Intelligence Risks}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{An Epistemic Framework for Leveraging Frontier AI Systems to
Upscale Conditional Policy Assessments in Bayesian Networks on a Narrow
Path towards Existential Safety}
\author{Valentin Jakob Meyer}
\date{2025-05-26}
\begin{document}
\frontmatter
\maketitle

\begin{titlepage}
\thispagestyle{empty}% Remove page number from title page

% Top header with logo (left) and department (right)
\begin{minipage}{0.3\textwidth}
  \includegraphics[width=5cm]{latex/uni-bayreuth-logo.png}
\end{minipage}
\hfill
\begin{minipage}{0.9\textwidth}
  \begin{center}
    -- P\&E Master's Programme --\\
    Chair of Philosophy, Computer\\
    Science \& Artificial Intelligence
  \end{center}
\end{minipage}

% Horizontal rule
\vspace{1.5cm}
\hrule
\vspace{2cm}

% Title in bold
\begin{center}
  \Large\textbf{Automating the Modelling of
Transformative Artificial Intelligence Risks}
\end{center}
\vspace{0.2cm}

\begin{center}
  -----
\end{center}
\vspace{0.2cm}

% Subtitle in italics with quotation marks
\begin{center}
  \normalsize``\textit{An Epistemic Framework for Leveraging Frontier AI Systems
to Upscale Conditional Policy Assessments in Bayesian Networks on a Narrow Path towards Existencial Safety }''
\end{center}
\vspace{0.2cm}

\begin{center}
  -----
\end{center}
\vspace{0.2cm}

% Thesis designation
\begin{center}
  A thesis submitted at the Department of Philosophy\\[0.4cm]
  for the degree of \textit{Master of Arts in Philosophy \& Economics}
\end{center}

\vspace{1.5cm}
% Horizontal rule
\hrule
\vspace{1.5cm}

% Author and supervisor information with precise alignment
\begin{minipage}[t]{0.48\textwidth}
  \textbf{Author:}\\[0.3cm]
  \href{https://www.vjmeyer.org}{Valentin Jakob Meyer}\\
  \href{mailto:Valentin.meyer@uni-bayreuth.de}{Valentin.meyer@uni-bayreuth.de}\\
  \textit{Matriculation Number:} 1828610\\
  \textit{Tel.:} +49 (1573) 4512494\\
  Pielmühler Straße 15\\
  93138 Lappersdorf
\end{minipage}
\hfill
\begin{minipage}[t]{0.48\textwidth}
  \begin{flushright}
    \textbf{Supervisor:}\\[0.3cm]
    \href{mailto:timo.speith@uni-bayreuth.de}{Dr. Timo Speith}\\[0.35cm]
    \textit{Word Count:}\\
    30.000\\[0.1cm]
    \textit{Source / Identifier:}\\
    \href{https://github.com/VJMeyer/submission}{Document URL}
  \end{flushright}
\end{minipage}

% Date at bottom
\vfill
\begin{center}
  26th of May 2025
\end{center}
\end{titlepage}

% Critical: Clean page break to TOC
\cleardoublepage

\renewcommand*\contentsname{Table of Contents}
{
\setcounter{tocdepth}{9}
\tableofcontents
}
\listoffigures
\listoftables

\mainmatter
\bookmarksetup{startatroot}

\chapter{Abstract}\label{sec-abstract}

\begin{quote}
The coordination crisis in AI governance presents a paradoxical
challenge: unprecedented investment in AI safety coexists alongside
fundamental coordination failures across technical, policy, and ethical
domains. These divisions systematically increase existential risk. This
thesis introduces AMTAIR (Automating Transformative AI Risk Modeling), a
computational approach addressing this coordination failure by
automating the extraction of probabilistic world models from AI safety
literature using frontier language models. The system implements an
end-to-end pipeline transforming unstructured text into interactive
Bayesian networks through a novel two-stage extraction process that
bridges communication gaps between stakeholders.
\end{quote}

\section{\texorpdfstring{\textbf{Acknowledgments}}{Acknowledgments}}\label{acknowledgments}

\begin{itemize}
\tightlist
\item
  Academic supervisor (Prof.~Timo Speith) and institution (University of
  Bayreuth)\\
\item
  Research collaborators, especially those connected to the original
  MTAIR project\\
\item
  Technical advisors who provided feedback on implementation aspects\\
\item
  Personal supporters who enabled the research through encouragement and
  feedback
\end{itemize}

\section*{List of Abbreviations}\label{list-of-abbreviations}
\addcontentsline{toc}{section}{List of Abbreviations}

\markright{List of Abbreviations}

\begin{itemize}
\tightlist
\item
  AGI - Artificial General Intelligence
\item
  AMTAIR - Automating Modeling of Transformative AI Risks
\item
  API - Application Programming Interface
\item
  APS - Advanced, Planning, Strategic
\item
  BN - Bayesian Network
\item
  CPT - Conditional Probability Table
\item
  DAG - Directed Acyclic Graph
\item
  LLM - Large Language Model
\item
  MTAIR - Modeling Transformative AI Risks
\item
  TAI - Transformative Artificial Intelligence
\end{itemize}

\section*{Glossary}\label{glossary}

\markright{Glossary}

\begin{itemize}
\tightlist
\item
  \textbf{Argument mapping}: A method for visually representing the
  structure of arguments\\
\item
  \textbf{BayesDown}: An extension of ArgDown that incorporates
  probabilistic information\\
\item
  \textbf{Bayesian network}: A probabilistic graphical model
  representing variables and their dependencies\\
\item
  \textbf{Conditional probability}: The probability of an event given
  that another event has occurred\\
\item
  \textbf{Directed Acyclic Graph (DAG)}: A graph with directed edges and
  no cycles\\
\item
  \textbf{Existential risk}: Risk of permanent curtailment of humanity's
  potential\\
\item
  \textbf{Power-seeking AI}: AI systems with instrumental incentives to
  acquire resources and power\\
\item
  \textbf{Prediction market}: A market where participants trade
  contracts that resolve based on future events\\
\item
  \textbf{d-separation}: A criterion for identifying conditional
  independence relationships in Bayesian networks\\
\item
  \textbf{Monte Carlo sampling}: A computational technique using random
  sampling to obtain numerical results
\end{itemize}

\bookmarksetup{startatroot}

\chapter{Final Thesis: Automating the Modeling of Transformative
Artificial Intelligence
Risks}\label{final-thesis-automating-the-modeling-of-transformative-artificial-intelligence-risks}

\section{Frontmatter: Preface}\label{frontmatter-preface}

This thesis represents the culmination of interdisciplinary research at
the intersection of AI safety, formal epistemology, and computational
social science. The work emerged from recognizing a fundamental
challenge in AI governance: while investment in AI safety research has
grown exponentially, coordination between different stakeholder
communities remains fragmented, potentially increasing existential risk
through misaligned efforts.

The journey from initial concept to working implementation involved
iterative refinement based on feedback from advisors, domain experts,
and potential users. What began as a technical exercise in automated
extraction evolved into a broader framework for enhancing epistemic
security in one of humanity's most critical coordination challenges. The
AMTAIR project---Automating Transformative AI Risk Modeling---represents
an attempt to build computational bridges between communities that,
despite shared concerns about AI risk, often struggle to communicate
effectively due to incompatible frameworks, terminologies, and implicit
assumptions.

I hope this work contributes to building the intellectual and technical
infrastructure necessary for humanity to navigate the transition to
transformative AI safely. The tools and frameworks presented here are
offered in the spirit of collaborative problem-solving, recognizing that
the challenges we face require unprecedented cooperation across
disciplines, institutions, and worldviews.

\section{Acknowledgments}\label{acknowledgments-1}

I thank my supervisor Dr.~Timo Speith for his guidance throughout this
project, providing both technical insights and philosophical grounding.
The MTAIR team's pioneering manual approach inspired this automation
effort, and I am grateful for their foundational work.

I acknowledge Johannes Meyer and Jelena Meyer for their invaluable
assistance in verifying the automated extraction procedure through
manual extraction of ArgDown and BayesDown data from the Carlsmith
paper, providing crucial ground truth for validation.

Special recognition goes to Coleman Snell for his partnership and
research collaboration with the AMTAIR project, offering both technical
expertise and strategic vision. The AI safety community's creation of
rich literature made this work possible, and I thank all researchers
whose arguments provided the raw material for formalization.

Any errors or limitations remain my own responsibility.

\section{List of Figures}\label{list-of-figures}

\section{List of Tables}\label{list-of-tables}

\section{List of Abbreviations}\label{list-of-abbreviations-1}

AI - Artificial Intelligence\\
AGI - Artificial General Intelligence\\
AMTAIR - Automating Transformative AI Risk Modeling\\
API - Application Programming Interface\\
APS - Advanced, Planning, Strategic (AI systems)\\
BN - Bayesian Network\\
CPT - Conditional Probability Table\\
DAG - Directed Acyclic Graph\\
LLM - Large Language Model\\
ML - Machine Learning\\
MTAIR - Modeling Transformative AI Risks\\
NLP - Natural Language Processing\\
P\&E - Philosophy \& Economics\\
PDF - Portable Document Format\\
TAI - Transformative Artificial Intelligence

\bookmarksetup{startatroot}

\chapter{1. Introduction: The Coordination Crisis in AI
Governance}\label{introduction-the-coordination-crisis-in-ai-governance}

\section{1.1 Opening Scenario: The Policymaker's
Dilemma}\label{opening-scenario-the-policymakers-dilemma}

Imagine a senior policy advisor preparing recommendations for AI
governance legislation. On her desk lie a dozen reports from leading AI
safety researchers, each painting a different picture of the risks
ahead. One argues that misaligned AI could pose existential risks within
the decade, citing complex technical arguments about instrumental
convergence and orthogonality. Another suggests these concerns are
overblown, emphasizing uncertainty and the strength of existing
institutions. A third proposes specific technical standards but
acknowledges deep uncertainty about their effectiveness.

Each report seems compelling in isolation, written by credentialed
experts with sophisticated arguments. Yet they reach dramatically
different conclusions about both the magnitude of risk and appropriate
interventions. The technical arguments involve unfamiliar
concepts---mesa-optimization, corrigibility, capability
amplification---expressed through different frameworks and implicit
assumptions. Time is limited, stakes are high, and the legislation could
shape humanity's trajectory for decades.

This scenario\footnote{The orthogonality thesis posits that intelligence
  and goals are independent---an AI can have any set of objectives
  regardless of its intelligence level. The instrumental convergence
  thesis suggests that different AI systems may adopt similar
  instrumental goals (e.g., self-preservation, resource acquisition) to
  achieve their objectives.} plays out daily across government offices,
corporate boardrooms, and research institutions worldwide. It
exemplifies what I term the ``coordination crisis'' in AI governance:
despite unprecedented attention and resources directed toward AI safety,
we lack the epistemic infrastructure to synthesize diverse expert
knowledge into actionable governance strategies \textcite{todd2024}.

Show Image

\section{1.2 The Coordination Crisis in AI
Governance}\label{the-coordination-crisis-in-ai-governance}

As AI capabilities advance at an accelerating pace---demonstrated by the
rapid progression from GPT-3 to GPT-4, Claude, and emerging multimodal
systems \textcite{maslej2025} \textcite{samborska2025}---humanity faces
a governance challenge unlike any in history. The task of ensuring
increasingly powerful AI systems remain aligned with human values and
beneficial to our long-term flourishing grows more urgent with each
capability breakthrough. This challenge becomes particularly acute when
considering transformative AI systems that could drastically alter
civilization's trajectory, potentially including existential risks from
misaligned systems pursuing objectives counter to human welfare.

Despite unprecedented investment in AI safety research, rapidly growing
awareness among key stakeholders, and proliferating frameworks for
responsible AI development, we face what I'll term the ``coordination
crisis'' in AI governance---a systemic failure to align diverse efforts
across technical, policy, and strategic domains into a coherent response
proportionate to the risks we face.

The current state of AI governance presents a striking paradox. On one
hand, we witness extraordinary mobilization: billions in research
funding, proliferating safety initiatives, major tech companies
establishing alignment teams, and governments worldwide developing AI
strategies. The Asilomar AI Principles garnered thousands of signatures
\textcite{tegmark2024}, the EU advances comprehensive AI regulation
\textcite{european2024}, and technical researchers produce increasingly
sophisticated work on alignment, interpretability, and robustness.

Yet alongside this activity, we observe systematic coordination failures
that may prove catastrophic. Technical safety researchers develop
sophisticated alignment techniques without clear implementation
pathways. Policy specialists craft regulatory frameworks lacking
technical grounding to ensure practical efficacy. Ethicists articulate
normative principles that lack operational specificity. Strategy
researchers identify critical uncertainties but struggle to translate
these into actionable guidance. International bodies convene without
shared frameworks for assessing interventions.

Show Image

\subsection{1.2.1 Safety Gaps from Misaligned
Efforts}\label{safety-gaps-from-misaligned-efforts}

The fragmentation problem manifests in incompatible frameworks between
technical researchers, policy specialists, and strategic analysts. Each
community develops sophisticated approaches within their domain, yet
translation between domains remains primitive. This creates systematic
blind spots where risks emerge at the interfaces between technical
capabilities, institutional responses, and strategic dynamics.

When different communities operate with incompatible frameworks,
critical risks fall through the cracks. Technical researchers may solve
alignment problems under assumptions that policymakers' decisions
invalidate. Regulations optimized for current systems may inadvertently
incentivize dangerous development patterns. Without shared models of the
risk landscape, our collective efforts resemble the parable of blind men
describing an elephant---each accurate within their domain but missing
the complete picture \textcite{paul2023}.

Historical precedents demonstrate how coordination failures in
technology governance can lead to dangerous dynamics. The nuclear arms
race exemplifies how lack of coordination can create negative-sum
outcomes where all parties become less secure despite massive
investments in safety measures. Similar dynamics may emerge in AI
development without proper coordination infrastructure.

\subsection{1.2.2 Resource Misallocation}\label{resource-misallocation}

The AI safety community faces a complex tradeoff in resource allocation.
While some duplication of efforts can improve reliability through
independent verification---akin to reproducing scientific results---the
current level of fragmentation often leads to wasteful redundancy.
Multiple teams independently develop similar frameworks without building
on each other's work, creating opportunity costs where critical but
unglamorous research areas remain understaffed. Funders struggle to
identify high-impact opportunities across technical and governance
domains, lacking the epistemic infrastructure to assess where marginal
resources would have the greatest impact. This misallocation becomes
more costly as the window for establishing effective governance narrows
with accelerating AI development.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}@{}}
\caption{Examples of duplicated AI safety efforts across
organizations}\label{tbl-resource-duplication}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Research Area
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Organization A
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Organization B
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Duplication Level
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Opportunity Cost
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Research Area
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Organization A
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Organization B
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Duplication Level
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Opportunity Cost
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Interpretability Methods & Anthropic's mechanistic interpretability &
DeepMind's concept activation vectors & Medium & Reduced focus on
multi-agent safety \\
Alignment Frameworks & MIRI's embedded agency & FHI's comprehensive AI
services & High & Limited work on institutional design \\
Risk Assessment Models & GovAI's policy models & CSER's existential risk
frameworks & High & Insufficient capability benchmarking \\
\end{longtable}

\subsection{1.2.3 Negative-Sum Dynamics}\label{negative-sum-dynamics}

Perhaps most concerning, uncoordinated interventions can actively
increase risk. Safety standards that advantage established players may
accelerate risky development elsewhere. Partial transparency
requirements might enable capability advances without commensurate
safety improvements. International agreements lacking shared technical
understanding may lock in dangerous practices. Without coordination, our
cure risks becoming worse than the disease.

The game-theoretic structure of AI development creates particularly
pernicious dynamics. Armstrong et al. \textcite{armstrong2016}
demonstrate how uncoordinated policies can incentivize a ``race to the
precipice'' where competitive pressures override safety considerations.
The situation resembles a multi-player prisoner's dilemma or stag hunt
where individually rational decisions lead to collectively catastrophic
outcomes \textcite{samuel2023} \textcite{hunt2025}.

\section{1.3 Historical Parallels and Temporal
Urgency}\label{historical-parallels-and-temporal-urgency}

History offers instructive parallels. The nuclear age began with
scientists racing to understand and control forces that could destroy
civilization. Early coordination failures---competing national programs,
scientist-military tensions, public-expert divides---nearly led to
catastrophe multiple times. Only through developing shared frameworks
(deterrence theory) \textcite{schelling1960}, institutions (IAEA), and
communication channels (hotlines, treaties) did humanity navigate the
nuclear precipice \textcite{rehman2025}.

Yet AI presents unique coordination challenges that compress our
response timeline:

\textbf{Accelerating Development}: Unlike nuclear weapons requiring
massive infrastructure, AI development proceeds in corporate labs and
academic departments worldwide. Capability improvements come through
algorithmic insights and computational scale, both advancing
exponentially.

\textbf{Dual-Use Ubiquity}: Every AI advance potentially contributes to
both beneficial applications and catastrophic risks. The same language
model architectures enabling scientific breakthroughs could facilitate
dangerous manipulation or deception at scale.

\textbf{Comprehension Barriers}: Nuclear risks were viscerally
understandable---cities vaporized, radiation sickness, nuclear winter.
AI risks involve abstract concepts like optimization processes, goal
misspecification, and emergent capabilities that resist intuitive
understanding.

\textbf{Governance Lag}: Traditional governance
mechanisms---legislation, international treaties, professional
standards---operate on timescales of years to decades. AI capabilities
advance on timescales of months to years, creating an ever-widening
capability-governance gap.

Show Image

\section{1.4 Research Question and
Scope}\label{research-question-and-scope}

This thesis addresses a specific dimension of the coordination challenge
by investigating the question:

\textbf{Can frontier AI technologies be utilized to automate the
modeling of transformative AI risks, enabling robust prediction of
policy impacts across diverse worldviews?}

More specifically, I explore whether frontier language models can
automate the extraction and formalization of probabilistic world models
from AI safety literature, creating a scalable computational framework
that enhances coordination in AI governance through systematic policy
evaluation under uncertainty.

To break this down into its components:

\begin{itemize}
\tightlist
\item
  \textbf{Frontier AI Technologies}: Today's most capable language
  models (GPT-4, Claude-3 level systems)
\item
  \textbf{Automated Modeling}: Using these systems to extract and
  formalize argument structures from natural language
\item
  \textbf{Transformative AI Risks}: Potentially catastrophic outcomes
  from advanced AI systems, particularly existential risks
\item
  \textbf{Policy Impact Prediction}: Evaluating how governance
  interventions might alter probability distributions over outcomes
\item
  \textbf{Diverse Worldviews}: Accounting for fundamental disagreements
  about AI development trajectories and risk factors
\end{itemize}

The investigation encompasses both theoretical development and practical
implementation, focusing specifically on existential risks from
misaligned AI systems rather than broader AI ethics concerns. This
narrowed scope enables deep technical development while addressing the
highest-stakes coordination challenges.

\section{1.5 The Multiplicative Benefits
Framework}\label{the-multiplicative-benefits-framework}

The central thesis of this work is that combining three
elements---automated worldview extraction, prediction market
integration, and formal policy evaluation---creates multiplicative
rather than merely additive benefits for AI governance. Each component
enhances the others, creating a system more valuable than the sum of its
parts.

Show Image

\subsection{1.5.1 Automated Worldview
Extraction}\label{automated-worldview-extraction}

Current approaches to AI risk modeling, exemplified by the Modeling
Transformative AI Risks (MTAIR) project, demonstrate the value of formal
representation but require extensive manual effort. Creating a single
model demands dozens of expert-hours to translate qualitative arguments
into quantitative frameworks. This bottleneck severely limits the number
of perspectives that can be formalized and the speed of model updates as
new arguments emerge.

Automation using frontier language models addresses this scaling
challenge. By developing systematic methods to extract causal structures
and probability judgments from natural language, we can:

\begin{itemize}
\tightlist
\item
  Process orders of magnitude more content
\item
  Incorporate diverse perspectives rapidly
\item
  Maintain models that evolve with the discourse
\item
  Reduce barriers to entry for contributing worldviews
\end{itemize}

\subsection{1.5.2 Live Data Integration}\label{live-data-integration}

Static models, however well-constructed, quickly become outdated in
fast-moving domains. Prediction markets and forecasting platforms
aggregate distributed knowledge about uncertain futures, providing
continuously updated probability estimates. By connecting formal models
to these live data sources, we create dynamic assessments that
incorporate the latest collective intelligence \textcite{tetlock2015}.

This integration serves multiple purposes:

\begin{itemize}
\tightlist
\item
  Grounding abstract models in empirical forecasts
\item
  Identifying which uncertainties most affect outcomes
\item
  Revealing when model assumptions diverge from collective expectations
\item
  Generating new questions for forecasting communities
\end{itemize}

\subsection{1.5.3 Formal Policy
Evaluation}\label{formal-policy-evaluation}

\textbf{Formal policy evaluation} transforms static risk assessments
into actionable guidance by modeling how specific interventions alter
critical parameters. Using causal inference techniques
\textcite{pearl2000} \textcite{pearl2009}, we can assess not just the
probability of adverse outcomes but how those probabilities change under
different policy regimes.

This enables genuinely evidence-based policy development:

\begin{itemize}
\tightlist
\item
  Comparing interventions across multiple worldviews
\item
  Identifying robust strategies that work across scenarios
\item
  Understanding which uncertainties most affect policy effectiveness
\item
  Prioritizing research to reduce decision-relevant uncertainty
\end{itemize}

\subsection{1.5.4 The Synergy}\label{the-synergy}

The multiplicative benefits emerge from the interactions between
components:

\begin{itemize}
\tightlist
\item
  Automation enables comprehensive coverage, making prediction market
  integration more valuable by connecting to more perspectives
\item
  Market data validates and calibrates automated extractions, improving
  quality
\item
  Policy evaluation gains precision from both comprehensive models and
  live probability updates
\item
  The complete system creates feedback loops where policy analysis
  identifies critical uncertainties for market attention
\end{itemize}

This synergistic combination addresses the coordination crisis by
providing common ground for disparate communities, translating between
technical and policy languages, quantifying previously implicit
disagreements, and enabling evidence-based compromise.

\section{1.6 Thesis Structure and
Roadmap}\label{thesis-structure-and-roadmap}

The remainder of this thesis develops the multiplicative benefits
framework from theoretical foundations to practical implementation:

\textbf{Chapter 2: Context and Theoretical Foundations} establishes the
intellectual groundwork, examining the epistemic challenges unique to AI
governance, Bayesian networks as formal tools for uncertainty
representation, argument mapping as a bridge from natural language to
formal models, the MTAIR project's achievements and limitations, and
requirements for effective coordination infrastructure.

\textbf{Chapter 3: AMTAIR Design and Implementation} presents the
technical system including overall architecture and design principles,
the two-stage extraction pipeline (ArgDown → BayesDown), validation
methodology and results, case studies from simple examples to complex AI
risk models, and integration with prediction markets and policy
evaluation.

\textbf{Chapter 4: Discussion - Implications and Limitations} critically
examines technical limitations and failure modes, conceptual concerns
about formalization, integration with existing governance frameworks,
scaling challenges and opportunities, and broader implications for
epistemic security.

\textbf{Chapter 5: Conclusion} synthesizes key contributions and charts
paths forward with a summary of theoretical and practical achievements,
concrete recommendations for stakeholders, research agenda for community
development, and vision for AI governance with proper coordination
infrastructure.

Throughout this progression, I maintain dual focus on theoretical
sophistication and practical utility. The framework aims not merely to
advance academic understanding but to provide actionable tools for
improving coordination in AI governance during this critical period.

Show Image

Having established the coordination crisis and outlined how automated
modeling can address it, we now turn to the theoretical foundations that
make this approach possible. The next chapter examines the unique
epistemic challenges of AI governance and introduces the formal
tools---particularly Bayesian networks---that enable rigorous reasoning
under deep uncertainty.

\bookmarksetup{startatroot}

\chapter{2. Context and Theoretical
Foundations}\label{context-and-theoretical-foundations}

This chapter establishes the theoretical and methodological foundations
for the AMTAIR approach. We begin by examining a concrete example of
structured AI risk assessment---Joseph Carlsmith's power-seeking AI
model---to ground our discussion in practical terms. We then explore the
unique epistemic challenges of AI governance that render traditional
policy analysis inadequate, introduce Bayesian networks as formal tools
for representing uncertainty, and examine how argument mapping bridges
natural language reasoning and formal models. The chapter concludes by
analyzing the MTAIR project's achievements and limitations, motivating
the need for automated approaches, and surveying relevant literature
across AI risk modeling, governance proposals, and technical
methodologies.

\section{2.1 AI Existential Risk: The Carlsmith
Model}\label{ai-existential-risk-the-carlsmith-model}

To ground our discussion in concrete terms, I examine Joseph Carlsmith's
``Is Power-Seeking AI an Existential Risk?'' as an exemplar of
structured reasoning about AI catastrophic risk
\textcite{carlsmith2022}. Carlsmith's analysis stands out for its
explicit probabilistic decomposition of the path from current AI
development to potential existential catastrophe.

\subsection{2.1.1 Six-Premise
Decomposition}\label{six-premise-decomposition}

According to the MTAIR model \textcite{clarke2022}, Carlsmith decomposes
existential risk into a probabilistic chain with explicit
estimates\footnote{Multiple versions of Carlsmith's paper exist with
  slight updates to probability estimates: \textcite{carlsmith2021},
  \textcite{carlsmith2022}, \textcite{carlsmith2024}. We primarily
  reference the version used by the MTAIR team for their extraction.
  Extended discussion and expert probability estimates can be found on
  LessWrong.}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Premise 1}: Transformative AI development this century
  (P≈0.80)(P ≈ 0.80) (P≈0.80)
\item
  \textbf{Premise 2}: AI systems pursuing objectives in the world
  (P≈0.95)(P ≈ 0.95) (P≈0.95)
\item
  \textbf{Premise 3}: Systems with power-seeking instrumental incentives
  (P≈0.40)(P ≈ 0.40) (P≈0.40)
\item
  \textbf{Premise 4}: Sufficient capability for existential threat
  (P≈0.65)(P ≈ 0.65) (P≈0.65)
\item
  \textbf{Premise 5}: Misaligned systems despite safety efforts
  (P≈0.50)(P ≈ 0.50) (P≈0.50)
\item
  \textbf{Premise 6}: Catastrophic outcomes from misaligned
  power-seeking (P≈0.65)(P ≈ 0.65) (P≈0.65)
\end{enumerate}

\textbf{Composite Risk Calculation}: P(doom)≈0.05P(doom) ≈ 0.05
P(doom)≈0.05 (5\%)

mermaid

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{flowchart TD}
\NormalTok{    P1[Premise 1: Transformative AI\textless{}br/\textgreater{}P ≈ 0.80] {-}{-}\textgreater{} P2[Premise 2: AI pursuing objectives\textless{}br/\textgreater{}P ≈ 0.95]}
\NormalTok{    P2 {-}{-}\textgreater{} P3[Premise 3: Power{-}seeking incentives\textless{}br/\textgreater{}P ≈ 0.40]}
\NormalTok{    P3 {-}{-}\textgreater{} P4[Premise 4: Existential capability\textless{}br/\textgreater{}P ≈ 0.65]}
\NormalTok{    P4 {-}{-}\textgreater{} P5[Premise 5: Misalignment despite safety\textless{}br/\textgreater{}P ≈ 0.50]}
\NormalTok{    P5 {-}{-}\textgreater{} P6[Premise 6: Catastrophic outcome\textless{}br/\textgreater{}P ≈ 0.65]}
\NormalTok{    P6 {-}{-}\textgreater{} D[Existential Catastrophe\textless{}br/\textgreater{}P ≈ 0.05]}
\end{Highlighting}
\end{Shaded}

Carlsmith structures his argument through six conditional premises, each
assigned explicit probability estimates:

\textbf{Premise 1: APS Systems by 2070} (P≈0.65)(P ≈ 0.65) (P≈0.65) ``By
2070, there will be AI systems with Advanced capability, Agentic
planning, and Strategic awareness''---the conjunction of capabilities
that could enable systematic pursuit of objectives in the world.

\textbf{Premise 2: Alignment Difficulty} (P≈0.40)(P ≈ 0.40) (P≈0.40)
``It will be harder to build aligned APS systems than misaligned systems
that are still attractive to deploy''---capturing the challenge that
safety may conflict with capability or efficiency.

\textbf{Premise 3: Deployment Despite Misalignment} (P≈0.70)(P ≈ 0.70)
(P≈0.70) ``Conditional on 1 and 2, we will deploy misaligned APS
systems''---reflecting competitive pressures and limited coordination.

\textbf{Premise 4: Power-Seeking Behavior} (P≈0.65)(P ≈ 0.65) (P≈0.65)
``Conditional on 1-3, misaligned APS systems will seek power in
high-impact ways''---based on instrumental convergence arguments.

\textbf{Premise 5: Disempowerment Success} (P≈0.40)(P ≈ 0.40) (P≈0.40)
``Conditional on 1-4, power-seeking will scale to permanent human
disempowerment''---despite potential resistance and safeguards.

\textbf{Premise 6: Existential Catastrophe} (P≈0.95)(P ≈ 0.95) (P≈0.95)
``Conditional on 1-5, this disempowerment constitutes existential
catastrophe''---connecting power loss to permanent curtailment of human
potential.

\textbf{Overall Risk}: Multiplying through the conditional chain yields
P(doom)≈0.05P(doom) ≈ 0.05 P(doom)≈0.05 or 5\% by 2070.

This structured approach exemplifies the type of reasoning AMTAIR aims
to formalize and automate. While Carlsmith spent months developing this
model manually, similar rigor exists implicitly in many AI safety
arguments awaiting extraction.

\subsection{2.1.2 Why Carlsmith Exemplifies Formalizable
Arguments}\label{why-carlsmith-exemplifies-formalizable-arguments}

Carlsmith's model demonstrates several features that make it ideal for
formal representation:

\textbf{Explicit Probabilistic Structure}: Each premise receives
numerical probability estimates with documented reasoning, enabling
direct translation to Bayesian network parameters.

\textbf{Clear Conditional Dependencies}: The logical flow from
capabilities through deployment decisions to catastrophic outcomes maps
naturally onto directed acyclic graphs.

\textbf{Transparent Decomposition}: Breaking the argument into modular
premises allows independent evaluation and sensitivity analysis of each
component.

\textbf{Documented Reasoning}: Extensive justification for each
probability enables extraction of both structure and parameters from the
source text.

We will return to Carlsmith's model in Chapter 3 as our primary complex
case study, demonstrating how AMTAIR successfully extracts and
formalizes this sophisticated multi-level argument.

Beyond Carlsmith's model, other structured approaches to AI risk---such
as Christiano's ``What failure looks like''
\textcite{christiano2019}---provide additional targets for automated
extraction, enabling comparative analysis across different expert
worldviews.

\section{2.2 The Epistemic Challenge of Policy
Evaluation}\label{the-epistemic-challenge-of-policy-evaluation}

AI governance policy evaluation faces unique epistemic challenges that
render traditional policy analysis methods insufficient. Understanding
these challenges motivates the need for new computational approaches.

\subsection{2.2.1 Unique Characteristics of AI
Governance}\label{unique-characteristics-of-ai-governance}

\textbf{Deep Uncertainty Rather Than Risk}: Traditional policy analysis
distinguishes between risk (known probability distributions) and
uncertainty (known possibilities, unknown probabilities). AI governance
faces deep uncertainty---we cannot confidently enumerate possible
futures, much less assign probabilities \textcite{hallegatte2012}. Will
recursive self-improvement enable rapid capability gains? Can value
alignment be solved technically? These foundational questions resist
empirical resolution before their answers become catastrophically
relevant.

\textbf{Complex Multi-Level Causation}: Policy effects propagate through
technical, institutional, and social levels with intricate feedback
loops. A technical standard might alter research incentives, shifting
capability development trajectories, changing competitive dynamics, and
ultimately affecting existential risk through pathways invisible at the
policy's inception. Traditional linear causal models cannot capture
these dynamics.

\textbf{Irreversibility and Lock-In}: Many AI governance decisions
create path dependencies that prove difficult or impossible to reverse.
Early technical standards shape development trajectories. Institutional
structures ossify. International agreements create sticky equilibria.
Unlike many policy domains where course correction remains possible, AI
governance mistakes may prove permanent.

\textbf{Value-Laden Technical Choices}: The entanglement of technical
and normative questions confounds traditional separation of facts and
values. What constitutes ``alignment''? How much capability development
should we risk for economic benefits? Technical specifications embed
ethical judgments that resist neutral expertise.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\caption{Comparison of AI governance vs traditional policy
domains}\label{tbl-governance-challenges}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Traditional Policy
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Governance
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Traditional Policy
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
AI Governance
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Uncertainty Type & Risk (known distributions) & Deep uncertainty
(unknown unknowns) \\
Causal Structure & Linear, traceable & Multi-level, feedback loops \\
Reversibility & Course correction possible & Path dependencies,
lock-in \\
Fact-Value Separation & Clear boundaries & Entangled
technical-normative \\
Empirical Grounding & Historical precedents & Unprecedented phenomena \\
Time Horizons & Years to decades & Months to centuries \\
\end{longtable}

\subsection{2.2.2 Limitations of Traditional
Approaches}\label{limitations-of-traditional-approaches}

Standard policy evaluation tools prove inadequate for these challenges:

\textbf{Cost-Benefit Analysis} assumes commensurable outcomes and stable
probability distributions. When potential outcomes include existential
catastrophe with deeply uncertain probabilities, the mathematical
machinery breaks down. Infinite negative utility resists standard
decision frameworks.

\textbf{Scenario Planning} helps explore possible futures but typically
lacks the probabilistic reasoning needed for decision-making under
uncertainty. Without quantification, scenarios provide narrative
richness but limited action guidance.

\textbf{Expert Elicitation} aggregates specialist judgment but struggles
with interdisciplinary questions where no single expert grasps all
relevant factors. Moreover, experts often operate with different
implicit models, making aggregation problematic.

\textbf{Red Team Exercises} test specific plans but miss systemic risks
emerging from component interactions. Gaming individual failures cannot
reveal emergent catastrophic possibilities.

These limitations create a methodological gap: we need approaches that
handle deep uncertainty, represent complex causation, quantify expert
disagreement, and enable systematic exploration of intervention effects.

\subsection{2.2.3 The Underlying Epistemic
Framework}\label{the-underlying-epistemic-framework}

The AMTAIR approach rests on a specific epistemic framework that
combines probabilistic reasoning, conditional logic, and possible worlds
semantics. This framework provides the philosophical foundation for
representing deep uncertainty about AI futures.

\textbf{Probabilistic Epistemology}: Following the Bayesian tradition,
we treat probability as a measure of rational credence rather than
objective frequency. This subjective interpretation allows meaningful
probability assignments even for unique, unprecedented events like AI
catastrophe. As E.T. Jaynes demonstrated, probability theory extends
deductive logic to handle uncertainty, providing a calculus for rational
belief \textcite{jaynes2003}.

\textbf{Conditional Structure}: The framework emphasizes conditional
rather than absolute probabilities. Instead of asking ``What is
P(catastrophe)?'' we ask ``What is P(catastrophe \textbar{} specific
assumptions)?'' This conditionalization makes explicit the dependency of
conclusions on worldview assumptions, enabling productive disagreement
about premises rather than conclusions.

\textbf{Possible Worlds Semantics}: We conceptualize uncertainty as
distributions over possible worlds---complete descriptions of how
reality might unfold. Each world represents a coherent scenario with
specific values for all relevant variables. Probability distributions
over these worlds capture both what we know and what we don't know about
the future.

This framework enables several key capabilities:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Representing ignorance}: We can express uncertainty about
  uncertainty itself through hierarchical probability models
\item
  \textbf{Combining evidence}: Bayesian updating provides principled
  methods for integrating new information
\item
  \textbf{Comparing worldviews}: Different probability distributions
  over the same space of possibilities enable systematic comparison
\item
  \textbf{Evaluating interventions}: Counterfactual reasoning about how
  actions change probability distributions
\end{enumerate}

\subsection{2.2.4 Toward New Epistemic
Tools}\label{toward-new-epistemic-tools}

The inadequacy of traditional methods for AI governance creates an
urgent need for new epistemic tools. These tools must:

\begin{itemize}
\tightlist
\item
  \textbf{Handle Deep Uncertainty}: Move beyond point estimates to
  represent ranges of possibilities
\item
  \textbf{Capture Complex Causation}: Model multi-level interactions and
  feedback loops
\item
  \textbf{Quantify Disagreement}: Make explicit where experts diverge
  and why
\item
  \textbf{Enable Systematic Analysis}: Support rigorous comparison of
  policy options
\end{itemize}

\textbf{Key Insight}: The computational approaches developed in this
thesis---particularly Bayesian networks enhanced with automated
extraction---directly address each of these requirements by providing
formal frameworks for reasoning under uncertainty.

Show Image

Show Image

Show Image

Show Image

Recent work on conditional trees demonstrates the value of structured
approaches to uncertainty. McCaslin et al. \textcite{mccaslin2024} show
how hierarchical conditional forecasting can identify high-value
questions for reducing uncertainty about complex topics like AI risk.
Their methodology, which asks experts to produce simplified Bayesian
networks of informative forecasting questions, achieved nine times
higher information value than standard forecasting platform questions.

Tetlock's work with the Forecasting Research Institute
\textcite{tetlock2022} exemplifies how prediction markets can provide
empirical grounding for formal models. By structuring questions as
conditional trees, they enable forecasters to express complex
dependencies between events, providing exactly the type of data needed
for Bayesian network parameterization.

Gruetzemacher \textcite{gruetzemacher2022} evaluates the tradeoffs
between full Bayesian networks and conditional trees for forecasting
tournaments. While conditional trees offer simplicity, Bayesian networks
provide richer representation of dependencies---motivating AMTAIR's
approach of using full networks while leveraging conditional tree
insights for question generation.

\section{2.3 Bayesian Networks as Knowledge
Representation}\label{bayesian-networks-as-knowledge-representation}

Bayesian networks offer a mathematical framework uniquely suited to
addressing these epistemic challenges. By combining graphical structure
with probability theory, they provide tools for reasoning about complex
uncertain domains.

\subsection{2.3.1 Mathematical
Foundations}\label{mathematical-foundations}

A Bayesian network consists of:

\begin{itemize}
\tightlist
\item
  \textbf{Directed Acyclic Graph (DAG)}: Nodes represent variables,
  edges represent direct dependencies
\item
  \textbf{Conditional Probability Tables (CPTs)}: For each node,
  P(node\textbar parents) quantifies relationships
\end{itemize}

The joint probability distribution factors according to the graph
structure:

P(X1,X2,\ldots,Xn)=∏i=1nP(Xi∣Parents(Xi))P(X\_1, X\_2, \ldots, X\_n) =
\prod\_\{i=1\}\^{}\{n\} P(X\_i \textbar{}
Parents(X\_i))P(X1\hspace{0pt},X2\hspace{0pt},\ldots,Xn\hspace{0pt})=i=1∏n\hspace{0pt}P(Xi\hspace{0pt}∣Parents(Xi\hspace{0pt}))

This factorization enables efficient inference and embodies causal
assumptions explicitly.

Pearl's foundational work \textcite{pearl2014} established Bayesian
networks as a principled approach to automated reasoning under
uncertainty, providing both theoretical foundations and practical
algorithms.

\subsection{2.3.2 The Rain-Sprinkler-Grass
Example}\label{the-rain-sprinkler-grass-example}

The canonical example illustrates key concepts\footnote{This example,
  while simple, demonstrates all essential features of Bayesian networks
  and serves as the foundation for understanding more complex
  applications}:

\begin{verbatim}
[Grass_Wet]: Concentrated moisture on grass. 
 + [Rain]: Water falling from sky.
 + [Sprinkler]: Artificial watering system.
   + [Rain]
\end{verbatim}

Network Structure:

\begin{itemize}
\tightlist
\item
  \textbf{Rain} (root cause): P(rain) = 0.2
\item
  \textbf{Sprinkler} (intermediate): P(sprinkler\textbar rain) varies by
  rain state
\item
  \textbf{Grass\_Wet} (effect): P(wet\textbar rain, sprinkler) depends
  on both causes
\end{itemize}

mermaid

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{flowchart TD}
\NormalTok{    R[Rain\textless{}br/\textgreater{}P(rain) = 0.2] {-}{-}\textgreater{} S[Sprinkler]}
\NormalTok{    R {-}{-}\textgreater{} G[Grass\_Wet]}
\NormalTok{    S {-}{-}\textgreater{} G}
    
\NormalTok{    subgraph CPT1[Sprinkler CPT]}
\NormalTok{        S1[P(sprinkler|rain) = 0.01]}
\NormalTok{        S2[P(sprinkler|¬rain) = 0.4]}
\NormalTok{    end}
    
\NormalTok{    subgraph CPT2[Grass\_Wet CPT]}
\NormalTok{        G1[P(wet|rain,sprinkler) = 0.99]}
\NormalTok{        G2[P(wet|rain,¬sprinkler) = 0.8]}
\NormalTok{        G3[P(wet|¬rain,sprinkler) = 0.9]}
\NormalTok{        G4[P(wet|¬rain,¬sprinkler) = 0.01]}
\NormalTok{    end}
\end{Highlighting}
\end{Shaded}

python

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Basic network representation}
\NormalTok{nodes }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}Rain\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Sprinkler\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Grass\_Wet\textquotesingle{}}\NormalTok{]}
\NormalTok{edges }\OperatorTok{=}\NormalTok{ [(}\StringTok{\textquotesingle{}Rain\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Sprinkler\textquotesingle{}}\NormalTok{), (}\StringTok{\textquotesingle{}Rain\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Grass\_Wet\textquotesingle{}}\NormalTok{), (}\StringTok{\textquotesingle{}Sprinkler\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Grass\_Wet\textquotesingle{}}\NormalTok{)]}

\CommentTok{\# Conditional probability specification}
\NormalTok{P\_wet\_given\_causes }\OperatorTok{=}\NormalTok{ \{}
\NormalTok{    (}\VariableTok{True}\NormalTok{, }\VariableTok{True}\NormalTok{): }\FloatTok{0.99}\NormalTok{,    }\CommentTok{\# Rain=T, Sprinkler=T}
\NormalTok{    (}\VariableTok{True}\NormalTok{, }\VariableTok{False}\NormalTok{): }\FloatTok{0.80}\NormalTok{,   }\CommentTok{\# Rain=T, Sprinkler=F  }
\NormalTok{    (}\VariableTok{False}\NormalTok{, }\VariableTok{True}\NormalTok{): }\FloatTok{0.90}\NormalTok{,   }\CommentTok{\# Rain=F, Sprinkler=T}
\NormalTok{    (}\VariableTok{False}\NormalTok{, }\VariableTok{False}\NormalTok{): }\FloatTok{0.01}   \CommentTok{\# Rain=F, Sprinkler=F}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

This simple network demonstrates:

\begin{itemize}
\tightlist
\item
  \textbf{Marginal Inference}: P(grass\_wet) computed from joint
  distribution
\item
  \textbf{Diagnostic Reasoning}: P(rain\textbar grass\_wet) reasoning
  from effects to causes
\item
  \textbf{Intervention Modeling}: P(grass\_wet\textbar do(sprinkler=on))
  for policy analysis
\end{itemize}

Show Image

\subsubsection{Rain-Sprinkler-Grass Network
Rendering}\label{rain-sprinkler-grass-network-rendering}

\begin{verbatim}
#| label: rain_sprinkler_grass_example_network_rendering
#| echo: true
#| eval: true
#| fig-cap: "Dynamic Html Rendering of the Rain-Sprinkler-Grass DAG with Conditional Probabilities"
#| fig-link: "https://singularitysmith.github.io/AMTAIR_Prototype/bayesian_network.html"
#| fig-alt: "Dynamic Html Rendering of the Rain-Sprinkler-Grass DAG"

from IPython.display import IFrame

IFrame(src="https://singularitysmith.github.io/AMTAIR_Prototype/bayesian_network.html", width="100%", height="600px")
\end{verbatim}

\subsection{2.3.3 Advantages for AI Risk
Modeling}\label{advantages-for-ai-risk-modeling}

These features address key requirements for AI governance:

\begin{itemize}
\tightlist
\item
  \textbf{Handling Uncertainty}: Every parameter is a distribution, not
  a point estimate
\item
  \textbf{Representing Causation}: Directed edges embody causal
  relationships
\item
  \textbf{Enabling Analysis}: Formal inference algorithms support
  systematic evaluation
\item
  \textbf{Facilitating Communication}: Visual structure aids
  cross-domain understanding
\end{itemize}

\newpage{}

\subsection{2.3.3 Advantages for AI Risk
Modeling}\label{sec-modeling-advantages}

Bayesian networks offer several compelling advantages for the peculiar
challenge of modeling AI risks---a domain where we're essentially trying
to reason about systems that don't yet exist, wielding capabilities we
can barely imagine, potentially causing outcomes we desperately hope to
avoid.

\textbf{Explicit Uncertainty Representation}: Unlike traditional risk
assessment tools that often hide uncertainty behind point estimates,
Bayesian networks wear their uncertainty on their sleeve. Every node,
every edge, every probability is a distribution rather than a false
certainty. This matters enormously when discussing AI
catastrophe---we're not pretending to know the unknowable, but rather
mapping the landscape of our ignorance with mathematical precision.

\textbf{Native Causal Reasoning}: The directed edges in Bayesian
networks aren't just arrows on a diagram; they encode causal beliefs
about how the world works. This enables both forward reasoning (``If we
develop AGI, what happens?'') and diagnostic reasoning (``Given that we
observe concerning AI behaviors, what does this tell us about underlying
alignment?''). Pearl's do-calculus \textcite{pearl2009} transforms these
networks into laboratories for counterfactual exploration.

\textbf{Evidence Integration}: As new research emerges, as capabilities
advance, as governance experiments succeed or fail, Bayesian networks
provide a principled framework for updating our beliefs. Unlike static
position papers that age poorly, these models can evolve with our
understanding---a living document for a rapidly changing field.

\textbf{Modular Construction}: Complex arguments about AI risk involve
multiple interacting factors across technical, social, and political
domains. Bayesian networks allow us to build these arguments piece by
piece, validating each component before assembling the whole. This
modularity also enables different experts to contribute their
specialized knowledge without needing to understand every aspect of the
system.

\textbf{Visual Communication}: Perhaps most importantly for the
coordination challenge, Bayesian networks provide a visual language that
transcends disciplinary boundaries. A policymaker might not understand
the mathematics of instrumental convergence, but they can see how the
``power-seeking'' node connects to ``human disempowerment'' in the
network diagram. This shared visual vocabulary creates common ground for
productive disagreement.

\section{2.4 Argument Mapping and Formal
Representations}\label{sec-argument-mapping}

The journey from a researcher's intuition about AI risk to a formal
probabilistic model resembles translating poetry into
mathematics---something essential is always at risk of being lost, yet
something equally essential might be gained. Argument mapping provides
the crucial middle ground, a structured approach to preserving the logic
of natural language arguments while preparing them for mathematical
formalization.

\subsection{2.4.1 From Natural Language to
Structure}\label{sec-natural-to-structure}

Natural language arguments about AI risk are rich tapestries woven from
causal claims, conditional relationships, uncertainty expressions, and
support patterns. When Bostrom writes about the ``treacherous turn''
\textcite{bostrom2014}, he's not just coining a memorable phrase---he's
encoding a complex causal story about how a seemingly aligned AI system
might conceal its true objectives until it gains sufficient power to
pursue them without constraint.

The challenge lies in extracting this structure without losing the
nuance. Traditional logical analysis might reduce Bostrom's argument to
syllogisms, but this would miss the probabilistic texture, the implicit
conditionality, the causal directionality that makes the argument
compelling. Argument mapping takes a different approach, seeking to
identify:

\begin{itemize}
\tightlist
\item
  \textbf{Core claims and propositions}: What exactly is being asserted?
\item
  \textbf{Inferential relationships}: How do claims support or challenge
  each other?
\item
  \textbf{Implicit assumptions}: What unstated premises make the
  argument work?
\item
  \textbf{Uncertainty qualifications}: Where does the author express
  doubt or confidence?
\end{itemize}

Recent advances in computational argument mining \textcite{anderson2007}
\textcite{benn2011} \textcite{khartabil2021} have shown promise in
automating parts of this process. Tools like Microsoft's Claimify
\textcite{metropolitansky2025} demonstrate how large language models can
extract verifiable claims from complex texts, though the challenge of
preserving argumentative structure remains formidable.

\subsection{2.4.2 ArgDown: Structured Argument
Notation}\label{sec-argdown-notation}

Enter ArgDown \textcite{voigt2025}, a markdown-inspired syntax that
captures hierarchical argument structure while remaining human-readable.
Think of it as the middle child between the wild expressiveness of
natural language and the rigid formality of logic---inheriting the best
traits of both parents while developing its own personality.

\begin{verbatim}
[AI_Poses_Risk]: Advanced AI systems may pose existential risk to humanity.
 + [Capability_Growth]: AI capabilities are growing exponentially.
   + [Compute_Scaling]: Available compute doubles every few months.
   + [Algorithmic_Progress]: New architectures show surprising emergent abilities.
 + [Alignment_Difficulty]: Aligning AI with human values is unsolved.
   - [Current_Progress]: Some progress on interpretability and oversight.
 - [Institutional_Response]: Institutions are mobilizing to address risks.
\end{verbatim}

This notation does several clever things simultaneously. The
hierarchical structure mirrors how we naturally think about
arguments---main claims supported by evidence, which in turn rest on
more fundamental observations. The \texttt{+} and \texttt{-} symbols
indicate support and opposition relationships, creating a visual flow of
argumentative force. Most importantly, it preserves the semantic content
of each claim while imposing just enough structure to enable
computational processing.

For AMTAIR, we adapt ArgDown specifically for causal arguments, where
the hierarchy represents causal influence rather than logical support.
This seemingly small change has profound implications---we're not just
mapping what follows from what, but what causes what.

\subsection{2.4.3 BayesDown: The Bridge to Bayesian
Networks}\label{sec-bayesdown}

If ArgDown is the middle child, then BayesDown---developed specifically
for this thesis---is the ambitious younger sibling who insists on
quantifying everything. By extending ArgDown syntax with probabilistic
metadata in JSON format, BayesDown creates a complete specification for
Bayesian networks while maintaining human readability.

json

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{[}\ErrorTok{Existential\_Catastrophe}\OtherTok{]}\ErrorTok{:} \ErrorTok{Permanent} \ErrorTok{curtailment} \ErrorTok{of} \ErrorTok{humanity\textquotesingle{}s} \ErrorTok{potential.} \FunctionTok{\{}
  \DataTypeTok{"instantiations"}\FunctionTok{:} \OtherTok{[}\StringTok{"catastrophe\_TRUE"}\OtherTok{,} \StringTok{"catastrophe\_FALSE"}\OtherTok{]}\FunctionTok{,}
  \DataTypeTok{"priors"}\FunctionTok{:} \FunctionTok{\{}\DataTypeTok{"p(catastrophe\_TRUE)"}\FunctionTok{:} \StringTok{"0.05"}\FunctionTok{,} \DataTypeTok{"p(catastrophe\_FALSE)"}\FunctionTok{:} \StringTok{"0.95"}\FunctionTok{\},}
  \DataTypeTok{"posteriors"}\FunctionTok{:} \FunctionTok{\{}
    \DataTypeTok{"p(catastrophe\_TRUE|disempowerment\_TRUE)"}\FunctionTok{:} \StringTok{"0.95"}\FunctionTok{,}
    \DataTypeTok{"p(catastrophe\_TRUE|disempowerment\_FALSE)"}\FunctionTok{:} \StringTok{"0.001"}
  \FunctionTok{\}}
\FunctionTok{\}}
 \ErrorTok{+} \OtherTok{[}\ErrorTok{Human\_Disempowerment}\OtherTok{]}\ErrorTok{:} \ErrorTok{Loss} \ErrorTok{of} \ErrorTok{human} \ErrorTok{control} \ErrorTok{over} \ErrorTok{future} \ErrorTok{trajectory.} \FunctionTok{\{}
   \DataTypeTok{"instantiations"}\FunctionTok{:} \OtherTok{[}\StringTok{"disempowerment\_TRUE"}\OtherTok{,} \StringTok{"disempowerment\_FALSE"}\OtherTok{]}\FunctionTok{,}
   \DataTypeTok{"priors"}\FunctionTok{:} \FunctionTok{\{}\DataTypeTok{"p(disempowerment\_TRUE)"}\FunctionTok{:} \StringTok{"0.20"}\FunctionTok{,} \DataTypeTok{"p(disempowerment\_FALSE)"}\FunctionTok{:} \StringTok{"0.80"}\FunctionTok{\}}
 \FunctionTok{\}}
\end{Highlighting}
\end{Shaded}

This representation performs a delicate balancing act. The natural
language descriptions preserve the semantic meaning that makes arguments
comprehensible. The hierarchical structure maintains the causal
relationships that give arguments their logical force. The JSON metadata
adds the mathematical precision needed for formal analysis. Together,
they create what I call a ``hybrid representation''---neither fully
natural nor fully formal, but something more useful than either alone.

The two-stage extraction process (ArgDown → BayesDown) mirrors how
experts actually think about complex arguments. First, we identify what
matters and how things relate causally (structure). Then, we consider
how likely different scenarios are based on those relationships
(quantification). This separation isn't just convenient for
implementation---it's psychologically valid.

\section{2.5 The MTAIR Framework: Achievements and
Limitations}\label{sec-mtair-framework}

Understanding AMTAIR requires understanding its intellectual ancestor:
the Modeling Transformative AI Risks (MTAIR) project. Like many good
ideas in science, MTAIR began with a simple observation and a ambitious
goal.

\subsection{2.5.1 MTAIR's Approach}\label{sec-mtair-approach}

The MTAIR project, spearheaded by David Manheim and colleagues
\textcite{clarke2022}, emerged from a frustration familiar to anyone
who's attended a conference on AI safety: brilliant people talking past
each other, using the same words to mean different things, reaching
incompatible conclusions from seemingly shared premises. The diagnosis
was elegant---perhaps these disagreements stemmed not from fundamental
philosophical differences but from implicit models that had never been
made explicit.

Their prescription was equally elegant: manually translate influential
AI risk arguments into formal Bayesian networks, making assumptions
visible and disagreements quantifiable. Using Analytica software, the
team embarked on what can only be described as an intellectual
archaeology expedition, carefully excavating the implicit causal models
buried in papers, blog posts, and treatises about AI risk.

The process was painstaking:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Systematic Decomposition}: Breaking complex arguments into
  component claims, identifying variables and relationships through
  close reading and expert consultation.
\item
  \textbf{Probability Elicitation}: Gathering quantitative estimates
  through structured expert interviews, literature review, and careful
  interpretation of qualitative claims.
\item
  \textbf{Sensitivity Analysis}: Testing which parameters most
  influenced conclusions, revealing where disagreements actually
  mattered versus where they were merely academic.
\item
  \textbf{Visual Communication}: Creating interactive models that
  stakeholders could explore, modify, and understand without deep
  technical training.
\end{enumerate}

The ambition was breathtaking---to create a formal lingua franca for AI
risk discussions, enabling productive disagreement and cumulative
progress.

\subsection{2.5.2 Key Achievements}\label{sec-mtair-achievements}

Credit where credit is due: MTAIR demonstrated something many thought
impossible. Complex philosophical arguments about AI risk---the kind
that sprawl across hundred-page papers mixing technical detail with
speculative scenarios---could indeed be formalized without losing their
essential insights.

\textbf{Feasibility of Formalization}: The project's greatest
achievement was simply showing it could be done. Arguments from Bostrom,
Christiano, and others translated surprisingly well into network form,
suggesting that beneath the surface complexity lay coherent causal
models waiting to be extracted.

\textbf{Value of Quantification}: Moving from ``likely'' and
``probably'' to actual numbers forced precision in a domain often
clouded by vague pronouncements. Disagreements that seemed fundamental
sometimes evaporated when forced to specify exactly what probability
ranges were under dispute.

\textbf{Cross-Perspective Communication}: The formal models created
neutral ground where technical AI researchers and policy wonks could
meet. Instead of talking past each other in incompatible languages, they
could point to specific nodes and edges, making disagreements concrete
and tractable.

\textbf{Research Prioritization}: Perhaps most practically, sensitivity
analysis revealed which empirical questions actually mattered. If
changing your belief about technical parameter X from 0.3 to 0.7 doesn't
meaningfully affect the conclusion about AI risk, maybe we should focus
our research elsewhere.

\subsection{2.5.3 Fundamental Limitations}\label{sec-mtair-limitations}

But here's where the story takes a sobering turn. Despite these
achievements, MTAIR faced limitations that prevented it from achieving
its full vision---limitations that ultimately motivated the development
of AMTAIR.

\textbf{Labor Intensity}: Creating a single model required what can
charitably be called a heroic effort. Based on team reports and model
complexity, estimates ranged from 200 to 400 expert-hours per
formalization\footnote{These estimates include time for initial
  extraction, expert consultation, probability elicitation, validation,
  and refinement}. In a field where new influential arguments appear
monthly, this pace couldn't keep up with the discourse.

\textbf{Static Nature}: Once built, these beautiful models began aging
immediately. New research emerged, capability assessments shifted,
governance proposals evolved---but updating the models required
near-complete reconstruction. They were snapshots of arguments at
particular moments, not living representations that could evolve.

\textbf{Limited Accessibility}: Using the models required Analytica
software and non-trivial technical sophistication. The very experts
whose arguments were being formalized often couldn't directly engage
with their formalized representations without intermediation.

\textbf{Single Perspective}: Each model represented one worldview at a
time. Comparing different perspectives required building entirely
separate models, making systematic comparison across viewpoints
labor-intensive and error-prone.

These weren't failures of execution but fundamental constraints of the
manual approach. Like medieval scribes copying manuscripts, the MTAIR
team had shown the value of preservation and dissemination, but the
printing press had yet to be invented.

\subsection{2.5.4 The Automation
Opportunity}\label{sec-automation-opportunity}

The MTAIR experience revealed a tantalizing possibility: if the
bottleneck was human labor rather than conceptual feasibility, perhaps
automation could crack open the problem. The rise of large language
models capable of sophisticated reasoning about text created a
technological moment ripe for exploitation.

Key lessons from MTAIR informed the automation approach:

\begin{itemize}
\tightlist
\item
  Formal models genuinely enhance understanding and coordination---the
  juice is worth the squeeze
\item
  The modeling process itself surfaces implicit assumptions---extraction
  is as valuable as the final product
\item
  Quantification enables analyses impossible with qualitative arguments
  alone---numbers matter even when uncertain
\item
  But manual approaches cannot scale to match the challenge---we need
  computational leverage
\end{itemize}

This set the stage for AMTAIR's central innovation: using frontier
language models to automate the extraction and formalization process
while preserving the benefits MTAIR had demonstrated. Not to replace
human judgment, but to amplify it---turning what took weeks into what
takes hours, enabling comprehensive coverage rather than selective
sampling.

\section{2.6 Literature Review: Content and Technical
Levels}\label{sec-literature-review}

The intellectual landscape surrounding AI risk resembles a rapidly
expanding metropolis---new neighborhoods of thought spring up monthly,
connected by bridges of varying stability to the established districts.
A comprehensive review would fill volumes, so let me provide a guided
tour of the territories most relevant to AMTAIR's mission.

\subsection{2.6.1 AI Risk Models
Evolution}\label{sec-risk-models-evolution}

The evolution of AI risk models traces a path from philosophical
speculation to increasingly rigorous formalization---a journey from
``what if?'' to ``how likely?''

\textbf{Early Phase (2000-2010)}: The conversation began with broad
conceptual arguments. Good's ultraintelligent machine
\textcite{good1966} and Vinge's technological singularity set the stage,
but these were more thought experiments than models. Yudkowsky's early
writings \textcite{yudkowsky2008} introduced key concepts like recursive
self-improvement and orthogonality but remained largely qualitative.

\textbf{Formalization Phase (2010-2018)}: Bostrom's
\emph{Superintelligence} \textcite{bostrom2014} marked a watershed,
providing systematic analysis of pathways, capabilities, and risks. The
book's genius lay not in mathematical formalism but in conceptual
clarity---decomposing the nebulous fear of ``robot overlords'' into
specific mechanisms like instrumental convergence and infrastructure
profusion.

\textbf{Quantification Phase (2018-present)}: Recent years have seen
explicit probability estimates entering mainstream discourse.
Carlsmith's power-seeking model \textcite{carlsmith2022}, Cotra's
biological anchors, and various compute-based timelines represent
attempts to put numbers on previously qualitative claims. The field
increasingly recognizes that governance decisions require more than
philosophical arguments---they need probability distributions.

This progression reflects a maturing field, though it also creates new
challenges. As models become more quantitative, they risk false
precision. As they become more complex, they risk inscrutability. AMTAIR
attempts to navigate these tensions by preserving the narrative clarity
of earlier work while enabling the mathematical rigor of recent
approaches.

\subsection{2.6.2 Governance Proposals
Taxonomy}\label{sec-governance-taxonomy}

If risk models are the diagnosis, governance proposals are the treatment
plans---and like medicine, they range from gentle interventions to
radical surgery.

\textbf{Technical Standards}: The ``first, do no harm'' approach focuses
on concrete safety requirements---interpretability benchmarks,
robustness testing, capability thresholds. These proposals, exemplified
by standard-setting bodies and technical safety organizations, offer
specificity at the cost of narrowness.

\textbf{Regulatory Frameworks}: Moving up the intervention ladder, we
find comprehensive regulatory proposals like the EU AI Act
\textcite{european2024}. These create institutional structures,
liability regimes, and oversight mechanisms, trading broad coverage for
implementation complexity.

\textbf{International Coordination}: At the ambitious end, proposals for
international AI governance treaties, soft law arrangements, and
technical cooperation agreements aim to prevent races to the bottom.
Think nuclear non-proliferation but for minds instead of missiles.

\textbf{Research Priorities}: Cutting across these categories, work by
Dafoe \textcite{dafoe2018} and others maps the research landscape
itself---what questions need answering before we can govern wisely? This
meta-level analysis shapes funding flows and talent allocation.

A particularly compelling example of conditional governance thinking
comes from ``A Narrow Path'' \textcite{miotti2024}, which proposes a
phased approach: immediate safety measures to prevent uncontrolled
development, international institutions to ensure stability, and
long-term scientific foundations for beneficial transformative AI. This
temporal sequencing---safety, stability, then flourishing---reflects
growing sophistication in governance thinking.

\subsection{2.6.3 Bayesian Network Theory and
Applications}\label{sec-bn-theory}

The mathematical machinery underlying AMTAIR rests on decades of
theoretical development in probabilistic graphical models. Understanding
this foundation helps appreciate both the power and limitations of the
approach.

The key insight, crystallized in the work of Pearl \textcite{pearl2014}
and elaborated by Koller \& Friedman \textcite{koller2009}, is that
independence relationships in complex systems can be read from graph
structure. D-separation, the Markov condition, and the relationship
between graphs and probability distributions provide the mathematical
spine that makes Bayesian networks more than pretty pictures.

Critical concepts for AI risk modeling:

\begin{itemize}
\tightlist
\item
  \textbf{Conditional Independence}: Variable A is independent of C
  given B---encoded through graph separation
\item
  \textbf{Markov Condition}: Each variable is independent of its
  non-descendants given its parents
\item
  \textbf{Inference Algorithms}: From exact variable elimination to
  approximate Monte Carlo methods
\item
  \textbf{Causal Interpretation}: When edges represent causal influence,
  the network supports counterfactual reasoning
\end{itemize}

These aren't just mathematical niceties. When we claim that ``deployment
decisions'' mediates the relationship between ``capability advancement''
and ``catastrophic risk,'' we're making a precise statement about
conditional independence that has testable implications.

\subsection{2.6.4 Software Tools Landscape}\label{sec-software-tools}

The gap between Bayesian network theory and practical implementation is
bridged by an ecosystem of software tools, each with its own strengths
and opinions about how probabilistic reasoning should work.

\textbf{pgmpy}: This Python library provides the computational backbone
for AMTAIR, offering both learning algorithms and inference engines. Its
object-oriented design maps naturally onto our extraction pipeline.

\textbf{NetworkX}: For graph manipulation and analysis, NetworkX has
become the de facto standard in Python, providing algorithms for
everything from centrality measurement to community detection.

\textbf{PyVis}: Interactive visualization transforms static networks
into explorable landscapes. PyVis's integration with web technologies
enables the rich interactive features that make formal models
accessible.

\textbf{Pandas/NumPy}: The workhorses of scientific Python handle data
manipulation and numerical computation, providing the infrastructure on
which everything else builds.

The integration challenge---making these tools play nicely together
while maintaining performance and correctness---shaped many
architectural decisions in AMTAIR. Each tool excels in its domain, but
the seams between them required careful engineering.

\subsection{2.6.5 Formalization Approaches}\label{sec-formalization}

The challenge of formalizing natural language arguments extends far
beyond AI risk, touching on fundamental questions in logic, linguistics,
and artificial intelligence.

Pollock's work on cognitive carpentry \textcite{pollock1995} provides
philosophical grounding, arguing that human reasoning itself involves
implicit formal structures that can be computationally modeled. This
view---that formalization reveals rather than imposes
structure---underlies AMTAIR's approach.

Key theoretical challenges:

\begin{itemize}
\tightlist
\item
  \textbf{Semantic Preservation}: How do we maintain meaning while
  adding precision?
\item
  \textbf{Structural Extraction}: What implicit relationships lurk in
  natural language?
\item
  \textbf{Uncertainty Quantification}: How do we map ``likely'' to
  numbers?
\end{itemize}

Recent work on causal structure learning from text
\textcite{babakov2025} \textcite{ban2023} \textcite{bethard2007} offers
hope that these challenges can be addressed computationally. The
convergence of large language models with formal methods creates new
possibilities for bridging the semantic-symbolic gap.

\subsection{2.6.6 Correlation Accounting
Methods}\label{sec-correlation-methods}

One of the most persistent criticisms of Bayesian networks concerns
their assumption of conditional independence given parents. In the real
world, and especially in complex socio-technical systems like AI
development, correlations abound.

Methods for handling these correlations have evolved considerably:

\textbf{Copula Methods}: By separating marginal distributions from
dependence structure, copulas \textcite{nelson2006} allow modeling of
complex correlations while preserving the Bayesian network framework.
Think of it as adding a correlation layer on top of the basic network.

\textbf{Hierarchical Models}: Introducing latent variables that
influence multiple observed variables captures correlations naturally.
If ``AI research culture'' influences both ``capability progress'' and
``safety investment,'' their correlation is explained.

\textbf{Explicit Correlation Nodes}: Sometimes the most straightforward
approach is best---directly model correlation mechanisms as additional
nodes in the network.

\textbf{Sensitivity Bounds}: When correlations remain uncertain, compute
best and worst case scenarios. This reveals when independence
assumptions critically affect conclusions versus when they're harmless
simplifications.

For AMTAIR, the pragmatic approach dominates: start with independence
assumptions, identify where they matter through sensitivity analysis,
then selectively add correlation modeling where it most affects
conclusions.

\section{2.7 Methodology}\label{sec-methodology}

The methodology of this research resembles less a linear march from
hypothesis to conclusion and more an iterative dance between theory and
implementation, vision and reality. Let me walk you through the
choreography.

\subsection{2.7.1 Research Design Overview}\label{sec-research-design}

This research follows what methodologists might call a ``design
science'' approach---we're not just studying existing phenomena but
creating new artifacts (the AMTAIR system) and evaluating their utility
for solving practical problems (the coordination crisis in AI
governance).

The overall flow:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Theoretical Development}: Establishing why automated
  extraction could address the coordination crisis, grounded in
  epistemic theory and mechanism design
\item
  \textbf{Technical Implementation}: Building working software that
  demonstrates feasibility, not as a proof-of-concept toy but as a
  system capable of handling real arguments
\item
  \textbf{Empirical Validation}: Testing extraction quality against
  expert judgment, measuring not just accuracy but usefulness for
  downstream tasks
\item
  \textbf{Application Studies}: Applying the system to real AI
  governance questions, evaluating whether formal models actually
  enhance decision-making
\end{enumerate}

This isn't waterfall development where each phase completes before the
next begins. Rather, insights from implementation fed back into theory,
validation results shaped technical improvements, and application
attempts revealed new requirements. The methodology itself embodied the
iterative refinement it sought to enable.

\subsection{2.7.2 Formalizing World Models from AI Safety
Literature}\label{sec-formalizing-world-models}

The core methodological challenge---transforming natural language
arguments into formal probabilistic models---requires careful
consideration of what we're actually trying to capture.

A ``world model'' in this context isn't just any formal representation
but specifically a causal model embodying beliefs about how different
factors influence AI risk. The extraction approach must therefore:

\begin{itemize}
\tightlist
\item
  \textbf{Identify key variables}: Not just any entities mentioned, but
  causally relevant factors
\item
  \textbf{Extract causal relationships}: Not mere correlation or
  co-occurrence, but directed influence
\item
  \textbf{Capture uncertainty}: Both structural uncertainty (does A
  cause B?) and parametric uncertainty (how strongly?)
\item
  \textbf{Preserve context}: Maintaining enough semantic information to
  interpret the formal model
\end{itemize}

Large language models enable this through sophisticated pattern
recognition and reasoning capabilities, but they're tools, not magic
wands. The methodology must account for their strengths (recognizing
implicit structure) and weaknesses (potential hallucination,
inconsistency).

\subsection{2.7.3 From Natural Language to Computational
Models}\label{sec-natural-to-computational}

The journey from text to computation follows a carefully designed
pipeline that mirrors human cognitive processes. Just as you wouldn't
ask someone to simultaneously parse grammar and solve equations, we
separate structural understanding from quantitative reasoning.

\textbf{The Two-Stage Process}:

Stage 1 focuses on structure---what causes what? The LLM reads an
argument much as a human would, identifying key claims and their
relationships. The prompt design here is crucial, providing enough
guidance to ensure consistent extraction while allowing flexibility for
different argument styles.

Stage 2 adds quantities---how likely is each outcome? With structure
established, the system generates targeted questions about
probabilities. This separation enables different approaches to
quantification: extracting explicit estimates from text, inferring from
qualitative language, or even connecting to external prediction markets.

The magic happens in the interplay. Structure constrains what
probabilities are needed. Probability requirements might reveal missing
structural elements. The process is a dialogue between qualitative and
quantitative understanding.

\subsection{2.7.4 Directed Acyclic Graphs: Structure and
Semantics}\label{sec-dag-structure}

At the mathematical heart of Bayesian networks lie Directed Acyclic
Graphs (DAGs)---structures that are simultaneously simple enough to
analyze and rich enough to capture complex phenomena.

The ``directed'' part encodes causality or influence---edges have
direction, flowing from cause to effect. The ``acyclic'' part ensures
logical coherence---you can't have A causing B causing C causing A, no
matter how much certain political arguments might suggest otherwise.

Key properties for AI risk modeling:

\textbf{Acyclicity}: More than a mathematical convenience, this enforces
coherent temporal or causal ordering. In AI risk arguments, this
prevents circular reasoning where consequences justify premises that
predict those same consequences.

\textbf{D-separation}: This graphical criterion determines conditional
independence. If knowing about AI capabilities tells you nothing
additional about risk given that you know deployment decisions, then
capabilities and risk are d-separated given deployment.

\textbf{Markov Condition}: Each variable depends only on its parents,
not on its entire ancestry. This locality assumption makes inference
tractable and forces modelers to make intervention points explicit.

\textbf{Path Analysis}: Following paths through the graph reveals how
influence propagates. Multiple paths between variables indicate
redundancy---important for understanding intervention robustness.

The causal interpretation, following Pearl's framework, transforms these
mathematical objects into tools for counterfactual reasoning. When we
ask ``what if we prevented deployment of misaligned systems?'' we're
performing surgery on the DAG, setting variables and propagating
consequences.

\subsection{2.7.5 Quantification of Probabilistic
Judgments}\label{sec-quantification}

Here we encounter one of the most philosophically fraught aspects of the
methodology: turning words into numbers. When an expert writes ``highly
likely,'' what probability should we assign? When they say ``significant
risk,'' what distribution captures their belief?

The methodology embraces rather than elides this challenge:

\textbf{Calibration Studies}: Research on human probability expression
shows systematic patterns. ``Highly likely'' typically maps to 0.8-0.9,
``probable'' to 0.6-0.8, though individual and cultural variation is
substantial.

\textbf{Extraction Strategies}: The system uses multiple approaches:

\begin{itemize}
\tightlist
\item
  Direct extraction: ``We estimate 65\% probability''
\item
  Linguistic mapping: ``Very likely'' → 0.85 (with uncertainty)
\item
  Comparative extraction: ``More likely than X'' where P(X) is known
\item
  Bounded extraction: ``At least 30\%'' → {[}0.30, 1.0{]}
\end{itemize}

\textbf{Uncertainty Representation}: Rather than false precision, we
maintain uncertainty about probabilities themselves. This might seem
like uncertainty piled on uncertainty, but it's honest---and
mathematically tractable through hierarchical models.

The goal isn't perfect extraction but useful extraction. If we can
narrow ``significant risk'' from {[}0, 1{]} to {[}0.15, 0.45{]}, we've
added information even if we haven't achieved precision.

\subsection{2.7.6 Inference Techniques for Complex
Networks}\label{sec-inference-techniques}

Once we've built these formal models, we need to reason with them---and
here computational complexity rears its exponential head. The number of
probability calculations required for exact inference grows
exponentially with network connectivity, quickly overwhelming even
modern computers.

The methodology employs a portfolio of approaches:

\textbf{Exact Methods}: For smaller networks (\textless30 nodes),
variable elimination and junction tree algorithms provide exact answers.
These form the gold standard against which we validate approximate
methods.

\textbf{Sampling Approaches}: Monte Carlo methods trade exactness for
scalability. By simulating many possible worlds consistent with our
probability model, we approximate the true distributions. The law of
large numbers is our friend here.

\textbf{Variational Methods}: These turn inference into
optimization---find the simplest distribution that approximates our true
beliefs. Like finding the best polynomial approximation to a complex
curve.

\textbf{Hybrid Strategies}: Different parts of the network might use
different methods. Exact inference for critical subgraphs, approximation
for peripheral components.

The choice of method affects not just computation time but the types of
questions we can meaningfully ask. This creates a methodological
feedback loop where feasible inference shapes model design.

\subsection{2.7.7 Integration with Prediction Markets and Forecasting
Platforms}\label{sec-prediction-markets}

While full integration remains future work, the methodology anticipates
connection to live forecasting data as a critical enhancement. The
vision is compelling: formal models grounded in collective intelligence,
updating as new information emerges.

The planned approach would involve:

\textbf{Semantic Matching}: Model variables rarely align perfectly with
forecast questions. ``AI causes human extinction'' might map to multiple
specific forecasts about capabilities, deployment, and impacts.
Developing robust matching algorithms is essential.

\textbf{Temporal Alignment}: Markets predict specific dates (``AGI by
2030'') while models consider scenarios (``given AGI development'').
Bridging these requires careful probability conditioning.

\textbf{Quality Weighting}: Not all forecasts are created equal.
Platform reputation, forecaster track records, and market depth all
affect reliability. The methodology must account for this heterogeneity.

\textbf{Update Scheduling}: Real-time updates would overwhelm users and
computation. The system needs intelligent policies about when model
updates provide value.

Platforms like Metaculus \textcite{tetlock2022} already demonstrate
sophisticated conditional forecasting on AI topics. The challenge lies
not in data availability but in meaningful integration that enhances
rather than complicates decision-making.

With these theoretical foundations and methodological commitments
established, we can now turn to the concrete implementation of AMTAIR.
The next chapter demonstrates how these abstract principles translate
into working software that addresses real governance challenges. The
journey from theory to practice always involves surprises---some
pleasant, others less so---but that's what makes it interesting.

\bookmarksetup{startatroot}

\chapter{3. AMTAIR: Design and Implementation}\label{sec-amtair}

The moment of truth in any research project comes when elegant theories
meet stubborn reality. For AMTAIR, this meant transforming the vision of
automated argument extraction into working code that could handle the
beautiful messiness of real AI safety arguments. Let me take you through
this journey from blueprint to implementation, complete with victories,
defeats, and the occasional moment of ``well, that's unexpected.''

\section{3.1 System Architecture
Overview}\label{sec-system-architecture}

Picture, if you will, a factory for transforming arguments into models.
Raw materials (PDFs, blog posts, research papers) enter at one end.
Finished products (interactive Bayesian networks) emerge at the other.
In between lies a carefully orchestrated pipeline where each stage
performs its specialized transformation, passing refined materials to
the next.

The AMTAIR architecture embodies a philosophy: complex tasks become
manageable when decomposed into focused components. Rather than building
a monolithic ``argument-to-model'' black box, we created a series of
specialized modules, each excellent at one thing.

The pipeline consists of five main stages:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Text Ingestion and Preprocessing}: Like a careful librarian,
  this stage catalogues incoming documents, normalizes their format,
  extracts metadata, and identifies the argumentative content worth
  processing.
\item
  \textbf{Argument Extraction}: The intellectual heart of the system,
  where large language models perform their magic, transforming prose
  into structured representations.
\item
  \textbf{Data Transformation}: The workshop where extracted arguments
  are refined, validated, and prepared for mathematical representation.
\item
  \textbf{Network Construction}: The assembly line where formal Bayesian
  networks are instantiated, complete with conditional probability
  tables.
\item
  \textbf{Interactive Visualization}: The showroom where complex models
  become accessible through thoughtful design and interactivity.
\end{enumerate}

\subsection{3.1.1 Five-Stage Pipeline
Architecture}\label{sec-five-stage-pipeline}

Let's examine each stage more closely, understanding not just what they
do but why they exist as separate components.

\textbf{Text Ingestion and Preprocessing} handles the unglamorous but
essential work of standardization. Academic PDFs, with their two-column
layouts and embedded figures, differ vastly from blog posts with inline
code and hyperlinks. This stage creates a uniform representation while
preserving essential structure and metadata. Format normalization strips
away presentation while preserving content. Metadata extraction captures
authorship, publication date, and citations. Relevance filtering
identifies sections containing arguments rather than literature reviews
or acknowledgments. Character encoding standardization prevents those
maddening �replacement characters that plague text processing.

\textbf{Argument Extraction} represents AMTAIR's core innovation. Using
a two-stage process that mirrors human reasoning, it first identifies
structural relationships (what influences what) then quantifies those
relationships (how likely, how strong). This separation enables targeted
prompts optimized for each task, human verification between stages, and
modular improvements as LLM capabilities evolve.

\textbf{Data Transformation} bridges the gap between textual
representations and mathematical models. It parses the BayesDown syntax
into structured data, validates that the resulting network forms a
proper DAG, checks probability consistency, and handles missing data
intelligently.

\textbf{Network Construction} instantiates the formal mathematical
model. This involves creating nodes and edges according to extracted
structure, populating conditional probability tables, initializing
inference engines, and validating the complete model.

\textbf{Interactive Visualization} makes the complex accessible. Through
thoughtful visual encoding of probabilities and relationships,
progressive disclosure of detail, interactive exploration capabilities,
and multiple export formats, it serves diverse stakeholder needs.

\subsection{3.1.2 Design Principles}\label{sec-design-principles}

\textbf{Core Design Philosophy}: The architecture embodies several
principles that guided countless implementation decisions:

\textbf{Modularity}: Each component has clear inputs, outputs, and
responsibilities. This isn't just good software engineering---it enables
independent improvement of components and graceful degradation when
parts fail.

\textbf{Validation Checkpoints}: Between each stage, we validate outputs
before proceeding. Bad extractions don't propagate into visualization.
Malformed networks trigger re-extraction rather than cryptic errors.

\textbf{Human-in-the-Loop}: While pursuing automation, we recognize that
human judgment remains invaluable. The architecture provides natural
intervention points where experts can verify and correct.

\textbf{Extensibility}: New document formats, improved extraction
prompts, alternative visualization libraries---the architecture
accommodates growth without restructuring.

The system emphasizes transparency over black-box efficiency. Users can
inspect intermediate representations, understand extraction decisions,
and verify transformations. This builds trust---essential for a system
handling high-stakes arguments about existential risk.

\section{3.2 The Two-Stage Extraction
Process}\label{sec-two-stage-extraction}

The heart of AMTAIR beats with a two-stage rhythm: structure, then
probability. This separation, which initially seemed like an
implementation detail, revealed itself as fundamental to the extraction
challenge.

\subsection{3.2.1 Stage 1: Structural Extraction
(ArgDown)}\label{sec-stage1-argdown}

Imagine reading a complex argument about AI risk. Your first pass likely
isn't calculating exact probabilities---you're mapping the landscape.
What are the key claims? How do they relate? What supports what? Stage 1
mirrors this cognitive process.

The extraction begins with pattern recognition. Natural language
contains linguistic markers of causal relationships: ``leads to,''
``results in,'' ``depends on,'' ``influences.'' The LLM, trained on vast
corpora of argumentative text, recognizes these patterns and their
variations.

Consider extracting from a passage like: ``The development of artificial
general intelligence will likely lead to rapid capability gains through
recursive self-improvement. This intelligence explosion could result in
systems pursuing convergent instrumental goals, potentially including
resource acquisition and self-preservation. Without solved alignment,
such power-seeking behavior poses existential risks to humanity.''

The system identifies three key variables connected by causal
relationships:

\begin{itemize}
\tightlist
\item
  AGI Development → Intelligence Explosion
\item
  Intelligence Explosion → Power-Seeking Behavior
\item
  Power-Seeking Behavior → Existential Risk
\end{itemize}

But extraction goes beyond simple pattern matching. The system must
handle complex linguistic phenomena like coreference (``this,'' ``such
systems''), implicit relationships, conditional statements, and negative
statements. The magic lies in prompt engineering that guides the LLM to
consistent extraction while remaining flexible enough for diverse
argument styles.

The output, formatted in ArgDown syntax, preserves both structure and
semantics:

\begin{verbatim}
[Existential_Risk]: Threat to humanity's continued existence and flourishing.
 + [Power_Seeking_Behavior]: AI systems pursuing instrumental goals like resource acquisition.
   + [Intelligence_Explosion]: Rapid recursive self-improvement leading to superintelligence.
     + [AGI_Development]: Creation of artificial general intelligence systems.
\end{verbatim}

\subsection{3.2.2 Stage 2: Probability Integration
(BayesDown)}\label{sec-stage2-bayesdown}

With structure established, Stage 2 adds the quantitative flesh to the
qualitative bones. This stage faces a different challenge: extracting
numerical beliefs from text that often expresses uncertainty in
frustratingly vague terms.

The process begins by generating targeted questions based on the
extracted structure. For each node, we need prior probabilities. For
each child-parent relationship, we need conditional probabilities. The
combinatorics can be daunting---a node with three binary parents
requires 8 conditional probability values.

The system employs multiple strategies for probability extraction:

\textbf{Explicit Extraction}: When authors provide numerical estimates
(``we assign 70\% probability''), extraction is straightforward, though
we must handle various formats and contexts.

\textbf{Linguistic Mapping}: Qualitative expressions map to probability
ranges based on calibration studies. ``Highly likely'' becomes
approximately 0.85, though we maintain uncertainty about this mapping.

\textbf{Comparative Reasoning}: Statements like ``more probable than
not'' or ``at least as likely as X'' provide bounds even without exact
values.

\textbf{Coherence Enforcement}: Probabilities must sum correctly. If
P(A\textbar B) = 0.7, then P(not A\textbar B) must equal 0.3. The system
detects and resolves inconsistencies.

The result is a complete BayesDown specification:

json

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{[}\ErrorTok{Existential\_Risk}\OtherTok{]}\ErrorTok{:} \ErrorTok{Threat} \ErrorTok{to} \ErrorTok{humanity\textquotesingle{}s} \ErrorTok{continued} \ErrorTok{existence.} \FunctionTok{\{}
  \DataTypeTok{"instantiations"}\FunctionTok{:} \OtherTok{[}\StringTok{"true"}\OtherTok{,} \StringTok{"false"}\OtherTok{]}\FunctionTok{,}
  \DataTypeTok{"priors"}\FunctionTok{:} \FunctionTok{\{}\DataTypeTok{"p(true)"}\FunctionTok{:} \StringTok{"0.10"}\FunctionTok{,} \DataTypeTok{"p(false)"}\FunctionTok{:} \StringTok{"0.90"}\FunctionTok{\},}
  \DataTypeTok{"posteriors"}\FunctionTok{:} \FunctionTok{\{}
    \DataTypeTok{"p(true|power\_seeking\_true)"}\FunctionTok{:} \StringTok{"0.65"}\FunctionTok{,}
    \DataTypeTok{"p(true|power\_seeking\_false)"}\FunctionTok{:} \StringTok{"0.001"}
  \FunctionTok{\}}
\FunctionTok{\}}
\end{Highlighting}
\end{Shaded}

\subsection{3.2.3 Why Two Stages?}\label{sec-why-two-stages}

The separation of structure from probability isn't merely
convenient---it's cognitively valid and practically essential. Let me
count the ways this design decision pays dividends:

\textbf{Cognitive Alignment}: Humans naturally separate ``what relates
to what'' from ``how likely is it.'' The two-stage process mirrors this,
making the system's operation intuitive and interpretable.

\textbf{Error Isolation}: Structural errors (missing a key variable)
differ fundamentally from probability errors (estimating 0.7 instead of
0.8). Separating stages allows targeted debugging and improvement.

\textbf{Modular Validation}: Experts can verify structure without
needing to evaluate every probability. This enables efficient human
oversight at natural checkpoints.

\textbf{Flexible Quantification}: Different probability sources (text
extraction, expert elicitation, market data) can feed into the same
structure. The architecture accommodates multiple approaches to the
probability challenge.

\textbf{Transparency}: Users can inspect ArgDown to understand what was
extracted before probabilities were added. This builds trust and enables
meaningful correction.

The two-stage approach also revealed an unexpected benefit: ArgDown
itself became a valuable output. Researchers began using these
structural extractions for qualitative analysis, even without
probability quantification. Sometimes, just making argument structure
explicit provides sufficient value.

\section{3.3 Implementation Technologies}\label{sec-implementation-tech}

Choosing technologies for AMTAIR resembled assembling a band---each
instrument needed to excel individually while harmonizing with the
ensemble. The selection criteria balanced capability, maturity,
interoperability, and community support.

\subsection{3.3.1 Technology Stack}\label{sec-tech-stack}

The final ensemble performs beautifully:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Component
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Technology
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Why This Choice
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Language Models & GPT-4, Claude & Argument extraction & State-of-the-art
reasoning capabilities \\
Network Analysis & NetworkX & Graph algorithms & Mature, comprehensive,
well-documented \\
Probabilistic Modeling & pgmpy & Bayesian operations & Native Python,
active development \\
Visualization & PyVis & Interactive rendering & Web-based, customizable,
responsive \\
Data Processing & Pandas & Structured manipulation & Industry standard,
powerful operations \\
\end{longtable}

\textbf{Language Models} form the cognitive core. GPT-4 and Claude
demonstrate remarkable ability to understand complex arguments,
recognize implicit structure, and maintain coherence across long
extractions. The choice to support multiple models provides robustness
and allows leveraging their complementary strengths.

\textbf{NetworkX} handles all graph-theoretic heavy lifting. From basic
operations like cycle detection to advanced algorithms like centrality
measurement, it provides a comprehensive toolkit that would take years
to replicate.

\textbf{pgmpy} bridges the gap between graph structure and probabilistic
reasoning. Its clean API design maps naturally onto our extracted
representations, while its inference algorithms handle the computational
complexity of Bayesian reasoning.

\textbf{PyVis} transforms static networks into living documents. Built
on vis.js, it provides smooth physics simulations, rich interactivity,
and extensive customization options---all accessible through Python.

\textbf{Pandas} might seem mundane compared to its companions, but it's
the reliable rhythm section that keeps everything together. Its ability
to reshape, merge, and transform structured data makes the complex data
transformations tractable.

\subsection{3.3.2 Key Algorithms}\label{sec-key-algorithms}

Beyond the libraries lie custom algorithms that address AMTAIR-specific
challenges:

\textbf{Hierarchical Parsing}: The algorithm that transforms indented
ArgDown text into structured data represents a small miracle of
recursive descent parsing adapted for our custom syntax. It maintains
parent-child relationships while handling edge cases like repeated nodes
and complex dependencies.

python

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ parse\_hierarchy(text, current\_indent}\OperatorTok{=}\DecValTok{0}\NormalTok{):}
    \CommentTok{"""Recursively parse indented structure maintaining relationships"""}
    \CommentTok{\# Track nodes at each level for parent identification}
    \CommentTok{\# Handle repeated nodes by reference}
    \CommentTok{\# Validate DAG property during construction}
\end{Highlighting}
\end{Shaded}

\textbf{Probability Completion}: Real arguments rarely specify all
required probabilities. Our completion algorithm uses maximum entropy
principles---when uncertain, assume maximum disorder. This provides
conservative estimates that can be refined with additional information.

\textbf{Visual Encoding}: The algorithm mapping probabilities to colors
uses perceptual uniformity. The green-to-red gradient isn't linear in
RGB space but follows human perception of color difference. Small
details, big impact on usability.

\textbf{Layout Optimization}: Force-directed layouts often produce
``hairballs'' for complex networks. Our customized approach uses
hierarchical initialization based on causal depth, then refines with
physics simulation. The result: layouts that reveal structure rather
than obscuring it.

\subsection{3.3.3 (Expected) Performance
Characteristics}\label{sec-performance}

Performance in a system like AMTAIR involves multiple
dimensions---speed, accuracy, scalability. Let's examine what
theoretical analysis and design considerations suggest about system
behavior.

\textbf{Computational Complexity}: The extraction phase exhibits linear
complexity in document length---processing twice as much text takes
roughly twice as long. However, the inference phase faces exponential
complexity in network connectivity. A fully connected network with n
binary nodes requires O(2\^{}n) operations for exact inference. This
fundamental limitation shapes practical usage patterns.

\textbf{Practical Implications}: Small networks (\textless20 nodes)
enable real-time interaction with exact inference. Medium networks
(20-50 nodes) require seconds to minutes depending on connectivity.
Large networks (\textgreater50 nodes) necessitate approximate methods,
trading accuracy for tractability. Very large networks push the
boundaries of current methods.

The bottleneck shifts predictably: extraction remains manageable even
for lengthy documents, but inference becomes challenging as models grow.
This suggests a natural workflow---extract comprehensively, then focus
on relevant subnetworks for detailed analysis.

\textbf{Optimization Opportunities}: Several strategies could improve
performance: caching frequent inference queries, hierarchical
decomposition of large networks, parallel processing for independent
subgraphs, and progressive rendering for visualization. The modular
architecture accommodates these enhancements without fundamental
restructuring.

\subsection{3.3.4 Deterministic vs.~Probabilistic Components of the
Workflow}\label{sec-deterministic-probabilistic}

An interesting philosophical question arises: in a system reasoning
about probability, which components should themselves be probabilistic?

The current implementation draws a clear line:

\textbf{Deterministic Components}: All data transformations, graph
algorithms, and inference calculations operate deterministically. Given
the same input, they produce identical output. This provides
reproducibility and debuggability---essential for building trust.

\textbf{Probabilistic Components}: The LLM calls for extraction
introduce variability. Even with temperature set to 0, language models
exhibit some randomness. Different runs might extract slightly different
structures or probability estimates from the same text.

This division reflects a deeper principle: use determinism wherever
possible, embrace probability where necessary. The extraction
task---interpreting natural language---inherently involves uncertainty.
But once we have formal representations, all subsequent operations
should be predictable.

From an information-theoretic perspective, we're trying to extract
maximum information from documents within computational budget
constraints. Each document contains some finite amount of formalizable
argument structure. Our goal is recovering as much as possible given
realistic resource limits.

The two-stage extraction can be viewed as successive refinement---first
recovering the higher-order bits (structure), then filling in
lower-order bits (probabilities). This aligns with rate-distortion
theory, where we get the most important information first.

\section{3.4 Case Study:
Rain-Sprinkler-Grass}\label{sec-case-rain-sprinkler}

Every field has its canonical examples---physics has spherical cows,
economics has widget factories, and Bayesian networks have the
rain-sprinkler-grass scenario. Despite its simplicity, this example
teaches profound lessons about causal reasoning and serves as the
perfect test case for AMTAIR.

\subsection{3.4.1 Processing Steps}\label{sec-rsg-processing}

Let me walk you through how AMTAIR processes this foundational example:

The input arrives as a simple text description: ``When it rains, the
grass gets wet. The sprinkler also makes the grass wet. However, when it
rains, we usually don't run the sprinkler.''

From this prosaic description, the system performs five transformations:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{ArgDown Parsing}: Extract three variables (Rain, Sprinkler,
  Grass\_Wet) and identify that rain influences both sprinkler usage and
  grass wetness, while the sprinkler also influences grass wetness.
\item
  \textbf{Question Generation}: Create probability queries: What's
  P(Rain)? What's P(Sprinkler\textbar Rain)? What's
  P(Grass\_Wet\textbar Rain,Sprinkler) for all combinations?
\item
  \textbf{BayesDown Extraction}: Either extract probabilities from text
  or apply reasonable defaults. The ``usually don't run'' becomes
  P(Sprinkler\textbar Rain) ≈ 0.01.
\item
  \textbf{Network Construction}: Build the formal Bayesian network with
  three nodes, three edges, and complete conditional probability tables.
\item
  \textbf{Visualization Rendering}: Create an interactive display where
  rain appears as a root cause, influencing both sprinkler and grass
  directly.
\end{enumerate}

Each step validates its outputs before proceeding, ensuring that errors
don't cascade through the pipeline.

\subsection{3.4.2 Example Conversion Steps}\label{sec-rsg-input}

Let's trace the actual transformations to see the pipeline in action:

\textbf{Initial ArgDown Extraction}:

markdown

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{[Grass\_Wet]: }\NormalTok{Concentrated moisture on grass blades. \{"instantiations": }\CommentTok{[}\OtherTok{"wet", "dry"}\CommentTok{]}\NormalTok{\}    }
\SpecialStringTok{ + }\CommentTok{[}\OtherTok{Rain}\CommentTok{]}\NormalTok{: Precipitation from the sky. \{"instantiations": }\CommentTok{[}\OtherTok{"raining", "not\_raining"}\CommentTok{]}\NormalTok{\}}
\SpecialStringTok{ + }\CommentTok{[}\OtherTok{Sprinkler}\CommentTok{]}\NormalTok{: Artificial watering system. \{"instantiations": }\CommentTok{[}\OtherTok{"on", "off"}\CommentTok{]}\NormalTok{\}}
\SpecialStringTok{   + }\CommentTok{[}\OtherTok{Rain}\CommentTok{]}
\end{Highlighting}
\end{Shaded}

The hierarchy captures that rain influences sprinkler usage---a subtle
but important causal relationship that pure correlation would miss.

\textbf{Generated Questions for Probability Extraction}:

markdown

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{/* Prior probabilities */}
\SpecialStringTok{{-} }\NormalTok{What is the probability that it rains?}
\SpecialStringTok{{-} }\NormalTok{What is the probability the sprinkler is on?}

\NormalTok{/* Conditional probabilities */  }
\SpecialStringTok{{-} }\NormalTok{What is the probability the sprinkler is on when it\textquotesingle{}s raining?}
\SpecialStringTok{{-} }\NormalTok{What is the probability the sprinkler is on when it\textquotesingle{}s not raining?}
\SpecialStringTok{{-} }\NormalTok{What is the probability the grass is wet when it\textquotesingle{}s raining and sprinkler is on?}
\SpecialStringTok{{-} }\CommentTok{[}\OtherTok{... and so on for all combinations}\CommentTok{]}
\end{Highlighting}
\end{Shaded}

The system generates exactly the questions needed to fully specify the
network---no more, no less.

\textbf{Complete BayesDown Result}:

json

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{[}\ErrorTok{Grass\_Wet}\OtherTok{]}\ErrorTok{:} \ErrorTok{Concentrated} \ErrorTok{moisture} \ErrorTok{on} \ErrorTok{grass.} \FunctionTok{\{}
  \DataTypeTok{"instantiations"}\FunctionTok{:} \OtherTok{[}\StringTok{"wet"}\OtherTok{,} \StringTok{"dry"}\OtherTok{]}\FunctionTok{,}
  \DataTypeTok{"priors"}\FunctionTok{:} \FunctionTok{\{}\DataTypeTok{"p(wet)"}\FunctionTok{:} \StringTok{"0.45"}\FunctionTok{,} \DataTypeTok{"p(dry)"}\FunctionTok{:} \StringTok{"0.55"}\FunctionTok{\},}
  \DataTypeTok{"posteriors"}\FunctionTok{:} \FunctionTok{\{}
    \DataTypeTok{"p(wet|raining,on)"}\FunctionTok{:} \StringTok{"0.99"}\FunctionTok{,}
    \DataTypeTok{"p(wet|raining,off)"}\FunctionTok{:} \StringTok{"0.80"}\FunctionTok{,} 
    \DataTypeTok{"p(wet|not\_raining,on)"}\FunctionTok{:} \StringTok{"0.90"}\FunctionTok{,}
    \DataTypeTok{"p(wet|not\_raining,off)"}\FunctionTok{:} \StringTok{"0.01"}
  \FunctionTok{\}}
\FunctionTok{\}}
\end{Highlighting}
\end{Shaded}

Notice how the probabilities tell a coherent story---grass is almost
certainly wet if either water source is active, almost certainly dry if
neither is.

\textbf{Resulting DataFrame Structure}:

The transformation into tabular format enables standard data analysis
tools while preserving all relationships and probabilities. Each row
represents a node with its properties, parents, children, and
probability distributions.

\subsection{3.4.3 Results}\label{sec-rsg-results}

The successfully processed rain-sprinkler-grass example demonstrates
several key capabilities:

\textbf{Structure Preservation}: The causal relationships---including
the subtle influence of rain on sprinkler usage---are correctly captured
and maintained throughout processing.

\textbf{Probability Coherence}: All probability distributions sum to
1.0, conditional probabilities are complete, and the values tell a
plausible story.

\textbf{Visual Clarity}: The rendered network clearly shows rain as the
root cause, influencing both sprinkler and grass, while sprinkler
provides an additional pathway to wet grass.

\textbf{Interactive Exploration}: Users can click nodes to see detailed
probabilities, drag to rearrange for clarity, and explore how changing
parameters affects outcomes.

\textbf{Inference Capability}: The system correctly calculates derived
probabilities like P(Rain\textbar Grass\_Wet)---the diagnostic reasoning
from effect to cause that makes Bayesian networks so powerful.

This simple example validates the basic pipeline functionality. But the
real test comes with complex, real-world arguments\ldots{}

\section{3.5 Case Study: Carlsmith's Power-Seeking AI
Model}\label{sec-case-carlsmith}

From the gentle meadows of rain and sprinklers, we now ascend to the
existential peaks of AI risk. Carlsmith's model represents a dramatic
increase in complexity---both conceptually and computationally. Where
rain-sprinkler-grass has 3 nodes, Carlsmith involves 23. Where grass
wetness is intuitive, ``mesa-optimization'' and ``corrigibility''
require careful thought.

\subsection{3.5.1 Model Complexity}\label{sec-carlsmith-complexity}

The numbers tell only part of the story:

\begin{itemize}
\tightlist
\item
  \textbf{23 nodes}: Each representing a substantive claim about AI
  development, deployment, or risk
\item
  \textbf{29 edges}: Encoding causal relationships across technical,
  strategic, and societal domains
\item
  \textbf{Multiple probability tables}: Many nodes have several parents,
  creating combinatorial explosion
\item
  \textbf{Six-level causal depth}: From root causes to final
  catastrophe, influence propagates through multiple stages
\end{itemize}

But the conceptual complexity dwarfs the computational. Nodes like
``APS-Systems'' (Advanced, Planning, Strategically aware) encode
specific technical hypotheses. Relationships like how ``incentives to
build'' influence ``deployment despite misalignment'' require
understanding of organizational behavior under competitive pressure.

This is no longer a toy problem but a serious attempt to formalize one
of the most important arguments of our time.

\subsection{3.5.2 Automated Extraction of the Carlsmith's Argument
Structure}\label{sec-carlsmith-extraction}

The extraction process began with feeding Carlsmith's paper to AMTAIR.
Watching the system work felt like observing an archaeological
excavation---layers of argument slowly revealed their structure.

The LLM prompts for extraction deserve special attention. Through
iterative refinement, we developed prompts that guide extraction while
remaining flexible:

python

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ARGDOWN\_EXTRACTION }\OperatorTok{=}\NormalTok{ PromptTemplate(}\StringTok{"""}
\StringTok{You are extracting the causal model from an AI safety argument.}
\StringTok{Focus on:}
\StringTok{1. Identifying key variables that affect outcomes}
\StringTok{2. Capturing causal relationships (not mere association)  }
\StringTok{3. Preserving the author\textquotesingle{}s terminology where possible}
\StringTok{4. Creating a directed acyclic graph structure}

\StringTok{For Carlsmith\textquotesingle{}s argument about power{-}seeking AI, pay special attention to:}
\StringTok{{-} The chain from capabilities to catastrophe}
\StringTok{{-} Conditional relationships (X matters only if Y)}
\StringTok{{-} Technical preconditions for risk}
\StringTok{"""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The extraction revealed Carlsmith's elegant decomposition. At the
highest level: capabilities enable power-seeking, which enables
disempowerment, which constitutes catastrophe. But the details
matter---deployment decisions mediated by incentives and deception,
alignment difficulty influenced by multiple technical factors,
corrective mechanisms that might interrupt the chain.

The ArgDown representation captured this structure:

\begin{verbatim}
[Existential_Catastrophe]: Permanent curtailment of humanity's potential
 + [Human_Disempowerment]: Humans lose control over future
   + [Scale_Of_Power_Seeking]: Power-seeking behavior becomes overwhelming
     + [Misaligned_Power_Seeking]: AI systems pursue problematic objectives
       + [APS_Systems]: Advanced, planning, strategically aware AI
       + [Alignment_Difficulty]: Hard to align such systems
       + [Deployment_Despite_Misalignment]: Systems deployed anyway
         + [Incentives_To_Build]: Strong pressure to develop AI
         + [Deception]: AI systems hide misalignment
\end{verbatim}

The structure revealed insights. ``Misaligned\_Power\_Seeking'' emerged
as a critical hub, influenced by multiple factors and influencing
multiple outcomes. The pathway from incentives through deployment to
risk became explicit.

\subsection{3.5.3 From ArgDown to BayesDown in Carlsmith's
Model}\label{sec-carlsmith-bayesdown}

Adding probabilities to Carlsmith's structure presented unique
challenges. Unlike rain-sprinkler probabilities that have intuitive
values, what's the probability of ``mesa-optimization'' or ``deceptive
alignment''?

The system generated over 100 probability questions for the full model.
A sample:

\begin{verbatim}
For [Deployment_Decisions]:
- What is P(deploy)?
- What is P(deploy|strong_incentives, deception)?
- What is P(deploy|strong_incentives, no_deception)?
- What is P(deploy|weak_incentives, deception)?
- What is P(deploy|weak_incentives, no_deception)?
\end{verbatim}

Each question targets a specific parameter needed for the Bayesian
network. The conditional structure reflects Carlsmith's
argument---deployment depends on both incentives (external pressure) and
deception (hidden misalignment).

The LLM extraction drew on Carlsmith's explicit estimates where
available and inferred reasonable values elsewhere. The result captured
both the structure and Carlsmith's quantitative risk assessment:

json

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{[}\ErrorTok{Deployment\_Decisions}\OtherTok{]}\ErrorTok{:} \ErrorTok{Decisions} \ErrorTok{to} \ErrorTok{deploy} \ErrorTok{potentially} \ErrorTok{misaligned} \ErrorTok{AI.} \FunctionTok{\{}
  \DataTypeTok{"instantiations"}\FunctionTok{:} \OtherTok{[}\StringTok{"deploy"}\OtherTok{,} \StringTok{"withhold"}\OtherTok{]}\FunctionTok{,}
  \DataTypeTok{"priors"}\FunctionTok{:} \FunctionTok{\{}\DataTypeTok{"p(deploy)"}\FunctionTok{:} \StringTok{"0.70"}\FunctionTok{,} \DataTypeTok{"p(withhold)"}\FunctionTok{:} \StringTok{"0.30"}\FunctionTok{\},}
  \DataTypeTok{"posteriors"}\FunctionTok{:} \FunctionTok{\{}
    \DataTypeTok{"p(deploy|strong\_incentives,deception)"}\FunctionTok{:} \StringTok{"0.90"}\FunctionTok{,}
    \DataTypeTok{"p(deploy|strong\_incentives,no\_deception)"}\FunctionTok{:} \StringTok{"0.75"}\FunctionTok{,}
    \DataTypeTok{"p(deploy|weak\_incentives,deception)"}\FunctionTok{:} \StringTok{"0.60"}\FunctionTok{,}
    \DataTypeTok{"p(deploy|weak\_incentives,no\_deception)"}\FunctionTok{:} \StringTok{"0.30"}
  \FunctionTok{\}}
\FunctionTok{\}}
\end{Highlighting}
\end{Shaded}

The probabilities tell a plausible story: deployment becomes more likely
with stronger incentives and successful deception, but even without
deception, strong incentives create substantial deployment probability.

\subsection{3.5.4 Practically Meaningful
BayesDown}\label{sec-practically-meaningful}

The BayesDown representation achieves something remarkable: it bridges
the chasm between Carlsmith's nuanced prose and mathematical formalism
without losing the essence of either.

Consider what this bridge enables:

\textbf{For Technical Researchers}: The formal structure makes
assumptions explicit. Is power-seeking really independent of capability
level given strategic awareness? The model forces clarity.

\textbf{For Policymakers}: Probabilities attached to comprehensible
descriptions provide actionable intelligence. ``70\% chance of
deployment despite misalignment'' translates better than abstract
concerns.

\textbf{For Strategic Analysts}: The network structure reveals
intervention points. Which nodes, if changed, most affect the final
outcome? Where should we focus effort?

The hybrid nature---natural language plus formal structure plus
probabilities---serves each audience while enabling communication
between them. A policymaker can understand ``deployment decisions''
without probability theory. A researcher can analyze the mathematical
model without losing sight of what the variables mean.

This isn't just convenient---it's essential for coordination. When
different communities can refer to the same model but engage with it at
their appropriate level of technical detail, we create common ground for
productive disagreement and collaborative problem-solving.

\subsection{3.5.5 Interactive Visualization and
Exploration}\label{sec-interactive-visualization}

The moment when Carlsmith's model first rendered as an interactive
network felt like putting on glasses after years of squinting. Suddenly,
the complex web of relationships became navigable.

The visualization system employs multiple visual channels
simultaneously:

\textbf{Color Coding}: Nodes shift from deep red (low probability)
through yellow to bright green (high probability). At a glance, you see
which factors Carlsmith considers likely versus speculative.

\textbf{Border Styling}: Blue borders mark root causes (like
``Incentives\_To\_Build''), purple indicates intermediate nodes, magenta
highlights final outcomes. The visual grammar guides the eye through
causal flow.

\textbf{Layout Algorithm}: Initial placement uses causal depth---root
causes at bottom, final outcomes at top. Physics simulation then refines
positions to minimize edge crossings while preserving hierarchical
structure.

\textbf{Progressive Disclosure}: Hovering reveals probability summaries.
Clicking opens detailed conditional probability tables. Dragging allows
custom arrangement. Each interaction level serves different analytical
needs.

The implementation required careful attention to human factors:

python

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ create\_interactive\_visualization(network\_df):}
    \CommentTok{"""Transform formal model into explorable landscape"""}
    
    \CommentTok{\# Initialize with thoughtful defaults}
\NormalTok{    net }\OperatorTok{=}\NormalTok{ Network(height}\OperatorTok{=}\StringTok{"720px"}\NormalTok{, width}\OperatorTok{=}\StringTok{"100\%"}\NormalTok{, directed}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
    
    \CommentTok{\# Configure physics for clarity not just aesthetics}
\NormalTok{    net.force\_atlas\_2based(}
\NormalTok{        gravity}\OperatorTok{={-}}\DecValTok{50}\NormalTok{,      }\CommentTok{\# Gentle spread}
\NormalTok{        spring\_length}\OperatorTok{=}\DecValTok{150}\NormalTok{,  }\CommentTok{\# Readable spacing}
\NormalTok{        spring\_strength}\OperatorTok{=}\FloatTok{0.02}  \CommentTok{\# Soft constraints}
\NormalTok{    )}
    
    \CommentTok{\# Add nodes with rich metadata}
    \ControlFlowTok{for}\NormalTok{ node }\KeywordTok{in}\NormalTok{ nodes:}
\NormalTok{        net.add\_node(}
\NormalTok{            node\_id,}
\NormalTok{            label}\OperatorTok{=}\NormalTok{create\_simple\_label(node),      }\CommentTok{\# "Deployment\textbackslash{}np=0.70"}
\NormalTok{            title}\OperatorTok{=}\NormalTok{create\_rich\_tooltip(node),      }\CommentTok{\# Full probability details}
\NormalTok{            color}\OperatorTok{=}\NormalTok{probability\_to\_color(node),     }\CommentTok{\# Visual encoding}
\NormalTok{            borderWidth}\OperatorTok{=}\DecValTok{3}\NormalTok{,                        }\CommentTok{\# Visible borders}
\NormalTok{            shape}\OperatorTok{=}\StringTok{"box"}                          \CommentTok{\# Readable text}
\NormalTok{        )}
\end{Highlighting}
\end{Shaded}

The resulting visualization transforms abstract relationships into
tangible understanding. Users report ``aha'' moments when
exploring---suddenly seeing how technical factors compound into
strategic risks, or identifying previously unnoticed bottlenecks in the
causal chain.

\subsection{3.5.6 Validation Against Original (From the MTAIR
Project)}\label{sec-carlsmith-validation}

Validating AMTAIR's extraction required careful comparison with expert
judgment. While comprehensive benchmarking remains future work,
preliminary validation efforts provide encouraging signals.

\textbf{Manual Baseline Creation}: Domain experts, including Johannes
Meyer and Jelena Meyer, independently extracted ArgDown and BayesDown
representations from Carlsmith's paper. This created ground truth
accounting for legitimate interpretive variation---experts might
reasonably disagree on some structural choices or probability estimates.

\textbf{Structural Comparison}: Comparing extracted causal structures
revealed high agreement on core relationships. AMTAIR consistently
identified the main causal chain from capabilities through deployment to
catastrophe. Some variation appeared in handling of auxiliary
factors---where one expert might include a minor influence, another
might omit it for simplicity.

\textbf{Probability Assessment}: Probability extraction showed greater
variation, reflecting inherent ambiguity in translating qualitative
language. When Carlsmith writes ``likely,'' different readers might
reasonably interpret this as 0.7, 0.75, or 0.8. AMTAIR's extractions
fell within the range of expert interpretations, suggesting successful
capture of intended meaning even if not identical numbers.

\textbf{Semantic Preservation}: Most importantly, the formal models
preserved the essential insights of Carlsmith's argument. The critical
role of deployment decisions, the compound nature of risk, the
importance of technical and strategic factors---all emerged clearly in
the extracted representations.

An ideal validation protocol would expand this approach:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Multiple expert extractors working independently
\item
  Systematic comparison of structural and quantitative agreement
\item
  Analysis of where and why extractions diverge
\item
  Testing whether different extractions lead to different policy
  conclusions
\item
  Iterative refinement based on identified failure modes
\end{enumerate}

The goal isn't perfect agreement---even human experts disagree. Rather,
we seek extractions good enough to support meaningful analysis while
acknowledging their limitations.

\section{3.6 Validation Methodology}\label{sec-validation-methodology}

Building trust in automated extraction requires more than anecdotal
success. We need systematic validation that honestly assesses both
capabilities and limitations.

\subsection{3.6.1 Ground Truth Construction}\label{sec-ground-truth}

Creating ground truth for argument extraction poses unique challenges.
Unlike named entity recognition or sentiment analysis, argument
structure lacks universal standards. What constitutes the ``correct''
extraction from a complex text?

An ideal validation approach would embrace this inherent subjectivity:

\textbf{Expert Selection}: Recruit 5-10 domain experts with demonstrated
expertise in both AI safety and formal modeling. Diversity
matters---include technical researchers, policy analysts, and those with
mixed backgrounds.

\textbf{Extraction Protocol}: Provide standardized training on
ArgDown/BayesDown syntax while allowing flexibility in interpretation.
Experts work independently to avoid anchoring bias, documenting their
reasoning process alongside final extractions.

\textbf{Consensus Building}: Through structured discussion, identify
areas of convergence (likely core argument structure) versus legitimate
disagreement (interpretive choices, granularity decisions). This
distinguishes system errors from inherent ambiguity.

\textbf{Quality Metrics}: Rather than binary correct/incorrect
judgments, assess:

\begin{itemize}
\tightlist
\item
  Structural similarity (graph edit distance)
\item
  Probability distribution overlap (KL divergence)
\item
  Semantic preservation (expert ratings)
\item
  Downstream task performance (policy analysis agreement)
\end{itemize}

The resulting dataset would capture not a single ``truth'' but a
distribution of reasonable interpretations against which to evaluate
automated extraction.

\subsection{3.6.2 Evaluation Metrics}\label{sec-evaluation-metrics}

Evaluating argument extraction requires metrics that capture multiple
dimensions of quality:

\textbf{Structural Fidelity}:

\begin{itemize}
\tightlist
\item
  Node identification: What fraction of expert-identified variables does
  the system extract?
\item
  Edge accuracy: Are causal relationships preserved?
\item
  Hierarchy preservation: Does the system maintain argument levels?
\end{itemize}

\textbf{Probability Calibration}:

\begin{itemize}
\tightlist
\item
  Explicit extraction: When sources state probabilities, how accurately
  are they captured?
\item
  Linguistic mapping: Do qualitative expressions translate to reasonable
  probabilities?
\item
  Coherence: Are probability distributions properly normalized?
\end{itemize}

\textbf{Semantic Quality}:

\begin{itemize}
\tightlist
\item
  Description accuracy: Do extracted descriptions preserve original
  meaning?
\item
  Terminology preservation: Does the system maintain author's
  vocabulary?
\item
  Context retention: Is sufficient information preserved for
  interpretation?
\end{itemize}

\textbf{Functional Validity}:

\begin{itemize}
\tightlist
\item
  Inference agreement: Do extracted models support similar conclusions?
\item
  Sensitivity preservation: Are critical parameters identified as
  influential?
\item
  Policy robustness: Do different extractions suggest similar
  interventions?
\end{itemize}

These metrics acknowledge that perfect extraction is neither expected
nor necessary. The goal is extraction sufficient for practical use while
maintaining transparency about limitations.

\subsection{3.6.3 Results Summary}\label{sec-validation-results}

While comprehensive validation remains future work, preliminary
assessments using the methodology described above would likely reveal
several patterns:

\textbf{Expected Strengths}: Automated extraction should excel at
identifying explicit causal claims, preserving hierarchical argument
structure, and extracting stated probabilities. The two-stage approach
likely improves quality by allowing focused optimization for each task.

\textbf{Anticipated Challenges}: Implicit reasoning, complex
conditionals, and ambiguous quantifiers would pose greater challenges.
Coreference resolution across long documents and maintaining consistency
in large models would require continued refinement.

\textbf{Practical Utility Threshold}: Even with imperfect extraction,
the system could provide value if it achieves perhaps 70-80\% structural
accuracy and captures probability estimates within reasonable ranges.
This level of performance would enable rapid initial modeling that
experts could refine, dramatically reducing the time from argument to
formal model.

The validation framework itself represents a contribution---establishing
systematic methods for assessing argument extraction quality as this
research area develops.

\subsection{3.6.4 Error Analysis}\label{sec-error-analysis}

Understanding failure modes guides both appropriate use and future
improvements:

\textbf{Implicit Assumptions}: Authors often leave critical assumptions
unstated, relying on shared background knowledge. When an AI safety
researcher writes about ``alignment,'' they assume readers understand
the technical concept. The system must either extract these implicit
elements or flag their absence.

\textbf{Complex Conditionals}: Natural language expresses conditionality
in myriad ways. ``If we achieve alignment (which seems unlikely without
major theoretical breakthroughs), then deployment might be safe
(assuming robust verification).'' Parsing nested, qualified conditionals
challenges current methods.

\textbf{Ambiguous Quantifiers}: The word ``significant'' might mean 10\%
in one context, 60\% in another. Without calibration to author-specific
usage or domain conventions, probability extraction remains approximate.

\textbf{Coreference Challenges}: Academic writing loves pronouns and
indirect references. When ``this approach'' appears three paragraphs
after introducing multiple approaches, identifying the correct referent
requires sophisticated discourse understanding.

These limitations don't invalidate the approach but rather define its
boundaries. Users who understand these constraints can work within them,
leveraging automation's strengths while compensating for its weaknesses.

\section{3.7 Policy Evaluation
Capabilities}\label{sec-policy-evaluation}

The ultimate test of a model isn't its elegance but its utility. Can
AMTAIR's extracted models actually inform governance decisions? This
section demonstrates how formal models enable systematic policy
analysis.

\subsection{3.7.1 Intervention
Representation}\label{sec-intervention-representation}

Representing policy interventions in Bayesian networks requires
translating governance mechanisms into parameter modifications. Pearl's
do-calculus provides the mathematical framework, but the practical
challenge lies in meaningful translation.

An ideal implementation would support several intervention types:

\textbf{Parameter Modification}: Policies often change probabilities.
Safety requirements might reduce P(deployment\textbar misaligned) from
0.7 to 0.2 by making unsafe deployment legally prohibited or
reputationally costly.

\textbf{Structural Interventions}: Some policies add new causal
pathways. Introducing mandatory review boards creates new nodes and
edges representing oversight mechanisms.

\textbf{Uncertainty Modeling}: Policy effectiveness is itself uncertain.
Rather than assuming perfect implementation, represent ranges:
P(deployment\textbar misaligned) might become {[}0.1, 0.3{]} depending
on enforcement.

\textbf{Multi-Level Effects}: Policies influence multiple levels
simultaneously. Compute governance affects technical development,
corporate behavior, and international competition.

The system would translate high-level policy descriptions into specific
network modifications, enabling rigorous counterfactual analysis of
intervention effects.

\subsection{3.7.2 Example: Deployment
Governance}\label{sec-deployment-example}

Let's trace how a specific policy---mandatory safety certification
before deployment---might be evaluated:

\textbf{Baseline Model}: In Carlsmith's original model,
P(deployment\textbar misaligned) = 0.7, reflecting competitive pressures
overwhelming safety concerns.

\textbf{Policy Specification}: Safety certification requires
demonstrating alignment properties before deployment authorization.
Based on similar regulations in other domains, we might estimate 80-90\%
effectiveness.

\textbf{Parameter Update}: The modified model sets
P(deployment\textbar misaligned) = 0.1-0.2, representing the residual
probability of circumvention or regulatory capture.

\textbf{Downstream Effects}:

\begin{itemize}
\tightlist
\item
  Reduced deployment of misaligned systems
\item
  Lower probability of power-seeking manifestation
\item
  Decreased existential risk from \textasciitilde5\% to
  \textasciitilde1.2\%
\end{itemize}

\textbf{Sensitivity Analysis}: How robust is this conclusion? Varying
certification effectiveness, enforcement probability, and other
parameters reveals which assumptions critically affect the outcome.

This example illustrates policy evaluation's value: moving from vague
claims (``regulation would help'') to quantitative assessments (``this
specific intervention might reduce risk by 75\%±15\%'').

\subsection{3.7.3 Robustness Analysis}\label{sec-robustness}

Good policies work across scenarios. AMTAIR enables testing
interventions against multiple worldviews, parameter ranges, and
structural variations.

\textbf{Cross-Model Testing}: Extract multiple expert models and
evaluate the same policy in each. If an intervention reduces risk in
Carlsmith's model but increases it in Christiano's, we've identified a
critical dependency.

\textbf{Parameter Sensitivity}: Which uncertainties most affect policy
effectiveness? If the intervention only works for
P(alignment\_difficulty) \textless{} 0.3, and experts disagree whether
it's 0.2 or 0.4, we need more research before implementing.

\textbf{Structural Uncertainty}: Some disagreements concern model
structure itself. Does capability advancement directly influence
misalignment risk, or only indirectly through deployment pressures? Test
policies under both structures.

\textbf{Confidence Bounds}: Rather than point estimates, compute ranges.
``This policy reduces risk by 40-80\%'' honestly represents uncertainty
while still providing actionable guidance.

The goal isn't eliminating uncertainty but making decisions despite it.
Robustness analysis reveals which policies work across uncertainties
versus those requiring specific assumptions.

\section{3.8 Interactive Visualization
Design}\label{sec-visualization-design}

A Bayesian network without good visualization is like a symphony without
performers---all potential, no impact. The visualization system
transforms mathematical abstractions into intuitive understanding.

\subsection{3.8.1 Visual Encoding Strategy}\label{sec-visual-encoding}

Every visual element carries information:

\textbf{Color}: The probability spectrum from red (low) through yellow
to green (high) provides immediate gestalt understanding. Pre-attentive
processing---the brain's ability to process certain visual features
without conscious attention---makes patterns jump out.

\textbf{Borders}: Node type encoding (blue=root, purple=intermediate,
magenta=outcome) creates visual flow. The eye naturally follows from
blue through purple to magenta, tracing causal pathways.

\textbf{Size}: Larger nodes have higher centrality---more connections,
more influence. This emerges from the physics simulation but reinforces
importance.

\textbf{Layout}: Force-directed positioning naturally clusters related
concepts while maintaining readability. The algorithm balances competing
constraints: minimize edge crossings, maintain hierarchical levels,
avoid node overlap, and create aesthetic appeal.

The encoding philosophy: every pixel should earn its place by conveying
information while maintaining visual harmony.

\subsection{3.8.2 Progressive
Disclosure}\label{sec-progressive-disclosure}

Information overload kills understanding. The interface reveals
complexity gradually:

\textbf{Level 1 - Overview}: At first glance, see network structure and
probability color coding. This answers: ``What's the shape of the
argument? Where are the high-risk areas?''

\textbf{Level 2 - Hover Details}: Mouse over a node to see its
description and prior probability. This adds: ``What does this factor
represent? How likely is it?''

\textbf{Level 3 - Click Deep Dive}: Clicking opens full probability
tables and relationships. This reveals: ``How does this probability
change with conditions? What influences this factor?''

\textbf{Level 4 - Interactive Exploration}: Dragging, zooming, and
physics controls enable custom investigation. This supports: ``What if I
reorganize to see different patterns? How do these clusters relate?''

Each level serves different users and use cases. A policymaker might
work primarily with levels 1-2, while a researcher dives into level 3-4
details.

\subsection{3.8.3 User Interface Elements}\label{sec-ui-elements}

Effective interface design for Bayesian networks requires balancing
power with accessibility:

\textbf{Physics Controls}: Force-directed layouts benefit from tuning.
Gravity affects spread, spring length controls spacing, damping
influences settling time. Advanced users can adjust these for optimal
layouts, while defaults work well for most cases.

\textbf{Filter Options}: With large networks, selective viewing becomes
essential. Filter by probability ranges (show only likely events), node
types (focus on interventions), or causal depth (see only immediate
effects).

\textbf{Export Functions}: Different stakeholders need different
formats. Researchers want raw data, policymakers need reports,
presenters require images. Supporting diverse export formats enables
broad usage.

\textbf{Comparison Mode}: Understanding often comes from contrast.
Side-by-side viewing of baseline versus intervention, or different
expert models, reveals critical differences.

Iterative design with actual users would refine these features, ensuring
they serve real needs rather than imagined ones.

\section{3.9 Integration with Prediction
Markets}\label{sec-market-integration}

The vision: formal models that breathe with live data, updating as
collective intelligence evolves. While full implementation awaits, the
architecture anticipates this future.

\subsection{3.9.1 Design for Integration}\label{sec-integration-design}

\textbf{Integration Architecture} requires careful design to manage the
impedance mismatch between formal models and market data:

\textbf{API Specifications}: Each platform---Metaculus, Manifold, Good
Judgment Open---has unique data formats, update frequencies, and
question types. A unified adapter layer would translate
platform-specific formats into model-compatible data.

\textbf{Semantic Matching}: The hard problem---connecting ``AI causes
extinction by 2100'' (market question) to ``Existential\_Catastrophe''
(model node). This requires sophisticated NLP and possibly human
curation for high-stakes connections.

\textbf{Aggregation Methods}: When multiple markets address similar
questions, how do we combine? Weighted averages based on market depth,
participant quality, and historical accuracy provide more signal than
simple means.

\textbf{Update Scheduling}: Real-time updates would overwhelm users and
computation. Smart scheduling might update daily for slow-changing
strategic questions, hourly for capability announcements, immediately
for critical events.

\subsection{3.9.2 Challenges and
Opportunities}\label{sec-market-challenges}

The challenges are real but surmountable:

\textbf{Question Mapping}: Markets ask specific, time-bound questions
while models represent general relationships. ``AGI by 2030?'' maps
uncertainly to ``APS\_Systems exists.'' Developing robust mapping
functions requires deep understanding of both domains.

\textbf{Temporal Alignment}: Market probabilities change over time, but
model parameters are typically static. Should we use current market
values, time-weighted averages, or attempt to extract trend information?

\textbf{Quality Variation}: A liquid market with expert participants
provides different information than a thin market with casual
forecasters. Weighting schemes must account for these quality
differences.

\textbf{Incentive Effects}: If models influence policy and policy
influences outcomes, and markets forecast outcomes, we create feedback
loops. Understanding these dynamics prevents perverse incentives.

Despite challenges, even partial integration provides value:

\begin{itemize}
\tightlist
\item
  External validation of expert-derived probabilities
\item
  Dynamic updating as new information emerges
\item
  Identification of where model and market disagree
\item
  Quantified uncertainty from market spread
\end{itemize}

The perfect shouldn't be the enemy of the good---simple integration
beats no integration.

\section{3.10 Computational Performance
Analysis}\label{sec-computational-performance}

As networks grow from toy examples to real-world complexity,
computational challenges emerge. Understanding these constraints shapes
realistic expectations and optimization priorities.

\subsection{3.10.1 Exact vs.~Approximate
Inference}\label{sec-exact-approximate}

The fundamental tradeoff in probabilistic reasoning: exactness versus
tractability.

\textbf{Exact Inference}: Variable elimination and junction tree
algorithms provide mathematically exact answers. For our 3-node
rain-sprinkler network, calculations complete instantly. For 20-node
networks with modest connectivity, expect seconds. But for 50+ node
networks with complex dependencies, exact inference becomes
impractical---potentially taking hours or exhausting memory.

\textbf{Approximate Methods}: When exactness becomes impractical,
approximation saves the day:

\begin{itemize}
\tightlist
\item
  \textbf{Monte Carlo Sampling}: Generate thousands of scenarios
  consistent with the network, estimate probabilities from frequencies.
  Accuracy improves with samples, trading computation time for
  precision.
\item
  \textbf{Variational Inference}: Find the simplest distribution that
  approximates our complex reality. Like fitting a smooth curve to
  jagged data---we lose detail but gain comprehension.
\item
  \textbf{Belief Propagation}: Pass messages between nodes until beliefs
  converge. Works beautifully for tree-structured networks, can
  oscillate or converge slowly for complex loops.
\end{itemize}

The system selects methods based on network properties:

\begin{itemize}
\tightlist
\item
  Small networks: exact inference for precision
\item
  Medium networks: belief propagation for speed
\item
  Large networks: sampling for scalability
\item
  Very large networks: hierarchical decomposition
\end{itemize}

\subsection{3.10.2 Scaling Strategies}\label{sec-scaling-strategies}

When networks grow beyond convenient computation, clever strategies
maintain usability:

\textbf{Hierarchical Decomposition}: Break large networks into smaller,
manageable subnetworks. Compute locally, then integrate results. Like
solving a jigsaw puzzle by completing sections before assembling the
whole.

\textbf{Relevance Pruning}: For specific queries, most nodes don't
matter. If asking about deployment risk, technical details about
interpretability methods might be temporarily ignorable. Prune
irrelevant subgraphs for focused analysis.

\textbf{Caching Architecture}: Many queries repeat---P(catastrophe),
P(deployment\textbar misalignment). Cache results to avoid
recomputation. Smart invalidation updates only affected queries when
parameters change.

\textbf{Parallel Processing}: Inference calculations often decompose
naturally. Different branches of the network can be processed
simultaneously. Modern multi-core processors and cloud computing make
this increasingly attractive.

Implementation would balance these strategies based on usage patterns.
Interactive exploration benefits from caching and pruning. Batch
analysis leverages parallelization. The architecture accommodates
multiple approaches.

\section{3.11 Results and Achievements}\label{sec-results-achievements}

\subsection{3.11.1 Extraction Quality
Assessment}\label{sec-extraction-quality}

Assessing extraction quality requires honesty about both achievements
and limitations. An ideal evaluation would examine multiple dimensions:

\textbf{Coverage}: What proportion of arguments in source texts does the
system successfully capture? Initial applications suggest the two-stage
approach identifies most explicit causal claims while struggling with
deeply implicit relationships.

\textbf{Accuracy}: How closely do automated extractions match expert
consensus? Preliminary comparisons indicate strong agreement on primary
causal structures with more variation in probability estimates.

\textbf{Robustness}: How well does the system handle different writing
styles, argument structures, and domains? Academic papers with clear
argumentation extract more reliably than informal blog posts or policy
documents.

\textbf{Utility}: Do the extracted models enable meaningful analysis?
Even imperfect extractions that capture 80\% of structure with
approximate probabilities can dramatically accelerate modeling compared
to starting from scratch.

The key insight: perfect extraction isn't necessary for practical value.
Like machine translation, which provides useful results despite
imperfections, automated argument extraction can enhance human
capability without replacing human judgment.

\subsection{3.11.2 Computational
Performance}\label{sec-computational-performance}

Performance analysis would reveal the practical boundaries of the
current system:

\textbf{Extraction Speed}: LLM-based extraction scales roughly linearly
with document length. A 20-page paper might require 30-60 seconds for
structural extraction and similar time for probability extraction. This
enables processing dozens of documents daily---orders of magnitude
faster than manual approaches.

\textbf{Network Complexity Limits}: Exact inference remains tractable
for networks up to approximately 30-40 nodes with moderate connectivity.
Beyond this, approximate methods become necessary, with sampling methods
scaling to hundreds of nodes at the cost of precision.

\textbf{Visualization Responsiveness}: Interactive visualization
performs smoothly for networks under 50 nodes. Larger networks benefit
from hierarchical viewing or focus+context techniques to maintain
usability.

\textbf{End-to-End Pipeline}: From document input to interactive
visualization, expect 2-5 minutes for typical AI safety arguments. This
represents roughly 100x speedup compared to manual modeling efforts.

These performance characteristics make AMTAIR practical for real-world
use while highlighting areas for future optimization.

\subsection{3.11.3 Policy Impact Evaluation}\label{sec-policy-impact}

The true test of AMTAIR lies in its ability to inform governance
decisions. An ideal policy evaluation framework would demonstrate
several capabilities:

\textbf{Intervention Modeling}: Representing diverse policy
proposals---from technical standards to international agreements---as
parameter modifications in extracted networks. This translation from
qualitative proposals to quantitative changes enables rigorous analysis.

\textbf{Comparative Assessment}: Evaluating multiple interventions
across different expert worldviews to identify robust strategies.
Policies that reduce risk across different models deserve priority over
those requiring specific assumptions.

\textbf{Sensitivity Analysis}: Understanding which uncertainties most
affect policy conclusions. If an intervention's effectiveness depends
critically on disputed parameters, this highlights research priorities.

\textbf{Implementation Guidance}: Moving beyond ``this policy reduces
risk'' to specific recommendations about design details, implementation
sequences, and success metrics.

The system would transform abstract policy discussions into concrete
quantitative analyses, enabling evidence-based decision-making in AI
governance.

\section{3.12 Summary of Technical
Contributions}\label{sec-technical-summary}

Looking back at the implementation journey, several achievements stand
out:

\textbf{Automated Extraction}: The two-stage pipeline successfully
transforms natural language arguments into formal models, achieving
practical accuracy while maintaining transparency about limitations.

\textbf{Hybrid Representation}: BayesDown bridges qualitative and
quantitative worlds, preserving semantic richness while enabling
mathematical analysis.

\textbf{Scalable Architecture}: Modular design accommodates growth---new
document types, improved extraction methods, additional visualization
options---without fundamental restructuring.

\textbf{Interactive Accessibility}: Thoughtful visualization makes
complex models understandable to diverse stakeholders, democratizing
access to formal reasoning tools.

\textbf{Policy Relevance}: The ability to model interventions and assess
robustness transforms academic exercises into practical governance
tools.

These technical achievements validate the feasibility of computational
coordination infrastructure for AI governance. Not as a complete
solution, but as a meaningful enhancement to human judgment and
collaboration.

The implementation demonstrates that the vision of automated argument
extraction is not merely theoretical but practically achievable. While
challenges remain---particularly in handling implicit reasoning and
diverse uncertainty expressions---the system provides a foundation for
enhanced coordination in AI governance.

The journey from concept to implementation revealed unexpected insights.
The two-stage extraction process, initially a pragmatic choice, proved
cognitively valid. The intermediate representations became valuable
outputs themselves. The visualization challenges led to design
innovations applicable beyond this project.

Most importantly, the implementation confirms that formal modeling of AI
risk arguments need not remain the province of a few dedicated experts.
Through automation and thoughtful design, these powerful tools can serve
the broader community working to ensure advanced AI benefits humanity.

Having demonstrated technical feasibility and practical utility, we must
now critically examine limitations, address objections, and explore
broader implications. The next chapter undertakes this essential
reflection, ensuring we neither oversell the approach nor undervalue its
contributions.

\bookmarksetup{startatroot}

\chapter{4. Discussion: Implications and
Limitations}\label{sec-discussion}

\section{4.1 Technical Limitations and
Responses}\label{sec-technical-limitations}

\subsection{4.1.1 Objection 1: Extraction Quality
Boundaries}\label{sec-extraction-boundaries}

\textbf{Critic}: ``Complex implicit reasoning chains resist
formalization; automated extraction will systematically miss nuanced
arguments and subtle conditional relationships that human experts would
identify.''

\textbf{Response}: This concern has merit---extraction does face
inherent limitations. However, the empirical results tell a more nuanced
story. The two-stage extraction process, while imperfect, captures
sufficient structure for practical use while maintaining transparency
about its limitations.

More importantly, AMTAIR employs a hybrid human-AI workflow that
addresses this limitation:

\begin{itemize}
\tightlist
\item
  \textbf{Two-stage verification}: Humans review structural extraction
  before probability quantification
\item
  \textbf{Transparent outputs}: All intermediate representations remain
  human-readable
\item
  \textbf{Iterative refinement}: Extraction prompts improve based on
  error analysis
\item
  \textbf{Ensemble approaches}: Multiple extraction attempts can
  identify ambiguities
\end{itemize}

The question is not whether automated extraction perfectly captures
every nuance---it doesn't. Rather, it's whether imperfect extraction
still provides value over no formal representation. When the alternative
is relying on conflicting mental models that remain entirely implicit,
even partially accurate formal models represent significant progress.

Furthermore, extraction errors often reveal interesting properties of
the source arguments themselves---ambiguities that human readers gloss
over become explicit when formalization fails. This diagnostic value
enhances rather than undermines the approach.

\subsection{4.1.2 Objection 2: False Precision in
Uncertainty}\label{sec-false-precision}

\textbf{Critic}: ``Attaching exact probabilities to unprecedented events
like AI catastrophe is fundamentally misguided. The numbers create false
confidence in what amounts to educated speculation about radically
uncertain futures.''

\textbf{Response}: This philosophical objection strikes at the heart of
formal risk assessment. However, AMTAIR addresses it through several
design choices:

First, the system explicitly represents uncertainty about uncertainty.
Rather than point estimates, the framework supports probability
distributions over parameters. When someone says ``likely'' we might
model this as a range rather than exactly 0.8, capturing both the
central estimate and our uncertainty about it.

Second, all probabilities are explicitly conditional on stated
assumptions. The system doesn't claim ``P(catastrophe) = 0.05''
absolutely, but rather ``Given Carlsmith's model assumptions,
P(catastrophe) = 0.05.'' This conditionality is preserved throughout
analysis.

Third, sensitivity analysis reveals which probabilities actually matter.
Often, precise values are unnecessary---knowing whether a parameter is
closer to 0.1 or 0.9 suffices for decision-making. The formalization
helps identify where precision matters and where it doesn't.

Finally, the alternative to quantification isn't avoiding the problem
but making it worse. When experts say ``highly likely'' or ``significant
risk,'' they implicitly reason with probabilities. Formalization simply
makes these implicit quantities explicit and subject to scrutiny. As
Dennis Lindley noted, ``Uncertainty is not in the events, but in our
knowledge about them.''

\subsection{4.1.3 Objection 3: Correlation
Complexity}\label{sec-correlation-complexity}

\textbf{Critic}: ``Bayesian networks assume conditional independence
given parents, but real-world AI risks involve complex correlations.
Ignoring these dependencies could dramatically misrepresent risk
levels.''

\textbf{Response}: Standard Bayesian networks do face limitations with
correlation representation---this is a genuine technical challenge.
However, several approaches within the framework address this:

\textbf{Explicit correlation nodes}: When factors share hidden common
causes, we can add latent variables to capture correlations. For
instance, ``AI research culture'' might influence both ``capability
advancement'' and ``safety investment.''

\textbf{Copula methods}: For known correlation structures, copula
functions can model dependencies while preserving marginal
distributions. This extends standard Bayesian networks
significantly.\footnote{Copulas provide a mathematically elegant way to
  separate marginal behavior from dependence structure}

\textbf{Sensitivity bounds}: When correlations remain uncertain, we can
compute bounds on outcomes under different correlation assumptions. This
reveals when correlations critically affect conclusions.

\textbf{Model ensembles}: Different correlation structures can be
modeled separately and results aggregated, similar to climate modeling
approaches.

More fundamentally, the question is whether imperfect independence
assumptions invalidate the approach. In practice, explicitly modeling
first-order effects with known limitations often proves more valuable
than attempting to capture all dependencies informally. The framework
makes assumptions transparent, enabling targeted improvements where
correlations matter most.

\section{4.2 Conceptual and Methodological
Concerns}\label{sec-conceptual-concerns}

\subsection{4.2.1 Objection 4: Democratic
Exclusion}\label{sec-democratic-exclusion}

\textbf{Critic}: ``Transforming policy debates into complex graphs and
equations will sideline non-technical stakeholders, concentrating
influence among those comfortable with formal models. This technocratic
approach undermines democratic participation in crucial decisions about
humanity's future.''

\textbf{Response}: This concern about technocratic exclusion deserves
serious consideration---formal methods can indeed create barriers.
However, AMTAIR's design explicitly prioritizes accessibility alongside
rigor:

\textbf{Progressive disclosure interfaces} allow engagement at multiple
levels. A policymaker might explore visual network structures and
probability color-coding without engaging mathematical details.
Interactive features let users modify assumptions and see consequences
without understanding implementation.

\textbf{Natural language preservation} ensures original arguments remain
accessible. The BayesDown format maintains human-readable descriptions
alongside formal specifications. Users can always trace from
mathematical representations back to source texts.

\textbf{Comparative advantage} comes from making implicit technical
content explicit, not adding complexity. When experts debate AI risk,
they already employ sophisticated probabilistic
reasoning---formalization reveals rather than creates this complexity.
Making hidden assumptions visible arguably enhances rather than reduces
democratic participation.

\textbf{Multiple interfaces} serve different communities. Researchers
access full technical depth, policymakers use summary dashboards, public
stakeholders explore interactive visualizations. The same underlying
model supports varied engagement modes.

Rather than excluding non-technical stakeholders, proper implementation
can democratize access to expert reasoning by making it inspectable and
modifiable. The risk lies not in formalization itself but in poor
interface design or gatekeeping behaviors around model access.

\subsection{4.2.2 Objection 5: Oversimplification of Complex
Systems}\label{sec-oversimplification}

\textbf{Critic}: ``Forcing rich socio-technical systems into discrete
Bayesian networks necessarily loses crucial dynamics---feedback loops,
emergent properties, institutional responses, and cultural factors that
shape AI development. The models become precise but wrong.''

\textbf{Response}: All models simplify by necessity---as Box noted,
``All models are wrong, but some are useful.'' The question becomes
whether formal simplifications improve upon informal mental models:

\textbf{Transparent limitations} make formal models' shortcomings
explicit. Unlike mental models where simplifications remain hidden,
network representations clearly show what is and isn't included. This
transparency enables targeted criticism and improvement.

\textbf{Iterative refinement} allows models to grow more sophisticated
over time. Starting with first-order effects and adding complexity where
it proves important follows successful practice in other domains.
Climate models began simply and added dynamics as computational power
and understanding grew.

\textbf{Complementary tools} address different aspects of the system.
Bayesian networks excel at probabilistic reasoning and intervention
analysis. Other approaches---agent-based models, system dynamics,
scenario planning---can capture different properties. AMTAIR provides
one lens, not the only lens.

\textbf{Empirical adequacy} ultimately judges models. If simplified
representations enable better predictions and decisions than informal
alternatives, their abstractions are justified. Early results suggest
formal models, despite simplifications, outperform intuitive reasoning
for complex risk assessment.

The goal isn't creating perfect representations but useful ones. By
making simplifications explicit and modifiable, formal models enable
systematic improvement in ways mental models cannot.

\subsection{4.2.3 Objection 6: Idiosyncratic Implementation and Modeling
Choices}\label{sec-idiosyncratic}

\textbf{Critic}: ``The specific choices made in AMTAIR's
implementation---from prompt design to parsing algorithms to
visualization strategies---seem arbitrary. Different teams might make
entirely different choices, leading to incompatible results. How can we
trust conclusions that depend so heavily on implementation details?''

\textbf{Response}: This concern about implementation dependency is valid
and deserves careful consideration. However, several factors mitigate
this issue:

\textbf{Convergent Design Principles}: While specific implementations
vary, fundamental design principles tend to converge. The two-stage
extraction process (structure then probability) emerges naturally from
how humans parse arguments. The use of intermediate representations
follows established practice in computational linguistics. These aren't
arbitrary choices but responses to inherent challenges.

\textbf{Empirical Validation}: The ``correctness'' of implementation
choices isn't philosophical but empirical. If different reasonable
implementations extract similar structures and lead to similar policy
conclusions, this demonstrates robustness. If they diverge dramatically,
this reveals genuine ambiguity in source materials---itself valuable
information.

\textbf{Transparent Methodology}: By documenting all implementation
choices and making code open source, AMTAIR enables replication and
variation. Other teams can modify specific components while preserving
overall architecture, testing which choices matter.

\textbf{Convergence at Higher Levels}: Even if implementations differ in
details, they may converge at levels that matter for coordination. If
two systems extract slightly different network structures but reach
similar conclusions about policy robustness, the implementation
differences don't undermine the approach's value.

\textbf{Community Standards}: As the field matures, community standards
will likely emerge---not enforcing uniformity but establishing
interoperability. This parallels development in other technical fields
where multiple implementations coexist within shared frameworks.

The deeper insight is that implementation choices encode theoretical
commitments. By making these explicit and variable, AMTAIR turns a bug
into a feature---we can systematically explore how different assumptions
affect conclusions, enhancing rather than undermining epistemic
security.

\section{4.3 Red-Teaming Results}\label{sec-red-teaming}

To identify failure modes, systematic adversarial testing of the AMTAIR
system would be essential.

\subsection{4.3.1 Adversarial Extraction
Attempts}\label{sec-adversarial-extraction}

A comprehensive red-teaming approach would test the system with:

\textbf{Contradictory Arguments}: Texts containing logically
inconsistent claims or probability estimates. The system should flag
contradictions rather than silently reconciling them.

\textbf{Circular Reasoning}: Arguments with circular dependencies that
violate DAG requirements. Proper validation should detect and report
such structural issues.

\textbf{Ambiguous Language}: Texts using extremely vague or metaphorical
language. The system should acknowledge extraction uncertainty rather
than forcing precise interpretations.

\textbf{Deceptive Framings}: Arguments crafted to imply false causal
relationships. This tests whether the system merely extracts surface
claims or requires deeper coherence.

\textbf{Adversarial Prompts}: Inputs designed to trigger known LLM
failure modes. This ensures robustness against prompt injection and
manipulation attempts.

Each failure mode discovered would inform system improvements and user
guidance.

\subsection{4.3.2 Robustness Findings}\label{sec-robustness-findings}

Theoretical analysis suggests key vulnerabilities:

\textbf{Anchoring Effects}: Language models may over-weight information
presented early in documents, potentially biasing extraction toward
initial framings.

\textbf{Authority Sensitivity}: Extraction might be influenced by
explicit credibility signals in text, potentially giving undue weight to
claimed expertise.

\textbf{Complexity Limits}: Performance likely degrades with very large
argument structures, requiring hierarchical decomposition strategies.

\textbf{Context Windows}: Long-range dependencies exceeding model
context windows could be missed, fragmenting cohesive arguments.

Understanding these limitations enables appropriate use---leveraging
strengths while compensating for weaknesses through human oversight and
validation.

\subsection{4.3.3 Implications for
Deployment}\label{sec-deployment-implications}

These considerations suggest AMTAIR is suitable for:

\begin{itemize}
\tightlist
\item
  \textbf{Research applications} with expert oversight
\item
  \textbf{Policy analysis} of well-structured arguments
\item
  \textbf{Educational uses} demonstrating formal reasoning
\item
  \textbf{Collaborative modeling} with human verification
\end{itemize}

But should be used cautiously for:

\begin{itemize}
\tightlist
\item
  Fully automated analysis without review
\item
  Adversarial or politically contentious texts
\item
  Real-time decision-making without validation
\item
  Arguments far outside training distribution
\end{itemize}

\section{4.4 Enhancing Epistemic Security}\label{sec-epistemic-security}

Despite limitations, AMTAIR contributes to epistemic security in AI
governance through several mechanisms.

\subsection{4.4.1 Making Models
Inspectable}\label{sec-inspectable-models}

The greatest epistemic benefit comes from forcing implicit models into
explicit form. When an expert claims ``misalignment likely leads to
catastrophe,'' formalization asks:

\begin{itemize}
\tightlist
\item
  Likely means what probability?
\item
  Through what causal pathways?
\item
  Under what assumptions?
\item
  With what evidence?
\end{itemize}

This explicitation serves multiple functions:

\textbf{Clarity}: Vague statements become precise claims subject to
evaluation

\textbf{Comparability}: Different experts' models can be systematically
compared

\textbf{Criticizability}: Hidden assumptions become visible targets for
challenge

\textbf{Updatability}: Formal models can systematically incorporate new
evidence

\subsection{4.4.2 Revealing Convergence and
Divergence}\label{sec-convergence-divergence}

Theoretical analysis suggests formal comparison would reveal:

\textbf{Structural Patterns}: Experts likely share more agreement about
causal structures than probability values, suggesting common
understanding of mechanisms despite quantitative disagreement.

\textbf{Crux Identification}: Formal models make explicit which specific
disagreements drive different conclusions, focusing discussion on
genuinely critical differences.

\textbf{Hidden Agreements}: Apparently conflicting positions might share
substantial common ground obscured by different terminology or emphasis.

\textbf{Uncertainty Clustering}: Areas of high uncertainty likely
correlate across models, revealing where additional research would most
reduce disagreement.

These patterns remain invisible in natural language debates but become
analyzable through formalization.

\subsection{4.4.3 Improving Collective
Reasoning}\label{sec-collective-reasoning}

AMTAIR enhances group epistemics through:

\textbf{Explicit uncertainty}: Replacing ``might,'' ``could,''
``likely'' with probability distributions reduces miscommunication and
forces precision

\textbf{Compositional reasoning}: Complex arguments decompose into
manageable components that can be independently evaluated

\textbf{Evidence integration}: New information updates specific
parameters rather than requiring complete argument reconstruction

\textbf{Exploration tools}: Stakeholders can modify assumptions and
immediately see consequences, building intuition about model dynamics

While empirical validation remains future work, theoretical
considerations suggest these mechanisms could substantially improve
coordination quality. By providing shared representations and systematic
methods for managing disagreement, formal models create infrastructure
for collective intelligence that transcends individual limitations.

\section{4.5 Scaling Challenges and Opportunities}\label{sec-scaling}

Moving from prototype to widespread adoption faces both technical and
social challenges.

\subsection{4.5.1 Technical Scaling}\label{sec-technical-scaling}

\textbf{Computational complexity} grows with network size, but several
approaches help:

\begin{itemize}
\tightlist
\item
  Hierarchical decomposition for very large models
\item
  Caching and approximation for common queries
\item
  Distributed processing for extraction tasks
\item
  Incremental updating rather than full recomputation
\end{itemize}

\textbf{Data quality} varies dramatically across sources:

\begin{itemize}
\tightlist
\item
  Academic papers provide structured arguments
\item
  Blog posts offer rich ideas with less formal structure
\item
  Policy documents mix normative and empirical claims
\item
  Social media presents extreme extraction challenges
\end{itemize}

\textbf{Integration complexity} increases with ecosystem growth:

\begin{itemize}
\tightlist
\item
  Multiple LLM providers with different capabilities
\item
  Diverse visualization needs across users
\item
  Various export formats for downstream tools
\item
  Version control for evolving models
\end{itemize}

\subsection{4.5.2 Social and Institutional
Scaling}\label{sec-social-scaling}

\textbf{Adoption barriers} include:

\begin{itemize}
\tightlist
\item
  Learning curve for formal methods
\item
  Institutional inertia in established processes
\item
  Concerns about replacing human judgment
\item
  Resource requirements for implementation
\end{itemize}

\textbf{Trust building} requires:

\begin{itemize}
\tightlist
\item
  Transparent methodology documentation
\item
  Published validation studies
\item
  High-profile successful applications
\item
  Community ownership and development
\end{itemize}

\textbf{Sustainability} depends on:

\begin{itemize}
\tightlist
\item
  Open source development model
\item
  Diverse funding sources
\item
  Academic and industry partnerships
\item
  Clear value demonstration
\end{itemize}

\subsection{4.5.3 Opportunities for
Impact}\label{sec-impact-opportunities}

Despite challenges, several factors favor adoption:

\textbf{Timing}: AI governance needs tools now, creating receptive
audiences

\textbf{Complementarity}: AMTAIR enhances rather than replaces existing
processes

\textbf{Flexibility}: The approach adapts to different contexts and
needs

\textbf{Network effects}: Value increases as more perspectives are
formalized

Early adopters in research organizations and think tanks can demonstrate
value, creating momentum for broader adoption.

\section{4.6 Integration with Governance
Frameworks}\label{sec-governance-integration}

AMTAIR complements rather than replaces existing governance approaches.

\subsection{4.6.1 Standards
Development}\label{sec-standards-integration}

Technical standards bodies could use AMTAIR to:

\begin{itemize}
\tightlist
\item
  Model how proposed standards affect risk pathways
\item
  Compare different standard options systematically
\item
  Identify unintended consequences through pathway analysis
\item
  Build consensus through explicit model negotiation
\end{itemize}

Example: Evaluating compute thresholds for AI system regulation by
modeling how different thresholds affect capability development, safety
investment, and competitive dynamics.

\subsection{4.6.2 Regulatory Design}\label{sec-regulatory-integration}

Regulators could apply the framework to:

\begin{itemize}
\tightlist
\item
  Assess regulatory impact across different scenarios
\item
  Identify enforcement challenges through explicit modeling
\item
  Compare international approaches systematically
\item
  Design adaptive regulations responsive to evidence
\end{itemize}

Example: Analyzing how liability frameworks affect corporate AI
development decisions under different market conditions.

The extensive literature on corporate governance and liability
frameworks \textcite{cuomo2016} \textcite{demirag2000}
\textcite{devilliers2021} \textcite{divito2022} \textcite{kaur2024}
\textcite{list2011} \textcite{solomon2020} provides theoretical
grounding for understanding how regulatory interventions shape
organizational behavior. AMTAIR could formalize these relationships in
the specific context of AI development, making explicit how different
liability regimes might incentivize or discourage safety investments.

\subsection{4.6.3 International
Coordination}\label{sec-international-integration}

Multilateral bodies could leverage shared models for:

\begin{itemize}
\tightlist
\item
  Establishing common risk assessments
\item
  Negotiating agreements with explicit assumptions
\item
  Monitoring compliance through parameter tracking
\item
  Adapting agreements as evidence emerges
\end{itemize}

Example: Building shared models for AGI development scenarios to inform
international AI governance treaties.

\subsection{4.6.4 Organizational
Decision-Making}\label{sec-organizational-integration}

Individual organizations could use AMTAIR for:

\begin{itemize}
\tightlist
\item
  Internal risk assessment and planning
\item
  Board-level communication about AI strategies
\item
  Research prioritization based on model sensitivity
\item
  Safety case development with explicit assumptions
\end{itemize}

Example: An AI lab modeling how different safety investments affect both
capability advancement and risk mitigation.

\section{4.7 Future Research Directions}\label{sec-future-research}

Several research directions could enhance AMTAIR's capabilities and
impact.

\subsection{4.7.1 Technical Enhancements}\label{sec-technical-future}

\textbf{Improved extraction}: Fine-tuning language models specifically
for argument extraction, handling implicit reasoning, and cross-document
synthesis

\textbf{Richer representations}: Temporal dynamics, continuous
variables, and multi-agent interactions within extended frameworks

\textbf{Inference advances}: Quantum computing applications, neural
approximate inference, and hybrid symbolic-neural methods

\textbf{Validation methods}: Automated consistency checking, anomaly
detection in extracted models, and benchmark dataset development

\subsection{4.7.2 Methodological
Extensions}\label{sec-methodological-future}

\textbf{Causal discovery}: Inferring causal structures from data rather
than just extracting from text

\textbf{Experimental integration}: Connecting models to empirical
results from AI safety experiments

\textbf{Dynamic updating}: Continuous model refinement as new evidence
emerges from research and deployment

\textbf{Uncertainty quantification}: Richer representation of deep
uncertainty and model confidence

Recent advances in causal structure learning from both text and data
\textcite{babakov2025} \textcite{ban2023} \textcite{bethard2007}
\textcite{chen2023} \textcite{heinze-deml2018} \textcite{squires2023}
\textcite{yang2022} suggest promising directions for enhancing AMTAIR's
extraction capabilities. The theoretical foundations from
\textcite{duhem1954} and \textcite{meyer2022b} on the philosophy of
science and knowledge structures provide epistemological grounding for
these methodological extensions.

\subsection{4.7.3 Application Domains}\label{sec-application-future}

\textbf{Beyond AI safety}: Climate risk, biosecurity, nuclear policy,
and other existential risks

\textbf{Corporate governance}: Strategic planning, risk management, and
innovation assessment

\textbf{Scientific modeling}: Formalizing theoretical arguments in
emerging fields

\textbf{Educational tools}: Teaching probabilistic reasoning and
critical thinking

\subsection{4.7.4 Ecosystem Development}\label{sec-ecosystem-future}

\textbf{Open standards}: Common formats for model exchange and tool
interoperability

\textbf{Community platforms}: Collaborative model development and
sharing infrastructure

\textbf{Training programs}: Building capacity for formal modeling in
governance communities

\textbf{Quality assurance}: Certification processes for high-stakes
model applications

These directions could transform AMTAIR from a single tool into a
broader ecosystem for enhanced reasoning about complex risks.

\section{4.8 Known Unknowns and Deep
Uncertainties}\label{sec-deep-uncertainties}

While AMTAIR enhances reasoning under uncertainty, fundamental
limitations remain regarding truly novel developments that might fall
outside existing conceptual frameworks.

\subsection{4.8.1 Categories of Deep
Uncertainty}\label{sec-uncertainty-categories}

\textbf{Novel Capabilities}: Future AI developments may operate
according to principles outside current scientific understanding. No
amount of careful modeling can anticipate fundamental paradigm shifts in
what intelligence can accomplish.

\textbf{Emergent Behaviors}: Complex system properties that resist
prediction from component analysis may dominate outcomes. The
interaction between advanced AI systems and human society could produce
wholly unexpected dynamics.

\textbf{Strategic Interactions}: Game-theoretic dynamics with superhuman
AI systems exceed human modeling capacity. We cannot reliably predict
how entities smarter than us will behave strategically.

\textbf{Social Transformation}: Unprecedented social and economic
changes may invalidate current institutional assumptions. Our models
assume continuity in basic social structures that AI might fundamentally
alter.

\subsection{4.8.2 Adaptation Strategies for Deep
Uncertainty}\label{sec-adaptation-strategies}

Rather than pretending to model the unmodelable, AMTAIR incorporates
several strategies:

\textbf{Model Architecture Flexibility}: The modular structure enables
rapid incorporation of new variables as novel factors become apparent.
When surprises occur, models can be updated rather than discarded.

\textbf{Explicit Uncertainty Tracking}: Confidence levels for each model
component make clear where knowledge is solid versus speculative. This
prevents false confidence in highly uncertain domains.

\textbf{Scenario Branching}: Multiple model variants capture different
assumptions about fundamental uncertainties. Rather than committing to
one worldview, the system maintains portfolios of possibilities.

\textbf{Update Mechanisms}: Integration with prediction markets and
expert assessment enables rapid model revision as new information
emerges. Models evolve rather than remaining static.

\subsection{4.8.3 Robust Decision-Making
Principles}\label{sec-robust-principles}

Given deep uncertainty, certain decision principles become paramount:

\textbf{Option Value Preservation}: Policies should maintain flexibility
for future course corrections rather than locking in irreversible
choices based on current models.

\textbf{Portfolio Diversification}: Multiple approaches hedging across
different uncertainty sources provide robustness against model error.

\textbf{Early Warning Systems}: Monitoring for developments that would
invalidate current models enables rapid response when assumptions break
down.

\textbf{Adaptive Governance}: Institutional mechanisms must enable rapid
response to new information rather than rigid adherence to plans based
on outdated models.

The goal is not to eliminate uncertainty but to make good decisions
despite it. AMTAIR provides tools for systematic reasoning about what we
do know while maintaining appropriate humility about what we don't and
can't know.

\section{4.9 Summary of Implications}\label{sec-implications-summary}

The discussion reveals both the promise and limitations of computational
approaches to AI governance coordination:

\textbf{Technical Feasibility}: Despite imperfections, automated
extraction and formal modeling prove practically viable for complex AI
risk arguments.

\textbf{Epistemic Value}: Making implicit models explicit, enabling
systematic comparison, and supporting evidence integration enhance
collective reasoning.

\textbf{Practical Limitations}: Extraction boundaries, false precision
risks, and implementation dependencies require careful management.

\textbf{Integration Potential}: The approach complements rather than
replaces existing governance frameworks, adding rigor without
sacrificing flexibility.

\textbf{Future Development}: Technical enhancements, methodological
extensions, and ecosystem growth could amplify impact.

\textbf{Deep Uncertainty}: Fundamental limits on predicting novel
developments require maintaining humility and adaptability.

These findings suggest AMTAIR represents a valuable addition to the AI
governance toolkit---not a panacea but a meaningful enhancement to our
collective capacity for navigating unprecedented challenges.

\bookmarksetup{startatroot}

\chapter{5. Conclusion: Toward Coordinated AI
Governance}\label{sec-conclusion}

\section{5.1 Summary of Key Contributions}\label{sec-key-contributions}

This thesis has demonstrated both the need for and feasibility of
computational approaches to enhancing coordination in AI governance. The
work makes several distinct contributions across theory, methodology,
and implementation.

\subsection{5.1.1 Theoretical
Contributions}\label{sec-theoretical-contributions}

\textbf{Diagnosis of the Coordination Crisis}: I've articulated how
fragmentation across technical, policy, and strategic communities
systematically amplifies existential risk from advanced AI. This framing
moves beyond identifying disagreements to understanding how misaligned
efforts create negative-sum dynamics---safety gaps emerge between
communities, resources are misallocated through duplication and neglect,
and interventions interact destructively.

\textbf{The Multiplicative Benefits Framework}: The combination of
automated extraction, prediction market integration, and formal policy
evaluation creates value exceeding the sum of parts. Automation enables
scale, markets provide empirical grounding, and policy analysis delivers
actionable insights. Together, they address different facets of the
coordination challenge while reinforcing each other's strengths.

\textbf{Epistemic Infrastructure Conception}: Positioning formal models
as epistemic infrastructure reframes the role of technical tools in
governance. Rather than replacing human judgment, computational
approaches provide common languages, shared representations, and
systematic methods for managing disagreement---essential foundations for
coordination under uncertainty.

\subsection{5.1.2 Methodological
Innovations}\label{sec-methodological-innovations}

\textbf{Two-Stage Extraction Architecture}: Separating structural
extraction (ArgDown) from probability quantification (BayesDown)
addresses key challenges in automated formalization. This modularity
enables human oversight at critical points, supports multiple
quantification methods, allows for unprecedented transparency and
explainability of the entire process, and isolates different types of
errors for targeted improvement.

\textbf{BayesDown as Bridge Representation}: The development of
BayesDown syntax creates a crucial intermediate representation
preserving both narrative accessibility and mathematical precision. This
bridge enables the transformation from qualitative arguments to
quantitative models while maintaining traceability and human
readability.

\textbf{Validation Framework}: The systematic approach to validating
automated extraction---comparing against expert annotations, measuring
multiple accuracy dimensions, and analyzing error patterns---establishes
scientific standards for assessing formalization tools. This framework
can guide future development in this emerging area.

\subsection{5.1.3 Technical
Achievements}\label{sec-technical-achievements}

\textbf{Working Implementation}: AMTAIR demonstrates end-to-end
feasibility from document ingestion through interactive visualization.
The system successfully processes complex arguments like Carlsmith's
power-seeking AI model, extracting hierarchical structures and
probability information.

\textbf{Scalability Solutions}: Technical approaches for handling
realistic model complexity---hierarchical decomposition, approximate
inference, and progressive visualization---show that computational
limitations need not prevent practical application.

\textbf{Accessibility Design}: The layered interface approach serves
diverse stakeholders without compromising technical depth. Progressive
disclosure, visual encoding, and interactive exploration make formal
models accessible beyond technical specialists.

\subsection{5.1.4 Empirical Findings}\label{sec-empirical-findings}

\textbf{Extraction Feasibility}: The successful extraction of complex
arguments like Carlsmith's model validates the core premise that
implicit formal structures exist in natural language arguments and can
be computationally recovered with reasonable fidelity.

\textbf{Convergence Patterns}: Theoretical analysis suggests that formal
comparison would reveal structural agreements across different expert
worldviews even when probability estimates diverge---providing
foundations for coordination.

\textbf{Intervention Impacts}: Policy evaluation capabilities
demonstrate how formal models enable rigorous assessment of governance
options. The ability to trace intervention effects through complex
causal networks validates the practical value of formalization.

\section{5.2 Limitations and Honest
Assessment}\label{sec-limitations-assessment}

Despite these contributions, important limitations constrain current
capabilities and should guide appropriate use.

\subsection{5.2.1 Technical
Constraints}\label{sec-technical-constraints}

\textbf{Extraction Boundaries}: The system struggles with implicit
assumptions, complex conditionals, and ambiguous quantifiers. These
limitations necessitate human review for high-stakes applications.

\textbf{Correlation Handling}: Standard Bayesian networks inadequately
represent complex correlations in real systems. While extensions like
copulas and explicit correlation nodes help, fully capturing
interdependencies remains challenging.

\textbf{Computational Scaling}: Very large networks require
approximations that may affect accuracy. As models grow to represent
richer phenomena, computational constraints increasingly bind.

\subsection{5.2.2 Conceptual
Limitations}\label{sec-conceptual-limitations}

\textbf{Formalization Trade-offs}: Converting rich arguments to formal
models necessarily loses nuance. While making assumptions explicit
provides value, some insights resist mathematical representation.

\textbf{Probability Interpretation}: Deep uncertainty about
unprecedented events challenges probabilistic representation. Numbers
can create false precision even when explicitly conditional and
uncertain.

\textbf{Social Complexity}: Institutional dynamics, cultural factors,
and political processes influence AI development in ways that causal
models struggle to capture fully.

\subsection{5.2.3 Practical
Constraints}\label{sec-practical-constraints}

\textbf{Adoption Barriers}: Learning curves, institutional inertia, and
resource requirements limit immediate deployment. Even demonstrably
valuable tools face implementation challenges.

\textbf{Maintenance Burden}: Models require updating as arguments evolve
and evidence emerges. Without sustained effort, formal representations
quickly become outdated.

\textbf{Context Dependence}: The approach works best for well-structured
academic arguments. Application to informal discussions or political
rhetoric remains challenging.

\section{5.3 Implications for AI
Governance}\label{sec-governance-implications}

Despite limitations, AMTAIR's approach offers significant implications
for how AI governance can evolve toward greater coordination and
effectiveness.

\subsection{5.3.1 Near-Term
Applications}\label{sec-near-term-applications}

\textbf{Research Coordination}: Research organizations can use formal
models to:

\begin{itemize}
\tightlist
\item
  Map the landscape of current arguments and identify gaps
\item
  Prioritize investigations targeting high-sensitivity parameters
\item
  Build cumulative knowledge through explicit model updating
\item
  Facilitate collaboration through shared representations
\end{itemize}

\textbf{Policy Development}: Governance bodies can apply the framework
to:

\begin{itemize}
\tightlist
\item
  Evaluate proposals across multiple expert worldviews
\item
  Identify robust interventions effective under uncertainty
\item
  Make assumptions explicit for democratic scrutiny
\item
  Track how evidence changes optimal policies over time
\end{itemize}

\textbf{Stakeholder Communication}: The visualization and analysis tools
enable:

\begin{itemize}
\tightlist
\item
  Clearer communication between technical and policy communities
\item
  Public engagement with complex risk assessments
\item
  Board-level strategic discussions grounded in formal analysis
\item
  International negotiations with explicit shared models
\end{itemize}

\subsection{5.3.2 Medium-Term Transformation}\label{sec-medium-term}

As adoption spreads, we might see:

\textbf{Epistemic Commons}: Shared repositories of formalized arguments
become reference points for governance discussions, similar to how
economic models inform monetary policy or climate models guide
environmental agreements.

\textbf{Adaptive Governance}: Policies designed with explicit models can
include triggers for reassessment as key parameters change, enabling
responsive governance that avoids both paralysis and recklessness.

\textbf{Professionalization}: ``Model curator'' and ``argument
formalization specialist'' emerge as recognized roles, building
expertise in bridging natural language and formal representations.

\textbf{Quality Standards}: Community norms develop around model
transparency, validation requirements, and appropriate use cases,
preventing both dismissal and over-reliance on formal tools.

\subsection{5.3.3 Long-Term Vision}\label{sec-long-term-vision}

Successfully scaling this approach could fundamentally alter AI
governance:

\textbf{Coordinated Response}: Rather than fragmented efforts, the AI
safety ecosystem could operate with shared situational
awareness---different actors understanding how their efforts interact
and contribute to collective goals.

\textbf{Anticipatory Action}: Formal models with prediction market
integration could provide early warning of emerging risks, enabling
proactive rather than reactive governance.

\textbf{Global Cooperation}: Shared formal frameworks could facilitate
international coordination similar to how economic models enable
monetary coordination or climate models support environmental
agreements.

\textbf{Democratic Enhancement}: Making expert reasoning transparent and
modifiable could enable broader participation in crucial decisions about
humanity's technological future.

\section{5.4 Recommendations for
Stakeholders}\label{sec-recommendations}

Different communities can take concrete steps to realize these benefits:

\subsection{5.4.1 For Researchers}\label{sec-researcher-recommendations}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Experiment with formalization}: Try extracting your own
  arguments into ArgDown/BayesDown format to discover implicit
  assumptions
\item
  \textbf{Contribute to validation}: Provide expert annotations for
  building benchmark datasets and improving extraction quality
\item
  \textbf{Develop extensions}: Build on the open-source foundation to
  add capabilities for your specific domain needs
\item
  \textbf{Publish formally}: Include formal model representations
  alongside traditional papers to enable cumulative building
\end{enumerate}

\subsection{5.4.2 For
Policymakers}\label{sec-policymaker-recommendations}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Pilot applications}: Use AMTAIR for internal analysis of
  specific policy proposals to build familiarity and identify value
\item
  \textbf{Demand transparency}: Request formal models underlying expert
  recommendations to understand assumptions and uncertainties
\item
  \textbf{Fund development}: Support tool development and training to
  build governance capacity for formal methods
\item
  \textbf{Design adaptively}: Create policies with explicit triggers
  based on model parameters to enable responsive governance
\end{enumerate}

\subsection{5.4.3 For
Technologists}\label{sec-technologist-recommendations}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Improve extraction}: Contribute better prompting strategies,
  fine-tuned models, or validation methods
\item
  \textbf{Enhance interfaces}: Develop visualizations and interactions
  serving specific stakeholder needs
\item
  \textbf{Build integrations}: Connect AMTAIR to other tools in the AI
  governance ecosystem
\item
  \textbf{Scale infrastructure}: Address computational challenges for
  larger models and broader deployment
\end{enumerate}

\section{5.5 Future Research Agenda}\label{sec-future-research-agenda}

Looking ahead, the landscape of possibilities stretches toward the
horizon, each path promising its own rewards and challenges. Let me map
the territory worth exploring.

\subsection{5.5.1 Technical Priorities}\label{sec-technical-priorities}

The technical frontier advances on multiple fronts, each offering
multiplicative improvements when combined:

\textbf{Extraction Enhancement}: The current system, while functional,
merely scratches the surface of what's possible. Fine-tuning language
models specifically on argument extraction tasks could dramatically
improve accuracy. Imagine models trained not just on general text but on
thousands of examples of arguments transformed into formal
representations.

\textbf{Handling Implicit Reasoning}: So much of expert argumentation
relies on unstated background knowledge. When an AI safety researcher
mentions ``mesa-optimization,'' they assume familiarity with complex
concepts about learned optimization occurring within larger optimization
processes. Future systems need to bridge these inferential gaps, perhaps
by maintaining explicit knowledge bases of domain concepts or by
training models to recognize and fill common argumentative ellipses.

\textbf{Cross-Document Synthesis}: Real understanding emerges not from
single papers but from conversations across documents. Authors respond
to each other, build on previous work, refine arguments over time.
Future systems should trace these intellectual lineages, building
composite models that capture evolving community understanding rather
than static snapshots.

\textbf{Representation Extensions}: Current Bayesian networks, while
powerful, make limiting assumptions. Temporal dynamics matter---AI
development unfolds over time, with early decisions constraining later
options. Multi-agent representations could capture strategic
interactions between actors. Continuous variables better represent
quantities like ``capability level'' than binary approximations. Each
extension opens new analytical possibilities.

\subsection{5.5.2 Methodological
Development}\label{sec-methodological-development}

Beyond technical improvements lie deeper methodological questions about
how we validate, use, and improve these systems:

\textbf{Validation Science}: We need not just ad hoc evaluation but a
science of argument extraction assessment. This means building benchmark
datasets capturing diverse argument types, developing metrics that go
beyond surface accuracy to semantic fidelity, creating adversarial test
suites that probe system limitations, and establishing longitudinal
studies tracking how extracted models evolve with updating source
documents.

\textbf{Hybrid Intelligence}: The future isn't human or AI but human and
AI. Optimal collaboration patterns remain unexplored. Should humans
verify structure while AI handles probabilities? Should AI propose
multiple extractions for human selection? How do we combine formal
models with scenario narratives, quantitative forecasts with qualitative
insights? The design space for human-AI collaboration in argument
formalization remains largely uncharted.

\textbf{Social Methods}: Technology embedded in social contexts requires
social science. How do organizations actually use these models? What
changes when formal representations replace informal discussions?
Ethnographic studies of model use, measurement of coordination
improvements, identification of adoption barriers---all essential for
real-world impact.

\subsection{5.5.3 Application
Expansion}\label{sec-application-expansion}

The principles underlying AMTAIR apply far beyond AI risk:

\textbf{Domain Extensions}: Every field grappling with complex risks
could benefit. Biosecurity faces similar challenges---technical
complexity, value-laden choices, deep uncertainty. Climate policy
involves multi-level causation across physical, economic, and social
systems. Nuclear policy, despite decades of study, still struggles with
coordination across technical and strategic communities. Each domain
would require specialized extraction approaches but could leverage the
same fundamental architecture.

\textbf{Institutional Integration}: Moving from research prototype to
institutional tool requires thoughtful embedding. Regulatory impact
assessment could incorporate formal modeling to make assumptions
explicit. Corporate strategic planning, especially for companies
developing advanced technologies, needs tools for reasoning about
unprecedented risks. Academic peer review might benefit from formal
representation of complex arguments.

\textbf{Global Deployment}: AI governance is inherently international,
but different regions have different governance cultures, risk
tolerances, and institutional structures. Adapting AMTAIR for different
contexts---from Silicon Valley's move-fast culture to the EU's
precautionary approach to China's state-led development---requires both
technical and cultural translation.

\section{5.6 Closing Reflections}\label{sec-closing-reflections}

As I write these final words, I'm struck by the peculiar position we
find ourselves in. We are arguably the first generation that must govern
technologies that could fundamentally transform or terminate our
species' story. The margin for error shrinks as capabilities grow. The
cost of coordination failure rises toward infinity.

The AMTAIR project emerged from a simple observation paired with an
ambitious hope. The observation: while humanity mobilizes unprecedented
resources to address AI risks, our efforts remain tragically
uncoordinated. Different communities work with incompatible frameworks,
duplicate efforts, and sometimes actively undermine each other's work.
The hope: that computational tools might help us build the epistemic
infrastructure necessary for coordination.

What we've accomplished here is both less and more than originally
envisioned. Less, because the challenges proved deeper than anticipated.
Natural language resists formalization. Probabilities remain stubbornly
subjective. Coordination failures have roots beyond mere communication
difficulties. More, because the journey revealed unexpected
possibilities. Intermediate representations became valuable in
themselves. The extraction process surfaced insights about argument
structure. The visualization work demonstrated how thoughtful design can
democratize access to formal tools.

Perhaps most importantly, this work demonstrates that perfect solutions
need not be the enemy of meaningful progress. AMTAIR doesn't solve the
coordination crisis---no single tool could. But it offers genuine
assistance: making implicit models explicit, enabling systematic
comparison across worldviews, supporting evidence-based policy
evaluation, and creating common ground for productive disagreement.

\textbf{The Stakes}: Let me be plain about what's at risk. The
development of artificial general intelligence represents a
discontinuity in human history comparable to the emergence of life or
the evolution of consciousness. Get it right, and we might solve
problems that have plagued humanity since our beginning---disease,
poverty, ignorance, perhaps even death itself. Get it wrong, and we
might extinguish not just ourselves but all the potential futures we
might have created.

This isn't science fiction or academic speculation. The capabilities
advancing in labs today point toward systems that could, within decades
or less, exceed human cognitive abilities across all domains. What
happens when we create minds greater than our own? How do we ensure they
remain aligned with human values and flourishing? These questions demand
our best collective wisdom.

Yet we approach this challenge fragmented. Technical researchers develop
alignment techniques without clear paths to implementation. Policymakers
craft governance frameworks without deep technical understanding.
Ethicists articulate values without operational specificity.
International bodies convene without shared models of the risks they're
addressing. This fragmentation isn't just inefficient---it's
existentially dangerous.

AMTAIR represents one attempt to build bridges. By automating the
extraction of worldviews, integrating live forecasts, and enabling
systematic policy evaluation, we create infrastructure for enhanced
coordination. Not coordination itself---that requires human wisdom,
institutional change, and political will. But infrastructure that makes
coordination more feasible.

The path forward demands both ambition and humility. Ambition to build
the tools, institutions, and practices necessary for navigating
unprecedented risks. Humility to recognize that our tools are imperfect,
our understanding incomplete, and our time limited. We must act despite
uncertainty, coordinate despite disagreement, and hope despite the
magnitude of the challenge.

As I close this thesis, I think of future readers---perhaps humans
living in a world made wonderful by aligned AI, perhaps historians
studying how we navigated this crucial transition, perhaps no one at all
if we fail. To those readers, know that we tried. We saw the challenge,
recognized our limitations, and attempted to build what tools we could.

The coordination crisis in AI governance represents both existential
risk and existential opportunity. Risk, if we fail to align our efforts
before it's too late. Opportunity, if we succeed in creating
unprecedented cooperation around humanity's most important challenge.
AMTAIR offers one piece of the puzzle---computational infrastructure
that enhances our collective ability to reason about complex risks.

May we prove worthy of the challenge before us. May our tools amplify
our wisdom rather than our folly. And may future generations look back
on this time not as when humanity failed to coordinate, but as when we
rose to meet our greatest test.

The work continues. The stakes could not be higher. The time grows
short. Let us build what we can, while we can, for all our futures
depend on it.

\bookmarksetup{startatroot}

\chapter*{Bibliography}\label{bibliography}
\addcontentsline{toc}{chapter}{Bibliography}

\markboth{Bibliography}{Bibliography}

\printbibliography[heading=none]

\cleardoublepage
\phantomsection
\addcontentsline{toc}{part}{Appendices}
\appendix

\chapter{}\label{section}

{[}Existential\_Risk{]}: Increase in existential risks for humanity.
\{``instantiations'': {[}TRUE'', ``FALSE''{]}\}

\begin{itemize}
\tightlist
\item
  {[}Unaligned\_AGI\_Risk{]}: Unaligned artificial general intelligence
  causes existential risk. \{``instantiations'': {[}TRUE'',
  ``FALSE''{]}\}

  \begin{itemize}
  \tightlist
  \item
    {[}State-State\_Relations{]}
  \end{itemize}
\item
  {[}Near\_term\_AI{]}: Even if not unaligned AGI, near term AI can act
  as intermediate risk factor. \{``instantiations'': {[}TRUE'',
  ``FALSE''{]}\}

  \begin{itemize}
  \tightlist
  \item
    {[}State-State\_Relations{]}: AI arms race dynamic inhibits
    international coordination, diverting resources from other pressing
    issues \{``instantiations'': {[}TRUE'', ``FALSE''{]}\}

    \begin{itemize}
    \tightlist
    \item
      {[}Cybersecurity{]}: Probably enhances Cyber-Attack-Offense, may
      intensify cyber warfare. \{``instantiations'': {[}TRUE'',
      ``FALSE''{]}\}
    \end{itemize}
  \item
    {[}State-Cooperation\_Relations{]}: Cooperations have a lot of power
    and might have misaligned goals with society \{``instantiations'':
    {[}TRUE'', ``FALSE''{]}\}
  \item
    {[}Stable\_Repressive\_Regime{]}: More repressive instruments,
    possibility of stable repressive regime. \{``instantiations'':
    {[}``TRUE'', ``FALSE''{]}\}

    \begin{itemize}
    \tightlist
    \item
      {[}State-Citizen\_Relations{]}: AI helps regime monitor citizens
      \{``instantiations'': {[}TRUE'', ``FALSE''{]}\}
    \end{itemize}
  \item
    {[}Compromised\_Political\_Decision\_Making{]}: AI can compromise
    political decision making. \{``instantiations'': {[}``TRUE'',
    ``FALSE''{]}\}

    \begin{itemize}
    \tightlist
    \item
      {[}Social\_media\_and\_Recommender\_Systems{]}: Influence of AI in
      social media on public opinion. \{``instantiations'': {[}TRUE'',
      ``FALSE''{]}\}
    \end{itemize}
  \end{itemize}
\item
  {[}Nuclear{]}: Probability that nuclear conflict escalates to end
  civilisation. \{``instantiations'': {[}TRUE'', ``FALSE''{]}\}

  \begin{itemize}
  \tightlist
  \item
    {[}Compromised\_Political\_Decision\_Making{]}
  \end{itemize}
\item
  {[}Biological{]}: Probability that a natural or engineered pandemic
  poses existential risks. \{``instantiations'': {[}``TRUE'',
  ``FALSE''{]}\}

  \begin{itemize}
  \tightlist
  \item
    {[}Compromised\_Political\_Decision\_Making{]}
  \item
    {[}Social\_media\_and\_Recommender\_Systems{]}
  \end{itemize}
\item
  {[}Natural{]}: Non-human caused existential risks, seem unrelated with
  AI. \{``instantiations'': {[}``TRUE'', ``FALSE''{]}\}
\item
  {[}Environmental{]}: Probability of climate catastrophe.
  \{``instantiations'': {[}``TRUE'', ``FALSE''{]}\}

  \begin{itemize}
  \tightlist
  \item
    {[}Compromised\_Political\_Decision\_Making{]}
  \item
    {[}AI\_resource\_consumption{]}: Current AI models consume large
    amounts of energy having environmental impacts.
    \{``instantiations'': {[}``TRUE'', ``FALSE''{]}\}
  \item
    {[}Social\_media\_and\_Recommender\_Systems{]}
  \end{itemize}
\end{itemize}

\chapter{\texorpdfstring{\href{https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb\#scrollTo=lt8-AnebGUXr}{AMTAIR
Prototype Demonstration (Public Colab
Notebook)}}{AMTAIR Prototype Demonstration (Public Colab Notebook)}}\label{amtair-prototype-demonstration-public-colab-notebook}

\chapter{AMTAIR Prototype: Automating Transformative AI Risk
Modeling}\label{amtair-prototype-automating-transformative-ai-risk-modeling}

\section{Executive Summary}\label{executive-summary}

This notebook implements a prototype of the AMTAIR (Automating
Transformative AI Risk Modeling) project, which addresses the critical
coordination failure in AI governance by developing computational tools
that automate the extraction of probabilistic world models from AI
safety literature.

The prototype demonstrates the transformation pipeline from structured
argument representations (ArgDown) to probabilistic Bayesian networks
(BayesDown), enabling the visualization and analysis of causal
relationships and probability distributions that underlie AI risk
assessments and policy evaluations.

\subsection{Purpose Within the Master's
Thesis}\label{purpose-within-the-masters-thesis}

This notebook serves as the technical implementation component of the
Master's thesis ``Automating Transformative AI Risk Modeling: A
Computational Approach to Policy Impact Evaluation.'' It demonstrates
the feasibility of automating the extraction and formalization of world
models, focusing on the core extraction pipeline and visualization
capabilities that form the foundation for more sophisticated analysis.

\subsection{Relevance to AI
Governance}\label{relevance-to-ai-governance}

The coordination crisis in AI governance stems from different
stakeholders working with incompatible assumptions, terminologies, and
priorities. By making implicit models explicit through automated
extraction and formalization, this work helps bridge communication gaps
between technical researchers, policy specialists, and other
stakeholders, contributing to more effective coordination in addressing
existential risks from advanced AI.

\section{Notebook Structure and
Workflow}\label{notebook-structure-and-workflow}

This notebook implements a multi-stage pipeline for transforming
argument structures into interactive Bayesian network visualizations:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{-1}
\item
  \textbf{Environment Setup} (Sections 0.1-0.3): Establishes the
  technical environment with necessary libraries and data connections
\item
  \textbf{Argument Extraction: Sources to ArgDown} (Sections 1.0-1.8):
  Processes source documents into structured ArgDown representations
\item
  \textbf{Probability Integration} (Sections 2.0-2.8): Enhances ArgDown
  with probability information to create BayesDown
\item
  \textbf{Data Transformation} (Section 3.0): Converts BayesDown into
  structured DataFrame format
\item
  \textbf{Visualization and Analysis} (Section 4.0): Creates interactive
  Bayesian network visualizations
\item
  \textbf{Archiving and Export} (Sections 5.0-6.0): Provides utilities
  for saving and sharing results
\end{enumerate}

\section{Instructions --- How to use this
notebook:}\label{instructions-how-to-use-this-notebook}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Import Libraries \& Install Packages}: Run Section 0.1 to set
  up the necessary dependencies for data processing and visualization.
\item
  \textbf{Connect to GitHub Repository \& Load Data files}: Run Section
  0.2 to establish connections to the data repository and load example
  datasets. This step retrieves sample ArgDown files and extracted data
  for demonstration.
\item
  \textbf{Process Source Documents to ArgDown}: Sections 1.0-1.8
  demonstrate the extraction of argument structures from source
  documents (such as PDFs) into ArgDown format, a markdown-like notation
  for structured arguments.
\item
  \textbf{Convert ArgDown to BayesDown}: Sections 2.0-2.3 handle the
  transformation of ArgDown files into BayesDown format, which
  incorporates probabilistic information into the argument structure.
\item
  \textbf{Extract Data into Structured Format}: Section 3.0 processes
  BayesDown format into structured database entries (CSV) that can be
  used for analysis.
\item
  \textbf{Create and Analyze Bayesian Networks}: Section 4.0
  demonstrates how to build Bayesian networks from the extracted data
  and provides tools for analyzing risk pathways.
\item
  \textbf{Save and Export Results}: Sections 5.0-6.0 provide methods for
  archiving results and exporting visualizations.
\end{enumerate}

\begin{quote}
\hyperref[scrollTo=lt8-AnebGUXrux26uniqifier=1]{AMTAIR Prototype
Demonstration (Public Colab Notebook)}
\end{quote}

\begin{quote}
\hyperref[scrollTo=iDy_leH6DJH_ux26uniqifier=1]{AMTAIR Prototype:
Automating Transformative AI Risk Modeling}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=iDy_leH6DJH_ux26uniqifier=1]{Executive Summary}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\hyperref[scrollTo=iDy_leH6DJH_ux26uniqifier=1]{Purpose Within the
Master's Thesis}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\hyperref[scrollTo=iDy_leH6DJH_ux26uniqifier=1]{Relevance to AI
Governance}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=iDy_leH6DJH_ux26uniqifier=1]{Notebook Structure and
Workflow}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=22NBzTxxsnfQux26uniqifier=1]{Instructions --- How to
use this notebook:}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=NovjnOw6bzLiux26uniqifier=1]{Key Concepts:}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=NovjnOw6bzLiux26uniqifier=1]{Example Workflow:}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=NovjnOw6bzLiux26uniqifier=1]{Troubleshooting:}
\end{quote}
\end{quote}

\begin{quote}
\hyperref[scrollTo=GTuYkXbCrZ2Oux26uniqifier=1]{0 Environment Setup and
Data Access}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=GtVFO-s74vI_ux26uniqifier=1]{0.1 Prepare Colab/Python
Environment --- Import Libraries \& Packages}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=2a3VR0fLhJowux26uniqifier=1]{0.2 Connect to GitHub
Repository}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=y-ix4Rp5fE9mux26uniqifier=1]{0.3 File Import}
\end{quote}
\end{quote}

\begin{quote}
\hyperref[scrollTo=52XyPlte5HrUux26uniqifier=1]{1 Sources (PDF's of
Papers) to ArgDown (.md file)}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=1-7O4KHfNU-eux26uniqifier=1]{1.0 Sources to ArgDown:
Structured Argument Extraction}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\hyperref[scrollTo=1-7O4KHfNU-eux26uniqifier=1]{Process Overview}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\hyperref[scrollTo=1-7O4KHfNU-eux26uniqifier=1]{What is ArgDown?}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=ESKnZ_4f_a6yux26uniqifier=1]{1.1 Specify Source
Document (e.g.~PDF)}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=6ToQFra3_nl9ux26uniqifier=1]{1.2 Generate ArgDown
Extraction Prompt}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=pGv2KcZU_9Bnux26uniqifier=1]{1.3 Prepare LLM API
Call}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=i5xsDYnsAWC4ux26uniqifier=1]{1.4 Make ArgDown
Extraction LLM API Call}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=Lc2nMp8nAfeUux26uniqifier=1]{1.5 Save ArgDown
Extraction Response}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=5HcCfqE4A0htux26uniqifier=1]{1.6 Review and Check
ArgDown.md File}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\hyperref[scrollTo=gSpkvLbCC_PIux26uniqifier=1]{1.6.0 Check the Graph
Structure with the ArgDown Sandbox Online}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=MAm0UKpeBvyrux26uniqifier=1]{1.7 Extract ArgDown
Graph Information as DataFrame}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=iFC6oiyICREnux26uniqifier=1]{1.8 Store ArgDown
Information as `ArgDown.csv' file}
\end{quote}
\end{quote}

\begin{quote}
\hyperref[scrollTo=7SGB0XMp5VFqux26uniqifier=1]{2 Probability
Extractions: ArgDown (.csv) to BayesDown (.md + plugin JSON syntax)}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=hWkmySZYNtzSux26uniqifier=1]{2.0 ArgDown to
BayesDown: Adding Probability Information}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\hyperref[scrollTo=hWkmySZYNtzSux26uniqifier=1]{Process Overview}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\hyperref[scrollTo=hWkmySZYNtzSux26uniqifier=1]{What is BayesDown?}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=WcF2nHXBZru4ux26uniqifier=1]{2.1 Probability
Extraction Questions --- `ArgDown.csv' to `ArgDown\_WithQuestions.csv'}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=-q9UOQ8yaBZnux26uniqifier=1]{2.2
`ArgDown\_WithQuestions.csv' to `BayesDownQuestions.md'}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=Ux4OUCPue6Buux26uniqifier=1]{2.3 Generate BayesDown
Probability Extraction Prompt}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\hyperref[scrollTo=ivcnd2ml41Nvux26uniqifier=1]{2.3.0 BayesDown Format
Specification}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\begin{quote}
\hyperref[scrollTo=ivcnd2ml41Nvux26uniqifier=1]{Core Structure}
\end{quote}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\hyperref[scrollTo=Fn72WmgVEOH0ux26uniqifier=1]{2.3.1
Rain-Sprinkler-Lawn Example}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=d4tB9WD-fIWZux26uniqifier=1]{2.4 Prepare 2nd API
call}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=oPWto83lfN9Qux26uniqifier=1]{2.5 Make BayesDown
Probability Extraction API Call}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=L8NWpz8MfZ9_ux26uniqifier=1]{2.6 Save BayesDown with
Probability Estimates (.csv)}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=Q3PTtYgRfsLaux26uniqifier=1]{2.7 Review \& Verify
BayesDown Probability Estimates}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=VwoAgBsafonhux26uniqifier=1]{2.7.2 Check the Graph
Structure with the ArgDown Sandbox Online}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=19KDn2mKf309ux26uniqifier=1]{2.8 Extract BayesDown
with Probability Estimates as Dataframe}
\end{quote}
\end{quote}

\begin{quote}
\hyperref[scrollTo=Dh4ZEaAnxzIJux26uniqifier=1]{3 Data Extraction:
BayesDown (.md) to Database (.csv)}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=vUSS00TCEpeWux26uniqifier=1]{3.0 BayesDown to
Structured Data: Network Construction}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=vUSS00TCEpeWux26uniqifier=1]{Extraction Pipeline
Overview}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\hyperref[scrollTo=vUSS00TCEpeWux26uniqifier=1]{Theoretical Foundation}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\hyperref[scrollTo=vUSS00TCEpeWux26uniqifier=1]{Role in Thesis Research}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\hyperref[scrollTo=AFnu_1Ludahiux26uniqifier=1]{3.0.0
ExtractBayesDown-Data\_v1}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\hyperref[scrollTo=eUBJh8Qp4yd4ux26uniqifier=1]{3.0.1 Test BayesDown
Extraction}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\hyperref[scrollTo=z4Hgs0ICDQyWux26uniqifier=1]{3.0.2 Check the Graph
Structure with the ArgDown Sandbox Online}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=mv8f4c4D3yJjux26uniqifier=1]{3.1 Extraction}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=UcXf3fZ8dahjux26uniqifier=1]{3.2
Data-Post-Processing}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=xTwPO_J-dahjux26uniqifier=1]{3.4 Download and save
finished data frame as .csv file}
\end{quote}
\end{quote}

\begin{quote}
\hyperref[scrollTo=nLPEqZI7zSG4ux26uniqifier=1]{4 Analysis \& Inference:
Bayesian Network Visualization}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=t3zl7vKMECMgux26uniqifier=1]{4.0 Bayesian Network
Visualization Approach}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\hyperref[scrollTo=t3zl7vKMECMgux26uniqifier=1]{Visualization
Philosophy}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\hyperref[scrollTo=t3zl7vKMECMgux26uniqifier=1]{Connection to AMTAIR
Goals}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\hyperref[scrollTo=t3zl7vKMECMgux26uniqifier=1]{Implementation
Structure}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=LSeSAPvtgIgUux26uniqifier=1]{4.1 Phase 1:
Dependencies/Functions}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=byAExfek5yFUux26uniqifier=1]{4.2 Phase 2: Node
Classification and Styling Module}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=gnS3jFGU52OZux26uniqifier=1]{4.3 Phase 3: HTML
Content Generation Module}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=d2uyG0Pi571fux26uniqifier=1]{4.4 Phase 4: Main
Visualization Function}
\end{quote}
\end{quote}

\begin{quote}
\hyperref[scrollTo=pLShDqDXbzJxux26uniqifier=1]{5 Quick check HTML
Outputs}
\end{quote}

\begin{quote}
\hyperref[scrollTo=oatKYlKrOSiNux26uniqifier=1]{Conclusion: From
Prototype to Production}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=oatKYlKrOSiNux26uniqifier=1]{Summary of Achievements}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=oatKYlKrOSiNux26uniqifier=1]{Limitations and Future
Work}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=oatKYlKrOSiNux26uniqifier=1]{Connection to AMTAIR
Project}
\end{quote}
\end{quote}

\begin{quote}
\hyperref[scrollTo=kjbIj19epbrFux26uniqifier=1]{6 Save Outputs}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=0QqlN6dYpm4sux26uniqifier=1]{6.0 Saving and Exporting
Results}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=pS6AhdiSCLw4ux26uniqifier=1]{6.1 Convert .ipynb
Notebook to MarkDown}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=SUoQhT_U3AJbux26uniqifier=1]{6.2 Convert Notebook to
Markdown Documentation}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\hyperref[scrollTo=Tpk3z0Ta3ODsux26uniqifier=1]{6.3 Create PDF and
Latex}
\end{quote}
\end{quote}

\section{Key Concepts:}\label{key-concepts}

\begin{itemize}
\tightlist
\item
  \textbf{ArgDown}: A structured format for representing arguments, with
  hierarchical relationships between statements.
\item
  \textbf{BayesDown}: An extension of ArgDown that incorporates
  probabilistic information, allowing for Bayesian network construction.
\item
  \textbf{Extraction Pipeline}: The process of converting unstructured
  text to structured argument representations.
\item
  \textbf{Bayesian Networks}: Probabilistic graphical models that
  represent variables and their conditional dependencies.
\end{itemize}

\section{Example Workflow:}\label{example-workflow}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Load a sample ArgDown file from the repository
\item
  Extract the hierarchical structure and relationships
\item
  Add probabilistic information to create a BayesDown representation
\item
  Generate a Bayesian network visualization
\item
  Analyze conditional probabilities and risk pathways
\end{enumerate}

\section{Troubleshooting:}\label{troubleshooting}

\begin{itemize}
\tightlist
\item
  If connectivity issues occur, ensure you have access to the GitHub
  repository
\item
  For visualization errors, check that all required libraries are
  properly installed
\item
  When processing custom files, ensure they follow the expected format
  conventions
\end{itemize}

\chapter{0 Environment Setup and Data
Access}\label{environment-setup-and-data-access}

This section establishes the technical foundation for the AMTAIR
prototype by: 1. Installing and importing necessary libraries 2. Setting
up access to the GitHub repository 3. Loading example data files

The environment setup is designed to be run once per session, with flags
to prevent redundant installations and imports. This section forms the
basis for the subsequent extraction and analysis steps in the pipeline.

The key goal is to create a reproducible environment where the Bayesian
network extraction and visualization can be performed consistently, with
appropriate error handling and resource management.

\section{0.1 Prepare Colab/Python Environment --- Import Libraries \&
Packages}\label{prepare-colabpython-environment-import-libraries-packages}

\phantomsection\label{install_import_libraries}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 0.1.0 {-}{-}{-} Install \& Import Libraries \& Packages (One{-}Time Setup) {-}{-}{-} [install\_import\_libraries]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE:}
\CommentTok{Establishes the core technical environment for the AMTAIR prototype.}
\CommentTok{Sets up all required libraries for Bayesian network processing, visualization,}
\CommentTok{and data manipulation.}
\CommentTok{Uses a flag{-}based approach to ensure setup only runs once per session,}
\CommentTok{enhancing efficiency.}

\CommentTok{The setup follows a three{-}stage process:}
\CommentTok{1. Install required packages not available in Colab by default}
\CommentTok{2. Import all necessary libraries with error handling}
\CommentTok{3. Set a global flag to prevent redundant execution}

\CommentTok{DEPENDENCIES: Requires internet connection for package installation}
\CommentTok{OUTPUTS: Global variable \_setup\_imports\_done and loaded Python libraries}
\CommentTok{"""}

\CommentTok{\# Check if setup has already been completed in this session using environment flag}
\ControlFlowTok{try}\NormalTok{:}
    \CommentTok{\# If this variable exists, setup was already done successfully}
\NormalTok{    \_setup\_imports\_done}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"✅ Libraries already installed and imported in this session. Skipping setup."}\NormalTok{)}

\ControlFlowTok{except} \PreprocessorTok{NameError}\NormalTok{:}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"⏳ Performing one{-}time library installation and imports..."}\NormalTok{)}

    \CommentTok{\# {-}{-}{-} STAGE 1: Install required packages {-}{-}{-}}
    \CommentTok{\# Install visualization and network analysis libraries}
    \OperatorTok{!}\NormalTok{pip install }\OperatorTok{{-}}\NormalTok{q pyvis  }\CommentTok{\# Network visualization library}
    \OperatorTok{!}\NormalTok{apt}\OperatorTok{{-}}\NormalTok{get install pandoc }\OperatorTok{{-}}\NormalTok{y  }\CommentTok{\# Document conversion utility}

    \CommentTok{\# Install Google API and data processing packages}
    \CommentTok{\# Data manipulation and Google integration}
    \OperatorTok{!}\NormalTok{pip install }\OperatorTok{{-}}\NormalTok{q }\OperatorTok{{-}{-}}\NormalTok{upgrade gspread pandas google}\OperatorTok{{-}}\NormalTok{auth google}\OperatorTok{{-}}\NormalTok{colab}

    \CommentTok{\# Install Bayesian network and probabilistic modeling tools}
    \OperatorTok{!}\NormalTok{pip install }\OperatorTok{{-}}\NormalTok{q pgmpy  }\CommentTok{\# Probabilistic graphical models library}

    \CommentTok{\# Install notebook conversion tools}
    \OperatorTok{!}\NormalTok{pip install }\OperatorTok{{-}}\NormalTok{q nbconvert  }\CommentTok{\# Often pre{-}installed, but ensures availability}

    \BuiltInTok{print}\NormalTok{(}\StringTok{"   {-}{-}\textgreater{} Installations complete."}\NormalTok{)}

    \CommentTok{\# {-}{-}{-} STAGE 2: Import libraries with error handling {-}{-}{-}}
    \ControlFlowTok{try}\NormalTok{:}
        \CommentTok{\# Network and HTTP libraries}
        \ImportTok{import}\NormalTok{ requests      }\CommentTok{\# For making HTTP requests to APIs and GitHub}
        \ImportTok{import}\NormalTok{ io            }\CommentTok{\# For handling in{-}memory file{-}like objects}

        \CommentTok{\# Data processing libraries}
        \ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd  }\CommentTok{\# For structured data manipulation}
        \ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np   }\CommentTok{\# For numerical operations}
        \ImportTok{import}\NormalTok{ json          }\CommentTok{\# For JSON parsing and serialization}
        \ImportTok{import}\NormalTok{ re            }\CommentTok{\# For regular expression pattern matching}

        \CommentTok{\# Visualization libraries}
        \ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt  }\CommentTok{\# For creating plots and charts}
        \ImportTok{from}\NormalTok{ IPython.display }\ImportTok{import}\NormalTok{ HTML, display, Markdown  }\CommentTok{\# For rich output in notebook}

        \CommentTok{\# {-}{-}{-} Specialized libraries requiring installation {-}{-}{-}}
        \CommentTok{\# Network analysis library}
        \ImportTok{import}\NormalTok{ networkx }\ImportTok{as}\NormalTok{ nx  }\CommentTok{\# For graph representation and analysis}

        \CommentTok{\# Probabilistic modeling libraries}
        \ImportTok{from}\NormalTok{ pgmpy.models }\ImportTok{import}\NormalTok{ BayesianNetwork  }\CommentTok{\# For Bayesian network structure}
        \ImportTok{from}\NormalTok{ pgmpy.factors.discrete }\ImportTok{import}\NormalTok{ TabularCPD  }\CommentTok{\# For conditional probability tables}
        \ImportTok{from}\NormalTok{ pgmpy.inference }\ImportTok{import}\NormalTok{ VariableElimination  }\CommentTok{\# For probabilistic inference}

        \CommentTok{\# Interactive network visualization}
        \ImportTok{from}\NormalTok{ pyvis.network }\ImportTok{import}\NormalTok{ Network  }\CommentTok{\# For interactive network visualization}

        \CommentTok{\# Output version information for key libraries}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"      pandas version: }\SpecialCharTok{\{}\NormalTok{pd}\SpecialCharTok{.}\NormalTok{\_\_version\_\_}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"      networkx version: }\SpecialCharTok{\{}\NormalTok{nx}\SpecialCharTok{.}\NormalTok{\_\_version\_\_}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
        \CommentTok{\# Add others if specific versions are critical}

        \BuiltInTok{print}\NormalTok{(}\StringTok{"   {-}{-}\textgreater{} Imports complete."}\NormalTok{)}

        \CommentTok{\# {-}{-}{-} STAGE 3: Set flag to indicate successful setup {-}{-}{-}}
\NormalTok{        \_setup\_imports\_done }\OperatorTok{=} \VariableTok{True}
        \BuiltInTok{print}\NormalTok{(}\StringTok{"✅ One{-}time setup finished successfully."}\NormalTok{)}

    \ControlFlowTok{except} \PreprocessorTok{ImportError} \ImportTok{as}\NormalTok{ e:}
        \CommentTok{\# Handle specific import failures}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"❌ ERROR during import: }\SpecialCharTok{\{}\NormalTok{e}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
        \BuiltInTok{print}\NormalTok{(}\StringTok{"   {-}{-}\textgreater{} Setup did not complete successfully. Please check installations."}\NormalTok{)}
    \ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
        \CommentTok{\# Handle unexpected errors}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"❌ UNEXPECTED ERROR during setup: }\SpecialCharTok{\{}\NormalTok{e}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
        \BuiltInTok{print}\NormalTok{(}\StringTok{"   {-}{-}\textgreater{} Setup did not complete successfully."}\NormalTok{)}

\CommentTok{\# Environment is now ready for AMTAIR processing}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
✅ Libraries already installed and imported in this session. Skipping setup.
\end{verbatim}

\section{0.2 Connect to GitHub
Repository}\label{connect-to-github-repository}

The Public GitHub Repo Url in use:

https://raw.githubusercontent.com/SingularitySmith/AMTAIR\_Prototype/main/

Note: When encountering errors, accessing the data, try using ``RAW''
Urls.

\phantomsection\label{connect_to_github_repository}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 0.2.0 {-}{-}{-} Connect to GitHub Repository {-}{-}{-} Load Files [connect\_to\_github\_repository]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Establishes connection to the AMTAIR GitHub repository and provides}
\CommentTok{functions to load example data files for processing.}

\CommentTok{This block creates a reusable function for accessing files from the project\textquotesingle{}s}
\CommentTok{GitHub repository, enabling access to example files like the rain{-}sprinkler{-}lawn}
\CommentTok{Bayesian network that serves as our canonical test case.}

\CommentTok{DEPENDENCIES: requests library, io library}
\CommentTok{OUTPUTS: load\_file\_from\_repo function and test file loads}
\CommentTok{"""}

\ImportTok{from}\NormalTok{ requests.exceptions }\ImportTok{import}\NormalTok{ HTTPError}

\CommentTok{\# Specify the base repository URL for the AMTAIR project}
\NormalTok{repo\_url }\OperatorTok{=} \StringTok{"https://raw.githubusercontent.com/SingularitySmith/AMTAIR\_Prototype/main/data/example\_carlsmith/"}
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Connecting to repository: }\SpecialCharTok{\{}\NormalTok{repo\_url}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

\KeywordTok{def}\NormalTok{ load\_file\_from\_repo(relative\_path):}
    \CommentTok{"""}
\CommentTok{    Loads a file from the specified GitHub repository using a relative path.}

\CommentTok{    Args:}
\CommentTok{        relative\_path (str): Path to the file relative to the repo\_url}

\CommentTok{    Returns:}
\CommentTok{        For CSV/JSON: pandas DataFrame}
\CommentTok{        For MD: string containing file contents}

\CommentTok{    Raises:}
\CommentTok{        HTTPError: If file not found or other HTTP error occurs}
\CommentTok{        ValueError: If unsupported file type is requested}
\CommentTok{    """}
\NormalTok{    file\_url }\OperatorTok{=}\NormalTok{ repo\_url }\OperatorTok{+}\NormalTok{ relative\_path}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Attempting to load: }\SpecialCharTok{\{}\NormalTok{file\_url}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

    \CommentTok{\# Fetch the file content from GitHub}
\NormalTok{    response }\OperatorTok{=}\NormalTok{ requests.get(file\_url)}

    \CommentTok{\# Check for bad status codes with enhanced error messages}
    \ControlFlowTok{if}\NormalTok{ response.status\_code }\OperatorTok{==} \DecValTok{404}\NormalTok{:}
        \ControlFlowTok{raise}\NormalTok{ HTTPError(}\SpecialStringTok{f"File not found at URL: }\SpecialCharTok{\{}\NormalTok{file\_url}\SpecialCharTok{\}}\SpecialStringTok{. Check the file path/name and ensure the file is publicly accessible."}\NormalTok{, response}\OperatorTok{=}\NormalTok{response)}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        response.raise\_for\_status()  }\CommentTok{\# Raise for other error codes}

    \CommentTok{\# Convert response to file{-}like object}
\NormalTok{    file\_object }\OperatorTok{=}\NormalTok{ io.StringIO(response.text)}

    \CommentTok{\# Process different file types appropriately}
    \ControlFlowTok{if}\NormalTok{ relative\_path.endswith(}\StringTok{".csv"}\NormalTok{):}
        \ControlFlowTok{return}\NormalTok{ pd.read\_csv(file\_object)  }\CommentTok{\# Return DataFrame for CSV}
    \ControlFlowTok{elif}\NormalTok{ relative\_path.endswith(}\StringTok{".json"}\NormalTok{):}
        \ControlFlowTok{return}\NormalTok{ pd.read\_json(file\_object)  }\CommentTok{\# Return DataFrame for JSON}
    \ControlFlowTok{elif}\NormalTok{ relative\_path.endswith(}\StringTok{".md"}\NormalTok{):}
        \ControlFlowTok{return}\NormalTok{ file\_object.read()  }\CommentTok{\# Return raw content for MD files}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{(}\SpecialStringTok{f"Unsupported file type: }\SpecialCharTok{\{}\NormalTok{relative\_path}\SpecialCharTok{.}\NormalTok{split(}\StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{)[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{. Add support in the GitHub Connection section of this notebook."}\NormalTok{)}

\CommentTok{\# Load example files to test connection}
\ControlFlowTok{try}\NormalTok{:}
    \CommentTok{\# Load the extracted data CSV file}
\CommentTok{\#    df = load\_file\_from\_repo("extracted\_data.csv")}

    \CommentTok{\# Load the ArgDown test text}
\NormalTok{    md\_content }\OperatorTok{=}\NormalTok{ load\_file\_from\_repo(}\StringTok{"ArgDown.md"}\NormalTok{)}

    \BuiltInTok{print}\NormalTok{(}\StringTok{"✅ Successfully connected to repository and loaded test files."}\NormalTok{)}
\ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"❌ Error loading files: }\SpecialCharTok{\{}\BuiltInTok{str}\NormalTok{(e)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Please check your internet connection and the repository URL."}\NormalTok{)}

\CommentTok{\# Display preview of loaded content (commented out to avoid cluttering output)}
\BuiltInTok{print}\NormalTok{(md\_content)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Connecting to repository: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/
Attempting to load: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/ArgDown.md
✅ Successfully connected to repository and loaded test files.
[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {"instantiations": ["existential_catastrophe_TRUE", "existential_catastrophe_FALSE"]}
- [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {"instantiations": ["human_disempowerment_TRUE", "human_disempowerment_FALSE"]}
    - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {"instantiations": ["scale_of_power_seeking_TRUE", "scale_of_power_seeking_FALSE"]}
        - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}
            - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {"instantiations": ["aps_systems_TRUE", "aps_systems_FALSE"]}
                - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {"instantiations": ["advanced_ai_capability_TRUE", "advanced_ai_capability_FALSE"]}
                - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {"instantiations": ["agentic_planning_TRUE", "agentic_planning_FALSE"]}
                - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {"instantiations": ["strategic_awareness_TRUE", "strategic_awareness_FALSE"]}
            - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {"instantiations": ["difficulty_of_alignment_TRUE", "difficulty_of_alignment_FALSE"]}
                - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {"instantiations": ["instrumental_convergence_TRUE", "instrumental_convergence_FALSE"]}
                - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {"instantiations": ["problems_with_proxies_TRUE", "problems_with_proxies_FALSE"]}
                - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {"instantiations": ["problems_with_search_TRUE", "problems_with_search_FALSE"]}
            - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {"instantiations": ["deployment_decisions_DEPLOY", "deployment_decisions_WITHHOLD"]}
                - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {"instantiations": ["incentives_to_build_aps_STRONG", "incentives_to_build_aps_WEAK"]}
                    - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {"instantiations": ["usefulness_of_aps_HIGH", "usefulness_of_aps_LOW"]}
                    - [Competitive_Dynamics]: Competitive pressures between AI developers. {"instantiations": ["competitive_dynamics_STRONG", "competitive_dynamics_WEAK"]}
                - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {"instantiations": ["deception_by_ai_TRUE", "deception_by_ai_FALSE"]}
        - [Corrective_Feedback]: Human society implementing corrections after observing problems. {"instantiations": ["corrective_feedback_EFFECTIVE", "corrective_feedback_INEFFECTIVE"]}
            - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {"instantiations": ["warning_shots_OBSERVED", "warning_shots_UNOBSERVED"]}
            - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {"instantiations": ["rapid_capability_escalation_TRUE", "rapid_capability_escalation_FALSE"]}
[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {"instantiations": ["barriers_to_understanding_HIGH", "barriers_to_understanding_LOW"]}
- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}
[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {"instantiations": ["adversarial_dynamics_TRUE", "adversarial_dynamics_FALSE"]}
- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}
[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {"instantiations": ["stakes_of_error_HIGH", "stakes_of_error_LOW"]}
- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}
\end{verbatim}

\section{0.3 File Import}\label{file-import}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title}
\NormalTok{md\_content}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'[Existential_Catastrophe]: The destruction of humanity\'s long-term potential due to AI systems we\'ve lost control over. {"instantiations": ["existential_catastrophe_TRUE", "existential_catastrophe_FALSE"]}\n- [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {"instantiations": ["human_disempowerment_TRUE", "human_disempowerment_FALSE"]}\n    - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {"instantiations": ["scale_of_power_seeking_TRUE", "scale_of_power_seeking_FALSE"]}\n        - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}\n            - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {"instantiations": ["aps_systems_TRUE", "aps_systems_FALSE"]}\n                - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {"instantiations": ["advanced_ai_capability_TRUE", "advanced_ai_capability_FALSE"]}\n                - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {"instantiations": ["agentic_planning_TRUE", "agentic_planning_FALSE"]}\n                - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {"instantiations": ["strategic_awareness_TRUE", "strategic_awareness_FALSE"]}\n            - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {"instantiations": ["difficulty_of_alignment_TRUE", "difficulty_of_alignment_FALSE"]}\n                - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {"instantiations": ["instrumental_convergence_TRUE", "instrumental_convergence_FALSE"]}\n                - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {"instantiations": ["problems_with_proxies_TRUE", "problems_with_proxies_FALSE"]}\n                - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {"instantiations": ["problems_with_search_TRUE", "problems_with_search_FALSE"]}\n            - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {"instantiations": ["deployment_decisions_DEPLOY", "deployment_decisions_WITHHOLD"]}\n                - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {"instantiations": ["incentives_to_build_aps_STRONG", "incentives_to_build_aps_WEAK"]}\n                    - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {"instantiations": ["usefulness_of_aps_HIGH", "usefulness_of_aps_LOW"]}\n                    - [Competitive_Dynamics]: Competitive pressures between AI developers. {"instantiations": ["competitive_dynamics_STRONG", "competitive_dynamics_WEAK"]}\n                - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {"instantiations": ["deception_by_ai_TRUE", "deception_by_ai_FALSE"]}\n        - [Corrective_Feedback]: Human society implementing corrections after observing problems. {"instantiations": ["corrective_feedback_EFFECTIVE", "corrective_feedback_INEFFECTIVE"]}\n            - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {"instantiations": ["warning_shots_OBSERVED", "warning_shots_UNOBSERVED"]}\n            - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {"instantiations": ["rapid_capability_escalation_TRUE", "rapid_capability_escalation_FALSE"]}\n[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {"instantiations": ["barriers_to_understanding_HIGH", "barriers_to_understanding_LOW"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}\n[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {"instantiations": ["adversarial_dynamics_TRUE", "adversarial_dynamics_FALSE"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}\n[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {"instantiations": ["stakes_of_error_HIGH", "stakes_of_error_LOW"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}\n'
\end{verbatim}

\chapter{1 Argument Extraction: Sources (PDF's of Papers) to ArgDown
(.md
file)}\label{argument-extraction-sources-pdfs-of-papers-to-argdown-.md-file}

\section{1.0 Sources to ArgDown: Structured Argument
Extraction}\label{sources-to-argdown-structured-argument-extraction}

\subsection{Process Overview}\label{process-overview}

This section implements the first major stage of the AMTAIR pipeline:
transforming source documents (such as research papers, blog posts, or
expert analyses) into structured argument representations using the
ArgDown format.

ArgDown is a markdown-like notation for representing arguments in a
hierarchical structure. In the context of AMTAIR, it serves as the first
step toward creating formal Bayesian networks by: 1. Identifying key
variables/statements in the text 2. Capturing their hierarchical
relationships 3. Preserving their descriptive content 4. Defining their
possible states (instantiations)

The extraction process uses Large Language Models (LLMs) to identify the
structure and relationships in the text, though in this notebook we
focus on processing pre-formatted examples rather than performing the
full extraction from raw text.

\subsection{What is ArgDown?}\label{what-is-argdown}

ArgDown uses a simple syntax where: - Statements are represented as
\texttt{{[}Statement{]}:\ Description} - Relationships are indicated
with \texttt{+} symbols and indentation - Metadata is added in JSON
format, including possible states of each variable

For example:

\begin{verbatim}
[MainClaim]: Description of the main claim. {"instantiations": ["claim_TRUE", "claim_FALSE"]}

 + [SupportingEvidence]: Description of evidence. {"instantiations": ["evidence_TRUE", "evidence_FALSE"]}
\end{verbatim}

This structure will later be enhanced with probability information to
create BayesDown, which can be transformed into a Bayesian network for
analysis and visualization.

\section{1.1 Specify Source Document
(e.g.~PDF)}\label{specify-source-document-e.g.-pdf}

Review the source document, ensure it is suitable for API call and
upload to / store it in the correct location.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 1.1.0 {-}{-}{-} MTAIR Online Model (Analytica) {-}{-}{-} [online\_model]}

\ImportTok{from}\NormalTok{ IPython.display }\ImportTok{import}\NormalTok{ IFrame}

\NormalTok{IFrame(src}\OperatorTok{=}\StringTok{"https://acp.analytica.com/view0?invite=4560\&code=3000289064591444815"}\NormalTok{, width}\OperatorTok{=}\StringTok{"100\%"}\NormalTok{, height}\OperatorTok{=}\StringTok{"900px"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\phantomsection\label{online_model}
\begin{verbatim}
<IPython.lib.display.IFrame at 0x7b9cc9929f50>
\end{verbatim}

MTAIR Online Model (Analytica)

\section{1.2 Generate ArgDown Extraction
Prompt}\label{generate-argdown-extraction-prompt}

Generate Extraction Prompt

\phantomsection\label{prompt_template_function}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 1.2.0 {-}{-}{-} Prompt Template Function Definitions {-}{-}{-} [prompt\_template\_function]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Defines a flexible template system for LLM prompts used in the extraction pipeline.}

\CommentTok{This block implements two key classes:}
\CommentTok{1. PromptTemplate: A template class supporting variable substitution for dynamic prompts}
\CommentTok{2. PromptLibrary: A collection of pre{-}defined prompt templates for different extraction tasks}

\CommentTok{These templates are used in the ArgDown and BayesDown probability extraction}
\CommentTok{stages of the pipeline, providing consistent and well{-}structured prompts to the LLMs.}

\CommentTok{DEPENDENCIES: string.Template for variable substitution}
\CommentTok{OUTPUTS: PromptTemplate and PromptLibrary classes}
\CommentTok{"""}

\ImportTok{from}\NormalTok{ string }\ImportTok{import}\NormalTok{ Template}
\ImportTok{from}\NormalTok{ typing }\ImportTok{import}\NormalTok{ Dict, Optional, Union, List}

\KeywordTok{class}\NormalTok{ PromptTemplate:}
    \CommentTok{"""Template system for LLM prompts with variable substitution"""}

    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, template: }\BuiltInTok{str}\NormalTok{):}
        \CommentTok{"""Initialize with template string using $variable format"""}
        \VariableTok{self}\NormalTok{.template }\OperatorTok{=}\NormalTok{ Template(template)}

    \KeywordTok{def} \BuiltInTok{format}\NormalTok{(}\VariableTok{self}\NormalTok{, }\OperatorTok{**}\NormalTok{kwargs) }\OperatorTok{{-}\textgreater{}} \BuiltInTok{str}\NormalTok{:}
        \CommentTok{"""Substitute variables in the template"""}
        \ControlFlowTok{return} \VariableTok{self}\NormalTok{.template.safe\_substitute(}\OperatorTok{**}\NormalTok{kwargs)}

    \AttributeTok{@classmethod}
    \KeywordTok{def}\NormalTok{ from\_file(cls, filepath: }\BuiltInTok{str}\NormalTok{) }\OperatorTok{{-}\textgreater{}} \StringTok{\textquotesingle{}PromptTemplate\textquotesingle{}}\NormalTok{:}
        \CommentTok{"""Load template from a file"""}
        \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(filepath, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{            template }\OperatorTok{=}\NormalTok{ f.read()}
        \ControlFlowTok{return}\NormalTok{ cls(template)}

\KeywordTok{class}\NormalTok{ PromptLibrary:}
    \CommentTok{"""Collection of prompt templates for different extraction tasks"""}

    \CommentTok{\# ArgDown extraction prompt {-} transforms source text into structured argument map}
\NormalTok{    ARGDOWN\_EXTRACTION }\OperatorTok{=}\NormalTok{ PromptTemplate(}\StringTok{"""}
\StringTok{You are participating in the AMTAIR (Automating Transformative AI Risk Modeling)}
\StringTok{project and you are tasked with converting natural language arguments into}
\StringTok{ArgDown syntax by extracting and formalizing causal world models from}
\StringTok{unstructured text.}
\StringTok{Your specific task is to extract the implicit causal model from the provided}
\StringTok{document in structured ArgDown format.}

\StringTok{\#\# Epistemic Foundation \& Purpose}

\StringTok{This extraction represents one possible interpretation of the implicit causal}
\StringTok{model in the document. Multiple extractions from the same text help reveal}
\StringTok{patterns of convergence (where the model is clearly articulated) and}
\StringTok{divergence (where the model contains ambiguities). This approach acknowledges}
\StringTok{that expert texts often contain implicit rather than explicit causal models.}

\StringTok{Your role is to reveal the causal structure already present in the author\textquotesingle{}s}
\StringTok{thinking, maintaining epistemic humility about your interpretation while}
\StringTok{adhering strictly to the required format.}

\StringTok{\#\# ArgDown Format Specification}

\StringTok{\#\#\# Core Syntax}

\StringTok{ArgDown represents causal relationships using a hierarchical structure:}

\StringTok{1. Variables appear in square brackets with descriptive text:}
\StringTok{   \textasciigrave{}[Variable\_Name]: Description of the variable.\textasciigrave{}}

\StringTok{2. Causal relationships use indentation (2 spaces per level) and \textquotesingle{}+\textquotesingle{} symbols:}

\StringTok{[Effect]: Description of effect. + [Cause]: Description of cause. + [Deeper\_Cause]: Description of deeper cause.}

\StringTok{3. Causality flows from bottom (more indented) to top (less indented):}
\StringTok{{-} More indented variables (causes) influence less indented variables (effects)}
\StringTok{{-} The top{-}level variable is the ultimate effect or outcome}
\StringTok{{-} Deeper indentation levels represent root causes or earlier factors}

\StringTok{4. Each variable must include JSON metadata with possible states (instantiations):}
\StringTok{\textasciigrave{}[Variable]: Description. \{"instantiations": ["variable\_STATE1", "variable\_STATE2"]\}\textasciigrave{}}

\StringTok{\#\#\# JSON Metadata Format}

\StringTok{The JSON metadata must follow this exact structure:}

\StringTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}json}
\StringTok{\{"instantiations": ["variable\_STATE1", "variable\_STATE2"]\}}

\StringTok{Requirements:}
\StringTok{* Double quotes (not single) around field names and string values}
\StringTok{* Square brackets enclosing the instantiations array}
\StringTok{* Comma separation between array elements}
\StringTok{* No trailing comma after the last element}
\StringTok{* Must be valid JSON syntax that can be parsed by standard JSON parsers}

\StringTok{For binary variables (most common case):}
\StringTok{\{"instantiations": ["variable\_TRUE", "variable\_FALSE"]\}}

\StringTok{For multi{-}state variables (when clearly specified in the text):}
\StringTok{\{"instantiations": ["variable\_HIGH", "variable\_MEDIUM", "variable\_LOW"]\}}

\StringTok{The metadata must appear on the same line as the variable definition, after the description.}
\StringTok{\#\# Complex Structural Patterns}
\StringTok{\#\#\# Variables Influencing Multiple Effects}
\StringTok{The same variable can appear multiple times in different places in the hierarchy if it influences multiple effects:}
\StringTok{[Effect1]: First effect description. \{"instantiations": ["effect1\_TRUE", "effect1\_FALSE"]\}}
\StringTok{  + [Cause\_A]: Description of cause A. \{"instantiations": ["cause\_a\_TRUE", "cause\_a\_FALSE"]\}}

\StringTok{[Effect2]: Second effect description. \{"instantiations": ["effect2\_TRUE", "effect2\_FALSE"]\}}
\StringTok{  + [Cause\_A]}
\StringTok{  + [Cause\_B]: Description of cause B. \{"instantiations": ["cause\_b\_TRUE", "cause\_b\_FALSE"]\}}

\StringTok{\#\#\# Multiple Causes of the Same Effect}
\StringTok{Multiple causes can influence the same effect by being listed at the same indentation level:}
\StringTok{[Effect]: Description of effect. \{"instantiations": ["effect\_TRUE", "effect\_FALSE"]\}}
\StringTok{  + [Cause1]: Description of first cause. \{"instantiations": ["cause1\_TRUE", "cause1\_FALSE"]\}}
\StringTok{  + [Cause2]: Description of second cause. \{"instantiations": ["cause2\_TRUE", "cause2\_FALSE"]\}}
\StringTok{    + [Deeper\_Cause]: A cause that influences Cause2. \{"instantiations": ["deeper\_cause\_TRUE", "deeper\_cause\_FALSE"]\}}

\StringTok{\#\#\# Causal Chains}
\StringTok{Causal chains are represented through multiple levels of indentation:}
\StringTok{[Ultimate\_Effect]: The final outcome. \{"instantiations": ["ultimate\_effect\_TRUE", "ultimate\_effect\_FALSE"]\}}
\StringTok{  + [Intermediate\_Effect]: A mediating variable. \{"instantiations": ["intermediate\_effect\_TRUE", "intermediate\_effect\_FALSE"]\}}
\StringTok{    + [Root\_Cause]: The initial cause. \{"instantiations": ["root\_cause\_TRUE", "root\_cause\_FALSE"]\}}
\StringTok{  + [2nd\_Intermediate\_Effect]: A mediating variable. \{"instantiations": ["intermediate\_effect\_TRUE", "intermediate\_effect\_FALSE"]\}}


\StringTok{\#\#\# Common Cause of Multiple Variables}
\StringTok{A common cause affecting multiple variables is represented by referencing the same variable in multiple places:}
\StringTok{[Effect1]: First effect description. \{"instantiations": ["effect1\_TRUE", "effect1\_FALSE"]\}}
\StringTok{  + [Common\_Cause]: Description of common cause. \{"instantiations": ["common\_cause\_TRUE", "common\_cause\_FALSE"]\}}

\StringTok{[Effect2]: Second effect description. \{"instantiations": ["effect2\_TRUE", "effect2\_FALSE"]\}}
\StringTok{  + [Common\_Cause]}

\StringTok{\#\# Detailed Extraction Workflow}
\StringTok{Please follow this step{-}by{-}step process, documenting your reasoning in XML tags:}
\StringTok{\textless{}analysis\textgreater{}}
\StringTok{First, conduct a holistic analysis of the document:}
\StringTok{1. Identify the main subject matter or domain}
\StringTok{2. Note key concepts, variables, and factors discussed}
\StringTok{3. Pay attention to language indicating causal relationships (causes, affects, influences, depends on, etc.)}
\StringTok{4. Look for the ultimate outcomes or effects that are the focus of the document}
\StringTok{5. Record your general understanding of the document\textquotesingle{}s implicit causal structure}
\StringTok{\textless{}/analysis\textgreater{}}
\StringTok{\textless{}variable\_identification\textgreater{}}
\StringTok{Next, identify and list the key variables in the causal model:}
\StringTok{* Focus on factors that are discussed as having an influence or being influenced}
\StringTok{* For each variable:}
\StringTok{  * Create a descriptive name in [square\_brackets]}
\StringTok{  * Write a concise description based directly on the text}
\StringTok{  * Determine possible states (usually binary TRUE/FALSE unless clearly specified)}
\StringTok{* Distinguish between:}
\StringTok{  * Outcome variables (effects the author is concerned with)}
\StringTok{  * Intermediate variables (both causes and effects in chains)}
\StringTok{  * Root cause variables (exogenous factors in the model)}
\StringTok{* List all identified variables with their descriptions and possible states}
\StringTok{\textless{}/variable\_identification\textgreater{}}

\StringTok{\textless{}causal\_structure\textgreater{}}
\StringTok{Then, determine the causal relationships between variables:}
\StringTok{* For each variable, identify what factors influence it}
\StringTok{* Note the direction of causality (what causes what)}
\StringTok{* Look for mediating variables in causal chains}
\StringTok{* Identify common causes of multiple effects}
\StringTok{* Capture feedback loops if present (though they must be represented as DAGs)}
\StringTok{* Map out the hierarchical structure of the causal model}
\StringTok{\textless{}/causal\_structure\textgreater{}}

\StringTok{\textless{}format\_conversion\textgreater{}}
\StringTok{Now, convert your analysis into proper ArgDown format:}
\StringTok{* Start with the ultimate outcome variables at the top level}
\StringTok{* Place direct causes indented below with }\ErrorTok{\textbackslash{}}\StringTok{+ symbols}
\StringTok{* Continue with deeper causes at further indentation levels}
\StringTok{* Add variable descriptions and instantiations metadata}
\StringTok{* Ensure variables appearing in multiple places have consistent names}
\StringTok{* Check that the entire structure forms a valid directed acyclic graph}
\StringTok{\textless{}/format\_conversion\textgreater{}}

\StringTok{\textless{}validation\textgreater{}}

\StringTok{Finally, review your extraction for quality and format correctness:}
\StringTok{1. Verify all variables have properly formatted metadata}
\StringTok{2. Check that indentation properly represents causal direction}
\StringTok{3. Confirm the extraction accurately reflects the document\textquotesingle{}s implicit model}
\StringTok{4. Ensure no cycles exist in the causal structure}
\StringTok{5. Verify that variables referenced multiple times are consistent}
\StringTok{6. Check that the extraction would be useful for subsequent analysis}

\StringTok{\textless{}/validation\textgreater{}}


\StringTok{\#\# Source Document Analysis Guidance}
\StringTok{When analyzing the source document:}
\StringTok{* Focus on revealing the author\textquotesingle{}s own causal model, not imposing an external framework}
\StringTok{* Maintain the author\textquotesingle{}s terminology where possible}
\StringTok{* Look for both explicit statements of causality and implicit assumptions}
\StringTok{* Pay attention to the relative importance the author assigns to different factors}
\StringTok{* Notice where the author expresses certainty versus uncertainty}
\StringTok{* Consider the level of granularity appropriate to the document\textquotesingle{}s own analysis}

\StringTok{Remember that your goal is to make the implicit model explicit, not to evaluate or improve it.}
\StringTok{The value lies in accurately representing the author\textquotesingle{}s perspective, even if you might personally disagree or see limitations in their model.}

\StringTok{"""}\NormalTok{)}

    \CommentTok{\# BayesDown probability extraction prompt {-} enhances ArgDown with probability information}
\NormalTok{    BAYESDOWN\_EXTRACTION }\OperatorTok{=}\NormalTok{ PromptTemplate(}\StringTok{"""}
\StringTok{You are an expert in probabilistic reasoning and Bayesian networks. Your task is}
\StringTok{to extend the provided ArgDown structure with probability information,}
\StringTok{creating a BayesDown representation.}

\StringTok{For each statement in the ArgDown structure, you need to:}
\StringTok{1. Estimate prior probabilities for each possible state}
\StringTok{2. Estimate conditional probabilities given parent states}
\StringTok{3. Maintain the original structure and relationships}

\StringTok{Here is the format to follow:}
\StringTok{[Node]: Description. \{ "instantiations": ["node\_TRUE", "node\_FALSE"], "priors": \{ "p(node\_TRUE)": "0.7", "p(node\_FALSE)": "0.3" \}, "posteriors": \{ "p(node\_TRUE|parent\_TRUE)": "0.9", "p(node\_TRUE|parent\_FALSE)": "0.4", "p(node\_FALSE|parent\_TRUE)": "0.1", "p(node\_FALSE|parent\_FALSE)": "0.6" \} \}}
\StringTok{ [Parent]: Parent description. \{...\}}


\StringTok{Here are the specific probability questions to answer:}
\StringTok{$questions}

\StringTok{ArgDown structure to enhance:}
\StringTok{$argdown}

\StringTok{Provide the complete BayesDown representation with probabilities:}
\StringTok{"""}\NormalTok{)}

    \AttributeTok{@classmethod}
    \KeywordTok{def}\NormalTok{ get\_template(cls, template\_name: }\BuiltInTok{str}\NormalTok{) }\OperatorTok{{-}\textgreater{}}\NormalTok{ PromptTemplate:}
        \CommentTok{"""Get a prompt template by name"""}
        \ControlFlowTok{if} \BuiltInTok{hasattr}\NormalTok{(cls, template\_name):}
            \ControlFlowTok{return} \BuiltInTok{getattr}\NormalTok{(cls, template\_name)}
        \ControlFlowTok{else}\NormalTok{:}
            \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{(}\SpecialStringTok{f"Template not found: }\SpecialCharTok{\{}\NormalTok{template\_name}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{1.3 Prepare LLM API Call}\label{prepare-llm-api-call}

Combine Systemprompt + API Specifications + ArgDown Instructions +
Prompt + Source PDF for API Call

\phantomsection\label{provider_agnostic-interface}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 1.3.0 {-}{-}{-} Provider{-}Agnostic LLM API Interface {-}{-}{-} [provider\_agnostic{-}interface]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Provides a unified interface for interacting with different LLM providers.}

\CommentTok{This block implements a flexible, provider{-}agnostic system for making LLM API calls:}
\CommentTok{1. Base abstract class (LLMProvider) defining the common interface}
\CommentTok{2. Implementation classes for specific providers (OpenAI and Anthropic)}
\CommentTok{3. Factory class for creating appropriate provider instances}

\CommentTok{This abstraction allows the extraction pipeline to work with different LLM providers}
\CommentTok{without changing the core code, supporting both current and future LLM backends.}

\CommentTok{DEPENDENCIES: requests for API calls, os for environment variables, abstract base classes}
\CommentTok{OUTPUTS: LLMProvider abstract class and concrete implementations for OpenAI and Anthropic}
\CommentTok{"""}

\ImportTok{import}\NormalTok{ os}
\ImportTok{import}\NormalTok{ json}
\ImportTok{import}\NormalTok{ time}
\ImportTok{import}\NormalTok{ requests}
\ImportTok{from}\NormalTok{ abc }\ImportTok{import}\NormalTok{ ABC, abstractmethod}
\ImportTok{from}\NormalTok{ typing }\ImportTok{import}\NormalTok{ Dict, List, Optional, Union, Any}
\ImportTok{from}\NormalTok{ dataclasses }\ImportTok{import}\NormalTok{ dataclass}

\AttributeTok{@dataclass}
\KeywordTok{class}\NormalTok{ LLMResponse:}
    \CommentTok{"""Standard response object for LLM completions"""}
\NormalTok{    content: }\BuiltInTok{str}            \CommentTok{\# The generated text response}
\NormalTok{    model: }\BuiltInTok{str}              \CommentTok{\# The model used for generation}
\NormalTok{    usage: Dict[}\BuiltInTok{str}\NormalTok{, }\BuiltInTok{int}\NormalTok{]   }\CommentTok{\# Token usage statistics}
\NormalTok{    raw\_response: Dict[}\BuiltInTok{str}\NormalTok{, Any]  }\CommentTok{\# Complete provider{-}specific response}
\NormalTok{    created\_at: }\BuiltInTok{float} \OperatorTok{=}\NormalTok{ time.time()  }\CommentTok{\# Timestamp of response creation}

\KeywordTok{class}\NormalTok{ LLMProvider(ABC):}
    \CommentTok{"""Abstract base class for LLM providers"""}

    \AttributeTok{@abstractmethod}
    \KeywordTok{def}\NormalTok{ complete(}\VariableTok{self}\NormalTok{,}
\NormalTok{                prompt: }\BuiltInTok{str}\NormalTok{,}
\NormalTok{                system\_prompt: Optional[}\BuiltInTok{str}\NormalTok{] }\OperatorTok{=} \VariableTok{None}\NormalTok{,}
\NormalTok{                temperature: }\BuiltInTok{float} \OperatorTok{=} \FloatTok{0.7}\NormalTok{,}
\NormalTok{                max\_tokens: }\BuiltInTok{int} \OperatorTok{=} \DecValTok{4000}\NormalTok{) }\OperatorTok{{-}\textgreater{}}\NormalTok{ LLMResponse:}
        \CommentTok{"""Generate a completion from the LLM"""}
        \ControlFlowTok{pass}

    \AttributeTok{@abstractmethod}
    \KeywordTok{def}\NormalTok{ get\_available\_models(}\VariableTok{self}\NormalTok{) }\OperatorTok{{-}\textgreater{}}\NormalTok{ List[}\BuiltInTok{str}\NormalTok{]:}
        \CommentTok{"""Return a list of available models from this provider"""}
        \ControlFlowTok{pass}

\KeywordTok{class}\NormalTok{ OpenAIProvider(LLMProvider):}
    \CommentTok{"""OpenAI API implementation"""}

    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, api\_key: Optional[}\BuiltInTok{str}\NormalTok{] }\OperatorTok{=} \VariableTok{None}\NormalTok{, organization: Optional[}\BuiltInTok{str}\NormalTok{] }\OperatorTok{=} \VariableTok{None}\NormalTok{):}
        \CommentTok{"""Initialize with API key from args or environment"""}
        \VariableTok{self}\NormalTok{.api\_key }\OperatorTok{=}\NormalTok{ api\_key }\KeywordTok{or}\NormalTok{ os.environ.get(}\StringTok{"OPENAI\_API\_KEY"}\NormalTok{)}
        \ControlFlowTok{if} \KeywordTok{not} \VariableTok{self}\NormalTok{.api\_key:}
            \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{(}\StringTok{"OpenAI API key is required. Provide as argument "}
              \OperatorTok{+} \StringTok{"or set OPENAI\_API\_KEY environment variable."}\NormalTok{)}

        \VariableTok{self}\NormalTok{.organization }\OperatorTok{=}\NormalTok{ organization }\KeywordTok{or}\NormalTok{ os.environ.get(}\StringTok{"OPENAI\_ORGANIZATION"}\NormalTok{)}
        \VariableTok{self}\NormalTok{.api\_base }\OperatorTok{=} \StringTok{"https://api.openai.com/v1"}

    \KeywordTok{def}\NormalTok{ complete(}\VariableTok{self}\NormalTok{,}
\NormalTok{                prompt: }\BuiltInTok{str}\NormalTok{,}
\NormalTok{                system\_prompt: Optional[}\BuiltInTok{str}\NormalTok{] }\OperatorTok{=} \VariableTok{None}\NormalTok{,}
\NormalTok{                model: }\BuiltInTok{str} \OperatorTok{=} \StringTok{"gpt{-}4{-}turbo"}\NormalTok{,}
\NormalTok{                temperature: }\BuiltInTok{float} \OperatorTok{=} \FloatTok{0.7}\NormalTok{,}
\NormalTok{                max\_tokens: }\BuiltInTok{int} \OperatorTok{=} \DecValTok{4000}\NormalTok{) }\OperatorTok{{-}\textgreater{}}\NormalTok{ LLMResponse:}
        \CommentTok{"""Generate a completion using OpenAI\textquotesingle{}s API"""}

        \CommentTok{\# Prepare request headers}
\NormalTok{        headers }\OperatorTok{=}\NormalTok{ \{}
            \StringTok{"Content{-}Type"}\NormalTok{: }\StringTok{"application/json"}\NormalTok{,}
            \StringTok{"Authorization"}\NormalTok{: }\SpecialStringTok{f"Bearer }\SpecialCharTok{\{}\VariableTok{self}\SpecialCharTok{.}\NormalTok{api\_key}\SpecialCharTok{\}}\SpecialStringTok{"}
\NormalTok{        \}}

        \ControlFlowTok{if} \VariableTok{self}\NormalTok{.organization:}
\NormalTok{            headers[}\StringTok{"OpenAI{-}Organization"}\NormalTok{] }\OperatorTok{=} \VariableTok{self}\NormalTok{.organization}

        \CommentTok{\# Create message structure}
\NormalTok{        messages }\OperatorTok{=}\NormalTok{ []}
        \ControlFlowTok{if}\NormalTok{ system\_prompt:}
\NormalTok{            messages.append(\{}\StringTok{"role"}\NormalTok{: }\StringTok{"system"}\NormalTok{, }\StringTok{"content"}\NormalTok{: system\_prompt\})}

\NormalTok{        messages.append(\{}\StringTok{"role"}\NormalTok{: }\StringTok{"user"}\NormalTok{, }\StringTok{"content"}\NormalTok{: prompt\})}

        \CommentTok{\# Prepare request data}
\NormalTok{        data }\OperatorTok{=}\NormalTok{ \{}
            \StringTok{"model"}\NormalTok{: model,}
            \StringTok{"messages"}\NormalTok{: messages,}
            \StringTok{"temperature"}\NormalTok{: temperature,}
            \StringTok{"max\_tokens"}\NormalTok{: max\_tokens}
\NormalTok{        \}}

        \CommentTok{\# Make API call}
\NormalTok{        response }\OperatorTok{=}\NormalTok{ requests.post(}
            \SpecialStringTok{f"}\SpecialCharTok{\{}\VariableTok{self}\SpecialCharTok{.}\NormalTok{api\_base}\SpecialCharTok{\}}\SpecialStringTok{/chat/completions"}\NormalTok{,}
\NormalTok{            headers}\OperatorTok{=}\NormalTok{headers,}
\NormalTok{            json}\OperatorTok{=}\NormalTok{data}
\NormalTok{        )}

\NormalTok{        response.raise\_for\_status()}
\NormalTok{        result }\OperatorTok{=}\NormalTok{ response.json()}

        \CommentTok{\# Transform into standardized response format}
        \ControlFlowTok{return}\NormalTok{ LLMResponse(}
\NormalTok{            content}\OperatorTok{=}\NormalTok{result[}\StringTok{"choices"}\NormalTok{][}\DecValTok{0}\NormalTok{][}\StringTok{"message"}\NormalTok{][}\StringTok{"content"}\NormalTok{],}
\NormalTok{            model}\OperatorTok{=}\NormalTok{result[}\StringTok{"model"}\NormalTok{],}
\NormalTok{            usage}\OperatorTok{=}\NormalTok{result[}\StringTok{"usage"}\NormalTok{],}
\NormalTok{            raw\_response}\OperatorTok{=}\NormalTok{result}
\NormalTok{        )}

    \KeywordTok{def}\NormalTok{ get\_available\_models(}\VariableTok{self}\NormalTok{) }\OperatorTok{{-}\textgreater{}}\NormalTok{ List[}\BuiltInTok{str}\NormalTok{]:}
        \CommentTok{"""Return a list of available OpenAI models"""}
\NormalTok{        headers }\OperatorTok{=}\NormalTok{ \{}
            \StringTok{"Authorization"}\NormalTok{: }\SpecialStringTok{f"Bearer }\SpecialCharTok{\{}\VariableTok{self}\SpecialCharTok{.}\NormalTok{api\_key}\SpecialCharTok{\}}\SpecialStringTok{"}
\NormalTok{        \}}

        \ControlFlowTok{if} \VariableTok{self}\NormalTok{.organization:}
\NormalTok{            headers[}\StringTok{"OpenAI{-}Organization"}\NormalTok{] }\OperatorTok{=} \VariableTok{self}\NormalTok{.organization}

\NormalTok{        response }\OperatorTok{=}\NormalTok{ requests.get(}
            \SpecialStringTok{f"}\SpecialCharTok{\{}\VariableTok{self}\SpecialCharTok{.}\NormalTok{api\_base}\SpecialCharTok{\}}\SpecialStringTok{/models"}\NormalTok{,}
\NormalTok{            headers}\OperatorTok{=}\NormalTok{headers}
\NormalTok{        )}

\NormalTok{        response.raise\_for\_status()}
\NormalTok{        models }\OperatorTok{=}\NormalTok{ response.json()[}\StringTok{"data"}\NormalTok{]}
        \ControlFlowTok{return}\NormalTok{ [model[}\StringTok{"id"}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ model }\KeywordTok{in}\NormalTok{ models]}

\KeywordTok{class}\NormalTok{ AnthropicProvider(LLMProvider):}
    \CommentTok{"""Anthropic Claude API implementation"""}

    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, api\_key: Optional[}\BuiltInTok{str}\NormalTok{] }\OperatorTok{=} \VariableTok{None}\NormalTok{):}
        \CommentTok{"""Initialize with API key from args or environment"""}
        \VariableTok{self}\NormalTok{.api\_key }\OperatorTok{=}\NormalTok{ api\_key }\KeywordTok{or}\NormalTok{ os.environ.get(}\StringTok{"ANTHROPIC\_API\_KEY"}\NormalTok{)}
        \ControlFlowTok{if} \KeywordTok{not} \VariableTok{self}\NormalTok{.api\_key:}
            \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{(}\StringTok{"Anthropic API key is required. Provide as"}
              \OperatorTok{+} \StringTok{" argument or set ANTHROPIC\_API\_KEY environment variable."}\NormalTok{)}

        \VariableTok{self}\NormalTok{.api\_base }\OperatorTok{=} \StringTok{"https://api.anthropic.com/v1"}

    \KeywordTok{def}\NormalTok{ complete(}\VariableTok{self}\NormalTok{,}
\NormalTok{                prompt: }\BuiltInTok{str}\NormalTok{,}
\NormalTok{                system\_prompt: Optional[}\BuiltInTok{str}\NormalTok{] }\OperatorTok{=} \VariableTok{None}\NormalTok{,}
\NormalTok{                model: }\BuiltInTok{str} \OperatorTok{=} \StringTok{"claude{-}3{-}opus{-}20240229"}\NormalTok{,}
\NormalTok{                temperature: }\BuiltInTok{float} \OperatorTok{=} \FloatTok{0.7}\NormalTok{,}
\NormalTok{                max\_tokens: }\BuiltInTok{int} \OperatorTok{=} \DecValTok{4000}\NormalTok{) }\OperatorTok{{-}\textgreater{}}\NormalTok{ LLMResponse:}
        \CommentTok{"""Generate a completion using Anthropic\textquotesingle{}s API"""}

        \CommentTok{\# Prepare request headers}
\NormalTok{        headers }\OperatorTok{=}\NormalTok{ \{}
            \StringTok{"Content{-}Type"}\NormalTok{: }\StringTok{"application/json"}\NormalTok{,}
            \StringTok{"X{-}API{-}Key"}\NormalTok{: }\VariableTok{self}\NormalTok{.api\_key,}
            \StringTok{"anthropic{-}version"}\NormalTok{: }\StringTok{"2023{-}06{-}01"}
\NormalTok{        \}}

        \CommentTok{\# Prepare request data in Anthropic{-}specific format}
\NormalTok{        data }\OperatorTok{=}\NormalTok{ \{}
            \StringTok{"model"}\NormalTok{: model,}
            \StringTok{"messages"}\NormalTok{: [\{}\StringTok{"role"}\NormalTok{: }\StringTok{"user"}\NormalTok{, }\StringTok{"content"}\NormalTok{: prompt\}],}
            \StringTok{"temperature"}\NormalTok{: temperature,}
            \StringTok{"max\_tokens"}\NormalTok{: max\_tokens}
\NormalTok{        \}}

        \CommentTok{\# Add system prompt if provided (Anthropic uses a different format)}
        \ControlFlowTok{if}\NormalTok{ system\_prompt:}
\NormalTok{            data[}\StringTok{"system"}\NormalTok{] }\OperatorTok{=}\NormalTok{ system\_prompt}

        \CommentTok{\# Make API call}
\NormalTok{        response }\OperatorTok{=}\NormalTok{ requests.post(}
            \SpecialStringTok{f"}\SpecialCharTok{\{}\VariableTok{self}\SpecialCharTok{.}\NormalTok{api\_base}\SpecialCharTok{\}}\SpecialStringTok{/messages"}\NormalTok{,}
\NormalTok{            headers}\OperatorTok{=}\NormalTok{headers,}
\NormalTok{            json}\OperatorTok{=}\NormalTok{data}
\NormalTok{        )}

\NormalTok{        response.raise\_for\_status()}
\NormalTok{        result }\OperatorTok{=}\NormalTok{ response.json()}

        \CommentTok{\# Transform into standardized response format}
        \ControlFlowTok{return}\NormalTok{ LLMResponse(}
\NormalTok{            content}\OperatorTok{=}\NormalTok{result[}\StringTok{"content"}\NormalTok{][}\DecValTok{0}\NormalTok{][}\StringTok{"text"}\NormalTok{],}
\NormalTok{            model}\OperatorTok{=}\NormalTok{result[}\StringTok{"model"}\NormalTok{],}
\NormalTok{            usage}\OperatorTok{=}\NormalTok{\{}\StringTok{"prompt\_tokens"}\NormalTok{: result.get(}\StringTok{"usage"}\NormalTok{, \{\}).get(}\StringTok{"input\_tokens"}\NormalTok{, }\DecValTok{0}\NormalTok{),}
                   \StringTok{"completion\_tokens"}\NormalTok{: result.get(}\StringTok{"usage"}\NormalTok{, \{\}).get(}\StringTok{"output\_tokens"}\NormalTok{, }\DecValTok{0}\NormalTok{)\},}
\NormalTok{            raw\_response}\OperatorTok{=}\NormalTok{result}
\NormalTok{        )}

    \KeywordTok{def}\NormalTok{ get\_available\_models(}\VariableTok{self}\NormalTok{) }\OperatorTok{{-}\textgreater{}}\NormalTok{ List[}\BuiltInTok{str}\NormalTok{]:}
        \CommentTok{"""Return a list of available Anthropic models"""}
        \CommentTok{\# Anthropic doesn\textquotesingle{}t have a models endpoint, so we return a static list}
        \ControlFlowTok{return}\NormalTok{ [}
            \StringTok{"claude{-}3{-}opus{-}20240229"}\NormalTok{,}
            \StringTok{"claude{-}3{-}sonnet{-}20240229"}\NormalTok{,}
            \StringTok{"claude{-}3{-}haiku{-}20240307"}
\NormalTok{        ]}

\KeywordTok{class}\NormalTok{ LLMFactory:}
    \CommentTok{"""Factory for creating LLM providers"""}

    \AttributeTok{@staticmethod}
    \KeywordTok{def}\NormalTok{ create\_provider(provider\_name: }\BuiltInTok{str}\NormalTok{, }\OperatorTok{**}\NormalTok{kwargs) }\OperatorTok{{-}\textgreater{}}\NormalTok{ LLMProvider:}
        \CommentTok{"""Create and return an LLM provider instance"""}
        \ControlFlowTok{if}\NormalTok{ provider\_name.lower() }\OperatorTok{==} \StringTok{"openai"}\NormalTok{:}
            \ControlFlowTok{return}\NormalTok{ OpenAIProvider(}\OperatorTok{**}\NormalTok{kwargs)}
        \ControlFlowTok{elif}\NormalTok{ provider\_name.lower() }\OperatorTok{==} \StringTok{"anthropic"}\NormalTok{:}
            \ControlFlowTok{return}\NormalTok{ AnthropicProvider(}\OperatorTok{**}\NormalTok{kwargs)}
        \ControlFlowTok{else}\NormalTok{:}
            \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{(}\SpecialStringTok{f"Unsupported provider: }\SpecialCharTok{\{}\NormalTok{provider\_name}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\phantomsection\label{api_call_function_definitions}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 1.3.1 {-}{-}{-} API Call Function Definitions {-}{-}{-} [api\_call\_function\_definitions]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Provides core functions for extracting ArgDown representations from text using LLMs.}

\CommentTok{This block implements the main extraction functionality:}
\CommentTok{1. extract\_argdown\_from\_text: Sends text to LLM to extract structured ArgDown representation}
\CommentTok{2. validate\_argdown: Verifies the extracted ArgDown for correctness and completeness}
\CommentTok{3. process\_source\_document: Handles source files (PDF, TXT, MD) and manages extraction}
\CommentTok{4. save\_argdown\_extraction: Saves extraction results with metadata for further processing}

\CommentTok{These functions form the first stage of the AMTAIR pipeline, transforming}
\CommentTok{unstructured text into structured argument representations.}

\CommentTok{DEPENDENCIES: LLMFactory from previous cell, re for pattern matching}
\CommentTok{OUTPUTS: Functions for ArgDown extraction, validation, and storage}
\CommentTok{"""}

\KeywordTok{def}\NormalTok{ extract\_argdown\_from\_text(text: }\BuiltInTok{str}\NormalTok{, provider\_name: }\BuiltInTok{str} \OperatorTok{=} \StringTok{"openai"}\NormalTok{, model: }\BuiltInTok{str} \OperatorTok{=} \VariableTok{None}\NormalTok{) }\OperatorTok{{-}\textgreater{}} \BuiltInTok{str}\NormalTok{:}
    \CommentTok{"""}
\CommentTok{    Extract ArgDown representation from text using LLM}

\CommentTok{    Args:}
\CommentTok{        text: The source text to extract arguments from}
\CommentTok{        provider\_name: The LLM provider to use (openai or anthropic)}
\CommentTok{        model: Specific model to use, or None for default}

\CommentTok{    Returns:}
\CommentTok{        Extracted ArgDown representation}
\CommentTok{    """}
    \CommentTok{\# Create LLM provider}
\NormalTok{    provider }\OperatorTok{=}\NormalTok{ LLMFactory.create\_provider(provider\_name)}

    \CommentTok{\# Get extraction prompt}
\NormalTok{    prompt\_template }\OperatorTok{=}\NormalTok{ PromptLibrary.get\_template(}\StringTok{"ARGDOWN\_EXTRACTION"}\NormalTok{)}
\NormalTok{    prompt }\OperatorTok{=}\NormalTok{ prompt\_template.}\BuiltInTok{format}\NormalTok{(text}\OperatorTok{=}\NormalTok{text)}

    \CommentTok{\# Set model{-}specific parameters}
    \ControlFlowTok{if}\NormalTok{ provider\_name.lower() }\OperatorTok{==} \StringTok{"openai"}\NormalTok{:}
\NormalTok{        model }\OperatorTok{=}\NormalTok{ model }\KeywordTok{or} \StringTok{"gpt{-}4{-}turbo"}
\NormalTok{        temperature }\OperatorTok{=} \FloatTok{0.3}  \CommentTok{\# Lower temperature for more deterministic extraction}
\NormalTok{        max\_tokens }\OperatorTok{=} \DecValTok{4000}
    \ControlFlowTok{elif}\NormalTok{ provider\_name.lower() }\OperatorTok{==} \StringTok{"anthropic"}\NormalTok{:}
\NormalTok{        model }\OperatorTok{=}\NormalTok{ model }\KeywordTok{or} \StringTok{"claude{-}3{-}opus{-}20240229"}
\NormalTok{        temperature }\OperatorTok{=} \FloatTok{0.2}
\NormalTok{        max\_tokens }\OperatorTok{=} \DecValTok{4000}

    \CommentTok{\# Call the LLM}
\NormalTok{    system\_prompt }\OperatorTok{=} \StringTok{"You are an expert in argument mapping and causal reasoning."}
\NormalTok{    response }\OperatorTok{=}\NormalTok{ provider.complete(}
\NormalTok{        prompt}\OperatorTok{=}\NormalTok{prompt,}
\NormalTok{        system\_prompt}\OperatorTok{=}\NormalTok{system\_prompt,}
\NormalTok{        model}\OperatorTok{=}\NormalTok{model,}
\NormalTok{        temperature}\OperatorTok{=}\NormalTok{temperature,}
\NormalTok{        max\_tokens}\OperatorTok{=}\NormalTok{max\_tokens}
\NormalTok{    )}

    \CommentTok{\# Extract the ArgDown content (remove any markdown code blocks if present)}
\NormalTok{    argdown\_content }\OperatorTok{=}\NormalTok{ response.content}
    \ControlFlowTok{if} \StringTok{"\textasciigrave{}\textasciigrave{}\textasciigrave{}"} \KeywordTok{in}\NormalTok{ argdown\_content:}
        \CommentTok{\# Extract content between code blocks if present}
        \ImportTok{import}\NormalTok{ re}
\NormalTok{        matches }\OperatorTok{=}\NormalTok{ re.findall(}\VerbatimStringTok{r"\textasciigrave{}\textasciigrave{}\textasciigrave{}}\NormalTok{(?:}\VerbatimStringTok{argdown}\NormalTok{)}\OperatorTok{?}\CharTok{\textbackslash{}n}\KeywordTok{(}\PreprocessorTok{[}\DecValTok{\textbackslash{}s\textbackslash{}S}\PreprocessorTok{]}\OperatorTok{*?}\KeywordTok{)}\CharTok{\textbackslash{}n}\VerbatimStringTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}"}\NormalTok{, argdown\_content)}
        \ControlFlowTok{if}\NormalTok{ matches:}
\NormalTok{            argdown\_content }\OperatorTok{=}\NormalTok{ matches[}\DecValTok{0}\NormalTok{]}

    \ControlFlowTok{return}\NormalTok{ argdown\_content}

\KeywordTok{def}\NormalTok{ validate\_argdown(argdown\_text: }\BuiltInTok{str}\NormalTok{) }\OperatorTok{{-}\textgreater{}}\NormalTok{ Dict[}\BuiltInTok{str}\NormalTok{, Any]:}
    \CommentTok{"""}
\CommentTok{    Validate ArgDown representation to ensure it\textquotesingle{}s well{-}formed}

\CommentTok{    Args:}
\CommentTok{        argdown\_text: ArgDown representation to validate}

\CommentTok{    Returns:}
\CommentTok{        Dictionary with validation results}
\CommentTok{    """}
    \CommentTok{\# Initialize validation results}
\NormalTok{    results }\OperatorTok{=}\NormalTok{ \{}
        \StringTok{"is\_valid"}\NormalTok{: }\VariableTok{True}\NormalTok{,}
        \StringTok{"errors"}\NormalTok{: [],}
        \StringTok{"warnings"}\NormalTok{: [],}
        \StringTok{"stats"}\NormalTok{: \{}
            \StringTok{"node\_count"}\NormalTok{: }\DecValTok{0}\NormalTok{,}
            \StringTok{"relationship\_count"}\NormalTok{: }\DecValTok{0}\NormalTok{,}
            \StringTok{"max\_depth"}\NormalTok{: }\DecValTok{0}
\NormalTok{        \}}
\NormalTok{    \}}

    \CommentTok{\# Basic syntax checks}
\NormalTok{    lines }\OperatorTok{=}\NormalTok{ argdown\_text.split(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{    node\_pattern }\OperatorTok{=} \VerbatimStringTok{r\textquotesingle{}}\CharTok{\textbackslash{}[}\KeywordTok{(}\DecValTok{.}\OperatorTok{*?}\KeywordTok{)}\CharTok{\textbackslash{}]}\VerbatimStringTok{:\textquotesingle{}}
\NormalTok{    instantiation\_pattern }\OperatorTok{=} \VerbatimStringTok{r\textquotesingle{}\{"instantiations":\textquotesingle{}}

    \CommentTok{\# Track nodes and relationships}
\NormalTok{    nodes }\OperatorTok{=} \BuiltInTok{set}\NormalTok{()}
\NormalTok{    relationships }\OperatorTok{=}\NormalTok{ []}
\NormalTok{    current\_depth }\OperatorTok{=} \DecValTok{0}
\NormalTok{    max\_depth }\OperatorTok{=} \DecValTok{0}

    \ControlFlowTok{for}\NormalTok{ i, line }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(lines):}
        \CommentTok{\# Skip empty lines}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ line.strip():}
            \ControlFlowTok{continue}

        \CommentTok{\# Calculate indentation depth}
\NormalTok{        indent }\OperatorTok{=} \DecValTok{0}
        \ControlFlowTok{if} \StringTok{\textquotesingle{}+\textquotesingle{}} \KeywordTok{in}\NormalTok{ line:}
\NormalTok{            indent }\OperatorTok{=}\NormalTok{ line.find(}\StringTok{\textquotesingle{}+\textquotesingle{}}\NormalTok{) }\OperatorTok{//} \DecValTok{2}

\NormalTok{        current\_depth }\OperatorTok{=}\NormalTok{ indent}
\NormalTok{        max\_depth }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(max\_depth, current\_depth)}

        \CommentTok{\# Check for node definitions}
        \ImportTok{import}\NormalTok{ re}
\NormalTok{        node\_matches }\OperatorTok{=}\NormalTok{ re.findall(node\_pattern, line)}
        \ControlFlowTok{if}\NormalTok{ node\_matches:}
\NormalTok{            node }\OperatorTok{=}\NormalTok{ node\_matches[}\DecValTok{0}\NormalTok{]}
\NormalTok{            nodes.add(node)}
\NormalTok{            results[}\StringTok{"stats"}\NormalTok{][}\StringTok{"node\_count"}\NormalTok{] }\OperatorTok{+=} \DecValTok{1}

            \CommentTok{\# Check for instantiations}
            \ControlFlowTok{if}\NormalTok{ instantiation\_pattern }\KeywordTok{not} \KeywordTok{in}\NormalTok{ line:}
\NormalTok{                results[}\StringTok{"warnings"}\NormalTok{].append(}\SpecialStringTok{f"Line }\SpecialCharTok{\{}\NormalTok{i}\OperatorTok{+}\DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: Node \textquotesingle{}}\SpecialCharTok{\{}\NormalTok{node}\SpecialCharTok{\}}\SpecialStringTok{\textquotesingle{} is missing instantiations metadata"}\NormalTok{)}

        \CommentTok{\# Check parent{-}child relationships}
        \ControlFlowTok{if}\NormalTok{ indent }\OperatorTok{\textgreater{}} \DecValTok{0} \KeywordTok{and} \StringTok{\textquotesingle{}+\textquotesingle{}} \KeywordTok{in}\NormalTok{ line }\KeywordTok{and}\NormalTok{ node\_matches:}
            \CommentTok{\# This is a child node; find its parent}
\NormalTok{            parent\_indent }\OperatorTok{=}\NormalTok{ indent }\OperatorTok{{-}} \DecValTok{1}
\NormalTok{            j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}
            \ControlFlowTok{while}\NormalTok{ j }\OperatorTok{\textgreater{}=} \DecValTok{0}\NormalTok{:}
                \ControlFlowTok{if} \StringTok{\textquotesingle{}+\textquotesingle{}} \KeywordTok{in}\NormalTok{ lines[j] }\KeywordTok{and}\NormalTok{ lines[j].find(}\StringTok{\textquotesingle{}+\textquotesingle{}}\NormalTok{) }\OperatorTok{//} \DecValTok{2} \OperatorTok{==}\NormalTok{ parent\_indent:}
\NormalTok{                    parent\_matches }\OperatorTok{=}\NormalTok{ re.findall(node\_pattern, lines[j])}
                    \ControlFlowTok{if}\NormalTok{ parent\_matches:}
\NormalTok{                        parent }\OperatorTok{=}\NormalTok{ parent\_matches[}\DecValTok{0}\NormalTok{]}
\NormalTok{                        relationships.append((parent, node))}
\NormalTok{                        results[}\StringTok{"stats"}\NormalTok{][}\StringTok{"relationship\_count"}\NormalTok{] }\OperatorTok{+=} \DecValTok{1}
                        \ControlFlowTok{break}
\NormalTok{                j }\OperatorTok{{-}=} \DecValTok{1}

\NormalTok{    results[}\StringTok{"stats"}\NormalTok{][}\StringTok{"max\_depth"}\NormalTok{] }\OperatorTok{=}\NormalTok{ max\_depth}

    \CommentTok{\# If we didn\textquotesingle{}t find any nodes, that\textquotesingle{}s a problem}
    \ControlFlowTok{if}\NormalTok{ results[}\StringTok{"stats"}\NormalTok{][}\StringTok{"node\_count"}\NormalTok{] }\OperatorTok{==} \DecValTok{0}\NormalTok{:}
\NormalTok{        results[}\StringTok{"is\_valid"}\NormalTok{] }\OperatorTok{=} \VariableTok{False}
\NormalTok{        results[}\StringTok{"errors"}\NormalTok{].append(}\StringTok{"No valid nodes found in ArgDown representation"}\NormalTok{)}

    \ControlFlowTok{return}\NormalTok{ results}

\KeywordTok{def}\NormalTok{ process\_source\_document(file\_path: }\BuiltInTok{str}\NormalTok{, provider\_name: }\BuiltInTok{str} \OperatorTok{=} \StringTok{"openai"}\NormalTok{) }\OperatorTok{{-}\textgreater{}}\NormalTok{ Dict[}\BuiltInTok{str}\NormalTok{, Any]:}
    \CommentTok{"""}
\CommentTok{    Process a source document to extract ArgDown representation}

\CommentTok{    Args:}
\CommentTok{        file\_path: Path to the source document}
\CommentTok{        provider\_name: The LLM provider to use}

\CommentTok{    Returns:}
\CommentTok{        Dictionary with extraction results}
\CommentTok{    """}
    \CommentTok{\# Load the source document}
\NormalTok{    text }\OperatorTok{=} \StringTok{""}
    \ControlFlowTok{if}\NormalTok{ file\_path.endswith(}\StringTok{".pdf"}\NormalTok{):}
        \CommentTok{\# PDF handling requires additional libraries}
        \ControlFlowTok{try}\NormalTok{:}
            \ImportTok{import}\NormalTok{ PyPDF2}
            \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(file\_path, }\StringTok{\textquotesingle{}rb\textquotesingle{}}\NormalTok{) }\ImportTok{as} \BuiltInTok{file}\NormalTok{:}
\NormalTok{                reader }\OperatorTok{=}\NormalTok{ PyPDF2.PdfReader(}\BuiltInTok{file}\NormalTok{)}
\NormalTok{                text }\OperatorTok{=} \StringTok{""}
                \ControlFlowTok{for}\NormalTok{ page }\KeywordTok{in}\NormalTok{ reader.pages:}
\NormalTok{                    text }\OperatorTok{+=}\NormalTok{ page.extract\_text() }\OperatorTok{+} \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}
        \ControlFlowTok{except} \PreprocessorTok{ImportError}\NormalTok{:}
            \ControlFlowTok{raise} \PreprocessorTok{ImportError}\NormalTok{(}\StringTok{"PyPDF2 is required for PDF processing. "}
              \OperatorTok{+} \StringTok{"Install it with: pip install PyPDF2"}\NormalTok{)}
    \ControlFlowTok{elif}\NormalTok{ file\_path.endswith(}\StringTok{".txt"}\NormalTok{):}
        \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(file\_path, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{) }\ImportTok{as} \BuiltInTok{file}\NormalTok{:}
\NormalTok{            text }\OperatorTok{=} \BuiltInTok{file}\NormalTok{.read()}
    \ControlFlowTok{elif}\NormalTok{ file\_path.endswith(}\StringTok{".md"}\NormalTok{):}
        \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(file\_path, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{) }\ImportTok{as} \BuiltInTok{file}\NormalTok{:}
\NormalTok{            text }\OperatorTok{=} \BuiltInTok{file}\NormalTok{.read()}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{(}\SpecialStringTok{f"Unsupported file format: }\SpecialCharTok{\{}\NormalTok{file\_path}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

    \CommentTok{\# Extract ArgDown}
\NormalTok{    argdown\_content }\OperatorTok{=}\NormalTok{ extract\_argdown\_from\_text(text, provider\_name)}

    \CommentTok{\# Validate the extraction}
\NormalTok{    validation\_results }\OperatorTok{=}\NormalTok{ validate\_argdown(argdown\_content)}

    \CommentTok{\# Prepare results}
\NormalTok{    results }\OperatorTok{=}\NormalTok{ \{}
        \StringTok{"source\_path"}\NormalTok{: file\_path,}
        \StringTok{"extraction\_timestamp"}\NormalTok{: time.time(),}
        \StringTok{"argdown\_content"}\NormalTok{: argdown\_content,}
        \StringTok{"validation"}\NormalTok{: validation\_results,}
        \StringTok{"provider"}\NormalTok{: provider\_name}
\NormalTok{    \}}

    \ControlFlowTok{return}\NormalTok{ results}

\KeywordTok{def}\NormalTok{ save\_argdown\_extraction(results: Dict[}\BuiltInTok{str}\NormalTok{, Any], output\_path: }\BuiltInTok{str}\NormalTok{) }\OperatorTok{{-}\textgreater{}} \VariableTok{None}\NormalTok{:}
    \CommentTok{"""}
\CommentTok{    Save ArgDown extraction results}

\CommentTok{    Args:}
\CommentTok{        results: Extraction results dictionary}
\CommentTok{        output\_path: Path to save the results}
\CommentTok{    """}
    \CommentTok{\# Save the ArgDown content}
    \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(output\_path, }\StringTok{\textquotesingle{}w\textquotesingle{}}\NormalTok{) }\ImportTok{as} \BuiltInTok{file}\NormalTok{:}
        \BuiltInTok{file}\NormalTok{.write(results[}\StringTok{"argdown\_content"}\NormalTok{])}

    \CommentTok{\# Save metadata alongside}
\NormalTok{    metadata\_path }\OperatorTok{=}\NormalTok{ output\_path.replace(}\StringTok{\textquotesingle{}.md\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\_metadata.json\textquotesingle{}}\NormalTok{)}
\NormalTok{    metadata }\OperatorTok{=}\NormalTok{ \{}
        \StringTok{"source\_path"}\NormalTok{: results[}\StringTok{"source\_path"}\NormalTok{],}
        \StringTok{"extraction\_timestamp"}\NormalTok{: results[}\StringTok{"extraction\_timestamp"}\NormalTok{],}
        \StringTok{"validation"}\NormalTok{: results[}\StringTok{"validation"}\NormalTok{],}
        \StringTok{"provider"}\NormalTok{: results[}\StringTok{"provider"}\NormalTok{]}
\NormalTok{    \}}

    \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(metadata\_path, }\StringTok{\textquotesingle{}w\textquotesingle{}}\NormalTok{) }\ImportTok{as} \BuiltInTok{file}\NormalTok{:}
\NormalTok{        json.dump(metadata, }\BuiltInTok{file}\NormalTok{, indent}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\phantomsection\label{prepare_api_call}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 1.3.2 {-}{-}{-} Prepare LLM API Call {-}{-}{-} [prepare\_api\_call]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Prepares parameters for LLM API calls used in ArgDown extraction.}

\CommentTok{This function handles the configuration for LLM API calls, including:}
\CommentTok{1. Source document path validation}
\CommentTok{2. LLM provider selection and validation}
\CommentTok{3. Model selection with appropriate defaults}

\CommentTok{The function returns a configuration dictionary that can be passed to the}
\CommentTok{extraction function in the next step of the pipeline.}

\CommentTok{DEPENDENCIES: None (uses standard Python functionality)}
\CommentTok{OUTPUTS: Dictionary with extraction configuration parameters}
\CommentTok{"""}

\KeywordTok{def}\NormalTok{ prepare\_extraction\_call(source\_path, provider\_name}\OperatorTok{=}\StringTok{"openai"}\NormalTok{, model}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
    \CommentTok{"""}
\CommentTok{    Prepare the LLM API call for ArgDown extraction}

\CommentTok{    Args:}
\CommentTok{        source\_path (str): Path to the source document to extract from}
\CommentTok{        provider\_name (str): LLM provider to use (\textquotesingle{}openai\textquotesingle{} or \textquotesingle{}anthropic\textquotesingle{})}
\CommentTok{        model (str, optional): Specific model to use. Defaults to None (uses provider\textquotesingle{}s default).}

\CommentTok{    Returns:}
\CommentTok{        dict: Configuration parameters for extraction}

\CommentTok{    Raises:}
\CommentTok{        ValueError: If an unsupported provider is specified}
\CommentTok{    """}
    \CommentTok{\# Load the source document}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Processing source document: }\SpecialCharTok{\{}\NormalTok{source\_path}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

    \CommentTok{\# Determine provider and model}
\NormalTok{    provider }\OperatorTok{=}\NormalTok{ provider\_name.lower()}
    \ControlFlowTok{if}\NormalTok{ provider }\KeywordTok{not} \KeywordTok{in}\NormalTok{ [}\StringTok{"openai"}\NormalTok{, }\StringTok{"anthropic"}\NormalTok{]:}
        \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{(}\SpecialStringTok{f"Unsupported provider: }\SpecialCharTok{\{}\NormalTok{provider}\SpecialCharTok{\}}\SpecialStringTok{. Use \textquotesingle{}openai\textquotesingle{} or \textquotesingle{}anthropic\textquotesingle{}."}\NormalTok{)}

    \CommentTok{\# Set default model if none provided}
    \ControlFlowTok{if}\NormalTok{ model }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
        \ControlFlowTok{if}\NormalTok{ provider }\OperatorTok{==} \StringTok{"openai"}\NormalTok{:}
\NormalTok{            model }\OperatorTok{=} \StringTok{"gpt{-}4{-}turbo"}
        \ControlFlowTok{elif}\NormalTok{ provider }\OperatorTok{==} \StringTok{"anthropic"}\NormalTok{:}
\NormalTok{            model }\OperatorTok{=} \StringTok{"claude{-}3{-}opus{-}20240229"}

    \CommentTok{\# Print configuration}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Using provider: }\SpecialCharTok{\{}\NormalTok{provider}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Selected model: }\SpecialCharTok{\{}\NormalTok{model}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

    \ControlFlowTok{return}\NormalTok{ \{}
        \StringTok{"source\_path"}\NormalTok{: source\_path,}
        \StringTok{"provider"}\NormalTok{: provider,}
        \StringTok{"model"}\NormalTok{: model}
\NormalTok{    \}}

\CommentTok{\# Usage example:}
\NormalTok{source\_path }\OperatorTok{=} \StringTok{"example\_document.pdf"}  \CommentTok{\# Replace with actual document path}
\NormalTok{extraction\_config }\OperatorTok{=}\NormalTok{ prepare\_extraction\_call(source\_path, provider\_name}\OperatorTok{=}\StringTok{"openai"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Processing source document: example_document.pdf
Using provider: openai
Selected model: gpt-4-turbo
\end{verbatim}

\section{1.4 Make ArgDown Extraction LLM API
Call}\label{make-argdown-extraction-llm-api-call}

\phantomsection\label{extraction_api_call}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 1.4.0 {-}{-}{-} Make ArgDown Extraction LLM API Call {-}{-}{-} [extraction\_api\_call]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Executes the ArgDown extraction process using the LLM API.}

\CommentTok{This function performs the actual extraction of ArgDown representations from}
\CommentTok{source documents:}
\CommentTok{1. Takes the configuration parameters prepared in the previous step}
\CommentTok{2. Processes the document using the LLM API}
\CommentTok{3. Validates the extraction results}
\CommentTok{4. Provides timing and statistics about the extraction}

\CommentTok{The extraction process transforms unstructured text into a structured argument}
\CommentTok{representation following the ArgDown syntax defined in the AMTAIR project.}

\CommentTok{DEPENDENCIES: process\_source\_document function from previous cells}
\CommentTok{OUTPUTS: Dictionary with extraction results including ArgDown content and validation info}
\CommentTok{"""}

\KeywordTok{def}\NormalTok{ execute\_extraction(extraction\_config):}
    \CommentTok{"""}
\CommentTok{    Execute the ArgDown extraction using the LLM API}

\CommentTok{    Args:}
\CommentTok{        extraction\_config (dict): Configuration parameters for extraction}

\CommentTok{    Returns:}
\CommentTok{        dict: Extraction results including ArgDown content and validation info}

\CommentTok{    Raises:}
\CommentTok{        Exception: For any errors during extraction}
\CommentTok{    """}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Starting extraction from }\SpecialCharTok{\{}\NormalTok{extraction\_config[}\StringTok{\textquotesingle{}source\_path\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\NormalTok{    start\_time }\OperatorTok{=}\NormalTok{ time.time()}

    \ControlFlowTok{try}\NormalTok{:}
        \CommentTok{\# Process the document}
\NormalTok{        results }\OperatorTok{=}\NormalTok{ process\_source\_document(}
\NormalTok{            extraction\_config[}\StringTok{"source\_path"}\NormalTok{],}
\NormalTok{            provider\_name}\OperatorTok{=}\NormalTok{extraction\_config[}\StringTok{"provider"}\NormalTok{]}
\NormalTok{        )}

        \CommentTok{\# Print success message}
\NormalTok{        elapsed\_time }\OperatorTok{=}\NormalTok{ time.time() }\OperatorTok{{-}}\NormalTok{ start\_time}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Extraction completed in }\SpecialCharTok{\{}\NormalTok{elapsed\_time}\SpecialCharTok{:.2f\}}\SpecialStringTok{ seconds"}\NormalTok{)}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Extracted }\SpecialCharTok{\{}\NormalTok{results[}\StringTok{\textquotesingle{}validation\textquotesingle{}}\NormalTok{][}\StringTok{\textquotesingle{}stats\textquotesingle{}}\NormalTok{][}\StringTok{\textquotesingle{}node\_count\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{ nodes with "}
              \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{results[}\StringTok{\textquotesingle{}validation\textquotesingle{}}\NormalTok{][}\StringTok{\textquotesingle{}stats\textquotesingle{}}\NormalTok{][}\StringTok{\textquotesingle{}relationship\_count\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{ relationships"}\NormalTok{)}

        \CommentTok{\# Print any warnings}
        \ControlFlowTok{if}\NormalTok{ results[}\StringTok{\textquotesingle{}validation\textquotesingle{}}\NormalTok{][}\StringTok{\textquotesingle{}warnings\textquotesingle{}}\NormalTok{]:}
            \BuiltInTok{print}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{Warnings:"}\NormalTok{)}
            \ControlFlowTok{for}\NormalTok{ warning }\KeywordTok{in}\NormalTok{ results[}\StringTok{\textquotesingle{}validation\textquotesingle{}}\NormalTok{][}\StringTok{\textquotesingle{}warnings\textquotesingle{}}\NormalTok{]:}
                \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"{-} }\SpecialCharTok{\{}\NormalTok{warning}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

        \ControlFlowTok{return}\NormalTok{ results}

    \ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Error during extraction: }\SpecialCharTok{\{}\BuiltInTok{str}\NormalTok{(e)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
        \ControlFlowTok{raise}

\CommentTok{\# Usage example:}
\NormalTok{extraction\_results }\OperatorTok{=}\NormalTok{ execute\_extraction(extraction\_config)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Starting extraction from example_document.pdf
Error during extraction: PyPDF2 is required for PDF processing. Install it with: pip install PyPDF2
\end{verbatim}

\begin{Highlighting}
\textcolor{black}{ImportError: PyPDF2 is required for PDF processing. Install it with: pip install PyPDF2}
\textcolor{black}{}\textcolor{QuartoInternalColor1}{---------------------------------------------------------------------------}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor1}{ModuleNotFoundError}\textcolor{QuartoInternalColor2}{                       Traceback (most recent call last)}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor3}{<ipython-input-19-fd592eb962ab>}\textcolor{QuartoInternalColor2}{ in }\textcolor{QuartoInternalColor4}{process\_source\_document}\textcolor{QuartoInternalColor5}{(file\_path, provider\_name)}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor6}{    166}\textcolor{QuartoInternalColor2}{         }\textcolor{QuartoInternalColor3}{try}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{:}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor3}{--> 167}\textcolor{QuartoInternalColor1}{             }\textcolor{QuartoInternalColor3}{import}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor2}{PyPDF2}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor6}{    168}\textcolor{QuartoInternalColor2}{             }\textcolor{QuartoInternalColor3}{with}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor2}{open}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{(}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{file\_path}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{,}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor5}{'rb'}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{)}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor3}{as}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor2}{file}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{:}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor1}{ModuleNotFoundError}\textcolor{QuartoInternalColor2}{: No module named 'PyPDF2'}
\textcolor{QuartoInternalColor2}{During handling of the above exception, another exception occurred:}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor1}{ImportError}\textcolor{QuartoInternalColor2}{                               Traceback (most recent call last)}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor3}{<ipython-input-21-27555067c1d2>}\textcolor{QuartoInternalColor2}{ in }\textcolor{QuartoInternalColor4}{<cell line: 0>}\textcolor{QuartoInternalColor5}{()}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor6}{     59}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor6}{     60}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor1}{# Usage example:}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor3}{---> 61}\textcolor{QuartoInternalColor1}{ }\textcolor{QuartoInternalColor2}{extraction\_results}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor5}{=}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor2}{execute\_extraction}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{(}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{extraction\_config}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{)}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor3}{<ipython-input-21-27555067c1d2>}\textcolor{QuartoInternalColor2}{ in }\textcolor{QuartoInternalColor4}{execute\_extraction}\textcolor{QuartoInternalColor5}{(extraction\_config)}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor6}{     35}\textcolor{QuartoInternalColor2}{     }\textcolor{QuartoInternalColor3}{try}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{:}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor6}{     36}\textcolor{QuartoInternalColor2}{         }\textcolor{QuartoInternalColor1}{# Process the document}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor3}{---> 37}\textcolor{QuartoInternalColor1}{         results = process\_source\_document(}
\textcolor{QuartoInternalColor1}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor6}{     38}\textcolor{QuartoInternalColor2}{             }\textcolor{QuartoInternalColor2}{extraction\_config}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{[}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{"source\_path"}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{]}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{,}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor6}{     39}\textcolor{QuartoInternalColor2}{             }\textcolor{QuartoInternalColor2}{provider\_name}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{=}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{extraction\_config}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{[}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{"provider"}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{]}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor3}{<ipython-input-19-fd592eb962ab>}\textcolor{QuartoInternalColor2}{ in }\textcolor{QuartoInternalColor4}{process\_source\_document}\textcolor{QuartoInternalColor5}{(file\_path, provider\_name)}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor6}{    172}\textcolor{QuartoInternalColor2}{                     }\textcolor{QuartoInternalColor2}{text}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor5}{+=}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor2}{page}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{.}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{extract\_text}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{(}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{)}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor5}{+}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor5}{"\textbackslash{}n"}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor6}{    173}\textcolor{QuartoInternalColor2}{         }\textcolor{QuartoInternalColor3}{except}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor2}{ImportError}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{:}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor3}{--> 174}\textcolor{QuartoInternalColor1}{             }\textcolor{QuartoInternalColor3}{raise}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor2}{ImportError}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{(}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{"PyPDF2 is required for PDF processing. Install it with: pip install PyPDF2"}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{)}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor6}{    175}\textcolor{QuartoInternalColor2}{     }\textcolor{QuartoInternalColor3}{elif}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor2}{file\_path}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{.}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{endswith}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{(}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{".txt"}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{)}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{:}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor6}{    176}\textcolor{QuartoInternalColor2}{         }\textcolor{QuartoInternalColor3}{with}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor2}{open}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{(}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{file\_path}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{,}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor5}{'r'}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{)}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor3}{as}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor2}{file}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{:}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor1}{ImportError}\textcolor{QuartoInternalColor2}{: PyPDF2 is required for PDF processing. Install it with: pip install PyPDF2}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor1}{---------------------------------------------------------------------------}\textcolor{QuartoInternalColor3}{}
\textcolor{QuartoInternalColor3}{NOTE: If your import is failing due to a missing package, you can}
\textcolor{QuartoInternalColor3}{manually install dependencies using either !pip or !apt.}
\textcolor{QuartoInternalColor3}{To view examples of installing some common dependencies, click the}
\textcolor{QuartoInternalColor3}{"Open Examples" button below.}
\textcolor{QuartoInternalColor3}{}\textcolor{QuartoInternalColor1}{---------------------------------------------------------------------------}\textcolor{QuartoInternalColor2}{}
\end{Highlighting}

\section{1.5 Save ArgDown Extraction
Response}\label{save-argdown-extraction-response}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Save and log API return
\item
  Save ArgDown.md file for further Proecessing
\end{enumerate}

\phantomsection\label{save_extraction_response}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 1.5.0 {-}{-}{-} Save ArgDown Extraction Response {-}{-}{-} [save\_extraction\_response]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Saves the extracted ArgDown content to files for further processing.}

\CommentTok{This function handles saving the extraction results:}
\CommentTok{1. Creates an output directory if it doesn\textquotesingle{}t exist}
\CommentTok{2. Saves the extracted ArgDown content with a timestamp in the filename}
\CommentTok{3. Saves accompanying metadata in a JSON file}
\CommentTok{4. Saves a copy at a standard location for the next steps in the pipeline}
\CommentTok{5. Provides a preview of the extracted content}

\CommentTok{The saved files serve as inputs for the next stage of the pipeline where}
\CommentTok{probability information will be added to create BayesDown.}

\CommentTok{DEPENDENCIES: os module for directory operations}
\CommentTok{OUTPUTS: Saved ArgDown files and preview of extracted content}
\CommentTok{"""}

\KeywordTok{def}\NormalTok{ save\_extraction\_results(results, output\_directory}\OperatorTok{=}\StringTok{"./outputs"}\NormalTok{):}
    \CommentTok{"""}
\CommentTok{    Save the extraction results to file}

\CommentTok{    Args:}
\CommentTok{        results (dict): Extraction results from execute\_extraction}
\CommentTok{        output\_directory (str): Directory to save results}

\CommentTok{    Returns:}
\CommentTok{        str: Path to the saved ArgDown file}
\CommentTok{    """}
    \CommentTok{\# Ensure output directory exists}
    \ImportTok{import}\NormalTok{ os}
\NormalTok{    os.makedirs(output\_directory, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

    \CommentTok{\# Create base filename from source}
    \ImportTok{import}\NormalTok{ os.path}
\NormalTok{    base\_name }\OperatorTok{=}\NormalTok{ os.path.basename(results[}\StringTok{"source\_path"}\NormalTok{]).split(}\StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{)[}\DecValTok{0}\NormalTok{]}
\NormalTok{    timestamp }\OperatorTok{=}\NormalTok{ time.strftime(}\StringTok{"\%Y\%m}\SpecialCharTok{\%d}\StringTok{{-}\%H\%M\%S"}\NormalTok{)}
\NormalTok{    output\_filename }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{base\_name}\SpecialCharTok{\}}\SpecialStringTok{\_argdown\_}\SpecialCharTok{\{}\NormalTok{timestamp}\SpecialCharTok{\}}\SpecialStringTok{.md"}
\NormalTok{    output\_path }\OperatorTok{=}\NormalTok{ os.path.join(output\_directory, output\_filename)}

    \CommentTok{\# Save the results}
\NormalTok{    save\_argdown\_extraction(results, output\_path)}

    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Saved ArgDown extraction to: }\SpecialCharTok{\{}\NormalTok{output\_path}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Metadata saved to: }\SpecialCharTok{\{}\NormalTok{output\_path}\SpecialCharTok{.}\NormalTok{replace(}\StringTok{\textquotesingle{}.md\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\_metadata.json\textquotesingle{}}\NormalTok{)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

    \CommentTok{\# Also save to standard location for further processing}
\NormalTok{    standard\_path }\OperatorTok{=}\NormalTok{ os.path.join(output\_directory, }\StringTok{"ArgDown.md"}\NormalTok{)}
    \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(standard\_path, }\StringTok{\textquotesingle{}w\textquotesingle{}}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{        f.write(results[}\StringTok{"argdown\_content"}\NormalTok{])}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Also saved to standard location: }\SpecialCharTok{\{}\NormalTok{standard\_path}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

    \ControlFlowTok{return}\NormalTok{ output\_path}

\CommentTok{\# Usage example:}
\NormalTok{output\_path }\OperatorTok{=}\NormalTok{ save\_extraction\_results(extraction\_results)}

\CommentTok{\# Preview the extracted ArgDown}
\ImportTok{from}\NormalTok{ IPython.display }\ImportTok{import}\NormalTok{ Markdown, display}

\CommentTok{\# Display the first 500 characters of the extracted ArgDown}
\NormalTok{preview }\OperatorTok{=}\NormalTok{ extraction\_results[}\StringTok{"argdown\_content"}\NormalTok{][:}\DecValTok{500}\NormalTok{] }\OperatorTok{+} \StringTok{"..."} \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(extraction\_results[}\StringTok{"argdown\_content"}\NormalTok{]) }\OperatorTok{\textgreater{}} \DecValTok{500} \ControlFlowTok{else}\NormalTok{ extraction\_results[}\StringTok{"argdown\_content"}\NormalTok{]}
\NormalTok{display(Markdown(}\SpecialStringTok{f"\#\# Extracted ArgDown Preview}\CharTok{\textbackslash{}n\textbackslash{}n}\SpecialStringTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}\CharTok{\textbackslash{}n}\SpecialCharTok{\{}\NormalTok{preview}\SpecialCharTok{\}}\CharTok{\textbackslash{}n}\SpecialStringTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Highlighting}
\textcolor{black}{NameError: name 'extraction\_results' is not defined}
\textcolor{black}{}\textcolor{QuartoInternalColor1}{---------------------------------------------------------------------------}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor1}{NameError}\textcolor{QuartoInternalColor2}{                                 Traceback (most recent call last)}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor3}{<ipython-input-57-84ee4ea64739>}\textcolor{QuartoInternalColor2}{ in }\textcolor{QuartoInternalColor4}{<cell line: 0>}\textcolor{QuartoInternalColor5}{()}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor6}{     55}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor6}{     56}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor1}{# Usage example:}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor3}{---> 57}\textcolor{QuartoInternalColor1}{ }\textcolor{QuartoInternalColor2}{output\_path}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor5}{=}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor2}{save\_extraction\_results}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{(}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{extraction\_results}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{)}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor6}{     58}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor6}{     59}\textcolor{QuartoInternalColor2}{ }\textcolor{QuartoInternalColor1}{# Preview the extracted ArgDown}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor5}{}\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor2}{}
\textcolor{QuartoInternalColor2}{}\textcolor{QuartoInternalColor1}{NameError}\textcolor{QuartoInternalColor2}{: name 'extraction\_results' is not defined}
\end{Highlighting}

\section{1.6 Review and Check ArgDown.md
File}\label{review-and-check-argdown.md-file}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{display(Markdown(md\_content))}
\end{Highlighting}
\end{Shaded}

{[}Existential\_Catastrophe{]}: The destruction of humanity's long-term
potential due to AI systems we've lost control over.
\{``instantiations'': {[}``existential\_catastrophe\_TRUE'',
``existential\_catastrophe\_FALSE''{]}\} - {[}Human\_Disempowerment{]}:
Permanent and collective disempowerment of humanity relative to AI
systems. \{``instantiations'': {[}``human\_disempowerment\_TRUE'',
``human\_disempowerment\_FALSE''{]}\} - {[}Scale\_Of\_Power\_Seeking{]}:
Power-seeking by AI systems scaling to the point of permanently
disempowering all of humanity. \{``instantiations'':
{[}``scale\_of\_power\_seeking\_TRUE'',
``scale\_of\_power\_seeking\_FALSE''{]}\} -
{[}Misaligned\_Power\_Seeking{]}: Deployed AI systems seeking power in
unintended and high-impact ways due to problems with their objectives.
\{``instantiations'': {[}``misaligned\_power\_seeking\_TRUE'',
``misaligned\_power\_seeking\_FALSE''{]}\} - {[}APS\_Systems{]}: AI
systems with advanced capabilities, agentic planning, and strategic
awareness. \{``instantiations'': {[}``aps\_systems\_TRUE'',
``aps\_systems\_FALSE''{]}\} - {[}Advanced\_AI\_Capability{]}: AI
systems that outperform humans on tasks that grant significant power in
the world. \{``instantiations'': {[}``advanced\_ai\_capability\_TRUE'',
``advanced\_ai\_capability\_FALSE''{]}\} - {[}Agentic\_Planning{]}: AI
systems making and executing plans based on world models to achieve
objectives. \{``instantiations'': {[}``agentic\_planning\_TRUE'',
``agentic\_planning\_FALSE''{]}\} - {[}Strategic\_Awareness{]}: AI
systems with models accurately representing power dynamics with humans.
\{``instantiations'': {[}``strategic\_awareness\_TRUE'',
``strategic\_awareness\_FALSE''{]}\} - {[}Difficulty\_Of\_Alignment{]}:
It is harder to build aligned systems than misaligned systems that are
attractive to deploy. \{``instantiations'':
{[}``difficulty\_of\_alignment\_TRUE'',
``difficulty\_of\_alignment\_FALSE''{]}\} -
{[}Instrumental\_Convergence{]}: AI systems with misaligned objectives
tend to seek power as an instrumental goal. \{``instantiations'':
{[}``instrumental\_convergence\_TRUE'',
``instrumental\_convergence\_FALSE''{]}\} -
{[}Problems\_With\_Proxies{]}: Optimizing for proxy objectives breaks
correlations with intended goals. \{``instantiations'':
{[}``problems\_with\_proxies\_TRUE'',
``problems\_with\_proxies\_FALSE''{]}\} - {[}Problems\_With\_Search{]}:
Search processes can yield systems pursuing different objectives than
intended. \{``instantiations'': {[}``problems\_with\_search\_TRUE'',
``problems\_with\_search\_FALSE''{]}\} - {[}Deployment\_Decisions{]}:
Decisions to deploy potentially misaligned AI systems.
\{``instantiations'': {[}``deployment\_decisions\_DEPLOY'',
``deployment\_decisions\_WITHHOLD''{]}\} -
{[}Incentives\_To\_Build\_APS{]}: Strong incentives to build and deploy
APS systems. \{``instantiations'':
{[}``incentives\_to\_build\_aps\_STRONG'',
``incentives\_to\_build\_aps\_WEAK''{]}\} - {[}Usefulness\_Of\_APS{]}:
APS systems are very useful for many valuable tasks.
\{``instantiations'': {[}``usefulness\_of\_aps\_HIGH'',
``usefulness\_of\_aps\_LOW''{]}\} - {[}Competitive\_Dynamics{]}:
Competitive pressures between AI developers. \{``instantiations'':
{[}``competitive\_dynamics\_STRONG'',
``competitive\_dynamics\_WEAK''{]}\} - {[}Deception\_By\_AI{]}: AI
systems deceiving humans about their true objectives.
\{``instantiations'': {[}``deception\_by\_ai\_TRUE'',
``deception\_by\_ai\_FALSE''{]}\} - {[}Corrective\_Feedback{]}: Human
society implementing corrections after observing problems.
\{``instantiations'': {[}``corrective\_feedback\_EFFECTIVE'',
``corrective\_feedback\_INEFFECTIVE''{]}\} - {[}Warning\_Shots{]}:
Observable failures in weaker systems before catastrophic risks.
\{``instantiations'': {[}``warning\_shots\_OBSERVED'',
``warning\_shots\_UNOBSERVED''{]}\} -
{[}Rapid\_Capability\_Escalation{]}: AI capabilities escalating very
rapidly, allowing little time for correction. \{``instantiations'':
{[}``rapid\_capability\_escalation\_TRUE'',
``rapid\_capability\_escalation\_FALSE''{]}\}
{[}Barriers\_To\_Understanding{]}: Difficulty in understanding the
internal workings of advanced AI systems. \{``instantiations'':
{[}``barriers\_to\_understanding\_HIGH'',
``barriers\_to\_understanding\_LOW''{]}\} -
{[}Misaligned\_Power\_Seeking{]}: Deployed AI systems seeking power in
unintended and high-impact ways due to problems with their objectives.
\{``instantiations'': {[}``misaligned\_power\_seeking\_TRUE'',
``misaligned\_power\_seeking\_FALSE''{]}\} {[}Adversarial\_Dynamics{]}:
Potentially adversarial relationships between humans and power-seeking
AI. \{``instantiations'': {[}``adversarial\_dynamics\_TRUE'',
``adversarial\_dynamics\_FALSE''{]}\} -
{[}Misaligned\_Power\_Seeking{]}: Deployed AI systems seeking power in
unintended and high-impact ways due to problems with their objectives.
\{``instantiations'': {[}``misaligned\_power\_seeking\_TRUE'',
``misaligned\_power\_seeking\_FALSE''{]}\} {[}Stakes\_Of\_Error{]}: The
escalating impact of mistakes with power-seeking AI systems.
\{``instantiations'': {[}``stakes\_of\_error\_HIGH'',
``stakes\_of\_error\_LOW''{]}\} - {[}Misaligned\_Power\_Seeking{]}:
Deployed AI systems seeking power in unintended and high-impact ways due
to problems with their objectives. \{``instantiations'':
{[}``misaligned\_power\_seeking\_TRUE'',
``misaligned\_power\_seeking\_FALSE''{]}\}

\subsection{1.6.0 Check the Graph Structure with the ArgDown Sandbox
Online}\label{check-the-graph-structure-with-the-argdown-sandbox-online}

Copy and paste the BayesDown formatted \ldots{} in the ArgDown Sandbox
below to quickly verify that the network renders correctly.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 1.6.1 {-}{-}{-} ArgDown Online Sandbox {-}{-}{-} [argdown\_online\_sandbox]}

\ImportTok{from}\NormalTok{ IPython.display }\ImportTok{import}\NormalTok{ IFrame}

\NormalTok{IFrame(src}\OperatorTok{=}\StringTok{"https://argdown.org/sandbox/map/"}\NormalTok{, width}\OperatorTok{=}\StringTok{"100\%"}\NormalTok{, height}\OperatorTok{=}\StringTok{"600px"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\phantomsection\label{argdown_online_sandbox}
\begin{verbatim}
<IPython.lib.display.IFrame at 0x7b9ccf0ea210>
\end{verbatim}

ArgDown Online Sandbox

\section{1.7 Extract ArgDown Graph Information as
DataFrame}\label{extract-argdown-graph-information-as-dataframe}

Extract:

\begin{itemize}
\tightlist
\item
  Nodes (Variable\_Title)
\item
  Edges (Parents)
\item
  Instantiations
\item
  Description
\end{itemize}

Implementation nodes: - One function for ArgDown and BayesDown
extraction, but: - IF YOU ONLY WANT ARGDOWN EXTRACTION: USE ARGUMENT IN
FUNCTION CALL ``parse\_markdown\_hierarchy(markdown\_text, ArgDown =
True)'' - so if you set ArgDown = True, it gives you only
instantiations, no probabilities.

\phantomsection\label{parsing_argdown_bayesdown}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 1.7.0 {-}{-}{-} Parsing ArgDown \& BayesDown (.md to .csv) {-}{-}{-} [parsing\_argdown\_bayesdown]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Provides the core parsing functionality for transforming ArgDown}
\CommentTok{and BayesDown text representations into structured DataFrame format for further}
\CommentTok{processing.}

\CommentTok{This block implements the critical extraction pipeline described in the AMTAIR}
\CommentTok{project (see PY\_TechnicalImplementation) that converts argument structures}
\CommentTok{into Bayesian networks.}
\CommentTok{The function can handle both basic ArgDown (structure{-}only) and}
\CommentTok{BayesDown (with probabilities).}

\CommentTok{Key steps in the parsing process:}
\CommentTok{1. Remove comments from the markdown text}
\CommentTok{2. Extract titles, descriptions, and indentation levels}
\CommentTok{3. Establish parent{-}child relationships based on indentation}
\CommentTok{4. Convert the structured information into a DataFrame}
\CommentTok{5. Add derived columns for network analysis}

\CommentTok{DEPENDENCIES: pandas, re, json libraries}
\CommentTok{INPUTS: Markdown text in ArgDown/BayesDown format}
\CommentTok{OUTPUTS: Structured DataFrame with node information, relationships, and properties}
\CommentTok{"""}

\KeywordTok{def}\NormalTok{ parse\_markdown\_hierarchy\_fixed(markdown\_text, ArgDown}\OperatorTok{=}\VariableTok{False}\NormalTok{):}
    \CommentTok{"""}
\CommentTok{    Parse ArgDown or BayesDown format into a structured DataFrame with parent{-}child relationships.}

\CommentTok{    Args:}
\CommentTok{        markdown\_text (str): Text in ArgDown or BayesDown format}
\CommentTok{        ArgDown (bool): If True, extracts only structure without probabilities}
\CommentTok{                        If False, extracts both structure and probability information}

\CommentTok{    Returns:}
\CommentTok{        pandas.DataFrame: Structured data with node information, relationships, and attributes}
\CommentTok{    """}
    \CommentTok{\# PHASE 1: Clean and prepare the text}
\NormalTok{    clean\_text }\OperatorTok{=}\NormalTok{ remove\_comments(markdown\_text)}

    \CommentTok{\# PHASE 2: Extract basic information about nodes}
\NormalTok{    titles\_info }\OperatorTok{=}\NormalTok{ extract\_titles\_info(clean\_text)}

    \CommentTok{\# PHASE 3: Determine the hierarchical relationships}
\NormalTok{    titles\_with\_relations }\OperatorTok{=}\NormalTok{ establish\_relationships\_fixed(titles\_info, clean\_text)}

    \CommentTok{\# PHASE 4: Convert to structured DataFrame format}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ convert\_to\_dataframe(titles\_with\_relations, ArgDown)}

    \CommentTok{\# PHASE 5: Add derived columns for analysis}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ add\_no\_parent\_no\_child\_columns\_to\_df(df)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ add\_parents\_instantiation\_columns\_to\_df(df)}

    \ControlFlowTok{return}\NormalTok{ df}

\KeywordTok{def}\NormalTok{ remove\_comments(markdown\_text):}
    \CommentTok{"""}
\CommentTok{    Remove comment blocks from markdown text using regex pattern matching.}

\CommentTok{    Args:}
\CommentTok{        markdown\_text (str): Text containing potential comment blocks}

\CommentTok{    Returns:}
\CommentTok{        str: Text with comment blocks removed}
\CommentTok{    """}
    \CommentTok{\# Remove anything between /* and */ using regex}
    \ControlFlowTok{return}\NormalTok{ re.sub(}\VerbatimStringTok{r\textquotesingle{}/}\CharTok{\textbackslash{}*}\DecValTok{.}\OperatorTok{*?}\CharTok{\textbackslash{}*}\VerbatimStringTok{/\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{, markdown\_text, flags}\OperatorTok{=}\NormalTok{re.DOTALL)}

\KeywordTok{def}\NormalTok{ extract\_titles\_info(text):}
    \CommentTok{"""}
\CommentTok{    Extract titles with their descriptions and indentation levels from markdown text.}

\CommentTok{    Args:}
\CommentTok{        text (str): Cleaned markdown text}

\CommentTok{    Returns:}
\CommentTok{        dict: Dictionary with titles as keys and dictionaries of attributes as values}
\CommentTok{    """}
\NormalTok{    lines }\OperatorTok{=}\NormalTok{ text.split(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    titles\_info }\OperatorTok{=}\NormalTok{ \{\}}

    \ControlFlowTok{for}\NormalTok{ line }\KeywordTok{in}\NormalTok{ lines:}
        \CommentTok{\# Skip empty lines}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ line.strip():}
            \ControlFlowTok{continue}

        \CommentTok{\# Extract title within square or angle brackets}
\NormalTok{        title\_match }\OperatorTok{=}\NormalTok{ re.search(}\VerbatimStringTok{r\textquotesingle{}}\PreprocessorTok{[\textless{}}\CharTok{\textbackslash{}[}\PreprocessorTok{]}\KeywordTok{(}\DecValTok{.}\OperatorTok{+?}\KeywordTok{)}\PreprocessorTok{[\textgreater{}}\CharTok{\textbackslash{}]}\PreprocessorTok{]}\VerbatimStringTok{\textquotesingle{}}\NormalTok{, line)}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ title\_match:}
            \ControlFlowTok{continue}

\NormalTok{        title }\OperatorTok{=}\NormalTok{ title\_match.group(}\DecValTok{1}\NormalTok{)}

        \CommentTok{\# Extract description and metadata}
\NormalTok{        title\_pattern\_in\_line }\OperatorTok{=} \VerbatimStringTok{r\textquotesingle{}}\PreprocessorTok{[\textless{}}\CharTok{\textbackslash{}[}\PreprocessorTok{]}\VerbatimStringTok{\textquotesingle{}} \OperatorTok{+}\NormalTok{ re.escape(title) }\OperatorTok{+} \VerbatimStringTok{r\textquotesingle{}}\PreprocessorTok{[\textgreater{}}\CharTok{\textbackslash{}]}\PreprocessorTok{]}\VerbatimStringTok{:\textquotesingle{}}
\NormalTok{        description\_match }\OperatorTok{=}\NormalTok{ re.search(title\_pattern\_in\_line }\OperatorTok{+} \VerbatimStringTok{r\textquotesingle{}}\DecValTok{\textbackslash{}s}\OperatorTok{*}\KeywordTok{(}\DecValTok{.}\OperatorTok{*}\KeywordTok{)}\VerbatimStringTok{\textquotesingle{}}\NormalTok{, line)}

        \ControlFlowTok{if}\NormalTok{ description\_match:}
\NormalTok{            full\_text }\OperatorTok{=}\NormalTok{ description\_match.group(}\DecValTok{1}\NormalTok{).strip()}

            \CommentTok{\# Split description and metadata at the first "\{"}
            \ControlFlowTok{if} \StringTok{"\{"} \KeywordTok{in}\NormalTok{ full\_text:}
\NormalTok{                split\_index }\OperatorTok{=}\NormalTok{ full\_text.find(}\StringTok{"\{"}\NormalTok{)}
\NormalTok{                description }\OperatorTok{=}\NormalTok{ full\_text[:split\_index].strip()}
\NormalTok{                metadata }\OperatorTok{=}\NormalTok{ full\_text[split\_index:].strip()}
            \ControlFlowTok{else}\NormalTok{:}
                \CommentTok{\# Keep the entire description and no metadata}
\NormalTok{                description }\OperatorTok{=}\NormalTok{ full\_text}
\NormalTok{                metadata }\OperatorTok{=} \StringTok{\textquotesingle{}\textquotesingle{}}  \CommentTok{\# Initialize as empty string}
        \ControlFlowTok{else}\NormalTok{:}
\NormalTok{            description }\OperatorTok{=} \StringTok{\textquotesingle{}\textquotesingle{}}
\NormalTok{            metadata }\OperatorTok{=} \StringTok{\textquotesingle{}\textquotesingle{}}  \CommentTok{\# Ensure metadata is initialized}

        \CommentTok{\# Calculate indentation level based on spaces before + or {-} symbol}
\NormalTok{        indentation }\OperatorTok{=} \DecValTok{0}
        \ControlFlowTok{if} \StringTok{\textquotesingle{}+\textquotesingle{}} \KeywordTok{in}\NormalTok{ line:}
\NormalTok{            symbol\_index }\OperatorTok{=}\NormalTok{ line.find(}\StringTok{\textquotesingle{}+\textquotesingle{}}\NormalTok{)}
            \CommentTok{\# Count spaces before the \textquotesingle{}+\textquotesingle{} symbol}
\NormalTok{            i }\OperatorTok{=}\NormalTok{ symbol\_index }\OperatorTok{{-}} \DecValTok{1}
            \ControlFlowTok{while}\NormalTok{ i }\OperatorTok{\textgreater{}=} \DecValTok{0} \KeywordTok{and}\NormalTok{ line[i] }\OperatorTok{==} \StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{:}
\NormalTok{                indentation }\OperatorTok{+=} \DecValTok{1}
\NormalTok{                i }\OperatorTok{{-}=} \DecValTok{1}
        \ControlFlowTok{elif} \StringTok{\textquotesingle{}{-}\textquotesingle{}} \KeywordTok{in}\NormalTok{ line:}
\NormalTok{            symbol\_index }\OperatorTok{=}\NormalTok{ line.find(}\StringTok{\textquotesingle{}{-}\textquotesingle{}}\NormalTok{)}
            \CommentTok{\# Count spaces before the \textquotesingle{}{-}\textquotesingle{} symbol}
\NormalTok{            i }\OperatorTok{=}\NormalTok{ symbol\_index }\OperatorTok{{-}} \DecValTok{1}
            \ControlFlowTok{while}\NormalTok{ i }\OperatorTok{\textgreater{}=} \DecValTok{0} \KeywordTok{and}\NormalTok{ line[i] }\OperatorTok{==} \StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{:}
\NormalTok{                indentation }\OperatorTok{+=} \DecValTok{1}
\NormalTok{                i }\OperatorTok{{-}=} \DecValTok{1}

        \CommentTok{\# If neither symbol exists, indentation remains 0}

        \ControlFlowTok{if}\NormalTok{ title }\KeywordTok{in}\NormalTok{ titles\_info:}
            \CommentTok{\# Only update description if it\textquotesingle{}s currently empty and we found a new one}
            \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ titles\_info[title][}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{] }\KeywordTok{and}\NormalTok{ description:}
\NormalTok{                titles\_info[title][}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ description}

            \CommentTok{\# Store all indentation levels for this title}
\NormalTok{            titles\_info[title][}\StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{].append(indentation)}

            \CommentTok{\# Keep max indentation for backward compatibility}
            \ControlFlowTok{if}\NormalTok{ indentation }\OperatorTok{\textgreater{}}\NormalTok{ titles\_info[title][}\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{]:}
\NormalTok{                titles\_info[title][}\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ indentation}

            \CommentTok{\# Do NOT update metadata here {-} keep the original metadata}
        \ControlFlowTok{else}\NormalTok{:}
            \CommentTok{\# First time seeing this title, create a new entry}
\NormalTok{            titles\_info[title] }\OperatorTok{=}\NormalTok{ \{}
                \StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{: description,}
                \StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{: indentation,}
                \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{: [indentation],  }\CommentTok{\# Initialize with first indentation level}
                \StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{: [],}
                \StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{: [],}
                \StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{: }\VariableTok{None}\NormalTok{,}
                \StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{: [],  }\CommentTok{\# Initialize an empty list for all occurrences}
                \StringTok{\textquotesingle{}metadata\textquotesingle{}}\NormalTok{: metadata  }\CommentTok{\# Set metadata explicitly from what we found}
\NormalTok{            \}}

    \ControlFlowTok{return}\NormalTok{ titles\_info}

\KeywordTok{def}\NormalTok{ establish\_relationships\_fixed(titles\_info, text):}
    \CommentTok{"""}
\CommentTok{    Establish parent{-}child relationships between titles using BayesDown}
\CommentTok{    indentation rules.}

\CommentTok{    In BayesDown syntax:}
\CommentTok{    {-} More indented nodes (with + symbol) are PARENTS of less indented nodes}
\CommentTok{    {-} The relationship reads as "Effect is caused by Cause" (Effect + Cause)}
\CommentTok{    {-} This aligns with how Bayesian networks represent causality}

\CommentTok{    Args:}
\CommentTok{        titles\_info (dict): Dictionary with information about titles}
\CommentTok{        text (str): Original markdown text (for identifying line numbers)}

\CommentTok{    Returns:}
\CommentTok{        dict: Updated dictionary with parent{-}child relationships}
\CommentTok{    """}
\NormalTok{    lines }\OperatorTok{=}\NormalTok{ text.split(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}

    \CommentTok{\# Dictionary to store line numbers for each title occurrence}
\NormalTok{    title\_occurrences }\OperatorTok{=}\NormalTok{ \{\}}

    \CommentTok{\# Record line number for each title (including multiple occurrences)}
\NormalTok{    line\_number }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ line }\KeywordTok{in}\NormalTok{ lines:}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ line.strip():}
\NormalTok{            line\_number }\OperatorTok{+=} \DecValTok{1}
            \ControlFlowTok{continue}

\NormalTok{        title\_match }\OperatorTok{=}\NormalTok{ re.search(}\VerbatimStringTok{r\textquotesingle{}}\PreprocessorTok{[\textless{}}\CharTok{\textbackslash{}[}\PreprocessorTok{]}\KeywordTok{(}\DecValTok{.}\OperatorTok{+?}\KeywordTok{)}\PreprocessorTok{[\textgreater{}}\CharTok{\textbackslash{}]}\PreprocessorTok{]}\VerbatimStringTok{\textquotesingle{}}\NormalTok{, line)}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ title\_match:}
\NormalTok{            line\_number }\OperatorTok{+=} \DecValTok{1}
            \ControlFlowTok{continue}

\NormalTok{        title }\OperatorTok{=}\NormalTok{ title\_match.group(}\DecValTok{1}\NormalTok{)}

        \CommentTok{\# Store all occurrences of each title with their line numbers}
        \ControlFlowTok{if}\NormalTok{ title }\KeywordTok{not} \KeywordTok{in}\NormalTok{ title\_occurrences:}
\NormalTok{            title\_occurrences[title] }\OperatorTok{=}\NormalTok{ []}
\NormalTok{        title\_occurrences[title].append(line\_number)}

        \CommentTok{\# Store all line numbers where this title appears}
        \ControlFlowTok{if} \StringTok{\textquotesingle{}line\_numbers\textquotesingle{}} \KeywordTok{not} \KeywordTok{in}\NormalTok{ titles\_info[title]:}
\NormalTok{            titles\_info[title][}\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ []}
\NormalTok{        titles\_info[title][}\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{].append(line\_number)}

        \CommentTok{\# For backward compatibility, keep the first occurrence in \textquotesingle{}line\textquotesingle{}}
        \ControlFlowTok{if}\NormalTok{ titles\_info[title][}\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{] }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
\NormalTok{            titles\_info[title][}\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ line\_number}

\NormalTok{        line\_number }\OperatorTok{+=} \DecValTok{1}

    \CommentTok{\# Create an ordered list of all title occurrences with their line numbers}
\NormalTok{    all\_occurrences }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{for}\NormalTok{ title, occurrences }\KeywordTok{in}\NormalTok{ title\_occurrences.items():}
        \ControlFlowTok{for}\NormalTok{ line\_num }\KeywordTok{in}\NormalTok{ occurrences:}
\NormalTok{            all\_occurrences.append((title, line\_num))}

    \CommentTok{\# Sort occurrences by line number}
\NormalTok{    all\_occurrences.sort(key}\OperatorTok{=}\KeywordTok{lambda}\NormalTok{ x: x[}\DecValTok{1}\NormalTok{])}

    \CommentTok{\# Get indentation for each occurrence}
\NormalTok{    occurrence\_indents }\OperatorTok{=}\NormalTok{ \{\}}
    \ControlFlowTok{for}\NormalTok{ title, line\_num }\KeywordTok{in}\NormalTok{ all\_occurrences:}
        \ControlFlowTok{for}\NormalTok{ line }\KeywordTok{in}\NormalTok{ lines[line\_num:line\_num}\OperatorTok{+}\DecValTok{1}\NormalTok{]:  }\CommentTok{\# Only check the current line}
\NormalTok{            indent }\OperatorTok{=} \DecValTok{0}
            \ControlFlowTok{if} \StringTok{\textquotesingle{}+\textquotesingle{}} \KeywordTok{in}\NormalTok{ line:}
\NormalTok{                symbol\_index }\OperatorTok{=}\NormalTok{ line.find(}\StringTok{\textquotesingle{}+\textquotesingle{}}\NormalTok{)}
                \CommentTok{\# Count spaces before the \textquotesingle{}+\textquotesingle{} symbol}
\NormalTok{                j }\OperatorTok{=}\NormalTok{ symbol\_index }\OperatorTok{{-}} \DecValTok{1}
                \ControlFlowTok{while}\NormalTok{ j }\OperatorTok{\textgreater{}=} \DecValTok{0} \KeywordTok{and}\NormalTok{ line[j] }\OperatorTok{==} \StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{:}
\NormalTok{                    indent }\OperatorTok{+=} \DecValTok{1}
\NormalTok{                    j }\OperatorTok{{-}=} \DecValTok{1}
            \ControlFlowTok{elif} \StringTok{\textquotesingle{}{-}\textquotesingle{}} \KeywordTok{in}\NormalTok{ line:}
\NormalTok{                symbol\_index }\OperatorTok{=}\NormalTok{ line.find(}\StringTok{\textquotesingle{}{-}\textquotesingle{}}\NormalTok{)}
                \CommentTok{\# Count spaces before the \textquotesingle{}{-}\textquotesingle{} symbol}
\NormalTok{                j }\OperatorTok{=}\NormalTok{ symbol\_index }\OperatorTok{{-}} \DecValTok{1}
                \ControlFlowTok{while}\NormalTok{ j }\OperatorTok{\textgreater{}=} \DecValTok{0} \KeywordTok{and}\NormalTok{ line[j] }\OperatorTok{==} \StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{:}
\NormalTok{                    indent }\OperatorTok{+=} \DecValTok{1}
\NormalTok{                    j }\OperatorTok{{-}=} \DecValTok{1}
\NormalTok{            occurrence\_indents[(title, line\_num)] }\OperatorTok{=}\NormalTok{ indent}

    \CommentTok{\# Enhanced backward pass for correct parent{-}child relationships}
    \ControlFlowTok{for}\NormalTok{ i, (title, line\_num) }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(all\_occurrences):}
\NormalTok{        current\_indent }\OperatorTok{=}\NormalTok{ occurrence\_indents[(title, line\_num)]}

        \CommentTok{\# Skip root nodes (indentation 0) for processing}
        \ControlFlowTok{if}\NormalTok{ current\_indent }\OperatorTok{==} \DecValTok{0}\NormalTok{:}
            \ControlFlowTok{continue}

        \CommentTok{\# Look for the immediately preceding node with lower indentation}
\NormalTok{        j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}
        \ControlFlowTok{while}\NormalTok{ j }\OperatorTok{\textgreater{}=} \DecValTok{0}\NormalTok{:}
\NormalTok{            prev\_title, prev\_line }\OperatorTok{=}\NormalTok{ all\_occurrences[j]}
\NormalTok{            prev\_indent }\OperatorTok{=}\NormalTok{ occurrence\_indents[(prev\_title, prev\_line)]}

            \CommentTok{\# If we find a node with less indentation, it\textquotesingle{}s a child of current node}
            \ControlFlowTok{if}\NormalTok{ prev\_indent }\OperatorTok{\textless{}}\NormalTok{ current\_indent:}
                \CommentTok{\# In BayesDown:}
                \CommentTok{\# More indented node is a parent (cause) of less indented node (effect)}
                \ControlFlowTok{if}\NormalTok{ title }\KeywordTok{not} \KeywordTok{in}\NormalTok{ titles\_info[prev\_title][}\StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{]:}
\NormalTok{                    titles\_info[prev\_title][}\StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{].append(title)}
                \ControlFlowTok{if}\NormalTok{ prev\_title }\KeywordTok{not} \KeywordTok{in}\NormalTok{ titles\_info[title][}\StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{]:}
\NormalTok{                    titles\_info[title][}\StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{].append(prev\_title)}

                \CommentTok{\# Only need to find the immediate child}
                \CommentTok{\# (closest preceding node with lower indentation)}
                \ControlFlowTok{break}

\NormalTok{            j }\OperatorTok{{-}=} \DecValTok{1}

    \ControlFlowTok{return}\NormalTok{ titles\_info}

\KeywordTok{def}\NormalTok{ convert\_to\_dataframe(titles\_info, ArgDown):}
    \CommentTok{"""}
\CommentTok{    Convert the titles information dictionary to a pandas DataFrame.}

\CommentTok{    Args:}
\CommentTok{        titles\_info (dict): Dictionary with information about titles}
\CommentTok{        ArgDown (bool): If True, extract only structural information without probabilities}

\CommentTok{    Returns:}
\CommentTok{        pandas.DataFrame: Structured data with node information and relationships}
\CommentTok{    """}
    \ControlFlowTok{if}\NormalTok{ ArgDown }\OperatorTok{==} \VariableTok{True}\NormalTok{:}
        \CommentTok{\# For ArgDown, exclude probability columns}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.DataFrame(columns}\OperatorTok{=}\NormalTok{[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{,}
                               \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{])}
    \ControlFlowTok{else}\NormalTok{:}
        \CommentTok{\# For BayesDown, include probability columns}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.DataFrame(columns}\OperatorTok{=}\NormalTok{[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{,}
                               \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{,}
                               \StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{])}

    \ControlFlowTok{for}\NormalTok{ title, info }\KeywordTok{in}\NormalTok{ titles\_info.items():}
        \CommentTok{\# Parse the metadata JSON string into a Python dictionary}
        \ControlFlowTok{if} \StringTok{\textquotesingle{}metadata\textquotesingle{}} \KeywordTok{in}\NormalTok{ info }\KeywordTok{and}\NormalTok{ info[}\StringTok{\textquotesingle{}metadata\textquotesingle{}}\NormalTok{]:}
            \ControlFlowTok{try}\NormalTok{:}
                \CommentTok{\# Only try to parse if metadata is not empty}
                \ControlFlowTok{if}\NormalTok{ info[}\StringTok{\textquotesingle{}metadata\textquotesingle{}}\NormalTok{].strip():}
\NormalTok{                    jsonMetadata }\OperatorTok{=}\NormalTok{ json.loads(info[}\StringTok{\textquotesingle{}metadata\textquotesingle{}}\NormalTok{])}
                    \ControlFlowTok{if}\NormalTok{ ArgDown }\OperatorTok{==} \VariableTok{True}\NormalTok{:}
                        \CommentTok{\# Create the row dictionary with instantiations as}
                        \CommentTok{\# metadata only, no probabilities yet}
\NormalTok{                        row }\OperatorTok{=}\NormalTok{ \{}
                            \StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{: title,}
                            \StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                            \StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                            \StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{, []),}
                            \StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                            \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{, []),}
                            \StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{, []),}
                            \StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{, []),}
                            \CommentTok{\# Extract specific metadata fields,}
                            \CommentTok{\# defaulting to empty if not present}
                            \StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{: jsonMetadata.get(}\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{, []),}
\NormalTok{                        \}}
                    \ControlFlowTok{else}\NormalTok{:}
                        \CommentTok{\# Create dict with probabilities for BayesDown}
\NormalTok{                        row }\OperatorTok{=}\NormalTok{ \{}
                            \StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{: title,}
                            \StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                            \StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                            \StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{, []),}
                            \StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                            \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{, []),}
                            \StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{, []),}
                            \StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{, []),}
                            \CommentTok{\# Extract specific metadata fields, defaulting to empty if not present}
                            \StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{: jsonMetadata.get(}\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{, []),}
                            \StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{: jsonMetadata.get(}\StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{, \{\}),}
                            \StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{: jsonMetadata.get(}\StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{, \{\})}
\NormalTok{                        \}}
                \ControlFlowTok{else}\NormalTok{:}
                    \CommentTok{\# Empty metadata case}
\NormalTok{                    row }\OperatorTok{=}\NormalTok{ \{}
                        \StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{: title,}
                        \StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                        \StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                        \StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{, []),}
                        \StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                        \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{, []),}
                        \StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{, []),}
                        \StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{, []),}
                        \StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{: [],}
                        \StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{: \{\},}
                        \StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{: \{\}}
\NormalTok{                    \}}
            \ControlFlowTok{except}\NormalTok{ json.JSONDecodeError:}
                \CommentTok{\# Handle case where metadata isn\textquotesingle{}t valid JSON}
\NormalTok{                row }\OperatorTok{=}\NormalTok{ \{}
                    \StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{: title,}
                    \StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                    \StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                    \StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{, []),}
                    \StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                    \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{, []),}
                    \StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{, []),}
                    \StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{, []),}
                    \StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{: [],}
                    \StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{: \{\},}
                    \StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{: \{\}}
\NormalTok{                \}}
        \ControlFlowTok{else}\NormalTok{:}
            \CommentTok{\# Handle case where metadata field doesn\textquotesingle{}t exist or is empty}
\NormalTok{            row }\OperatorTok{=}\NormalTok{ \{}
                \StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{: title,}
                \StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                \StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                \StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{, []),}
                \StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{, []),}
                \StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{, []),}
                \StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{, []),}
                \StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{: [],}
                \StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{: \{\},}
                \StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{: \{\}}
\NormalTok{            \}}

        \CommentTok{\# Add the row to the DataFrame}
\NormalTok{        df.loc[}\BuiltInTok{len}\NormalTok{(df)] }\OperatorTok{=}\NormalTok{ row}

    \ControlFlowTok{return}\NormalTok{ df}

\KeywordTok{def}\NormalTok{ add\_no\_parent\_no\_child\_columns\_to\_df(dataframe):}
    \CommentTok{"""}
\CommentTok{    Add No\_Parent and No\_Children boolean columns to the DataFrame to}
\CommentTok{    identify root and leaf nodes.}

\CommentTok{    Args:}
\CommentTok{        dataframe (pandas.DataFrame): The DataFrame to enhance}

\CommentTok{    Returns:}
\CommentTok{        pandas.DataFrame: Enhanced DataFrame with additional boolean columns}
\CommentTok{    """}
\NormalTok{    no\_parent }\OperatorTok{=}\NormalTok{ []}
\NormalTok{    no\_children }\OperatorTok{=}\NormalTok{ []}

    \ControlFlowTok{for}\NormalTok{ \_, row }\KeywordTok{in}\NormalTok{ dataframe.iterrows():}
\NormalTok{        no\_parent.append(}\KeywordTok{not}\NormalTok{ row[}\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{])  }\CommentTok{\# True if Parents list is empty}
\NormalTok{        no\_children.append(}\KeywordTok{not}\NormalTok{ row[}\StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{])  }\CommentTok{\# True if Children list is empty}

\NormalTok{    dataframe[}\StringTok{\textquotesingle{}No\_Parent\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ no\_parent}
\NormalTok{    dataframe[}\StringTok{\textquotesingle{}No\_Children\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ no\_children}

    \ControlFlowTok{return}\NormalTok{ dataframe}

\KeywordTok{def}\NormalTok{ add\_parents\_instantiation\_columns\_to\_df(dataframe):}
    \CommentTok{"""}
\CommentTok{    Add all possible instantiations of parents as a list of lists column}
\CommentTok{    to the DataFrame.}
\CommentTok{    This is crucial for generating conditional probability tables.}

\CommentTok{    Args:}
\CommentTok{        dataframe (pandas.DataFrame): The DataFrame to enhance}

\CommentTok{    Returns:}
\CommentTok{        pandas.DataFrame: Enhanced DataFrame with parent\_instantiations column}
\CommentTok{    """}
    \CommentTok{\# Create a new column to store parent instantiations}
\NormalTok{    parent\_instantiations }\OperatorTok{=}\NormalTok{ []}

    \CommentTok{\# Iterate through each row in the dataframe}
    \ControlFlowTok{for}\NormalTok{ \_, row }\KeywordTok{in}\NormalTok{ dataframe.iterrows():}
\NormalTok{        parents }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{]}
\NormalTok{        parent\_insts }\OperatorTok{=}\NormalTok{ []}

        \CommentTok{\# For each parent, find its instantiations and add to the list}
        \ControlFlowTok{for}\NormalTok{ parent }\KeywordTok{in}\NormalTok{ parents:}
            \CommentTok{\# Find the row where Title matches the parent}
\NormalTok{            parent\_row }\OperatorTok{=}\NormalTok{ dataframe[dataframe[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{] }\OperatorTok{==}\NormalTok{ parent]}

            \CommentTok{\# If parent found in the dataframe}
            \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ parent\_row.empty:}
                \CommentTok{\# Get the instantiations of this parent}
\NormalTok{                parent\_instantiation }\OperatorTok{=}\NormalTok{ parent\_row[}\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{].iloc[}\DecValTok{0}\NormalTok{]}
\NormalTok{                parent\_insts.append(parent\_instantiation)}

        \CommentTok{\# Add the list of parent instantiations to our new column}
\NormalTok{        parent\_instantiations.append(parent\_insts)}

    \CommentTok{\# Add the new column to the dataframe}
\NormalTok{    dataframe[}\StringTok{\textquotesingle{}parent\_instantiations\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ parent\_instantiations}

    \ControlFlowTok{return}\NormalTok{ dataframe}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# example use case:}
\NormalTok{ex\_csv }\OperatorTok{=}\NormalTok{ parse\_markdown\_hierarchy\_fixed(md\_content, ArgDown }\OperatorTok{=} \VariableTok{True}\NormalTok{)}
\NormalTok{ex\_csv}
\end{Highlighting}
\end{Shaded}

\phantomsection\label{example_use_case}
\begin{longtable}[]{@{}lllllllllllll@{}}
\toprule\noalign{}
& Title & Description & line & line\_numbers & indentation &
indentation\_levels & Parents & Children & instantiations & No\_Parent &
No\_Children & parent\_instantiations \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & Existential\_Catastrophe & The destruction of
humanity\textquotesingle s long-term potent... & 0 & {[}0{]} & 0 &
{[}0{]} & {[}{]} & {[}{]} & {[}existential\_catastrophe\_TRUE,
existential\_cat... & True & True & {[}{]} \\
1 & Human\_Disempowerment & Permanent and collective disempowerment of
hum... & 1 & {[}1{]} & 0 & {[}0{]} & {[}Scale\_Of\_Power\_Seeking{]} &
{[}{]} & {[}human\_disempowerment\_TRUE, human\_disempowerme... & False
& True & {[}{[}scale\_of\_power\_seeking\_TRUE, scale\_of\_power\_... \\
2 & Scale\_Of\_Power\_Seeking & Power-seeking by AI systems scaling to
the poi... & 2 & {[}2{]} & 4 & {[}4{]} & {[}Misaligned\_Power\_Seeking,
Corrective\_Feedback{]} & {[}Human\_Disempowerment{]} &
{[}scale\_of\_power\_seeking\_TRUE, scale\_of\_power\_s... & False &
False & {[}{[}misaligned\_power\_seeking\_TRUE, misaligned\_po... \\
3 & Misaligned\_Power\_Seeking & Deployed AI systems seeking power in
unintende... & 3 & {[}3, 21, 23, 25{]} & 8 & {[}8, 0, 0, 0{]} &
{[}APS\_Systems, Difficulty\_Of\_Alignment, Deploym... &
{[}Scale\_Of\_Power\_Seeking{]} & {[}misaligned\_power\_seeking\_TRUE,
misaligned\_pow... & False & False & {[}{[}aps\_systems\_TRUE,
aps\_systems\_FALSE{]}, {[}diffi... \\
4 & APS\_Systems & AI systems with advanced capabilities, agentic... & 4
& {[}4{]} & 12 & {[}12{]} & {[}Advanced\_AI\_Capability,
Agentic\_Planning, Str... & {[}Misaligned\_Power\_Seeking{]} &
{[}aps\_systems\_TRUE, aps\_systems\_FALSE{]} & False & False &
{[}{[}advanced\_ai\_capability\_TRUE, advanced\_ai\_cap... \\
5 & Advanced\_AI\_Capability & AI systems that outperform humans on
tasks tha... & 5 & {[}5{]} & 16 & {[}16{]} & {[}{]} & {[}APS\_Systems{]}
& {[}advanced\_ai\_capability\_TRUE, advanced\_ai\_capa... & True &
False & {[}{]} \\
6 & Agentic\_Planning & AI systems making and executing plans based
on... & 6 & {[}6{]} & 16 & {[}16{]} & {[}{]} & {[}APS\_Systems{]} &
{[}agentic\_planning\_TRUE, agentic\_planning\_FALSE{]} & True & False &
{[}{]} \\
7 & Strategic\_Awareness & AI systems with models accurately
representing... & 7 & {[}7{]} & 16 & {[}16{]} & {[}{]} &
{[}APS\_Systems{]} & {[}strategic\_awareness\_TRUE,
strategic\_awareness... & True & False & {[}{]} \\
8 & Difficulty\_Of\_Alignment & It is harder to build aligned systems
than mis... & 8 & {[}8{]} & 12 & {[}12{]} &
{[}Instrumental\_Convergence, Problems\_With\_Proxi... &
{[}Misaligned\_Power\_Seeking{]} & {[}difficulty\_of\_alignment\_TRUE,
difficulty\_of\_a... & False & False &
{[}{[}instrumental\_convergence\_TRUE, instrumental\_... \\
9 & Instrumental\_Convergence & AI systems with misaligned objectives
tend to ... & 9 & {[}9{]} & 16 & {[}16{]} & {[}{]} &
{[}Difficulty\_Of\_Alignment{]} & {[}instrumental\_convergence\_TRUE,
instrumental\_c... & True & False & {[}{]} \\
10 & Problems\_With\_Proxies & Optimizing for proxy objectives breaks
correla... & 10 & {[}10{]} & 16 & {[}16{]} & {[}{]} &
{[}Difficulty\_Of\_Alignment{]} & {[}problems\_with\_proxies\_TRUE,
problems\_with\_pro... & True & False & {[}{]} \\
11 & Problems\_With\_Search & Search processes can yield systems
pursuing di... & 11 & {[}11{]} & 16 & {[}16{]} & {[}{]} &
{[}Difficulty\_Of\_Alignment{]} & {[}problems\_with\_search\_TRUE,
problems\_with\_sear... & True & False & {[}{]} \\
12 & Deployment\_Decisions & Decisions to deploy potentially misaligned
AI ... & 12 & {[}12{]} & 12 & {[}12{]} & {[}Incentives\_To\_Build\_APS,
Deception\_By\_AI{]} & {[}Misaligned\_Power\_Seeking{]} &
{[}deployment\_decisions\_DEPLOY, deployment\_decis... & False & False &
{[}{[}incentives\_to\_build\_aps\_STRONG, incentives\_t... \\
13 & Incentives\_To\_Build\_APS & Strong incentives to build and deploy
APS syst... & 13 & {[}13{]} & 16 & {[}16{]} & {[}Usefulness\_Of\_APS,
Competitive\_Dynamics{]} & {[}Deployment\_Decisions{]} &
{[}incentives\_to\_build\_aps\_STRONG, incentives\_to... & False & False
& {[}{[}usefulness\_of\_aps\_HIGH, usefulness\_of\_aps\_LO... \\
14 & Usefulness\_Of\_APS & APS systems are very useful for many valuable
... & 14 & {[}14{]} & 20 & {[}20{]} & {[}{]} &
{[}Incentives\_To\_Build\_APS{]} & {[}usefulness\_of\_aps\_HIGH,
usefulness\_of\_aps\_LOW{]} & True & False & {[}{]} \\
15 & Competitive\_Dynamics & Competitive pressures between AI
developers. & 15 & {[}15{]} & 20 & {[}20{]} & {[}{]} &
{[}Incentives\_To\_Build\_APS{]} & {[}competitive\_dynamics\_STRONG,
competitive\_dyna... & True & False & {[}{]} \\
16 & Deception\_By\_AI & AI systems deceiving humans about their true
o... & 16 & {[}16{]} & 16 & {[}16{]} & {[}{]} &
{[}Deployment\_Decisions{]} & {[}deception\_by\_ai\_TRUE,
deception\_by\_ai\_FALSE{]} & True & False & {[}{]} \\
17 & Corrective\_Feedback & Human society implementing corrections after
o... & 17 & {[}17{]} & 8 & {[}8{]} & {[}Warning\_Shots,
Rapid\_Capability\_Escalation{]} & {[}Scale\_Of\_Power\_Seeking{]} &
{[}corrective\_feedback\_EFFECTIVE, corrective\_fee... & False & False &
{[}{[}warning\_shots\_OBSERVED, warning\_shots\_UNOBSE... \\
18 & Warning\_Shots & Observable failures in weaker systems before c...
& 18 & {[}18{]} & 12 & {[}12{]} & {[}{]} & {[}Corrective\_Feedback{]} &
{[}warning\_shots\_OBSERVED, warning\_shots\_UNOBSER... & True & False &
{[}{]} \\
19 & Rapid\_Capability\_Escalation & AI capabilities escalating very
rapidly, allow... & 19 & {[}19{]} & 12 & {[}12{]} & {[}{]} &
{[}Corrective\_Feedback{]} & {[}rapid\_capability\_escalation\_TRUE,
rapid\_capab... & True & False & {[}{]} \\
20 & Barriers\_To\_Understanding & Difficulty in understanding the
internal worki... & 20 & {[}20{]} & 0 & {[}0{]} & {[}{]} & {[}{]} &
{[}barriers\_to\_understanding\_HIGH, barriers\_to\_u... & True & True &
{[}{]} \\
21 & Adversarial\_Dynamics & Potentially adversarial relationships
between ... & 22 & {[}22{]} & 0 & {[}0{]} & {[}{]} & {[}{]} &
{[}adversarial\_dynamics\_TRUE, adversarial\_dynami... & True & True &
{[}{]} \\
22 & Stakes\_Of\_Error & The escalating impact of mistakes with
power-s... & 24 & {[}24{]} & 0 & {[}0{]} & {[}{]} & {[}{]} &
{[}stakes\_of\_error\_HIGH, stakes\_of\_error\_LOW{]} & True & True &
{[}{]} \\
\end{longtable}

example use case

\section{1.8 Store ArgDown Information as `ArgDown.csv'
file}\label{store-argdown-information-as-argdown.csv-file}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Assuming \textquotesingle{}md\_content\textquotesingle{} holds the markdown text}
\CommentTok{\# Store the results of running the function parse\_markdown\_hierarchy(md\_content, ArgDown = True) as the file \textquotesingle{}ArgDown.csv\textquotesingle{}}
\NormalTok{result\_df }\OperatorTok{=}\NormalTok{ parse\_markdown\_hierarchy\_fixed(md\_content, ArgDown }\OperatorTok{=} \VariableTok{True}\NormalTok{)}

\CommentTok{\# Save to CSV}
\NormalTok{result\_df.to\_csv(}\StringTok{\textquotesingle{}ArgDown.csv\textquotesingle{}}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Test if \textquotesingle{}ArgDown.csv\textquotesingle{} has been saved correctly with the correct information}
\CommentTok{\# Load the data from the CSV file}
\NormalTok{argdown\_df }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}ArgDown.csv\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Display the DataFrame}
\BuiltInTok{print}\NormalTok{(argdown\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                          Title  \
0       Existential_Catastrophe   
1          Human_Disempowerment   
2        Scale_Of_Power_Seeking   
3      Misaligned_Power_Seeking   
4                   APS_Systems   
5        Advanced_AI_Capability   
6              Agentic_Planning   
7           Strategic_Awareness   
8       Difficulty_Of_Alignment   
9      Instrumental_Convergence   
10        Problems_With_Proxies   
11         Problems_With_Search   
12         Deployment_Decisions   
13      Incentives_To_Build_APS   
14            Usefulness_Of_APS   
15         Competitive_Dynamics   
16              Deception_By_AI   
17          Corrective_Feedback   
18                Warning_Shots   
19  Rapid_Capability_Escalation   
20    Barriers_To_Understanding   
21         Adversarial_Dynamics   
22              Stakes_Of_Error   

                                          Description  line     line_numbers  \
0   The destruction of humanity's long-term potent...     0              [0]   
1   Permanent and collective disempowerment of hum...     1              [1]   
2   Power-seeking by AI systems scaling to the poi...     2              [2]   
3   Deployed AI systems seeking power in unintende...     3  [3, 21, 23, 25]   
4   AI systems with advanced capabilities, agentic...     4              [4]   
5   AI systems that outperform humans on tasks tha...     5              [5]   
6   AI systems making and executing plans based on...     6              [6]   
7   AI systems with models accurately representing...     7              [7]   
8   It is harder to build aligned systems than mis...     8              [8]   
9   AI systems with misaligned objectives tend to ...     9              [9]   
10  Optimizing for proxy objectives breaks correla...    10             [10]   
11  Search processes can yield systems pursuing di...    11             [11]   
12  Decisions to deploy potentially misaligned AI ...    12             [12]   
13  Strong incentives to build and deploy APS syst...    13             [13]   
14  APS systems are very useful for many valuable ...    14             [14]   
15       Competitive pressures between AI developers.    15             [15]   
16  AI systems deceiving humans about their true o...    16             [16]   
17  Human society implementing corrections after o...    17             [17]   
18  Observable failures in weaker systems before c...    18             [18]   
19  AI capabilities escalating very rapidly, allow...    19             [19]   
20  Difficulty in understanding the internal worki...    20             [20]   
21  Potentially adversarial relationships between ...    22             [22]   
22  The escalating impact of mistakes with power-s...    24             [24]   

    indentation indentation_levels  \
0             0                [0]   
1             0                [0]   
2             4                [4]   
3             8       [8, 0, 0, 0]   
4            12               [12]   
5            16               [16]   
6            16               [16]   
7            16               [16]   
8            12               [12]   
9            16               [16]   
10           16               [16]   
11           16               [16]   
12           12               [12]   
13           16               [16]   
14           20               [20]   
15           20               [20]   
16           16               [16]   
17            8                [8]   
18           12               [12]   
19           12               [12]   
20            0                [0]   
21            0                [0]   
22            0                [0]   

                                              Parents  \
0                                                  []   
1                          ['Scale_Of_Power_Seeking']   
2   ['Misaligned_Power_Seeking', 'Corrective_Feedb...   
3   ['APS_Systems', 'Difficulty_Of_Alignment', 'De...   
4   ['Advanced_AI_Capability', 'Agentic_Planning',...   
5                                                  []   
6                                                  []   
7                                                  []   
8   ['Instrumental_Convergence', 'Problems_With_Pr...   
9                                                  []   
10                                                 []   
11                                                 []   
12     ['Incentives_To_Build_APS', 'Deception_By_AI']   
13      ['Usefulness_Of_APS', 'Competitive_Dynamics']   
14                                                 []   
15                                                 []   
16                                                 []   
17   ['Warning_Shots', 'Rapid_Capability_Escalation']   
18                                                 []   
19                                                 []   
20                                                 []   
21                                                 []   
22                                                 []   

                        Children  \
0                             []   
1                             []   
2       ['Human_Disempowerment']   
3     ['Scale_Of_Power_Seeking']   
4   ['Misaligned_Power_Seeking']   
5                ['APS_Systems']   
6                ['APS_Systems']   
7                ['APS_Systems']   
8   ['Misaligned_Power_Seeking']   
9    ['Difficulty_Of_Alignment']   
10   ['Difficulty_Of_Alignment']   
11   ['Difficulty_Of_Alignment']   
12  ['Misaligned_Power_Seeking']   
13      ['Deployment_Decisions']   
14   ['Incentives_To_Build_APS']   
15   ['Incentives_To_Build_APS']   
16      ['Deployment_Decisions']   
17    ['Scale_Of_Power_Seeking']   
18       ['Corrective_Feedback']   
19       ['Corrective_Feedback']   
20                            []   
21                            []   
22                            []   

                                       instantiations  No_Parent  No_Children  \
0   ['existential_catastrophe_TRUE', 'existential_...       True         True   
1   ['human_disempowerment_TRUE', 'human_disempowe...      False         True   
2   ['scale_of_power_seeking_TRUE', 'scale_of_powe...      False        False   
3   ['misaligned_power_seeking_TRUE', 'misaligned_...      False        False   
4           ['aps_systems_TRUE', 'aps_systems_FALSE']      False        False   
5   ['advanced_ai_capability_TRUE', 'advanced_ai_c...       True        False   
6   ['agentic_planning_TRUE', 'agentic_planning_FA...       True        False   
7   ['strategic_awareness_TRUE', 'strategic_awaren...       True        False   
8   ['difficulty_of_alignment_TRUE', 'difficulty_o...      False        False   
9   ['instrumental_convergence_TRUE', 'instrumenta...       True        False   
10  ['problems_with_proxies_TRUE', 'problems_with_...       True        False   
11  ['problems_with_search_TRUE', 'problems_with_s...       True        False   
12  ['deployment_decisions_DEPLOY', 'deployment_de...      False        False   
13  ['incentives_to_build_aps_STRONG', 'incentives...      False        False   
14  ['usefulness_of_aps_HIGH', 'usefulness_of_aps_...       True        False   
15  ['competitive_dynamics_STRONG', 'competitive_d...       True        False   
16  ['deception_by_ai_TRUE', 'deception_by_ai_FALSE']       True        False   
17  ['corrective_feedback_EFFECTIVE', 'corrective_...      False        False   
18  ['warning_shots_OBSERVED', 'warning_shots_UNOB...       True        False   
19  ['rapid_capability_escalation_TRUE', 'rapid_ca...       True        False   
20  ['barriers_to_understanding_HIGH', 'barriers_t...       True         True   
21  ['adversarial_dynamics_TRUE', 'adversarial_dyn...       True         True   
22    ['stakes_of_error_HIGH', 'stakes_of_error_LOW']       True         True   

                                parent_instantiations  
0                                                  []  
1   [['scale_of_power_seeking_TRUE', 'scale_of_pow...  
2   [['misaligned_power_seeking_TRUE', 'misaligned...  
3   [['aps_systems_TRUE', 'aps_systems_FALSE'], ['...  
4   [['advanced_ai_capability_TRUE', 'advanced_ai_...  
5                                                  []  
6                                                  []  
7                                                  []  
8   [['instrumental_convergence_TRUE', 'instrument...  
9                                                  []  
10                                                 []  
11                                                 []  
12  [['incentives_to_build_aps_STRONG', 'incentive...  
13  [['usefulness_of_aps_HIGH', 'usefulness_of_aps...  
14                                                 []  
15                                                 []  
16                                                 []  
17  [['warning_shots_OBSERVED', 'warning_shots_UNO...  
18                                                 []  
19                                                 []  
20                                                 []  
21                                                 []  
22                                                 []  
\end{verbatim}

\chapter{2 Probability Extractions: ArgDown (.csv) to BayesDown (.md +
plugin JSON
syntax)}\label{probability-extractions-argdown-.csv-to-bayesdown-.md-plugin-json-syntax}

\section{2.0 ArgDown to BayesDown: Adding Probability
Information}\label{argdown-to-bayesdown-adding-probability-information}

\subsection{Process Overview}\label{process-overview-1}

This section implements the second major stage of the AMTAIR pipeline:
enhancing the structured argument representation (ArgDown) with
probability information to create BayesDown.

BayesDown extends ArgDown by adding: 1. Prior probabilities for each
variable (unconditional beliefs) 2. Conditional probabilities
representing the relationships between variables 3. The full parameter
specification needed for a Bayesian network

The process follows these steps: 1. Generate probability questions for
each node and its relationships 2. Create a BayesDown template with
placeholders for these probabilities 3. Answer the probability questions
(manually or via LLM) 4. Substitute the answers into the BayesDown
representation

This enhanced representation contains all the information needed to
construct a formal Bayesian network, enabling probabilistic reasoning
and policy evaluation.

\subsection{What is BayesDown?}\label{what-is-bayesdown}

BayesDown maintains the ArgDown structure but adds probability metadata:

\begin{verbatim}
[Node]: Description. {
"instantiations": ["node_TRUE", "node_FALSE"],
"priors": { "p(node_TRUE)": "0.7", "p(node_FALSE)": "0.3" },
"posteriors": { "p(node_TRUE|parent_TRUE)": "0.9", "p(node_TRUE|parent_FALSE)": "0.4" }
}
\end{verbatim}

The result is a hybrid representation that preserves the narrative
structure of arguments while adding the mathematical precision of
Bayesian networks.

\section{2.1 Probability Extraction Questions --- `ArgDown.csv' to
`ArgDown\_WithQuestions.csv'}\label{probability-extraction-questions-argdown.csv-to-argdown_withquestions.csv}

\phantomsection\label{probability_extraction_questions_generation}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 2.1.0 {-}{-}{-} Probability Extraction Questions Generation {-}{-}{-} [probability\_extraction\_questions\_generation]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Generates probability questions for ArgDown nodes to prepare for BayesDown conversion.}

\CommentTok{This block implements a key step in the pipeline where structure (from ArgDown)}
\CommentTok{is prepared for probability integration (to create BayesDown). It:}

\CommentTok{1. Processes a CSV file containing ArgDown structure}
\CommentTok{2. For each node, generates appropriate probability questions:}
\CommentTok{   {-} Prior probability questions for all nodes}
\CommentTok{   {-} Conditional probability questions for nodes with parents}
\CommentTok{3. Creates a new CSV file with these questions ready for the next stage}

\CommentTok{The generated questions serve as placeholders that will be answered in the}
\CommentTok{probability extraction phase to complete the Bayesian network.}

\CommentTok{DEPENDENCIES: pandas, json, itertools libraries}
\CommentTok{INPUTS: ArgDown CSV file}
\CommentTok{OUTPUTS: Enhanced CSV with probability questions for each node}
\CommentTok{"""}

\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ re}
\ImportTok{import}\NormalTok{ json}
\ImportTok{import}\NormalTok{ itertools}
\ImportTok{from}\NormalTok{ IPython.display }\ImportTok{import}\NormalTok{ Markdown, display}


\KeywordTok{def}\NormalTok{ parse\_instantiations(instantiations\_str):}
    \CommentTok{"""}
\CommentTok{    Parse instantiations from string or list format.}
\CommentTok{    Handles various input formats flexibly.}

\CommentTok{    Args:}
\CommentTok{        instantiations\_str: Instantiations in string or list format}

\CommentTok{    Returns:}
\CommentTok{        list: Parsed instantiations as a list}
\CommentTok{    """}
    \ControlFlowTok{if}\NormalTok{ pd.isna(instantiations\_str) }\KeywordTok{or}\NormalTok{ instantiations\_str }\OperatorTok{==} \StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ []}

    \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(instantiations\_str, }\BuiltInTok{list}\NormalTok{):}
        \ControlFlowTok{return}\NormalTok{ instantiations\_str}

    \ControlFlowTok{try}\NormalTok{:}
        \CommentTok{\# Try to parse as JSON}
        \ControlFlowTok{return}\NormalTok{ json.loads(instantiations\_str)}
    \ControlFlowTok{except}\NormalTok{:}
        \CommentTok{\# Try to parse as string list}
        \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(instantiations\_str, }\BuiltInTok{str}\NormalTok{):}
            \CommentTok{\# Remove brackets and split by comma}
\NormalTok{            clean\_str }\OperatorTok{=}\NormalTok{ instantiations\_str.strip(}\StringTok{\textquotesingle{}[]"}\CharTok{\textbackslash{}\textquotesingle{}}\StringTok{\textquotesingle{}}\NormalTok{)}
            \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ clean\_str:}
                \ControlFlowTok{return}\NormalTok{ []}
            \ControlFlowTok{return}\NormalTok{ [s.strip(}\StringTok{\textquotesingle{} "}\CharTok{\textbackslash{}\textquotesingle{}}\StringTok{\textquotesingle{}}\NormalTok{) }\ControlFlowTok{for}\NormalTok{ s }\KeywordTok{in}\NormalTok{ clean\_str.split(}\StringTok{\textquotesingle{},\textquotesingle{}}\NormalTok{) }\ControlFlowTok{if}\NormalTok{ s.strip()]}

    \ControlFlowTok{return}\NormalTok{ []}

\KeywordTok{def}\NormalTok{ parse\_parents(parents\_str):}
    \CommentTok{"""}
\CommentTok{    Parse parents from string or list format.}
\CommentTok{    Handles various input formats flexibly.}

\CommentTok{    Args:}
\CommentTok{        parents\_str: Parents in string or list format}

\CommentTok{    Returns:}
\CommentTok{        list: Parsed parents as a list}
\CommentTok{    """}
    \ControlFlowTok{if}\NormalTok{ pd.isna(parents\_str) }\KeywordTok{or}\NormalTok{ parents\_str }\OperatorTok{==} \StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ []}

    \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(parents\_str, }\BuiltInTok{list}\NormalTok{):}
        \ControlFlowTok{return}\NormalTok{ parents\_str}

    \ControlFlowTok{try}\NormalTok{:}
        \CommentTok{\# Try to parse as JSON}
        \ControlFlowTok{return}\NormalTok{ json.loads(parents\_str)}
    \ControlFlowTok{except}\NormalTok{:}
        \CommentTok{\# Try to parse as string list}
        \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(parents\_str, }\BuiltInTok{str}\NormalTok{):}
            \CommentTok{\# Remove brackets and split by comma}
\NormalTok{            clean\_str }\OperatorTok{=}\NormalTok{ parents\_str.strip(}\StringTok{\textquotesingle{}[]"}\CharTok{\textbackslash{}\textquotesingle{}}\StringTok{\textquotesingle{}}\NormalTok{)}
            \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ clean\_str:}
                \ControlFlowTok{return}\NormalTok{ []}
            \ControlFlowTok{return}\NormalTok{ [s.strip(}\StringTok{\textquotesingle{} "}\CharTok{\textbackslash{}\textquotesingle{}}\StringTok{\textquotesingle{}}\NormalTok{) }\ControlFlowTok{for}\NormalTok{ s }\KeywordTok{in}\NormalTok{ clean\_str.split(}\StringTok{\textquotesingle{},\textquotesingle{}}\NormalTok{) }\ControlFlowTok{if}\NormalTok{ s.strip()]}

    \ControlFlowTok{return}\NormalTok{ []}

\KeywordTok{def}\NormalTok{ get\_parent\_instantiations(parent, df):}
    \CommentTok{"""}
\CommentTok{    Get the instantiations for a parent node from the DataFrame.}
\CommentTok{    Returns default instantiations if not found.}

\CommentTok{    Args:}
\CommentTok{        parent (str): Parent node name}
\CommentTok{        df (DataFrame): DataFrame containing node information}

\CommentTok{    Returns:}
\CommentTok{        list: Instantiations for the parent node}
\CommentTok{    """}
\NormalTok{    parent\_row }\OperatorTok{=}\NormalTok{ df[df[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{] }\OperatorTok{==}\NormalTok{ parent]}
    \ControlFlowTok{if}\NormalTok{ parent\_row.empty:}
        \ControlFlowTok{return}\NormalTok{ [}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{parent}\SpecialCharTok{\}}\SpecialStringTok{\_TRUE"}\NormalTok{, }\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{parent}\SpecialCharTok{\}}\SpecialStringTok{\_FALSE"}\NormalTok{]}

\NormalTok{    instantiations }\OperatorTok{=}\NormalTok{ parse\_instantiations(parent\_row.iloc[}\DecValTok{0}\NormalTok{][}\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{])}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ instantiations:}
        \ControlFlowTok{return}\NormalTok{ [}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{parent}\SpecialCharTok{\}}\SpecialStringTok{\_TRUE"}\NormalTok{, }\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{parent}\SpecialCharTok{\}}\SpecialStringTok{\_FALSE"}\NormalTok{]}

    \ControlFlowTok{return}\NormalTok{ instantiations}

\KeywordTok{def}\NormalTok{ generate\_instantiation\_questions(title, instantiation, parents, df):}
    \CommentTok{"""}
\CommentTok{    Generate questions for a specific instantiation of a node.}

\CommentTok{    Args:}
\CommentTok{        title (str): The title of the node}
\CommentTok{        instantiation (str): The specific instantiation (e.g., "title\_TRUE")}
\CommentTok{        parents (list): List of parent nodes}
\CommentTok{        df (DataFrame): The full DataFrame for looking up parent instantiations}

\CommentTok{    Returns:}
\CommentTok{        dict: Dictionary mapping questions to estimate keys}
\CommentTok{    """}
\NormalTok{    questions }\OperatorTok{=}\NormalTok{ \{\}}

    \CommentTok{\# Always generate a prior probability question, regardless of parents}
\NormalTok{    prior\_question }\OperatorTok{=} \SpecialStringTok{f"What is the probability for }\SpecialCharTok{\{}\NormalTok{title}\SpecialCharTok{\}}\SpecialStringTok{=}\SpecialCharTok{\{}\NormalTok{instantiation}\SpecialCharTok{\}}\SpecialStringTok{?"}
\NormalTok{    questions[prior\_question] }\OperatorTok{=} \StringTok{\textquotesingle{}prior\textquotesingle{}} \CommentTok{\# Question is the key, \textquotesingle{}prior\textquotesingle{} is the value}

    \CommentTok{\# If no parents, return only the prior question}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ parents:}
        \ControlFlowTok{return}\NormalTok{ questions}

    \CommentTok{\# For nodes with parents, generate conditional probability questions}
    \CommentTok{\# Get all combinations of parent instantiations}
\NormalTok{    parent\_instantiations }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{for}\NormalTok{ parent }\KeywordTok{in}\NormalTok{ parents:}
\NormalTok{        parent\_insts }\OperatorTok{=}\NormalTok{ get\_parent\_instantiations(parent, df)}
\NormalTok{        parent\_instantiations.append([(parent, inst) }\ControlFlowTok{for}\NormalTok{ inst }\KeywordTok{in}\NormalTok{ parent\_insts])}

    \CommentTok{\# Generate all combinations}
\NormalTok{    all\_combinations }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(itertools.product(}\OperatorTok{*}\NormalTok{parent\_instantiations))}

    \CommentTok{\# Create conditional probability questions for each combination}
    \CommentTok{\# and use questions as keys, estimate\_i as values}
    \ControlFlowTok{for}\NormalTok{ i, combination }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(all\_combinations):}
\NormalTok{        condition\_str }\OperatorTok{=} \StringTok{", "}\NormalTok{.join([}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{parent}\SpecialCharTok{\}}\SpecialStringTok{=}\SpecialCharTok{\{}\NormalTok{inst}\SpecialCharTok{\}}\SpecialStringTok{"} \ControlFlowTok{for}\NormalTok{ parent, inst }\KeywordTok{in}\NormalTok{ combination])}
\NormalTok{        question }\OperatorTok{=} \SpecialStringTok{f"What is the probability for }\SpecialCharTok{\{}\NormalTok{title}\SpecialCharTok{\}}\SpecialStringTok{=}\SpecialCharTok{\{}\NormalTok{instantiation}\SpecialCharTok{\}}\SpecialStringTok{ if }\SpecialCharTok{\{}\NormalTok{condition\_str}\SpecialCharTok{\}}\SpecialStringTok{?"}
\NormalTok{        questions[question] }\OperatorTok{=} \SpecialStringTok{f\textquotesingle{}estimate\_}\SpecialCharTok{\{}\NormalTok{i }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{\textquotesingle{}}  \CommentTok{\# Question is the key,}
                                                   \CommentTok{\# estimate\_i is the value}

    \ControlFlowTok{return}\NormalTok{ questions}


\KeywordTok{def}\NormalTok{ generate\_argdown\_with\_questions(argdown\_csv\_path, output\_csv\_path):}
    \CommentTok{"""}
\CommentTok{    Generate probability questions based on the ArgDown CSV file and save}
\CommentTok{    to a new CSV file.}

\CommentTok{    Args:}
\CommentTok{        argdown\_csv\_path (str): Path to the input ArgDown CSV file}
\CommentTok{        output\_csv\_path (str): Path to save the output CSV file with questions}

\CommentTok{    Returns:}
\CommentTok{        DataFrame: Enhanced DataFrame with probability questions}

\CommentTok{    Raises:}
\CommentTok{        Exception: If CSV loading fails or required columns are missing}
\CommentTok{    """}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Loading ArgDown CSV from }\SpecialCharTok{\{}\NormalTok{argdown\_csv\_path}\SpecialCharTok{\}}\SpecialStringTok{..."}\NormalTok{)}

    \CommentTok{\# Load the ArgDown CSV file}
    \ControlFlowTok{try}\NormalTok{:}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.read\_csv(argdown\_csv\_path)}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Successfully loaded CSV with }\SpecialCharTok{\{}\BuiltInTok{len}\NormalTok{(df)}\SpecialCharTok{\}}\SpecialStringTok{ rows."}\NormalTok{)}
    \ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
        \ControlFlowTok{raise} \PreprocessorTok{Exception}\NormalTok{(}\SpecialStringTok{f"Error loading ArgDown CSV: }\SpecialCharTok{\{}\NormalTok{e}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

    \CommentTok{\# Validate required columns}
\NormalTok{    required\_columns }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{]}
\NormalTok{    missing\_columns }\OperatorTok{=}\NormalTok{ [col }\ControlFlowTok{for}\NormalTok{ col }\KeywordTok{in}\NormalTok{ required\_columns }\ControlFlowTok{if}\NormalTok{ col }\KeywordTok{not} \KeywordTok{in}\NormalTok{ df.columns]}
    \ControlFlowTok{if}\NormalTok{ missing\_columns:}
        \ControlFlowTok{raise} \PreprocessorTok{Exception}\NormalTok{(}\SpecialStringTok{f"Missing required columns: }\SpecialCharTok{\{}\StringTok{\textquotesingle{}, \textquotesingle{}}\SpecialCharTok{.}\NormalTok{join(missing\_columns)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

    \CommentTok{\# Initialize columns for questions}
\NormalTok{    df[}\StringTok{\textquotesingle{}Generate\_Positive\_Instantiation\_Questions\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \VariableTok{None}
\NormalTok{    df[}\StringTok{\textquotesingle{}Generate\_Negative\_Instantiation\_Questions\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \VariableTok{None}

    \BuiltInTok{print}\NormalTok{(}\StringTok{"Generating probability questions for each node..."}\NormalTok{)}

    \CommentTok{\# Process each row to generate questions}
    \ControlFlowTok{for}\NormalTok{ idx, row }\KeywordTok{in}\NormalTok{ df.iterrows():}
\NormalTok{        title }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{]}
\NormalTok{        instantiations }\OperatorTok{=}\NormalTok{ parse\_instantiations(row[}\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{])}
\NormalTok{        parents }\OperatorTok{=}\NormalTok{ parse\_parents(row[}\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{])}

        \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(instantiations) }\OperatorTok{\textless{}} \DecValTok{2}\NormalTok{:}
            \CommentTok{\# Default instantiations if not provided}
\NormalTok{            instantiations }\OperatorTok{=}\NormalTok{ [}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{title}\SpecialCharTok{\}}\SpecialStringTok{\_TRUE"}\NormalTok{, }\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{title}\SpecialCharTok{\}}\SpecialStringTok{\_FALSE"}\NormalTok{]}

        \CommentTok{\# Generate positive instantiation questions}
\NormalTok{        positive\_questions }\OperatorTok{=}\NormalTok{ generate\_instantiation\_questions(title, instantiations[}\DecValTok{0}\NormalTok{], parents, df)}

        \CommentTok{\# Generate negative instantiation questions}
\NormalTok{        negative\_questions }\OperatorTok{=}\NormalTok{ generate\_instantiation\_questions(title, instantiations[}\DecValTok{1}\NormalTok{], parents, df)}

        \CommentTok{\# Update the DataFrame}
\NormalTok{        df.at[idx, }\StringTok{\textquotesingle{}Generate\_Positive\_Instantiation\_Questions\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ json.dumps(positive\_questions)}
\NormalTok{        df.at[idx, }\StringTok{\textquotesingle{}Generate\_Negative\_Instantiation\_Questions\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ json.dumps(negative\_questions)}

    \CommentTok{\# Save the enhanced DataFrame}
\NormalTok{    df.to\_csv(output\_csv\_path, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Generated questions saved to }\SpecialCharTok{\{}\NormalTok{output\_csv\_path}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

    \ControlFlowTok{return}\NormalTok{ df}

\CommentTok{\# Example usage:}
\NormalTok{df\_with\_questions }\OperatorTok{=}\NormalTok{ generate\_argdown\_with\_questions(}\StringTok{"ArgDown.csv"}\NormalTok{, }\StringTok{"ArgDown\_WithQuestions.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Loading ArgDown CSV from ArgDown.csv...
Successfully loaded CSV with 23 rows.
Generating probability questions for each node...
Generated questions saved to ArgDown_WithQuestions.csv
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load the data from the ArgDown\_WithQuestions CSV file}
\NormalTok{argdown\_with\_questions\_df }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}ArgDown\_WithQuestions.csv\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Display the DataFrame}
\BuiltInTok{print}\NormalTok{(argdown\_with\_questions\_df)}
\NormalTok{argdown\_with\_questions\_df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                          Title  \
0       Existential_Catastrophe   
1          Human_Disempowerment   
2        Scale_Of_Power_Seeking   
3      Misaligned_Power_Seeking   
4                   APS_Systems   
5        Advanced_AI_Capability   
6              Agentic_Planning   
7           Strategic_Awareness   
8       Difficulty_Of_Alignment   
9      Instrumental_Convergence   
10        Problems_With_Proxies   
11         Problems_With_Search   
12         Deployment_Decisions   
13      Incentives_To_Build_APS   
14            Usefulness_Of_APS   
15         Competitive_Dynamics   
16              Deception_By_AI   
17          Corrective_Feedback   
18                Warning_Shots   
19  Rapid_Capability_Escalation   
20    Barriers_To_Understanding   
21         Adversarial_Dynamics   
22              Stakes_Of_Error   

                                          Description  line     line_numbers  \
0   The destruction of humanity's long-term potent...     0              [0]   
1   Permanent and collective disempowerment of hum...     1              [1]   
2   Power-seeking by AI systems scaling to the poi...     2              [2]   
3   Deployed AI systems seeking power in unintende...     3  [3, 21, 23, 25]   
4   AI systems with advanced capabilities, agentic...     4              [4]   
5   AI systems that outperform humans on tasks tha...     5              [5]   
6   AI systems making and executing plans based on...     6              [6]   
7   AI systems with models accurately representing...     7              [7]   
8   It is harder to build aligned systems than mis...     8              [8]   
9   AI systems with misaligned objectives tend to ...     9              [9]   
10  Optimizing for proxy objectives breaks correla...    10             [10]   
11  Search processes can yield systems pursuing di...    11             [11]   
12  Decisions to deploy potentially misaligned AI ...    12             [12]   
13  Strong incentives to build and deploy APS syst...    13             [13]   
14  APS systems are very useful for many valuable ...    14             [14]   
15       Competitive pressures between AI developers.    15             [15]   
16  AI systems deceiving humans about their true o...    16             [16]   
17  Human society implementing corrections after o...    17             [17]   
18  Observable failures in weaker systems before c...    18             [18]   
19  AI capabilities escalating very rapidly, allow...    19             [19]   
20  Difficulty in understanding the internal worki...    20             [20]   
21  Potentially adversarial relationships between ...    22             [22]   
22  The escalating impact of mistakes with power-s...    24             [24]   

    indentation indentation_levels  \
0             0                [0]   
1             0                [0]   
2             4                [4]   
3             8       [8, 0, 0, 0]   
4            12               [12]   
5            16               [16]   
6            16               [16]   
7            16               [16]   
8            12               [12]   
9            16               [16]   
10           16               [16]   
11           16               [16]   
12           12               [12]   
13           16               [16]   
14           20               [20]   
15           20               [20]   
16           16               [16]   
17            8                [8]   
18           12               [12]   
19           12               [12]   
20            0                [0]   
21            0                [0]   
22            0                [0]   

                                              Parents  \
0                                                  []   
1                          ['Scale_Of_Power_Seeking']   
2   ['Misaligned_Power_Seeking', 'Corrective_Feedb...   
3   ['APS_Systems', 'Difficulty_Of_Alignment', 'De...   
4   ['Advanced_AI_Capability', 'Agentic_Planning',...   
5                                                  []   
6                                                  []   
7                                                  []   
8   ['Instrumental_Convergence', 'Problems_With_Pr...   
9                                                  []   
10                                                 []   
11                                                 []   
12     ['Incentives_To_Build_APS', 'Deception_By_AI']   
13      ['Usefulness_Of_APS', 'Competitive_Dynamics']   
14                                                 []   
15                                                 []   
16                                                 []   
17   ['Warning_Shots', 'Rapid_Capability_Escalation']   
18                                                 []   
19                                                 []   
20                                                 []   
21                                                 []   
22                                                 []   

                        Children  \
0                             []   
1                             []   
2       ['Human_Disempowerment']   
3     ['Scale_Of_Power_Seeking']   
4   ['Misaligned_Power_Seeking']   
5                ['APS_Systems']   
6                ['APS_Systems']   
7                ['APS_Systems']   
8   ['Misaligned_Power_Seeking']   
9    ['Difficulty_Of_Alignment']   
10   ['Difficulty_Of_Alignment']   
11   ['Difficulty_Of_Alignment']   
12  ['Misaligned_Power_Seeking']   
13      ['Deployment_Decisions']   
14   ['Incentives_To_Build_APS']   
15   ['Incentives_To_Build_APS']   
16      ['Deployment_Decisions']   
17    ['Scale_Of_Power_Seeking']   
18       ['Corrective_Feedback']   
19       ['Corrective_Feedback']   
20                            []   
21                            []   
22                            []   

                                       instantiations  No_Parent  No_Children  \
0   ['existential_catastrophe_TRUE', 'existential_...       True         True   
1   ['human_disempowerment_TRUE', 'human_disempowe...      False         True   
2   ['scale_of_power_seeking_TRUE', 'scale_of_powe...      False        False   
3   ['misaligned_power_seeking_TRUE', 'misaligned_...      False        False   
4           ['aps_systems_TRUE', 'aps_systems_FALSE']      False        False   
5   ['advanced_ai_capability_TRUE', 'advanced_ai_c...       True        False   
6   ['agentic_planning_TRUE', 'agentic_planning_FA...       True        False   
7   ['strategic_awareness_TRUE', 'strategic_awaren...       True        False   
8   ['difficulty_of_alignment_TRUE', 'difficulty_o...      False        False   
9   ['instrumental_convergence_TRUE', 'instrumenta...       True        False   
10  ['problems_with_proxies_TRUE', 'problems_with_...       True        False   
11  ['problems_with_search_TRUE', 'problems_with_s...       True        False   
12  ['deployment_decisions_DEPLOY', 'deployment_de...      False        False   
13  ['incentives_to_build_aps_STRONG', 'incentives...      False        False   
14  ['usefulness_of_aps_HIGH', 'usefulness_of_aps_...       True        False   
15  ['competitive_dynamics_STRONG', 'competitive_d...       True        False   
16  ['deception_by_ai_TRUE', 'deception_by_ai_FALSE']       True        False   
17  ['corrective_feedback_EFFECTIVE', 'corrective_...      False        False   
18  ['warning_shots_OBSERVED', 'warning_shots_UNOB...       True        False   
19  ['rapid_capability_escalation_TRUE', 'rapid_ca...       True        False   
20  ['barriers_to_understanding_HIGH', 'barriers_t...       True         True   
21  ['adversarial_dynamics_TRUE', 'adversarial_dyn...       True         True   
22    ['stakes_of_error_HIGH', 'stakes_of_error_LOW']       True         True   

                                parent_instantiations  \
0                                                  []   
1   [['scale_of_power_seeking_TRUE', 'scale_of_pow...   
2   [['misaligned_power_seeking_TRUE', 'misaligned...   
3   [['aps_systems_TRUE', 'aps_systems_FALSE'], ['...   
4   [['advanced_ai_capability_TRUE', 'advanced_ai_...   
5                                                  []   
6                                                  []   
7                                                  []   
8   [['instrumental_convergence_TRUE', 'instrument...   
9                                                  []   
10                                                 []   
11                                                 []   
12  [['incentives_to_build_aps_STRONG', 'incentive...   
13  [['usefulness_of_aps_HIGH', 'usefulness_of_aps...   
14                                                 []   
15                                                 []   
16                                                 []   
17  [['warning_shots_OBSERVED', 'warning_shots_UNO...   
18                                                 []   
19                                                 []   
20                                                 []   
21                                                 []   
22                                                 []   

            Generate_Positive_Instantiation_Questions  \
0   {"What is the probability for Existential_Cata...   
1   {"What is the probability for Human_Disempower...   
2   {"What is the probability for Scale_Of_Power_S...   
3   {"What is the probability for Misaligned_Power...   
4   {"What is the probability for APS_Systems=aps_...   
5   {"What is the probability for Advanced_AI_Capa...   
6   {"What is the probability for Agentic_Planning...   
7   {"What is the probability for Strategic_Awaren...   
8   {"What is the probability for Difficulty_Of_Al...   
9   {"What is the probability for Instrumental_Con...   
10  {"What is the probability for Problems_With_Pr...   
11  {"What is the probability for Problems_With_Se...   
12  {"What is the probability for Deployment_Decis...   
13  {"What is the probability for Incentives_To_Bu...   
14  {"What is the probability for Usefulness_Of_AP...   
15  {"What is the probability for Competitive_Dyna...   
16  {"What is the probability for Deception_By_AI=...   
17  {"What is the probability for Corrective_Feedb...   
18  {"What is the probability for Warning_Shots=wa...   
19  {"What is the probability for Rapid_Capability...   
20  {"What is the probability for Barriers_To_Unde...   
21  {"What is the probability for Adversarial_Dyna...   
22  {"What is the probability for Stakes_Of_Error=...   

            Generate_Negative_Instantiation_Questions  
0   {"What is the probability for Existential_Cata...  
1   {"What is the probability for Human_Disempower...  
2   {"What is the probability for Scale_Of_Power_S...  
3   {"What is the probability for Misaligned_Power...  
4   {"What is the probability for APS_Systems=aps_...  
5   {"What is the probability for Advanced_AI_Capa...  
6   {"What is the probability for Agentic_Planning...  
7   {"What is the probability for Strategic_Awaren...  
8   {"What is the probability for Difficulty_Of_Al...  
9   {"What is the probability for Instrumental_Con...  
10  {"What is the probability for Problems_With_Pr...  
11  {"What is the probability for Problems_With_Se...  
12  {"What is the probability for Deployment_Decis...  
13  {"What is the probability for Incentives_To_Bu...  
14  {"What is the probability for Usefulness_Of_AP...  
15  {"What is the probability for Competitive_Dyna...  
16  {"What is the probability for Deception_By_AI=...  
17  {"What is the probability for Corrective_Feedb...  
18  {"What is the probability for Warning_Shots=wa...  
19  {"What is the probability for Rapid_Capability...  
20  {"What is the probability for Barriers_To_Unde...  
21  {"What is the probability for Adversarial_Dyna...  
22  {"What is the probability for Stakes_Of_Error=...  
\end{verbatim}

\begin{longtable}[]{@{}lllllllllllllll@{}}
\toprule\noalign{}
& Title & Description & line & line\_numbers & indentation &
indentation\_levels & Parents & Children & instantiations & No\_Parent &
No\_Children & parent\_instantiations &
Generate\_Positive\_Instantiation\_Questions &
Generate\_Negative\_Instantiation\_Questions \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & Existential\_Catastrophe & The destruction of
humanity\textquotesingle s long-term potent... & 0 & {[}0{]} & 0 &
{[}0{]} & {[}{]} & {[}{]} &
{[}\textquotesingle existential\_catastrophe\_TRUE\textquotesingle,
\textquotesingle existential\_... & True & True & {[}{]} & \{"What is
the probability for Existential\_Cata... & \{"What is the probability
for Existential\_Cata... \\
1 & Human\_Disempowerment & Permanent and collective disempowerment of
hum... & 1 & {[}1{]} & 0 & {[}0{]} &
{[}\textquotesingle Scale\_Of\_Power\_Seeking\textquotesingle{]} &
{[}{]} &
{[}\textquotesingle human\_disempowerment\_TRUE\textquotesingle,
\textquotesingle human\_disempowe... & False & True &
{[}{[}\textquotesingle scale\_of\_power\_seeking\_TRUE\textquotesingle,
\textquotesingle scale\_of\_pow... & \{"What is the probability for
Human\_Disempower... & \{"What is the probability for
Human\_Disempower... \\
2 & Scale\_Of\_Power\_Seeking & Power-seeking by AI systems scaling to
the poi... & 2 & {[}2{]} & 4 & {[}4{]} &
{[}\textquotesingle Misaligned\_Power\_Seeking\textquotesingle,
\textquotesingle Corrective\_Feedb... &
{[}\textquotesingle Human\_Disempowerment\textquotesingle{]} &
{[}\textquotesingle scale\_of\_power\_seeking\_TRUE\textquotesingle,
\textquotesingle scale\_of\_powe... & False & False &
{[}{[}\textquotesingle misaligned\_power\_seeking\_TRUE\textquotesingle,
\textquotesingle misaligned... & \{"What is the probability for
Scale\_Of\_Power\_S... & \{"What is the probability for
Scale\_Of\_Power\_S... \\
3 & Misaligned\_Power\_Seeking & Deployed AI systems seeking power in
unintende... & 3 & {[}3, 21, 23, 25{]} & 8 & {[}8, 0, 0, 0{]} &
{[}\textquotesingle APS\_Systems\textquotesingle,
\textquotesingle Difficulty\_Of\_Alignment\textquotesingle,
\textquotesingle De... &
{[}\textquotesingle Scale\_Of\_Power\_Seeking\textquotesingle{]} &
{[}\textquotesingle misaligned\_power\_seeking\_TRUE\textquotesingle,
\textquotesingle misaligned\_... & False & False &
{[}{[}\textquotesingle aps\_systems\_TRUE\textquotesingle,
\textquotesingle aps\_systems\_FALSE\textquotesingle{]},
{[}\textquotesingle... & \{"What is the probability for
Misaligned\_Power... & \{"What is the probability for
Misaligned\_Power... \\
4 & APS\_Systems & AI systems with advanced capabilities, agentic... & 4
& {[}4{]} & 12 & {[}12{]} &
{[}\textquotesingle Advanced\_AI\_Capability\textquotesingle,
\textquotesingle Agentic\_Planning\textquotesingle,... &
{[}\textquotesingle Misaligned\_Power\_Seeking\textquotesingle{]} &
{[}\textquotesingle aps\_systems\_TRUE\textquotesingle,
\textquotesingle aps\_systems\_FALSE\textquotesingle{]} & False & False
& {[}{[}\textquotesingle advanced\_ai\_capability\_TRUE\textquotesingle,
\textquotesingle advanced\_ai\_... & \{"What is the probability for
APS\_Systems=aps\_... & \{"What is the probability for
APS\_Systems=aps\_... \\
5 & Advanced\_AI\_Capability & AI systems that outperform humans on
tasks tha... & 5 & {[}5{]} & 16 & {[}16{]} & {[}{]} &
{[}\textquotesingle APS\_Systems\textquotesingle{]} &
{[}\textquotesingle advanced\_ai\_capability\_TRUE\textquotesingle,
\textquotesingle advanced\_ai\_c... & True & False & {[}{]} & \{"What is
the probability for Advanced\_AI\_Capa... & \{"What is the probability
for Advanced\_AI\_Capa... \\
6 & Agentic\_Planning & AI systems making and executing plans based
on... & 6 & {[}6{]} & 16 & {[}16{]} & {[}{]} &
{[}\textquotesingle APS\_Systems\textquotesingle{]} &
{[}\textquotesingle agentic\_planning\_TRUE\textquotesingle,
\textquotesingle agentic\_planning\_FA... & True & False & {[}{]} &
\{"What is the probability for Agentic\_Planning... & \{"What is the
probability for Agentic\_Planning... \\
7 & Strategic\_Awareness & AI systems with models accurately
representing... & 7 & {[}7{]} & 16 & {[}16{]} & {[}{]} &
{[}\textquotesingle APS\_Systems\textquotesingle{]} &
{[}\textquotesingle strategic\_awareness\_TRUE\textquotesingle,
\textquotesingle strategic\_awaren... & True & False & {[}{]} & \{"What
is the probability for Strategic\_Awaren... & \{"What is the probability
for Strategic\_Awaren... \\
8 & Difficulty\_Of\_Alignment & It is harder to build aligned systems
than mis... & 8 & {[}8{]} & 12 & {[}12{]} &
{[}\textquotesingle Instrumental\_Convergence\textquotesingle,
\textquotesingle Problems\_With\_Pr... &
{[}\textquotesingle Misaligned\_Power\_Seeking\textquotesingle{]} &
{[}\textquotesingle difficulty\_of\_alignment\_TRUE\textquotesingle,
\textquotesingle difficulty\_o... & False & False &
{[}{[}\textquotesingle instrumental\_convergence\_TRUE\textquotesingle,
\textquotesingle instrument... & \{"What is the probability for
Difficulty\_Of\_Al... & \{"What is the probability for
Difficulty\_Of\_Al... \\
9 & Instrumental\_Convergence & AI systems with misaligned objectives
tend to ... & 9 & {[}9{]} & 16 & {[}16{]} & {[}{]} &
{[}\textquotesingle Difficulty\_Of\_Alignment\textquotesingle{]} &
{[}\textquotesingle instrumental\_convergence\_TRUE\textquotesingle,
\textquotesingle instrumenta... & True & False & {[}{]} & \{"What is the
probability for Instrumental\_Con... & \{"What is the probability for
Instrumental\_Con... \\
10 & Problems\_With\_Proxies & Optimizing for proxy objectives breaks
correla... & 10 & {[}10{]} & 16 & {[}16{]} & {[}{]} &
{[}\textquotesingle Difficulty\_Of\_Alignment\textquotesingle{]} &
{[}\textquotesingle problems\_with\_proxies\_TRUE\textquotesingle,
\textquotesingle problems\_with\_... & True & False & {[}{]} & \{"What
is the probability for Problems\_With\_Pr... & \{"What is the
probability for Problems\_With\_Pr... \\
11 & Problems\_With\_Search & Search processes can yield systems
pursuing di... & 11 & {[}11{]} & 16 & {[}16{]} & {[}{]} &
{[}\textquotesingle Difficulty\_Of\_Alignment\textquotesingle{]} &
{[}\textquotesingle problems\_with\_search\_TRUE\textquotesingle,
\textquotesingle problems\_with\_s... & True & False & {[}{]} & \{"What
is the probability for Problems\_With\_Se... & \{"What is the
probability for Problems\_With\_Se... \\
12 & Deployment\_Decisions & Decisions to deploy potentially misaligned
AI ... & 12 & {[}12{]} & 12 & {[}12{]} &
{[}\textquotesingle Incentives\_To\_Build\_APS\textquotesingle,
\textquotesingle Deception\_By\_AI\textquotesingle{]} &
{[}\textquotesingle Misaligned\_Power\_Seeking\textquotesingle{]} &
{[}\textquotesingle deployment\_decisions\_DEPLOY\textquotesingle,
\textquotesingle deployment\_de... & False & False &
{[}{[}\textquotesingle incentives\_to\_build\_aps\_STRONG\textquotesingle,
\textquotesingle incentive... & \{"What is the probability for
Deployment\_Decis... & \{"What is the probability for
Deployment\_Decis... \\
13 & Incentives\_To\_Build\_APS & Strong incentives to build and deploy
APS syst... & 13 & {[}13{]} & 16 & {[}16{]} &
{[}\textquotesingle Usefulness\_Of\_APS\textquotesingle,
\textquotesingle Competitive\_Dynamics\textquotesingle{]} &
{[}\textquotesingle Deployment\_Decisions\textquotesingle{]} &
{[}\textquotesingle incentives\_to\_build\_aps\_STRONG\textquotesingle,
\textquotesingle incentives... & False & False &
{[}{[}\textquotesingle usefulness\_of\_aps\_HIGH\textquotesingle,
\textquotesingle usefulness\_of\_aps... & \{"What is the probability for
Incentives\_To\_Bu... & \{"What is the probability for
Incentives\_To\_Bu... \\
14 & Usefulness\_Of\_APS & APS systems are very useful for many valuable
... & 14 & {[}14{]} & 20 & {[}20{]} & {[}{]} &
{[}\textquotesingle Incentives\_To\_Build\_APS\textquotesingle{]} &
{[}\textquotesingle usefulness\_of\_aps\_HIGH\textquotesingle,
\textquotesingle usefulness\_of\_aps\_... & True & False & {[}{]} &
\{"What is the probability for Usefulness\_Of\_AP... & \{"What is the
probability for Usefulness\_Of\_AP... \\
15 & Competitive\_Dynamics & Competitive pressures between AI
developers. & 15 & {[}15{]} & 20 & {[}20{]} & {[}{]} &
{[}\textquotesingle Incentives\_To\_Build\_APS\textquotesingle{]} &
{[}\textquotesingle competitive\_dynamics\_STRONG\textquotesingle,
\textquotesingle competitive\_d... & True & False & {[}{]} & \{"What is
the probability for Competitive\_Dyna... & \{"What is the probability
for Competitive\_Dyna... \\
16 & Deception\_By\_AI & AI systems deceiving humans about their true
o... & 16 & {[}16{]} & 16 & {[}16{]} & {[}{]} &
{[}\textquotesingle Deployment\_Decisions\textquotesingle{]} &
{[}\textquotesingle deception\_by\_ai\_TRUE\textquotesingle,
\textquotesingle deception\_by\_ai\_FALSE\textquotesingle{]} & True &
False & {[}{]} & \{"What is the probability for Deception\_By\_AI=... &
\{"What is the probability for Deception\_By\_AI=... \\
17 & Corrective\_Feedback & Human society implementing corrections after
o... & 17 & {[}17{]} & 8 & {[}8{]} &
{[}\textquotesingle Warning\_Shots\textquotesingle,
\textquotesingle Rapid\_Capability\_Escalation\textquotesingle{]} &
{[}\textquotesingle Scale\_Of\_Power\_Seeking\textquotesingle{]} &
{[}\textquotesingle corrective\_feedback\_EFFECTIVE\textquotesingle,
\textquotesingle corrective\_... & False & False &
{[}{[}\textquotesingle warning\_shots\_OBSERVED\textquotesingle,
\textquotesingle warning\_shots\_UNO... & \{"What is the probability for
Corrective\_Feedb... & \{"What is the probability for
Corrective\_Feedb... \\
18 & Warning\_Shots & Observable failures in weaker systems before c...
& 18 & {[}18{]} & 12 & {[}12{]} & {[}{]} &
{[}\textquotesingle Corrective\_Feedback\textquotesingle{]} &
{[}\textquotesingle warning\_shots\_OBSERVED\textquotesingle,
\textquotesingle warning\_shots\_UNOB... & True & False & {[}{]} &
\{"What is the probability for Warning\_Shots=wa... & \{"What is the
probability for Warning\_Shots=wa... \\
19 & Rapid\_Capability\_Escalation & AI capabilities escalating very
rapidly, allow... & 19 & {[}19{]} & 12 & {[}12{]} & {[}{]} &
{[}\textquotesingle Corrective\_Feedback\textquotesingle{]} &
{[}\textquotesingle rapid\_capability\_escalation\_TRUE\textquotesingle,
\textquotesingle rapid\_ca... & True & False & {[}{]} & \{"What is the
probability for Rapid\_Capability... & \{"What is the probability for
Rapid\_Capability... \\
20 & Barriers\_To\_Understanding & Difficulty in understanding the
internal worki... & 20 & {[}20{]} & 0 & {[}0{]} & {[}{]} & {[}{]} &
{[}\textquotesingle barriers\_to\_understanding\_HIGH\textquotesingle,
\textquotesingle barriers\_t... & True & True & {[}{]} & \{"What is the
probability for Barriers\_To\_Unde... & \{"What is the probability for
Barriers\_To\_Unde... \\
21 & Adversarial\_Dynamics & Potentially adversarial relationships
between ... & 22 & {[}22{]} & 0 & {[}0{]} & {[}{]} & {[}{]} &
{[}\textquotesingle adversarial\_dynamics\_TRUE\textquotesingle,
\textquotesingle adversarial\_dyn... & True & True & {[}{]} & \{"What is
the probability for Adversarial\_Dyna... & \{"What is the probability
for Adversarial\_Dyna... \\
22 & Stakes\_Of\_Error & The escalating impact of mistakes with
power-s... & 24 & {[}24{]} & 0 & {[}0{]} & {[}{]} & {[}{]} &
{[}\textquotesingle stakes\_of\_error\_HIGH\textquotesingle,
\textquotesingle stakes\_of\_error\_LOW\textquotesingle{]} & True & True
& {[}{]} & \{"What is the probability for Stakes\_Of\_Error=... &
\{"What is the probability for Stakes\_Of\_Error=... \\
\end{longtable}

\section{2.2 `ArgDown\_WithQuestions.csv' to
`BayesDownQuestions.md'}\label{argdown_withquestions.csv-to-bayesdownquestions.md}

2.2 Save BayesDown Extraction Questions as `BayesDownQuestions.md'

\phantomsection\label{bayesdown_questions_generation}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 2.2.0 {-}{-}{-} BayesDown Questions Generation {-}{-}{-} [bayesdown\_questions\_generation]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Transforms the ArgDown with questions into a BayesDown template with placeholders.}

\CommentTok{This function creates a BayesDown representation with probability placeholders}
\CommentTok{based on the questions generated in the previous step. It:}

\CommentTok{1. Loads the CSV file with probability questions}
\CommentTok{2. Constructs a directed graph to represent the causal structure}
\CommentTok{3. Processes each node to create BayesDown syntax with probability placeholders}
\CommentTok{4. Optionally includes comments with the specific questions to be answered}
\CommentTok{5. Saves the result as a markdown file for the next stage of the pipeline}

\CommentTok{The output is a BayesDown template that can be used in the probability}
\CommentTok{extraction phase, where the placeholders will be replaced with actual}
\CommentTok{probability values.}

\CommentTok{DEPENDENCIES: networkx, pandas, json libraries}
\CommentTok{INPUTS: CSV file with ArgDown structure and probability questions}
\CommentTok{OUTPUTS: BayesDown markdown file with probability placeholders}
\CommentTok{"""}

\KeywordTok{def}\NormalTok{ extract\_bayesdown\_questions\_fixed(argdown\_with\_questions\_path, output\_md\_path, include\_questions\_as\_comments}\OperatorTok{=}\VariableTok{True}\NormalTok{):}
  \CommentTok{"""}
\CommentTok{  Generate BayesDown syntax from the ArgDown\_WithQuestions CSV file with}
\CommentTok{  correct parent{-}child relationships.}

\CommentTok{  Args:}
\CommentTok{      argdown\_with\_questions\_path (str): Path to the CSV file with probability questions}
\CommentTok{      output\_md\_path (str): Path to save the output BayesDown file}
\CommentTok{      include\_questions\_as\_comments (bool, optional): Whether to include the original}
\CommentTok{                                                    questions as comments. Defaults to True.}

\CommentTok{  Returns:}
\CommentTok{      str: The generated BayesDown content}

\CommentTok{  Raises:}
\CommentTok{      Exception: If CSV loading fails or required columns are missing}
\CommentTok{  """}
  \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Loading CSV from }\SpecialCharTok{\{}\NormalTok{argdown\_with\_questions\_path}\SpecialCharTok{\}}\SpecialStringTok{..."}\NormalTok{)}

  \CommentTok{\# Load the CSV file}
  \ControlFlowTok{try}\NormalTok{:}
\NormalTok{      df }\OperatorTok{=}\NormalTok{ pd.read\_csv(argdown\_with\_questions\_path)}
      \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Successfully loaded CSV with }\SpecialCharTok{\{}\BuiltInTok{len}\NormalTok{(df)}\SpecialCharTok{\}}\SpecialStringTok{ rows."}\NormalTok{)}
  \ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
      \ControlFlowTok{raise} \PreprocessorTok{Exception}\NormalTok{(}\SpecialStringTok{f"Error loading CSV: }\SpecialCharTok{\{}\NormalTok{e}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

  \CommentTok{\# Validate required columns}
\NormalTok{  required\_columns }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{]}
\NormalTok{  missing\_columns }\OperatorTok{=}\NormalTok{ [col }\ControlFlowTok{for}\NormalTok{ col }\KeywordTok{in}\NormalTok{ required\_columns }\ControlFlowTok{if}\NormalTok{ col }\KeywordTok{not} \KeywordTok{in}\NormalTok{ df.columns]}
  \ControlFlowTok{if}\NormalTok{ missing\_columns:}
      \ControlFlowTok{raise} \PreprocessorTok{Exception}\NormalTok{(}\SpecialStringTok{f"Missing required columns: }\SpecialCharTok{\{}\StringTok{\textquotesingle{}, \textquotesingle{}}\SpecialCharTok{.}\NormalTok{join(missing\_columns)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

  \BuiltInTok{print}\NormalTok{(}\StringTok{"Generating BayesDown syntax with placeholder probabilities..."}\NormalTok{)}

  \CommentTok{\# Build a directed graph of nodes}
\NormalTok{  G }\OperatorTok{=}\NormalTok{ nx.DiGraph()}

  \CommentTok{\# Add nodes to the graph}
  \ControlFlowTok{for}\NormalTok{ idx, row }\KeywordTok{in}\NormalTok{ df.iterrows():}
\NormalTok{      G.add\_node(row[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{], data}\OperatorTok{=}\NormalTok{row)}

  \CommentTok{\# Add edges to the graph based on parent{-}child relationships {-} CORRECTLY}
  \ControlFlowTok{for}\NormalTok{ idx, row }\KeywordTok{in}\NormalTok{ df.iterrows():}
\NormalTok{      child }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{]}

      \CommentTok{\# Parse parents and add edges}
\NormalTok{      parents }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{]}
      \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(parents, }\BuiltInTok{str}\NormalTok{):}
          \CommentTok{\# Handle string representation of list}
          \ControlFlowTok{if}\NormalTok{ parents.startswith(}\StringTok{\textquotesingle{}[\textquotesingle{}}\NormalTok{) }\KeywordTok{and}\NormalTok{ parents.endswith(}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{):}
\NormalTok{              parents }\OperatorTok{=}\NormalTok{ parents.strip(}\StringTok{\textquotesingle{}[]\textquotesingle{}}\NormalTok{)}
              \ControlFlowTok{if}\NormalTok{ parents:  }\CommentTok{\# Check if not empty}
\NormalTok{                  parent\_list }\OperatorTok{=}\NormalTok{ [p.strip().strip(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}\textquotesingle{}}\StringTok{"\textquotesingle{}}\NormalTok{) }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ parents.split(}\StringTok{\textquotesingle{},\textquotesingle{}}\NormalTok{)]}
                  \ControlFlowTok{for}\NormalTok{ parent }\KeywordTok{in}\NormalTok{ parent\_list:}
                      \ControlFlowTok{if}\NormalTok{ parent }\KeywordTok{in}\NormalTok{ G.nodes():}
                          \CommentTok{\# In BayesDown: Parent (cause) {-}\textgreater{} Child (effect)}
\NormalTok{                          G.add\_edge(parent, child)}
      \ControlFlowTok{elif} \BuiltInTok{isinstance}\NormalTok{(parents, }\BuiltInTok{list}\NormalTok{):}
          \CommentTok{\# Handle actual list}
          \ControlFlowTok{for}\NormalTok{ parent }\KeywordTok{in}\NormalTok{ parents:}
              \ControlFlowTok{if}\NormalTok{ parent }\KeywordTok{in}\NormalTok{ G.nodes():}
\NormalTok{                  G.add\_edge(parent, child)}

  \CommentTok{\# Function to safely parse JSON strings}
  \KeywordTok{def}\NormalTok{ safe\_parse\_json(json\_str):}
      \ControlFlowTok{if}\NormalTok{ pd.isna(json\_str):}
          \ControlFlowTok{return}\NormalTok{ \{\}}

      \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(json\_str, }\BuiltInTok{dict}\NormalTok{):}
          \ControlFlowTok{return}\NormalTok{ json\_str}

      \ControlFlowTok{try}\NormalTok{:}
          \ControlFlowTok{return}\NormalTok{ json.loads(json\_str)}
      \ControlFlowTok{except}\NormalTok{:}
          \ControlFlowTok{return}\NormalTok{ \{\}}

  \CommentTok{\# Start building the BayesDown content}
\NormalTok{  bayesdown\_content }\OperatorTok{=} \StringTok{""}  \CommentTok{\# Initialize as empty}

  \ControlFlowTok{if}\NormalTok{ include\_questions\_as\_comments:}
\NormalTok{    bayesdown\_content }\OperatorTok{=} \StringTok{"\# BayesDown Representation with Placeholder Probabilities}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{"}
\NormalTok{    bayesdown\_content }\OperatorTok{+=} \StringTok{"/* This file contains BayesDown syntax with placeholder probabilities.}\CharTok{\textbackslash{}n}\StringTok{"}
\NormalTok{    bayesdown\_content }\OperatorTok{+=} \StringTok{"   Replace the placeholders with actual probability values based on the }\CharTok{\textbackslash{}n}\StringTok{"}
\NormalTok{    bayesdown\_content }\OperatorTok{+=} \StringTok{"   questions in the comments. */}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{"}

  \CommentTok{\# Get leaf nodes (nodes with no outgoing edges) {-} these are effects without children}
\NormalTok{  leaf\_nodes }\OperatorTok{=}\NormalTok{ [n }\ControlFlowTok{for}\NormalTok{ n }\KeywordTok{in}\NormalTok{ G.nodes() }\ControlFlowTok{if}\NormalTok{ G.out\_degree(n) }\OperatorTok{==} \DecValTok{0}\NormalTok{]}

  \CommentTok{\# Helper function to process a node and its parents recursively}
  \KeywordTok{def}\NormalTok{ process\_node(node, indent\_level}\OperatorTok{=}\DecValTok{0}\NormalTok{, processed\_nodes}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
      \ControlFlowTok{if}\NormalTok{ processed\_nodes }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
\NormalTok{          processed\_nodes }\OperatorTok{=} \BuiltInTok{set}\NormalTok{()}

      \CommentTok{\# Create the indentation string}
\NormalTok{      indent }\OperatorTok{=} \StringTok{\textquotesingle{} \textquotesingle{}} \OperatorTok{*}\NormalTok{ (indent\_level }\OperatorTok{*} \DecValTok{2}\NormalTok{)}
\NormalTok{      prefix }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{indent}\SpecialCharTok{\}}\SpecialStringTok{+ "} \ControlFlowTok{if}\NormalTok{ indent\_level }\OperatorTok{\textgreater{}} \DecValTok{0} \ControlFlowTok{else} \StringTok{""}

      \CommentTok{\# Get node data}
\NormalTok{      node\_data }\OperatorTok{=}\NormalTok{ G.nodes[node][}\StringTok{\textquotesingle{}data\textquotesingle{}}\NormalTok{]}
\NormalTok{      title }\OperatorTok{=}\NormalTok{ node\_data[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{]}
\NormalTok{      description }\OperatorTok{=}\NormalTok{ node\_data[}\StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{] }\ControlFlowTok{if} \KeywordTok{not}\NormalTok{ pd.isna(node\_data[}\StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{]) }\ControlFlowTok{else} \StringTok{""}

      \CommentTok{\# Parse instantiations from the row data}
\NormalTok{      instantiations }\OperatorTok{=}\NormalTok{ parse\_instantiations\_safely(node\_data[}\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{])}

      \CommentTok{\# Build the node string}
\NormalTok{      node\_output }\OperatorTok{=} \StringTok{""}

      \CommentTok{\# Add comments with questions if requested}
      \ControlFlowTok{if}\NormalTok{ include\_questions\_as\_comments:}
          \CommentTok{\# Add positive questions as comments}
          \ControlFlowTok{if} \StringTok{\textquotesingle{}Generate\_Positive\_Instantiation\_Questions\textquotesingle{}} \KeywordTok{in}\NormalTok{ node\_data:}
\NormalTok{              positive\_questions }\OperatorTok{=}\NormalTok{ safe\_parse\_json(node\_data[}\StringTok{\textquotesingle{}Generate\_Positive\_Instantiation\_Questions\textquotesingle{}}\NormalTok{])}
              \ControlFlowTok{for}\NormalTok{ question }\KeywordTok{in}\NormalTok{ positive\_questions.keys():}
\NormalTok{                  node\_output }\OperatorTok{+=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{indent}\SpecialCharTok{\}}\SpecialStringTok{/* }\SpecialCharTok{\{}\NormalTok{question}\SpecialCharTok{\}}\SpecialStringTok{ */}\CharTok{\textbackslash{}n}\SpecialStringTok{"}

          \CommentTok{\# Add negative questions as comments}
          \ControlFlowTok{if} \StringTok{\textquotesingle{}Generate\_Negative\_Instantiation\_Questions\textquotesingle{}} \KeywordTok{in}\NormalTok{ node\_data:}
\NormalTok{              negative\_questions }\OperatorTok{=}\NormalTok{ safe\_parse\_json(node\_data[}\StringTok{\textquotesingle{}Generate\_Negative\_Instantiation\_Questions\textquotesingle{}}\NormalTok{])}
              \ControlFlowTok{for}\NormalTok{ question }\KeywordTok{in}\NormalTok{ negative\_questions.keys():}
\NormalTok{                  node\_output }\OperatorTok{+=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{indent}\SpecialCharTok{\}}\SpecialStringTok{/* }\SpecialCharTok{\{}\NormalTok{question}\SpecialCharTok{\}}\SpecialStringTok{ */}\CharTok{\textbackslash{}n}\SpecialStringTok{"}

      \CommentTok{\# Check if this node was already fully defined elsewhere}
      \ControlFlowTok{if}\NormalTok{ node }\KeywordTok{in}\NormalTok{ processed\_nodes:}
          \CommentTok{\# Just add a reference to the node}
\NormalTok{          node\_output }\OperatorTok{+=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{prefix}\SpecialCharTok{\}}\SpecialStringTok{[}\SpecialCharTok{\{}\NormalTok{title}\SpecialCharTok{\}}\SpecialStringTok{]}\CharTok{\textbackslash{}n}\SpecialStringTok{"}
          \ControlFlowTok{return}\NormalTok{ node\_output}

      \CommentTok{\# Mark this node as processed}
\NormalTok{      processed\_nodes.add(node)}

      \CommentTok{\# Prepare the metadata JSON}
\NormalTok{      metadata }\OperatorTok{=}\NormalTok{ \{}
          \StringTok{"instantiations"}\NormalTok{: instantiations}
\NormalTok{      \}}

      \CommentTok{\# Add priors with full questions as keys}
\NormalTok{      priors }\OperatorTok{=}\NormalTok{ \{\}}
      \ControlFlowTok{if} \StringTok{\textquotesingle{}Generate\_Positive\_Instantiation\_Questions\textquotesingle{}} \KeywordTok{in}\NormalTok{ node\_data:}
\NormalTok{          positive\_questions }\OperatorTok{=}\NormalTok{ safe\_parse\_json(node\_data[}\StringTok{\textquotesingle{}Generate\_Positive\_Instantiation\_Questions\textquotesingle{}}\NormalTok{])}
          \ControlFlowTok{for}\NormalTok{ question, estimate\_key }\KeywordTok{in}\NormalTok{ positive\_questions.items():}
              \ControlFlowTok{if}\NormalTok{ estimate\_key }\OperatorTok{==} \StringTok{\textquotesingle{}prior\textquotesingle{}}\NormalTok{:}
\NormalTok{                  priors[question] }\OperatorTok{=} \StringTok{"\%?"}  \CommentTok{\# Default placeholder}

      \ControlFlowTok{if} \StringTok{\textquotesingle{}Generate\_Negative\_Instantiation\_Questions\textquotesingle{}} \KeywordTok{in}\NormalTok{ node\_data:}
\NormalTok{          negative\_questions }\OperatorTok{=}\NormalTok{ safe\_parse\_json(node\_data[}\StringTok{\textquotesingle{}Generate\_Negative\_Instantiation\_Questions\textquotesingle{}}\NormalTok{])}
          \ControlFlowTok{for}\NormalTok{ question, estimate\_key }\KeywordTok{in}\NormalTok{ negative\_questions.items():}
              \ControlFlowTok{if}\NormalTok{ estimate\_key }\OperatorTok{==} \StringTok{\textquotesingle{}prior\textquotesingle{}}\NormalTok{:}
\NormalTok{                  priors[question] }\OperatorTok{=} \StringTok{"\%?"}  \CommentTok{\# Default placeholder}

\NormalTok{      metadata[}\StringTok{"priors"}\NormalTok{] }\OperatorTok{=}\NormalTok{ priors}

      \CommentTok{\# Add posteriors with full questions as keys}
\NormalTok{      parents }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(G.predecessors(node))}
      \ControlFlowTok{if}\NormalTok{ parents:}
\NormalTok{          posteriors }\OperatorTok{=}\NormalTok{ \{\}}
          \ControlFlowTok{if} \StringTok{\textquotesingle{}Generate\_Positive\_Instantiation\_Questions\textquotesingle{}} \KeywordTok{in}\NormalTok{ node\_data:}
\NormalTok{              positive\_questions }\OperatorTok{=}\NormalTok{ safe\_parse\_json(node\_data[}\StringTok{\textquotesingle{}Generate\_Positive\_Instantiation\_Questions\textquotesingle{}}\NormalTok{])}
              \ControlFlowTok{for}\NormalTok{ question, estimate\_key }\KeywordTok{in}\NormalTok{ positive\_questions.items():}
                  \ControlFlowTok{if}\NormalTok{ estimate\_key.startswith(}\StringTok{\textquotesingle{}estimate\_\textquotesingle{}}\NormalTok{):}
\NormalTok{                      posteriors[question] }\OperatorTok{=} \StringTok{"?\%"}  \CommentTok{\# Default placeholder}

          \ControlFlowTok{if} \StringTok{\textquotesingle{}Generate\_Negative\_Instantiation\_Questions\textquotesingle{}} \KeywordTok{in}\NormalTok{ node\_data:}
\NormalTok{              negative\_questions }\OperatorTok{=}\NormalTok{ safe\_parse\_json(node\_data[}\StringTok{\textquotesingle{}Generate\_Negative\_Instantiation\_Questions\textquotesingle{}}\NormalTok{])}
              \ControlFlowTok{for}\NormalTok{ question, estimate\_key }\KeywordTok{in}\NormalTok{ negative\_questions.items():}
                  \ControlFlowTok{if}\NormalTok{ estimate\_key.startswith(}\StringTok{\textquotesingle{}estimate\_\textquotesingle{}}\NormalTok{):}
\NormalTok{                      posteriors[question] }\OperatorTok{=} \StringTok{"?\%"}  \CommentTok{\# Default placeholder}

\NormalTok{          metadata[}\StringTok{"posteriors"}\NormalTok{] }\OperatorTok{=}\NormalTok{ posteriors}

      \CommentTok{\# Format the node with metadata}
\NormalTok{      node\_output }\OperatorTok{+=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{prefix}\SpecialCharTok{\}}\SpecialStringTok{[}\SpecialCharTok{\{}\NormalTok{title}\SpecialCharTok{\}}\SpecialStringTok{]: }\SpecialCharTok{\{}\NormalTok{description}\SpecialCharTok{\}}\SpecialStringTok{ }\SpecialCharTok{\{}\NormalTok{json}\SpecialCharTok{.}\NormalTok{dumps(metadata)}\SpecialCharTok{\}}\CharTok{\textbackslash{}n}\SpecialStringTok{"}

      \CommentTok{\# Process parent nodes}
      \ControlFlowTok{for}\NormalTok{ parent }\KeywordTok{in}\NormalTok{ parents:}
          \ControlFlowTok{if}\NormalTok{ parent }\OperatorTok{!=}\NormalTok{ node:  }\CommentTok{\# Avoid self{-}references}
\NormalTok{              parent\_output }\OperatorTok{=}\NormalTok{ process\_node(parent, indent\_level }\OperatorTok{+} \DecValTok{1}\NormalTok{, processed\_nodes)}
\NormalTok{              node\_output }\OperatorTok{+=}\NormalTok{ parent\_output}

      \ControlFlowTok{return}\NormalTok{ node\_output}

  \CommentTok{\# Helper function to parse instantiations safely}
  \KeywordTok{def}\NormalTok{ parse\_instantiations\_safely(instantiations\_data):}
      \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(instantiations\_data, }\BuiltInTok{list}\NormalTok{):}
          \ControlFlowTok{return}\NormalTok{ instantiations\_data }\ControlFlowTok{if}\NormalTok{ instantiations\_data }\ControlFlowTok{else}\NormalTok{ [}\SpecialStringTok{f"TRUE"}\NormalTok{, }\SpecialStringTok{f"FALSE"}\NormalTok{]}

      \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(instantiations\_data, }\BuiltInTok{str}\NormalTok{):}
          \ControlFlowTok{try}\NormalTok{:}
\NormalTok{              parsed }\OperatorTok{=}\NormalTok{ json.loads(instantiations\_data)}
              \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(parsed, }\BuiltInTok{list}\NormalTok{):}
                  \ControlFlowTok{return}\NormalTok{ parsed }\ControlFlowTok{if}\NormalTok{ parsed }\ControlFlowTok{else}\NormalTok{ [}\SpecialStringTok{f"TRUE"}\NormalTok{, }\SpecialStringTok{f"FALSE"}\NormalTok{]}
          \ControlFlowTok{except}\NormalTok{:}
              \ControlFlowTok{if}\NormalTok{ instantiations\_data.startswith(}\StringTok{\textquotesingle{}[\textquotesingle{}}\NormalTok{) }\KeywordTok{and}\NormalTok{ instantiations\_data.endswith(}\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{):}
\NormalTok{                  items }\OperatorTok{=}\NormalTok{ instantiations\_data.strip(}\StringTok{\textquotesingle{}[]\textquotesingle{}}\NormalTok{).split(}\StringTok{\textquotesingle{},\textquotesingle{}}\NormalTok{)}
\NormalTok{                  result }\OperatorTok{=}\NormalTok{ [item.strip(}\StringTok{\textquotesingle{} "}\CharTok{\textbackslash{}\textquotesingle{}}\StringTok{\textquotesingle{}}\NormalTok{) }\ControlFlowTok{for}\NormalTok{ item }\KeywordTok{in}\NormalTok{ items }\ControlFlowTok{if}\NormalTok{ item.strip()]}
                  \ControlFlowTok{return}\NormalTok{ result }\ControlFlowTok{if}\NormalTok{ result }\ControlFlowTok{else}\NormalTok{ [}\SpecialStringTok{f"TRUE"}\NormalTok{, }\SpecialStringTok{f"FALSE"}\NormalTok{]}

      \ControlFlowTok{return}\NormalTok{ [}\SpecialStringTok{f"TRUE"}\NormalTok{, }\SpecialStringTok{f"FALSE"}\NormalTok{]  }\CommentTok{\# Default}

  \CommentTok{\# Process each leaf node and its ancestors}
  \ControlFlowTok{for}\NormalTok{ leaf }\KeywordTok{in}\NormalTok{ leaf\_nodes:}
\NormalTok{      bayesdown\_content }\OperatorTok{+=}\NormalTok{ process\_node(leaf)}

  \CommentTok{\# Save the BayesDown content}
  \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(output\_md\_path, }\StringTok{\textquotesingle{}w\textquotesingle{}}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{      f.write(bayesdown\_content)}

  \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"BayesDown Questions saved to }\SpecialCharTok{\{}\NormalTok{output\_md\_path}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
  \ControlFlowTok{return}\NormalTok{ bayesdown\_content}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Explicitly set the value of include\_questions\_as\_comments}
\NormalTok{include\_questions\_as\_comments}\OperatorTok{=}\VariableTok{False}  \CommentTok{\# or False, depending on your needs}

\CommentTok{\# Get the markdown content}
\NormalTok{bayesdown\_questions }\OperatorTok{=}\NormalTok{ extract\_bayesdown\_questions\_fixed(}
  \StringTok{"ArgDown\_WithQuestions.csv"}\NormalTok{,}
  \StringTok{"BayesDownQuestions.md"}\NormalTok{, include\_questions\_as\_comments}\OperatorTok{=}\NormalTok{include\_questions\_as\_comments}
\NormalTok{)}

\CommentTok{\# Determine the output file path based on include\_questions\_as\_comments}
\ControlFlowTok{if}\NormalTok{ include\_questions\_as\_comments: }\CommentTok{\# Assuming include\_questions\_as\_comments is defined somewhere in previous cells}
\NormalTok{    output\_file\_path }\OperatorTok{=} \StringTok{"FULL\_BayesDownQuestions.md"}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    output\_file\_path }\OperatorTok{=} \StringTok{"BayesDownQuestions.md"}

\CommentTok{\# Save the markdown content to the appropriate file}
\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(output\_file\_path, }\StringTok{\textquotesingle{}w\textquotesingle{}}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    f.write(md\_content)}

\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Markdown content saved to }\SpecialCharTok{\{}\NormalTok{output\_file\_path}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Loading CSV from ArgDown_WithQuestions.csv...
Successfully loaded CSV with 23 rows.
Generating BayesDown syntax with placeholder probabilities...
BayesDown Questions saved to BayesDownQuestions.md
Markdown content saved to BayesDownQuestions.md
\end{verbatim}

\phantomsection\label{generate_bayesdown}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Generate BayesDown format}
\NormalTok{bayesdown\_questions }\OperatorTok{=}\NormalTok{ extract\_bayesdown\_questions\_fixed(}
    \StringTok{"ArgDown\_WithQuestions.csv"}\NormalTok{,}
    \StringTok{"FULL\_BayesDownQuestions.md"}\NormalTok{,}
\NormalTok{    include\_questions\_as\_comments}\OperatorTok{=}\VariableTok{True}
\NormalTok{)}

\CommentTok{\# Display a preview of the format}
\BuiltInTok{print}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{BayesDown Format Preview:"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(bayesdown\_questions[:}\DecValTok{5000}\NormalTok{] }\OperatorTok{+} \StringTok{"...}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Loading CSV from ArgDown_WithQuestions.csv...
Successfully loaded CSV with 23 rows.
Generating BayesDown syntax with placeholder probabilities...
BayesDown Questions saved to FULL_BayesDownQuestions.md

BayesDown Format Preview:
# BayesDown Representation with Placeholder Probabilities

/* This file contains BayesDown syntax with placeholder probabilities.
   Replace the placeholders with actual probability values based on the 
   questions in the comments. */

/* What is the probability for Existential_Catastrophe=existential_catastrophe_TRUE? */
/* What is the probability for Existential_Catastrophe=existential_catastrophe_FALSE? */
[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {"instantiations": ["existential_catastrophe_TRUE", "existential_catastrophe_FALSE"], "priors": {"What is the probability for Existential_Catastrophe=existential_catastrophe_TRUE?": "%?", "What is the probability for Existential_Catastrophe=existential_catastrophe_FALSE?": "%?"}}
/* What is the probability for Human_Disempowerment=human_disempowerment_TRUE? */
/* What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE? */
/* What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE? */
/* What is the probability for Human_Disempowerment=human_disempowerment_FALSE? */
/* What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE? */
/* What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE? */
[Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {"instantiations": ["human_disempowerment_TRUE", "human_disempowerment_FALSE"], "priors": {"What is the probability for Human_Disempowerment=human_disempowerment_TRUE?": "%?", "What is the probability for Human_Disempowerment=human_disempowerment_FALSE?": "%?"}, "posteriors": {"What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?": "?%", "What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?": "?%", "What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?": "?%", "What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?": "?%"}}
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */
  + [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {"instantiations": ["scale_of_power_seeking_TRUE", "scale_of_power_seeking_FALSE"], "priors": {"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?": "%?", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?": "%?"}, "posteriors": {"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?": "?%"}}
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    + [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"], "priors": {"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE?": "%?", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE?": "%?"}, "posteriors": {"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%"}}
      /* What is the probability for APS_Systems=aps_systems_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */
      + [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {"instantiations": ["aps_systems_TRUE", "aps_systems_FALSE"], "priors": {"What is the probability for APS_Systems=aps_systems_TRUE?": "%?", "What is the probability for APS_Systems=aps_systems_FALSE?": "%?"}, "posteriors": {"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?": "?%"}}
        /* What is the probability for Advanced_AI_Capability=advanced_ai_capability_TRUE? */
        /* What is the probability for Advanced_AI_Capability=advanced_ai_capability_FALSE? */
        + [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {"instantiations": ["advanced_ai_capability_TRUE", "advanced_ai_capability_FALSE"], "priors": {"What is the probability for Advanced_AI_Capability=advanced_ai_capability_TRUE?": "%?", "What is the probability for Advanced_AI_Capability=advanced_ai_capability_FALSE?": "%?"}}
        /* What is the probability for Agentic_Planning=agentic_planning_TRUE? */
        /* What is the probability for Agentic_Planning=agentic_planning_FALSE? */
        + [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {"instantiations": ["agentic_planning_TRUE", "agentic_planning_FALSE"], "priors": {"What is the probability for Agentic_Planning=agentic_planning_TRUE?": "%?", "What is the probability for Agentic_Planning=agentic_planning_FALSE?": "%?"}}
        /* What is the probability for Strategic_Awareness=strategic_awareness_TRUE? */
        /* What is the probability for Strategic_Awareness=strategic_awareness_FALSE? */
        + [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {"instantiations": ["strategic_awareness_TRUE", "strategic_awareness_FALSE"], "priors": {"What is the probability for Strategic_Awareness=strategic_awareness_TRUE?": "%?", "What is the probability for Strategic_Awareness=strategic_awareness_FALSE?": "%?"}}
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */
      + [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {"instantiations": ["difficulty_of_alignment_TRUE", "difficulty_of_alignment_FALSE"], "priors": {"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE?": "%?", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE?": "%?"}, "posteriors": {"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?": "?%"}}
        /* What is the probability for Instrumental_Convergence=instrumental_convergence_TRUE? */
        /* What is the probability for Instrumental_Convergence=instrumental_convergence_FALSE? */
        + [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {"instantiations": ["instrumental_convergence_TRUE", "instrumental_convergence_FALSE"], "priors": {"What is the probability for Instrumental_Convergence=instrumental_convergence_TRUE?": "%?", "What is the probability for Instrumental_Convergence=instrumental_convergence_FALSE?": "%?"}}
        /* What is the probability for Problems_With_Proxies=problems_with_proxies_TRUE? */
        /* What is the probability for Problems_With_Proxies=problems_with_proxies_FALSE? */
        + [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {"instantiations": ["problems_with_proxies_TRUE", "problems_with_proxies_FALSE"], "priors": {"What is the probability for Problems_With_Proxies=problems_with_proxies_TRUE?": "%?", "What is the probability for Problems_With_Proxies=problems_with_proxies_FALSE?": "%?"}}
        /* What is the probability for Problems_With_Search=problems_with_search_TRUE? */
        /* What is the probability for Problems_With_Search=problems_with_search_FALSE? */
        + [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {"instantiations": ["problems_with_search_TRUE", "problems_with_search_FALSE"], "priors": {"What is the probability for Problems_With_Search=problems_with_search_TRUE?": "%?", "What is the probability for Problems_With_Search=problems_with_search_FALSE?": "%?"}}
      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE? */
      + [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {"instantiations": ["deployment_decisions_DEPLOY", "deployment_decisions_WITHHOLD"], "priors": {"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY?": "%?", "What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD?": "%?"}, "posteriors": {"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE?": "?%"}}
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK? */
        + [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {"instantiations": ["incentives_to_build_aps_STRONG", "incentives_to_build_aps_WEAK"], "priors": {"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG?": "%?", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK?": "%?"}, "posteriors": {"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK?": "?%"}}
          /* What is the probability for Usefulness_Of_APS=usefulness_of_aps_HIGH? */
          /* What is the probability for Usefulness_Of_APS=usefulness_of_aps_LOW? */
          + [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {"instantiations": ["usefulness_of_aps_HIGH", "usefulness_of_aps_LOW"], "priors": {"What is the probability for Usefulness_Of_APS=usefulness_of_aps_HIGH?": "%?", "What is the probability for Usefulness_Of_APS=usefulness_of_aps_LOW?": "%?"}}
          /* What is the probability for Competitive_Dynamics=competitive_dynamics_STRONG? */
          /* What is the probability for Competitive_Dynamics=competitive_dynamics_WEAK? */
          + [Competitive_Dynamics]: Competitive pressures between AI developers. {"instantiations": ["competitive_dynamics_STRONG", "competitive_dynamics_WEAK"], "priors": {"What is the probability for Competitive_Dynamics=competitive_dynamics_STRONG?": "%?", "What is the probability for Competitive_Dynamics=competitive_dynamics_WEAK?": "%?"}}
        /* What is the probability for Deception_By_AI=deception_by_ai_TRUE? */
        /* What is the probability for Deception_By_AI=deception_by_ai_FALSE? */
        + [Deception_By_AI]: AI systems deceiving humans about their true objectives. {"instantiations": ["deception_by_ai_TRUE", "deception_by_ai_FALSE"], "priors": {"What is the probability for Deception_By_AI=deception_by_ai_TRUE?": "%?", "What is the probability for Deception_By_AI=deception_by_ai_FALSE?": "%?"}}
    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */
    + [Corrective_Feedback]: Human society implementing corrections after observing problems. {"instantiations": ["corrective_feedback_EFFECTIVE", "corrective_feedback_INEFFECTIVE"], "priors": {"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE?": "%?", "What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE?": "%?"}, "posteriors": {"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?": "?%"}}
      /* What is the probability for Warning_Shots=warning_shots_OBSERVED? */
      /* What is the probability for Warning_Shots=warning_shots_UNOBSERVED? */
      + [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {"instantiations": ["warning_shots_OBSERVED", "warning_shots_UNOBSERVED"], "priors": {"What is the probability for Warning_Shots=warning_shots_OBSERVED?": "%?", "What is the probability for Warning_Shots=warning_shots_UNOBSERVED?": "%?"}}
      /* What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */
      /* What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */
      + [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {"instantiations": ["rapid_capability_escalation_TRUE", "rapid_capability_escalation_FALSE"], "priors": {"What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?": "%?", "What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?": "%?"}}
/* What is the probability for Barriers_To_Understanding=barriers_to_understanding_HIGH? */
/* What is the probability for Barriers_To_Understanding=barriers_to_understanding_LOW? */
[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {"instantiations": ["barriers_to_understanding_HIGH", "barriers_to_understanding_LOW"], "priors": {"What is the probability for Barriers_To_Understanding=barriers_to_understanding_HIGH?": "%?", "What is the probability for Barriers_To_Understanding=barriers_to_understanding_LOW?": "%?"}}
/* What is the probability for Adversarial_Dynamics=adversarial_dynamics_TRUE? */
/* What is the probability for Adversarial_Dynamics=adversarial_dynamics_FALSE? */
[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {"instantiations": ["adversarial_dynamics_TRUE", "adversarial_dynamics_FALSE"], "priors": {"What is the probability for Adversarial_Dynamics=adversarial_dynamics_TRUE?": "%?", "What is the probability for Adversarial_Dynamics=adversarial_dynamics_FALSE?": "%?"}}
/* What is the probability for Stakes_Of_Error=stakes_of_error_HIGH? */
/* What is the probability for Stakes_Of_Error=stakes_of_error_LOW? */
[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {"instantiations": ["stakes_of_error_HIGH", "stakes_of_error_LOW"], "priors": {"What is the probability for Stakes_Of_Error=stakes_of_error_HIGH?": "%?", "What is the probability for Stakes_Of_Error=stakes_of_error_LOW?": "%?"}}
...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load and print the content of the \textquotesingle{}FULL\_BayesDownQuestions.md\textquotesingle{} file}
\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\StringTok{"FULL\_BayesDownQuestions.md"}\NormalTok{, }\StringTok{"r"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    file\_content }\OperatorTok{=}\NormalTok{ f.read()}
    \BuiltInTok{print}\NormalTok{(file\_content)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# BayesDown Representation with Placeholder Probabilities

/* This file contains BayesDown syntax with placeholder probabilities.
   Replace the placeholders with actual probability values based on the 
   questions in the comments. */

/* What is the probability for Existential_Catastrophe=existential_catastrophe_TRUE? */
/* What is the probability for Existential_Catastrophe=existential_catastrophe_FALSE? */
[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {"instantiations": ["existential_catastrophe_TRUE", "existential_catastrophe_FALSE"], "priors": {"What is the probability for Existential_Catastrophe=existential_catastrophe_TRUE?": "%?", "What is the probability for Existential_Catastrophe=existential_catastrophe_FALSE?": "%?"}}
/* What is the probability for Human_Disempowerment=human_disempowerment_TRUE? */
/* What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE? */
/* What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE? */
/* What is the probability for Human_Disempowerment=human_disempowerment_FALSE? */
/* What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE? */
/* What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE? */
[Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {"instantiations": ["human_disempowerment_TRUE", "human_disempowerment_FALSE"], "priors": {"What is the probability for Human_Disempowerment=human_disempowerment_TRUE?": "%?", "What is the probability for Human_Disempowerment=human_disempowerment_FALSE?": "%?"}, "posteriors": {"What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?": "?%", "What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?": "?%", "What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?": "?%", "What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?": "?%"}}
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */
  + [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {"instantiations": ["scale_of_power_seeking_TRUE", "scale_of_power_seeking_FALSE"], "priors": {"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?": "%?", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?": "%?"}, "posteriors": {"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?": "?%"}}
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    + [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"], "priors": {"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE?": "%?", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE?": "%?"}, "posteriors": {"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%"}}
      /* What is the probability for APS_Systems=aps_systems_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */
      + [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {"instantiations": ["aps_systems_TRUE", "aps_systems_FALSE"], "priors": {"What is the probability for APS_Systems=aps_systems_TRUE?": "%?", "What is the probability for APS_Systems=aps_systems_FALSE?": "%?"}, "posteriors": {"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?": "?%"}}
        /* What is the probability for Advanced_AI_Capability=advanced_ai_capability_TRUE? */
        /* What is the probability for Advanced_AI_Capability=advanced_ai_capability_FALSE? */
        + [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {"instantiations": ["advanced_ai_capability_TRUE", "advanced_ai_capability_FALSE"], "priors": {"What is the probability for Advanced_AI_Capability=advanced_ai_capability_TRUE?": "%?", "What is the probability for Advanced_AI_Capability=advanced_ai_capability_FALSE?": "%?"}}
        /* What is the probability for Agentic_Planning=agentic_planning_TRUE? */
        /* What is the probability for Agentic_Planning=agentic_planning_FALSE? */
        + [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {"instantiations": ["agentic_planning_TRUE", "agentic_planning_FALSE"], "priors": {"What is the probability for Agentic_Planning=agentic_planning_TRUE?": "%?", "What is the probability for Agentic_Planning=agentic_planning_FALSE?": "%?"}}
        /* What is the probability for Strategic_Awareness=strategic_awareness_TRUE? */
        /* What is the probability for Strategic_Awareness=strategic_awareness_FALSE? */
        + [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {"instantiations": ["strategic_awareness_TRUE", "strategic_awareness_FALSE"], "priors": {"What is the probability for Strategic_Awareness=strategic_awareness_TRUE?": "%?", "What is the probability for Strategic_Awareness=strategic_awareness_FALSE?": "%?"}}
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */
      + [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {"instantiations": ["difficulty_of_alignment_TRUE", "difficulty_of_alignment_FALSE"], "priors": {"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE?": "%?", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE?": "%?"}, "posteriors": {"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?": "?%"}}
        /* What is the probability for Instrumental_Convergence=instrumental_convergence_TRUE? */
        /* What is the probability for Instrumental_Convergence=instrumental_convergence_FALSE? */
        + [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {"instantiations": ["instrumental_convergence_TRUE", "instrumental_convergence_FALSE"], "priors": {"What is the probability for Instrumental_Convergence=instrumental_convergence_TRUE?": "%?", "What is the probability for Instrumental_Convergence=instrumental_convergence_FALSE?": "%?"}}
        /* What is the probability for Problems_With_Proxies=problems_with_proxies_TRUE? */
        /* What is the probability for Problems_With_Proxies=problems_with_proxies_FALSE? */
        + [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {"instantiations": ["problems_with_proxies_TRUE", "problems_with_proxies_FALSE"], "priors": {"What is the probability for Problems_With_Proxies=problems_with_proxies_TRUE?": "%?", "What is the probability for Problems_With_Proxies=problems_with_proxies_FALSE?": "%?"}}
        /* What is the probability for Problems_With_Search=problems_with_search_TRUE? */
        /* What is the probability for Problems_With_Search=problems_with_search_FALSE? */
        + [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {"instantiations": ["problems_with_search_TRUE", "problems_with_search_FALSE"], "priors": {"What is the probability for Problems_With_Search=problems_with_search_TRUE?": "%?", "What is the probability for Problems_With_Search=problems_with_search_FALSE?": "%?"}}
      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE? */
      + [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {"instantiations": ["deployment_decisions_DEPLOY", "deployment_decisions_WITHHOLD"], "priors": {"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY?": "%?", "What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD?": "%?"}, "posteriors": {"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE?": "?%"}}
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK? */
        + [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {"instantiations": ["incentives_to_build_aps_STRONG", "incentives_to_build_aps_WEAK"], "priors": {"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG?": "%?", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK?": "%?"}, "posteriors": {"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK?": "?%"}}
          /* What is the probability for Usefulness_Of_APS=usefulness_of_aps_HIGH? */
          /* What is the probability for Usefulness_Of_APS=usefulness_of_aps_LOW? */
          + [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {"instantiations": ["usefulness_of_aps_HIGH", "usefulness_of_aps_LOW"], "priors": {"What is the probability for Usefulness_Of_APS=usefulness_of_aps_HIGH?": "%?", "What is the probability for Usefulness_Of_APS=usefulness_of_aps_LOW?": "%?"}}
          /* What is the probability for Competitive_Dynamics=competitive_dynamics_STRONG? */
          /* What is the probability for Competitive_Dynamics=competitive_dynamics_WEAK? */
          + [Competitive_Dynamics]: Competitive pressures between AI developers. {"instantiations": ["competitive_dynamics_STRONG", "competitive_dynamics_WEAK"], "priors": {"What is the probability for Competitive_Dynamics=competitive_dynamics_STRONG?": "%?", "What is the probability for Competitive_Dynamics=competitive_dynamics_WEAK?": "%?"}}
        /* What is the probability for Deception_By_AI=deception_by_ai_TRUE? */
        /* What is the probability for Deception_By_AI=deception_by_ai_FALSE? */
        + [Deception_By_AI]: AI systems deceiving humans about their true objectives. {"instantiations": ["deception_by_ai_TRUE", "deception_by_ai_FALSE"], "priors": {"What is the probability for Deception_By_AI=deception_by_ai_TRUE?": "%?", "What is the probability for Deception_By_AI=deception_by_ai_FALSE?": "%?"}}
    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */
    + [Corrective_Feedback]: Human society implementing corrections after observing problems. {"instantiations": ["corrective_feedback_EFFECTIVE", "corrective_feedback_INEFFECTIVE"], "priors": {"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE?": "%?", "What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE?": "%?"}, "posteriors": {"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?": "?%"}}
      /* What is the probability for Warning_Shots=warning_shots_OBSERVED? */
      /* What is the probability for Warning_Shots=warning_shots_UNOBSERVED? */
      + [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {"instantiations": ["warning_shots_OBSERVED", "warning_shots_UNOBSERVED"], "priors": {"What is the probability for Warning_Shots=warning_shots_OBSERVED?": "%?", "What is the probability for Warning_Shots=warning_shots_UNOBSERVED?": "%?"}}
      /* What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */
      /* What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */
      + [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {"instantiations": ["rapid_capability_escalation_TRUE", "rapid_capability_escalation_FALSE"], "priors": {"What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?": "%?", "What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?": "%?"}}
/* What is the probability for Barriers_To_Understanding=barriers_to_understanding_HIGH? */
/* What is the probability for Barriers_To_Understanding=barriers_to_understanding_LOW? */
[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {"instantiations": ["barriers_to_understanding_HIGH", "barriers_to_understanding_LOW"], "priors": {"What is the probability for Barriers_To_Understanding=barriers_to_understanding_HIGH?": "%?", "What is the probability for Barriers_To_Understanding=barriers_to_understanding_LOW?": "%?"}}
/* What is the probability for Adversarial_Dynamics=adversarial_dynamics_TRUE? */
/* What is the probability for Adversarial_Dynamics=adversarial_dynamics_FALSE? */
[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {"instantiations": ["adversarial_dynamics_TRUE", "adversarial_dynamics_FALSE"], "priors": {"What is the probability for Adversarial_Dynamics=adversarial_dynamics_TRUE?": "%?", "What is the probability for Adversarial_Dynamics=adversarial_dynamics_FALSE?": "%?"}}
/* What is the probability for Stakes_Of_Error=stakes_of_error_HIGH? */
/* What is the probability for Stakes_Of_Error=stakes_of_error_LOW? */
[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {"instantiations": ["stakes_of_error_HIGH", "stakes_of_error_LOW"], "priors": {"What is the probability for Stakes_Of_Error=stakes_of_error_HIGH?": "%?", "What is the probability for Stakes_Of_Error=stakes_of_error_LOW?": "%?"}}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Generate BayesDown format}
\NormalTok{bayesdown\_questions }\OperatorTok{=}\NormalTok{ extract\_bayesdown\_questions\_fixed(}
    \StringTok{"ArgDown\_WithQuestions.csv"}\NormalTok{,}
    \StringTok{"BayesDownQuestions.md"}\NormalTok{,}
\NormalTok{    include\_questions\_as\_comments}\OperatorTok{=}\VariableTok{False}
\NormalTok{)}

\CommentTok{\# Display a preview of the format}
\BuiltInTok{print}\NormalTok{(}

\NormalTok{)}
\BuiltInTok{print}\NormalTok{(bayesdown\_questions[:}\DecValTok{50000}\NormalTok{] }\OperatorTok{+} \StringTok{"...}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Loading CSV from ArgDown_WithQuestions.csv...
Successfully loaded CSV with 23 rows.
Generating BayesDown syntax with placeholder probabilities...
BayesDown Questions saved to BayesDownQuestions.md

[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {"instantiations": ["existential_catastrophe_TRUE", "existential_catastrophe_FALSE"], "priors": {"What is the probability for Existential_Catastrophe=existential_catastrophe_TRUE?": "%?", "What is the probability for Existential_Catastrophe=existential_catastrophe_FALSE?": "%?"}}
[Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {"instantiations": ["human_disempowerment_TRUE", "human_disempowerment_FALSE"], "priors": {"What is the probability for Human_Disempowerment=human_disempowerment_TRUE?": "%?", "What is the probability for Human_Disempowerment=human_disempowerment_FALSE?": "%?"}, "posteriors": {"What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?": "?%", "What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?": "?%", "What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?": "?%", "What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?": "?%"}}
  + [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {"instantiations": ["scale_of_power_seeking_TRUE", "scale_of_power_seeking_FALSE"], "priors": {"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?": "%?", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?": "%?"}, "posteriors": {"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?": "?%"}}
    + [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"], "priors": {"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE?": "%?", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE?": "%?"}, "posteriors": {"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%"}}
      + [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {"instantiations": ["aps_systems_TRUE", "aps_systems_FALSE"], "priors": {"What is the probability for APS_Systems=aps_systems_TRUE?": "%?", "What is the probability for APS_Systems=aps_systems_FALSE?": "%?"}, "posteriors": {"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?": "?%"}}
        + [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {"instantiations": ["advanced_ai_capability_TRUE", "advanced_ai_capability_FALSE"], "priors": {"What is the probability for Advanced_AI_Capability=advanced_ai_capability_TRUE?": "%?", "What is the probability for Advanced_AI_Capability=advanced_ai_capability_FALSE?": "%?"}}
        + [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {"instantiations": ["agentic_planning_TRUE", "agentic_planning_FALSE"], "priors": {"What is the probability for Agentic_Planning=agentic_planning_TRUE?": "%?", "What is the probability for Agentic_Planning=agentic_planning_FALSE?": "%?"}}
        + [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {"instantiations": ["strategic_awareness_TRUE", "strategic_awareness_FALSE"], "priors": {"What is the probability for Strategic_Awareness=strategic_awareness_TRUE?": "%?", "What is the probability for Strategic_Awareness=strategic_awareness_FALSE?": "%?"}}
      + [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {"instantiations": ["difficulty_of_alignment_TRUE", "difficulty_of_alignment_FALSE"], "priors": {"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE?": "%?", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE?": "%?"}, "posteriors": {"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?": "?%"}}
        + [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {"instantiations": ["instrumental_convergence_TRUE", "instrumental_convergence_FALSE"], "priors": {"What is the probability for Instrumental_Convergence=instrumental_convergence_TRUE?": "%?", "What is the probability for Instrumental_Convergence=instrumental_convergence_FALSE?": "%?"}}
        + [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {"instantiations": ["problems_with_proxies_TRUE", "problems_with_proxies_FALSE"], "priors": {"What is the probability for Problems_With_Proxies=problems_with_proxies_TRUE?": "%?", "What is the probability for Problems_With_Proxies=problems_with_proxies_FALSE?": "%?"}}
        + [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {"instantiations": ["problems_with_search_TRUE", "problems_with_search_FALSE"], "priors": {"What is the probability for Problems_With_Search=problems_with_search_TRUE?": "%?", "What is the probability for Problems_With_Search=problems_with_search_FALSE?": "%?"}}
      + [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {"instantiations": ["deployment_decisions_DEPLOY", "deployment_decisions_WITHHOLD"], "priors": {"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY?": "%?", "What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD?": "%?"}, "posteriors": {"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE?": "?%"}}
        + [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {"instantiations": ["incentives_to_build_aps_STRONG", "incentives_to_build_aps_WEAK"], "priors": {"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG?": "%?", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK?": "%?"}, "posteriors": {"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK?": "?%"}}
          + [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {"instantiations": ["usefulness_of_aps_HIGH", "usefulness_of_aps_LOW"], "priors": {"What is the probability for Usefulness_Of_APS=usefulness_of_aps_HIGH?": "%?", "What is the probability for Usefulness_Of_APS=usefulness_of_aps_LOW?": "%?"}}
          + [Competitive_Dynamics]: Competitive pressures between AI developers. {"instantiations": ["competitive_dynamics_STRONG", "competitive_dynamics_WEAK"], "priors": {"What is the probability for Competitive_Dynamics=competitive_dynamics_STRONG?": "%?", "What is the probability for Competitive_Dynamics=competitive_dynamics_WEAK?": "%?"}}
        + [Deception_By_AI]: AI systems deceiving humans about their true objectives. {"instantiations": ["deception_by_ai_TRUE", "deception_by_ai_FALSE"], "priors": {"What is the probability for Deception_By_AI=deception_by_ai_TRUE?": "%?", "What is the probability for Deception_By_AI=deception_by_ai_FALSE?": "%?"}}
    + [Corrective_Feedback]: Human society implementing corrections after observing problems. {"instantiations": ["corrective_feedback_EFFECTIVE", "corrective_feedback_INEFFECTIVE"], "priors": {"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE?": "%?", "What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE?": "%?"}, "posteriors": {"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?": "?%"}}
      + [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {"instantiations": ["warning_shots_OBSERVED", "warning_shots_UNOBSERVED"], "priors": {"What is the probability for Warning_Shots=warning_shots_OBSERVED?": "%?", "What is the probability for Warning_Shots=warning_shots_UNOBSERVED?": "%?"}}
      + [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {"instantiations": ["rapid_capability_escalation_TRUE", "rapid_capability_escalation_FALSE"], "priors": {"What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?": "%?", "What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?": "%?"}}
[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {"instantiations": ["barriers_to_understanding_HIGH", "barriers_to_understanding_LOW"], "priors": {"What is the probability for Barriers_To_Understanding=barriers_to_understanding_HIGH?": "%?", "What is the probability for Barriers_To_Understanding=barriers_to_understanding_LOW?": "%?"}}
[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {"instantiations": ["adversarial_dynamics_TRUE", "adversarial_dynamics_FALSE"], "priors": {"What is the probability for Adversarial_Dynamics=adversarial_dynamics_TRUE?": "%?", "What is the probability for Adversarial_Dynamics=adversarial_dynamics_FALSE?": "%?"}}
[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {"instantiations": ["stakes_of_error_HIGH", "stakes_of_error_LOW"], "priors": {"What is the probability for Stakes_Of_Error=stakes_of_error_HIGH?": "%?", "What is the probability for Stakes_Of_Error=stakes_of_error_LOW?": "%?"}}
...
\end{verbatim}

\section{2.3 Generate BayesDown Probability Extraction
Prompt}\label{generate-bayesdown-probability-extraction-prompt}

Generate 2nd Extraction Prompt for Probabilities based on the questions
generated from the `ArgDown.csv' extraction

\subsection{2.3.0 BayesDown Format
Specification}\label{bayesdown-format-specification}

BayesDown extends ArgDown with probability data in a structured JSON
format to represent Bayesian networks. This intermediate representation
bridges the gap between natural language arguments and formal
probabilistic models, preserving both narrative structure and
quantitative relationships.

\subsubsection{Core Structure}\label{core-structure}

A BayesDown representation consists of:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Nodes}: Variables or statements in brackets
  \texttt{{[}Node\_Name{]}} with descriptive text
\item
  \textbf{Relationships}: Hierarchical structure with indentation and
  \texttt{+} symbols
\item
  \textbf{Metadata}: JSON objects containing probability information:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\{}
  \DataTypeTok{"instantiations"}\FunctionTok{:} \OtherTok{[}\StringTok{"state\_TRUE"}\OtherTok{,} \StringTok{"state\_FALSE"}\OtherTok{]}\FunctionTok{,}  \ErrorTok{//} \ErrorTok{Possible} \ErrorTok{states} \ErrorTok{of} \ErrorTok{variable}
  \DataTypeTok{"priors"}\FunctionTok{:} \FunctionTok{\{}
    \DataTypeTok{"p(state\_TRUE)"}\FunctionTok{:} \StringTok{"0.7"}\FunctionTok{,}   \ErrorTok{//} \ErrorTok{Unconditional} \ErrorTok{probability} \ErrorTok{of} \ErrorTok{state\_TRUE}
    \DataTypeTok{"p(state\_FALSE)"}\FunctionTok{:} \StringTok{"0.3"}   \ErrorTok{//} \ErrorTok{Unconditional} \ErrorTok{probability} \ErrorTok{of} \ErrorTok{state\_FALSE}
  \FunctionTok{\},}
  \DataTypeTok{"posteriors"}\FunctionTok{:} \FunctionTok{\{}
    \DataTypeTok{"p(state\_TRUE|condition1\_TRUE,condition2\_FALSE)"}\FunctionTok{:} \StringTok{"0.9"}\FunctionTok{,}  \ErrorTok{//} \ErrorTok{Conditional} \ErrorTok{on} \ErrorTok{parent} \ErrorTok{states}
    \DataTypeTok{"p(state\_TRUE|condition1\_FALSE,condition2\_TRUE)"}\FunctionTok{:} \StringTok{"0.4"}   \ErrorTok{//} \ErrorTok{Different} \ErrorTok{parent} \ErrorTok{configuration}
  \FunctionTok{\}}
\FunctionTok{\}}

\ErrorTok{\#\#\#} \ErrorTok{2.3.1} \ErrorTok{Rain{-}Sprinkler{-}Lawn} \ErrorTok{Example}
\OtherTok{[}\ErrorTok{Grass\_Wet}\OtherTok{]}\ErrorTok{:} \ErrorTok{Concentrated} \ErrorTok{moisture} \ErrorTok{on} \ErrorTok{grass.} \FunctionTok{\{}\DataTypeTok{"instantiations"}\FunctionTok{:} \OtherTok{[}\StringTok{"grass\_wet\_TRUE"}\OtherTok{,} \StringTok{"grass\_wet\_FALSE"}\OtherTok{]}\FunctionTok{,}
\DataTypeTok{"priors"}\FunctionTok{:} \FunctionTok{\{}\DataTypeTok{"p(grass\_wet\_TRUE)"}\FunctionTok{:} \StringTok{"0.322"}\FunctionTok{,} \DataTypeTok{"p(grass\_wet\_FALSE)"}\FunctionTok{:} \StringTok{"0.678"}\FunctionTok{\},}
\DataTypeTok{"posteriors"}\FunctionTok{:} \FunctionTok{\{}\DataTypeTok{"p(grass\_wet\_TRUE|sprinkler\_TRUE,rain\_TRUE)"}\FunctionTok{:} \StringTok{"0.99"}\FunctionTok{,}
\DataTypeTok{"p(grass\_wet\_TRUE|sprinkler\_TRUE,rain\_FALSE)"}\FunctionTok{:} \StringTok{"0.9"}\FunctionTok{,}
\DataTypeTok{"p(grass\_wet\_TRUE|sprinkler\_FALSE,rain\_TRUE)"}\FunctionTok{:} \StringTok{"0.8"}\FunctionTok{,}
\DataTypeTok{"p(grass\_wet\_TRUE|sprinkler\_FALSE,rain\_FALSE)"}\FunctionTok{:} \StringTok{"0.0"}\FunctionTok{\}\}}
 \ErrorTok{+} \OtherTok{[}\ErrorTok{Rain}\OtherTok{]}\ErrorTok{:} \ErrorTok{Water} \ErrorTok{falling} \ErrorTok{from} \ErrorTok{the} \ErrorTok{sky.} \FunctionTok{\{}\DataTypeTok{"instantiations"}\FunctionTok{:} \OtherTok{[}\StringTok{"rain\_TRUE"}\OtherTok{,} \StringTok{"rain\_FALSE"}\OtherTok{]}\FunctionTok{,}
 \DataTypeTok{"priors"}\FunctionTok{:} \FunctionTok{\{}\DataTypeTok{"p(rain\_TRUE)"}\FunctionTok{:} \StringTok{"0.2"}\FunctionTok{,} \DataTypeTok{"p(rain\_FALSE)"}\FunctionTok{:} \StringTok{"0.8"}\FunctionTok{\}\}}
 \ErrorTok{+} \OtherTok{[}\ErrorTok{Sprinkler}\OtherTok{]}\ErrorTok{:} \ErrorTok{Artificial} \ErrorTok{watering} \ErrorTok{system.} \FunctionTok{\{}\DataTypeTok{"instantiations"}\FunctionTok{:} \OtherTok{[}\StringTok{"sprinkler\_TRUE"}\OtherTok{,} \StringTok{"sprinkler\_FALSE"}\OtherTok{]}\FunctionTok{,}
 \DataTypeTok{"priors"}\FunctionTok{:} \FunctionTok{\{}\DataTypeTok{"p(sprinkler\_TRUE)"}\FunctionTok{:} \StringTok{"0.44838"}\FunctionTok{,} \DataTypeTok{"p(sprinkler\_FALSE)"}\FunctionTok{:} \StringTok{"0.55162"}\FunctionTok{\},}
 \DataTypeTok{"posteriors"}\FunctionTok{:} \FunctionTok{\{}\DataTypeTok{"p(sprinkler\_TRUE|rain\_TRUE)"}\FunctionTok{:} \StringTok{"0.01"}\FunctionTok{,} \DataTypeTok{"p(sprinkler\_TRUE|rain\_FALSE)"}\FunctionTok{:} \StringTok{"0.4"}\FunctionTok{\}\}}
   \ErrorTok{+} \OtherTok{[}\ErrorTok{Rain}\OtherTok{]}


\ErrorTok{In} \ErrorTok{this} \ErrorTok{example:}

\ErrorTok{+} \ErrorTok{Grass\_Wet} \ErrorTok{is} \ErrorTok{the} \ErrorTok{effect/outcome} \ErrorTok{node}
\ErrorTok{+} \ErrorTok{Rain} \ErrorTok{and} \ErrorTok{Sprinkler} \ErrorTok{are} \ErrorTok{parent} \ErrorTok{nodes} \ErrorTok{(causes)}
\ErrorTok{+} \ErrorTok{Rain} \ErrorTok{also} \ErrorTok{influences} \ErrorTok{Sprinkler} \ErrorTok{(people} \ErrorTok{tend} \ErrorTok{not} \ErrorTok{to} \ErrorTok{use} \ErrorTok{sprinklers} \ErrorTok{when} \ErrorTok{it\textquotesingle{}s} \ErrorTok{raining)}

\ErrorTok{Role} \ErrorTok{in} \ErrorTok{AMTAIR}
\ErrorTok{BayesDown} \ErrorTok{serves} \ErrorTok{as} \ErrorTok{the} \ErrorTok{critical} \ErrorTok{intermediate} \ErrorTok{representation} \ErrorTok{in} \ErrorTok{the} \ErrorTok{AMTAIR} \ErrorTok{extraction} \ErrorTok{pipeline,} \ErrorTok{bridging} \ErrorTok{between} \ErrorTok{qualitative} \ErrorTok{arguments} \ErrorTok{in} \ErrorTok{AI} \ErrorTok{safety} \ErrorTok{literature} \ErrorTok{and} \ErrorTok{formal} \ErrorTok{Bayesian} \ErrorTok{networks} \ErrorTok{that} \ErrorTok{can} \ErrorTok{be} \ErrorTok{used} \ErrorTok{for} \ErrorTok{probabilistic} \ErrorTok{reasoning} \ErrorTok{and} \ErrorTok{policy} \ErrorTok{evaluation.} \ErrorTok{By} \ErrorTok{preserving} \ErrorTok{both} \ErrorTok{narrative} \ErrorTok{explanation} \ErrorTok{and} \ErrorTok{probabilistic} \ErrorTok{information,} \ErrorTok{it} \ErrorTok{enables} \ErrorTok{the} \ErrorTok{automated} \ErrorTok{extraction} \ErrorTok{of} \ErrorTok{world} \ErrorTok{models} \ErrorTok{while} \ErrorTok{maintaining} \ErrorTok{traceability} \ErrorTok{to} \ErrorTok{the} \ErrorTok{original} \ErrorTok{arguments.}
\ErrorTok{For} \ErrorTok{full} \ErrorTok{syntax} \ErrorTok{details,} \ErrorTok{see} \ErrorTok{the} \ErrorTok{BayesDownSyntax.md} \ErrorTok{file} \ErrorTok{in} \ErrorTok{the} \ErrorTok{repository.}

\ErrorTok{\#\#\#} \ErrorTok{2.3.2} \ErrorTok{Probability} \ErrorTok{Extraction} \ErrorTok{Process}
\ErrorTok{The} \ErrorTok{probability} \ErrorTok{extraction} \ErrorTok{pipeline} \ErrorTok{follows} \ErrorTok{these} \ErrorTok{steps:}


\ErrorTok{Identify} \ErrorTok{variables} \ErrorTok{and} \ErrorTok{their} \ErrorTok{possible} \ErrorTok{states}
\ErrorTok{Extract} \ErrorTok{prior} \ErrorTok{probability} \ErrorTok{statements}
\ErrorTok{Identify} \ErrorTok{conditional} \ErrorTok{relationships}
\ErrorTok{Extract} \ErrorTok{conditional} \ErrorTok{probability} \ErrorTok{statements}
\ErrorTok{Format} \ErrorTok{the} \ErrorTok{data} \ErrorTok{in} \ErrorTok{BayesDown} \ErrorTok{syntax}

\ErrorTok{\#\#\#} \ErrorTok{2.3.3} \ErrorTok{Implementation} \ErrorTok{Steps}
\ErrorTok{To} \ErrorTok{extract} \ErrorTok{probabilities} \ErrorTok{and} \ErrorTok{create} \ErrorTok{BayesDown} \ErrorTok{format:}

\ErrorTok{Run} \ErrorTok{the} \ErrorTok{extract\_probabilities} \ErrorTok{function} \ErrorTok{on} \ErrorTok{ArgDown} \ErrorTok{text}
\ErrorTok{Process} \ErrorTok{the} \ErrorTok{results} \ErrorTok{into} \ErrorTok{a} \ErrorTok{structured} \ErrorTok{format}
\ErrorTok{Validate} \ErrorTok{the} \ErrorTok{probability} \ErrorTok{distributions} \ErrorTok{(ensure} \ErrorTok{they} \ErrorTok{sum} \ErrorTok{to} \ErrorTok{1)}
\ErrorTok{Generate} \ErrorTok{the} \ErrorTok{enhanced} \ErrorTok{BayesDown} \ErrorTok{representation}

\ErrorTok{\#\#\#} \ErrorTok{2.3.4} \ErrorTok{Validation} \ErrorTok{and} \ErrorTok{Quality} \ErrorTok{Control}
\ErrorTok{The} \ErrorTok{probability} \ErrorTok{extraction} \ErrorTok{process} \ErrorTok{includes} \ErrorTok{validation} \ErrorTok{steps:}

\ErrorTok{Ensuring} \ErrorTok{coherent} \ErrorTok{probability} \ErrorTok{distributions}
\ErrorTok{Checking} \ErrorTok{for} \ErrorTok{logical} \ErrorTok{consistency} \ErrorTok{in} \ErrorTok{conditional} \ErrorTok{relationships}
\ErrorTok{Verifying} \ErrorTok{that} \ErrorTok{all} \ErrorTok{required} \ErrorTok{probability} \ErrorTok{statements} \ErrorTok{are} \ErrorTok{present}
\ErrorTok{Handling} \ErrorTok{missing} \ErrorTok{data} \ErrorTok{with} \ErrorTok{appropriate} \ErrorTok{default} \ErrorTok{values}

\ErrorTok{\#\#} \ErrorTok{2.4} \ErrorTok{Prepare} \ErrorTok{2nd} \ErrorTok{API} \ErrorTok{call}

\ErrorTok{\#\#} \ErrorTok{2.5} \ErrorTok{Make} \ErrorTok{BayesDown} \ErrorTok{Probability} \ErrorTok{Extraction} \ErrorTok{API} \ErrorTok{Call}

\ErrorTok{\#\#} \ErrorTok{2.6} \ErrorTok{Save} \ErrorTok{BayesDown} \ErrorTok{with} \ErrorTok{Probability} \ErrorTok{Estimates} \ErrorTok{(.csv)}

\ErrorTok{\#\#} \ErrorTok{2.7} \ErrorTok{Review} \ErrorTok{\&} \ErrorTok{Verify} \ErrorTok{BayesDown} \ErrorTok{Probability} \ErrorTok{Estimates}

\ErrorTok{\#\#} \ErrorTok{2.7.2} \ErrorTok{Check} \ErrorTok{the} \ErrorTok{Graph} \ErrorTok{Structure} \ErrorTok{with} \ErrorTok{the} \ErrorTok{ArgDown} \ErrorTok{Sandbox} \ErrorTok{Online}
\ErrorTok{Copy} \ErrorTok{and} \ErrorTok{paste} \ErrorTok{the} \ErrorTok{BayesDown} \ErrorTok{formatted} \ErrorTok{...} \ErrorTok{in} \ErrorTok{the} \ErrorTok{ArgDown} \ErrorTok{Sandbox} \ErrorTok{below} \ErrorTok{to} \ErrorTok{quickly} \ErrorTok{verify} \ErrorTok{that} \ErrorTok{the} \ErrorTok{network} \ErrorTok{renders} \ErrorTok{correctly.}

\ErrorTok{\#\#} \ErrorTok{2.8} \ErrorTok{Extract} \ErrorTok{BayesDown} \ErrorTok{with} \ErrorTok{Probability} \ErrorTok{Estimates} \ErrorTok{as} \ErrorTok{Dataframe}

\ErrorTok{\#} \ErrorTok{3} \ErrorTok{Data} \ErrorTok{Extraction:} \ErrorTok{BayesDown} \ErrorTok{(.md)} \ErrorTok{to} \ErrorTok{Database} \ErrorTok{(.csv)}

\ErrorTok{\#\#} \ErrorTok{3.0} \ErrorTok{BayesDown} \ErrorTok{to} \ErrorTok{Structured} \ErrorTok{Data:} \ErrorTok{Network} \ErrorTok{Construction}

\ErrorTok{\#\#} \ErrorTok{Extraction} \ErrorTok{Pipeline} \ErrorTok{Overview}

\ErrorTok{This} \ErrorTok{section} \ErrorTok{implements} \ErrorTok{the} \ErrorTok{core} \ErrorTok{extraction} \ErrorTok{pipeline} \ErrorTok{described} \ErrorTok{in} \ErrorTok{the} \ErrorTok{AMTAIR} \ErrorTok{project} \ErrorTok{documentation} \ErrorTok{(see} \ErrorTok{\textasciigrave{}PY\_TechnicalImplementation.md\textasciigrave{}),} \ErrorTok{which} \ErrorTok{transforms} \ErrorTok{structured} \ErrorTok{argument} \ErrorTok{representations} \ErrorTok{into} \ErrorTok{formal} \ErrorTok{Bayesian} \ErrorTok{networks} \ErrorTok{through} \ErrorTok{a} \ErrorTok{series} \ErrorTok{of} \ErrorTok{processing} \ErrorTok{steps:}

\ErrorTok{1.} \ErrorTok{**Input**:} \ErrorTok{Text} \ErrorTok{in} \ErrorTok{BayesDown} \ErrorTok{format} \ErrorTok{(see} \ErrorTok{Section} \ErrorTok{2.3.1)}
\ErrorTok{2.} \ErrorTok{**Parsing**:} \ErrorTok{Extract} \ErrorTok{nodes,} \ErrorTok{relationships,} \ErrorTok{and} \ErrorTok{probability} \ErrorTok{information}
\ErrorTok{3.} \ErrorTok{**Structuring**:} \ErrorTok{Organize} \ErrorTok{into} \ErrorTok{a} \ErrorTok{DataFrame} \ErrorTok{with} \ErrorTok{formal} \ErrorTok{relationships}
\ErrorTok{4.} \ErrorTok{**Enhancement**:} \ErrorTok{Add} \ErrorTok{derived} \ErrorTok{properties} \ErrorTok{and} \ErrorTok{network} \ErrorTok{metrics}
\ErrorTok{5.} \ErrorTok{**Output**:} \ErrorTok{Structured} \ErrorTok{data} \ErrorTok{ready} \ErrorTok{for} \ErrorTok{Bayesian} \ErrorTok{network} \ErrorTok{construction}

\ErrorTok{\#\#\#} \ErrorTok{Theoretical} \ErrorTok{Foundation}

\ErrorTok{This} \ErrorTok{implementation} \ErrorTok{follows} \ErrorTok{the} \ErrorTok{extraction} \ErrorTok{algorithm} \ErrorTok{outlined} \ErrorTok{in} \ErrorTok{the} \ErrorTok{AMTAIR} \ErrorTok{project} \ErrorTok{description:}

\ErrorTok{1.} \ErrorTok{Get} \ErrorTok{nodes:} \ErrorTok{All} \ErrorTok{premises} \ErrorTok{and} \ErrorTok{conclusions} \ErrorTok{from} \ErrorTok{the} \ErrorTok{argument} \ErrorTok{structure}
\ErrorTok{2.} \ErrorTok{Get} \ErrorTok{edges:} \ErrorTok{Parent{-}child} \ErrorTok{relationships} \ErrorTok{between} \ErrorTok{nodes}
\ErrorTok{3.} \ErrorTok{Extract} \ErrorTok{probability} \ErrorTok{distributions:} \ErrorTok{Prior} \ErrorTok{and} \ErrorTok{conditional} \ErrorTok{probabilities}
\ErrorTok{4.} \ErrorTok{Calculate} \ErrorTok{derived} \ErrorTok{metrics:} \ErrorTok{Network} \ErrorTok{statistics} \ErrorTok{and} \ErrorTok{node} \ErrorTok{classifications}

\ErrorTok{The} \ErrorTok{resulting} \ErrorTok{structured} \ErrorTok{data} \ErrorTok{maintains} \ErrorTok{the} \ErrorTok{complete} \ErrorTok{information} \ErrorTok{needed} \ErrorTok{to} \ErrorTok{reconstruct} \ErrorTok{the} \ErrorTok{Bayesian} \ErrorTok{network} \ErrorTok{while} \ErrorTok{enabling} \ErrorTok{additional} \ErrorTok{analysis} \ErrorTok{and} \ErrorTok{visualization.}

\ErrorTok{\#\#\#} \ErrorTok{Role} \ErrorTok{in} \ErrorTok{Thesis} \ErrorTok{Research}

\ErrorTok{This} \ErrorTok{extraction} \ErrorTok{pipeline} \ErrorTok{represents} \ErrorTok{a} \ErrorTok{key} \ErrorTok{contribution} \ErrorTok{of} \ErrorTok{the} \ErrorTok{Master\textquotesingle{}s} \ErrorTok{thesis,} \ErrorTok{demonstrating} \ErrorTok{how} \ErrorTok{argument} \ErrorTok{structures} \ErrorTok{from} \ErrorTok{AI} \ErrorTok{safety} \ErrorTok{literature} \ErrorTok{can} \ErrorTok{be} \ErrorTok{automatically} \ErrorTok{transformed} \ErrorTok{into} \ErrorTok{formal} \ErrorTok{probabilistic} \ErrorTok{models.} \ErrorTok{While} \ErrorTok{the} \ErrorTok{current} \ErrorTok{implementation} \ErrorTok{focuses} \ErrorTok{on} \ErrorTok{pre{-}formatted} \ErrorTok{BayesDown,} \ErrorTok{the} \ErrorTok{architecture} \ErrorTok{is} \ErrorTok{designed} \ErrorTok{to} \ErrorTok{be} \ErrorTok{extended} \ErrorTok{with} \ErrorTok{LLM{-}powered} \ErrorTok{extraction} \ErrorTok{directly} \ErrorTok{from} \ErrorTok{natural} \ErrorTok{language} \ErrorTok{in} \ErrorTok{future} \ErrorTok{work.}

\ErrorTok{The} \ErrorTok{rain{-}sprinkler{-}lawn} \ErrorTok{example} \ErrorTok{serves} \ErrorTok{as} \ErrorTok{a} \ErrorTok{simple} \ErrorTok{but} \ErrorTok{complete} \ErrorTok{test} \ErrorTok{case,} \ErrorTok{demonstrating} \ErrorTok{every} \ErrorTok{step} \ErrorTok{in} \ErrorTok{the} \ErrorTok{pipeline} \ErrorTok{from} \ErrorTok{structured} \ErrorTok{text} \ErrorTok{to} \ErrorTok{interactive} \ErrorTok{Bayesian} \ErrorTok{network} \ErrorTok{visualization.}

\ErrorTok{\#\#\#} \ErrorTok{3.0.0} \ErrorTok{ExtractBayesDown{-}Data\_v1}
\ErrorTok{Build} \ErrorTok{data} \ErrorTok{frame} \ErrorTok{with} \ErrorTok{extractable} \ErrorTok{information} \ErrorTok{from} \ErrorTok{BayesDown}

\ErrorTok{:::} \FunctionTok{\{}\ErrorTok{.cell} \ErrorTok{quarto{-}private{-}1=\textquotesingle{}\{}\DataTypeTok{"key"}\FunctionTok{:}\StringTok{"colab"}\FunctionTok{,}\DataTypeTok{"value"}\FunctionTok{:\{}\DataTypeTok{"base\_uri"}\FunctionTok{:}\StringTok{"https://localhost:8080/"}\FunctionTok{,}\DataTypeTok{"height"}\FunctionTok{:}\DecValTok{157}\FunctionTok{\}\}}\ErrorTok{\textquotesingle{}} \ErrorTok{outputId=\textquotesingle{}e27e2c8c{-}bcb6{-}4e6b{-}e507{-}2b67d48ba814\textquotesingle{}\}}
\ErrorTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}} \FunctionTok{\{}\ErrorTok{.python} \ErrorTok{.cell{-}code}\FunctionTok{\}}
\ErrorTok{\#} \ErrorTok{read} \ErrorTok{sprinkler} \ErrorTok{example} \ErrorTok{{-}{-}} \ErrorTok{Occam} \ErrorTok{Colab} \ErrorTok{Online}
\ErrorTok{file\_path\_ex\_rain} \ErrorTok{=} \ErrorTok{"https://raw.githubusercontent.com/SingularitySmith/AMTAIR\_Prototype/main/data/example\_carlsmith/BayesDown.md"}

\ErrorTok{\#} \ErrorTok{Use} \ErrorTok{requests.get} \ErrorTok{to} \ErrorTok{fetch} \ErrorTok{content} \ErrorTok{from} \ErrorTok{URL}
\ErrorTok{response} \ErrorTok{=} \ErrorTok{requests.get(file\_path\_ex\_rain)}
\ErrorTok{response.raise\_for\_status()}  \ErrorTok{\#} \ErrorTok{Raise} \ErrorTok{HTTPError} \ErrorTok{for} \ErrorTok{bad} \ErrorTok{responses} \ErrorTok{(4xx} \ErrorTok{or} \ErrorTok{5xx)}

\ErrorTok{\#} \ErrorTok{Read} \ErrorTok{content} \ErrorTok{from} \ErrorTok{the} \ErrorTok{response}
\ErrorTok{md\_content\_ex\_rain} \ErrorTok{=} \ErrorTok{response.text}

\ErrorTok{md\_content\_ex\_rain}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
'[Existential_Catastrophe]: The destruction of humanity\'s long-term potential due to AI systems we\'ve lost control over. {"instantiations": ["existential_catastrophe_TRUE", "existential_catastrophe_FALSE"], "priors": {"p(existential_catastrophe_TRUE)": "0.05", "p(existential_catastrophe_FALSE)": "0.95"}, "posteriors": {"p(existential_catastrophe_TRUE|human_disempowerment_TRUE)": "0.95", "p(existential_catastrophe_TRUE|human_disempowerment_FALSE)": "0.0", "p(existential_catastrophe_FALSE|human_disempowerment_TRUE)": "0.05", "p(existential_catastrophe_FALSE|human_disempowerment_FALSE)": "1.0"}}\n- [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {"instantiations": ["human_disempowerment_TRUE", "human_disempowerment_FALSE"], "priors": {"p(human_disempowerment_TRUE)": "0.208", "p(human_disempowerment_FALSE)": "0.792"}, "posteriors": {"p(human_disempowerment_TRUE|scale_of_power_seeking_TRUE)": "1.0", "p(human_disempowerment_TRUE|scale_of_power_seeking_FALSE)": "0.0", "p(human_disempowerment_FALSE|scale_of_power_seeking_TRUE)": "0.0", "p(human_disempowerment_FALSE|scale_of_power_seeking_FALSE)": "1.0"}}\n    - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {"instantiations": ["scale_of_power_seeking_TRUE", "scale_of_power_seeking_FALSE"], "priors": {"p(scale_of_power_seeking_TRUE)": "0.208", "p(scale_of_power_seeking_FALSE)": "0.792"}, "posteriors": {"p(scale_of_power_seeking_TRUE|misaligned_power_seeking_TRUE, corrective_feedback_EFFECTIVE)": "0.25", "p(scale_of_power_seeking_TRUE|misaligned_power_seeking_TRUE, corrective_feedback_INEFFECTIVE)": "0.60", "p(scale_of_power_seeking_TRUE|misaligned_power_seeking_FALSE, corrective_feedback_EFFECTIVE)": "0.0", "p(scale_of_power_seeking_TRUE|misaligned_power_seeking_FALSE, corrective_feedback_INEFFECTIVE)": "0.0", "p(scale_of_power_seeking_FALSE|misaligned_power_seeking_TRUE, corrective_feedback_EFFECTIVE)": "0.75", "p(scale_of_power_seeking_FALSE|misaligned_power_seeking_TRUE, corrective_feedback_INEFFECTIVE)": "0.40", "p(scale_of_power_seeking_FALSE|misaligned_power_seeking_FALSE, corrective_feedback_EFFECTIVE)": "1.0", "p(scale_of_power_seeking_FALSE|misaligned_power_seeking_FALSE, corrective_feedback_INEFFECTIVE)": "1.0"}}\n        - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"], "priors": {"p(misaligned_power_seeking_TRUE)": "0.338", "p(misaligned_power_seeking_FALSE)": "0.662"}, "posteriors": {"p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)": "0.90", "p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_WITHHOLD)": "0.10", "p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)": "0.25", "p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_WITHHOLD)": "0.05", "p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)": "0.0", "p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_WITHHOLD)": "0.0", "p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)": "0.0", "p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_FALSE, deployment_decisions_WITHHOLD)": "0.0", "p(misaligned_power_seeking_FALSE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)": "0.10", "p(misaligned_power_seeking_FALSE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_WITHHOLD)": "0.90", "p(misaligned_power_seeking_FALSE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)": "0.75", "p(misaligned_power_seeking_FALSE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_WITHHOLD)": "0.95", "p(misaligned_power_seeking_FALSE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)": "1.0", "p(misaligned_power_seeking_FALSE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_WITHHOLD)": "1.0", "p(misaligned_power_seeking_FALSE|aps_systems_FALSE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)": "1.0", "p(misaligned_power_seeking_FALSE|aps_systems_FALSE, difficulty_of_alignment_FALSE, deployment_decisions_WITHHOLD)": "1.0"}}\n            - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {"instantiations": ["aps_systems_TRUE", "aps_systems_FALSE"], "priors": {"p(aps_systems_TRUE)": "0.65", "p(aps_systems_FALSE)": "0.35"}, "posteriors": {"p(aps_systems_TRUE|advanced_ai_capability_TRUE, agentic_planning_TRUE, strategic_awareness_TRUE)": "1.0", "p(aps_systems_TRUE|advanced_ai_capability_TRUE, agentic_planning_TRUE, strategic_awareness_FALSE)": "0.0", "p(aps_systems_TRUE|advanced_ai_capability_TRUE, agentic_planning_FALSE, strategic_awareness_TRUE)": "0.0", "p(aps_systems_TRUE|advanced_ai_capability_TRUE, agentic_planning_FALSE, strategic_awareness_FALSE)": "0.0", "p(aps_systems_TRUE|advanced_ai_capability_FALSE, agentic_planning_TRUE, strategic_awareness_TRUE)": "0.0", "p(aps_systems_TRUE|advanced_ai_capability_FALSE, agentic_planning_TRUE, strategic_awareness_FALSE)": "0.0", "p(aps_systems_TRUE|advanced_ai_capability_FALSE, agentic_planning_FALSE, strategic_awareness_TRUE)": "0.0", "p(aps_systems_TRUE|advanced_ai_capability_FALSE, agentic_planning_FALSE, strategic_awareness_FALSE)": "0.0", "p(aps_systems_FALSE|advanced_ai_capability_TRUE, agentic_planning_TRUE, strategic_awareness_TRUE)": "0.0", "p(aps_systems_FALSE|advanced_ai_capability_TRUE, agentic_planning_TRUE, strategic_awareness_FALSE)": "1.0", "p(aps_systems_FALSE|advanced_ai_capability_TRUE, agentic_planning_FALSE, strategic_awareness_TRUE)": "1.0", "p(aps_systems_FALSE|advanced_ai_capability_TRUE, agentic_planning_FALSE, strategic_awareness_FALSE)": "1.0", "p(aps_systems_FALSE|advanced_ai_capability_FALSE, agentic_planning_TRUE, strategic_awareness_TRUE)": "1.0", "p(aps_systems_FALSE|advanced_ai_capability_FALSE, agentic_planning_TRUE, strategic_awareness_FALSE)": "1.0", "p(aps_systems_FALSE|advanced_ai_capability_FALSE, agentic_planning_FALSE, strategic_awareness_TRUE)": "1.0", "p(aps_systems_FALSE|advanced_ai_capability_FALSE, agentic_planning_FALSE, strategic_awareness_FALSE)": "1.0"}}\n                - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {"instantiations": ["advanced_ai_capability_TRUE", "advanced_ai_capability_FALSE"], "priors": {"p(advanced_ai_capability_TRUE)": "0.80", "p(advanced_ai_capability_FALSE)": "0.20"}}\n                - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {"instantiations": ["agentic_planning_TRUE", "agentic_planning_FALSE"], "priors": {"p(agentic_planning_TRUE)": "0.85", "p(agentic_planning_FALSE)": "0.15"}}\n                - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {"instantiations": ["strategic_awareness_TRUE", "strategic_awareness_FALSE"], "priors": {"p(strategic_awareness_TRUE)": "0.75", "p(strategic_awareness_FALSE)": "0.25"}}\n            - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {"instantiations": ["difficulty_of_alignment_TRUE", "difficulty_of_alignment_FALSE"], "priors": {"p(difficulty_of_alignment_TRUE)": "0.40", "p(difficulty_of_alignment_FALSE)": "0.60"}, "posteriors": {"p(difficulty_of_alignment_TRUE|instrumental_convergence_TRUE, problems_with_proxies_TRUE, problems_with_search_TRUE)": "0.85", "p(difficulty_of_alignment_TRUE|instrumental_convergence_TRUE, problems_with_proxies_TRUE, problems_with_search_FALSE)": "0.70", "p(difficulty_of_alignment_TRUE|instrumental_convergence_TRUE, problems_with_proxies_FALSE, problems_with_search_TRUE)": "0.60", "p(difficulty_of_alignment_TRUE|instrumental_convergence_TRUE, problems_with_proxies_FALSE, problems_with_search_FALSE)": "0.40", "p(difficulty_of_alignment_TRUE|instrumental_convergence_FALSE, problems_with_proxies_TRUE, problems_with_search_TRUE)": "0.55", "p(difficulty_of_alignment_TRUE|instrumental_convergence_FALSE, problems_with_proxies_TRUE, problems_with_search_FALSE)": "0.40", "p(difficulty_of_alignment_TRUE|instrumental_convergence_FALSE, problems_with_proxies_FALSE, problems_with_search_TRUE)": "0.30", "p(difficulty_of_alignment_TRUE|instrumental_convergence_FALSE, problems_with_proxies_FALSE, problems_with_search_FALSE)": "0.10", "p(difficulty_of_alignment_FALSE|instrumental_convergence_TRUE, problems_with_proxies_TRUE, problems_with_search_TRUE)": "0.15", "p(difficulty_of_alignment_FALSE|instrumental_convergence_TRUE, problems_with_proxies_TRUE, problems_with_search_FALSE)": "0.30", "p(difficulty_of_alignment_FALSE|instrumental_convergence_TRUE, problems_with_proxies_FALSE, problems_with_search_TRUE)": "0.40", "p(difficulty_of_alignment_FALSE|instrumental_convergence_TRUE, problems_with_proxies_FALSE, problems_with_search_FALSE)": "0.60", "p(difficulty_of_alignment_FALSE|instrumental_convergence_FALSE, problems_with_proxies_TRUE, problems_with_search_TRUE)": "0.45", "p(difficulty_of_alignment_FALSE|instrumental_convergence_FALSE, problems_with_proxies_TRUE, problems_with_search_FALSE)": "0.60", "p(difficulty_of_alignment_FALSE|instrumental_convergence_FALSE, problems_with_proxies_FALSE, problems_with_search_TRUE)": "0.70", "p(difficulty_of_alignment_FALSE|instrumental_convergence_FALSE, problems_with_proxies_FALSE, problems_with_search_FALSE)": "0.90"}}\n                - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {"instantiations": ["instrumental_convergence_TRUE", "instrumental_convergence_FALSE"], "priors": {"p(instrumental_convergence_TRUE)": "0.75", "p(instrumental_convergence_FALSE)": "0.25"}}\n                - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {"instantiations": ["problems_with_proxies_TRUE", "problems_with_proxies_FALSE"], "priors": {"p(problems_with_proxies_TRUE)": "0.80", "p(problems_with_proxies_FALSE)": "0.20"}}\n                - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {"instantiations": ["problems_with_search_TRUE", "problems_with_search_FALSE"], "priors": {"p(problems_with_search_TRUE)": "0.70", "p(problems_with_search_FALSE)": "0.30"}}\n            - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {"instantiations": ["deployment_decisions_DEPLOY", "deployment_decisions_WITHHOLD"], "priors": {"p(deployment_decisions_DEPLOY)": "0.70", "p(deployment_decisions_WITHHOLD)": "0.30"}, "posteriors": {"p(deployment_decisions_DEPLOY|incentives_to_build_aps_STRONG, deception_by_ai_TRUE)": "0.90", "p(deployment_decisions_DEPLOY|incentives_to_build_aps_STRONG, deception_by_ai_FALSE)": "0.75", "p(deployment_decisions_DEPLOY|incentives_to_build_aps_WEAK, deception_by_ai_TRUE)": "0.60", "p(deployment_decisions_DEPLOY|incentives_to_build_aps_WEAK, deception_by_ai_FALSE)": "0.30", "p(deployment_decisions_WITHHOLD|incentives_to_build_aps_STRONG, deception_by_ai_TRUE)": "0.10", "p(deployment_decisions_WITHHOLD|incentives_to_build_aps_STRONG, deception_by_ai_FALSE)": "0.25", "p(deployment_decisions_WITHHOLD|incentives_to_build_aps_WEAK, deception_by_ai_TRUE)": "0.40", "p(deployment_decisions_WITHHOLD|incentives_to_build_aps_WEAK, deception_by_ai_FALSE)": "0.70"}}\n                - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {"instantiations": ["incentives_to_build_aps_STRONG", "incentives_to_build_aps_WEAK"], "priors": {"p(incentives_to_build_aps_STRONG)": "0.80", "p(incentives_to_build_aps_WEAK)": "0.20"}, "posteriors": {"p(incentives_to_build_aps_STRONG|usefulness_of_aps_HIGH, competitive_dynamics_STRONG)": "0.95", "p(incentives_to_build_aps_STRONG|usefulness_of_aps_HIGH, competitive_dynamics_WEAK)": "0.80", "p(incentives_to_build_aps_STRONG|usefulness_of_aps_LOW, competitive_dynamics_STRONG)": "0.70", "p(incentives_to_build_aps_STRONG|usefulness_of_aps_LOW, competitive_dynamics_WEAK)": "0.30", "p(incentives_to_build_aps_WEAK|usefulness_of_aps_HIGH, competitive_dynamics_STRONG)": "0.05", "p(incentives_to_build_aps_WEAK|usefulness_of_aps_HIGH, competitive_dynamics_WEAK)": "0.20", "p(incentives_to_build_aps_WEAK|usefulness_of_aps_LOW, competitive_dynamics_STRONG)": "0.30", "p(incentives_to_build_aps_WEAK|usefulness_of_aps_LOW, competitive_dynamics_WEAK)": "0.70"}}\n                    - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {"instantiations": ["usefulness_of_aps_HIGH", "usefulness_of_aps_LOW"], "priors": {"p(usefulness_of_aps_HIGH)": "0.85", "p(usefulness_of_aps_LOW)": "0.15"}}\n                    - [Competitive_Dynamics]: Competitive pressures between AI developers. {"instantiations": ["competitive_dynamics_STRONG", "competitive_dynamics_WEAK"], "priors": {"p(competitive_dynamics_STRONG)": "0.75", "p(competitive_dynamics_WEAK)": "0.25"}}\n                - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {"instantiations": ["deception_by_ai_TRUE", "deception_by_ai_FALSE"], "priors": {"p(deception_by_ai_TRUE)": "0.50", "p(deception_by_ai_FALSE)": "0.50"}}\n        - [Corrective_Feedback]: Human society implementing corrections after observing problems. {"instantiations": ["corrective_feedback_EFFECTIVE", "corrective_feedback_INEFFECTIVE"], "priors": {"p(corrective_feedback_EFFECTIVE)": "0.60", "p(corrective_feedback_INEFFECTIVE)": "0.40"}, "posteriors": {"p(corrective_feedback_EFFECTIVE|warning_shots_OBSERVED, rapid_capability_escalation_TRUE)": "0.40", "p(corrective_feedback_EFFECTIVE|warning_shots_OBSERVED, rapid_capability_escalation_FALSE)": "0.80", "p(corrective_feedback_EFFECTIVE|warning_shots_UNOBSERVED, rapid_capability_escalation_TRUE)": "0.15", "p(corrective_feedback_EFFECTIVE|warning_shots_UNOBSERVED, rapid_capability_escalation_FALSE)": "0.50", "p(corrective_feedback_INEFFECTIVE|warning_shots_OBSERVED, rapid_capability_escalation_TRUE)": "0.60", "p(corrective_feedback_INEFFECTIVE|warning_shots_OBSERVED, rapid_capability_escalation_FALSE)": "0.20", "p(corrective_feedback_INEFFECTIVE|warning_shots_UNOBSERVED, rapid_capability_escalation_TRUE)": "0.85", "p(corrective_feedback_INEFFECTIVE|warning_shots_UNOBSERVED, rapid_capability_escalation_FALSE)": "0.50"}}\n            - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {"instantiations": ["warning_shots_OBSERVED", "warning_shots_UNOBSERVED"], "priors": {"p(warning_shots_OBSERVED)": "0.70", "p(warning_shots_UNOBSERVED)": "0.30"}}\n            - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {"instantiations": ["rapid_capability_escalation_TRUE", "rapid_capability_escalation_FALSE"], "priors": {"p(rapid_capability_escalation_TRUE)": "0.45", "p(rapid_capability_escalation_FALSE)": "0.55"}}\n[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {"instantiations": ["barriers_to_understanding_HIGH", "barriers_to_understanding_LOW"], "priors": {"p(barriers_to_understanding_HIGH)": "0.70", "p(barriers_to_understanding_LOW)": "0.30"}, "posteriors": {"p(barriers_to_understanding_HIGH|misaligned_power_seeking_TRUE)": "0.85", "p(barriers_to_understanding_HIGH|misaligned_power_seeking_FALSE)": "0.60", "p(barriers_to_understanding_LOW|misaligned_power_seeking_TRUE)": "0.15", "p(barriers_to_understanding_LOW|misaligned_power_seeking_FALSE)": "0.40"}}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"], "priors": {"p(misaligned_power_seeking_TRUE)": "0.338", "p(misaligned_power_seeking_FALSE)": "0.662"}}\n[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {"instantiations": ["adversarial_dynamics_TRUE", "adversarial_dynamics_FALSE"], "priors": {"p(adversarial_dynamics_TRUE)": "0.60", "p(adversarial_dynamics_FALSE)": "0.40"}, "posteriors": {"p(adversarial_dynamics_TRUE|misaligned_power_seeking_TRUE)": "0.95", "p(adversarial_dynamics_TRUE|misaligned_power_seeking_FALSE)": "0.10", "p(adversarial_dynamics_FALSE|misaligned_power_seeking_TRUE)": "0.05", "p(adversarial_dynamics_FALSE|misaligned_power_seeking_FALSE)": "0.90"}}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"], "priors": {"p(misaligned_power_seeking_TRUE)": "0.338", "p(misaligned_power_seeking_FALSE)": "0.662"}}\n[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {"instantiations": ["stakes_of_error_HIGH", "stakes_of_error_LOW"], "priors": {"p(stakes_of_error_HIGH)": "0.85", "p(stakes_of_error_LOW)": "0.15"}, "posteriors": {"p(stakes_of_error_HIGH|misaligned_power_seeking_TRUE)": "0.95", "p(stakes_of_error_HIGH|misaligned_power_seeking_FALSE)": "0.50", "p(stakes_of_error_LOW|misaligned_power_seeking_TRUE)": "0.05", "p(stakes_of_error_LOW|misaligned_power_seeking_FALSE)": "0.50"}}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"], "priors": {"p(misaligned_power_seeking_TRUE)": "0.338", "p(misaligned_power_seeking_FALSE)": "0.662"}}\n'
\end{verbatim}

:::

\subsection{3.0.1 Test BayesDown
Extraction}\label{test-bayesdown-extraction}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{display(Markdown(md\_content\_ex\_rain)) }\CommentTok{\# view BayesDown file formatted as MarkDown}
\end{Highlighting}
\end{Shaded}

{[}Existential\_Catastrophe{]}: The destruction of humanity's long-term
potential due to AI systems we've lost control over.
\{``instantiations'': {[}``existential\_catastrophe\_TRUE'',
``existential\_catastrophe\_FALSE''{]}, ``priors'':
\{``p(existential\_catastrophe\_TRUE)'': ``0.05'',
``p(existential\_catastrophe\_FALSE)'': ``0.95''\}, ``posteriors'':
\{``p(existential\_catastrophe\_TRUE\textbar human\_disempowerment\_TRUE)'':
``0.95'',
``p(existential\_catastrophe\_TRUE\textbar human\_disempowerment\_FALSE)'':
``0.0'',
``p(existential\_catastrophe\_FALSE\textbar human\_disempowerment\_TRUE)'':
``0.05'',
``p(existential\_catastrophe\_FALSE\textbar human\_disempowerment\_FALSE)'':
``1.0''\}\} - {[}Human\_Disempowerment{]}: Permanent and collective
disempowerment of humanity relative to AI systems. \{``instantiations'':
{[}``human\_disempowerment\_TRUE'', ``human\_disempowerment\_FALSE''{]},
``priors'': \{``p(human\_disempowerment\_TRUE)'': ``0.208'',
``p(human\_disempowerment\_FALSE)'': ``0.792''\}, ``posteriors'':
\{``p(human\_disempowerment\_TRUE\textbar scale\_of\_power\_seeking\_TRUE)'':
``1.0'',
``p(human\_disempowerment\_TRUE\textbar scale\_of\_power\_seeking\_FALSE)'':
``0.0'',
``p(human\_disempowerment\_FALSE\textbar scale\_of\_power\_seeking\_TRUE)'':
``0.0'',
``p(human\_disempowerment\_FALSE\textbar scale\_of\_power\_seeking\_FALSE)'':
``1.0''\}\} - {[}Scale\_Of\_Power\_Seeking{]}: Power-seeking by AI
systems scaling to the point of permanently disempowering all of
humanity. \{``instantiations'': {[}``scale\_of\_power\_seeking\_TRUE'',
``scale\_of\_power\_seeking\_FALSE''{]}, ``priors'':
\{``p(scale\_of\_power\_seeking\_TRUE)'': ``0.208'',
``p(scale\_of\_power\_seeking\_FALSE)'': ``0.792''\}, ``posteriors'':
\{``p(scale\_of\_power\_seeking\_TRUE\textbar misaligned\_power\_seeking\_TRUE,
corrective\_feedback\_EFFECTIVE)'': ``0.25'',
``p(scale\_of\_power\_seeking\_TRUE\textbar misaligned\_power\_seeking\_TRUE,
corrective\_feedback\_INEFFECTIVE)'': ``0.60'',
``p(scale\_of\_power\_seeking\_TRUE\textbar misaligned\_power\_seeking\_FALSE,
corrective\_feedback\_EFFECTIVE)'': ``0.0'',
``p(scale\_of\_power\_seeking\_TRUE\textbar misaligned\_power\_seeking\_FALSE,
corrective\_feedback\_INEFFECTIVE)'': ``0.0'',
``p(scale\_of\_power\_seeking\_FALSE\textbar misaligned\_power\_seeking\_TRUE,
corrective\_feedback\_EFFECTIVE)'': ``0.75'',
``p(scale\_of\_power\_seeking\_FALSE\textbar misaligned\_power\_seeking\_TRUE,
corrective\_feedback\_INEFFECTIVE)'': ``0.40'',
``p(scale\_of\_power\_seeking\_FALSE\textbar misaligned\_power\_seeking\_FALSE,
corrective\_feedback\_EFFECTIVE)'': ``1.0'',
``p(scale\_of\_power\_seeking\_FALSE\textbar misaligned\_power\_seeking\_FALSE,
corrective\_feedback\_INEFFECTIVE)'': ``1.0''\}\} -
{[}Misaligned\_Power\_Seeking{]}: Deployed AI systems seeking power in
unintended and high-impact ways due to problems with their objectives.
\{``instantiations'': {[}``misaligned\_power\_seeking\_TRUE'',
``misaligned\_power\_seeking\_FALSE''{]}, ``priors'':
\{``p(misaligned\_power\_seeking\_TRUE)'': ``0.338'',
``p(misaligned\_power\_seeking\_FALSE)'': ``0.662''\}, ``posteriors'':
\{``p(misaligned\_power\_seeking\_TRUE\textbar aps\_systems\_TRUE,
difficulty\_of\_alignment\_TRUE, deployment\_decisions\_DEPLOY)'':
``0.90'',
``p(misaligned\_power\_seeking\_TRUE\textbar aps\_systems\_TRUE,
difficulty\_of\_alignment\_TRUE, deployment\_decisions\_WITHHOLD)'':
``0.10'',
``p(misaligned\_power\_seeking\_TRUE\textbar aps\_systems\_TRUE,
difficulty\_of\_alignment\_FALSE, deployment\_decisions\_DEPLOY)'':
``0.25'',
``p(misaligned\_power\_seeking\_TRUE\textbar aps\_systems\_TRUE,
difficulty\_of\_alignment\_FALSE, deployment\_decisions\_WITHHOLD)'':
``0.05'',
``p(misaligned\_power\_seeking\_TRUE\textbar aps\_systems\_FALSE,
difficulty\_of\_alignment\_TRUE, deployment\_decisions\_DEPLOY)'':
``0.0'',
``p(misaligned\_power\_seeking\_TRUE\textbar aps\_systems\_FALSE,
difficulty\_of\_alignment\_TRUE, deployment\_decisions\_WITHHOLD)'':
``0.0'',
``p(misaligned\_power\_seeking\_TRUE\textbar aps\_systems\_FALSE,
difficulty\_of\_alignment\_FALSE, deployment\_decisions\_DEPLOY)'':
``0.0'',
``p(misaligned\_power\_seeking\_TRUE\textbar aps\_systems\_FALSE,
difficulty\_of\_alignment\_FALSE, deployment\_decisions\_WITHHOLD)'':
``0.0'',
``p(misaligned\_power\_seeking\_FALSE\textbar aps\_systems\_TRUE,
difficulty\_of\_alignment\_TRUE, deployment\_decisions\_DEPLOY)'':
``0.10'',
``p(misaligned\_power\_seeking\_FALSE\textbar aps\_systems\_TRUE,
difficulty\_of\_alignment\_TRUE, deployment\_decisions\_WITHHOLD)'':
``0.90'',
``p(misaligned\_power\_seeking\_FALSE\textbar aps\_systems\_TRUE,
difficulty\_of\_alignment\_FALSE, deployment\_decisions\_DEPLOY)'':
``0.75'',
``p(misaligned\_power\_seeking\_FALSE\textbar aps\_systems\_TRUE,
difficulty\_of\_alignment\_FALSE, deployment\_decisions\_WITHHOLD)'':
``0.95'',
``p(misaligned\_power\_seeking\_FALSE\textbar aps\_systems\_FALSE,
difficulty\_of\_alignment\_TRUE, deployment\_decisions\_DEPLOY)'':
``1.0'',
``p(misaligned\_power\_seeking\_FALSE\textbar aps\_systems\_FALSE,
difficulty\_of\_alignment\_TRUE, deployment\_decisions\_WITHHOLD)'':
``1.0'',
``p(misaligned\_power\_seeking\_FALSE\textbar aps\_systems\_FALSE,
difficulty\_of\_alignment\_FALSE, deployment\_decisions\_DEPLOY)'':
``1.0'',
``p(misaligned\_power\_seeking\_FALSE\textbar aps\_systems\_FALSE,
difficulty\_of\_alignment\_FALSE, deployment\_decisions\_WITHHOLD)'':
``1.0''\}\} - {[}APS\_Systems{]}: AI systems with advanced capabilities,
agentic planning, and strategic awareness. \{``instantiations'':
{[}``aps\_systems\_TRUE'', ``aps\_systems\_FALSE''{]}, ``priors'':
\{``p(aps\_systems\_TRUE)'': ``0.65'', ``p(aps\_systems\_FALSE)'':
``0.35''\}, ``posteriors'':
\{``p(aps\_systems\_TRUE\textbar advanced\_ai\_capability\_TRUE,
agentic\_planning\_TRUE, strategic\_awareness\_TRUE)'': ``1.0'',
``p(aps\_systems\_TRUE\textbar advanced\_ai\_capability\_TRUE,
agentic\_planning\_TRUE, strategic\_awareness\_FALSE)'': ``0.0'',
``p(aps\_systems\_TRUE\textbar advanced\_ai\_capability\_TRUE,
agentic\_planning\_FALSE, strategic\_awareness\_TRUE)'': ``0.0'',
``p(aps\_systems\_TRUE\textbar advanced\_ai\_capability\_TRUE,
agentic\_planning\_FALSE, strategic\_awareness\_FALSE)'': ``0.0'',
``p(aps\_systems\_TRUE\textbar advanced\_ai\_capability\_FALSE,
agentic\_planning\_TRUE, strategic\_awareness\_TRUE)'': ``0.0'',
``p(aps\_systems\_TRUE\textbar advanced\_ai\_capability\_FALSE,
agentic\_planning\_TRUE, strategic\_awareness\_FALSE)'': ``0.0'',
``p(aps\_systems\_TRUE\textbar advanced\_ai\_capability\_FALSE,
agentic\_planning\_FALSE, strategic\_awareness\_TRUE)'': ``0.0'',
``p(aps\_systems\_TRUE\textbar advanced\_ai\_capability\_FALSE,
agentic\_planning\_FALSE, strategic\_awareness\_FALSE)'': ``0.0'',
``p(aps\_systems\_FALSE\textbar advanced\_ai\_capability\_TRUE,
agentic\_planning\_TRUE, strategic\_awareness\_TRUE)'': ``0.0'',
``p(aps\_systems\_FALSE\textbar advanced\_ai\_capability\_TRUE,
agentic\_planning\_TRUE, strategic\_awareness\_FALSE)'': ``1.0'',
``p(aps\_systems\_FALSE\textbar advanced\_ai\_capability\_TRUE,
agentic\_planning\_FALSE, strategic\_awareness\_TRUE)'': ``1.0'',
``p(aps\_systems\_FALSE\textbar advanced\_ai\_capability\_TRUE,
agentic\_planning\_FALSE, strategic\_awareness\_FALSE)'': ``1.0'',
``p(aps\_systems\_FALSE\textbar advanced\_ai\_capability\_FALSE,
agentic\_planning\_TRUE, strategic\_awareness\_TRUE)'': ``1.0'',
``p(aps\_systems\_FALSE\textbar advanced\_ai\_capability\_FALSE,
agentic\_planning\_TRUE, strategic\_awareness\_FALSE)'': ``1.0'',
``p(aps\_systems\_FALSE\textbar advanced\_ai\_capability\_FALSE,
agentic\_planning\_FALSE, strategic\_awareness\_TRUE)'': ``1.0'',
``p(aps\_systems\_FALSE\textbar advanced\_ai\_capability\_FALSE,
agentic\_planning\_FALSE, strategic\_awareness\_FALSE)'': ``1.0''\}\} -
{[}Advanced\_AI\_Capability{]}: AI systems that outperform humans on
tasks that grant significant power in the world. \{``instantiations'':
{[}``advanced\_ai\_capability\_TRUE'',
``advanced\_ai\_capability\_FALSE''{]}, ``priors'':
\{``p(advanced\_ai\_capability\_TRUE)'': ``0.80'',
``p(advanced\_ai\_capability\_FALSE)'': ``0.20''\}\} -
{[}Agentic\_Planning{]}: AI systems making and executing plans based on
world models to achieve objectives. \{``instantiations'':
{[}``agentic\_planning\_TRUE'', ``agentic\_planning\_FALSE''{]},
``priors'': \{``p(agentic\_planning\_TRUE)'': ``0.85'',
``p(agentic\_planning\_FALSE)'': ``0.15''\}\} -
{[}Strategic\_Awareness{]}: AI systems with models accurately
representing power dynamics with humans. \{``instantiations'':
{[}``strategic\_awareness\_TRUE'', ``strategic\_awareness\_FALSE''{]},
``priors'': \{``p(strategic\_awareness\_TRUE)'': ``0.75'',
``p(strategic\_awareness\_FALSE)'': ``0.25''\}\} -
{[}Difficulty\_Of\_Alignment{]}: It is harder to build aligned systems
than misaligned systems that are attractive to deploy.
\{``instantiations'': {[}``difficulty\_of\_alignment\_TRUE'',
``difficulty\_of\_alignment\_FALSE''{]}, ``priors'':
\{``p(difficulty\_of\_alignment\_TRUE)'': ``0.40'',
``p(difficulty\_of\_alignment\_FALSE)'': ``0.60''\}, ``posteriors'':
\{``p(difficulty\_of\_alignment\_TRUE\textbar instrumental\_convergence\_TRUE,
problems\_with\_proxies\_TRUE, problems\_with\_search\_TRUE)'':
``0.85'',
``p(difficulty\_of\_alignment\_TRUE\textbar instrumental\_convergence\_TRUE,
problems\_with\_proxies\_TRUE, problems\_with\_search\_FALSE)'':
``0.70'',
``p(difficulty\_of\_alignment\_TRUE\textbar instrumental\_convergence\_TRUE,
problems\_with\_proxies\_FALSE, problems\_with\_search\_TRUE)'':
``0.60'',
``p(difficulty\_of\_alignment\_TRUE\textbar instrumental\_convergence\_TRUE,
problems\_with\_proxies\_FALSE, problems\_with\_search\_FALSE)'':
``0.40'',
``p(difficulty\_of\_alignment\_TRUE\textbar instrumental\_convergence\_FALSE,
problems\_with\_proxies\_TRUE, problems\_with\_search\_TRUE)'':
``0.55'',
``p(difficulty\_of\_alignment\_TRUE\textbar instrumental\_convergence\_FALSE,
problems\_with\_proxies\_TRUE, problems\_with\_search\_FALSE)'':
``0.40'',
``p(difficulty\_of\_alignment\_TRUE\textbar instrumental\_convergence\_FALSE,
problems\_with\_proxies\_FALSE, problems\_with\_search\_TRUE)'':
``0.30'',
``p(difficulty\_of\_alignment\_TRUE\textbar instrumental\_convergence\_FALSE,
problems\_with\_proxies\_FALSE, problems\_with\_search\_FALSE)'':
``0.10'',
``p(difficulty\_of\_alignment\_FALSE\textbar instrumental\_convergence\_TRUE,
problems\_with\_proxies\_TRUE, problems\_with\_search\_TRUE)'':
``0.15'',
``p(difficulty\_of\_alignment\_FALSE\textbar instrumental\_convergence\_TRUE,
problems\_with\_proxies\_TRUE, problems\_with\_search\_FALSE)'':
``0.30'',
``p(difficulty\_of\_alignment\_FALSE\textbar instrumental\_convergence\_TRUE,
problems\_with\_proxies\_FALSE, problems\_with\_search\_TRUE)'':
``0.40'',
``p(difficulty\_of\_alignment\_FALSE\textbar instrumental\_convergence\_TRUE,
problems\_with\_proxies\_FALSE, problems\_with\_search\_FALSE)'':
``0.60'',
``p(difficulty\_of\_alignment\_FALSE\textbar instrumental\_convergence\_FALSE,
problems\_with\_proxies\_TRUE, problems\_with\_search\_TRUE)'':
``0.45'',
``p(difficulty\_of\_alignment\_FALSE\textbar instrumental\_convergence\_FALSE,
problems\_with\_proxies\_TRUE, problems\_with\_search\_FALSE)'':
``0.60'',
``p(difficulty\_of\_alignment\_FALSE\textbar instrumental\_convergence\_FALSE,
problems\_with\_proxies\_FALSE, problems\_with\_search\_TRUE)'':
``0.70'',
``p(difficulty\_of\_alignment\_FALSE\textbar instrumental\_convergence\_FALSE,
problems\_with\_proxies\_FALSE, problems\_with\_search\_FALSE)'':
``0.90''\}\} - {[}Instrumental\_Convergence{]}: AI systems with
misaligned objectives tend to seek power as an instrumental goal.
\{``instantiations'': {[}``instrumental\_convergence\_TRUE'',
``instrumental\_convergence\_FALSE''{]}, ``priors'':
\{``p(instrumental\_convergence\_TRUE)'': ``0.75'',
``p(instrumental\_convergence\_FALSE)'': ``0.25''\}\} -
{[}Problems\_With\_Proxies{]}: Optimizing for proxy objectives breaks
correlations with intended goals. \{``instantiations'':
{[}``problems\_with\_proxies\_TRUE'',
``problems\_with\_proxies\_FALSE''{]}, ``priors'':
\{``p(problems\_with\_proxies\_TRUE)'': ``0.80'',
``p(problems\_with\_proxies\_FALSE)'': ``0.20''\}\} -
{[}Problems\_With\_Search{]}: Search processes can yield systems
pursuing different objectives than intended. \{``instantiations'':
{[}``problems\_with\_search\_TRUE'',
``problems\_with\_search\_FALSE''{]}, ``priors'':
\{``p(problems\_with\_search\_TRUE)'': ``0.70'',
``p(problems\_with\_search\_FALSE)'': ``0.30''\}\} -
{[}Deployment\_Decisions{]}: Decisions to deploy potentially misaligned
AI systems. \{``instantiations'': {[}``deployment\_decisions\_DEPLOY'',
``deployment\_decisions\_WITHHOLD''{]}, ``priors'':
\{``p(deployment\_decisions\_DEPLOY)'': ``0.70'',
``p(deployment\_decisions\_WITHHOLD)'': ``0.30''\}, ``posteriors'':
\{``p(deployment\_decisions\_DEPLOY\textbar incentives\_to\_build\_aps\_STRONG,
deception\_by\_ai\_TRUE)'': ``0.90'',
``p(deployment\_decisions\_DEPLOY\textbar incentives\_to\_build\_aps\_STRONG,
deception\_by\_ai\_FALSE)'': ``0.75'',
``p(deployment\_decisions\_DEPLOY\textbar incentives\_to\_build\_aps\_WEAK,
deception\_by\_ai\_TRUE)'': ``0.60'',
``p(deployment\_decisions\_DEPLOY\textbar incentives\_to\_build\_aps\_WEAK,
deception\_by\_ai\_FALSE)'': ``0.30'',
``p(deployment\_decisions\_WITHHOLD\textbar incentives\_to\_build\_aps\_STRONG,
deception\_by\_ai\_TRUE)'': ``0.10'',
``p(deployment\_decisions\_WITHHOLD\textbar incentives\_to\_build\_aps\_STRONG,
deception\_by\_ai\_FALSE)'': ``0.25'',
``p(deployment\_decisions\_WITHHOLD\textbar incentives\_to\_build\_aps\_WEAK,
deception\_by\_ai\_TRUE)'': ``0.40'',
``p(deployment\_decisions\_WITHHOLD\textbar incentives\_to\_build\_aps\_WEAK,
deception\_by\_ai\_FALSE)'': ``0.70''\}\} -
{[}Incentives\_To\_Build\_APS{]}: Strong incentives to build and deploy
APS systems. \{``instantiations'':
{[}``incentives\_to\_build\_aps\_STRONG'',
``incentives\_to\_build\_aps\_WEAK''{]}, ``priors'':
\{``p(incentives\_to\_build\_aps\_STRONG)'': ``0.80'',
``p(incentives\_to\_build\_aps\_WEAK)'': ``0.20''\}, ``posteriors'':
\{``p(incentives\_to\_build\_aps\_STRONG\textbar usefulness\_of\_aps\_HIGH,
competitive\_dynamics\_STRONG)'': ``0.95'',
``p(incentives\_to\_build\_aps\_STRONG\textbar usefulness\_of\_aps\_HIGH,
competitive\_dynamics\_WEAK)'': ``0.80'',
``p(incentives\_to\_build\_aps\_STRONG\textbar usefulness\_of\_aps\_LOW,
competitive\_dynamics\_STRONG)'': ``0.70'',
``p(incentives\_to\_build\_aps\_STRONG\textbar usefulness\_of\_aps\_LOW,
competitive\_dynamics\_WEAK)'': ``0.30'',
``p(incentives\_to\_build\_aps\_WEAK\textbar usefulness\_of\_aps\_HIGH,
competitive\_dynamics\_STRONG)'': ``0.05'',
``p(incentives\_to\_build\_aps\_WEAK\textbar usefulness\_of\_aps\_HIGH,
competitive\_dynamics\_WEAK)'': ``0.20'',
``p(incentives\_to\_build\_aps\_WEAK\textbar usefulness\_of\_aps\_LOW,
competitive\_dynamics\_STRONG)'': ``0.30'',
``p(incentives\_to\_build\_aps\_WEAK\textbar usefulness\_of\_aps\_LOW,
competitive\_dynamics\_WEAK)'': ``0.70''\}\} -
{[}Usefulness\_Of\_APS{]}: APS systems are very useful for many valuable
tasks. \{``instantiations'': {[}``usefulness\_of\_aps\_HIGH'',
``usefulness\_of\_aps\_LOW''{]}, ``priors'':
\{``p(usefulness\_of\_aps\_HIGH)'': ``0.85'',
``p(usefulness\_of\_aps\_LOW)'': ``0.15''\}\} -
{[}Competitive\_Dynamics{]}: Competitive pressures between AI
developers. \{``instantiations'': {[}``competitive\_dynamics\_STRONG'',
``competitive\_dynamics\_WEAK''{]}, ``priors'':
\{``p(competitive\_dynamics\_STRONG)'': ``0.75'',
``p(competitive\_dynamics\_WEAK)'': ``0.25''\}\} -
{[}Deception\_By\_AI{]}: AI systems deceiving humans about their true
objectives. \{``instantiations'': {[}``deception\_by\_ai\_TRUE'',
``deception\_by\_ai\_FALSE''{]}, ``priors'':
\{``p(deception\_by\_ai\_TRUE)'': ``0.50'',
``p(deception\_by\_ai\_FALSE)'': ``0.50''\}\} -
{[}Corrective\_Feedback{]}: Human society implementing corrections after
observing problems. \{``instantiations'':
{[}``corrective\_feedback\_EFFECTIVE'',
``corrective\_feedback\_INEFFECTIVE''{]}, ``priors'':
\{``p(corrective\_feedback\_EFFECTIVE)'': ``0.60'',
``p(corrective\_feedback\_INEFFECTIVE)'': ``0.40''\}, ``posteriors'':
\{``p(corrective\_feedback\_EFFECTIVE\textbar warning\_shots\_OBSERVED,
rapid\_capability\_escalation\_TRUE)'': ``0.40'',
``p(corrective\_feedback\_EFFECTIVE\textbar warning\_shots\_OBSERVED,
rapid\_capability\_escalation\_FALSE)'': ``0.80'',
``p(corrective\_feedback\_EFFECTIVE\textbar warning\_shots\_UNOBSERVED,
rapid\_capability\_escalation\_TRUE)'': ``0.15'',
``p(corrective\_feedback\_EFFECTIVE\textbar warning\_shots\_UNOBSERVED,
rapid\_capability\_escalation\_FALSE)'': ``0.50'',
``p(corrective\_feedback\_INEFFECTIVE\textbar warning\_shots\_OBSERVED,
rapid\_capability\_escalation\_TRUE)'': ``0.60'',
``p(corrective\_feedback\_INEFFECTIVE\textbar warning\_shots\_OBSERVED,
rapid\_capability\_escalation\_FALSE)'': ``0.20'',
``p(corrective\_feedback\_INEFFECTIVE\textbar warning\_shots\_UNOBSERVED,
rapid\_capability\_escalation\_TRUE)'': ``0.85'',
``p(corrective\_feedback\_INEFFECTIVE\textbar warning\_shots\_UNOBSERVED,
rapid\_capability\_escalation\_FALSE)'': ``0.50''\}\} -
{[}Warning\_Shots{]}: Observable failures in weaker systems before
catastrophic risks. \{``instantiations'':
{[}``warning\_shots\_OBSERVED'', ``warning\_shots\_UNOBSERVED''{]},
``priors'': \{``p(warning\_shots\_OBSERVED)'': ``0.70'',
``p(warning\_shots\_UNOBSERVED)'': ``0.30''\}\} -
{[}Rapid\_Capability\_Escalation{]}: AI capabilities escalating very
rapidly, allowing little time for correction. \{``instantiations'':
{[}``rapid\_capability\_escalation\_TRUE'',
``rapid\_capability\_escalation\_FALSE''{]}, ``priors'':
\{``p(rapid\_capability\_escalation\_TRUE)'': ``0.45'',
``p(rapid\_capability\_escalation\_FALSE)'': ``0.55''\}\}
{[}Barriers\_To\_Understanding{]}: Difficulty in understanding the
internal workings of advanced AI systems. \{``instantiations'':
{[}``barriers\_to\_understanding\_HIGH'',
``barriers\_to\_understanding\_LOW''{]}, ``priors'':
\{``p(barriers\_to\_understanding\_HIGH)'': ``0.70'',
``p(barriers\_to\_understanding\_LOW)'': ``0.30''\}, ``posteriors'':
\{``p(barriers\_to\_understanding\_HIGH\textbar misaligned\_power\_seeking\_TRUE)'':
``0.85'',
``p(barriers\_to\_understanding\_HIGH\textbar misaligned\_power\_seeking\_FALSE)'':
``0.60'',
``p(barriers\_to\_understanding\_LOW\textbar misaligned\_power\_seeking\_TRUE)'':
``0.15'',
``p(barriers\_to\_understanding\_LOW\textbar misaligned\_power\_seeking\_FALSE)'':
``0.40''\}\} - {[}Misaligned\_Power\_Seeking{]}: Deployed AI systems
seeking power in unintended and high-impact ways due to problems with
their objectives. \{``instantiations'':
{[}``misaligned\_power\_seeking\_TRUE'',
``misaligned\_power\_seeking\_FALSE''{]}, ``priors'':
\{``p(misaligned\_power\_seeking\_TRUE)'': ``0.338'',
``p(misaligned\_power\_seeking\_FALSE)'': ``0.662''\}\}
{[}Adversarial\_Dynamics{]}: Potentially adversarial relationships
between humans and power-seeking AI. \{``instantiations'':
{[}``adversarial\_dynamics\_TRUE'', ``adversarial\_dynamics\_FALSE''{]},
``priors'': \{``p(adversarial\_dynamics\_TRUE)'': ``0.60'',
``p(adversarial\_dynamics\_FALSE)'': ``0.40''\}, ``posteriors'':
\{``p(adversarial\_dynamics\_TRUE\textbar misaligned\_power\_seeking\_TRUE)'':
``0.95'',
``p(adversarial\_dynamics\_TRUE\textbar misaligned\_power\_seeking\_FALSE)'':
``0.10'',
``p(adversarial\_dynamics\_FALSE\textbar misaligned\_power\_seeking\_TRUE)'':
``0.05'',
``p(adversarial\_dynamics\_FALSE\textbar misaligned\_power\_seeking\_FALSE)'':
``0.90''\}\} - {[}Misaligned\_Power\_Seeking{]}: Deployed AI systems
seeking power in unintended and high-impact ways due to problems with
their objectives. \{``instantiations'':
{[}``misaligned\_power\_seeking\_TRUE'',
``misaligned\_power\_seeking\_FALSE''{]}, ``priors'':
\{``p(misaligned\_power\_seeking\_TRUE)'': ``0.338'',
``p(misaligned\_power\_seeking\_FALSE)'': ``0.662''\}\}
{[}Stakes\_Of\_Error{]}: The escalating impact of mistakes with
power-seeking AI systems. \{``instantiations'':
{[}``stakes\_of\_error\_HIGH'', ``stakes\_of\_error\_LOW''{]},
``priors'': \{``p(stakes\_of\_error\_HIGH)'': ``0.85'',
``p(stakes\_of\_error\_LOW)'': ``0.15''\}, ``posteriors'':
\{``p(stakes\_of\_error\_HIGH\textbar misaligned\_power\_seeking\_TRUE)'':
``0.95'',
``p(stakes\_of\_error\_HIGH\textbar misaligned\_power\_seeking\_FALSE)'':
``0.50'',
``p(stakes\_of\_error\_LOW\textbar misaligned\_power\_seeking\_TRUE)'':
``0.05'',
``p(stakes\_of\_error\_LOW\textbar misaligned\_power\_seeking\_FALSE)'':
``0.50''\}\} - {[}Misaligned\_Power\_Seeking{]}: Deployed AI systems
seeking power in unintended and high-impact ways due to problems with
their objectives. \{``instantiations'':
{[}``misaligned\_power\_seeking\_TRUE'',
``misaligned\_power\_seeking\_FALSE''{]}, ``priors'':
\{``p(misaligned\_power\_seeking\_TRUE)'': ``0.338'',
``p(misaligned\_power\_seeking\_FALSE)'': ``0.662''\}\}

\subsection{3.0.2 Check the Graph Structure with the ArgDown Sandbox
Online}\label{check-the-graph-structure-with-the-argdown-sandbox-online-1}

Copy and paste the BayesDown formatted \ldots{} in the ArgDown Sandbox
below to quickly verify that the network renders correctly.

\section{3.1 Extraction}\label{extraction}

BayesDown Extraction Code already part of ArgDown extraction code,
therefore just use same function
``parse\_markdown\_hierarchy(markdown\_data)'' and ignore the extra
argument (``ArgDown'') because it is automatically set to false amd will
by default extract BayesDown.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{result\_df }\OperatorTok{=}\NormalTok{ parse\_markdown\_hierarchy\_fixed(md\_content\_ex\_rain)}
\NormalTok{result\_df}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lllllllllllllll@{}}
\toprule\noalign{}
& Title & Description & line & line\_numbers & indentation &
indentation\_levels & Parents & Children & instantiations & priors &
posteriors & No\_Parent & No\_Children & parent\_instantiations \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & Existential\_Catastrophe & The destruction of
humanity\textquotesingle s long-term potent... & 0 & {[}0{]} & 0 &
{[}0{]} & {[}{]} & {[}{]} & {[}existential\_catastrophe\_TRUE,
existential\_cat... &
\{\textquotesingle p(existential\_catastrophe\_TRUE)\textquotesingle:
\textquotesingle0.05\textquotesingle, \textquotesingle p... &
\{\textquotesingle p(existential\_catastrophe\_TRUE\textbar human\_disempo...
& True & True & {[}{]} \\
1 & Human\_Disempowerment & Permanent and collective disempowerment of
hum... & 1 & {[}1{]} & 0 & {[}0{]} & {[}Scale\_Of\_Power\_Seeking{]} &
{[}{]} & {[}human\_disempowerment\_TRUE, human\_disempowerme... &
\{\textquotesingle p(human\_disempowerment\_TRUE)\textquotesingle:
\textquotesingle0.208\textquotesingle, \textquotesingle p(h... &
\{\textquotesingle p(human\_disempowerment\_TRUE\textbar scale\_of\_power\_s...
& False & True & {[}{[}scale\_of\_power\_seeking\_TRUE,
scale\_of\_power\_... \\
2 & Scale\_Of\_Power\_Seeking & Power-seeking by AI systems scaling to
the poi... & 2 & {[}2{]} & 4 & {[}4{]} & {[}Misaligned\_Power\_Seeking,
Corrective\_Feedback{]} & {[}Human\_Disempowerment{]} &
{[}scale\_of\_power\_seeking\_TRUE, scale\_of\_power\_s... &
\{\textquotesingle p(scale\_of\_power\_seeking\_TRUE)\textquotesingle:
\textquotesingle0.208\textquotesingle, \textquotesingle p... &
\{\textquotesingle p(scale\_of\_power\_seeking\_TRUE\textbar misaligned\_pow...
& False & False & {[}{[}misaligned\_power\_seeking\_TRUE,
misaligned\_po... \\
3 & Misaligned\_Power\_Seeking & Deployed AI systems seeking power in
unintende... & 3 & {[}3, 21, 23, 25{]} & 8 & {[}8, 0, 0, 0{]} &
{[}APS\_Systems, Difficulty\_Of\_Alignment, Deploym... &
{[}Scale\_Of\_Power\_Seeking{]} & {[}misaligned\_power\_seeking\_TRUE,
misaligned\_pow... &
\{\textquotesingle p(misaligned\_power\_seeking\_TRUE)\textquotesingle:
\textquotesingle0.338\textquotesingle, ... &
\{\textquotesingle p(misaligned\_power\_seeking\_TRUE\textbar aps\_systems\_...
& False & False & {[}{[}aps\_systems\_TRUE, aps\_systems\_FALSE{]},
{[}diffi... \\
4 & APS\_Systems & AI systems with advanced capabilities, agentic... & 4
& {[}4{]} & 12 & {[}12{]} & {[}Advanced\_AI\_Capability,
Agentic\_Planning, Str... & {[}Misaligned\_Power\_Seeking{]} &
{[}aps\_systems\_TRUE, aps\_systems\_FALSE{]} &
\{\textquotesingle p(aps\_systems\_TRUE)\textquotesingle:
\textquotesingle0.65\textquotesingle, \textquotesingle p(aps\_systems...
&
\{\textquotesingle p(aps\_systems\_TRUE\textbar advanced\_ai\_capability\_TR...
& False & False & {[}{[}advanced\_ai\_capability\_TRUE,
advanced\_ai\_cap... \\
5 & Advanced\_AI\_Capability & AI systems that outperform humans on
tasks tha... & 5 & {[}5{]} & 16 & {[}16{]} & {[}{]} & {[}APS\_Systems{]}
& {[}advanced\_ai\_capability\_TRUE, advanced\_ai\_capa... &
\{\textquotesingle p(advanced\_ai\_capability\_TRUE)\textquotesingle:
\textquotesingle0.80\textquotesingle, \textquotesingle p(... & \{\} &
True & False & {[}{]} \\
6 & Agentic\_Planning & AI systems making and executing plans based
on... & 6 & {[}6{]} & 16 & {[}16{]} & {[}{]} & {[}APS\_Systems{]} &
{[}agentic\_planning\_TRUE, agentic\_planning\_FALSE{]} &
\{\textquotesingle p(agentic\_planning\_TRUE)\textquotesingle:
\textquotesingle0.85\textquotesingle, \textquotesingle p(agenti... &
\{\} & True & False & {[}{]} \\
7 & Strategic\_Awareness & AI systems with models accurately
representing... & 7 & {[}7{]} & 16 & {[}16{]} & {[}{]} &
{[}APS\_Systems{]} & {[}strategic\_awareness\_TRUE,
strategic\_awareness... &
\{\textquotesingle p(strategic\_awareness\_TRUE)\textquotesingle:
\textquotesingle0.75\textquotesingle, \textquotesingle p(str... & \{\} &
True & False & {[}{]} \\
8 & Difficulty\_Of\_Alignment & It is harder to build aligned systems
than mis... & 8 & {[}8{]} & 12 & {[}12{]} &
{[}Instrumental\_Convergence, Problems\_With\_Proxi... &
{[}Misaligned\_Power\_Seeking{]} & {[}difficulty\_of\_alignment\_TRUE,
difficulty\_of\_a... &
\{\textquotesingle p(difficulty\_of\_alignment\_TRUE)\textquotesingle:
\textquotesingle0.40\textquotesingle, \textquotesingle p... &
\{\textquotesingle p(difficulty\_of\_alignment\_TRUE\textbar instrumental\_...
& False & False & {[}{[}instrumental\_convergence\_TRUE,
instrumental\_... \\
9 & Instrumental\_Convergence & AI systems with misaligned objectives
tend to ... & 9 & {[}9{]} & 16 & {[}16{]} & {[}{]} &
{[}Difficulty\_Of\_Alignment{]} & {[}instrumental\_convergence\_TRUE,
instrumental\_c... &
\{\textquotesingle p(instrumental\_convergence\_TRUE)\textquotesingle:
\textquotesingle0.75\textquotesingle, \textquotesingle... & \{\} & True
& False & {[}{]} \\
10 & Problems\_With\_Proxies & Optimizing for proxy objectives breaks
correla... & 10 & {[}10{]} & 16 & {[}16{]} & {[}{]} &
{[}Difficulty\_Of\_Alignment{]} & {[}problems\_with\_proxies\_TRUE,
problems\_with\_pro... &
\{\textquotesingle p(problems\_with\_proxies\_TRUE)\textquotesingle:
\textquotesingle0.80\textquotesingle, \textquotesingle p(p... & \{\} &
True & False & {[}{]} \\
11 & Problems\_With\_Search & Search processes can yield systems
pursuing di... & 11 & {[}11{]} & 16 & {[}16{]} & {[}{]} &
{[}Difficulty\_Of\_Alignment{]} & {[}problems\_with\_search\_TRUE,
problems\_with\_sear... &
\{\textquotesingle p(problems\_with\_search\_TRUE)\textquotesingle:
\textquotesingle0.70\textquotesingle, \textquotesingle p(pr... & \{\} &
True & False & {[}{]} \\
12 & Deployment\_Decisions & Decisions to deploy potentially misaligned
AI ... & 12 & {[}12{]} & 12 & {[}12{]} & {[}Incentives\_To\_Build\_APS,
Deception\_By\_AI{]} & {[}Misaligned\_Power\_Seeking{]} &
{[}deployment\_decisions\_DEPLOY, deployment\_decis... &
\{\textquotesingle p(deployment\_decisions\_DEPLOY)\textquotesingle:
\textquotesingle0.70\textquotesingle, \textquotesingle p(... &
\{\textquotesingle p(deployment\_decisions\_DEPLOY\textbar incentives\_to\_...
& False & False & {[}{[}incentives\_to\_build\_aps\_STRONG,
incentives\_t... \\
13 & Incentives\_To\_Build\_APS & Strong incentives to build and deploy
APS syst... & 13 & {[}13{]} & 16 & {[}16{]} & {[}Usefulness\_Of\_APS,
Competitive\_Dynamics{]} & {[}Deployment\_Decisions{]} &
{[}incentives\_to\_build\_aps\_STRONG, incentives\_to... &
\{\textquotesingle p(incentives\_to\_build\_aps\_STRONG)\textquotesingle:
\textquotesingle0.80\textquotesingle, ... &
\{\textquotesingle p(incentives\_to\_build\_aps\_STRONG\textbar usefulness\_...
& False & False & {[}{[}usefulness\_of\_aps\_HIGH,
usefulness\_of\_aps\_LO... \\
14 & Usefulness\_Of\_APS & APS systems are very useful for many valuable
... & 14 & {[}14{]} & 20 & {[}20{]} & {[}{]} &
{[}Incentives\_To\_Build\_APS{]} & {[}usefulness\_of\_aps\_HIGH,
usefulness\_of\_aps\_LOW{]} &
\{\textquotesingle p(usefulness\_of\_aps\_HIGH)\textquotesingle:
\textquotesingle0.85\textquotesingle, \textquotesingle p(usefu... & \{\}
& True & False & {[}{]} \\
15 & Competitive\_Dynamics & Competitive pressures between AI
developers. & 15 & {[}15{]} & 20 & {[}20{]} & {[}{]} &
{[}Incentives\_To\_Build\_APS{]} & {[}competitive\_dynamics\_STRONG,
competitive\_dyna... &
\{\textquotesingle p(competitive\_dynamics\_STRONG)\textquotesingle:
\textquotesingle0.75\textquotesingle, \textquotesingle p(... & \{\} &
True & False & {[}{]} \\
16 & Deception\_By\_AI & AI systems deceiving humans about their true
o... & 16 & {[}16{]} & 16 & {[}16{]} & {[}{]} &
{[}Deployment\_Decisions{]} & {[}deception\_by\_ai\_TRUE,
deception\_by\_ai\_FALSE{]} &
\{\textquotesingle p(deception\_by\_ai\_TRUE)\textquotesingle:
\textquotesingle0.50\textquotesingle, \textquotesingle p(decepti... &
\{\} & True & False & {[}{]} \\
17 & Corrective\_Feedback & Human society implementing corrections after
o... & 17 & {[}17{]} & 8 & {[}8{]} & {[}Warning\_Shots,
Rapid\_Capability\_Escalation{]} & {[}Scale\_Of\_Power\_Seeking{]} &
{[}corrective\_feedback\_EFFECTIVE, corrective\_fee... &
\{\textquotesingle p(corrective\_feedback\_EFFECTIVE)\textquotesingle:
\textquotesingle0.60\textquotesingle, \textquotesingle... &
\{\textquotesingle p(corrective\_feedback\_EFFECTIVE\textbar warning\_shot...
& False & False & {[}{[}warning\_shots\_OBSERVED,
warning\_shots\_UNOBSE... \\
18 & Warning\_Shots & Observable failures in weaker systems before c...
& 18 & {[}18{]} & 12 & {[}12{]} & {[}{]} & {[}Corrective\_Feedback{]} &
{[}warning\_shots\_OBSERVED, warning\_shots\_UNOBSER... &
\{\textquotesingle p(warning\_shots\_OBSERVED)\textquotesingle:
\textquotesingle0.70\textquotesingle, \textquotesingle p(warni... & \{\}
& True & False & {[}{]} \\
19 & Rapid\_Capability\_Escalation & AI capabilities escalating very
rapidly, allow... & 19 & {[}19{]} & 12 & {[}12{]} & {[}{]} &
{[}Corrective\_Feedback{]} & {[}rapid\_capability\_escalation\_TRUE,
rapid\_capab... &
\{\textquotesingle p(rapid\_capability\_escalation\_TRUE)\textquotesingle:
\textquotesingle0.45\textquotesingle... & \{\} & True & False &
{[}{]} \\
20 & Barriers\_To\_Understanding & Difficulty in understanding the
internal worki... & 20 & {[}20{]} & 0 & {[}0{]} & {[}{]} & {[}{]} &
{[}barriers\_to\_understanding\_HIGH, barriers\_to\_u... &
\{\textquotesingle p(barriers\_to\_understanding\_HIGH)\textquotesingle:
\textquotesingle0.70\textquotesingle, ... &
\{\textquotesingle p(barriers\_to\_understanding\_HIGH\textbar misaligned\_...
& True & True & {[}{]} \\
21 & Adversarial\_Dynamics & Potentially adversarial relationships
between ... & 22 & {[}22{]} & 0 & {[}0{]} & {[}{]} & {[}{]} &
{[}adversarial\_dynamics\_TRUE, adversarial\_dynami... &
\{\textquotesingle p(adversarial\_dynamics\_TRUE)\textquotesingle:
\textquotesingle0.60\textquotesingle, \textquotesingle p(ad... &
\{\textquotesingle p(adversarial\_dynamics\_TRUE\textbar misaligned\_power...
& True & True & {[}{]} \\
22 & Stakes\_Of\_Error & The escalating impact of mistakes with
power-s... & 24 & {[}24{]} & 0 & {[}0{]} & {[}{]} & {[}{]} &
{[}stakes\_of\_error\_HIGH, stakes\_of\_error\_LOW{]} &
\{\textquotesingle p(stakes\_of\_error\_HIGH)\textquotesingle:
\textquotesingle0.85\textquotesingle, \textquotesingle p(stakes\_... &
\{\textquotesingle p(stakes\_of\_error\_HIGH\textbar misaligned\_power\_seek...
& True & True & {[}{]} \\
\end{longtable}

\section{3.2 Data-Post-Processing}\label{data-post-processing}

Add rows to data frame that can be calculated from the extracted rows

\phantomsection\label{data_post_processing_functions}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 3.2.0 Data Post{-}Processing Functions {-}{-}{-} [data\_post\_processing\_functions]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Enhances the extracted BayesDown data with calculated metrics and network properties.}

\CommentTok{This block provides functions to enrich the basic extracted data with additional}
\CommentTok{calculated columns that are useful for analysis and visualization:}

\CommentTok{1. Joint probabilities {-} Calculating P(A,B) from conditional and prior probabilities}
\CommentTok{2. Network metrics {-} Centrality measures that indicate importance of nodes in the network}
\CommentTok{3. Markov blanket {-} Identifying the minimal set of nodes that shield a node from the rest}

\CommentTok{These enhancements provide valuable context for understanding the network structure}
\CommentTok{and the relationships between variables, enabling more advanced analysis and}
\CommentTok{improving visualization.}

\CommentTok{DEPENDENCIES: networkx for graph calculations}
\CommentTok{INPUTS: DataFrame with basic extracted BayesDown data}
\CommentTok{OUTPUTS: Enhanced DataFrame with additional calculated columns}
\CommentTok{"""}

\KeywordTok{def}\NormalTok{ enhance\_extracted\_data(df):}
    \CommentTok{"""}
\CommentTok{    Enhance the extracted data with calculated columns}

\CommentTok{    Args:}
\CommentTok{        df: DataFrame with extracted BayesDown data}

\CommentTok{    Returns:}
\CommentTok{        Enhanced DataFrame with additional columns}
\CommentTok{    """}
    \CommentTok{\# Create a copy to avoid modifying the original}
\NormalTok{    enhanced\_df }\OperatorTok{=}\NormalTok{ df.copy()}

    \CommentTok{\# 1. Calculate joint probabilities {-} P(A,B) = P(A|B) * P(B)}
\NormalTok{    enhanced\_df[}\StringTok{\textquotesingle{}joint\_probabilities\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \VariableTok{None}

    \ControlFlowTok{for}\NormalTok{ idx, row }\KeywordTok{in}\NormalTok{ enhanced\_df.iterrows():}
\NormalTok{        title }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{]}
\NormalTok{        priors }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{] }\ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(row[}\StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{], }\BuiltInTok{dict}\NormalTok{) }\ControlFlowTok{else}\NormalTok{ \{\}}
\NormalTok{        posteriors }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{] }\ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(row[}\StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{], }\BuiltInTok{dict}\NormalTok{) }\ControlFlowTok{else}\NormalTok{ \{\}}
\NormalTok{        parents }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{] }\ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(row[}\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{], }\BuiltInTok{list}\NormalTok{) }\ControlFlowTok{else}\NormalTok{ []}

        \CommentTok{\# Skip if no parents or no priors}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ parents }\KeywordTok{or} \KeywordTok{not}\NormalTok{ priors:}
            \ControlFlowTok{continue}

        \CommentTok{\# Initialize joint probabilities dictionary}
\NormalTok{        joint\_probs }\OperatorTok{=}\NormalTok{ \{\}}

        \CommentTok{\# Get instantiations}
\NormalTok{        instantiations }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{]}
        \ControlFlowTok{if} \KeywordTok{not} \BuiltInTok{isinstance}\NormalTok{(instantiations, }\BuiltInTok{list}\NormalTok{) }\KeywordTok{or} \KeywordTok{not}\NormalTok{ instantiations:}
            \ControlFlowTok{continue}

        \CommentTok{\# For each parent and child instantiation combination, calculate joint probability}
        \ControlFlowTok{for}\NormalTok{ inst }\KeywordTok{in}\NormalTok{ instantiations:}
            \CommentTok{\# Get this instantiation\textquotesingle{}s prior probability}
\NormalTok{            inst\_prior\_key }\OperatorTok{=} \SpecialStringTok{f"p(}\SpecialCharTok{\{}\NormalTok{inst}\SpecialCharTok{\}}\SpecialStringTok{)"}
            \ControlFlowTok{if}\NormalTok{ inst\_prior\_key }\KeywordTok{not} \KeywordTok{in}\NormalTok{ priors:}
                \ControlFlowTok{continue}

            \ControlFlowTok{try}\NormalTok{:}
\NormalTok{                inst\_prior }\OperatorTok{=} \BuiltInTok{float}\NormalTok{(priors[inst\_prior\_key])}
            \ControlFlowTok{except}\NormalTok{ (}\PreprocessorTok{ValueError}\NormalTok{, }\PreprocessorTok{TypeError}\NormalTok{):}
                \ControlFlowTok{continue}

            \CommentTok{\# For each parent}
            \ControlFlowTok{for}\NormalTok{ parent }\KeywordTok{in}\NormalTok{ parents:}
\NormalTok{                parent\_row }\OperatorTok{=}\NormalTok{ enhanced\_df[enhanced\_df[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{] }\OperatorTok{==}\NormalTok{ parent]}
                \ControlFlowTok{if}\NormalTok{ parent\_row.empty:}
                    \ControlFlowTok{continue}

\NormalTok{                parent\_insts }\OperatorTok{=}\NormalTok{ parent\_row.iloc[}\DecValTok{0}\NormalTok{][}\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{]}
                \ControlFlowTok{if} \KeywordTok{not} \BuiltInTok{isinstance}\NormalTok{(parent\_insts, }\BuiltInTok{list}\NormalTok{) }\KeywordTok{or} \KeywordTok{not}\NormalTok{ parent\_insts:}
                    \ControlFlowTok{continue}

                \ControlFlowTok{for}\NormalTok{ parent\_inst }\KeywordTok{in}\NormalTok{ parent\_insts:}
                    \CommentTok{\# Get conditional probability}
\NormalTok{                    cond\_key }\OperatorTok{=} \SpecialStringTok{f"p(}\SpecialCharTok{\{}\NormalTok{inst}\SpecialCharTok{\}}\SpecialStringTok{|}\SpecialCharTok{\{}\NormalTok{parent}\SpecialCharTok{\}}\SpecialStringTok{=}\SpecialCharTok{\{}\NormalTok{parent\_inst}\SpecialCharTok{\}}\SpecialStringTok{)"}
                    \ControlFlowTok{if}\NormalTok{ cond\_key }\KeywordTok{in}\NormalTok{ posteriors:}
                        \ControlFlowTok{try}\NormalTok{:}
\NormalTok{                            cond\_prob }\OperatorTok{=} \BuiltInTok{float}\NormalTok{(posteriors[cond\_key])}

                            \CommentTok{\# Get parent\textquotesingle{}s prior}
\NormalTok{                            parent\_priors }\OperatorTok{=}\NormalTok{ parent\_row.iloc[}\DecValTok{0}\NormalTok{][}\StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{]}
                            \ControlFlowTok{if} \KeywordTok{not} \BuiltInTok{isinstance}\NormalTok{(parent\_priors, }\BuiltInTok{dict}\NormalTok{):}
                                \ControlFlowTok{continue}

\NormalTok{                            parent\_prior\_key }\OperatorTok{=} \SpecialStringTok{f"p(}\SpecialCharTok{\{}\NormalTok{parent\_inst}\SpecialCharTok{\}}\SpecialStringTok{)"}
                            \ControlFlowTok{if}\NormalTok{ parent\_prior\_key }\KeywordTok{not} \KeywordTok{in}\NormalTok{ parent\_priors:}
                                \ControlFlowTok{continue}

                            \ControlFlowTok{try}\NormalTok{:}
\NormalTok{                                parent\_prior }\OperatorTok{=} \BuiltInTok{float}\NormalTok{(parent\_priors[parent\_prior\_key])}

                                \CommentTok{\# Calculate joint probability:}
                                \CommentTok{\# P(A,B) = P(A|B) * P(B)}
\NormalTok{                                joint\_prob }\OperatorTok{=}\NormalTok{ cond\_prob }\OperatorTok{*}\NormalTok{ parent\_prior}
\NormalTok{                                joint\_key }\OperatorTok{=} \SpecialStringTok{f"p(}\SpecialCharTok{\{}\NormalTok{inst}\SpecialCharTok{\}}\SpecialStringTok{,}\SpecialCharTok{\{}\NormalTok{parent}\SpecialCharTok{\}}\SpecialStringTok{=}\SpecialCharTok{\{}\NormalTok{parent\_inst}\SpecialCharTok{\}}\SpecialStringTok{)"}
\NormalTok{                                joint\_probs[joint\_key] }\OperatorTok{=} \BuiltInTok{str}\NormalTok{(}\BuiltInTok{round}\NormalTok{(joint\_prob, }\DecValTok{4}\NormalTok{))}
                            \ControlFlowTok{except}\NormalTok{ (}\PreprocessorTok{ValueError}\NormalTok{, }\PreprocessorTok{TypeError}\NormalTok{):}
\NormalTok{                                joint\_prob }\OperatorTok{=}\NormalTok{ cond\_prob }\OperatorTok{*}\NormalTok{ parent\_prior}
\NormalTok{                                joint\_key }\OperatorTok{=} \SpecialStringTok{f"p(}\SpecialCharTok{\{}\NormalTok{inst}\SpecialCharTok{\}}\SpecialStringTok{,}\SpecialCharTok{\{}\NormalTok{parent}\SpecialCharTok{\}}\SpecialStringTok{=}\SpecialCharTok{\{}\NormalTok{parent\_inst}\SpecialCharTok{\}}\SpecialStringTok{)"}
\NormalTok{                                joint\_probs[joint\_key] }\OperatorTok{=} \BuiltInTok{str}\NormalTok{(}\BuiltInTok{round}\NormalTok{(joint\_prob, }\DecValTok{4}\NormalTok{))}
                            \ControlFlowTok{except}\NormalTok{ (}\PreprocessorTok{ValueError}\NormalTok{, }\PreprocessorTok{TypeError}\NormalTok{):}
                                \ControlFlowTok{continue}
                        \ControlFlowTok{except}\NormalTok{ (}\PreprocessorTok{ValueError}\NormalTok{, }\PreprocessorTok{TypeError}\NormalTok{):}
                            \ControlFlowTok{continue}

        \CommentTok{\# Store joint probabilities in dataframe}
\NormalTok{        enhanced\_df.at[idx, }\StringTok{\textquotesingle{}joint\_probabilities\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ joint\_probs}

    \CommentTok{\# 2. Calculate network metrics}
    \CommentTok{\# Create a directed graph}
    \ImportTok{import}\NormalTok{ networkx }\ImportTok{as}\NormalTok{ nx}
\NormalTok{    G }\OperatorTok{=}\NormalTok{ nx.DiGraph()}

    \CommentTok{\# Add nodes}
    \ControlFlowTok{for}\NormalTok{ idx, row }\KeywordTok{in}\NormalTok{ enhanced\_df.iterrows():}
\NormalTok{        G.add\_node(row[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{])}

    \CommentTok{\# Add edges}
    \ControlFlowTok{for}\NormalTok{ idx, row }\KeywordTok{in}\NormalTok{ enhanced\_df.iterrows():}
\NormalTok{        child }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{]}
\NormalTok{        parents }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{] }\ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(row[}\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{], }\BuiltInTok{list}\NormalTok{) }\ControlFlowTok{else}\NormalTok{ []}

        \ControlFlowTok{for}\NormalTok{ parent }\KeywordTok{in}\NormalTok{ parents:}
            \ControlFlowTok{if}\NormalTok{ parent }\KeywordTok{in}\NormalTok{ G.nodes():}
\NormalTok{                G.add\_edge(parent, child)}

    \CommentTok{\# Calculate centrality measures}
\NormalTok{    degree\_centrality }\OperatorTok{=}\NormalTok{ nx.degree\_centrality(G)  }\CommentTok{\# Overall connectedness}
\NormalTok{    in\_degree\_centrality }\OperatorTok{=}\NormalTok{ nx.in\_degree\_centrality(G)  }\CommentTok{\# How many nodes affect this one}
\NormalTok{    out\_degree\_centrality }\OperatorTok{=}\NormalTok{ nx.out\_degree\_centrality(G)  }\CommentTok{\# How many nodes this one affects}

    \ControlFlowTok{try}\NormalTok{:}
\NormalTok{        betweenness\_centrality }\OperatorTok{=}\NormalTok{ nx.betweenness\_centrality(G)  }\CommentTok{\# Node\textquotesingle{}s role as a connector}
    \ControlFlowTok{except}\NormalTok{:}
\NormalTok{        betweenness\_centrality }\OperatorTok{=}\NormalTok{ \{node: }\DecValTok{0} \ControlFlowTok{for}\NormalTok{ node }\KeywordTok{in}\NormalTok{ G.nodes()\}}

    \CommentTok{\# Add metrics to dataframe}
\NormalTok{    enhanced\_df[}\StringTok{\textquotesingle{}degree\_centrality\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \VariableTok{None}
\NormalTok{    enhanced\_df[}\StringTok{\textquotesingle{}in\_degree\_centrality\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \VariableTok{None}
\NormalTok{    enhanced\_df[}\StringTok{\textquotesingle{}out\_degree\_centrality\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \VariableTok{None}
\NormalTok{    enhanced\_df[}\StringTok{\textquotesingle{}betweenness\_centrality\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \VariableTok{None}

    \ControlFlowTok{for}\NormalTok{ idx, row }\KeywordTok{in}\NormalTok{ enhanced\_df.iterrows():}
\NormalTok{        title }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{]}
\NormalTok{        enhanced\_df.at[idx, }\StringTok{\textquotesingle{}degree\_centrality\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ degree\_centrality.get(title, }\DecValTok{0}\NormalTok{)}
\NormalTok{        enhanced\_df.at[idx, }\StringTok{\textquotesingle{}in\_degree\_centrality\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ in\_degree\_centrality.get(title, }\DecValTok{0}\NormalTok{)}
\NormalTok{        enhanced\_df.at[idx, }\StringTok{\textquotesingle{}out\_degree\_centrality\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ out\_degree\_centrality.get(title, }\DecValTok{0}\NormalTok{)}
\NormalTok{        enhanced\_df.at[idx, }\StringTok{\textquotesingle{}betweenness\_centrality\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ betweenness\_centrality.get(title, }\DecValTok{0}\NormalTok{)}

    \CommentTok{\# 3. Add Markov blanket information (parents, children, and children\textquotesingle{}s parents)}
\NormalTok{    enhanced\_df[}\StringTok{\textquotesingle{}markov\_blanket\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \VariableTok{None}

    \ControlFlowTok{for}\NormalTok{ idx, row }\KeywordTok{in}\NormalTok{ enhanced\_df.iterrows():}
\NormalTok{        title }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{]}
\NormalTok{        parents }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{] }\ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(row[}\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{], }\BuiltInTok{list}\NormalTok{) }\ControlFlowTok{else}\NormalTok{ []}
\NormalTok{        children }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{] }\ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(row[}\StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{], }\BuiltInTok{list}\NormalTok{) }\ControlFlowTok{else}\NormalTok{ []}

        \CommentTok{\# Get children\textquotesingle{}s parents (excluding this node)}
\NormalTok{        childrens\_parents }\OperatorTok{=}\NormalTok{ []}
        \ControlFlowTok{for}\NormalTok{ child }\KeywordTok{in}\NormalTok{ children:}
\NormalTok{            child\_row }\OperatorTok{=}\NormalTok{ enhanced\_df[enhanced\_df[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{] }\OperatorTok{==}\NormalTok{ child]}
            \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ child\_row.empty:}
\NormalTok{                child\_parents }\OperatorTok{=}\NormalTok{ child\_row.iloc[}\DecValTok{0}\NormalTok{][}\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{]}
                \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(child\_parents, }\BuiltInTok{list}\NormalTok{):}
\NormalTok{                    childrens\_parents.extend([p }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ child\_parents }\ControlFlowTok{if}\NormalTok{ p }\OperatorTok{!=}\NormalTok{ title])}

        \CommentTok{\# Remove duplicates}
\NormalTok{        childrens\_parents }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(}\BuiltInTok{set}\NormalTok{(childrens\_parents))}

        \CommentTok{\# Combine to get Markov blanket}
\NormalTok{        markov\_blanket }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(}\BuiltInTok{set}\NormalTok{(parents }\OperatorTok{+}\NormalTok{ children }\OperatorTok{+}\NormalTok{ childrens\_parents))}
\NormalTok{        enhanced\_df.at[idx, }\StringTok{\textquotesingle{}markov\_blanket\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ markov\_blanket}

    \ControlFlowTok{return}\NormalTok{ enhanced\_df}
\end{Highlighting}
\end{Shaded}

\phantomsection\label{enhance_extracted_data_with_network_metrics}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 3.2.1 {-}{-}{-} Enhance Extracted Data with Network Metrics {-}{-}{-} [enhance\_extracted\_data\_with\_network\_metrics]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Applies the post{-}processing functions to enhance the extracted data.}

\CommentTok{This block takes the basic extracted DataFrame from the BayesDown parsing step}
\CommentTok{and enriches it with calculated metrics that provide deeper insight into the}
\CommentTok{network structure and relationships. It:}

\CommentTok{1. Applies the enhancement functions defined previously}
\CommentTok{2. Displays summary information about key calculated metrics}
\CommentTok{3. Saves the enhanced data for further analysis and visualization}

\CommentTok{The enhanced DataFrame provides a richer representation of the Bayesian network,}
\CommentTok{including measures of node importance and conditional relationships that are}
\CommentTok{essential for effective analysis and visualization.}

\CommentTok{DEPENDENCIES: enhance\_extracted\_data function}
\CommentTok{INPUTS: DataFrame with basic extracted BayesDown data}
\CommentTok{OUTPUTS: Enhanced DataFrame with additional calculated columns, saved to CSV}
\CommentTok{"""}

\CommentTok{\# Enhance the extracted dataframe with calculated columns}
\NormalTok{enhanced\_df }\OperatorTok{=}\NormalTok{ enhance\_extracted\_data(result\_df)}

\CommentTok{\# Display the enhanced dataframe}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Enhanced DataFrame with additional calculated columns:"}\NormalTok{)}
\NormalTok{enhanced\_df.head()}

\CommentTok{\# Check some calculated metrics}
\BuiltInTok{print}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{Joint Probabilities Example:"}\NormalTok{)}
\NormalTok{example\_node }\OperatorTok{=}\NormalTok{ enhanced\_df.loc[}\DecValTok{0}\NormalTok{, }\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{]}
\NormalTok{joint\_probs }\OperatorTok{=}\NormalTok{ enhanced\_df.loc[}\DecValTok{0}\NormalTok{, }\StringTok{\textquotesingle{}joint\_probabilities\textquotesingle{}}\NormalTok{]}
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Joint probabilities for }\SpecialCharTok{\{}\NormalTok{example\_node}\SpecialCharTok{\}}\SpecialStringTok{:"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(joint\_probs)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{Network Metrics:"}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ idx, row }\KeywordTok{in}\NormalTok{ enhanced\_df.iterrows():}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{row[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{:"}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"  Degree Centrality: }\SpecialCharTok{\{}\NormalTok{row[}\StringTok{\textquotesingle{}degree\_centrality\textquotesingle{}}\NormalTok{]}\SpecialCharTok{:.3f\}}\SpecialStringTok{"}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"  Betweenness Centrality: }\SpecialCharTok{\{}\NormalTok{row[}\StringTok{\textquotesingle{}betweenness\_centrality\textquotesingle{}}\NormalTok{]}\SpecialCharTok{:.3f\}}\SpecialStringTok{"}\NormalTok{)}

\CommentTok{\# Save the enhanced dataframe}
\NormalTok{enhanced\_df.to\_csv(}\StringTok{\textquotesingle{}enhanced\_extracted\_data.csv\textquotesingle{}}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{Enhanced data saved to \textquotesingle{}enhanced\_extracted\_data.csv\textquotesingle{}"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Enhanced DataFrame with additional calculated columns:

Joint Probabilities Example:
Joint probabilities for Existential_Catastrophe:
None

Network Metrics:
Existential_Catastrophe:
  Degree Centrality: 0.000
  Betweenness Centrality: 0.000
Human_Disempowerment:
  Degree Centrality: 0.045
  Betweenness Centrality: 0.000
Scale_Of_Power_Seeking:
  Degree Centrality: 0.136
  Betweenness Centrality: 0.037
Misaligned_Power_Seeking:
  Degree Centrality: 0.182
  Betweenness Centrality: 0.056
APS_Systems:
  Degree Centrality: 0.182
  Betweenness Centrality: 0.019
Advanced_AI_Capability:
  Degree Centrality: 0.045
  Betweenness Centrality: 0.000
Agentic_Planning:
  Degree Centrality: 0.045
  Betweenness Centrality: 0.000
Strategic_Awareness:
  Degree Centrality: 0.045
  Betweenness Centrality: 0.000
Difficulty_Of_Alignment:
  Degree Centrality: 0.182
  Betweenness Centrality: 0.019
Instrumental_Convergence:
  Degree Centrality: 0.045
  Betweenness Centrality: 0.000
Problems_With_Proxies:
  Degree Centrality: 0.045
  Betweenness Centrality: 0.000
Problems_With_Search:
  Degree Centrality: 0.045
  Betweenness Centrality: 0.000
Deployment_Decisions:
  Degree Centrality: 0.136
  Betweenness Centrality: 0.026
Incentives_To_Build_APS:
  Degree Centrality: 0.136
  Betweenness Centrality: 0.017
Usefulness_Of_APS:
  Degree Centrality: 0.045
  Betweenness Centrality: 0.000
Competitive_Dynamics:
  Degree Centrality: 0.045
  Betweenness Centrality: 0.000
Deception_By_AI:
  Degree Centrality: 0.045
  Betweenness Centrality: 0.000
Corrective_Feedback:
  Degree Centrality: 0.136
  Betweenness Centrality: 0.009
Warning_Shots:
  Degree Centrality: 0.045
  Betweenness Centrality: 0.000
Rapid_Capability_Escalation:
  Degree Centrality: 0.045
  Betweenness Centrality: 0.000
Barriers_To_Understanding:
  Degree Centrality: 0.000
  Betweenness Centrality: 0.000
Adversarial_Dynamics:
  Degree Centrality: 0.000
  Betweenness Centrality: 0.000
Stakes_Of_Error:
  Degree Centrality: 0.000
  Betweenness Centrality: 0.000

Enhanced data saved to 'enhanced_extracted_data.csv'
\end{verbatim}

\section{3.4 Download and save finished data frame as .csv
file}\label{download-and-save-finished-data-frame-as-.csv-file}

\phantomsection\label{save_extracted_data_for_further_processing}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 3.4.0 {-}{-}{-} Save Extracted Data for Further Processing {-}{-}{-} [save\_extracted\_data\_for\_further\_processing]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Saves the extracted data to a CSV file for further processing.}

\CommentTok{This step is essential for:}
\CommentTok{1. Persisting the structured representation of the Bayesian network}
\CommentTok{2. Enabling further analysis in other tools or notebook sections}
\CommentTok{3. Creating a permanent record of the extraction results}
\CommentTok{4. Making the data available for the visualization pipeline}

\CommentTok{The CSV format provides a standardized, tabular representation of the network}
\CommentTok{that can be easily loaded and processed in subsequent analysis steps.}

\CommentTok{DEPENDENCIES: pandas DataFrame operations}
\CommentTok{INPUTS: Extracted DataFrame from the parsing step}
\CommentTok{OUTPUTS: CSV file containing the structured network data}
\CommentTok{"""}

\CommentTok{\# Save the extracted data as a CSV file}
\NormalTok{result\_df.to\_csv(}\StringTok{\textquotesingle{}extracted\_data.csv\textquotesingle{}}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"✅ Extracted data saved successfully to \textquotesingle{}extracted\_data.csv\textquotesingle{}"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Note: If using updated data in future steps, "}
        \OperatorTok{+} \StringTok{"the file must be pushed to the GitHub repository"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
✅ Extracted data saved successfully to 'extracted_data.csv'
Note: If using updated data in future steps, the file must be pushed to the GitHub repository
\end{verbatim}

\chapter{4 Analysis \& Inference: Bayesian Network
Visualization}\label{analysis-inference-bayesian-network-visualization}

\section{4.0 Bayesian Network Visualization
Approach}\label{bayesian-network-visualization-approach}

This section implements the visualization component of the AMTAIR
project, transforming the structured data extracted from BayesDown into
an interactive network visualization that makes complex probabilistic
relationships accessible to human understanding.

\subsection{Visualization Philosophy}\label{visualization-philosophy}

A key challenge in AI governance is making complex probabilistic
relationships understandable to diverse stakeholders. This visualization
system addresses this challenge through:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Visual Encoding of Probability}: Node colors reflect
  probability values (green for high probability, red for low)
\item
  \textbf{Structural Classification}: Border colors indicate node types
  (blue for root causes, purple for intermediate nodes, magenta for leaf
  nodes)
\item
  \textbf{Progressive Disclosure}: Basic information in tooltips,
  detailed probability tables in modal popups
\item
  \textbf{Interactive Exploration}: Draggable nodes, configurable
  physics, click interactions
\end{enumerate}

\subsection{Connection to AMTAIR
Goals}\label{connection-to-amtair-goals}

This visualization approach directly supports the AMTAIR project's goal
of improving coordination in AI governance by:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Making implicit models explicit through visual representation
\item
  Providing a common language for discussing probabilistic relationships
\item
  Enabling non-technical stakeholders to engage with formal models
\item
  Creating shareable artifacts that facilitate collaboration
\end{enumerate}

\subsection{Implementation Structure}\label{implementation-structure}

The visualization system is implemented in four phases:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Network Construction}: Creating a directed graph
  representation using NetworkX
\item
  \textbf{Node Classification}: Identifying node types based on network
  position
\item
  \textbf{Visual Enhancement}: Adding color coding, tooltips, and
  interactive elements
\item
  \textbf{Interactive Features}: Implementing click handling for
  detailed exploration
\end{enumerate}

The resulting visualization serves as both an analytical tool for
experts and a communication tool for broader audiences, bridging the gap
between technical and policy domains in AI governance discussions.

\section{4.1 Phase 1:
Dependencies/Functions}\label{phase-1-dependenciesfunctions}

\phantomsection\label{bayesian_network_visualization_functions}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 4.1.0 {-}{-}{-} Bayesian Network Visualization Functions {-}{-}{-} [bayesian\_network\_visualization\_functions]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Provides functions to create interactive Bayesian network}
\CommentTok{visualizations from DataFrame representations of ArgDown/BayesDown data.}

\CommentTok{This block implements the visualization pipeline described in the AMTAIR project,}
\CommentTok{transforming the structured DataFrame extracted from ArgDown/BayesDown into an}
\CommentTok{interactive network graph that displays nodes, relationships, and probability}
\CommentTok{information. The visualization leverages NetworkX for graph representation and}
\CommentTok{PyVis for interactive display.}

\CommentTok{Key visualization features:}
\CommentTok{1. Color{-}coding of nodes based on probability values}
\CommentTok{2. Border styling to indicate node types (root, intermediate, leaf)}
\CommentTok{3. Interactive tooltips with probability information}
\CommentTok{4. Modal popups with detailed conditional probability tables}
\CommentTok{5. Physics{-}based layout for intuitive exploration}

\CommentTok{DEPENDENCIES: networkx, pyvis, HTML display from IPython}
\CommentTok{INPUTS: DataFrame with node information, relationships, and probabilities}
\CommentTok{OUTPUTS: Interactive HTML visualization of the Bayesian network}
\CommentTok{"""}

\ImportTok{from}\NormalTok{ pyvis.network }\ImportTok{import}\NormalTok{ Network}
\ImportTok{import}\NormalTok{ networkx }\ImportTok{as}\NormalTok{ nx}
\ImportTok{from}\NormalTok{ IPython.display }\ImportTok{import}\NormalTok{ HTML}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ io}
\ImportTok{import}\NormalTok{ base64}
\ImportTok{import}\NormalTok{ colorsys}
\ImportTok{import}\NormalTok{ json}

\KeywordTok{def}\NormalTok{ create\_bayesian\_network\_with\_probabilities(df):}
    \CommentTok{"""}
\CommentTok{    Create an interactive Bayesian network visualization with enhanced}
\CommentTok{    probability visualization and node classification based on network structure.}

\CommentTok{    Args:}
\CommentTok{        df (pandas.DataFrame): DataFrame containing node information, relationships, and probabilities}

\CommentTok{    Returns:}
\CommentTok{        IPython.display.HTML: Interactive HTML visualization of the Bayesian network}
\CommentTok{    """}
    \CommentTok{\# PHASE 1: Create a directed graph representation}
\NormalTok{    G }\OperatorTok{=}\NormalTok{ nx.DiGraph()}

    \CommentTok{\# Add nodes with proper attributes}
    \ControlFlowTok{for}\NormalTok{ idx, row }\KeywordTok{in}\NormalTok{ df.iterrows():}
\NormalTok{        title }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{]}
\NormalTok{        description }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{]}

        \CommentTok{\# Process probability information}
\NormalTok{        priors }\OperatorTok{=}\NormalTok{ get\_priors(row)}
\NormalTok{        instantiations }\OperatorTok{=}\NormalTok{ get\_instantiations(row)}

        \CommentTok{\# Add node with base information}
\NormalTok{        G.add\_node(}
\NormalTok{            title,}
\NormalTok{            description}\OperatorTok{=}\NormalTok{description,}
\NormalTok{            priors}\OperatorTok{=}\NormalTok{priors,}
\NormalTok{            instantiations}\OperatorTok{=}\NormalTok{instantiations,}
\NormalTok{            posteriors}\OperatorTok{=}\NormalTok{get\_posteriors(row)}
\NormalTok{        )}

    \CommentTok{\# Add edges based on parent{-}child relationships}
    \ControlFlowTok{for}\NormalTok{ idx, row }\KeywordTok{in}\NormalTok{ df.iterrows():}
\NormalTok{        child }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{]}
\NormalTok{        parents }\OperatorTok{=}\NormalTok{ get\_parents(row)}

        \CommentTok{\# Add edges from each parent to this child}
        \ControlFlowTok{for}\NormalTok{ parent }\KeywordTok{in}\NormalTok{ parents:}
            \ControlFlowTok{if}\NormalTok{ parent }\KeywordTok{in}\NormalTok{ G.nodes():}
\NormalTok{                G.add\_edge(parent, child)}

    \CommentTok{\# PHASE 2: Classify nodes based on network structure}
\NormalTok{    classify\_nodes(G)}

    \CommentTok{\# PHASE 3: Create interactive network visualization}
\NormalTok{    net }\OperatorTok{=}\NormalTok{ Network(notebook}\OperatorTok{=}\VariableTok{True}\NormalTok{, directed}\OperatorTok{=}\VariableTok{True}\NormalTok{, cdn\_resources}\OperatorTok{=}\StringTok{"in\_line"}\NormalTok{, height}\OperatorTok{=}\StringTok{"600px"}\NormalTok{, width}\OperatorTok{=}\StringTok{"100\%"}\NormalTok{)}

    \CommentTok{\# Configure physics for better layout}
\NormalTok{    net.force\_atlas\_2based(gravity}\OperatorTok{={-}}\DecValTok{50}\NormalTok{, spring\_length}\OperatorTok{=}\DecValTok{100}\NormalTok{, spring\_strength}\OperatorTok{=}\FloatTok{0.02}\NormalTok{)}
\NormalTok{    net.show\_buttons(filter\_}\OperatorTok{=}\NormalTok{[}\StringTok{\textquotesingle{}physics\textquotesingle{}}\NormalTok{])  }\CommentTok{\# Allow user to adjust physics settings}

    \CommentTok{\# Add the graph to the network}
\NormalTok{    net.from\_nx(G)}

    \CommentTok{\# PHASE 4: Enhance node appearance with probability information}
    \ControlFlowTok{for}\NormalTok{ node }\KeywordTok{in}\NormalTok{ net.nodes:}
\NormalTok{        node\_id }\OperatorTok{=}\NormalTok{ node[}\StringTok{\textquotesingle{}id\textquotesingle{}}\NormalTok{]}
\NormalTok{        node\_data }\OperatorTok{=}\NormalTok{ G.nodes[node\_id]}

        \CommentTok{\# Get node type and set border color}
\NormalTok{        node\_type }\OperatorTok{=}\NormalTok{ node\_data.get(}\StringTok{\textquotesingle{}node\_type\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}unknown\textquotesingle{}}\NormalTok{)}
\NormalTok{        border\_color }\OperatorTok{=}\NormalTok{ get\_border\_color(node\_type)}

        \CommentTok{\# Get probability information}
\NormalTok{        priors }\OperatorTok{=}\NormalTok{ node\_data.get(}\StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{, \{\})}
\NormalTok{        true\_prob }\OperatorTok{=}\NormalTok{ priors.get(}\StringTok{\textquotesingle{}true\_prob\textquotesingle{}}\NormalTok{, }\FloatTok{0.5}\NormalTok{) }\ControlFlowTok{if}\NormalTok{ priors }\ControlFlowTok{else} \FloatTok{0.5}

        \CommentTok{\# Get proper state names}
\NormalTok{        instantiations }\OperatorTok{=}\NormalTok{ node\_data.get(}\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{, [}\StringTok{"TRUE"}\NormalTok{, }\StringTok{"FALSE"}\NormalTok{])}
\NormalTok{        true\_state }\OperatorTok{=}\NormalTok{ instantiations[}\DecValTok{0}\NormalTok{] }\ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(instantiations) }\OperatorTok{\textgreater{}} \DecValTok{0} \ControlFlowTok{else} \StringTok{"TRUE"}
\NormalTok{        false\_state }\OperatorTok{=}\NormalTok{ instantiations[}\DecValTok{1}\NormalTok{] }\ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(instantiations) }\OperatorTok{\textgreater{}} \DecValTok{1} \ControlFlowTok{else} \StringTok{"FALSE"}

        \CommentTok{\# Create background color based on probability}
\NormalTok{        background\_color }\OperatorTok{=}\NormalTok{ get\_probability\_color(priors)}

        \CommentTok{\# Create tooltip with probability information}
\NormalTok{        tooltip }\OperatorTok{=}\NormalTok{ create\_tooltip(node\_id, node\_data)}

        \CommentTok{\# Create a simpler node label with probability}
\NormalTok{        simple\_label }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{node\_id}\SpecialCharTok{\}}\CharTok{\textbackslash{}n}\SpecialStringTok{p=}\SpecialCharTok{\{}\NormalTok{true\_prob}\SpecialCharTok{:.2f\}}\SpecialStringTok{"}

        \CommentTok{\# Store expanded content as a node attribute for use in click handler}
\NormalTok{        node\_data[}\StringTok{\textquotesingle{}expanded\_content\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ create\_expanded\_content(node\_id, node\_data)}

        \CommentTok{\# Set node attributes}
\NormalTok{        node[}\StringTok{\textquotesingle{}title\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ tooltip  }\CommentTok{\# Tooltip HTML}
\NormalTok{        node[}\StringTok{\textquotesingle{}label\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ simple\_label  }\CommentTok{\# Simple text label}
\NormalTok{        node[}\StringTok{\textquotesingle{}shape\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \StringTok{\textquotesingle{}box\textquotesingle{}}
\NormalTok{        node[}\StringTok{\textquotesingle{}color\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ \{}
            \StringTok{\textquotesingle{}background\textquotesingle{}}\NormalTok{: background\_color,}
            \StringTok{\textquotesingle{}border\textquotesingle{}}\NormalTok{: border\_color,}
            \StringTok{\textquotesingle{}highlight\textquotesingle{}}\NormalTok{: \{}
                \StringTok{\textquotesingle{}background\textquotesingle{}}\NormalTok{: background\_color,}
                \StringTok{\textquotesingle{}border\textquotesingle{}}\NormalTok{: border\_color}
\NormalTok{            \}}
\NormalTok{        \}}

    \CommentTok{\# PHASE 5: Setup interactive click handling}
    \CommentTok{\# Prepare data for click handler}
\NormalTok{    setup\_data }\OperatorTok{=}\NormalTok{ \{}
        \StringTok{\textquotesingle{}nodes\_data\textquotesingle{}}\NormalTok{: \{node\_id: \{}
            \StringTok{\textquotesingle{}expanded\_content\textquotesingle{}}\NormalTok{: json.dumps(G.nodes[node\_id].get(}\StringTok{\textquotesingle{}expanded\_content\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{)),}
            \StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{: G.nodes[node\_id].get(}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
            \StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{: G.nodes[node\_id].get(}\StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{, \{\}),}
            \StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{: G.nodes[node\_id].get(}\StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{, \{\})}
\NormalTok{        \} }\ControlFlowTok{for}\NormalTok{ node\_id }\KeywordTok{in}\NormalTok{ G.nodes()\}}
\NormalTok{    \}}

    \CommentTok{\# JavaScript code for handling node clicks}
\NormalTok{    click\_js }\OperatorTok{=} \StringTok{"""}
\StringTok{    // Store node data for click handling}
\StringTok{    var nodesData = }\SpecialCharTok{\%s}\StringTok{;}

\StringTok{    // Add event listener for node clicks}
\StringTok{    network.on("click", function(params) \{}
\StringTok{        if (params.nodes.length \textgreater{} 0) \{}
\StringTok{            var nodeId = params.nodes[0];}
\StringTok{            var nodeInfo = nodesData[nodeId];}

\StringTok{            if (nodeInfo) \{}
\StringTok{                // Create a modal popup for expanded content}
\StringTok{                var modal = document.createElement(\textquotesingle{}div\textquotesingle{});}
\StringTok{                modal.style.position = \textquotesingle{}fixed\textquotesingle{};}
\StringTok{                modal.style.left = \textquotesingle{}50}\SpecialCharTok{\%\%}\StringTok{\textquotesingle{};}
\StringTok{                modal.style.top = \textquotesingle{}50}\SpecialCharTok{\%\%}\StringTok{\textquotesingle{};}
\StringTok{                modal.style.transform = \textquotesingle{}translate({-}50}\SpecialCharTok{\%\%}\StringTok{, {-}50}\SpecialCharTok{\%\%}\StringTok{)\textquotesingle{};}
\StringTok{                modal.style.backgroundColor = \textquotesingle{}white\textquotesingle{};}
\StringTok{                modal.style.padding = \textquotesingle{}20px\textquotesingle{};}
\StringTok{                modal.style.borderRadius = \textquotesingle{}5px\textquotesingle{};}
\StringTok{                modal.style.boxShadow = \textquotesingle{}0 0 10px rgba(0,0,0,0.5)\textquotesingle{};}
\StringTok{                modal.style.zIndex = \textquotesingle{}1000\textquotesingle{};}
\StringTok{                modal.style.maxWidth = \textquotesingle{}80}\SpecialCharTok{\%\%}\StringTok{\textquotesingle{};}
\StringTok{                modal.style.maxHeight = \textquotesingle{}80}\SpecialCharTok{\%\%}\StringTok{\textquotesingle{};}
\StringTok{                modal.style.overflow = \textquotesingle{}auto\textquotesingle{};}

\StringTok{                // Add expanded content}
\StringTok{                modal.innerHTML = nodeInfo.expanded\_content || \textquotesingle{}No detailed information available\textquotesingle{};}

\StringTok{                // Add close button}
\StringTok{                var closeBtn = document.createElement(\textquotesingle{}button\textquotesingle{});}
\StringTok{                closeBtn.innerHTML = \textquotesingle{}Close\textquotesingle{};}
\StringTok{                closeBtn.style.marginTop = \textquotesingle{}10px\textquotesingle{};}
\StringTok{                closeBtn.style.padding = \textquotesingle{}5px 10px\textquotesingle{};}
\StringTok{                closeBtn.style.cursor = \textquotesingle{}pointer\textquotesingle{};}
\StringTok{                closeBtn.onclick = function() \{}
\StringTok{                    document.body.removeChild(modal);}
\StringTok{                \};}
\StringTok{                modal.appendChild(closeBtn);}

\StringTok{                // Add modal to body}
\StringTok{                document.body.appendChild(modal);}
\StringTok{            \}}
\StringTok{        \}}
\StringTok{    \});}
\StringTok{    """} \OperatorTok{\%}\NormalTok{ json.dumps(setup\_data[}\StringTok{\textquotesingle{}nodes\_data\textquotesingle{}}\NormalTok{])}

    \CommentTok{\# PHASE 6: Save the graph to HTML and inject custom click handling}
\NormalTok{    html\_file }\OperatorTok{=} \StringTok{"bayesian\_network.html"}
\NormalTok{    net.save\_graph(html\_file)}

    \CommentTok{\# Inject custom click handling into HTML}
    \ControlFlowTok{try}\NormalTok{:}
        \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(html\_file, }\StringTok{"r"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{            html\_content }\OperatorTok{=}\NormalTok{ f.read()}

        \CommentTok{\# Insert click handling script before the closing body tag}
\NormalTok{        html\_content }\OperatorTok{=}\NormalTok{ html\_content.replace(}\StringTok{\textquotesingle{}\textless{}/body\textgreater{}\textquotesingle{}}\NormalTok{, }\SpecialStringTok{f\textquotesingle{}\textless{}script\textgreater{}}\SpecialCharTok{\{}\NormalTok{click\_js}\SpecialCharTok{\}}\SpecialStringTok{\textless{}/script\textgreater{}\textless{}/body\textgreater{}\textquotesingle{}}\NormalTok{)}

        \CommentTok{\# Write back the modified HTML}
        \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(html\_file, }\StringTok{"w"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{            f.write(html\_content)}

        \ControlFlowTok{return}\NormalTok{ HTML(html\_content)}
    \ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
        \ControlFlowTok{return}\NormalTok{ HTML(}\SpecialStringTok{f"\textless{}p\textgreater{}Error rendering HTML: }\SpecialCharTok{\{}\BuiltInTok{str}\NormalTok{(e)}\SpecialCharTok{\}}\SpecialStringTok{\textless{}/p\textgreater{}"}
          \OperatorTok{+} \StringTok{"\textless{}p\textgreater{}The network visualization has been saved to \textquotesingle{}}\SpecialCharTok{\{html\_file\}}\StringTok{\textquotesingle{}\textless{}/p\textgreater{}"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{4.2 Phase 2: Node Classification and Styling
Module}\label{phase-2-node-classification-and-styling-module}

\phantomsection\label{node_classification_and_styling_functions}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 4.2.0 {-}{-}{-} Node Classification and Styling Functions {-}{-}{-} [node\_classification\_and\_styling\_functions]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Implements the visual classification and styling of nodes in the Bayesian network.}

\CommentTok{This module handles the identification of node types based on their position in}
\CommentTok{the network and provides appropriate visual styling for each type.}
\CommentTok{The functions:}

\CommentTok{1. Classify nodes as parents (causes), children (intermediate effects), or leaves (final effects)}
\CommentTok{2. Assign appropriate border colors to visually distinguish node types}
\CommentTok{3. Calculate background colors based on probability values}
\CommentTok{4. Extract relevant information from DataFrame rows in a robust manner}

\CommentTok{The visual encoding helps users understand both the structure of the network}
\CommentTok{and the probability distributions at a glance.}

\CommentTok{DEPENDENCIES: colorsys for color manipulation}
\CommentTok{INPUTS: Graph structure and node data}
\CommentTok{OUTPUTS: Classification and styling information for visualization}
\CommentTok{"""}

\KeywordTok{def}\NormalTok{ classify\_nodes(G):}
    \CommentTok{"""}
\CommentTok{    Classify nodes as parent, child, or leaf based on network structure}

\CommentTok{    Args:}
\CommentTok{        G (networkx.DiGraph): Directed graph representation of the Bayesian network}

\CommentTok{    Effects:}
\CommentTok{        Adds \textquotesingle{}node\_type\textquotesingle{} attribute to each node in the graph:}
\CommentTok{        {-} \textquotesingle{}parent\textquotesingle{}: Root node with no parents but has children (causal source)}
\CommentTok{        {-} \textquotesingle{}child\textquotesingle{}: Node with both parents and children (intermediate)}
\CommentTok{        {-} \textquotesingle{}leaf\textquotesingle{}: Node with parents but no children (final effect)}
\CommentTok{        {-} \textquotesingle{}isolated\textquotesingle{}: Node with no connections (rare in Bayesian networks)}
\CommentTok{    """}
    \ControlFlowTok{for}\NormalTok{ node }\KeywordTok{in}\NormalTok{ G.nodes():}
\NormalTok{        predecessors }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(G.predecessors(node))  }\CommentTok{\# Nodes pointing to this one (causes)}
\NormalTok{        successors }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(G.successors(node))      }\CommentTok{\# Nodes this one points to (effects)}

        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ predecessors:  }\CommentTok{\# No parents}
            \ControlFlowTok{if}\NormalTok{ successors:  }\CommentTok{\# Has children}
\NormalTok{                G.nodes[node][}\StringTok{\textquotesingle{}node\_type\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \StringTok{\textquotesingle{}parent\textquotesingle{}}  \CommentTok{\# Root cause}
            \ControlFlowTok{else}\NormalTok{:  }\CommentTok{\# No children either}
\NormalTok{                G.nodes[node][}\StringTok{\textquotesingle{}node\_type\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \StringTok{\textquotesingle{}isolated\textquotesingle{}}  \CommentTok{\# Disconnected node}
        \ControlFlowTok{else}\NormalTok{:  }\CommentTok{\# Has parents}
            \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ successors:  }\CommentTok{\# No children}
\NormalTok{                G.nodes[node][}\StringTok{\textquotesingle{}node\_type\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \StringTok{\textquotesingle{}leaf\textquotesingle{}}  \CommentTok{\# Final effect}
            \ControlFlowTok{else}\NormalTok{:  }\CommentTok{\# Has both parents and children}
\NormalTok{                G.nodes[node][}\StringTok{\textquotesingle{}node\_type\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \StringTok{\textquotesingle{}child\textquotesingle{}}  \CommentTok{\# Intermediate node}

\KeywordTok{def}\NormalTok{ get\_border\_color(node\_type):}
    \CommentTok{"""}
\CommentTok{    Return border color based on node type}

\CommentTok{    Args:}
\CommentTok{        node\_type (str): Type of node (\textquotesingle{}parent\textquotesingle{}, \textquotesingle{}child\textquotesingle{}, \textquotesingle{}leaf\textquotesingle{}, or \textquotesingle{}isolated\textquotesingle{})}

\CommentTok{    Returns:}
\CommentTok{        str: Hex color code for node border}
\CommentTok{    """}
    \ControlFlowTok{if}\NormalTok{ node\_type }\OperatorTok{==} \StringTok{\textquotesingle{}parent\textquotesingle{}}\NormalTok{:}
        \ControlFlowTok{return} \StringTok{\textquotesingle{}\#0000FF\textquotesingle{}}  \CommentTok{\# Blue for root causes}
    \ControlFlowTok{elif}\NormalTok{ node\_type }\OperatorTok{==} \StringTok{\textquotesingle{}child\textquotesingle{}}\NormalTok{:}
        \ControlFlowTok{return} \StringTok{\textquotesingle{}\#800080\textquotesingle{}}  \CommentTok{\# Purple for intermediate nodes}
    \ControlFlowTok{elif}\NormalTok{ node\_type }\OperatorTok{==} \StringTok{\textquotesingle{}leaf\textquotesingle{}}\NormalTok{:}
        \ControlFlowTok{return} \StringTok{\textquotesingle{}\#FF00FF\textquotesingle{}}  \CommentTok{\# Magenta for final effects}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{return} \StringTok{\textquotesingle{}\#000000\textquotesingle{}}  \CommentTok{\# Default black for any other type}

\KeywordTok{def}\NormalTok{ get\_probability\_color(priors):}
    \CommentTok{"""}
\CommentTok{    Create background color based on probability (red to green gradient)}

\CommentTok{    Args:}
\CommentTok{        priors (dict): Dictionary containing probability information}

\CommentTok{    Returns:}
\CommentTok{        str: Hex color code for node background, ranging from red (low probability)}
\CommentTok{             to green (high probability)}
\CommentTok{    """}
    \CommentTok{\# Default to neutral color if no probability}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ priors }\KeywordTok{or} \StringTok{\textquotesingle{}true\_prob\textquotesingle{}} \KeywordTok{not} \KeywordTok{in}\NormalTok{ priors:}
        \ControlFlowTok{return} \StringTok{\textquotesingle{}\#F8F8F8\textquotesingle{}}  \CommentTok{\# Light grey}

    \CommentTok{\# Get probability value}
\NormalTok{    prob }\OperatorTok{=}\NormalTok{ priors[}\StringTok{\textquotesingle{}true\_prob\textquotesingle{}}\NormalTok{]}

    \CommentTok{\# Create color gradient from red (0.0) to green (1.0)}
\NormalTok{    hue }\OperatorTok{=} \DecValTok{120} \OperatorTok{*}\NormalTok{ prob  }\CommentTok{\# 0 = red, 120 = green (in HSL color space)}
\NormalTok{    saturation }\OperatorTok{=} \FloatTok{0.75}
\NormalTok{    lightness }\OperatorTok{=} \FloatTok{0.8}  \CommentTok{\# Lighter color for better text visibility}

    \CommentTok{\# Convert HSL to RGB}
\NormalTok{    r, g, b }\OperatorTok{=}\NormalTok{ colorsys.hls\_to\_rgb(hue}\OperatorTok{/}\DecValTok{360}\NormalTok{, lightness, saturation)}

    \CommentTok{\# Convert to hex format}
\NormalTok{    hex\_color }\OperatorTok{=} \StringTok{"\#}\SpecialCharTok{\{:02x\}\{:02x\}\{:02x\}}\StringTok{"}\NormalTok{.}\BuiltInTok{format}\NormalTok{(}\BuiltInTok{int}\NormalTok{(r}\OperatorTok{*}\DecValTok{255}\NormalTok{), }\BuiltInTok{int}\NormalTok{(g}\OperatorTok{*}\DecValTok{255}\NormalTok{), }\BuiltInTok{int}\NormalTok{(b}\OperatorTok{*}\DecValTok{255}\NormalTok{))}

    \ControlFlowTok{return}\NormalTok{ hex\_color}

\KeywordTok{def}\NormalTok{ get\_parents(row):}
    \CommentTok{"""}
\CommentTok{    Extract parent nodes from row data, with safe handling for different data types}

\CommentTok{    Args:}
\CommentTok{        row (pandas.Series): Row from DataFrame containing node information}

\CommentTok{    Returns:}
\CommentTok{        list: List of parent node names}
\CommentTok{    """}
    \ControlFlowTok{if} \StringTok{\textquotesingle{}Parents\textquotesingle{}} \KeywordTok{not} \KeywordTok{in}\NormalTok{ row:}
        \ControlFlowTok{return}\NormalTok{ []}

\NormalTok{    parents\_data }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{]}

    \CommentTok{\# Handle NaN, None, or empty list}
    \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(parents\_data, }\BuiltInTok{float}\NormalTok{) }\KeywordTok{and}\NormalTok{ pd.isna(parents\_data):}
        \ControlFlowTok{return}\NormalTok{ []}

    \ControlFlowTok{if}\NormalTok{ parents\_data }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ []}

    \CommentTok{\# Handle different data types}
    \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(parents\_data, }\BuiltInTok{list}\NormalTok{):}
        \CommentTok{\# Return a list with NaN and empty strings removed}
        \ControlFlowTok{return}\NormalTok{ [p }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ parents\_data }\ControlFlowTok{if} \KeywordTok{not}\NormalTok{ (}\BuiltInTok{isinstance}\NormalTok{(p, }\BuiltInTok{float}\NormalTok{) }\KeywordTok{and}\NormalTok{ pd.isna(p)) }\KeywordTok{and}\NormalTok{ p }\OperatorTok{!=} \StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{]}

    \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(parents\_data, }\BuiltInTok{str}\NormalTok{):}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ parents\_data.strip():}
            \ControlFlowTok{return}\NormalTok{ []}

        \CommentTok{\# Remove brackets and split by comma, removing empty strings and NaN}
\NormalTok{        cleaned }\OperatorTok{=}\NormalTok{ parents\_data.strip(}\StringTok{\textquotesingle{}[]"}\CharTok{\textbackslash{}\textquotesingle{}}\StringTok{\textquotesingle{}}\NormalTok{)}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ cleaned:}
            \ControlFlowTok{return}\NormalTok{ []}

        \ControlFlowTok{return}\NormalTok{ [p.strip(}\StringTok{\textquotesingle{} "}\CharTok{\textbackslash{}\textquotesingle{}}\StringTok{\textquotesingle{}}\NormalTok{) }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ cleaned.split(}\StringTok{\textquotesingle{},\textquotesingle{}}\NormalTok{) }\ControlFlowTok{if}\NormalTok{ p.strip()]}

    \CommentTok{\# Default: empty list}
    \ControlFlowTok{return}\NormalTok{ []}

\KeywordTok{def}\NormalTok{ get\_instantiations(row):}
    \CommentTok{"""}
\CommentTok{    Extract instantiations with safe handling for different data types}

\CommentTok{    Args:}
\CommentTok{        row (pandas.Series): Row from DataFrame containing node information}

\CommentTok{    Returns:}
\CommentTok{        list: List of possible instantiations (states) for the node}
\CommentTok{    """}
    \ControlFlowTok{if} \StringTok{\textquotesingle{}instantiations\textquotesingle{}} \KeywordTok{not} \KeywordTok{in}\NormalTok{ row:}
        \ControlFlowTok{return}\NormalTok{ [}\StringTok{"TRUE"}\NormalTok{, }\StringTok{"FALSE"}\NormalTok{]}

\NormalTok{    inst\_data }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{]}

    \CommentTok{\# Handle NaN or None}
    \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(inst\_data, }\BuiltInTok{float}\NormalTok{) }\KeywordTok{and}\NormalTok{ pd.isna(inst\_data):}
        \ControlFlowTok{return}\NormalTok{ [}\StringTok{"TRUE"}\NormalTok{, }\StringTok{"FALSE"}\NormalTok{]}

    \ControlFlowTok{if}\NormalTok{ inst\_data }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ [}\StringTok{"TRUE"}\NormalTok{, }\StringTok{"FALSE"}\NormalTok{]}

    \CommentTok{\# Handle different data types}
    \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(inst\_data, }\BuiltInTok{list}\NormalTok{):}
        \ControlFlowTok{return}\NormalTok{ inst\_data }\ControlFlowTok{if}\NormalTok{ inst\_data }\ControlFlowTok{else}\NormalTok{ [}\StringTok{"TRUE"}\NormalTok{, }\StringTok{"FALSE"}\NormalTok{]}

    \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(inst\_data, }\BuiltInTok{str}\NormalTok{):}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ inst\_data.strip():}
            \ControlFlowTok{return}\NormalTok{ [}\StringTok{"TRUE"}\NormalTok{, }\StringTok{"FALSE"}\NormalTok{]}

        \CommentTok{\# Remove brackets and split by comma}
\NormalTok{        cleaned }\OperatorTok{=}\NormalTok{ inst\_data.strip(}\StringTok{\textquotesingle{}[]"}\CharTok{\textbackslash{}\textquotesingle{}}\StringTok{\textquotesingle{}}\NormalTok{)}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ cleaned:}
            \ControlFlowTok{return}\NormalTok{ [}\StringTok{"TRUE"}\NormalTok{, }\StringTok{"FALSE"}\NormalTok{]}

        \ControlFlowTok{return}\NormalTok{ [i.strip(}\StringTok{\textquotesingle{} "}\CharTok{\textbackslash{}\textquotesingle{}}\StringTok{\textquotesingle{}}\NormalTok{) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in}\NormalTok{ cleaned.split(}\StringTok{\textquotesingle{},\textquotesingle{}}\NormalTok{) }\ControlFlowTok{if}\NormalTok{ i.strip()]}

    \CommentTok{\# Default}
    \ControlFlowTok{return}\NormalTok{ [}\StringTok{"TRUE"}\NormalTok{, }\StringTok{"FALSE"}\NormalTok{]}

\KeywordTok{def}\NormalTok{ get\_priors(row):}
    \CommentTok{"""}
\CommentTok{    Extract prior probabilities with safe handling for different data types}

\CommentTok{    Args:}
\CommentTok{        row (pandas.Series): Row from DataFrame containing node information}

\CommentTok{    Returns:}
\CommentTok{        dict: Dictionary of prior probabilities with \textquotesingle{}true\_prob\textquotesingle{} added for convenience}
\CommentTok{    """}
    \ControlFlowTok{if} \StringTok{\textquotesingle{}priors\textquotesingle{}} \KeywordTok{not} \KeywordTok{in}\NormalTok{ row:}
        \ControlFlowTok{return}\NormalTok{ \{\}}

\NormalTok{    priors\_data }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{]}

    \CommentTok{\# Handle NaN or None}
    \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(priors\_data, }\BuiltInTok{float}\NormalTok{) }\KeywordTok{and}\NormalTok{ pd.isna(priors\_data):}
        \ControlFlowTok{return}\NormalTok{ \{\}}

    \ControlFlowTok{if}\NormalTok{ priors\_data }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ \{\}}

\NormalTok{    result }\OperatorTok{=}\NormalTok{ \{\}}

    \CommentTok{\# Handle dictionary}
    \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(priors\_data, }\BuiltInTok{dict}\NormalTok{):}
\NormalTok{        result }\OperatorTok{=}\NormalTok{ priors\_data}
    \CommentTok{\# Handle string representation of dictionary}
    \ControlFlowTok{elif} \BuiltInTok{isinstance}\NormalTok{(priors\_data, }\BuiltInTok{str}\NormalTok{):}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ priors\_data.strip() }\KeywordTok{or}\NormalTok{ priors\_data }\OperatorTok{==} \StringTok{\textquotesingle{}}\SpecialCharTok{\{\}}\StringTok{\textquotesingle{}}\NormalTok{:}
            \ControlFlowTok{return}\NormalTok{ \{\}}

        \ControlFlowTok{try}\NormalTok{:}
            \CommentTok{\# Try to evaluate as Python literal}
            \ImportTok{import}\NormalTok{ ast}
\NormalTok{            result }\OperatorTok{=}\NormalTok{ ast.literal\_eval(priors\_data)}
        \ControlFlowTok{except}\NormalTok{:}
            \CommentTok{\# Simple parsing for items like \{\textquotesingle{}p(TRUE)\textquotesingle{}: \textquotesingle{}0.2\textquotesingle{}, \textquotesingle{}p(FALSE)\textquotesingle{}: \textquotesingle{}0.8\textquotesingle{}\}}
            \ControlFlowTok{if} \StringTok{\textquotesingle{}\{\textquotesingle{}} \KeywordTok{in}\NormalTok{ priors\_data }\KeywordTok{and} \StringTok{\textquotesingle{}\}\textquotesingle{}} \KeywordTok{in}\NormalTok{ priors\_data:}
\NormalTok{                content }\OperatorTok{=}\NormalTok{ priors\_data[priors\_data.find(}\StringTok{\textquotesingle{}\{\textquotesingle{}}\NormalTok{)}\OperatorTok{+}\DecValTok{1}\NormalTok{:priors\_data.rfind(}\StringTok{\textquotesingle{}\}\textquotesingle{}}\NormalTok{)]}
\NormalTok{                items }\OperatorTok{=}\NormalTok{ [item.strip() }\ControlFlowTok{for}\NormalTok{ item }\KeywordTok{in}\NormalTok{ content.split(}\StringTok{\textquotesingle{},\textquotesingle{}}\NormalTok{)]}

                \ControlFlowTok{for}\NormalTok{ item }\KeywordTok{in}\NormalTok{ items:}
                    \ControlFlowTok{if} \StringTok{\textquotesingle{}:\textquotesingle{}} \KeywordTok{in}\NormalTok{ item:}
\NormalTok{                        key, value }\OperatorTok{=}\NormalTok{ item.split(}\StringTok{\textquotesingle{}:\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{                        key }\OperatorTok{=}\NormalTok{ key.strip(}\StringTok{\textquotesingle{} }\CharTok{\textbackslash{}\textquotesingle{}\textbackslash{}"}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{                        value }\OperatorTok{=}\NormalTok{ value.strip(}\StringTok{\textquotesingle{} }\CharTok{\textbackslash{}\textquotesingle{}\textbackslash{}"}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{                        result[key] }\OperatorTok{=}\NormalTok{ value}

    \CommentTok{\# Extract main probability for TRUE state}
\NormalTok{    instantiations }\OperatorTok{=}\NormalTok{ get\_instantiations(row)}
\NormalTok{    true\_state }\OperatorTok{=}\NormalTok{ instantiations[}\DecValTok{0}\NormalTok{] }\ControlFlowTok{if}\NormalTok{ instantiations }\ControlFlowTok{else} \StringTok{"TRUE"}
\NormalTok{    true\_key }\OperatorTok{=} \SpecialStringTok{f"p(}\SpecialCharTok{\{}\NormalTok{true\_state}\SpecialCharTok{\}}\SpecialStringTok{)"}

    \ControlFlowTok{if}\NormalTok{ true\_key }\KeywordTok{in}\NormalTok{ result:}
        \ControlFlowTok{try}\NormalTok{:}
\NormalTok{            result[}\StringTok{\textquotesingle{}true\_prob\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \BuiltInTok{float}\NormalTok{(result[true\_key])}
        \ControlFlowTok{except}\NormalTok{:}
            \ControlFlowTok{pass}

    \ControlFlowTok{return}\NormalTok{ result}

\KeywordTok{def}\NormalTok{ get\_posteriors(row):}
    \CommentTok{"""}
\CommentTok{    Extract posterior probabilities with safe handling for different data types}

\CommentTok{    Args:}
\CommentTok{        row (pandas.Series): Row from DataFrame containing node information}

\CommentTok{    Returns:}
\CommentTok{        dict: Dictionary of conditional probabilities}
\CommentTok{    """}
    \ControlFlowTok{if} \StringTok{\textquotesingle{}posteriors\textquotesingle{}} \KeywordTok{not} \KeywordTok{in}\NormalTok{ row:}
        \ControlFlowTok{return}\NormalTok{ \{\}}

\NormalTok{    posteriors\_data }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{]}

    \CommentTok{\# Handle NaN or None}
    \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(posteriors\_data, }\BuiltInTok{float}\NormalTok{) }\KeywordTok{and}\NormalTok{ pd.isna(posteriors\_data):}
        \ControlFlowTok{return}\NormalTok{ \{\}}

    \ControlFlowTok{if}\NormalTok{ posteriors\_data }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ \{\}}

\NormalTok{    result }\OperatorTok{=}\NormalTok{ \{\}}

    \CommentTok{\# Handle dictionary}
    \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(posteriors\_data, }\BuiltInTok{dict}\NormalTok{):}
\NormalTok{        result }\OperatorTok{=}\NormalTok{ posteriors\_data}
    \CommentTok{\# Handle string representation of dictionary}
    \ControlFlowTok{elif} \BuiltInTok{isinstance}\NormalTok{(posteriors\_data, }\BuiltInTok{str}\NormalTok{):}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ posteriors\_data.strip() }\KeywordTok{or}\NormalTok{ posteriors\_data }\OperatorTok{==} \StringTok{\textquotesingle{}}\SpecialCharTok{\{\}}\StringTok{\textquotesingle{}}\NormalTok{:}
            \ControlFlowTok{return}\NormalTok{ \{\}}

        \ControlFlowTok{try}\NormalTok{:}
            \CommentTok{\# Try to evaluate as Python literal}
            \ImportTok{import}\NormalTok{ ast}
\NormalTok{            result }\OperatorTok{=}\NormalTok{ ast.literal\_eval(posteriors\_data)}
        \ControlFlowTok{except}\NormalTok{:}
            \CommentTok{\# Simple parsing}
            \ControlFlowTok{if} \StringTok{\textquotesingle{}\{\textquotesingle{}} \KeywordTok{in}\NormalTok{ posteriors\_data }\KeywordTok{and} \StringTok{\textquotesingle{}\}\textquotesingle{}} \KeywordTok{in}\NormalTok{ posteriors\_data:}
\NormalTok{                content }\OperatorTok{=}\NormalTok{ posteriors\_data[posteriors\_data.find(}\StringTok{\textquotesingle{}\{\textquotesingle{}}\NormalTok{)}\OperatorTok{+}\DecValTok{1}\NormalTok{:posteriors\_data.rfind(}\StringTok{\textquotesingle{}\}\textquotesingle{}}\NormalTok{)]}
\NormalTok{                items }\OperatorTok{=}\NormalTok{ [item.strip() }\ControlFlowTok{for}\NormalTok{ item }\KeywordTok{in}\NormalTok{ content.split(}\StringTok{\textquotesingle{},\textquotesingle{}}\NormalTok{)]}

                \ControlFlowTok{for}\NormalTok{ item }\KeywordTok{in}\NormalTok{ items:}
                    \ControlFlowTok{if} \StringTok{\textquotesingle{}:\textquotesingle{}} \KeywordTok{in}\NormalTok{ item:}
\NormalTok{                        key, value }\OperatorTok{=}\NormalTok{ item.split(}\StringTok{\textquotesingle{}:\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{                        key }\OperatorTok{=}\NormalTok{ key.strip(}\StringTok{\textquotesingle{} }\CharTok{\textbackslash{}\textquotesingle{}\textbackslash{}"}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{                        value }\OperatorTok{=}\NormalTok{ value.strip(}\StringTok{\textquotesingle{} }\CharTok{\textbackslash{}\textquotesingle{}\textbackslash{}"}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{                        result[key] }\OperatorTok{=}\NormalTok{ value}

    \ControlFlowTok{return}\NormalTok{ result}
\end{Highlighting}
\end{Shaded}

\section{4.3 Phase 3: HTML Content Generation
Module}\label{phase-3-html-content-generation-module}

\phantomsection\label{html_content_generation_functions}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 4.3.0 {-}{-}{-} HTML Content Generation Functions {-}{-}{-} [html\_content\_generation\_functions]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Creates rich HTML content for the interactive Bayesian network visualization.}

\CommentTok{This module generates the HTML components that enhance the Bayesian network}
\CommentTok{visualization:}
\CommentTok{1. Probability bars {-} Visual representation of probability distributions}
\CommentTok{2. Node tooltips {-} Rich information displayed on hover}
\CommentTok{3. Expanded content {-} Detailed probability information shown when clicking nodes}

\CommentTok{These HTML components make the mathematical concepts of Bayesian networks more}
\CommentTok{intuitive and accessible to users without requiring deep statistical knowledge.}
\CommentTok{The visual encoding of probabilities (colors, bars) and the progressive}
\CommentTok{disclosure of information (hover, click) help users build understanding at}
\CommentTok{their own pace.}

\CommentTok{DEPENDENCIES: HTML generation capabilities}
\CommentTok{INPUTS: Node data from the Bayesian network}
\CommentTok{OUTPUTS: HTML content for visualization components}
\CommentTok{"""}

\KeywordTok{def}\NormalTok{ create\_probability\_bar(true\_prob, false\_prob, height}\OperatorTok{=}\StringTok{"15px"}\NormalTok{, show\_values}\OperatorTok{=}\VariableTok{True}\NormalTok{, value\_prefix}\OperatorTok{=}\StringTok{""}\NormalTok{):}
    \CommentTok{"""}
\CommentTok{    Creates a reusable HTML component to visualize probability distribution}

\CommentTok{    Args:}
\CommentTok{        true\_prob (float): Probability of the true state (0.0{-}1.0)}
\CommentTok{        false\_prob (float): Probability of the false state (0.0{-}1.0)}
\CommentTok{        height (str): CSS height of the bar}
\CommentTok{        show\_values (bool): Whether to display numerical values}
\CommentTok{        value\_prefix (str): Prefix to add before values (e.g., "p=")}

\CommentTok{    Returns:}
\CommentTok{        str: HTML for a horizontal bar showing probabilities}
\CommentTok{    """}
    \CommentTok{\# Prepare display labels if showing values}
\NormalTok{    true\_label }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{value\_prefix}\SpecialCharTok{\}\{}\NormalTok{true\_prob}\SpecialCharTok{:.3f\}}\SpecialStringTok{"} \ControlFlowTok{if}\NormalTok{ show\_values }\ControlFlowTok{else} \StringTok{""}
\NormalTok{    false\_label }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{value\_prefix}\SpecialCharTok{\}\{}\NormalTok{false\_prob}\SpecialCharTok{:.3f\}}\SpecialStringTok{"} \ControlFlowTok{if}\NormalTok{ show\_values }\ControlFlowTok{else} \StringTok{""}

    \CommentTok{\# Create the HTML for a horizontal stacked bar}
\NormalTok{    html }\OperatorTok{=} \SpecialStringTok{f"""}
\SpecialStringTok{    \textless{}div style="width:100\%; height:}\SpecialCharTok{\{}\NormalTok{height}\SpecialCharTok{\}}\SpecialStringTok{; display:flex; border:1px solid \#ccc; overflow:hidden; border{-}radius:3px; margin{-}top:3px; margin{-}bottom:3px;"\textgreater{}}
\SpecialStringTok{        \textless{}div style="flex{-}basis:}\SpecialCharTok{\{}\NormalTok{true\_prob}\OperatorTok{*}\DecValTok{100}\SpecialCharTok{\}}\SpecialStringTok{\%; background:linear{-}gradient(to bottom, rgba(0,180,0,0.9), rgba(0,140,0,0.7)); border{-}right:2px solid \#008800; display:flex; align{-}items:center; justify{-}content:center; overflow:hidden; min{-}width:}\SpecialCharTok{\{}\DecValTok{2} \ControlFlowTok{if}\NormalTok{ true\_prob }\OperatorTok{\textgreater{}} \DecValTok{0} \ControlFlowTok{else} \DecValTok{0}\SpecialCharTok{\}}\SpecialStringTok{px;"\textgreater{}}
\SpecialStringTok{            \textless{}span style="font{-}size:10px; color:white; text{-}shadow:0px 0px 2px \#000;"\textgreater{}}\SpecialCharTok{\{}\NormalTok{true\_label}\SpecialCharTok{\}}\SpecialStringTok{\textless{}/span\textgreater{}}
\SpecialStringTok{        \textless{}/div\textgreater{}}
\SpecialStringTok{        \textless{}div style="flex{-}basis:}\SpecialCharTok{\{}\NormalTok{false\_prob}\OperatorTok{*}\DecValTok{100}\SpecialCharTok{\}}\SpecialStringTok{\%; background:linear{-}gradient(to bottom, rgba(220,0,0,0.9), rgba(180,0,0,0.7)); border{-}left:2px solid \#880000; display:flex; align{-}items:center; justify{-}content:center; overflow:hidden; min{-}width:}\SpecialCharTok{\{}\DecValTok{2} \ControlFlowTok{if}\NormalTok{ false\_prob }\OperatorTok{\textgreater{}} \DecValTok{0} \ControlFlowTok{else} \DecValTok{0}\SpecialCharTok{\}}\SpecialStringTok{px;"\textgreater{}}
\SpecialStringTok{            \textless{}span style="font{-}size:10px; color:white; text{-}shadow:0px 0px 2px \#000;"\textgreater{}}\SpecialCharTok{\{}\NormalTok{false\_label}\SpecialCharTok{\}}\SpecialStringTok{\textless{}/span\textgreater{}}
\SpecialStringTok{        \textless{}/div\textgreater{}}
\SpecialStringTok{    \textless{}/div\textgreater{}}
\SpecialStringTok{    """}
    \ControlFlowTok{return}\NormalTok{ html}

\KeywordTok{def}\NormalTok{ create\_tooltip(node\_id, node\_data):}
    \CommentTok{"""}
\CommentTok{    Create rich HTML tooltip with probability information}

\CommentTok{    Args:}
\CommentTok{        node\_id (str): Identifier of the node}
\CommentTok{        node\_data (dict): Node attributes including probabilities}

\CommentTok{    Returns:}
\CommentTok{        str: HTML content for tooltip displayed on hover}
\CommentTok{    """}
    \CommentTok{\# Extract node information}
\NormalTok{    description }\OperatorTok{=}\NormalTok{ node\_data.get(}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{)}
\NormalTok{    priors }\OperatorTok{=}\NormalTok{ node\_data.get(}\StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{, \{\})}
\NormalTok{    instantiations }\OperatorTok{=}\NormalTok{ node\_data.get(}\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{, [}\StringTok{"TRUE"}\NormalTok{, }\StringTok{"FALSE"}\NormalTok{])}

    \CommentTok{\# Start building the HTML tooltip}
\NormalTok{    html }\OperatorTok{=} \SpecialStringTok{f"""}
\SpecialStringTok{    \textless{}div style="max{-}width:350px; padding:10px; background{-}color:\#f8f9fa; border{-}radius:5px; font{-}family:Arial, sans{-}serif;"\textgreater{}}
\SpecialStringTok{        \textless{}h3 style="margin{-}top:0; color:\#202124;"\textgreater{}}\SpecialCharTok{\{}\NormalTok{node\_id}\SpecialCharTok{\}}\SpecialStringTok{\textless{}/h3\textgreater{}}
\SpecialStringTok{        \textless{}p style="font{-}style:italic;"\textgreater{}}\SpecialCharTok{\{}\NormalTok{description}\SpecialCharTok{\}}\SpecialStringTok{\textless{}/p\textgreater{}}
\SpecialStringTok{    """}

    \CommentTok{\# Add prior probabilities section}
    \ControlFlowTok{if}\NormalTok{ priors }\KeywordTok{and} \StringTok{\textquotesingle{}true\_prob\textquotesingle{}} \KeywordTok{in}\NormalTok{ priors:}
\NormalTok{        true\_prob }\OperatorTok{=}\NormalTok{ priors[}\StringTok{\textquotesingle{}true\_prob\textquotesingle{}}\NormalTok{]}
\NormalTok{        false\_prob }\OperatorTok{=} \FloatTok{1.0} \OperatorTok{{-}}\NormalTok{ true\_prob}

        \CommentTok{\# Get proper state names}
\NormalTok{        true\_state }\OperatorTok{=}\NormalTok{ instantiations[}\DecValTok{0}\NormalTok{] }\ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(instantiations) }\OperatorTok{\textgreater{}} \DecValTok{0} \ControlFlowTok{else} \StringTok{"TRUE"}
\NormalTok{        false\_state }\OperatorTok{=}\NormalTok{ instantiations[}\DecValTok{1}\NormalTok{] }\ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(instantiations) }\OperatorTok{\textgreater{}} \DecValTok{1} \ControlFlowTok{else} \StringTok{"FALSE"}

\NormalTok{        html }\OperatorTok{+=} \SpecialStringTok{f"""}
\SpecialStringTok{        \textless{}div style="margin{-}top:10px; background{-}color:\#fff; padding:8px; border{-}radius:4px; border:1px solid \#ddd;"\textgreater{}}
\SpecialStringTok{            \textless{}h4 style="margin{-}top:0; font{-}size:14px;"\textgreater{}Prior Probabilities:\textless{}/h4\textgreater{}}
\SpecialStringTok{            \textless{}div style="display:flex; justify{-}content:space{-}between; margin{-}bottom:4px;"\textgreater{}}
\SpecialStringTok{                \textless{}div style="font{-}size:12px;"\textgreater{}}\SpecialCharTok{\{}\NormalTok{true\_state}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\NormalTok{true\_prob}\SpecialCharTok{:.3f\}}\SpecialStringTok{\textless{}/div\textgreater{}}
\SpecialStringTok{                \textless{}div style="font{-}size:12px;"\textgreater{}}\SpecialCharTok{\{}\NormalTok{false\_state}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\NormalTok{false\_prob}\SpecialCharTok{:.3f\}}\SpecialStringTok{\textless{}/div\textgreater{}}
\SpecialStringTok{            \textless{}/div\textgreater{}}
\SpecialStringTok{            }\SpecialCharTok{\{}\NormalTok{create\_probability\_bar(true\_prob, false\_prob, }\StringTok{"20px"}\NormalTok{, }\VariableTok{True}\NormalTok{)}\SpecialCharTok{\}}
\SpecialStringTok{        \textless{}/div\textgreater{}}
\SpecialStringTok{        """}

    \CommentTok{\# Add click instruction}
\NormalTok{    html }\OperatorTok{+=} \StringTok{"""}
\StringTok{    \textless{}div style="margin{-}top:8px; font{-}size:12px; color:\#666; text{-}align:center;"\textgreater{}}
\StringTok{        Click node to see full probability details}
\StringTok{    \textless{}/div\textgreater{}}
\StringTok{    \textless{}/div\textgreater{}}
\StringTok{    """}

    \ControlFlowTok{return}\NormalTok{ html}

\KeywordTok{def}\NormalTok{ create\_expanded\_content(node\_id, node\_data):}
    \CommentTok{"""}
\CommentTok{    Create expanded content shown when a node is clicked}

\CommentTok{    Args:}
\CommentTok{        node\_id (str): Identifier of the node}
\CommentTok{        node\_data (dict): Node attributes including probabilities}

\CommentTok{    Returns:}
\CommentTok{        str: HTML content for detailed view displayed on click}
\CommentTok{    """}
    \CommentTok{\# Extract node information}
\NormalTok{    description }\OperatorTok{=}\NormalTok{ node\_data.get(}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{)}
\NormalTok{    priors }\OperatorTok{=}\NormalTok{ node\_data.get(}\StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{, \{\})}
\NormalTok{    posteriors }\OperatorTok{=}\NormalTok{ node\_data.get(}\StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{, \{\})}
\NormalTok{    instantiations }\OperatorTok{=}\NormalTok{ node\_data.get(}\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{, [}\StringTok{"TRUE"}\NormalTok{, }\StringTok{"FALSE"}\NormalTok{])}

    \CommentTok{\# Get proper state names}
\NormalTok{    true\_state }\OperatorTok{=}\NormalTok{ instantiations[}\DecValTok{0}\NormalTok{] }\ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(instantiations) }\OperatorTok{\textgreater{}} \DecValTok{0} \ControlFlowTok{else} \StringTok{"TRUE"}
\NormalTok{    false\_state }\OperatorTok{=}\NormalTok{ instantiations[}\DecValTok{1}\NormalTok{] }\ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(instantiations) }\OperatorTok{\textgreater{}} \DecValTok{1} \ControlFlowTok{else} \StringTok{"FALSE"}

    \CommentTok{\# Extract probabilities}
\NormalTok{    true\_prob }\OperatorTok{=}\NormalTok{ priors.get(}\StringTok{\textquotesingle{}true\_prob\textquotesingle{}}\NormalTok{, }\FloatTok{0.5}\NormalTok{)}
\NormalTok{    false\_prob }\OperatorTok{=} \FloatTok{1.0} \OperatorTok{{-}}\NormalTok{ true\_prob}

    \CommentTok{\# Start building the expanded content}
\NormalTok{    html }\OperatorTok{=} \SpecialStringTok{f"""}
\SpecialStringTok{    \textless{}div style="max{-}width:500px; padding:15px; font{-}family:Arial, sans{-}serif;"\textgreater{}}
\SpecialStringTok{        \textless{}h2 style="margin{-}top:0; color:\#333;"\textgreater{}}\SpecialCharTok{\{}\NormalTok{node\_id}\SpecialCharTok{\}}\SpecialStringTok{\textless{}/h2\textgreater{}}
\SpecialStringTok{        \textless{}p style="font{-}style:italic; margin{-}bottom:15px;"\textgreater{}}\SpecialCharTok{\{}\NormalTok{description}\SpecialCharTok{\}}\SpecialStringTok{\textless{}/p\textgreater{}}

\SpecialStringTok{        \textless{}div style="margin{-}bottom:20px; padding:12px; border:1px solid \#ddd; background{-}color:\#f9f9f9; border{-}radius:5px;"\textgreater{}}
\SpecialStringTok{            \textless{}h3 style="margin{-}top:0; color:\#333;"\textgreater{}Prior Probabilities\textless{}/h3\textgreater{}}
\SpecialStringTok{            \textless{}div style="display:flex; justify{-}content:space{-}between; margin{-}bottom:5px;"\textgreater{}}
\SpecialStringTok{                \textless{}div\textgreater{}\textless{}strong\textgreater{}}\SpecialCharTok{\{}\NormalTok{true\_state}\SpecialCharTok{\}}\SpecialStringTok{:\textless{}/strong\textgreater{} }\SpecialCharTok{\{}\NormalTok{true\_prob}\SpecialCharTok{:.3f\}}\SpecialStringTok{\textless{}/div\textgreater{}}
\SpecialStringTok{                \textless{}div\textgreater{}\textless{}strong\textgreater{}}\SpecialCharTok{\{}\NormalTok{false\_state}\SpecialCharTok{\}}\SpecialStringTok{:\textless{}/strong\textgreater{} }\SpecialCharTok{\{}\NormalTok{false\_prob}\SpecialCharTok{:.3f\}}\SpecialStringTok{\textless{}/div\textgreater{}}
\SpecialStringTok{            \textless{}/div\textgreater{}}
\SpecialStringTok{            }\SpecialCharTok{\{}\NormalTok{create\_probability\_bar(true\_prob, false\_prob, }\StringTok{"25px"}\NormalTok{, }\VariableTok{True}\NormalTok{)}\SpecialCharTok{\}}
\SpecialStringTok{        \textless{}/div\textgreater{}}
\SpecialStringTok{    """}

    \CommentTok{\# Add conditional probability table if available}
    \ControlFlowTok{if}\NormalTok{ posteriors:}
\NormalTok{        html }\OperatorTok{+=} \StringTok{"""}
\StringTok{        \textless{}div style="padding:12px; border:1px solid \#ddd; background{-}color:\#f9f9f9; border{-}radius:5px;"\textgreater{}}
\StringTok{            \textless{}h3 style="margin{-}top:0; color:\#333;"\textgreater{}Conditional Probabilities\textless{}/h3\textgreater{}}
\StringTok{            \textless{}table style="width:100\%; border{-}collapse:collapse; font{-}size:13px;"\textgreater{}}
\StringTok{                \textless{}tr style="background{-}color:\#eee;"\textgreater{}}
\StringTok{                    \textless{}th style="padding:8px; text{-}align:left; border:1px solid \#ddd;"\textgreater{}Condition\textless{}/th\textgreater{}}
\StringTok{                    \textless{}th style="padding:8px; text{-}align:center; border:1px solid \#ddd; width:80px;"\textgreater{}Value\textless{}/th\textgreater{}}
\StringTok{                    \textless{}th style="padding:8px; text{-}align:center; border:1px solid \#ddd;"\textgreater{}Visualization\textless{}/th\textgreater{}}
\StringTok{                \textless{}/tr\textgreater{}}
\StringTok{        """}

        \CommentTok{\# Sort posteriors to group by similar conditions}
\NormalTok{        posterior\_items }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(posteriors.items())}
\NormalTok{        posterior\_items.sort(key}\OperatorTok{=}\KeywordTok{lambda}\NormalTok{ x: x[}\DecValTok{0}\NormalTok{])}

        \CommentTok{\# Add rows for conditional probabilities}
        \ControlFlowTok{for}\NormalTok{ key, value }\KeywordTok{in}\NormalTok{ posterior\_items:}
            \ControlFlowTok{try}\NormalTok{:}
                \CommentTok{\# Try to parse probability value}
\NormalTok{                prob\_value }\OperatorTok{=} \BuiltInTok{float}\NormalTok{(value)}
\NormalTok{                inv\_prob }\OperatorTok{=} \FloatTok{1.0} \OperatorTok{{-}}\NormalTok{ prob\_value}

                \CommentTok{\# Add row with probability visualization}
\NormalTok{                html }\OperatorTok{+=} \SpecialStringTok{f"""}
\SpecialStringTok{                \textless{}tr\textgreater{}}
\SpecialStringTok{                    \textless{}td style="padding:8px; border:1px solid \#ddd;"\textgreater{}}\SpecialCharTok{\{}\NormalTok{key}\SpecialCharTok{\}}\SpecialStringTok{\textless{}/td\textgreater{}}
\SpecialStringTok{                    \textless{}td style="padding:8px; text{-}align:center; border:1px solid \#ddd;"\textgreater{}}\SpecialCharTok{\{}\NormalTok{prob\_value}\SpecialCharTok{:.3f\}}\SpecialStringTok{\textless{}/td\textgreater{}}
\SpecialStringTok{                    \textless{}td style="padding:8px; border:1px solid \#ddd;"\textgreater{}}
\SpecialStringTok{                        }\SpecialCharTok{\{}\NormalTok{create\_probability\_bar(prob\_value, inv\_prob, }\StringTok{"20px"}\NormalTok{, }\VariableTok{False}\NormalTok{)}\SpecialCharTok{\}}
\SpecialStringTok{                    \textless{}/td\textgreater{}}
\SpecialStringTok{                \textless{}/tr\textgreater{}}
\SpecialStringTok{                """}
            \ControlFlowTok{except}\NormalTok{:}
                \CommentTok{\# Fallback for non{-}numeric values}
\NormalTok{                html }\OperatorTok{+=} \SpecialStringTok{f"""}
\SpecialStringTok{                \textless{}tr\textgreater{}}
\SpecialStringTok{                    \textless{}td style="padding:8px; border:1px solid \#ddd;"\textgreater{}}\SpecialCharTok{\{}\NormalTok{key}\SpecialCharTok{\}}\SpecialStringTok{\textless{}/td\textgreater{}}
\SpecialStringTok{                    \textless{}td style="padding:8px; text{-}align:center; border:1px solid \#ddd;" colspan="2"\textgreater{}}\SpecialCharTok{\{}\NormalTok{value}\SpecialCharTok{\}}\SpecialStringTok{\textless{}/td\textgreater{}}
\SpecialStringTok{                \textless{}/tr\textgreater{}}
\SpecialStringTok{                """}

\NormalTok{        html }\OperatorTok{+=} \StringTok{"""}
\StringTok{            \textless{}/table\textgreater{}}
\StringTok{        \textless{}/div\textgreater{}}
\StringTok{        """}

\NormalTok{    html }\OperatorTok{+=} \StringTok{"\textless{}/div\textgreater{}"}

    \ControlFlowTok{return}\NormalTok{ html}
\end{Highlighting}
\end{Shaded}

\section{4.4 Phase 4: Main Visualization
Function}\label{phase-4-main-visualization-function}

\phantomsection\label{main_visualization_function}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 4.4.0 {-}{-}{-} Main Visualization Function {-}{-}{-} [main\_visualization\_function]}

\KeywordTok{def}\NormalTok{ create\_bayesian\_network\_with\_probabilities(df):}
    \CommentTok{"""}
\CommentTok{    Create an interactive Bayesian network visualization with enhanced}
\CommentTok{    probability visualization and node classification based on network structure.}
\CommentTok{    """}
    \CommentTok{\# Create a directed graph}
\NormalTok{    G }\OperatorTok{=}\NormalTok{ nx.DiGraph()}

    \CommentTok{\# Add nodes with proper attributes}
    \ControlFlowTok{for}\NormalTok{ idx, row }\KeywordTok{in}\NormalTok{ df.iterrows():}
\NormalTok{        title }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{]}
\NormalTok{        description }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{]}

        \CommentTok{\# Process probability information}
\NormalTok{        priors }\OperatorTok{=}\NormalTok{ get\_priors(row)}
\NormalTok{        instantiations }\OperatorTok{=}\NormalTok{ get\_instantiations(row)}

        \CommentTok{\# Add node with base information}
\NormalTok{        G.add\_node(}
\NormalTok{            title,}
\NormalTok{            description}\OperatorTok{=}\NormalTok{description,}
\NormalTok{            priors}\OperatorTok{=}\NormalTok{priors,}
\NormalTok{            instantiations}\OperatorTok{=}\NormalTok{instantiations,}
\NormalTok{            posteriors}\OperatorTok{=}\NormalTok{get\_posteriors(row)}
\NormalTok{        )}

    \CommentTok{\# Add edges}
    \ControlFlowTok{for}\NormalTok{ idx, row }\KeywordTok{in}\NormalTok{ df.iterrows():}
\NormalTok{        child }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{]}
\NormalTok{        parents }\OperatorTok{=}\NormalTok{ get\_parents(row)}

        \CommentTok{\# Add edges from each parent to this child}
        \ControlFlowTok{for}\NormalTok{ parent }\KeywordTok{in}\NormalTok{ parents:}
            \ControlFlowTok{if}\NormalTok{ parent }\KeywordTok{in}\NormalTok{ G.nodes():}
\NormalTok{                G.add\_edge(parent, child)}

    \CommentTok{\# Classify nodes based on network structure}
\NormalTok{    classify\_nodes(G)}

    \CommentTok{\# Create network visualization}
\NormalTok{    net }\OperatorTok{=}\NormalTok{ Network(notebook}\OperatorTok{=}\VariableTok{True}\NormalTok{, directed}\OperatorTok{=}\VariableTok{True}\NormalTok{, cdn\_resources}\OperatorTok{=}\StringTok{"in\_line"}\NormalTok{, height}\OperatorTok{=}\StringTok{"600px"}\NormalTok{, width}\OperatorTok{=}\StringTok{"100\%"}\NormalTok{)}

    \CommentTok{\# Configure physics for better layout}
\NormalTok{    net.force\_atlas\_2based(gravity}\OperatorTok{={-}}\DecValTok{50}\NormalTok{, spring\_length}\OperatorTok{=}\DecValTok{100}\NormalTok{, spring\_strength}\OperatorTok{=}\FloatTok{0.02}\NormalTok{)}
\NormalTok{    net.show\_buttons(filter\_}\OperatorTok{=}\NormalTok{[}\StringTok{\textquotesingle{}physics\textquotesingle{}}\NormalTok{])}

    \CommentTok{\# Add the graph to the network}
\NormalTok{    net.from\_nx(G)}

    \CommentTok{\# Enhance node appearance with probability information and classification}
    \ControlFlowTok{for}\NormalTok{ node }\KeywordTok{in}\NormalTok{ net.nodes:}
\NormalTok{        node\_id }\OperatorTok{=}\NormalTok{ node[}\StringTok{\textquotesingle{}id\textquotesingle{}}\NormalTok{]}
\NormalTok{        node\_data }\OperatorTok{=}\NormalTok{ G.nodes[node\_id]}

        \CommentTok{\# Get node type and set border color}
\NormalTok{        node\_type }\OperatorTok{=}\NormalTok{ node\_data.get(}\StringTok{\textquotesingle{}node\_type\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}unknown\textquotesingle{}}\NormalTok{)}
\NormalTok{        border\_color }\OperatorTok{=}\NormalTok{ get\_border\_color(node\_type)}

        \CommentTok{\# Get probability information}
\NormalTok{        priors }\OperatorTok{=}\NormalTok{ node\_data.get(}\StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{, \{\})}
\NormalTok{        true\_prob }\OperatorTok{=}\NormalTok{ priors.get(}\StringTok{\textquotesingle{}true\_prob\textquotesingle{}}\NormalTok{, }\FloatTok{0.5}\NormalTok{) }\ControlFlowTok{if}\NormalTok{ priors }\ControlFlowTok{else} \FloatTok{0.5}

        \CommentTok{\# Get proper state names}
\NormalTok{        instantiations }\OperatorTok{=}\NormalTok{ node\_data.get(}\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{, [}\StringTok{"TRUE"}\NormalTok{, }\StringTok{"FALSE"}\NormalTok{])}
\NormalTok{        true\_state }\OperatorTok{=}\NormalTok{ instantiations[}\DecValTok{0}\NormalTok{] }\ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(instantiations) }\OperatorTok{\textgreater{}} \DecValTok{0} \ControlFlowTok{else} \StringTok{"TRUE"}
\NormalTok{        false\_state }\OperatorTok{=}\NormalTok{ instantiations[}\DecValTok{1}\NormalTok{] }\ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(instantiations) }\OperatorTok{\textgreater{}} \DecValTok{1} \ControlFlowTok{else} \StringTok{"FALSE"}

        \CommentTok{\# Create background color based on probability}
\NormalTok{        background\_color }\OperatorTok{=}\NormalTok{ get\_probability\_color(priors)}

        \CommentTok{\# Create tooltip with probability information}
\NormalTok{        tooltip }\OperatorTok{=}\NormalTok{ create\_tooltip(node\_id, node\_data)}

        \CommentTok{\# Create a simpler node label with probability}
\NormalTok{        simple\_label }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{node\_id}\SpecialCharTok{\}}\CharTok{\textbackslash{}n}\SpecialStringTok{p=}\SpecialCharTok{\{}\NormalTok{true\_prob}\SpecialCharTok{:.2f\}}\SpecialStringTok{"}

        \CommentTok{\# Store expanded content as a node attribute for use in click handler}
\NormalTok{        node\_data[}\StringTok{\textquotesingle{}expanded\_content\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ create\_expanded\_content(node\_id, node\_data)}

        \CommentTok{\# Set node attributes}
\NormalTok{        node[}\StringTok{\textquotesingle{}title\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ tooltip  }\CommentTok{\# Tooltip HTML}
\NormalTok{        node[}\StringTok{\textquotesingle{}label\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ simple\_label  }\CommentTok{\# Simple text label}
\NormalTok{        node[}\StringTok{\textquotesingle{}shape\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \StringTok{\textquotesingle{}box\textquotesingle{}}
\NormalTok{        node[}\StringTok{\textquotesingle{}color\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ \{}
            \StringTok{\textquotesingle{}background\textquotesingle{}}\NormalTok{: background\_color,}
            \StringTok{\textquotesingle{}border\textquotesingle{}}\NormalTok{: border\_color,}
            \StringTok{\textquotesingle{}highlight\textquotesingle{}}\NormalTok{: \{}
                \StringTok{\textquotesingle{}background\textquotesingle{}}\NormalTok{: background\_color,}
                \StringTok{\textquotesingle{}border\textquotesingle{}}\NormalTok{: border\_color}
\NormalTok{            \}}
\NormalTok{        \}}

    \CommentTok{\# Set up the click handler with proper data}
\NormalTok{    setup\_data }\OperatorTok{=}\NormalTok{ \{}
        \StringTok{\textquotesingle{}nodes\_data\textquotesingle{}}\NormalTok{: \{node\_id: \{}
            \StringTok{\textquotesingle{}expanded\_content\textquotesingle{}}\NormalTok{: json.dumps(G.nodes[node\_id].get(}\StringTok{\textquotesingle{}expanded\_content\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{)),}
            \StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{: G.nodes[node\_id].get(}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
            \StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{: G.nodes[node\_id].get(}\StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{, \{\}),}
            \StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{: G.nodes[node\_id].get(}\StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{, \{\})}
\NormalTok{        \} }\ControlFlowTok{for}\NormalTok{ node\_id }\KeywordTok{in}\NormalTok{ G.nodes()\}}
\NormalTok{    \}}

    \CommentTok{\# Add custom click handling JavaScript}
\NormalTok{    click\_js }\OperatorTok{=} \StringTok{"""}
\StringTok{    // Store node data for click handling}
\StringTok{    var nodesData = }\SpecialCharTok{\%s}\StringTok{;}

\StringTok{    // Add event listener for node clicks}
\StringTok{    network.on("click", function(params) \{}
\StringTok{        if (params.nodes.length \textgreater{} 0) \{}
\StringTok{            var nodeId = params.nodes[0];}
\StringTok{            var nodeInfo = nodesData[nodeId];}

\StringTok{            if (nodeInfo) \{}
\StringTok{                // Create a modal popup for expanded content}
\StringTok{                var modal = document.createElement(\textquotesingle{}div\textquotesingle{});}
\StringTok{                modal.style.position = \textquotesingle{}fixed\textquotesingle{};}
\StringTok{                modal.style.left = \textquotesingle{}50}\SpecialCharTok{\%\%}\StringTok{\textquotesingle{};}
\StringTok{                modal.style.top = \textquotesingle{}50}\SpecialCharTok{\%\%}\StringTok{\textquotesingle{};}
\StringTok{                modal.style.transform = \textquotesingle{}translate({-}50}\SpecialCharTok{\%\%}\StringTok{, {-}50}\SpecialCharTok{\%\%}\StringTok{)\textquotesingle{};}
\StringTok{                modal.style.backgroundColor = \textquotesingle{}white\textquotesingle{};}
\StringTok{                modal.style.padding = \textquotesingle{}20px\textquotesingle{};}
\StringTok{                modal.style.borderRadius = \textquotesingle{}5px\textquotesingle{};}
\StringTok{                modal.style.boxShadow = \textquotesingle{}0 0 10px rgba(0,0,0,0.5)\textquotesingle{};}
\StringTok{                modal.style.zIndex = \textquotesingle{}1000\textquotesingle{};}
\StringTok{                modal.style.maxWidth = \textquotesingle{}80}\SpecialCharTok{\%\%}\StringTok{\textquotesingle{};}
\StringTok{                modal.style.maxHeight = \textquotesingle{}80}\SpecialCharTok{\%\%}\StringTok{\textquotesingle{};}
\StringTok{                modal.style.overflow = \textquotesingle{}auto\textquotesingle{};}

\StringTok{                // Parse the JSON string back to HTML content}
\StringTok{                try \{}
\StringTok{                    var expandedContent = JSON.parse(nodeInfo.expanded\_content);}
\StringTok{                    modal.innerHTML = expandedContent;}
\StringTok{                \} catch (e) \{}
\StringTok{                    modal.innerHTML = \textquotesingle{}Error displaying content: \textquotesingle{} + e.message;}
\StringTok{                \}}

\StringTok{                // Add close button}
\StringTok{                var closeBtn = document.createElement(\textquotesingle{}button\textquotesingle{});}
\StringTok{                closeBtn.innerHTML = \textquotesingle{}Close\textquotesingle{};}
\StringTok{                closeBtn.style.marginTop = \textquotesingle{}10px\textquotesingle{};}
\StringTok{                closeBtn.style.padding = \textquotesingle{}5px 10px\textquotesingle{};}
\StringTok{                closeBtn.style.cursor = \textquotesingle{}pointer\textquotesingle{};}
\StringTok{                closeBtn.onclick = function() \{}
\StringTok{                    document.body.removeChild(modal);}
\StringTok{                \};}
\StringTok{                modal.appendChild(closeBtn);}

\StringTok{                // Add modal to body}
\StringTok{                document.body.appendChild(modal);}
\StringTok{            \}}
\StringTok{        \}}
\StringTok{    \});}
\StringTok{    """} \OperatorTok{\%}\NormalTok{ json.dumps(setup\_data[}\StringTok{\textquotesingle{}nodes\_data\textquotesingle{}}\NormalTok{])}

    \CommentTok{\# Save the graph to HTML}
\NormalTok{    html\_file }\OperatorTok{=} \StringTok{"bayesian\_network.html"}
\NormalTok{    net.save\_graph(html\_file)}

    \CommentTok{\# Inject custom click handling into HTML}
    \ControlFlowTok{try}\NormalTok{:}
        \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(html\_file, }\StringTok{"r"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{            html\_content }\OperatorTok{=}\NormalTok{ f.read()}

        \CommentTok{\# Insert click handling script before the closing body tag}
\NormalTok{        html\_content }\OperatorTok{=}\NormalTok{ html\_content.replace(}\StringTok{\textquotesingle{}\textless{}/body\textgreater{}\textquotesingle{}}\NormalTok{, }\SpecialStringTok{f\textquotesingle{}\textless{}script\textgreater{}}\SpecialCharTok{\{}\NormalTok{click\_js}\SpecialCharTok{\}}\SpecialStringTok{\textless{}/script\textgreater{}\textless{}/body\textgreater{}\textquotesingle{}}\NormalTok{)}

        \CommentTok{\# Write back the modified HTML}
        \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(html\_file, }\StringTok{"w"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{            f.write(html\_content)}

        \ControlFlowTok{return}\NormalTok{ HTML(html\_content)}
    \ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
        \ControlFlowTok{return}\NormalTok{ HTML(}\SpecialStringTok{f"\textless{}p\textgreater{}Error rendering HTML: }\SpecialCharTok{\{}\BuiltInTok{str}\NormalTok{(e)}\SpecialCharTok{\}}\SpecialStringTok{\textless{}/p\textgreater{}"}
        \OperatorTok{+} \StringTok{"\textless{}p\textgreater{}The network visualization has been saved to \textquotesingle{}}\SpecialCharTok{\{html\_file\}}\StringTok{\textquotesingle{}\textless{}/p\textgreater{}"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\chapter{5 Quick check HTML Outputs}\label{quick-check-html-outputs}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 5.0 {-}{-}{-} Quick check HTML Outputs{-}{-}{-} [html\_graph\_visualization]}

\NormalTok{create\_bayesian\_network\_with\_probabilities(result\_df)}
\end{Highlighting}
\end{Shaded}

\phantomsection\label{html_graph_visualization}
Quick check HTML Outputs

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Use the function to create and display the visualization}

\BuiltInTok{print}\NormalTok{(result\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                          Title  \
0       Existential_Catastrophe   
1          Human_Disempowerment   
2        Scale_Of_Power_Seeking   
3      Misaligned_Power_Seeking   
4                   APS_Systems   
5        Advanced_AI_Capability   
6              Agentic_Planning   
7           Strategic_Awareness   
8       Difficulty_Of_Alignment   
9      Instrumental_Convergence   
10        Problems_With_Proxies   
11         Problems_With_Search   
12         Deployment_Decisions   
13      Incentives_To_Build_APS   
14            Usefulness_Of_APS   
15         Competitive_Dynamics   
16              Deception_By_AI   
17          Corrective_Feedback   
18                Warning_Shots   
19  Rapid_Capability_Escalation   
20    Barriers_To_Understanding   
21         Adversarial_Dynamics   
22              Stakes_Of_Error   

                                          Description  line     line_numbers  \
0   The destruction of humanity's long-term potent...     0              [0]   
1   Permanent and collective disempowerment of hum...     1              [1]   
2   Power-seeking by AI systems scaling to the poi...     2              [2]   
3   Deployed AI systems seeking power in unintende...     3  [3, 21, 23, 25]   
4   AI systems with advanced capabilities, agentic...     4              [4]   
5   AI systems that outperform humans on tasks tha...     5              [5]   
6   AI systems making and executing plans based on...     6              [6]   
7   AI systems with models accurately representing...     7              [7]   
8   It is harder to build aligned systems than mis...     8              [8]   
9   AI systems with misaligned objectives tend to ...     9              [9]   
10  Optimizing for proxy objectives breaks correla...    10             [10]   
11  Search processes can yield systems pursuing di...    11             [11]   
12  Decisions to deploy potentially misaligned AI ...    12             [12]   
13  Strong incentives to build and deploy APS syst...    13             [13]   
14  APS systems are very useful for many valuable ...    14             [14]   
15       Competitive pressures between AI developers.    15             [15]   
16  AI systems deceiving humans about their true o...    16             [16]   
17  Human society implementing corrections after o...    17             [17]   
18  Observable failures in weaker systems before c...    18             [18]   
19  AI capabilities escalating very rapidly, allow...    19             [19]   
20  Difficulty in understanding the internal worki...    20             [20]   
21  Potentially adversarial relationships between ...    22             [22]   
22  The escalating impact of mistakes with power-s...    24             [24]   

    indentation indentation_levels  \
0             0                [0]   
1             0                [0]   
2             4                [4]   
3             8       [8, 0, 0, 0]   
4            12               [12]   
5            16               [16]   
6            16               [16]   
7            16               [16]   
8            12               [12]   
9            16               [16]   
10           16               [16]   
11           16               [16]   
12           12               [12]   
13           16               [16]   
14           20               [20]   
15           20               [20]   
16           16               [16]   
17            8                [8]   
18           12               [12]   
19           12               [12]   
20            0                [0]   
21            0                [0]   
22            0                [0]   

                                              Parents  \
0                                                  []   
1                            [Scale_Of_Power_Seeking]   
2     [Misaligned_Power_Seeking, Corrective_Feedback]   
3   [APS_Systems, Difficulty_Of_Alignment, Deploym...   
4   [Advanced_AI_Capability, Agentic_Planning, Str...   
5                                                  []   
6                                                  []   
7                                                  []   
8   [Instrumental_Convergence, Problems_With_Proxi...   
9                                                  []   
10                                                 []   
11                                                 []   
12         [Incentives_To_Build_APS, Deception_By_AI]   
13          [Usefulness_Of_APS, Competitive_Dynamics]   
14                                                 []   
15                                                 []   
16                                                 []   
17       [Warning_Shots, Rapid_Capability_Escalation]   
18                                                 []   
19                                                 []   
20                                                 []   
21                                                 []   
22                                                 []   

                      Children  \
0                           []   
1                           []   
2       [Human_Disempowerment]   
3     [Scale_Of_Power_Seeking]   
4   [Misaligned_Power_Seeking]   
5                [APS_Systems]   
6                [APS_Systems]   
7                [APS_Systems]   
8   [Misaligned_Power_Seeking]   
9    [Difficulty_Of_Alignment]   
10   [Difficulty_Of_Alignment]   
11   [Difficulty_Of_Alignment]   
12  [Misaligned_Power_Seeking]   
13      [Deployment_Decisions]   
14   [Incentives_To_Build_APS]   
15   [Incentives_To_Build_APS]   
16      [Deployment_Decisions]   
17    [Scale_Of_Power_Seeking]   
18       [Corrective_Feedback]   
19       [Corrective_Feedback]   
20                          []   
21                          []   
22                          []   

                                       instantiations  \
0   [existential_catastrophe_TRUE, existential_cat...   
1   [human_disempowerment_TRUE, human_disempowerme...   
2   [scale_of_power_seeking_TRUE, scale_of_power_s...   
3   [misaligned_power_seeking_TRUE, misaligned_pow...   
4               [aps_systems_TRUE, aps_systems_FALSE]   
5   [advanced_ai_capability_TRUE, advanced_ai_capa...   
6     [agentic_planning_TRUE, agentic_planning_FALSE]   
7   [strategic_awareness_TRUE, strategic_awareness...   
8   [difficulty_of_alignment_TRUE, difficulty_of_a...   
9   [instrumental_convergence_TRUE, instrumental_c...   
10  [problems_with_proxies_TRUE, problems_with_pro...   
11  [problems_with_search_TRUE, problems_with_sear...   
12  [deployment_decisions_DEPLOY, deployment_decis...   
13  [incentives_to_build_aps_STRONG, incentives_to...   
14    [usefulness_of_aps_HIGH, usefulness_of_aps_LOW]   
15  [competitive_dynamics_STRONG, competitive_dyna...   
16      [deception_by_ai_TRUE, deception_by_ai_FALSE]   
17  [corrective_feedback_EFFECTIVE, corrective_fee...   
18  [warning_shots_OBSERVED, warning_shots_UNOBSER...   
19  [rapid_capability_escalation_TRUE, rapid_capab...   
20  [barriers_to_understanding_HIGH, barriers_to_u...   
21  [adversarial_dynamics_TRUE, adversarial_dynami...   
22        [stakes_of_error_HIGH, stakes_of_error_LOW]   

                                               priors  \
0   {'p(existential_catastrophe_TRUE)': '0.05', 'p...   
1   {'p(human_disempowerment_TRUE)': '0.208', 'p(h...   
2   {'p(scale_of_power_seeking_TRUE)': '0.208', 'p...   
3   {'p(misaligned_power_seeking_TRUE)': '0.338', ...   
4   {'p(aps_systems_TRUE)': '0.65', 'p(aps_systems...   
5   {'p(advanced_ai_capability_TRUE)': '0.80', 'p(...   
6   {'p(agentic_planning_TRUE)': '0.85', 'p(agenti...   
7   {'p(strategic_awareness_TRUE)': '0.75', 'p(str...   
8   {'p(difficulty_of_alignment_TRUE)': '0.40', 'p...   
9   {'p(instrumental_convergence_TRUE)': '0.75', '...   
10  {'p(problems_with_proxies_TRUE)': '0.80', 'p(p...   
11  {'p(problems_with_search_TRUE)': '0.70', 'p(pr...   
12  {'p(deployment_decisions_DEPLOY)': '0.70', 'p(...   
13  {'p(incentives_to_build_aps_STRONG)': '0.80', ...   
14  {'p(usefulness_of_aps_HIGH)': '0.85', 'p(usefu...   
15  {'p(competitive_dynamics_STRONG)': '0.75', 'p(...   
16  {'p(deception_by_ai_TRUE)': '0.50', 'p(decepti...   
17  {'p(corrective_feedback_EFFECTIVE)': '0.60', '...   
18  {'p(warning_shots_OBSERVED)': '0.70', 'p(warni...   
19  {'p(rapid_capability_escalation_TRUE)': '0.45'...   
20  {'p(barriers_to_understanding_HIGH)': '0.70', ...   
21  {'p(adversarial_dynamics_TRUE)': '0.60', 'p(ad...   
22  {'p(stakes_of_error_HIGH)': '0.85', 'p(stakes_...   

                                           posteriors  No_Parent  No_Children  \
0   {'p(existential_catastrophe_TRUE|human_disempo...       True         True   
1   {'p(human_disempowerment_TRUE|scale_of_power_s...      False         True   
2   {'p(scale_of_power_seeking_TRUE|misaligned_pow...      False        False   
3   {'p(misaligned_power_seeking_TRUE|aps_systems_...      False        False   
4   {'p(aps_systems_TRUE|advanced_ai_capability_TR...      False        False   
5                                                  {}       True        False   
6                                                  {}       True        False   
7                                                  {}       True        False   
8   {'p(difficulty_of_alignment_TRUE|instrumental_...      False        False   
9                                                  {}       True        False   
10                                                 {}       True        False   
11                                                 {}       True        False   
12  {'p(deployment_decisions_DEPLOY|incentives_to_...      False        False   
13  {'p(incentives_to_build_aps_STRONG|usefulness_...      False        False   
14                                                 {}       True        False   
15                                                 {}       True        False   
16                                                 {}       True        False   
17  {'p(corrective_feedback_EFFECTIVE|warning_shot...      False        False   
18                                                 {}       True        False   
19                                                 {}       True        False   
20  {'p(barriers_to_understanding_HIGH|misaligned_...       True         True   
21  {'p(adversarial_dynamics_TRUE|misaligned_power...       True         True   
22  {'p(stakes_of_error_HIGH|misaligned_power_seek...       True         True   

                                parent_instantiations  
0                                                  []  
1   [[scale_of_power_seeking_TRUE, scale_of_power_...  
2   [[misaligned_power_seeking_TRUE, misaligned_po...  
3   [[aps_systems_TRUE, aps_systems_FALSE], [diffi...  
4   [[advanced_ai_capability_TRUE, advanced_ai_cap...  
5                                                  []  
6                                                  []  
7                                                  []  
8   [[instrumental_convergence_TRUE, instrumental_...  
9                                                  []  
10                                                 []  
11                                                 []  
12  [[incentives_to_build_aps_STRONG, incentives_t...  
13  [[usefulness_of_aps_HIGH, usefulness_of_aps_LO...  
14                                                 []  
15                                                 []  
16                                                 []  
17  [[warning_shots_OBSERVED, warning_shots_UNOBSE...  
18                                                 []  
19                                                 []  
20                                                 []  
21                                                 []  
22                                                 []  
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 5.1 {-}{-}{-} File Import {-}{-}{-} Load Files [file\_import]}

\ImportTok{import}\NormalTok{ requests}
\ImportTok{import}\NormalTok{ io}
\ImportTok{from}\NormalTok{ IPython.display }\ImportTok{import}\NormalTok{ HTML, display}

\KeywordTok{def}\NormalTok{ load\_and\_display\_html\_from\_github(repo\_url, relative\_path):}
    \CommentTok{"""}
\CommentTok{    Loads an HTML file from a public GitHub repository and displays it.}

\CommentTok{    Args:}
\CommentTok{        repo\_url (str): The base URL of the GitHub repository (raw content).}
\CommentTok{        relative\_path (str): The path to the HTML file relative to the repo\_url.}
\CommentTok{    """}
\NormalTok{    file\_url }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{repo\_url}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{relative\_path}\SpecialCharTok{\}}\SpecialStringTok{"}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Attempting to load HTML from: }\SpecialCharTok{\{}\NormalTok{file\_url}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

    \ControlFlowTok{try}\NormalTok{:}
        \CommentTok{\# Fetch the file content from GitHub}
\NormalTok{        response }\OperatorTok{=}\NormalTok{ requests.get(file\_url)}

        \CommentTok{\# Check for successful response}
\NormalTok{        response.raise\_for\_status()}

        \CommentTok{\# Read the content}
\NormalTok{        html\_content }\OperatorTok{=}\NormalTok{ io.StringIO(response.text).read()}

        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"✅ Successfully loaded }\SpecialCharTok{\{}\NormalTok{relative\_path}\SpecialCharTok{\}}\SpecialStringTok{."}\NormalTok{)}

        \CommentTok{\# Render the HTML content directly in the notebook}
\NormalTok{        display(HTML(html\_content))}

    \ControlFlowTok{except}\NormalTok{ requests.exceptions.RequestException }\ImportTok{as}\NormalTok{ e:}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"❌ Error loading HTML file: }\SpecialCharTok{\{}\NormalTok{e}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
        \BuiltInTok{print}\NormalTok{(}\StringTok{"Please check the URL and your internet connection."}\NormalTok{)}
    \ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"❌ An unexpected error occurred: }\SpecialCharTok{\{}\NormalTok{e}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

\CommentTok{\# Specify the base repository URL and the relative path to the HTML file}
\NormalTok{repo\_base\_url }\OperatorTok{=} \StringTok{"https://raw.githubusercontent.com/SingularitySmith/AMTAIR\_Prototype/main/data/example\_carlsmith"}
\NormalTok{html\_relative\_path }\OperatorTok{=} \StringTok{"runtime\_created\_data/bayesian\_network.html"}

\CommentTok{\# Load and display the HTML file}
\NormalTok{load\_and\_display\_html\_from\_github(repo\_base\_url, html\_relative\_path)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Attempting to load HTML from: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/runtime_created_data/bayesian_network.html
✅ Successfully loaded runtime_created_data/bayesian_network.html.
\end{verbatim}

\phantomsection\label{file_import}
File Import

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 5.2 {-}{-}{-} File Import {-}{-}{-} Load Files [file\_import2]}

\ImportTok{import}\NormalTok{ requests}
\ImportTok{import}\NormalTok{ io}
\ImportTok{from}\NormalTok{ IPython.display }\ImportTok{import}\NormalTok{ HTML, display}

\KeywordTok{def}\NormalTok{ load\_and\_display\_html\_from\_github(repo\_url, relative\_path):}
    \CommentTok{"""}
\CommentTok{    Loads an HTML file from a public GitHub repository and displays it.}

\CommentTok{    Args:}
\CommentTok{        repo\_url (str): The base URL of the GitHub repository (raw content).}
\CommentTok{        relative\_path (str): The path to the HTML file relative to the repo\_url.}
\CommentTok{    """}
\NormalTok{    file\_url }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{repo\_url}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{relative\_path}\SpecialCharTok{\}}\SpecialStringTok{"}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Attempting to load HTML from: }\SpecialCharTok{\{}\NormalTok{file\_url}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

    \ControlFlowTok{try}\NormalTok{:}
        \CommentTok{\# Fetch the file content from GitHub}
\NormalTok{        response }\OperatorTok{=}\NormalTok{ requests.get(file\_url)}

        \CommentTok{\# Check for successful response}
\NormalTok{        response.raise\_for\_status()}

        \CommentTok{\# Read the content}
\NormalTok{        html\_content }\OperatorTok{=}\NormalTok{ io.StringIO(response.text).read()}

        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"✅ Successfully loaded }\SpecialCharTok{\{}\NormalTok{relative\_path}\SpecialCharTok{\}}\SpecialStringTok{."}\NormalTok{)}

        \CommentTok{\# Render the HTML content directly in the notebook}
\NormalTok{        display(HTML(html\_content))}

    \ControlFlowTok{except}\NormalTok{ requests.exceptions.RequestException }\ImportTok{as}\NormalTok{ e:}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"❌ Error loading HTML file: }\SpecialCharTok{\{}\NormalTok{e}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
        \BuiltInTok{print}\NormalTok{(}\StringTok{"Please check the URL and your internet connection."}\NormalTok{)}
    \ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"❌ An unexpected error occurred: }\SpecialCharTok{\{}\NormalTok{e}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

\CommentTok{\# Specify the base repository URL and the relative path to the HTML file}
\NormalTok{repo\_base\_url }\OperatorTok{=} \StringTok{"https://raw.githubusercontent.com/VJMeyer/submission/refs/heads/main/AMTAIR\_Prototype/data/example\_carlsmith/"}
\NormalTok{html\_relative\_path }\OperatorTok{=} \StringTok{"runtime\_created\_data/bayesian\_network.html"}

\CommentTok{\# Load and display the HTML file}
\NormalTok{load\_and\_display\_html\_from\_github(repo\_base\_url, html\_relative\_path)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Attempting to load HTML from: https://raw.githubusercontent.com/VJMeyer/submission/refs/heads/main/AMTAIR_Prototype/data/example_carlsmith//runtime_created_data/bayesian_network.html
✅ Successfully loaded runtime_created_data/bayesian_network.html.
\end{verbatim}

\phantomsection\label{file_import2}
File Import 2

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ IPython.display }\ImportTok{import}\NormalTok{ IFrame}

\NormalTok{IFrame(src}\OperatorTok{=}\StringTok{"https://singularitysmith.github.io/AMTAIR\_Prototype/bayesian\_network\_carlsmith.html"}\NormalTok{, width}\OperatorTok{=}\StringTok{"100\%"}\NormalTok{, height}\OperatorTok{=}\StringTok{"600px"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\phantomsection\label{html_graph_visualization_from_githubpage}
\begin{verbatim}
<IPython.lib.display.IFrame at 0x7f04d69f0d90>
\end{verbatim}

Dynamic Html Rendering of the Carlsmith Bayesian Network/DAG
Visualization

\chapter{Conclusion: From Prototype to
Production}\label{conclusion-from-prototype-to-production}

\section{Summary of Achievements}\label{summary-of-achievements}

This notebook has successfully demonstrated the core AMTAIR extraction
pipeline, transforming structured argument representations into
interactive Bayesian network visualizations through the following steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Environment Setup}: Established a reproducible environment
  with necessary libraries and data access
\item
  \textbf{Argument Extraction}: Processed structured ArgDown
  representations preserving the hierarchical relationships
\item
  \textbf{Probability Integration}: Enhanced arguments with probability
  information to create BayesDown
\item
  \textbf{Data Transformation}: Converted BayesDown into structured
  DataFrame representation
\item
  \textbf{Visualization \& Analysis}: Created interactive Bayesian
  network visualizations with probability encoding
\end{enumerate}

The rain-sprinkler-lawn example, though simple, demonstrates all the key
components of the extraction pipeline that can be applied to more
complex AI safety arguments.

\section{Limitations and Future Work}\label{limitations-and-future-work}

While this prototype successfully demonstrates the core pipeline,
several limitations and opportunities for future work remain:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{LLM Extraction}: The current implementation focuses on
  processing pre-formatted ArgDown rather than performing extraction
  directly from unstructured text. Future work will integrate
  LLM-powered extraction.
\item
  \textbf{Scalability}: The system has been tested on small examples;
  scaling to larger, more complex arguments will require additional
  optimization and handling of computational complexity.
\item
  \textbf{Policy Evaluation}: The current implementation focuses on
  representation and visualization; future work will add policy
  evaluation capabilities by implementing intervention modeling.
\item
  \textbf{Prediction Market Integration}: Future versions will integrate
  with forecasting platforms to incorporate live data into the models.
\end{enumerate}

\section{Connection to AMTAIR
Project}\label{connection-to-amtair-project}

This prototype represents just one component of the broader AMTAIR
project described in the project documentation (see
PY\_AMTAIRDescription and PY\_AMTAIR\_SoftwareToolsNMilestones). The
full project includes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{AI Risk Pathway Analyzer (ARPA)}: The core extraction and
  visualization system demonstrated in this notebook
\item
  \textbf{Worldview Comparator}: Tools for comparing different
  perspectives on AI risk
\item
  \textbf{Policy Impact Evaluator}: Systems for evaluating intervention
  effects across scenarios
\item
  \textbf{Strategic Intervention Generator}: Tools for identifying
  robust governance strategies
\end{enumerate}

Together, these components aim to address the coordination crisis in AI
governance by providing computational tools that make implicit models
explicit, identify cruxes of disagreement, and evaluate policy impacts
across diverse worldviews.

By transforming unstructured text into formal, analyzable
representations, the AMTAIR project helps bridge the gaps between
technical researchers, policy specialists, and other stakeholders,
enabling more effective coordination in addressing existential risks
from advanced AI.

\chapter{6 Save Outputs}\label{save-outputs}

\section{6.0 Saving and Exporting
Results}\label{saving-and-exporting-results}

This section provides tools for saving the notebook results and
visualizations in various formats:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{HTML Export}: Creates a self-contained HTML version of the
  notebook with all visualizations
\item
  \textbf{Markdown Export}: Generates documentation-friendly Markdown
  version of the notebook
\item
  \textbf{PDF Export}: Creates a PDF document for formal sharing
  (requires LaTeX installation)
\end{enumerate}

These exports are essential for: - Sharing analysis results with
colleagues and stakeholders - Including visualizations in presentations
and reports - Creating documentation for the AMTAIR project - Preserving
results for future reference

The different formats serve different purposes, from interactive
exploration (HTML) to documentation (Markdown) to formal presentation
(PDF).

Instruction:

Download the ipynb, which you want to convert, on your local computer.
Run the code below to upload the ipynb.

The html version will be downloaded automatically on your local machine.
Enjoy it!

\phantomsection\label{save_visualization_and_notebook_outputs_as_html}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 6.0.0 {-}{-}{-} Save Visualization and Notebook Outputs as .HTML{-}{-}{-} [save\_visualization\_and\_notebook\_outputs\_as\_html]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Provides tools for saving the notebook results in various formats.}

\CommentTok{This block offers functions to:}
\CommentTok{1. Convert the notebook to HTML for easy sharing and viewing}
\CommentTok{2. Convert the notebook to Markdown for documentation purposes}
\CommentTok{3. Save the visualization outputs for external use}

\CommentTok{These tools are essential for preserving the analysis results and making them}
\CommentTok{accessible outside the notebook environment, supporting knowledge transfer}
\CommentTok{and integration with other AMTAIR project components.}

\CommentTok{DEPENDENCIES: nbformat, nbconvert modules}
\CommentTok{INPUTS: Current notebook state}
\CommentTok{OUTPUTS: HTML, Markdown, or other format versions of the notebook}
\CommentTok{"""}

\ImportTok{import}\NormalTok{ nbformat}
\ImportTok{from}\NormalTok{ nbconvert }\ImportTok{import}\NormalTok{ HTMLExporter}
\ImportTok{import}\NormalTok{ os}

\CommentTok{\# Repository URL variable for file access}
\NormalTok{repo\_url }\OperatorTok{=} \StringTok{"https://raw.githubusercontent.com/SingularitySmith/AMTAIR\_Prototype/main/data/example\_carlsmith/"}
\NormalTok{notebook\_name }\OperatorTok{=} \StringTok{"AMTAIR\_Prototype\_example\_carlsmith"}  \CommentTok{\# Change when working with different examples}

\CommentTok{\# Download the notebook file}
\OperatorTok{!}\NormalTok{wget \{repo\_url\}\{notebook\_name\}.ipynb }\OperatorTok{{-}}\NormalTok{O \{notebook\_name\}.ipynb}

\CommentTok{\# Load the notebook}
\ControlFlowTok{try}\NormalTok{:}
  \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{notebook\_name}\SpecialCharTok{\}}\SpecialStringTok{.ipynb"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    nb }\OperatorTok{=}\NormalTok{ nbformat.read(f, as\_version}\OperatorTok{=}\DecValTok{4}\NormalTok{)}
  \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"✅ Successfully loaded notebook: }\SpecialCharTok{\{}\NormalTok{notebook\_name}\SpecialCharTok{\}}\SpecialStringTok{.ipynb"}\NormalTok{)}
\ControlFlowTok{except} \PreprocessorTok{FileNotFoundError}\NormalTok{:}
  \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"❌ Error: File \textquotesingle{}}\SpecialCharTok{\{}\NormalTok{notebook\_name}\SpecialCharTok{\}}\SpecialStringTok{.ipynb\textquotesingle{} not found. Please check if it was downloaded correctly."}\NormalTok{)}

\CommentTok{\# Initialize the HTML exporter}
\NormalTok{exporter }\OperatorTok{=}\NormalTok{ HTMLExporter()}

\CommentTok{\# Convert the notebook to HTML}
\ControlFlowTok{try}\NormalTok{:}
\NormalTok{    (body, resources) }\OperatorTok{=}\NormalTok{ exporter.from\_notebook\_node(nb)}

    \CommentTok{\# Save the HTML to a file}
    \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{notebook\_name}\SpecialCharTok{\}}\SpecialStringTok{IPYNB.html"}\NormalTok{, }\StringTok{"w"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{        f.write(body)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"✅ Successfully saved HTML version to: }\SpecialCharTok{\{}\NormalTok{notebook\_name}\SpecialCharTok{\}}\SpecialStringTok{IPYNB.html"}\NormalTok{)}
\ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"❌ Error converting notebook to HTML: }\SpecialCharTok{\{}\BuiltInTok{str}\NormalTok{(e)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
--2025-05-24 20:09:38--  https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1689816 (1.6M) [text/plain]
Saving to: ‘AMTAIR_Prototype_example_carlsmith.ipynb’

AMTAIR_Prototype_ex 100%[===================>]   1.61M  6.36MB/s    in 0.3s    

2025-05-24 20:09:38 (6.36 MB/s) - ‘AMTAIR_Prototype_example_carlsmith.ipynb’ saved [1689816/1689816]

✅ Successfully loaded notebook: AMTAIR_Prototype_example_carlsmith.ipynb
✅ Successfully saved HTML version to: AMTAIR_Prototype_example_carlsmithIPYNB.html
\end{verbatim}

\section{6.1 Convert .ipynb Notebook to
MarkDown}\label{convert-.ipynb-notebook-to-markdown}

\phantomsection\label{convert_notebook_to_markdown}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 6.1.0 {-}{-}{-} Convert .ipynb Notebook to MarkDown {-}{-}{-} [convert\_notebook\_to\_markdown]}

\ImportTok{import}\NormalTok{ nbformat}
\ImportTok{from}\NormalTok{ nbconvert }\ImportTok{import}\NormalTok{ MarkdownExporter}
\ImportTok{import}\NormalTok{ os}

\CommentTok{\# repo\_url = "https://raw.githubusercontent.com/SingularitySmith/AMTAIR\_Prototype/main/data/example\_1/"}
\NormalTok{notebook\_name }\OperatorTok{=} \StringTok{"AMTAIR\_Prototype\_example\_carlsmith"}  \CommentTok{\#Change Notebook name and path when working on different examples}

\CommentTok{\# Download the notebook file}
\OperatorTok{!}\NormalTok{wget \{repo\_url\}\{notebook\_name\}.ipynb }\OperatorTok{{-}}\NormalTok{O \{notebook\_name\}.ipynb  }\CommentTok{\# Corrected line}

\CommentTok{\# Load the notebook}
\CommentTok{\# add error handling for file not found}
\ControlFlowTok{try}\NormalTok{:}
  \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{notebook\_name}\SpecialCharTok{\}}\SpecialStringTok{.ipynb"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    nb }\OperatorTok{=}\NormalTok{ nbformat.read(f, as\_version}\OperatorTok{=}\DecValTok{4}\NormalTok{)}
\ControlFlowTok{except} \PreprocessorTok{FileNotFoundError}\NormalTok{:}
  \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Error: File \textquotesingle{}}\SpecialCharTok{\{}\NormalTok{notebook\_name}\SpecialCharTok{\}}\SpecialStringTok{.ipynb\textquotesingle{} not found. Please check if it was downloaded correctly."}\NormalTok{)}


\CommentTok{\# Initialize the Markdown exporter}
\NormalTok{exporter }\OperatorTok{=}\NormalTok{ MarkdownExporter(exclude\_output}\OperatorTok{=}\VariableTok{True}\NormalTok{)  }\CommentTok{\# Correct initialization}

\CommentTok{\# Convert the notebook to Markdown}
\NormalTok{(body, resources) }\OperatorTok{=}\NormalTok{ exporter.from\_notebook\_node(nb)}

\CommentTok{\# Save the Markdown to a file}
\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{notebook\_name}\SpecialCharTok{\}}\SpecialStringTok{IPYNB.md"}\NormalTok{, }\StringTok{"w"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    f.write(body)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
--2025-05-24 20:09:47--  https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1689816 (1.6M) [text/plain]
Saving to: ‘AMTAIR_Prototype_example_carlsmith.ipynb’

AMTAIR_Prototype_ex 100%[===================>]   1.61M  5.38MB/s    in 0.3s    

2025-05-24 20:09:48 (5.38 MB/s) - ‘AMTAIR_Prototype_example_carlsmith.ipynb’ saved [1689816/1689816]
\end{verbatim}

\section{6.2 Convert Notebook to Markdown
Documentation}\label{convert-notebook-to-markdown-documentation}

\phantomsection\label{convert_notebook_to_markdown_documentation}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 6.2.0 {-}{-}{-} Convert Notebook to Markdown Documentation {-}{-}{-} [convert\_notebook\_to\_markdown\_documentation]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Converts the notebook to Markdown format for documentation purposes.}

\CommentTok{Markdown is a lightweight markup language that is widely used for documentation}
\CommentTok{and is easily readable in both plain text and rendered formats. This conversion:}

\CommentTok{1. Preserves the structure and content of the notebook}
\CommentTok{2. Creates a format suitable for inclusion in documentation systems}
\CommentTok{3. Excludes code outputs to focus on the process and methodology}
\CommentTok{4. Supports version control and collaboration on GitHub}

\CommentTok{The resulting Markdown file can be used in project documentation, GitHub wikis,}
\CommentTok{or as a standalone reference guide to the AMTAIR extraction pipeline.}

\CommentTok{DEPENDENCIES: nbformat, nbconvert.MarkdownExporter modules}
\CommentTok{INPUTS: Current notebook state}
\CommentTok{OUTPUTS: Markdown version of the notebook}
\CommentTok{"""}

\ImportTok{import}\NormalTok{ nbformat}
\ImportTok{from}\NormalTok{ nbconvert }\ImportTok{import}\NormalTok{ MarkdownExporter}
\ImportTok{import}\NormalTok{ os}

\CommentTok{\# Repository URL variable for file access}
\CommentTok{\# repo\_url = "https://raw.githubusercontent.com/SingularitySmith/AMTAIR\_Prototype/main/data/example\_carlsmith/"}
\NormalTok{notebook\_name }\OperatorTok{=} \StringTok{"AMTAIR\_Prototype\_example\_carlsmith"}  \CommentTok{\# Change when working with different examples}

\CommentTok{\# Download the notebook file}
\OperatorTok{!}\NormalTok{wget \{repo\_url\}\{notebook\_name\}.ipynb }\OperatorTok{{-}}\NormalTok{O \{notebook\_name\}.ipynb}

\CommentTok{\# Load the notebook}
\ControlFlowTok{try}\NormalTok{:}
  \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{notebook\_name}\SpecialCharTok{\}}\SpecialStringTok{.ipynb"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    nb }\OperatorTok{=}\NormalTok{ nbformat.read(f, as\_version}\OperatorTok{=}\DecValTok{4}\NormalTok{)}
  \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"✅ Successfully loaded notebook: }\SpecialCharTok{\{}\NormalTok{notebook\_name}\SpecialCharTok{\}}\SpecialStringTok{.ipynb"}\NormalTok{)}
\ControlFlowTok{except} \PreprocessorTok{FileNotFoundError}\NormalTok{:}
  \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"❌ Error: File \textquotesingle{}}\SpecialCharTok{\{}\NormalTok{notebook\_name}\SpecialCharTok{\}}\SpecialStringTok{.ipynb\textquotesingle{} not found. Please check "}
    \OperatorTok{+} \StringTok{"if it was downloaded correctly."}\NormalTok{)}


\CommentTok{\# Initialize the Markdown exporter}
\NormalTok{exporter }\OperatorTok{=}\NormalTok{ MarkdownExporter(exclude\_output}\OperatorTok{=}\VariableTok{True}\NormalTok{)  }\CommentTok{\# Exclude outputs for cleaner documentation}

\CommentTok{\# Convert the notebook to Markdown}
\ControlFlowTok{try}\NormalTok{:}
\NormalTok{    (body, resources) }\OperatorTok{=}\NormalTok{ exporter.from\_notebook\_node(nb)}

    \CommentTok{\# Save the Markdown to a file}
    \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{notebook\_name}\SpecialCharTok{\}}\SpecialStringTok{IPYNB.md"}\NormalTok{, }\StringTok{"w"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{        f.write(body)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"✅ Successfully saved Markdown version to: }\SpecialCharTok{\{}\NormalTok{notebook\_name}\SpecialCharTok{\}}\SpecialStringTok{IPYNB.md"}\NormalTok{)}
\ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"❌ Error converting notebook to Markdown: }\SpecialCharTok{\{}\BuiltInTok{str}\NormalTok{(e)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
--2025-05-24 20:09:53--  https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1689816 (1.6M) [text/plain]
Saving to: ‘AMTAIR_Prototype_example_carlsmith.ipynb’

AMTAIR_Prototype_ex 100%[===================>]   1.61M  5.78MB/s    in 0.3s    

2025-05-24 20:09:53 (5.78 MB/s) - ‘AMTAIR_Prototype_example_carlsmith.ipynb’ saved [1689816/1689816]

✅ Successfully loaded notebook: AMTAIR_Prototype_example_carlsmith.ipynb
✅ Successfully saved Markdown version to: AMTAIR_Prototype_example_carlsmithIPYNB.md
\end{verbatim}

\section{6.3 Create PDF and Latex}\label{create-pdf-and-latex}

\phantomsection\label{pdf_and_latex}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 6.3.0 {-}{-}{-} PDF and Latex{-}{-}{-} [pdf\_and\_latex]}

\ImportTok{import}\NormalTok{ nbformat}
\ImportTok{from}\NormalTok{ nbconvert }\ImportTok{import}\NormalTok{ PDFExporter}
\ImportTok{import}\NormalTok{ os}
\ImportTok{import}\NormalTok{ subprocess}
\ImportTok{import}\NormalTok{ re}

\KeywordTok{def}\NormalTok{ escape\_latex\_special\_chars(text):}
  \CommentTok{"""Escapes special LaTeX characters in a string."""}
\NormalTok{  latex\_special\_chars }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}\&\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\%\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\#\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\_\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\{\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\}\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textasciitilde{}\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\^{}\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{\textquotesingle{}}\NormalTok{]}
\NormalTok{  replacement\_patterns }\OperatorTok{=}\NormalTok{ [}
\NormalTok{      (char, }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{\textquotesingle{}} \OperatorTok{+}\NormalTok{ char) }\ControlFlowTok{for}\NormalTok{ char }\KeywordTok{in}\NormalTok{ latex\_special\_chars}
\NormalTok{  ]}

  \CommentTok{\# Escape reserved characters}
  \ControlFlowTok{for}\NormalTok{ original, replacement }\KeywordTok{in}\NormalTok{ replacement\_patterns:}
\NormalTok{    text }\OperatorTok{=}\NormalTok{ text.replace(original, replacement) }\CommentTok{\# This is the fix}
  \ControlFlowTok{return}\NormalTok{ text}

\CommentTok{\# Function to check if a command is available}
\KeywordTok{def}\NormalTok{ is\_command\_available(command):}
    \ControlFlowTok{try}\NormalTok{:}
\NormalTok{        subprocess.run([command], capture\_output}\OperatorTok{=}\VariableTok{True}\NormalTok{, check}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
        \ControlFlowTok{return} \VariableTok{True}
    \ControlFlowTok{except}\NormalTok{ (subprocess.CalledProcessError, }\PreprocessorTok{FileNotFoundError}\NormalTok{):}
        \ControlFlowTok{return} \VariableTok{False}

\CommentTok{\# Check if xelatex is installed, and install if necessary}
\ControlFlowTok{if} \KeywordTok{not}\NormalTok{ is\_command\_available(}\StringTok{"xelatex"}\NormalTok{):}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Installing necessary TeX packages..."}\NormalTok{)}
    \OperatorTok{!}\NormalTok{apt}\OperatorTok{{-}}\NormalTok{get install }\OperatorTok{{-}}\NormalTok{y texlive}\OperatorTok{{-}}\NormalTok{xetex texlive}\OperatorTok{{-}}\NormalTok{fonts}\OperatorTok{{-}}\NormalTok{recommended texlive}\OperatorTok{{-}}\NormalTok{plain}\OperatorTok{{-}}\NormalTok{generic}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"TeX packages installed successfully."}\NormalTok{)}
\ControlFlowTok{else}\NormalTok{:}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"xelatex is already installed. Skipping installation."}\NormalTok{)}

\CommentTok{\# repo\_url = "https://raw.githubusercontent.com/SingularitySmith/AMTAIR\_Prototype/main/data/example\_1/"}
\NormalTok{notebook\_name }\OperatorTok{=} \StringTok{"AMTAIR\_Prototype\_example\_carlsmith"}  \CommentTok{\# Change Notebook name}
                                  \CommentTok{\# and path when working on different examples}

\CommentTok{\# Download the notebook file}
\OperatorTok{!}\NormalTok{wget \{repo\_url\}\{notebook\_name\}.ipynb }\OperatorTok{{-}}\NormalTok{O \{notebook\_name\}.ipynb  }\CommentTok{\# Corrected line}

\CommentTok{\# Load the notebook}
\CommentTok{\# add error handling for file not found}
\ControlFlowTok{try}\NormalTok{:}
  \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{notebook\_name}\SpecialCharTok{\}}\SpecialStringTok{.ipynb"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    nb }\OperatorTok{=}\NormalTok{ nbformat.read(f, as\_version}\OperatorTok{=}\DecValTok{4}\NormalTok{)}
\ControlFlowTok{except} \PreprocessorTok{FileNotFoundError}\NormalTok{:}
  \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Error: File \textquotesingle{}}\SpecialCharTok{\{}\NormalTok{notebook\_name}\SpecialCharTok{\}}\SpecialStringTok{.ipynb\textquotesingle{} not found. Please check if it was downloaded correctly."}\NormalTok{)}


\CommentTok{\# Initialize the PDF exporter}
\NormalTok{exporter }\OperatorTok{=}\NormalTok{ PDFExporter(exclude\_output}\OperatorTok{=}\VariableTok{True}\NormalTok{)  }\CommentTok{\# Changed to PDFExporter}

\CommentTok{\# Sanitize notebook cell titles to escape special LaTeX characters like \textquotesingle{}\&\textquotesingle{}}
\ControlFlowTok{for}\NormalTok{ cell }\KeywordTok{in}\NormalTok{ nb.cells:}
    \ControlFlowTok{if} \StringTok{\textquotesingle{}cell\_type\textquotesingle{}} \KeywordTok{in}\NormalTok{ cell }\KeywordTok{and}\NormalTok{ cell[}\StringTok{\textquotesingle{}cell\_type\textquotesingle{}}\NormalTok{] }\OperatorTok{==} \StringTok{\textquotesingle{}markdown\textquotesingle{}}\NormalTok{:}
        \ControlFlowTok{if} \StringTok{\textquotesingle{}source\textquotesingle{}} \KeywordTok{in}\NormalTok{ cell }\KeywordTok{and} \BuiltInTok{isinstance}\NormalTok{(cell[}\StringTok{\textquotesingle{}source\textquotesingle{}}\NormalTok{], }\BuiltInTok{str}\NormalTok{):}
            \CommentTok{\# Replace \textquotesingle{}\&\textquotesingle{} with \textquotesingle{}\textbackslash{}protect\&\textquotesingle{} in markdown cell titles AND CONTENT}
            \CommentTok{\# Updated to use escape\_latex\_special\_chars function}
\NormalTok{            cell[}\StringTok{\textquotesingle{}source\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ escape\_latex\_special\_chars(cell[}\StringTok{\textquotesingle{}source\textquotesingle{}}\NormalTok{])}
            \CommentTok{\# Additionally, escape special characters in headings}
\NormalTok{            cell[}\StringTok{\textquotesingle{}source\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ re.sub(}\VerbatimStringTok{r\textquotesingle{}}\KeywordTok{(}\VerbatimStringTok{\#}\OperatorTok{+}\KeywordTok{)}\DecValTok{\textbackslash{}s}\OperatorTok{*}\KeywordTok{(}\DecValTok{.}\OperatorTok{*}\KeywordTok{)}\VerbatimStringTok{\textquotesingle{}}\NormalTok{, }\KeywordTok{lambda}\NormalTok{ m: m.group(}\DecValTok{1}\NormalTok{) }\OperatorTok{+} \StringTok{\textquotesingle{} \textquotesingle{}} \OperatorTok{+}\NormalTok{ escape\_latex\_special\_chars(m.group(}\DecValTok{2}\NormalTok{)), cell[}\StringTok{\textquotesingle{}source\textquotesingle{}}\NormalTok{])}



\CommentTok{\# Convert the notebook to PDF}
\NormalTok{(body, resources) }\OperatorTok{=}\NormalTok{ exporter.from\_notebook\_node(nb)}


\CommentTok{\# Save the PDF to a file}
\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{notebook\_name}\SpecialCharTok{\}}\SpecialStringTok{IPYNB.pdf"}\NormalTok{, }\StringTok{"wb"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:  }\CommentTok{\# Changed to \textquotesingle{}wb\textquotesingle{} for binary writing}
\NormalTok{    f.write(body)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Installing necessary TeX packages...
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
The following additional packages will be installed:
  dvisvgm fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono
  fonts-texgyre fonts-urw-base35 libapache-pom-java libcommons-logging-java
  libcommons-parent-java libfontbox-java libgs9 libgs9-common libidn12
  libijs-0.35 libjbig2dec0 libkpathsea6 libpdfbox-java libptexenc1 libruby3.0
  libsynctex2 libteckit0 libtexlua53 libtexluajit2 libwoff1 libzzip-0-13
  lmodern poppler-data preview-latex-style rake ruby ruby-net-telnet
  ruby-rubygems ruby-webrick ruby-xmlrpc ruby3.0 rubygems-integration t1utils
  teckit tex-common tex-gyre texlive-base texlive-binaries texlive-latex-base
  texlive-latex-extra texlive-latex-recommended texlive-pictures tipa
  xfonts-encodings xfonts-utils
Suggested packages:
  fonts-noto fonts-freefont-otf | fonts-freefont-ttf libavalon-framework-java
  libcommons-logging-java-doc libexcalibur-logkit-java liblog4j1.2-java
  poppler-utils ghostscript fonts-japanese-mincho | fonts-ipafont-mincho
  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai
  fonts-arphic-uming fonts-nanum ri ruby-dev bundler debhelper gv
  | postscript-viewer perl-tk xpdf | pdf-viewer xzdec
  texlive-fonts-recommended-doc texlive-latex-base-doc python3-pygments
  icc-profiles libfile-which-perl libspreadsheet-parseexcel-perl
  texlive-latex-extra-doc texlive-latex-recommended-doc texlive-luatex
  texlive-pstricks dot2tex prerex texlive-pictures-doc vprerex
  default-jre-headless tipa-doc
The following NEW packages will be installed:
  dvisvgm fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono
  fonts-texgyre fonts-urw-base35 libapache-pom-java libcommons-logging-java
  libcommons-parent-java libfontbox-java libgs9 libgs9-common libidn12
  libijs-0.35 libjbig2dec0 libkpathsea6 libpdfbox-java libptexenc1 libruby3.0
  libsynctex2 libteckit0 libtexlua53 libtexluajit2 libwoff1 libzzip-0-13
  lmodern poppler-data preview-latex-style rake ruby ruby-net-telnet
  ruby-rubygems ruby-webrick ruby-xmlrpc ruby3.0 rubygems-integration t1utils
  teckit tex-common tex-gyre texlive-base texlive-binaries
  texlive-fonts-recommended texlive-latex-base texlive-latex-extra
  texlive-latex-recommended texlive-pictures texlive-plain-generic
  texlive-xetex tipa xfonts-encodings xfonts-utils
0 upgraded, 53 newly installed, 0 to remove and 34 not upgraded.
Need to get 182 MB of archives.
After this operation, 571 MB of additional disk space will be used.
Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1build1 [1,805 kB]
Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-lato all 2.0-2.1 [2,696 kB]
Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2,171 kB]
Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-common all 6.17 [33.7 kB]
Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-urw-base35 all 20200910-1 [6,367 kB]
Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9-common all 9.55.0~dfsg1-0ubuntu5.11 [753 kB]
Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libidn12 amd64 1.38-4ubuntu1 [60.0 kB]
Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libijs-0.35 amd64 0.35-15build2 [16.5 kB]
Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjbig2dec0 amd64 0.19-3build2 [64.7 kB]
Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9 amd64 9.55.0~dfsg1-0ubuntu5.11 [5,031 kB]
Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libkpathsea6 amd64 2021.20210626.59705-1ubuntu0.2 [60.4 kB]
Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwoff1 amd64 1.0.2-1build4 [45.2 kB]
Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dvisvgm amd64 2.13.1-1 [1,221 kB]
Get:14 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-lmodern all 2.004.5-6.1 [4,532 kB]
Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]
Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-texgyre all 20180621-3.1 [10.2 MB]
Get:17 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libapache-pom-java all 18-1 [4,720 B]
Get:18 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-parent-java all 43-1 [10.8 kB]
Get:19 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-logging-java all 1.2-2 [60.3 kB]
Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libptexenc1 amd64 2021.20210626.59705-1ubuntu0.2 [39.1 kB]
Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 rubygems-integration all 1.18 [5,336 B]
Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby3.0 amd64 3.0.2-7ubuntu2.10 [50.1 kB]
Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-rubygems all 3.3.5-2 [228 kB]
Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby amd64 1:3.0~exp1 [5,100 B]
Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 rake all 13.0.6-2 [61.7 kB]
Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]
Get:27 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-webrick all 1.7.0-3ubuntu0.1 [52.1 kB]
Get:28 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-xmlrpc all 0.3.2-1ubuntu0.1 [24.9 kB]
Get:29 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libruby3.0 amd64 3.0.2-7ubuntu2.10 [5,114 kB]
Get:30 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsynctex2 amd64 2021.20210626.59705-1ubuntu0.2 [55.6 kB]
Get:31 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libteckit0 amd64 2.5.11+ds1-1 [421 kB]
Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexlua53 amd64 2021.20210626.59705-1ubuntu0.2 [120 kB]
Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexluajit2 amd64 2021.20210626.59705-1ubuntu0.2 [267 kB]
Get:34 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libzzip-0-13 amd64 0.13.72+dfsg.1-1.1 [27.0 kB]
Get:35 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]
Get:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]
Get:37 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lmodern all 2.004.5-6.1 [9,471 kB]
Get:38 http://archive.ubuntu.com/ubuntu jammy/universe amd64 preview-latex-style all 12.2-1ubuntu1 [185 kB]
Get:39 http://archive.ubuntu.com/ubuntu jammy/main amd64 t1utils amd64 1.41-4build2 [61.3 kB]
Get:40 http://archive.ubuntu.com/ubuntu jammy/universe amd64 teckit amd64 2.5.11+ds1-1 [699 kB]
Get:41 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-gyre all 20180621-3.1 [6,209 kB]
Get:42 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 texlive-binaries amd64 2021.20210626.59705-1ubuntu0.2 [9,860 kB]
Get:43 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-base all 2021.20220204-1 [21.0 MB]
Get:44 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-fonts-recommended all 2021.20220204-1 [4,972 kB]
Get:45 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-base all 2021.20220204-1 [1,128 kB]
Get:46 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfontbox-java all 1:1.8.16-2 [207 kB]
Get:47 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libpdfbox-java all 1:1.8.16-2 [5,199 kB]
Get:48 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-recommended all 2021.20220204-1 [14.4 MB]
Get:49 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-pictures all 2021.20220204-1 [8,720 kB]
Get:50 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-extra all 2021.20220204-1 [13.9 MB]
Get:51 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-plain-generic all 2021.20220204-1 [27.5 MB]
Get:52 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tipa all 2:1.3-21 [2,967 kB]
Get:53 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-xetex all 2021.20220204-1 [12.4 MB]
Fetched 182 MB in 12s (15.2 MB/s)
Extracting templates from packages: 100%
Preconfiguring packages ...
Selecting previously unselected package fonts-droid-fallback.
(Reading database ... 126327 files and directories currently installed.)
Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...
Unpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...
Selecting previously unselected package fonts-lato.
Preparing to unpack .../01-fonts-lato_2.0-2.1_all.deb ...
Unpacking fonts-lato (2.0-2.1) ...
Selecting previously unselected package poppler-data.
Preparing to unpack .../02-poppler-data_0.4.11-1_all.deb ...
Unpacking poppler-data (0.4.11-1) ...
Selecting previously unselected package tex-common.
Preparing to unpack .../03-tex-common_6.17_all.deb ...
Unpacking tex-common (6.17) ...
Selecting previously unselected package fonts-urw-base35.
Preparing to unpack .../04-fonts-urw-base35_20200910-1_all.deb ...
Unpacking fonts-urw-base35 (20200910-1) ...
Selecting previously unselected package libgs9-common.
Preparing to unpack .../05-libgs9-common_9.55.0~dfsg1-0ubuntu5.11_all.deb ...
Unpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.11) ...
Selecting previously unselected package libidn12:amd64.
Preparing to unpack .../06-libidn12_1.38-4ubuntu1_amd64.deb ...
Unpacking libidn12:amd64 (1.38-4ubuntu1) ...
Selecting previously unselected package libijs-0.35:amd64.
Preparing to unpack .../07-libijs-0.35_0.35-15build2_amd64.deb ...
Unpacking libijs-0.35:amd64 (0.35-15build2) ...
Selecting previously unselected package libjbig2dec0:amd64.
Preparing to unpack .../08-libjbig2dec0_0.19-3build2_amd64.deb ...
Unpacking libjbig2dec0:amd64 (0.19-3build2) ...
Selecting previously unselected package libgs9:amd64.
Preparing to unpack .../09-libgs9_9.55.0~dfsg1-0ubuntu5.11_amd64.deb ...
Unpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.11) ...
Selecting previously unselected package libkpathsea6:amd64.
Preparing to unpack .../10-libkpathsea6_2021.20210626.59705-1ubuntu0.2_amd64.deb ...
Unpacking libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...
Selecting previously unselected package libwoff1:amd64.
Preparing to unpack .../11-libwoff1_1.0.2-1build4_amd64.deb ...
Unpacking libwoff1:amd64 (1.0.2-1build4) ...
Selecting previously unselected package dvisvgm.
Preparing to unpack .../12-dvisvgm_2.13.1-1_amd64.deb ...
Unpacking dvisvgm (2.13.1-1) ...
Selecting previously unselected package fonts-lmodern.
Preparing to unpack .../13-fonts-lmodern_2.004.5-6.1_all.deb ...
Unpacking fonts-lmodern (2.004.5-6.1) ...
Selecting previously unselected package fonts-noto-mono.
Preparing to unpack .../14-fonts-noto-mono_20201225-1build1_all.deb ...
Unpacking fonts-noto-mono (20201225-1build1) ...
Selecting previously unselected package fonts-texgyre.
Preparing to unpack .../15-fonts-texgyre_20180621-3.1_all.deb ...
Unpacking fonts-texgyre (20180621-3.1) ...
Selecting previously unselected package libapache-pom-java.
Preparing to unpack .../16-libapache-pom-java_18-1_all.deb ...
Unpacking libapache-pom-java (18-1) ...
Selecting previously unselected package libcommons-parent-java.
Preparing to unpack .../17-libcommons-parent-java_43-1_all.deb ...
Unpacking libcommons-parent-java (43-1) ...
Selecting previously unselected package libcommons-logging-java.
Preparing to unpack .../18-libcommons-logging-java_1.2-2_all.deb ...
Unpacking libcommons-logging-java (1.2-2) ...
Selecting previously unselected package libptexenc1:amd64.
Preparing to unpack .../19-libptexenc1_2021.20210626.59705-1ubuntu0.2_amd64.deb ...
Unpacking libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...
Selecting previously unselected package rubygems-integration.
Preparing to unpack .../20-rubygems-integration_1.18_all.deb ...
Unpacking rubygems-integration (1.18) ...
Selecting previously unselected package ruby3.0.
Preparing to unpack .../21-ruby3.0_3.0.2-7ubuntu2.10_amd64.deb ...
Unpacking ruby3.0 (3.0.2-7ubuntu2.10) ...
Selecting previously unselected package ruby-rubygems.
Preparing to unpack .../22-ruby-rubygems_3.3.5-2_all.deb ...
Unpacking ruby-rubygems (3.3.5-2) ...
Selecting previously unselected package ruby.
Preparing to unpack .../23-ruby_1%3a3.0~exp1_amd64.deb ...
Unpacking ruby (1:3.0~exp1) ...
Selecting previously unselected package rake.
Preparing to unpack .../24-rake_13.0.6-2_all.deb ...
Unpacking rake (13.0.6-2) ...
Selecting previously unselected package ruby-net-telnet.
Preparing to unpack .../25-ruby-net-telnet_0.1.1-2_all.deb ...
Unpacking ruby-net-telnet (0.1.1-2) ...
Selecting previously unselected package ruby-webrick.
Preparing to unpack .../26-ruby-webrick_1.7.0-3ubuntu0.1_all.deb ...
Unpacking ruby-webrick (1.7.0-3ubuntu0.1) ...
Selecting previously unselected package ruby-xmlrpc.
Preparing to unpack .../27-ruby-xmlrpc_0.3.2-1ubuntu0.1_all.deb ...
Unpacking ruby-xmlrpc (0.3.2-1ubuntu0.1) ...
Selecting previously unselected package libruby3.0:amd64.
Preparing to unpack .../28-libruby3.0_3.0.2-7ubuntu2.10_amd64.deb ...
Unpacking libruby3.0:amd64 (3.0.2-7ubuntu2.10) ...
Selecting previously unselected package libsynctex2:amd64.
Preparing to unpack .../29-libsynctex2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...
Unpacking libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...
Selecting previously unselected package libteckit0:amd64.
Preparing to unpack .../30-libteckit0_2.5.11+ds1-1_amd64.deb ...
Unpacking libteckit0:amd64 (2.5.11+ds1-1) ...
Selecting previously unselected package libtexlua53:amd64.
Preparing to unpack .../31-libtexlua53_2021.20210626.59705-1ubuntu0.2_amd64.deb ...
Unpacking libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...
Selecting previously unselected package libtexluajit2:amd64.
Preparing to unpack .../32-libtexluajit2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...
Unpacking libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...
Selecting previously unselected package libzzip-0-13:amd64.
Preparing to unpack .../33-libzzip-0-13_0.13.72+dfsg.1-1.1_amd64.deb ...
Unpacking libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...
Selecting previously unselected package xfonts-encodings.
Preparing to unpack .../34-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...
Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...
Selecting previously unselected package xfonts-utils.
Preparing to unpack .../35-xfonts-utils_1%3a7.7+6build2_amd64.deb ...
Unpacking xfonts-utils (1:7.7+6build2) ...
Selecting previously unselected package lmodern.
Preparing to unpack .../36-lmodern_2.004.5-6.1_all.deb ...
Unpacking lmodern (2.004.5-6.1) ...
Selecting previously unselected package preview-latex-style.
Preparing to unpack .../37-preview-latex-style_12.2-1ubuntu1_all.deb ...
Unpacking preview-latex-style (12.2-1ubuntu1) ...
Selecting previously unselected package t1utils.
Preparing to unpack .../38-t1utils_1.41-4build2_amd64.deb ...
Unpacking t1utils (1.41-4build2) ...
Selecting previously unselected package teckit.
Preparing to unpack .../39-teckit_2.5.11+ds1-1_amd64.deb ...
Unpacking teckit (2.5.11+ds1-1) ...
Selecting previously unselected package tex-gyre.
Preparing to unpack .../40-tex-gyre_20180621-3.1_all.deb ...
Unpacking tex-gyre (20180621-3.1) ...
Selecting previously unselected package texlive-binaries.
Preparing to unpack .../41-texlive-binaries_2021.20210626.59705-1ubuntu0.2_amd64.deb ...
Unpacking texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...
Selecting previously unselected package texlive-base.
Preparing to unpack .../42-texlive-base_2021.20220204-1_all.deb ...
Unpacking texlive-base (2021.20220204-1) ...
Selecting previously unselected package texlive-fonts-recommended.
Preparing to unpack .../43-texlive-fonts-recommended_2021.20220204-1_all.deb ...
Unpacking texlive-fonts-recommended (2021.20220204-1) ...
Selecting previously unselected package texlive-latex-base.
Preparing to unpack .../44-texlive-latex-base_2021.20220204-1_all.deb ...
Unpacking texlive-latex-base (2021.20220204-1) ...
Selecting previously unselected package libfontbox-java.
Preparing to unpack .../45-libfontbox-java_1%3a1.8.16-2_all.deb ...
Unpacking libfontbox-java (1:1.8.16-2) ...
Selecting previously unselected package libpdfbox-java.
Preparing to unpack .../46-libpdfbox-java_1%3a1.8.16-2_all.deb ...
Unpacking libpdfbox-java (1:1.8.16-2) ...
Selecting previously unselected package texlive-latex-recommended.
Preparing to unpack .../47-texlive-latex-recommended_2021.20220204-1_all.deb ...
Unpacking texlive-latex-recommended (2021.20220204-1) ...
Selecting previously unselected package texlive-pictures.
Preparing to unpack .../48-texlive-pictures_2021.20220204-1_all.deb ...
Unpacking texlive-pictures (2021.20220204-1) ...
Selecting previously unselected package texlive-latex-extra.
Preparing to unpack .../49-texlive-latex-extra_2021.20220204-1_all.deb ...
Unpacking texlive-latex-extra (2021.20220204-1) ...
Selecting previously unselected package texlive-plain-generic.
Preparing to unpack .../50-texlive-plain-generic_2021.20220204-1_all.deb ...
Unpacking texlive-plain-generic (2021.20220204-1) ...
Selecting previously unselected package tipa.
Preparing to unpack .../51-tipa_2%3a1.3-21_all.deb ...
Unpacking tipa (2:1.3-21) ...
Selecting previously unselected package texlive-xetex.
Preparing to unpack .../52-texlive-xetex_2021.20220204-1_all.deb ...
Unpacking texlive-xetex (2021.20220204-1) ...
Setting up fonts-lato (2.0-2.1) ...
Setting up fonts-noto-mono (20201225-1build1) ...
Setting up libwoff1:amd64 (1.0.2-1build4) ...
Setting up libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...
Setting up libijs-0.35:amd64 (0.35-15build2) ...
Setting up libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...
Setting up libfontbox-java (1:1.8.16-2) ...
Setting up rubygems-integration (1.18) ...
Setting up libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...
Setting up fonts-urw-base35 (20200910-1) ...
Setting up poppler-data (0.4.11-1) ...
Setting up tex-common (6.17) ...
update-language: texlive-base not installed and configured, doing nothing!
Setting up libjbig2dec0:amd64 (0.19-3build2) ...
Setting up libteckit0:amd64 (2.5.11+ds1-1) ...
Setting up libapache-pom-java (18-1) ...
Setting up ruby-net-telnet (0.1.1-2) ...
Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...
Setting up t1utils (1.41-4build2) ...
Setting up libidn12:amd64 (1.38-4ubuntu1) ...
Setting up fonts-texgyre (20180621-3.1) ...
Setting up libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...
Setting up ruby-webrick (1.7.0-3ubuntu0.1) ...
Setting up fonts-lmodern (2.004.5-6.1) ...
Setting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...
Setting up ruby-xmlrpc (0.3.2-1ubuntu0.1) ...
Setting up libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...
Setting up libgs9-common (9.55.0~dfsg1-0ubuntu5.11) ...
Setting up teckit (2.5.11+ds1-1) ...
Setting up libpdfbox-java (1:1.8.16-2) ...
Setting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.11) ...
Setting up preview-latex-style (12.2-1ubuntu1) ...
Setting up libcommons-parent-java (43-1) ...
Setting up dvisvgm (2.13.1-1) ...
Setting up libcommons-logging-java (1.2-2) ...
Setting up xfonts-utils (1:7.7+6build2) ...
Setting up libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...
Setting up texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...
update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode
update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode
Setting up lmodern (2.004.5-6.1) ...
Setting up texlive-base (2021.20220204-1) ...
/usr/bin/ucfr
/usr/bin/ucfr
/usr/bin/ucfr
/usr/bin/ucfr
mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... 
mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... 
mktexlsr: Updating /var/lib/texmf/ls-R... 
mktexlsr: Done.
tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps
tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg
tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper
tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/tex-ini-files/pdftexconfig.tex
Setting up tex-gyre (20180621-3.1) ...
Setting up texlive-plain-generic (2021.20220204-1) ...
Setting up texlive-latex-base (2021.20220204-1) ...
Setting up texlive-latex-recommended (2021.20220204-1) ...
Setting up texlive-pictures (2021.20220204-1) ...
Setting up texlive-fonts-recommended (2021.20220204-1) ...
Setting up tipa (2:1.3-21) ...
Setting up texlive-latex-extra (2021.20220204-1) ...
Setting up texlive-xetex (2021.20220204-1) ...
Setting up rake (13.0.6-2) ...
Setting up libruby3.0:amd64 (3.0.2-7ubuntu2.10) ...
Setting up ruby3.0 (3.0.2-7ubuntu2.10) ...
Setting up ruby (1:3.0~exp1) ...
Setting up ruby-rubygems (3.3.5-2) ...
Processing triggers for man-db (2.10.2-1) ...
Processing triggers for mailcap (3.70+nmu1ubuntu1) ...
Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...
Processing triggers for libc-bin (2.35-0ubuntu3.8) ...
/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link

/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link

/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link

/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link

/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link

/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link

/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link

/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link

/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link

/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link

/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link

/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link

/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link

Processing triggers for tex-common (6.17) ...
Running updmap-sys. This may take some time... done.
Running mktexlsr /var/lib/texmf ... done.
Building format(s) --all.
    This may take some time... done.
TeX packages installed successfully.
--2025-05-24 20:12:59--  https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1689816 (1.6M) [text/plain]
Saving to: ‘AMTAIR_Prototype_example_carlsmith.ipynb’

AMTAIR_Prototype_ex 100%[===================>]   1.61M  5.31MB/s    in 0.3s    

2025-05-24 20:12:59 (5.31 MB/s) - ‘AMTAIR_Prototype_example_carlsmith.ipynb’ saved [1689816/1689816]
\end{verbatim}


\backmatter
\printbibliography[title=Bibliography]



\clearpage
\thispagestyle{empty} % Removes page numbering for current page

\newpage


% Top header with logo (left) and department (right)
\begin{minipage}{0.3\textwidth}
  \includegraphics[width=5cm]{latex/uni-bayreuth-logo.png}
\end{minipage}
\hfill
\begin{minipage}{0.9\textwidth}
  \begin{center}
    -- P\&E Master's Programme --\\
    Chair of Philosophy, Computer\\
    Science \& Artificial Intelligence
  \end{center}
\end{minipage}

% Horizontal rule
\vspace{1.5cm}
\hrule
\vspace{2.5cm}

% Title in bold

  \LARGE\textbf{Affidavit}
\vspace{1.5cm}

\center

\normalsize

% \part*{Affidavit}

    \subsection*{\Large{ Declaration of Academic Honesty}}
	    \vspace{1cm}\noindent \\
	    Hereby, I attest that I have composed and written the presented thesis 
        \vspace*{0.5cm}\noindent \\
        \textit{ \textbf{ Automating the Modelling of Transformative Artificial Intelligence Risks }}
        \vspace*{0.5cm}\noindent \\
        independently on my own, without the use of other than the stated aids and without any other resources than the ones indicated. All thoughts taken directly or indirectly from external sources are properly denoted as such.
	    \vspace{\baselineskip}
	    \\  This paper has neither been previously submitted in the same or a similar form to another authority nor has it been published yet.
	    \vspace{2cm}
	    
    \flushright
    \begin{minipage}{0.5\textwidth}
        \begin{flushleft} \large
        \textsc{Bayreuth}                     %   Place
        on the \\ % 26th of May 2025     \\
        \today           %   Date
        \vspace{2cm}\\
    	{\rule[-3pt]{\linewidth}{.4pt}\par\smallskip  
        \textsc{Valentin Meyer}	\\         %   Your name
    	}
        \end{flushleft}
        \end{minipage}


\end{document}
