% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  11pt,
  letterpaper,
]{book}
\usepackage{xcolor}
\usepackage[margin=2.5cm,paper=a4paper]{geometry}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother
\usepackage{fancyvrb}

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother

\ifLuaTeX
  \usepackage{luacolor}
  \usepackage[soul]{lua-ul}
\else
  \usepackage{soul}
\fi




\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 
\usepackage[]{biblatex}
\addbibresource{ref/MAref.bib}


% AMTAIR Thesis Preamble - Zero package conflicts
% Only formatting commands, no package loading

% Line spacing for academic work
\usepackage{setspace}
\onehalfspacing

% Custom chapter formatting (remove "Chapter N" prefix) but unfortunately leaves blank space
\usepackage{titlesec}
\titleformat{\chapter}[display]
  {\normalfont\huge\bfseries}  % format
  {}                           % label (empty = no "Chapter N")
  {0pt}                        % sep
  {\Huge}                      % before-code



% Page formatting and headers
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\slshape\nouppercase{\rightmark}}
\fancyhead[LO,RE]{\slshape\nouppercase{\leftmark}}
\fancyfoot[C]{\thepage}

% % Fix page breaks after title page
% \newcommand{\cleartitlepage}{
%   \clearpage
%   \thispagestyle{empty}
%   \mbox{}
%   \clearpage
% }



\renewcommand{\maketitle}{}

%  Citation customization
% \usepackage[style=authoryear,backend=biber,natbib=true]{biblatex}

% % Custom citation commands for different contexts
% \newcommand{\citeauthor}[1]{\textcite{#1}}           % Author (year)
% \newcommand{\citeyear}[1]{(\citeyear*{#1})}         % (year)
% \newcommand{\citealt}[1]{\citeauthor{#1} \citeyear{#1}}  % Author year
% \newcommand{\citep}[1]{(\cite{#1})}                 # (Author, year)

% Page reference styling
% \DeclareFieldFormat{postnote}{#1}                    # No "p." prefix
% \DeclareFieldFormat{multipostnote}{#1}               # No "pp." prefix


% % Page numbering control
% \usepackage{afterpage}

% % Command to start front matter (roman numerals)
% \newcommand{\frontmatter}{
%   \cleardoublepage
%   \pagenumbering{roman}
%   \setcounter{page}{1}
% }

% % Command to start main matter (arabic numerals)
% \newcommand{\mainmatter}{
%   \cleardoublepage
%   \pagenumbering{arabic}
%   \setcounter{page}{1}
% }

% % Command to start back matter (continue arabic)
% \newcommand{\backmatter}{
%   \cleardoublepage
%   % Keep arabic numbering but could change style if needed
% }

% % Suppress page numbers on title page
% \newcommand{\titlepage}{
%   \thispagestyle{empty}
% }



% Commands for custom title page
% \newcommand{\thesistitle}{Automating the Modelling of Transformative Artificial Intelligence Risks}
% \newcommand{\thesisauthor}{Valentin Jakob Meyer}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\usepackage{pdflscape}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\VerbatimFootnotes % allow verbatim text in footnotes
\hypersetup{
  pdftitle={Automating the Modelling of Transformative Artificial Intelligence Risks},
  pdfauthor={Valentin Jakob Meyer},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}


\title{Automating the Modelling of Transformative Artificial
Intelligence Risks}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{An Epistemic Framework for Leveraging Frontier AI Systems to
Upscale Conditional Policy Assessments in Bayesian Networks on a Narrow
Path towards Existential Safety}
\author{Valentin Jakob Meyer}
\date{2025-05-26}
\begin{document}
\frontmatter
\maketitle

\begin{titlepage}
\thispagestyle{empty}% Remove page number from title page

% Top header with logo (left) and department (right)
\begin{minipage}{0.3\textwidth}
  \includegraphics[width=5cm]{latex/uni-bayreuth-logo.png}
\end{minipage}
\hfill
\begin{minipage}{0.9\textwidth}
  \begin{center}
    -- P\&E Master's Programme --\\
    Chair of Philosophy, Computer\\
    Science \& Artificial Intelligence
  \end{center}
\end{minipage}

% Horizontal rule
\vspace{1.5cm}
\hrule
\vspace{2cm}

% Title in bold
\begin{center}
  \Large\textbf{Automating the Modelling of
Transformative Artificial Intelligence Risks}
\end{center}
\vspace{0.2cm}

\begin{center}
  -----
\end{center}
\vspace{0.2cm}

% Subtitle in italics with quotation marks
\begin{center}
  \normalsize``\textit{An Epistemic Framework for Leveraging Frontier AI Systems
to Upscale Conditional Policy Assessments in Bayesian Networks on a Narrow Path towards Existencial Safety }''
\end{center}
\vspace{0.2cm}

\begin{center}
  -----
\end{center}
\vspace{0.2cm}

% Thesis designation
\begin{center}
  A thesis submitted at the Department of Philosophy\\[0.4cm]
  for the degree of \textit{Master of Arts in Philosophy \& Economics}
\end{center}

\vspace{1.5cm}
% Horizontal rule
\hrule
\vspace{1.5cm}

% Author and supervisor information with precise alignment
\begin{minipage}[t]{0.48\textwidth}
  \textbf{Author:}\\[0.3cm]
  \href{https://www.vjmeyer.org}{Valentin Jakob Meyer}\\
  \href{mailto:Valentin.meyer@uni-bayreuth.de}{Valentin.meyer@uni-bayreuth.de}\\
  \textit{Matriculation Number:} 1828610\\
  \textit{Tel.:} +49 (1573) 4512494\\
  Pielmühler Straße 15\\
  52066 Lappersdorf
\end{minipage}
\hfill
\begin{minipage}[t]{0.48\textwidth}
  \begin{flushright}
    \textbf{Supervisor:}\\[0.3cm]
    \href{mailto:timo.speith@uni-bayreuth.de}{Dr. Timo Speith}\\[0.35cm]
    \textit{Word Count:}\\
    30.000\\[0.1cm]
    \textit{Source / Identifier:}\\
    \href{https://github.com/VJMeyer/submission}{Document URL}
  \end{flushright}
\end{minipage}

% Date at bottom
\vfill
\begin{center}
  26th of May 2025
\end{center}
\end{titlepage}

% Critical: Clean page break to TOC
\cleardoublepage

\renewcommand*\contentsname{Table of Contents}
{
\setcounter{tocdepth}{9}
\tableofcontents
}
\listoffigures
\listoftables

\mainmatter
\bookmarksetup{startatroot}

\chapter*{Preface}\label{preface}
\addcontentsline{toc}{chapter}{Preface}

\markboth{Preface}{Preface}

\bookmarksetup{startatroot}

\chapter*{Abstract}\label{sec-abstract}
\addcontentsline{toc}{chapter}{Abstract}

\markboth{Abstract}{Abstract}

\begin{quote}
The coordination crisis in AI governance presents a paradoxical
challenge: unprecedented investment in AI safety coexists alongside
fundamental coordination failures across technical, policy, and ethical
domains. These divisions systematically increase existential risk. This
thesis introduces AMTAIR (Automating Transformative AI Risk Modeling), a
computational approach addressing this coordination failure by
automating the extraction of probabilistic world models from AI safety
literature using frontier language models. The system implements an
end-to-end pipeline transforming unstructured text into interactive
Bayesian networks through a novel two-stage extraction process that
bridges communication gaps between stakeholders.
\end{quote}

\texttt{The\ coordination\ crisis\ in\ AI\ governance\ presents\ a\ paradoxical\ challenge:\ unprecedented\ investment\ in\ AI\ safety\ coexists\ alongside\ fundamental\ coordination\ failures\ across\ technical,\ policy,\ and\ ethical\ domains.\ These\ divisions\ systematically\ increase\ existential\ risk\ by\ creating\ safety\ gaps,\ misallocating\ resources,\ and\ fostering\ inconsistent\ approaches\ to\ interdependent\ problems.}

\begin{quote}
This thesis introduces AMTAIR (Automating Transformative AI Risk
Modeling), a computational approach that addresses this coordination
failure by automating the extraction of probabilistic world models from
AI safety literature using frontier language models.
\end{quote}

\texttt{The\ AMTAIR\ system\ implements\ an\ end-to-end\ pipeline\ that\ transforms\ unstructured\ text\ into\ interactive\ Bayesian\ networks\ through\ a\ novel\ two-stage\ extraction\ process:\ first\ capturing\ argument\ structure\ in\ ArgDown\ format,\ then\ enhancing\ it\ with\ probability\ information\ in\ BayesDown.\ This\ approach\ bridges\ communication\ gaps\ between\ stakeholders\ by\ making\ implicit\ models\ explicit,\ enabling\ comparison\ across\ different\ worldviews,\ providing\ a\ common\ language\ for\ discussing\ probabilistic\ relationships,\ and\ supporting\ policy\ evaluation\ across\ diverse\ scenarios.}

\bookmarksetup{startatroot}

\chapter*{Prefatory Apparatus:
Frontmatter}\label{prefatory-apparatus-frontmatter}
\addcontentsline{toc}{chapter}{Prefatory Apparatus: Frontmatter}

\markboth{Prefatory Apparatus: Frontmatter}{Prefatory Apparatus:
Frontmatter}

\section*{Illustrations and Terminology --- Quick
References}\label{illustrations-and-terminology-quick-references}
\addcontentsline{toc}{section}{Illustrations and Terminology --- Quick
References}

\markright{Illustrations and Terminology --- Quick References}

\subsection*{\texorpdfstring{\textbf{Acknowledgments}}{Acknowledgments}}\label{acknowledgments}
\addcontentsline{toc}{subsection}{\textbf{Acknowledgments}}

\begin{itemize}
\tightlist
\item
  Academic supervisor (Prof.~Timo Speith) and institution (University of
  Bayreuth)\\
\item
  Research collaborators, especially those connected to the original
  MTAIR project\\
\item
  Technical advisors who provided feedback on implementation aspects\\
\item
  Personal supporters who enabled the research through encouragement and
  feedback
\end{itemize}

\section*{List of Graphics \& Figures}\label{list-of-graphics-figures}
\addcontentsline{toc}{section}{List of Graphics \& Figures}

\markright{List of Graphics \& Figures}

\begin{itemize}
\tightlist
\item
  Figure 1.1: The coordination crisis in AI governance - visualization
  of fragmentation\\
\item
  Figure 2.1: The Carlsmith model - DAG representation\\
\item
  Figure 3.1: Research design overview - workflow diagram\\
\item
  Figure 3.2: From natural language to BayesDown - transformation
  process\\
\item
  Figure 4.1: ARPA system architecture - component diagram\\
\item
  Figure 4.2: Visualization of Rain-Sprinkler-Grass\_Wet Bayesian
  network - screenshot\\
\item
  Figure 5.1: Extraction quality metrics - comparative chart\\
\item
  Figure 5.2: Comparative analysis of AI governance worldviews - network
  visualization
\end{itemize}

\section*{List of Abbreviations}\label{list-of-abbreviations}
\addcontentsline{toc}{section}{List of Abbreviations}

\markright{List of Abbreviations}

esp.~especially

f., ff.~following

incl.~including

p., pp.~page(s)

MAD Mutually Assured Destruction

\begin{itemize}
\tightlist
\item
  AI - Artificial Intelligence\\
\item
  AGI - Artificial General Intelligence\\
\item
  ARPA - AI Risk Pathway Analyzer\\
\item
  DAG - Directed Acyclic Graph\\
\item
  LLM - Large Language Model\\
\item
  MTAIR - Modeling Transformative AI Risks\\
\item
  P(Doom) - Probability of existential catastrophe from misaligned AI\\
\item
  CPT - Conditional Probability Table
\end{itemize}

\section*{Glossary}\label{glossary}

\markright{Glossary}

\begin{itemize}
\tightlist
\item
  \textbf{Argument mapping}: A method for visually representing the
  structure of arguments\\
\item
  \textbf{BayesDown}: An extension of ArgDown that incorporates
  probabilistic information\\
\item
  \textbf{Bayesian network}: A probabilistic graphical model
  representing variables and their dependencies\\
\item
  \textbf{Conditional probability}: The probability of an event given
  that another event has occurred\\
\item
  \textbf{Directed Acyclic Graph (DAG)}: A graph with directed edges and
  no cycles\\
\item
  \textbf{Existential risk}: Risk of permanent curtailment of humanity's
  potential\\
\item
  \textbf{Power-seeking AI}: AI systems with instrumental incentives to
  acquire resources and power\\
\item
  \textbf{Prediction market}: A market where participants trade
  contracts that resolve based on future events\\
\item
  \textbf{d-separation}: A criterion for identifying conditional
  independence relationships in Bayesian networks\\
\item
  \textbf{Monte Carlo sampling}: A computational technique using random
  sampling to obtain numerical results
\end{itemize}

\bookmarksetup{startatroot}

\chapter*{Quarto Syntax and Best Practices
Guide}\label{quarto-syntax-and-best-practices-guide}
\addcontentsline{toc}{chapter}{Quarto Syntax and Best Practices Guide}

\markboth{Quarto Syntax and Best Practices Guide}{Quarto Syntax and Best
Practices Guide}

\section*{Key Features}\label{key-features}
\addcontentsline{toc}{section}{Key Features}

\markright{Key Features}

\subsection*{1. Task Management System}\label{task-management-system}
\addcontentsline{toc}{subsection}{1. Task Management System}

\begin{itemize}
\tightlist
\item
  HTML comments with \texttt{{[}\ {]}} for tasks visible in ToDo-Tree
\item
  Categories: FIND, VERIFY, CREATE, TODO
\item
  Progress tracking with \texttt{{[}x{]}} (done) and \texttt{{[}-{]}}
  (verified)
\end{itemize}

\subsection*{2. Multi-Format Output}\label{multi-format-output}
\addcontentsline{toc}{subsection}{2. Multi-Format Output}

\begin{itemize}
\tightlist
\item
  HTML: Interactive web version with navigation
\item
  PDF: Professional academic document
\item
  LaTeX: Source for further customization
\item
  DOCX: For collaboration
\end{itemize}

\subsection*{3. Cross-Referencing}\label{cross-referencing}
\addcontentsline{toc}{subsection}{3. Cross-Referencing}

\begin{itemize}
\tightlist
\item
  Sections: \texttt{@sec-section-name}
\item
  Figures: \texttt{@fig-figure-name}
\item
  Tables: \texttt{@tbl-table-name}
\item
  Citations: \texttt{@citation-key}
\end{itemize}

\subsection*{4. Advanced Features}\label{advanced-features}
\addcontentsline{toc}{subsection}{4. Advanced Features}

\begin{itemize}
\tightlist
\item
  Interactive Jupyter notebooks
\item
  Mermaid diagrams
\item
  Math equations (LaTeX)
\item
  Callout blocks
\item
  Extensive footnotes
\item
  Glossary and abbreviations
\end{itemize}

\section*{Quick Start}\label{quick-start}
\addcontentsline{toc}{section}{Quick Start}

\markright{Quick Start}

\subsection*{Task Management}\label{task-management}
\addcontentsline{toc}{subsection}{Task Management}

Write and track tasks with HTML comments in markdown blocks or with
\texttt{verbatim\ code} ticks but ALWAYS add linke breaks between tasks:

\begin{Shaded}
\begin{Highlighting}[]
\InformationTok{\textasciigrave{}\textless{}!{-}{-} [ ] TODO: Task description {-}{-}\textgreater{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textless{}!{-}{-} [ ] FIND: @missing{-}citation: "Description" {-}{-}\textgreater{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textless{}!{-}{-} [ ] VERIFY: @suggested{-}citation: "Source" {-}{-}\textgreater{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textless{}!{-}{-} [ ] CREATE: \{\#fig{-}name\}: "Figure description" {-}{-}\textgreater{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

\subsection*{Adding Content}\label{adding-content}
\addcontentsline{toc}{subsection}{Adding Content}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create/edit \texttt{.qmd} files in chapters/
\item
  Update \texttt{\_quarto.yml} if adding new chapters
\item
  Add citations to \texttt{ref/MAref.bib}
\item
  Place images in \texttt{images/}
\end{enumerate}

\section*{Best Practices}\label{best-practices}
\addcontentsline{toc}{section}{Best Practices}

\markright{Best Practices}

\subsection*{1. Consistent Formatting}\label{consistent-formatting}
\addcontentsline{toc}{subsection}{1. Consistent Formatting}

\begin{itemize}
\tightlist
\item
  Use American spelling throughout
\item
  Follow heading hierarchy (\#\#, \#\#\#, \#\#\#\#)
\item
  Maintain consistent citation style
\item
  Use semantic line breaks
\end{itemize}

\subsection*{2. Task Tracking}\label{task-tracking}
\addcontentsline{toc}{subsection}{2. Task Tracking}

\begin{itemize}
\tightlist
\item
  Create tasks as you write
\item
  Update task status regularly
\item
  Use categories for clarity
\item
  Include implementation details
\end{itemize}

\subsection*{3. Version Control}\label{version-control}
\addcontentsline{toc}{subsection}{3. Version Control}

\begin{itemize}
\tightlist
\item
  Commit frequently with descriptive messages
\item
  Use branches for major revisions
\item
  Tag releases (draft versions)
\end{itemize}

\subsection*{4. Documentation}\label{documentation}
\addcontentsline{toc}{subsection}{4. Documentation}

\begin{itemize}
\tightlist
\item
  Comment complex code blocks
\item
  Provide alt text for all figures
\item
  Keep this README updated
\item
  Document any custom scripts
\end{itemize}

\section*{Troubleshooting}\label{troubleshooting}
\addcontentsline{toc}{section}{Troubleshooting}

\markright{Troubleshooting}

\subsection*{Common Issues}\label{common-issues}
\addcontentsline{toc}{subsection}{Common Issues}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{LaTeX errors}: Check \texttt{\_quarto.yml} for LaTeX settings
\item
  \textbf{Missing references}: Ensure citations are in
  \texttt{MAref.bib}
\item
  \textbf{Broken links}: Use relative paths for internal links
\item
  \textbf{Task visibility}: Install ToDo-Tree extension in VS Code
\end{enumerate}

\subsection*{Getting Help}\label{getting-help}
\addcontentsline{toc}{subsection}{Getting Help}

\begin{itemize}
\tightlist
\item
  Quarto documentation: \url{https://quarto.org}
\item
  Project repository: \url{https://github.com/VJMeyer/submission}
\item
  Contact:
  \href{mailto:Valentin2meyer@gmail.com}{\nolinkurl{Valentin2meyer@gmail.com}}
\end{itemize}

\section*{License}\label{license}
\addcontentsline{toc}{section}{License}

\markright{License}

MIT License - See LICENSE file for details

\section*{Document Structure and
Headings}\label{document-structure-and-headings}
\addcontentsline{toc}{section}{Document Structure and Headings}

\markright{Document Structure and Headings}

\subsection*{Heading Hierarchy}\label{heading-hierarchy}
\addcontentsline{toc}{subsection}{Heading Hierarchy}

Always use the full heading hierarchy for maximum organization:

markdown

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\# Chapter Title \{\#sec{-}chapter\}}
\FunctionTok{\#\# Major Section \{\#sec{-}major{-}section\}}
\FunctionTok{\#\#\# Subsection \{\#sec{-}subsection\}}
\FunctionTok{\#\#\#\# Sub{-}subsection \{\#sec{-}subsubsection\}}
\InformationTok{\textasciigrave{}\#\#\#\#\# Sub{-}subsubsection \{\#sec{-}subsubsubsection\}\textasciigrave{}}
\InformationTok{\textasciigrave{}\#\#\#\#\#\# Sub{-}subsubsubsection \{\#sec{-}subsubsubsection\}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

\textbf{Best Practices:}

\begin{itemize}
\tightlist
\item
  Always include \texttt{\{\#sec-label\}} for cross-referencing
\item
  Use descriptive, concise heading names
\item
  Maintain consistent capitalization (Title Case for chapters, Sentence
  case for sections)
\item
  Add \texttt{.unnumbered} for sections without numbers (e.g.,
  References)
\item
  Add \texttt{.unlisted} to exclude from TOC
\item
  Do not manually number headings
\end{itemize}

\section*{Text Formatting}\label{text-formatting}
\addcontentsline{toc}{section}{Text Formatting}

\markright{Text Formatting}

\subsection*{Basic Formatting}\label{basic-formatting}
\addcontentsline{toc}{subsection}{Basic Formatting}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{*italics* for emphasis}
\NormalTok{**bold** for strong emphasis}
\NormalTok{***bold italics*** for very strong emphasis}
\NormalTok{\textasciitilde{}\textasciitilde{}strikethrough\textasciitilde{}\textasciitilde{} for deleted text}
\CommentTok{[}\OtherTok{highlighted text}\CommentTok{]}\NormalTok{\{.mark\}}
\CommentTok{[}\OtherTok{underlined text}\CommentTok{]}\NormalTok{\{.underline\}}
\CommentTok{[}\OtherTok{small caps}\CommentTok{]}\NormalTok{\{.smallcaps\}}
\InformationTok{\textasciigrave{}inline code\textasciigrave{}}\NormalTok{ in numerous applications}
\end{Highlighting}
\end{Shaded}

\subsection*{Advanced Formatting}\label{advanced-formatting}
\addcontentsline{toc}{subsection}{Advanced Formatting}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{superscript\^{}2\^{} for exponents}
\NormalTok{subscript\textasciitilde{}2\textasciitilde{} for chemical formulas}
\end{Highlighting}
\end{Shaded}

\section*{Links}\label{links}
\addcontentsline{toc}{section}{Links}

\markright{Links}

\texttt{\textless{}https://quarto.org/docs/authoring/markdown-basics.html\textgreater{}}
produces: \url{https://quarto.org/docs/authoring/markdown-basics.html}

\texttt{{[}Quarto\ Book\ Cross-References{]}(https://quarto.org/docs/books/book-crossrefs.html)}
produces:
\href{https://quarto.org/docs/books/book-crossrefs.html}{Quarto Book
Cross-References}

\section*{Including Code}\label{sec-code}
\addcontentsline{toc}{section}{Including Code}

\markright{Including Code}

\begin{figure}

\centering{

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\BuiltInTok{print}\NormalTok{(}\StringTok{"AMTAIR is working!"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
AMTAIR is working!
\end{verbatim}

}

\caption{\label{fig-extraction-pipeline}AMTAIR extraction pipeline
visualization}

\end{figure}%

\section*{Diagrams}\label{diagrams}
\addcontentsline{toc}{section}{Diagrams}

\markright{Diagrams}

Quarto has native support for embedding Mermaid and Graphviz diagrams.
This enables you to create flowcharts, sequence diagrams, state
diagrams, Gantt charts, and more using a plain text syntax inspired by
markdown.

For example, here we embed a flowchart created using Mermaid:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{flowchart LR}
\NormalTok{  A[Hard edge] {-}{-}\textgreater{} B(Round edge)}
\NormalTok{  B {-}{-}\textgreater{} C\{Decision\}}
\NormalTok{  C {-}{-}\textgreater{} D[Result one]}
\NormalTok{  C {-}{-}\textgreater{} E[Result two]}
\end{Highlighting}
\end{Shaded}

\includegraphics[width=6.88in,height=1.81in]{index_files/figure-latex/mermaid-figure-1.png}

\subsection*{In-Line LaTeX}\label{in-line-latex}
\addcontentsline{toc}{subsection}{In-Line LaTeX}

\renewcommand*{\labelitemi}{\textgreater}

\subsection*{In-Line HTML}\label{in-line-html}
\addcontentsline{toc}{subsection}{In-Line HTML}

Here's some raw inline HTML: html

\section*{Reference or Embed Code from .ipynb
files}\label{reference-or-embed-code-from-.ipynb-files}
\addcontentsline{toc}{section}{Reference or Embed Code from .ipynb
files}

\markright{Reference or Embed Code from .ipynb files}

\subsubsection*{Code chunks from .ipynb notebooks can be embedded in the
.qmd text
with:}\label{code-chunks-from-.ipynb-notebooks-can-be-embedded-in-the-.qmd-text-with}
\addcontentsline{toc}{subsubsection}{Code chunks from .ipynb notebooks
can be embedded in the .qmd text with:}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{\{\textless{} embed /AMTAIR\_Prototype/data/example\_carlsmith/AMTAIR\_Prototype\_example\_carlsmith.ipynb\#connect\_to\_github\_repository \textgreater{}\}\}}
\end{Highlighting}
\end{Shaded}

\subsubsection*{which produces the output of executing the code
cell:}\label{which-produces-the-output-of-executing-the-code-cell}
\addcontentsline{toc}{subsubsection}{which produces the output of
executing the code cell:}

\phantomsection\label{connect_to_github_repository}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 0.2.0 {-}{-}{-} Connect to GitHub Repository {-}{-}{-} Load Files [connect\_to\_github\_repository]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Establishes connection to the AMTAIR GitHub repository and provides}
\CommentTok{functions to load example data files for processing.}

\CommentTok{This block creates a reusable function for accessing files from the project\textquotesingle{}s}
\CommentTok{GitHub repository, enabling access to example files like the rain{-}sprinkler{-}lawn}
\CommentTok{Bayesian network that serves as our canonical test case.}

\CommentTok{DEPENDENCIES: requests library, io library}
\CommentTok{OUTPUTS: load\_file\_from\_repo function and test file loads}
\CommentTok{"""}

\ImportTok{from}\NormalTok{ requests.exceptions }\ImportTok{import}\NormalTok{ HTTPError}

\CommentTok{\# Specify the base repository URL for the AMTAIR project}
\NormalTok{repo\_url }\OperatorTok{=} \StringTok{"https://raw.githubusercontent.com/SingularitySmith/AMTAIR\_Prototype/main/data/example\_carlsmith/"}
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Connecting to repository: }\SpecialCharTok{\{}\NormalTok{repo\_url}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

\KeywordTok{def}\NormalTok{ load\_file\_from\_repo(relative\_path):}
    \CommentTok{"""}
\CommentTok{    Loads a file from the specified GitHub repository using a relative path.}

\CommentTok{    Args:}
\CommentTok{        relative\_path (str): Path to the file relative to the repo\_url}

\CommentTok{    Returns:}
\CommentTok{        For CSV/JSON: pandas DataFrame}
\CommentTok{        For MD: string containing file contents}

\CommentTok{    Raises:}
\CommentTok{        HTTPError: If file not found or other HTTP error occurs}
\CommentTok{        ValueError: If unsupported file type is requested}
\CommentTok{    """}
\NormalTok{    file\_url }\OperatorTok{=}\NormalTok{ repo\_url }\OperatorTok{+}\NormalTok{ relative\_path}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Attempting to load: }\SpecialCharTok{\{}\NormalTok{file\_url}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

    \CommentTok{\# Fetch the file content from GitHub}
\NormalTok{    response }\OperatorTok{=}\NormalTok{ requests.get(file\_url)}

    \CommentTok{\# Check for bad status codes with enhanced error messages}
    \ControlFlowTok{if}\NormalTok{ response.status\_code }\OperatorTok{==} \DecValTok{404}\NormalTok{:}
        \ControlFlowTok{raise}\NormalTok{ HTTPError(}\SpecialStringTok{f"File not found at URL: }\SpecialCharTok{\{}\NormalTok{file\_url}\SpecialCharTok{\}}\SpecialStringTok{. Check the file path/name and ensure the file is publicly accessible."}\NormalTok{, response}\OperatorTok{=}\NormalTok{response)}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        response.raise\_for\_status()  }\CommentTok{\# Raise for other error codes}

    \CommentTok{\# Convert response to file{-}like object}
\NormalTok{    file\_object }\OperatorTok{=}\NormalTok{ io.StringIO(response.text)}

    \CommentTok{\# Process different file types appropriately}
    \ControlFlowTok{if}\NormalTok{ relative\_path.endswith(}\StringTok{".csv"}\NormalTok{):}
        \ControlFlowTok{return}\NormalTok{ pd.read\_csv(file\_object)  }\CommentTok{\# Return DataFrame for CSV}
    \ControlFlowTok{elif}\NormalTok{ relative\_path.endswith(}\StringTok{".json"}\NormalTok{):}
        \ControlFlowTok{return}\NormalTok{ pd.read\_json(file\_object)  }\CommentTok{\# Return DataFrame for JSON}
    \ControlFlowTok{elif}\NormalTok{ relative\_path.endswith(}\StringTok{".md"}\NormalTok{):}
        \ControlFlowTok{return}\NormalTok{ file\_object.read()  }\CommentTok{\# Return raw content for MD files}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{(}\SpecialStringTok{f"Unsupported file type: }\SpecialCharTok{\{}\NormalTok{relative\_path}\SpecialCharTok{.}\NormalTok{split(}\StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{)[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{. Add support in the GitHub Connection section of this notebook."}\NormalTok{)}

\CommentTok{\# Load example files to test connection}
\ControlFlowTok{try}\NormalTok{:}
    \CommentTok{\# Load the extracted data CSV file}
\CommentTok{\#    df = load\_file\_from\_repo("extracted\_data.csv")}

    \CommentTok{\# Load the ArgDown test text}
\NormalTok{    md\_content }\OperatorTok{=}\NormalTok{ load\_file\_from\_repo(}\StringTok{"ArgDown.md"}\NormalTok{)}

    \BuiltInTok{print}\NormalTok{(}\StringTok{"✅ Successfully connected to repository and loaded test files."}\NormalTok{)}
\ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"❌ Error loading files: }\SpecialCharTok{\{}\BuiltInTok{str}\NormalTok{(e)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Please check your internet connection and the repository URL."}\NormalTok{)}

\CommentTok{\# Display preview of loaded content (commented out to avoid cluttering output)}
\BuiltInTok{print}\NormalTok{(md\_content)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Connecting to repository: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/
Attempting to load: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/ArgDown.md
✅ Successfully connected to repository and loaded test files.
[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {"instantiations": ["existential_catastrophe_TRUE", "existential_catastrophe_FALSE"]}
- [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {"instantiations": ["human_disempowerment_TRUE", "human_disempowerment_FALSE"]}
    - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {"instantiations": ["scale_of_power_seeking_TRUE", "scale_of_power_seeking_FALSE"]}
        - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}
            - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {"instantiations": ["aps_systems_TRUE", "aps_systems_FALSE"]}
                - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {"instantiations": ["advanced_ai_capability_TRUE", "advanced_ai_capability_FALSE"]}
                - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {"instantiations": ["agentic_planning_TRUE", "agentic_planning_FALSE"]}
                - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {"instantiations": ["strategic_awareness_TRUE", "strategic_awareness_FALSE"]}
            - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {"instantiations": ["difficulty_of_alignment_TRUE", "difficulty_of_alignment_FALSE"]}
                - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {"instantiations": ["instrumental_convergence_TRUE", "instrumental_convergence_FALSE"]}
                - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {"instantiations": ["problems_with_proxies_TRUE", "problems_with_proxies_FALSE"]}
                - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {"instantiations": ["problems_with_search_TRUE", "problems_with_search_FALSE"]}
            - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {"instantiations": ["deployment_decisions_DEPLOY", "deployment_decisions_WITHHOLD"]}
                - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {"instantiations": ["incentives_to_build_aps_STRONG", "incentives_to_build_aps_WEAK"]}
                    - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {"instantiations": ["usefulness_of_aps_HIGH", "usefulness_of_aps_LOW"]}
                    - [Competitive_Dynamics]: Competitive pressures between AI developers. {"instantiations": ["competitive_dynamics_STRONG", "competitive_dynamics_WEAK"]}
                - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {"instantiations": ["deception_by_ai_TRUE", "deception_by_ai_FALSE"]}
        - [Corrective_Feedback]: Human society implementing corrections after observing problems. {"instantiations": ["corrective_feedback_EFFECTIVE", "corrective_feedback_INEFFECTIVE"]}
            - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {"instantiations": ["warning_shots_OBSERVED", "warning_shots_UNOBSERVED"]}
            - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {"instantiations": ["rapid_capability_escalation_TRUE", "rapid_capability_escalation_FALSE"]}
[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {"instantiations": ["barriers_to_understanding_HIGH", "barriers_to_understanding_LOW"]}
- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}
[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {"instantiations": ["adversarial_dynamics_TRUE", "adversarial_dynamics_FALSE"]}
- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}
[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {"instantiations": ["stakes_of_error_HIGH", "stakes_of_error_LOW"]}
- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}
\end{verbatim}

\subsubsection*{including `echo=true' renders the code of the
cell:}\label{including-echotrue-renders-the-code-of-the-cell}
\addcontentsline{toc}{subsubsection}{including `echo=true' renders the
code of the cell:}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{\{\textless{} embed /AMTAIR\_Prototype/data/example\_carlsmith/AMTAIR\_Prototype\_example\_carlsmith.ipynb\#connect\_to\_github\_repository echo=true \textgreater{}\}\}}
\end{Highlighting}
\end{Shaded}

\phantomsection\label{connect_to_github_repository}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 0.2.0 {-}{-}{-} Connect to GitHub Repository {-}{-}{-} Load Files [connect\_to\_github\_repository]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Establishes connection to the AMTAIR GitHub repository and provides}
\CommentTok{functions to load example data files for processing.}

\CommentTok{This block creates a reusable function for accessing files from the project\textquotesingle{}s}
\CommentTok{GitHub repository, enabling access to example files like the rain{-}sprinkler{-}lawn}
\CommentTok{Bayesian network that serves as our canonical test case.}

\CommentTok{DEPENDENCIES: requests library, io library}
\CommentTok{OUTPUTS: load\_file\_from\_repo function and test file loads}
\CommentTok{"""}

\ImportTok{from}\NormalTok{ requests.exceptions }\ImportTok{import}\NormalTok{ HTTPError}

\CommentTok{\# Specify the base repository URL for the AMTAIR project}
\NormalTok{repo\_url }\OperatorTok{=} \StringTok{"https://raw.githubusercontent.com/SingularitySmith/AMTAIR\_Prototype/main/data/example\_carlsmith/"}
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Connecting to repository: }\SpecialCharTok{\{}\NormalTok{repo\_url}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

\KeywordTok{def}\NormalTok{ load\_file\_from\_repo(relative\_path):}
    \CommentTok{"""}
\CommentTok{    Loads a file from the specified GitHub repository using a relative path.}

\CommentTok{    Args:}
\CommentTok{        relative\_path (str): Path to the file relative to the repo\_url}

\CommentTok{    Returns:}
\CommentTok{        For CSV/JSON: pandas DataFrame}
\CommentTok{        For MD: string containing file contents}

\CommentTok{    Raises:}
\CommentTok{        HTTPError: If file not found or other HTTP error occurs}
\CommentTok{        ValueError: If unsupported file type is requested}
\CommentTok{    """}
\NormalTok{    file\_url }\OperatorTok{=}\NormalTok{ repo\_url }\OperatorTok{+}\NormalTok{ relative\_path}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Attempting to load: }\SpecialCharTok{\{}\NormalTok{file\_url}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

    \CommentTok{\# Fetch the file content from GitHub}
\NormalTok{    response }\OperatorTok{=}\NormalTok{ requests.get(file\_url)}

    \CommentTok{\# Check for bad status codes with enhanced error messages}
    \ControlFlowTok{if}\NormalTok{ response.status\_code }\OperatorTok{==} \DecValTok{404}\NormalTok{:}
        \ControlFlowTok{raise}\NormalTok{ HTTPError(}\SpecialStringTok{f"File not found at URL: }\SpecialCharTok{\{}\NormalTok{file\_url}\SpecialCharTok{\}}\SpecialStringTok{. Check the file path/name and ensure the file is publicly accessible."}\NormalTok{, response}\OperatorTok{=}\NormalTok{response)}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        response.raise\_for\_status()  }\CommentTok{\# Raise for other error codes}

    \CommentTok{\# Convert response to file{-}like object}
\NormalTok{    file\_object }\OperatorTok{=}\NormalTok{ io.StringIO(response.text)}

    \CommentTok{\# Process different file types appropriately}
    \ControlFlowTok{if}\NormalTok{ relative\_path.endswith(}\StringTok{".csv"}\NormalTok{):}
        \ControlFlowTok{return}\NormalTok{ pd.read\_csv(file\_object)  }\CommentTok{\# Return DataFrame for CSV}
    \ControlFlowTok{elif}\NormalTok{ relative\_path.endswith(}\StringTok{".json"}\NormalTok{):}
        \ControlFlowTok{return}\NormalTok{ pd.read\_json(file\_object)  }\CommentTok{\# Return DataFrame for JSON}
    \ControlFlowTok{elif}\NormalTok{ relative\_path.endswith(}\StringTok{".md"}\NormalTok{):}
        \ControlFlowTok{return}\NormalTok{ file\_object.read()  }\CommentTok{\# Return raw content for MD files}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{(}\SpecialStringTok{f"Unsupported file type: }\SpecialCharTok{\{}\NormalTok{relative\_path}\SpecialCharTok{.}\NormalTok{split(}\StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{)[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{. Add support in the GitHub Connection section of this notebook."}\NormalTok{)}

\CommentTok{\# Load example files to test connection}
\ControlFlowTok{try}\NormalTok{:}
    \CommentTok{\# Load the extracted data CSV file}
\CommentTok{\#    df = load\_file\_from\_repo("extracted\_data.csv")}

    \CommentTok{\# Load the ArgDown test text}
\NormalTok{    md\_content }\OperatorTok{=}\NormalTok{ load\_file\_from\_repo(}\StringTok{"ArgDown.md"}\NormalTok{)}

    \BuiltInTok{print}\NormalTok{(}\StringTok{"✅ Successfully connected to repository and loaded test files."}\NormalTok{)}
\ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"❌ Error loading files: }\SpecialCharTok{\{}\BuiltInTok{str}\NormalTok{(e)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Please check your internet connection and the repository URL."}\NormalTok{)}

\CommentTok{\# Display preview of loaded content (commented out to avoid cluttering output)}
\BuiltInTok{print}\NormalTok{(md\_content)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Connecting to repository: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/
Attempting to load: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/ArgDown.md
✅ Successfully connected to repository and loaded test files.
[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {"instantiations": ["existential_catastrophe_TRUE", "existential_catastrophe_FALSE"]}
- [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {"instantiations": ["human_disempowerment_TRUE", "human_disempowerment_FALSE"]}
    - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {"instantiations": ["scale_of_power_seeking_TRUE", "scale_of_power_seeking_FALSE"]}
        - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}
            - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {"instantiations": ["aps_systems_TRUE", "aps_systems_FALSE"]}
                - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {"instantiations": ["advanced_ai_capability_TRUE", "advanced_ai_capability_FALSE"]}
                - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {"instantiations": ["agentic_planning_TRUE", "agentic_planning_FALSE"]}
                - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {"instantiations": ["strategic_awareness_TRUE", "strategic_awareness_FALSE"]}
            - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {"instantiations": ["difficulty_of_alignment_TRUE", "difficulty_of_alignment_FALSE"]}
                - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {"instantiations": ["instrumental_convergence_TRUE", "instrumental_convergence_FALSE"]}
                - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {"instantiations": ["problems_with_proxies_TRUE", "problems_with_proxies_FALSE"]}
                - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {"instantiations": ["problems_with_search_TRUE", "problems_with_search_FALSE"]}
            - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {"instantiations": ["deployment_decisions_DEPLOY", "deployment_decisions_WITHHOLD"]}
                - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {"instantiations": ["incentives_to_build_aps_STRONG", "incentives_to_build_aps_WEAK"]}
                    - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {"instantiations": ["usefulness_of_aps_HIGH", "usefulness_of_aps_LOW"]}
                    - [Competitive_Dynamics]: Competitive pressures between AI developers. {"instantiations": ["competitive_dynamics_STRONG", "competitive_dynamics_WEAK"]}
                - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {"instantiations": ["deception_by_ai_TRUE", "deception_by_ai_FALSE"]}
        - [Corrective_Feedback]: Human society implementing corrections after observing problems. {"instantiations": ["corrective_feedback_EFFECTIVE", "corrective_feedback_INEFFECTIVE"]}
            - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {"instantiations": ["warning_shots_OBSERVED", "warning_shots_UNOBSERVED"]}
            - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {"instantiations": ["rapid_capability_escalation_TRUE", "rapid_capability_escalation_FALSE"]}
[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {"instantiations": ["barriers_to_understanding_HIGH", "barriers_to_understanding_LOW"]}
- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}
[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {"instantiations": ["adversarial_dynamics_TRUE", "adversarial_dynamics_FALSE"]}
- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}
[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {"instantiations": ["stakes_of_error_HIGH", "stakes_of_error_LOW"]}
- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}
\end{verbatim}

Link:

Full Notebooks are embedded in the Appendix through the \_quarto.yml
file with:

\section*{Embed .html result/rendering from .ipynb
Notebook}\label{embed-.html-resultrendering-from-.ipynb-notebook}
\addcontentsline{toc}{section}{Embed .html result/rendering from .ipynb
Notebook}

\markright{Embed .html result/rendering from .ipynb Notebook}

\subsection*{Html Graph by Notebook Cell Inclusion - (from
github-pages)}\label{html-graph-by-notebook-cell-inclusion---from-github-pages}
\addcontentsline{toc}{subsection}{Html Graph by Notebook Cell Inclusion
- (from github-pages)}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{\{\textless{} embed /AMTAIR\_Prototype/data/example\_carlsmith/AMTAIR\_Prototype\_example\_carlsmith.ipynb\#html\_graph\_visualization\_from\_githubpage echo=true \textgreater{}\}\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ IPython.display }\ImportTok{import}\NormalTok{ IFrame}

\NormalTok{IFrame(src}\OperatorTok{=}\StringTok{"https://singularitysmith.github.io/AMTAIR\_Prototype/bayesian\_network\_carlsmith.html"}\NormalTok{, width}\OperatorTok{=}\StringTok{"100\%"}\NormalTok{, height}\OperatorTok{=}\StringTok{"600px"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\phantomsection\label{html_graph_visualization_from_githubpage}
\begin{verbatim}
<IPython.lib.display.IFrame at 0x7f04d69f0d90>
\end{verbatim}

Dynamic Html Rendering of the Carlsmith Bayesian Network/DAG
Visualization

\subsection*{Html Graph by Notebook Cell Inclusion with Website
Call?}\label{html-graph-by-notebook-cell-inclusion-with-website-call}
\addcontentsline{toc}{subsection}{Html Graph by Notebook Cell Inclusion
with Website Call?}

https://singularitysmith.github.io/AMTAIR\_Prototype/bayesian\_network\_carlsmith.html

\subsection*{Full Bayesian Network
Rendering}\label{full-bayesian-network-rendering}
\addcontentsline{toc}{subsection}{Full Bayesian Network Rendering}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{\{\textless{} embed /AMTAIR\_Prototype/data/example\_carlsmith/AMTAIR\_Prototype\_example\_carlsmith.ipynb\#html\_graph\_visualization\_from\_githubpage  echo=true \textgreater{}\}\}}
\end{Highlighting}
\end{Shaded}

\subsection*{Rain-Sprinkler-Grass Network
Rendering}\label{rain-sprinkler-grass-network-rendering}
\addcontentsline{toc}{subsection}{Rain-Sprinkler-Grass Network
Rendering}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ IPython.display }\ImportTok{import}\NormalTok{ IFrame}

\NormalTok{IFrame(src}\OperatorTok{=}\StringTok{"https://singularitysmith.github.io/AMTAIR\_Prototype/bayesian\_network.html"}\NormalTok{, width}\OperatorTok{=}\StringTok{"100\%"}\NormalTok{, height}\OperatorTok{=}\StringTok{"600px"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\phantomsection\label{rain_sprinkler_grass_example_network_rendering}
\begin{verbatim}
<IPython.lib.display.IFrame at 0x106661a90>
\end{verbatim}

Dynamic Html Rendering of the Rain-Sprinkler-Grass DAG

\section*{Lists and Enumerations}\label{lists-and-enumerations}
\addcontentsline{toc}{section}{Lists and Enumerations}

\markright{Lists and Enumerations}

\subsection*{Unordered Lists}\label{unordered-lists}
\addcontentsline{toc}{subsection}{Unordered Lists}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\SpecialStringTok{{-} }\NormalTok{First level item}
\SpecialStringTok{  {-} }\NormalTok{Second level item (2 spaces)}
\SpecialStringTok{    {-} }\NormalTok{Third level item (4 spaces)}
\SpecialStringTok{{-} }\NormalTok{Another first level item}
\NormalTok{  with continuation (2 spaces for alignment)}
\end{Highlighting}
\end{Shaded}

\subsection*{Ordered Lists}\label{ordered-lists}
\addcontentsline{toc}{subsection}{Ordered Lists}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\SpecialStringTok{1. }\NormalTok{First item}
\SpecialStringTok{2. }\NormalTok{Second item}
\NormalTok{   a) Sub{-}item (3 spaces)}
\NormalTok{      i. Sub{-}sub{-}item (6 spaces)}
\NormalTok{   b) Another sub{-}item}
\SpecialStringTok{3. }\NormalTok{Third item}
\end{Highlighting}
\end{Shaded}

\subsection*{Definition Lists}\label{definition-lists}
\addcontentsline{toc}{subsection}{Definition Lists}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Term One}
\NormalTok{: Definition of term one with detailed explanation}
\NormalTok{  that can span multiple lines}

\NormalTok{Term Two}
\NormalTok{: Brief definition}

\NormalTok{Term Three}
\NormalTok{: Another definition with multiple paragraphs}

\NormalTok{  Additional paragraph for term three}
\end{Highlighting}
\end{Shaded}

\section*{Code Blocks and Verbatim
Text}\label{code-blocks-and-verbatim-text}
\addcontentsline{toc}{section}{Code Blocks and Verbatim Text}

\markright{Code Blocks and Verbatim Text}

\subsection*{Inline Code}\label{inline-code}
\addcontentsline{toc}{subsection}{Inline Code}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Use }\InformationTok{\textasciigrave{}print("Hello")\textasciigrave{}}\NormalTok{ for inline code}
\end{Highlighting}
\end{Shaded}

\subsection*{Code Blocks with Syntax
Highlighting}\label{code-blocks-with-syntax-highlighting}
\addcontentsline{toc}{subsection}{Code Blocks with Syntax Highlighting}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}python}
\KeywordTok{def}\NormalTok{ calculate\_risk(probability, impact):}
    \CommentTok{"""Calculate risk score from probability and impact."""}
    \ControlFlowTok{return}\NormalTok{ probability }\OperatorTok{*}\NormalTok{ impact}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

\subsection*{Verbatim Text}\label{verbatim-text}
\addcontentsline{toc}{subsection}{Verbatim Text}

markdown

This is verbatim text that preserves all spacing and formatting exactly
as typed

\section*{Blockquotes and Callouts}\label{blockquotes-and-callouts}
\addcontentsline{toc}{section}{Blockquotes and Callouts}

\markright{Blockquotes and Callouts}

\subsection*{Simple Blockquote}\label{simple-blockquote}
\addcontentsline{toc}{subsection}{Simple Blockquote}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\AttributeTok{\textgreater{} This is a blockquote for citations or important quotes.}
\AttributeTok{\textgreater{} It can span multiple lines.}
\AttributeTok{\textgreater{}}
\AttributeTok{\textgreater{} And include multiple paragraphs.}
\end{Highlighting}
\end{Shaded}

\subsection*{Callout Blocks}\label{callout-blocks}
\addcontentsline{toc}{subsection}{Callout Blocks}

! With Callout blocks it is crucial to always have a line break after
the title and the \texttt{:::} in a new line after the note ! markdown

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{::: \{.callout{-}note\}}
\FunctionTok{\#\# Note Title}
\NormalTok{This is a note callout with important information.}
\NormalTok{:::}

\NormalTok{::: \{.callout{-}warning\}}
\FunctionTok{\#\# Warning}
\NormalTok{This warns about potential issues.}
\NormalTok{:::}

\NormalTok{::: \{.callout{-}tip\}}
\FunctionTok{\#\# Pro Tip}
\NormalTok{Helpful suggestions go here.}
\NormalTok{:::}

\NormalTok{::: \{.callout{-}important\}}
\FunctionTok{\#\# Important}
\NormalTok{Critical information that must not be missed.}
\NormalTok{:::}

\NormalTok{::: \{.callout{-}caution\}}
\FunctionTok{\#\# Caution}
\NormalTok{Use with care in specific situations.}
\NormalTok{:::}
\end{Highlighting}
\end{Shaded}

\section*{Figures and Images}\label{figures-and-images}
\addcontentsline{toc}{section}{Figures and Images}

\markright{Figures and Images}

\subsection*{Complete Figure Syntax}\label{complete-figure-syntax}
\addcontentsline{toc}{subsection}{Complete Figure Syntax}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{[}\OtherTok{![Figure Caption for Display}\CommentTok{](/path/to/image.png)}\NormalTok{\{}
\NormalTok{  \#fig{-}unique{-}identifier}
\NormalTok{  fig{-}scap="Short caption for list of figures"}
\NormalTok{  fig{-}alt="Detailed description for accessibility.}
\NormalTok{          TYPE: }\CommentTok{[}\OtherTok{Chart/Diagram/Photo/etc.}\CommentTok{]}
\NormalTok{          DATA: }\CommentTok{[}\OtherTok{What data is shown, axes, units}\CommentTok{]}
\NormalTok{          PURPOSE: }\CommentTok{[}\OtherTok{Why included, what to observe}\CommentTok{]}
\NormalTok{          DETAILS: }\CommentTok{[}\OtherTok{Key patterns, insights, anomalies}\CommentTok{]}
\NormalTok{          SOURCE: }\CommentTok{[}\OtherTok{Citation or data source}\CommentTok{]}\NormalTok{"}
\NormalTok{  fig{-}align="center"}
\NormalTok{  width="80\%"}
\NormalTok{\}](https://optional{-}link{-}url.com)}
\end{Highlighting}
\end{Shaded}

\subsection*{Figure Best Practices}\label{figure-best-practices}
\addcontentsline{toc}{subsection}{Figure Best Practices}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Always include comprehensive alt text
\item
  Use descriptive filenames
\item
  Optimize image sizes for web/PDF
\item
  Maintain consistent styling
\item
  Reference all figures in text: \texttt{See\ @fig-identifier}
\end{enumerate}

\section*{Tables}\label{tables}
\addcontentsline{toc}{section}{Tables}

\markright{Tables}

\subsection*{Markdown Tables}\label{markdown-tables}
\addcontentsline{toc}{subsection}{Markdown Tables}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{|}\NormalTok{ Column 1 }\PreprocessorTok{|}\NormalTok{ Column 2 }\PreprocessorTok{|}\NormalTok{ Column 3 }\PreprocessorTok{|}
\PreprocessorTok{|{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}|:{-}{-}{-}{-}{-}{-}{-}{-}:|{-}{-}{-}{-}{-}{-}{-}{-}:|}
\PreprocessorTok{|}\NormalTok{ Left     }\PreprocessorTok{|}\NormalTok{ Center   }\PreprocessorTok{|}\NormalTok{ Right   }\PreprocessorTok{|}
\PreprocessorTok{|}\NormalTok{ Data     }\PreprocessorTok{|}\NormalTok{ Data     }\PreprocessorTok{|}\NormalTok{ Data    }\PreprocessorTok{|}

\NormalTok{: Table caption \{\#tbl{-}identifier\}}
\end{Highlighting}
\end{Shaded}

\subsection*{Grid Tables}\label{grid-tables}
\addcontentsline{toc}{subsection}{Grid Tables}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{+{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}+{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}+{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}+}
\PreprocessorTok{|}\NormalTok{ Header 1 }\PreprocessorTok{|}\NormalTok{ Header 2 }\PreprocessorTok{|}\NormalTok{ Header 3 }\PreprocessorTok{|}
\NormalTok{+========}\AlertTok{==+==========+==}\NormalTok{========+}
\PreprocessorTok{|}\NormalTok{ Cell 1   }\PreprocessorTok{|}\NormalTok{ Cell 2   }\PreprocessorTok{|}\NormalTok{ Cell 3   }\PreprocessorTok{|}
\PreprocessorTok{|}          \PreprocessorTok{|}          \PreprocessorTok{|}          \PreprocessorTok{|}
\PreprocessorTok{|}\NormalTok{ Multi{-}   }\PreprocessorTok{|}\NormalTok{ Multi{-}   }\PreprocessorTok{|}\NormalTok{ Multi{-}   }\PreprocessorTok{|}
\PreprocessorTok{|}\NormalTok{ line     }\PreprocessorTok{|}\NormalTok{ line     }\PreprocessorTok{|}\NormalTok{ line     }\PreprocessorTok{|}
\NormalTok{+{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}+{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}+{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}+}

\NormalTok{: Complex table with multiple lines \{\#tbl{-}complex\}}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}rllc@{}}
\caption{Demonstration of pipe table
syntax}\label{tbl-letters}\tabularnewline
\toprule\noalign{}
Right & Left & Default & Center \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Right & Left & Default & Center \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
12 & 12 & 12 & 12 \\
123 & 123 & 123 & 123 \\
1 & 1 & 1 & 1 \\
\end{longtable}

\begin{longtable}[]{@{}lll@{}}
\caption{My Caption 1}\label{tbl-letters}\tabularnewline
\toprule\noalign{}
Col1 & Col2 & Col3 \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Col1 & Col2 & Col3 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A & B & C \\
E & F & G \\
A & G & G \\
\end{longtable}

Referencing tables with \texttt{@tbl-KEY}: See Table~\ref{tbl-letters}.

\begin{table}

\caption{\label{tbl-panel}Main Caption}

\begin{minipage}{0.50\linewidth}

\subcaption{\label{tbl-first}First Table}

\centering{

\begin{tabular}{lll}
\toprule
Col1 & Col2 & Col3\\
\midrule
A & B & C\\
E & F & G\\
A & G & G\\
\bottomrule
\end{tabular}

}

\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\subcaption{\label{tbl-second}Second Table}

\centering{

\begin{tabular}{lll}
\toprule
Col1 & Col2 & Col3\\
\midrule
A & B & C\\
E & F & G\\
A & G & G\\
\bottomrule
\end{tabular}

}

\end{minipage}%

\end{table}%

See Table~\ref{tbl-panel} for details, especially
Table~\ref{tbl-second}.

\section*{Citations and References}\label{citations-and-references}
\addcontentsline{toc}{section}{Citations and References}

\markright{Citations and References}

\subsection*{Citation Styles}\label{citation-styles}
\addcontentsline{toc}{subsection}{Citation Styles}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\AnnotationTok{Narrative:}\CommentTok{ @author2024 argues that...}
\AnnotationTok{Parenthetical:}\CommentTok{ This is supported by evidence [@author2024].}
\AnnotationTok{Multiple:}\CommentTok{ Several studies confirm this [@author2024; @other2023].}
\AnnotationTok{Page specific:}\CommentTok{ See discussion in [@author2024, pp. 45{-}67].}
\AnnotationTok{Author only:}\CommentTok{ As [{-}@author2024] demonstrates...}
\end{Highlighting}
\end{Shaded}

\subsection*{Bibliography Entry}\label{bibliography-entry}
\addcontentsline{toc}{subsection}{Bibliography Entry}

bibtex

\begin{Shaded}
\begin{Highlighting}[]
\VariableTok{@article}\NormalTok{\{}\OtherTok{author2024}\NormalTok{,}
  \DataTypeTok{title}\NormalTok{ = \{Article Title\},}
  \DataTypeTok{author}\NormalTok{ = \{Author, First and Other, Second\},}
  \DataTypeTok{date}\NormalTok{ = \{2024\},}
  \DataTypeTok{journaltitle}\NormalTok{ = \{Journal Name\},}
  \DataTypeTok{volume}\NormalTok{ = \{10\},}
  \DataTypeTok{number}\NormalTok{ = \{2\},}
  \DataTypeTok{pages}\NormalTok{ = \{45{-}{-}67\},}
  \DataTypeTok{doi}\NormalTok{ = \{10.1234/example\},}
  \DataTypeTok{url}\NormalTok{ = \{https://example.com\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\section*{Cross-References}\label{cross-references}
\addcontentsline{toc}{section}{Cross-References}

\markright{Cross-References}

\subsection*{Section References}\label{section-references}
\addcontentsline{toc}{subsection}{Section References}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{See @sec{-}introduction for background.}
\NormalTok{As discussed in @sec{-}methodology...}
\end{Highlighting}
\end{Shaded}

\subsection*{Figure and Table
References}\label{figure-and-table-references}
\addcontentsline{toc}{subsection}{Figure and Table References}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{@fig{-}pipeline shows the workflow.}
\NormalTok{Results are summarized in @tbl{-}results.}
\end{Highlighting}
\end{Shaded}

\subsection*{Equation References}\label{equation-references}
\addcontentsline{toc}{subsection}{Equation References}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{$$}
\NormalTok{E = mc\^{}2}
\NormalTok{$$ \{\#eq{-}einstein\}}

\NormalTok{Einstein\textquotesingle{}s equation (@eq{-}einstein) shows...}
\end{Highlighting}
\end{Shaded}

\section*{Mathematics}\label{mathematics}
\addcontentsline{toc}{section}{Mathematics}

\markright{Mathematics}

\subsection*{Inline Math}\label{inline-math}
\addcontentsline{toc}{subsection}{Inline Math}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{The probability $P(A|B) = \textbackslash{}frac\{P(B|A)P(A)\}\{P(B)\}$}
\end{Highlighting}
\end{Shaded}

\subsection*{Display Math}\label{display-math}
\addcontentsline{toc}{subsection}{Display Math}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{$$}
\NormalTok{\textbackslash{}begin\{align\}}
\NormalTok{\textbackslash{}nabla \textbackslash{}times \textbackslash{}vec\{\textbackslash{}mathbf\{B\}\} {-}\textbackslash{}, \textbackslash{}frac1c\textbackslash{}, \textbackslash{}frac\{\textbackslash{}partial\textbackslash{}vec\{\textbackslash{}mathbf\{E\}\}\}\{\textbackslash{}partial t\} \&= \textbackslash{}frac\{4\textbackslash{}pi\}\{c\}\textbackslash{}vec\{\textbackslash{}mathbf\{j\}\} }\SpecialCharTok{\textbackslash{}\textbackslash{}}
\NormalTok{\textbackslash{}nabla \textbackslash{}cdot \textbackslash{}vec\{\textbackslash{}mathbf\{E\}\} \&= 4 \textbackslash{}pi \textbackslash{}rho }\SpecialCharTok{\textbackslash{}\textbackslash{}}
\NormalTok{\textbackslash{}nabla \textbackslash{}times \textbackslash{}vec\{\textbackslash{}mathbf\{E\}\}\textbackslash{}, +\textbackslash{}, \textbackslash{}frac1c\textbackslash{}, \textbackslash{}frac\{\textbackslash{}partial\textbackslash{}vec\{\textbackslash{}mathbf\{B\}\}\}\{\textbackslash{}partial t\} \&= \textbackslash{}vec\{\textbackslash{}mathbf\{0\}\} }\SpecialCharTok{\textbackslash{}\textbackslash{}}
\NormalTok{\textbackslash{}nabla \textbackslash{}cdot \textbackslash{}vec\{\textbackslash{}mathbf\{B\}\} \&= 0}
\NormalTok{\textbackslash{}end\{align\}}
\NormalTok{$$}
\end{Highlighting}
\end{Shaded}

inline math: \(E = mc^{2}\)

display math:

\[E = mc^{2}\]

If you want to define custom TeX macros, include them within \$\$
delimiters enclosed in a .hidden block. For example:

\[
 \def\RR{{\bf R}}
 \def\bold#1{{\bf #1}}
\]

For HTML math processed using MathJax (the default) you can use the
\textbackslash def, \textbackslash newcommand,
\textbackslash renewcommand, \textbackslash newenvironment,
\textbackslash renewenvironment, and \textbackslash let commands to
create your own macros and environments.

\section*{Footnotes}\label{footnotes}
\addcontentsline{toc}{section}{Footnotes}

\markright{Footnotes}

Footnotes are to be used as much as possible!

\subsection*{Simple Footnote}\label{simple-footnote}
\addcontentsline{toc}{subsection}{Simple Footnote}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{This needs clarification.\^{}}\CommentTok{[}\OtherTok{This is an inline footnote.}\CommentTok{]}
\end{Highlighting}
\end{Shaded}

\subsection*{Referenced Footnote}\label{referenced-footnote}
\addcontentsline{toc}{subsection}{Referenced Footnote}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{This is important.}\OtherTok{[\^{}1]}

\OtherTok{[\^{}1]: }\NormalTok{This is a longer footnote with multiple paragraphs.}

\InformationTok{    Second paragraph of the footnote.}
\InformationTok{    }
\InformationTok{    Even code blocks are possible:}
\InformationTok{    \textasciigrave{}\textasciigrave{}\textasciigrave{}python}
\InformationTok{    print("In footnote")}
\InformationTok{    \textasciigrave{}\textasciigrave{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

Here is an inline note.\footnote{Inlines notes are easier to write,
  since you don't have to pick an identifier and move down to type the
  note.}

Here is a footnote reference,\footnote{Here is the footnote.}

Another Text with a footnote\footnote{Here's one with multiple blocks.

  Subsequent paragraphs are indented to show that they belong to the
  previous footnote.

\begin{Verbatim}
{ some.code }
\end{Verbatim}

  The whole paragraph can be indented, or just the first line. In this
  way, multi-paragraph footnotes work like multi-paragraph list items.}
but this time a ``longnote''.

This paragraph won't be part of the note, because it isn't indented.

\section*{Appendices}\label{appendices}
\addcontentsline{toc}{section}{Appendices}

\markright{Appendices}

\subsection*{Structure}\label{structure}
\addcontentsline{toc}{subsection}{Structure}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\# Appendices \{.unnumbered\}}

\FunctionTok{\#\# Appendix A: Technical Details \{\#sec{-}appendix{-}a .unnumbered\}}

\FunctionTok{\#\#\# A.1 Implementation \{.unnumbered\}}

\FunctionTok{\#\# Appendix B: Additional Results \{\#sec{-}appendix{-}b .unnumbered\}}
\end{Highlighting}
\end{Shaded}

\subsection*{Best Practices for
Appendices}\label{best-practices-for-appendices}
\addcontentsline{toc}{subsection}{Best Practices for Appendices}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Include all supplementary material
\item
  Reference from main text
\item
  Number consistently
\item
  Provide clear descriptions
\item
  Maintain same formatting standards
\end{enumerate}

\section*{Glossary and Abbreviations}\label{glossary-and-abbreviations}
\addcontentsline{toc}{section}{Glossary and Abbreviations}

\markright{Glossary and Abbreviations}

\subsection*{Glossary Format}\label{glossary-format}
\addcontentsline{toc}{subsection}{Glossary Format}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\# Glossary \{.unnumbered\}}
\NormalTok{Term}
\NormalTok{: Definition}


\NormalTok{AI}
\NormalTok{: Artificial Intelligence {-} Computer systems performing tasks requiring human intelligence}

\NormalTok{ML}
\NormalTok{: Machine Learning {-} Algorithms that improve through experience}

\NormalTok{DL}
\NormalTok{: Deep Learning {-} Neural networks with multiple layers}
\end{Highlighting}
\end{Shaded}

\section*{Interactive Elements}\label{interactive-elements}
\addcontentsline{toc}{section}{Interactive Elements}

\markright{Interactive Elements}

\subsection*{Jupyter Notebook
Embedding}\label{jupyter-notebook-embedding}
\addcontentsline{toc}{subsection}{Jupyter Notebook Embedding}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{\{\textless{} embed notebook.ipynb\#cell{-}label \textgreater{}\}\}}
\end{Highlighting}
\end{Shaded}

\subsection*{Mermaid Diagrams}\label{mermaid-diagrams}
\addcontentsline{toc}{subsection}{Mermaid Diagrams}

\begin{Shaded}
\begin{Highlighting}[]
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{mermaid\}}
\NormalTok{graph TD}
\NormalTok{    A[Start] {-}{-}\textgreater{} B\{Decision\}}
\NormalTok{    B {-}{-}\textgreater{}|Yes| C[Action }\DecValTok{1}\NormalTok{]}
\NormalTok{    B {-}{-}\textgreater{}|No| D[Action }\DecValTok{2}\NormalTok{]}
\NormalTok{    C {-}{-}\textgreater{} E[End]}
\NormalTok{    D {-}{-}\textgreater{} E}
\end{Highlighting}
\end{Shaded}

\section*{Line Breaks and Spacing}\label{line-breaks-and-spacing}
\addcontentsline{toc}{section}{Line Breaks and Spacing}

\markright{Line Breaks and Spacing}

\subsection*{Spacing Rules}\label{spacing-rules}
\addcontentsline{toc}{subsection}{Spacing Rules}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Between sections}: 2 blank lines
\item
  \textbf{Between paragraphs}: 1 blank line
\item
  \textbf{Around code blocks}: 1 blank line before and after
\item
  \textbf{Around figures/tables}: 1 blank line before and after
\item
  \textbf{After headings}: 1 blank line
\item
  \textbf{Between list items}: No blank lines unless containing multiple
  paragraphs
\end{enumerate}

\subsection*{Page Breaks}\label{page-breaks}
\addcontentsline{toc}{subsection}{Page Breaks}

\begin{Shaded}
\begin{Highlighting}[]

\end{Highlighting}
\end{Shaded}

\section*{Comments and Metadata}\label{comments-and-metadata}
\addcontentsline{toc}{section}{Comments and Metadata}

\markright{Comments and Metadata}

\subsection*{HTML Comments}\label{html-comments}
\addcontentsline{toc}{subsection}{HTML Comments}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} This is a comment not shown in output {-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\bookmarksetup{startatroot}

\chapter*{Comprehensive Task Management System for Quarto
Thesis}\label{comprehensive-task-management-system-for-quarto-thesis}
\addcontentsline{toc}{chapter}{Comprehensive Task Management System for
Quarto Thesis}

\markboth{Comprehensive Task Management System for Quarto
Thesis}{Comprehensive Task Management System for Quarto Thesis}

\section*{Overview}\label{overview}
\addcontentsline{toc}{section}{Overview}

\markright{Overview}

This task management system uses HTML comments with specific formatting
to create trackable, categorized tasks that integrate with VS Code's
ToDo-Tree extension while remaining invisible or visible depending on
the status in rendered output.

\section*{Task Categories and Syntax}\label{task-categories-and-syntax}
\addcontentsline{toc}{section}{Task Categories and Syntax}

\markright{Task Categories and Syntax}

Write and track tasks with HTML comments in markdown blocks or with
\texttt{verbatim\ code} ticks but ALWAYS add linke breaks between tasks:

\begin{Shaded}
\begin{Highlighting}[]
\InformationTok{\textasciigrave{}\textless{}!{-}{-} [ ] TODO: Task description {-}{-}\textgreater{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textless{}!{-}{-} [ ] FIND: @missing{-}citation: "Description" {-}{-}\textgreater{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textless{}!{-}{-} [ ] VERIFY: @suggested{-}citation: "Source" {-}{-}\textgreater{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textless{}!{-}{-} [ ] CREATE: \{\#fig{-}name\}: "Figure description" {-}{-}\textgreater{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

\subsection*{1. General Tasks}\label{general-tasks}
\addcontentsline{toc}{subsection}{1. General Tasks}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} [ ] }\AlertTok{TODO}\CommentTok{: General task description {-}{-}\textgreater{}}

\CommentTok{\textless{}!{-}{-} [ ] }\AlertTok{TODO}\CommentTok{: High{-}priority task with deadline (2024{-}12{-}31) {-}{-}\textgreater{}}


\CommentTok{\textless{}!{-}{-} [ ] }\AlertTok{TODO}\CommentTok{: Task with subtasks}
\CommentTok{        {-} [ ] Subtask 1}
\CommentTok{        {-} [ ] Subtask 2}
\CommentTok{        {-} [ ] Subtask 3}
\CommentTok{{-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\subsection*{2. Citation Tasks}\label{citation-tasks}
\addcontentsline{toc}{subsection}{2. Citation Tasks}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\InformationTok{\textasciigrave{}\textless{}!{-}{-} [ ] FIND: @missing{-}citation{-}key: "Description of needed source, keywords, search terms" {-}{-}\textgreater{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textless{}!{-}{-} [ ] VERIFY: @suggested{-}citation: "Author (Year). Title. Journal." [Include BibTeX if available] {-}{-}\textgreater{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textless{}!{-}{-} [ ] UPDATE: @outdated{-}citation: "Check for newer edition or updated data" {-}{-}\textgreater{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textless{}!{-}{-} [ ] VERIFIED: @citation: "URL" {-}{-}\textgreater{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

\subsection*{3. Figure/Graphic Tasks}\label{figuregraphic-tasks}
\addcontentsline{toc}{subsection}{3. Figure/Graphic Tasks}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} [ ] CREATE: \{\#fig{-}diagram{-}name\}: "Description of needed diagram, style, data to include" {-}{-}\textgreater{}}

\CommentTok{\textless{}!{-}{-} [ ] FIND: \{\#fig{-}example{-}image\}: "Stock photo of X, preferably showing Y" {-}{-}\textgreater{}}

\CommentTok{\textless{}!{-}{-} [ ] UPDATE: \{\#fig{-}outdated{-}chart\}: "Update with 2024 data" {-}{-}\textgreater{}}

\CommentTok{\textless{}!{-}{-} [ ] IMPROVE: \{\#fig{-}low{-}quality\}: "Higher resolution version needed" {-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\subsection*{4. Content Tasks}\label{content-tasks}
\addcontentsline{toc}{subsection}{4. Content Tasks}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} [ ] WRITE: Section 3.2 {-} Methodology details {-}{-}\textgreater{}}

\CommentTok{\textless{}!{-}{-} [ ] EXPAND: Background section needs 500 more words {-}{-}\textgreater{}}

\CommentTok{\textless{}!{-}{-} [ ] REVISE: Introduction for clarity and flow {-}{-}\textgreater{}}

\CommentTok{\textless{}!{-}{-} [ ] REVIEW: Chapter 4 for consistency {-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\subsection*{5. Technical Tasks}\label{technical-tasks}
\addcontentsline{toc}{subsection}{5. Technical Tasks}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} [ ] FIX: Code block in section 2.3 has syntax error {-}{-}\textgreater{}}

\CommentTok{\textless{}!{-}{-} [ ] }\AlertTok{TEST}\CommentTok{: Jupyter notebook embedding {-}{-}\textgreater{}}

\CommentTok{\textless{}!{-}{-} [ ] OPTIMIZE: Large figure file sizes {-}{-}\textgreater{}}

\CommentTok{\textless{}!{-}{-} [ ] IMPLEMENT: Cross{-}reference checking script {-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\section*{Task States}\label{task-states}
\addcontentsline{toc}{section}{Task States}

\markright{Task States}

\subsection*{Open or In-ProgressTasks}\label{open-or-in-progresstasks}
\addcontentsline{toc}{subsection}{Open or In-ProgressTasks}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} [ ] Task description {-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\subsection*{Completed Tasks (Visible in
ToDo-Tree)}\label{completed-tasks-visible-in-todo-tree}
\addcontentsline{toc}{subsection}{Completed Tasks (Visible in
ToDo-Tree)}

Either markdown blocks or \texttt{verbatim\ code} ticks or without (to
remain hidden in output):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} [x] Task description (completed 2024{-}01{-}20) {-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\subsection*{Verified/Archived Tasks (Hidden from
ToDo-Tree)}\label{verifiedarchived-tasks-hidden-from-todo-tree}
\addcontentsline{toc}{subsection}{Verified/Archived Tasks (Hidden from
ToDo-Tree)}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} [{-}] Task description (verified and archived) {-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\section*{Advanced Task Formatting}\label{advanced-task-formatting}
\addcontentsline{toc}{section}{Advanced Task Formatting}

\markright{Advanced Task Formatting}

\subsection*{Multi-line Tasks with
Details}\label{multi-line-tasks-with-details}
\addcontentsline{toc}{subsection}{Multi-line Tasks with Details}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} [ ] Major task with extensive details}
\CommentTok{  }
\CommentTok{  Background:}
\CommentTok{  {-} Context for why this task exists}
\CommentTok{  {-} Related issues or dependencies}
\CommentTok{  }
\CommentTok{  Requirements:}
\CommentTok{  1. Specific requirement one}
\CommentTok{  2. Specific requirement two}
\CommentTok{  3. Specific requirement three}
\CommentTok{  }
\CommentTok{  Implementation Plan:}
\CommentTok{  {-} [ ] Step 1: Initial research}
\CommentTok{  {-} [ ] Step 2: Draft content}
\CommentTok{  {-} [ ] Step 3: Review and revise}
\CommentTok{  }
\CommentTok{  Resources:}
\CommentTok{  {-} Reference document: path/to/doc}
\CommentTok{  {-} Example: url{-}to{-}example}
\CommentTok{  }
\CommentTok{{-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\subsection*{Linked Tasks}\label{linked-tasks}
\addcontentsline{toc}{subsection}{Linked Tasks}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} [ ] PRIMARY: Main task description}
\CommentTok{  Related tasks:}
\CommentTok{  {-} See also: Task in Chapter 2}
\CommentTok{  {-} Depends on: Task in Appendix A}
\CommentTok{  {-} Blocks: Task in Chapter 5}
\CommentTok{{-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\subsection*{Conditional Tasks}\label{conditional-tasks}
\addcontentsline{toc}{subsection}{Conditional Tasks}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} [ ] IF: Hypothesis confirmed in Chapter 3}
\CommentTok{     THEN: Add supporting evidence section}
\CommentTok{     ELSE: Revise theoretical framework {-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\section*{Task Tracking Best
Practices}\label{task-tracking-best-practices}
\addcontentsline{toc}{section}{Task Tracking Best Practices}

\markright{Task Tracking Best Practices}

\subsection*{1. Task Creation
Guidelines}\label{task-creation-guidelines}
\addcontentsline{toc}{subsection}{1. Task Creation Guidelines}

\begin{itemize}
\tightlist
\item
  Create tasks immediately when identified
\item
  Be specific and actionable
\item
  Include context and success criteria
\item
  Link related tasks
\end{itemize}

\subsection*{2. Task Organization}\label{task-organization}
\addcontentsline{toc}{subsection}{2. Task Organization}

\begin{itemize}
\tightlist
\item
  Group related tasks together
\item
  Place tasks near or inside relevant content
\item
  Use consistent formatting
\item
  Maintain task hierarchy
\end{itemize}

\subsection*{3. Priority System}\label{priority-system}
\addcontentsline{toc}{subsection}{3. Priority System}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} [ ] URGENT: Task needing immediate attention {-}{-}\textgreater{}}

\CommentTok{\textless{}!{-}{-} [ ] HIGH: Task important for next milestone {-}{-}\textgreater{}}

\CommentTok{\textless{}!{-}{-} [ ] MEDIUM: Standard priority task {-}{-}\textgreater{}}

\CommentTok{\textless{}!{-}{-} [ ] LOW: Nice{-}to{-}have improvement {-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\#\#\#\# Simple "One{-}line tasks"}

\NormalTok{Use Code ticks and html comment and task format for tasks distinctly visible across all formats including the ToDo{-}Tree overview:}

\InformationTok{\textasciigrave{}\textless{}!{-}{-} [ ] ToDos for things to do / tasks / reminders (allows "jump to with Taks Tree extension") {-}{-}\textgreater{}\textasciigrave{}}

\NormalTok{Use html comment and task format for open or uncertain tasks, visible in the .qmd file:}

\CommentTok{\textless{}!{-}{-} [ ] ToDos for things to do / tasks / reminders (allows "jump to with Taks Tree extension") {-}{-}\textgreater{}}



\FunctionTok{\#\#\#\# More Complex Tasks with Notes}
\end{Highlighting}
\end{Shaded}

More Information about task

Relevant notes

Step-by-step implementation Plan

Etc.

\begin{verbatim}

#### Completed Tasks

Retain completed tasks in ToDo-Tree by adding an x in the brackets: `[x]`
`<!-- [x] Tasks which have been finished but should remain for later verification -->`

<!-- [x] Tasks which have been finished but should remain for later verification -->


Mark and remove completed tasks from ToDo-Tree by adding a minus in the brackets: `[-]`

`<!-- [-] Tasks which have been finished but should remain visible for later verification -->`

<!-- [-] Tasks which have been finished but should remain for later verification (only in .qmd) -->
\end{verbatim}

\section*{Task Management Workflow}\label{task-management-workflow}
\addcontentsline{toc}{section}{Task Management Workflow}

\markright{Task Management Workflow}

\subsection*{1. Task Creation}\label{task-creation}
\addcontentsline{toc}{subsection}{1. Task Creation}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} [ ] }\AlertTok{TODO}\CommentTok{: Write introduction paragraph}
\CommentTok{  Context: Need to introduce the concept of X}
\CommentTok{  Requirements: }
\CommentTok{  {-} Define key terms}
\CommentTok{  {-} Provide historical context}
\CommentTok{  {-} Connect to thesis argument}
\CommentTok{  Deadline: 2024{-}02{-}15}
\CommentTok{{-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\subsection*{2. Task Execution}\label{task-execution}
\addcontentsline{toc}{subsection}{2. Task Execution}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} [ ] }\AlertTok{TODO}\CommentTok{: Write introduction paragraph}
\CommentTok{  Progress:}
\CommentTok{  {-} [x] Defined key terms}
\CommentTok{  {-} [{-}] Not Working on historical context}
\CommentTok{  {-} [ ] Connection to thesis argument}
\CommentTok{{-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\subsection*{3. Task Completion}\label{task-completion}
\addcontentsline{toc}{subsection}{3. Task Completion}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} [x] }\AlertTok{TODO}\CommentTok{: Write introduction paragraph (completed 2024{-}02{-}14)}
\CommentTok{  Final version includes all requirements}
\CommentTok{  Word count: 523}
\CommentTok{  Review status: Approved by advisor}
\CommentTok{{-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\subsection*{4. Task Archival}\label{task-archival}
\addcontentsline{toc}{subsection}{4. Task Archival}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} [{-}] }\AlertTok{TODO}\CommentTok{: Write introduction paragraph (archived 2024{-}02{-}20)}
\CommentTok{  Moved to version control history}
\CommentTok{{-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\section*{Best Practices Summary --- ALWAYS
CONSISTENTLY:}\label{best-practices-summary-always-consistently}
\addcontentsline{toc}{section}{Best Practices Summary --- ALWAYS
CONSISTENTLY:}

\markright{Best Practices Summary --- ALWAYS CONSISTENTLY:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Be Specific}: Tasks should be actionable and measurable
\item
  \textbf{Stay Organized}: Group related tasks and maintain hierarchy
\item
  \textbf{Archive Completed}: Keep task list manageable
\item
  \textbf{Use Categories}: Leverage task types for better organization
\item
  \textbf{Add Context}: Include enough detail for future reference
\item
  \textbf{Link Related}: Connect interdependent tasks
\item
  \textbf{Maintain Consistency}: Use standard formatting throughout
\item
  \textbf{Use correct formatting}: Deploy the correct formatting and fix
  any inconsistencies
\item
  \textbf{Always add extra line breaks}: Add additional line breaks
  between and around tasks
\end{enumerate}

\bookmarksetup{startatroot}

\chapter*{Tagging and Highlighting System for Content
Merging}\label{tagging-and-highlighting-system-for-content-merging}
\addcontentsline{toc}{chapter}{Tagging and Highlighting System for
Content Merging}

\markboth{Tagging and Highlighting System for Content Merging}{Tagging
and Highlighting System for Content Merging}

\section*{Overview}\label{overview-1}
\addcontentsline{toc}{section}{Overview}

\markright{Overview}

When merging content from multiple sources, it's crucial to identify and
manage duplicate, redundant, or overlapping material. This system uses
Quarto formatting features to clearly mark such content for review and
consolidation.

\section*{Tagging Categories}\label{tagging-categories}
\addcontentsline{toc}{section}{Tagging Categories}

\markright{Tagging Categories}

\subsection*{A. Duplicate Content
Marking}\label{a.-duplicate-content-marking}
\addcontentsline{toc}{subsection}{A. Duplicate Content Marking}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{::: \{.duplicate{-}content data{-}source="Chapter2.qmd" data{-}section="2.3"\}}
\NormalTok{This paragraph appears to be duplicated from Chapter 2, Section 2.3.}
\NormalTok{Consider consolidating or removing.}
\NormalTok{:::}

\InformationTok{\textasciigrave{}\textless{}!{-}{-} DUPLICATE: This content also appears in Section 2.3 {-}{-}\textgreater{}\textasciigrave{}}
\end{Highlighting}
\end{Shaded}

\subsection*{B. Redundant Content
Highlighting}\label{b.-redundant-content-highlighting}
\addcontentsline{toc}{subsection}{B. Redundant Content Highlighting}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{::: \{.redundant{-}content\}}
\CommentTok{[}\OtherTok{This section covers similar ground to Section 3.2 but with less detail}\CommentTok{]}\NormalTok{\{.mark style="background{-}color: \#ffeb3b"\}}
\NormalTok{:::}

\CommentTok{\textless{}!{-}{-} REDUNDANT: Similar content in Section 3.2 with more comprehensive coverage {-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\subsection*{C. Better Version
Available}\label{c.-better-version-available}
\addcontentsline{toc}{subsection}{C. Better Version Available}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{::: \{.superseded{-}content data{-}better{-}version="Chapter4.qmd\#sec{-}4{-}5"\}}
\NormalTok{This explanation is superseded by a more comprehensive version in Chapter 4, Section 4.5}
\NormalTok{:::}

\CommentTok{\textless{}!{-}{-} SUPERSEDED: See Chapter 4.5 for improved version {-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\subsection*{D. Merge Candidate}\label{d.-merge-candidate}
\addcontentsline{toc}{subsection}{D. Merge Candidate}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{::: \{.merge{-}candidate data{-}merge{-}with="Section 5.2"\}}
\NormalTok{**MERGE CANDIDATE**: This content could be combined with Section 5.2 for better flow.}

\NormalTok{Original content here...}
\NormalTok{:::}

\CommentTok{\textless{}!{-}{-} MERGE: Consider combining with Section 5.2 {-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\section*{Visual Marking System}\label{visual-marking-system}
\addcontentsline{toc}{section}{Visual Marking System}

\markright{Visual Marking System}

\subsection*{Color-Coded Highlighting}\label{color-coded-highlighting}
\addcontentsline{toc}{subsection}{Color-Coded Highlighting}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{[}\OtherTok{Duplicate content {-} exact match}\CommentTok{]}\NormalTok{\{style="background{-}color: \#ff6b6b; color: white"\}}
\CommentTok{[}\OtherTok{Redundant content {-} similar coverage}\CommentTok{]}\NormalTok{\{style="background{-}color: \#ffeb3b"\}}
\CommentTok{[}\OtherTok{Better version exists elsewhere}\CommentTok{]}\NormalTok{\{style="background{-}color: \#4ecdc4"\}}
\CommentTok{[}\OtherTok{Merge candidate}\CommentTok{]}\NormalTok{\{style="background{-}color: \#45b7d1"\}}
\CommentTok{[}\OtherTok{Review needed}\CommentTok{]}\NormalTok{\{style="background{-}color: \#fa8231"\}}
\end{Highlighting}
\end{Shaded}

\subsection*{Border Marking}\label{border-marking}
\addcontentsline{toc}{subsection}{Border Marking}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{::: \{style="border{-}left: 5px solid \#ff6b6b; padding{-}left: 10px"\}}
\NormalTok{This entire section is duplicated elsewhere.}
\NormalTok{:::}
\end{Highlighting}
\end{Shaded}

\subsection*{Inline Marking}\label{inline-marking}
\addcontentsline{toc}{subsection}{Inline Marking}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{This paragraph contains }\CommentTok{[}\OtherTok{duplicate phrase}\CommentTok{]}\NormalTok{\{.duplicate\} that appears }
\NormalTok{in multiple locations.}
\end{Highlighting}
\end{Shaded}

\section*{Metadata Tracking}\label{metadata-tracking}
\addcontentsline{toc}{section}{Metadata Tracking}

\markright{Metadata Tracking}

\subsection*{Comprehensive Metadata}\label{comprehensive-metadata}
\addcontentsline{toc}{subsection}{Comprehensive Metadata}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{::: \{.content{-}status }
\NormalTok{     data{-}status="duplicate"}
\NormalTok{     data{-}original{-}source="intro.qmd\#para{-}3"}
\NormalTok{     data{-}other{-}locations="chapter2.qmd\#para{-}15, chapter5.qmd\#para{-}8"}
\NormalTok{     data{-}recommendation="keep{-}original"}
\NormalTok{     data{-}reviewed{-}by="VM"}
\NormalTok{     data{-}review{-}date="2024{-}02{-}15"\}}
\NormalTok{This content appears in multiple locations.}
\NormalTok{The original in intro.qmd is most comprehensive.}
\NormalTok{:::}
\end{Highlighting}
\end{Shaded}

\subsection*{Quick Reference Tags}\label{quick-reference-tags}
\addcontentsline{toc}{subsection}{Quick Reference Tags}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} }
\CommentTok{  STATUS: Duplicate}
\CommentTok{  ORIGINAL: intro.qmd\#para{-}3}
\CommentTok{  ALSO IN: ch2\#para{-}15, ch5\#para{-}8}
\CommentTok{  ACTION: Remove this version}
\CommentTok{{-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\section*{Workflow for Content
Merging}\label{workflow-for-content-merging}
\addcontentsline{toc}{section}{Workflow for Content Merging}

\markright{Workflow for Content Merging}

\subsection*{1. Initial Marking Phase}\label{initial-marking-phase}
\addcontentsline{toc}{subsection}{1. Initial Marking Phase}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} PHASE 1: Initial marking {-}{-}\textgreater{}}
\CommentTok{\textless{}!{-}{-} [ ] }\AlertTok{TODO}\CommentTok{: Mark all duplicate content in Chapter 1 {-}{-}\textgreater{}}
\CommentTok{\textless{}!{-}{-} [ ] }\AlertTok{TODO}\CommentTok{: Identify redundant sections in Chapter 2 {-}{-}\textgreater{}}
\CommentTok{\textless{}!{-}{-} [ ] }\AlertTok{TODO}\CommentTok{: Tag better versions throughout document {-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\subsection*{2. Review and Comparison}\label{review-and-comparison}
\addcontentsline{toc}{subsection}{2. Review and Comparison}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} COMPARISON NEEDED {-}{-}\textgreater{}}
\NormalTok{::: \{.comparison{-}block\}}
\NormalTok{**Version A (Current)**: }
\NormalTok{Brief explanation of concept X.}

\NormalTok{**Version B (Chapter 3.2)**:}
\NormalTok{More detailed explanation of concept X with examples.}

\NormalTok{**Recommendation**: Keep Version B, update cross{-}references.}
\NormalTok{:::}
\end{Highlighting}
\end{Shaded}

\subsection*{3. Consolidation Actions}\label{consolidation-actions}
\addcontentsline{toc}{subsection}{3. Consolidation Actions}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} CONSOLIDATION PLAN {-}{-}\textgreater{}}
\NormalTok{::: \{.consolidation{-}plan\}}
\SpecialStringTok{1. }\NormalTok{Keep primary version in Section 2.3}
\SpecialStringTok{2. }\NormalTok{Remove duplicate from Section 4.1}
\SpecialStringTok{3. }\NormalTok{Add cross{-}reference from Section 4.1 to Section 2.3}
\SpecialStringTok{4. }\NormalTok{Merge unique insights from Section 4.1 into Section 2.3}
\NormalTok{:::}
\end{Highlighting}
\end{Shaded}

\section*{Automated Detection
Helpers}\label{automated-detection-helpers}
\addcontentsline{toc}{section}{Automated Detection Helpers}

\markright{Automated Detection Helpers}

\subsection*{Search Patterns}\label{search-patterns}
\addcontentsline{toc}{subsection}{Search Patterns}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} Common duplicate indicators {-}{-}\textgreater{}}
\SpecialStringTok{{-} }\NormalTok{"As mentioned earlier"}
\SpecialStringTok{{-} }\NormalTok{"As discussed in"}
\SpecialStringTok{{-} }\NormalTok{"Similar to"}
\SpecialStringTok{{-} }\NormalTok{"Like we saw in"}
\SpecialStringTok{{-} }\NormalTok{"Returning to"}
\end{Highlighting}
\end{Shaded}

\subsection*{Duplicate Detection
Checklist}\label{duplicate-detection-checklist}
\addcontentsline{toc}{subsection}{Duplicate Detection Checklist}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} [ ] Check for repeated definitions {-}{-}\textgreater{}}
\CommentTok{\textless{}!{-}{-} [ ] Identify similar examples {-}{-}\textgreater{}}
\CommentTok{\textless{}!{-}{-} [ ] Find redundant explanations {-}{-}\textgreater{}}
\CommentTok{\textless{}!{-}{-} [ ] Locate repeated figures/tables {-}{-}\textgreater{}}
\CommentTok{\textless{}!{-}{-} [ ] Search for similar section headings {-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\section*{Best Practices for Merging}\label{best-practices-for-merging}
\addcontentsline{toc}{section}{Best Practices for Merging}

\markright{Best Practices for Merging}

\subsection*{1. Pre-Merge Preparation}\label{pre-merge-preparation}
\addcontentsline{toc}{subsection}{1. Pre-Merge Preparation}

\begin{itemize}
\tightlist
\item
  Mark all content systematically
\item
  Create comparison documents
\item
  Track all locations of similar content
\item
  Document rationale for decisions
\end{itemize}

\subsection*{2. During Merge Process}\label{during-merge-process}
\addcontentsline{toc}{subsection}{2. During Merge Process}

\begin{itemize}
\tightlist
\item
  Keep best version based on:

  \begin{itemize}
  \tightlist
  \item
    Completeness
  \item
    Clarity
  \item
    Placement in document flow
  \item
    Citation quality
  \item
    Figure/table quality
  \end{itemize}
\end{itemize}

\subsection*{3. Post-Merge Cleanup}\label{post-merge-cleanup}
\addcontentsline{toc}{subsection}{3. Post-Merge Cleanup}

\begin{itemize}
\tightlist
\item
  Update all cross-references
\item
  Remove duplicate citations
\item
  Consolidate figures/tables
\item
  Harmonize terminology
\item
  Verify logical flow
\end{itemize}

\section*{Templates for Common
Scenarios}\label{templates-for-common-scenarios}
\addcontentsline{toc}{section}{Templates for Common Scenarios}

\markright{Templates for Common Scenarios}

\subsection*{Duplicate Definition}\label{duplicate-definition}
\addcontentsline{toc}{subsection}{Duplicate Definition}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{::: \{.duplicate{-}definition data{-}term="Bayesian Network"\}}
\NormalTok{**DUPLICATE DEFINITION**: "Bayesian Network" is defined in:}
\SpecialStringTok{{-} }\NormalTok{Section 2.1 (basic definition)}
\SpecialStringTok{{-} }\NormalTok{Section 3.3 (technical definition) ← **KEEP THIS**}
\SpecialStringTok{{-} }\NormalTok{Glossary (summary definition)}

\NormalTok{Action: Keep technical definition in 3.3, reference from 2.1}
\NormalTok{:::}
\end{Highlighting}
\end{Shaded}

\subsection*{Redundant Example}\label{redundant-example}
\addcontentsline{toc}{subsection}{Redundant Example}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{::: \{.redundant{-}example\}}
\NormalTok{**REDUNDANT EXAMPLE**: Rain{-}Sprinkler{-}Lawn appears in:}
\SpecialStringTok{1. }\NormalTok{Introduction (brief mention)}
\SpecialStringTok{2. }\NormalTok{Chapter 2 (detailed walkthrough) ← **PRIMARY**}
\SpecialStringTok{3. }\NormalTok{Chapter 4 (reference only)}

\NormalTok{Action: Keep detailed version, add cross{-}references from others}
\NormalTok{:::}
\end{Highlighting}
\end{Shaded}

\subsection*{Overlapping Sections}\label{overlapping-sections}
\addcontentsline{toc}{subsection}{Overlapping Sections}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{::: \{.section{-}overlap\}}
\NormalTok{**SECTION OVERLAP**: }
\SpecialStringTok{{-} }\NormalTok{Section 3.2 "Methodology Overview" }
\SpecialStringTok{{-} }\NormalTok{Section 4.1 "Methods Used"}

\NormalTok{Content comparison:}
\SpecialStringTok{{-} }\NormalTok{70\% overlap in general approach}
\SpecialStringTok{{-} }\NormalTok{3.2 has better technical detail}
\SpecialStringTok{{-} }\NormalTok{4.1 has better practical examples}

\NormalTok{Recommendation: Merge into 3.2, incorporate examples from 4.1}
\NormalTok{:::}
\end{Highlighting}
\end{Shaded}

\section*{Visual Summary Blocks}\label{visual-summary-blocks}
\addcontentsline{toc}{section}{Visual Summary Blocks}

\markright{Visual Summary Blocks}

\subsection*{Merge Status Dashboard}\label{merge-status-dashboard}
\addcontentsline{toc}{subsection}{Merge Status Dashboard}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{::: \{.merge{-}status{-}dashboard\}}
\NormalTok{**Chapter 2 Merge Status**}
\SpecialStringTok{{-} }\NormalTok{Total sections: 15}
\SpecialStringTok{{-} }\NormalTok{Duplicates found: 4}
\SpecialStringTok{{-} }\NormalTok{Redundant content: 7}
\SpecialStringTok{{-} }\NormalTok{Unique content: 4}
\SpecialStringTok{{-} }\NormalTok{Merge complete: 2/11}
\SpecialStringTok{{-} }\NormalTok{Pending review: 9}
\NormalTok{:::}
\end{Highlighting}
\end{Shaded}

\subsection*{Decision Log}\label{decision-log}
\addcontentsline{toc}{subsection}{Decision Log}

markdown

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{::: \{.merge{-}decision{-}log\}}
\NormalTok{**Merge Decisions {-} 2024{-}02{-}15**}
\SpecialStringTok{1. }\NormalTok{**Section 2.3 vs 4.1**: Kept 2.3, removed 4.1}
\SpecialStringTok{2. }\NormalTok{**Definition of AI**: Consolidated in Glossary}
\SpecialStringTok{3. }\NormalTok{**Example set A vs B**: Merged best of both into new set}
\SpecialStringTok{4. }\NormalTok{**Figure 2.1 vs 3.2**: Kept 3.2 (higher quality)}
\NormalTok{:::}
\end{Highlighting}
\end{Shaded}

\section*{Quality Assurance}\label{quality-assurance}
\addcontentsline{toc}{section}{Quality Assurance}

\markright{Quality Assurance}

\subsection*{Pre-Publication Checklist}\label{pre-publication-checklist}
\addcontentsline{toc}{subsection}{Pre-Publication Checklist}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} [ ] All duplicate markers removed {-}{-}\textgreater{}}
\CommentTok{\textless{}!{-}{-} [ ] All merge decisions documented {-}{-}\textgreater{}}
\CommentTok{\textless{}!{-}{-} [ ] Cross{-}references updated {-}{-}\textgreater{}}
\CommentTok{\textless{}!{-}{-} [ ] No broken links from removed content {-}{-}\textgreater{}}
\CommentTok{\textless{}!{-}{-} [ ] Terminology harmonized {-}{-}\textgreater{}}
\CommentTok{\textless{}!{-}{-} [ ] Flow tested after merging {-}{-}\textgreater{}}
\end{Highlighting}
\end{Shaded}

\subsection*{Final Verification}\label{final-verification}
\addcontentsline{toc}{subsection}{Final Verification}

In markdown blocks or with \texttt{verbatim\ code} ticks:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textless{}!{-}{-} FINAL CHECK: Content Merging {-}{-}\textgreater{}}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ No duplicate content remains untagged}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ All redundancies resolved}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ Best versions retained}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ Smooth transitions between merged sections}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ Complete citation consolidation}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ Figure/table deduplication}
\end{Highlighting}
\end{Shaded}

\bookmarksetup{startatroot}

\chapter*{Master Thesis Checklist for Quarto
Projects}\label{master-thesis-checklist-for-quarto-projects}
\addcontentsline{toc}{chapter}{Master Thesis Checklist for Quarto
Projects}

\markboth{Master Thesis Checklist for Quarto Projects}{Master Thesis
Checklist for Quarto Projects}

\subsection*{Content Creation
Checklist}\label{content-creation-checklist}
\addcontentsline{toc}{subsection}{Content Creation Checklist}

\subsubsection*{Document Structure}\label{document-structure}
\addcontentsline{toc}{subsubsection}{Document Structure}

\begin{itemize}
\tightlist
\item[$\square$]
  All chapters following consistent structure
\item[$\square$]
  Proper heading hierarchy (\#\#, \#\#\#, \#\#\#\#)
\item[$\square$]
  Section labels added (\{\#sec-label\})
\end{itemize}

\subsubsection*{Text Quality}\label{text-quality}
\addcontentsline{toc}{subsubsection}{Text Quality}

\begin{itemize}
\tightlist
\item[$\square$]
  American spelling throughout (run spell check)
\item[$\square$]
  Consistent terminology (maintain glossary, add entries)
\item[$\square$]
  Active voice preferred
\item[$\square$]
  Sentences clear and concise
\item[$\square$]
  Paragraphs focused on single ideas
\item[$\square$]
  Transitions between sections smooth
\item[$\square$]
  No widows or orphans in paragraphs
\end{itemize}

\subsubsection*{Formatting Elements}\label{formatting-elements}
\addcontentsline{toc}{subsubsection}{Formatting Elements}

\begin{itemize}
\tightlist
\item[$\square$]
  Lists properly formatted and consistent
\item[$\square$]
  Code blocks with appropriate syntax highlighting
\item[$\square$]
  Blockquotes used for citations
\item[$\square$]
  Callout boxes for important information
\item[$\square$]
  Mathematical equations properly formatted
\item[$\square$]
  Footnotes used wherever possible
\item[$\square$]
  Page breaks inserted where needed
\end{itemize}

\subsubsection*{Figures and Tables}\label{figures-and-tables}
\addcontentsline{toc}{subsubsection}{Figures and Tables}

\begin{itemize}
\tightlist
\item[$\square$]
  All figures have unique identifiers (\#fig-name)
\item[$\square$]
  Comprehensive alt text for accessibility
\item[$\square$]
  Short captions for list of figures
\item[$\square$]
  Full captions explaining content
\item[$\square$]
  Consistent sizing and alignment
\item[$\square$]
  All figures referenced in text
\item[$\square$]
  Source attribution included
\item[$\square$]
  File formats optimized (PNG/SVG for web, PDF for print)
\item[$\square$]
  Tables have proper headers
\item[$\square$]
  Table captions descriptive
\item[$\square$]
  All tables referenced in text
\end{itemize}

\subsubsection*{Citations and
References}\label{citations-and-references-1}
\addcontentsline{toc}{subsubsection}{Citations and References}

\begin{itemize}
\tightlist
\item[$\square$]
  All claims supported by citations
\item[$\square$]
  Citation style consistent throughout
\item[$\square$]
  Page numbers included where appropriate
\item[$\square$]
  Bibliography entries complete
\item[$\square$]
  No missing citations (check FIND tasks)
\item[$\square$]
  No duplicate citations
\item[$\square$]
  Citations verified (check VERIFY tasks)
\item[$\square$]
  DOIs/URLs included and working
\end{itemize}

\subsubsection*{Cross-References}\label{cross-references-1}
\addcontentsline{toc}{subsubsection}{Cross-References}

\begin{itemize}
\tightlist
\item[$\square$]
  All sections labeled for referencing
\item[$\square$]
  Figure references working (\texttt{@fig-name})
\item[$\square$]
  Table references working (\texttt{@tbl-name})
\item[$\square$]
  Section references working (\texttt{@sec-name})
\item[$\square$]
  No broken cross-references
\end{itemize}

\section*{Revision Phase}\label{revision-phase}
\addcontentsline{toc}{section}{Revision Phase}

\markright{Revision Phase}

\subsection*{Content Review}\label{content-review}
\addcontentsline{toc}{subsection}{Content Review}

\begin{itemize}
\tightlist
\item[$\square$]
  Argument flow logical and clear
\item[$\square$]
  Evidence supports all claims
\item[$\square$]
  Counterarguments addressed
\item[$\square$]
  Conclusions follow from evidence
\item[$\square$]
  No redundant content (check merge tags)
\item[$\square$]
  All promises in introduction fulfilled
\end{itemize}

\subsection*{Task Completion}\label{task-completion-1}
\addcontentsline{toc}{subsection}{Task Completion}

\begin{itemize}
\tightlist
\item[$\square$]
  All TODO items addressed or documented
\item[$\square$]
  All FIND items researched
\item[$\square$]
  All VERIFY items confirmed
\item[$\square$]
  All CREATE items completed
\item[$\square$]
  Task status updated ({[}{]}, {[}x{]}, {[}-{]})
\item[$\square$]
  Progress summaries updated
\end{itemize}

\section*{⚡ Prime Directives}\label{prime-directives}
\addcontentsline{toc}{section}{⚡ Prime Directives}

\markright{⚡ Prime Directives}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Quarto supremacy} -- exploit \emph{every} reliable feature
  Quarto offers.\\
\item
  \textbf{Four-level heading discipline} -- never skip a level.\\
\item
  \textbf{Redundancy tagged, not deleted} -- see § Tagging System.\\
\item
  \textbf{Checklists rule every commit} -- see § Rigorous Checklist.\\
\item
  \textbf{Footnotes galore} -- default to footnotes for nuance,
  citations, side quests.\\
\item
  \textbf{Glossary, TOC, LOF, LOT, appendices, cross-refs} -- keep fully
  synched; update on \emph{every} save.\\
\item
  \textbf{One thought ≈ one line-break} -- err on the side of whitespace
  also when formatting syntax.
\end{enumerate}

\section*{Quarto Syntax Cheat-Sheet ↔
Best-Practice}\label{quarto-syntax-cheat-sheet-best-practice}
\addcontentsline{toc}{section}{Quarto Syntax Cheat-Sheet ↔
Best-Practice}

\markright{Quarto Syntax Cheat-Sheet ↔ Best-Practice}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1837}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3265}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4898}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Feature
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Minimal Syntax
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best-Practice Guidance
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Headings (h1--h4)} & \texttt{\#}, \texttt{\#\#},
\texttt{\#\#\#}, \texttt{\#\#\#\#} & Use all four levels; propose deeper
sub-heads via
\texttt{\textless{}!-\/-\ SUGGEST-H5:\ …\ -\/-\textgreater{}}. \\
\textbf{Paragraph breaks} & blank line & Generally wrap at 80 chars ⇢
git-diff clarity. \\
\textbf{Bold / \emph{Italic} / }\emph{Both}** / \st{Strike}** &
\texttt{**b**}, \texttt{*i*}, \texttt{***bi***},
\texttt{\textasciitilde{}\textasciitilde{}del\textasciitilde{}\textasciitilde{}}
& Reserve bold for \emph{semantic} emphasis, italics for \emph{titles \&
meta}. \\
\textbf{Lists} & \texttt{-}, \texttt{*}, \texttt{1.} & Rarely nest
\textgreater{} 3 levels; indent 2 spaces per level. \\
\textbf{Callouts} & \texttt{:::\ \{.callout-note\}} & Use \texttt{.tip},
\texttt{.warning}, \texttt{.important}, \texttt{.duplicate} (custom) for
tagging; close with \texttt{:::}. \\
\textbf{Blockquotes} & \texttt{\textgreater{}} & Ideal for verbatim
interview excerpts; cite speaker. \\
\textbf{Code blocks} &
\texttt{\textasciigrave{}\textasciigrave{}\textasciigrave{}r} & Always
declare language; add caption: ````\texttt{\{python\}\ fig.cap="…"}. \\
\textbf{Figures \& Tables} & \texttt{!{[}{]}(fig.png)\{\#fig-id\}} &
Always add \texttt{\{\#fig-id\ fig-cap="…"\};} etc. cross-ref with
\texttt{@fig-id}. \\
\textbf{Cross-refs} & \texttt{@sec-intro}, \texttt{@tbl-results} &
Prefix: \texttt{sec-}, \texttt{fig-}, \texttt{tbl-}, \texttt{eq-}. \\
\textbf{Citations} & \texttt{{[}@smith2024{]}} & Maintain \texttt{.bib}
via Zotero; nightly \texttt{quarto\ check}. \\
\textbf{Footnotes} & \texttt{{[}\^{}1{]}} & Overuse for tangents,
mini-proofs, data caveats. \\
\textbf{Glossary} & \texttt{term:\ Definition} & Append
\texttt{glossary:\ true} in task; link in-text \texttt{\{@term\}}. \\
\textbf{Comments} &
\texttt{\textless{}!-\/-\ {[}\ {]}\ TODO:\ …\ -\/-\textgreater{}} & Use
for tasks; parse with \emph{Todo Tree} VS Code plugin. \\
\end{longtable}

\section*{Tagging / Highlighting System
🔖}\label{tagging-highlighting-system}
\addcontentsline{toc}{section}{Tagging / Highlighting System 🔖}

\markright{Tagging / Highlighting System 🔖}

Use the custom tagging and highlighting system for all materials

\section*{Workflow Rules}\label{workflow-rules}
\addcontentsline{toc}{section}{Workflow Rules}

\markright{Workflow Rules}

\textbf{During writing}\\
- \emph{Every new idea}: decide \emph{body}, \emph{footnote}, or
\emph{appendix} and place instantly.\\
- Add glossary entries as soon as a term of art appears.\\
- Insert provisional graphics with stub \texttt{\{\#fig-TBD\}} and
create a TODO comment.

\section*{Rigorous Checklist ✅}\label{rigorous-checklist}
\addcontentsline{toc}{section}{Rigorous Checklist ✅}

\markright{Rigorous Checklist ✅}

\begin{itemize}
\tightlist
\item[$\square$]
  Use the full hierarchy of headings
\item[$\square$]
  All figures/tables have IDs, captions, and are referenced in text.\\
\item[$\square$]
  Glossary updated; new \texttt{\{@term\}} links render without
  warnings.\\
\item[$\square$]
  Citation list reflects \emph{every} \texttt{{[}@{]}} callout.\\
\item[$\square$]
  Footnotes compile and are sorted numerically.\\
\item[$\square$]
  Appendices contain overflow material only; each referenced at least
  once.\\
\item[$\square$]
  \texttt{duplicate} callouts reviewed; none accidentally removed.\\
\item[$\square$]
  ``Outstanding graphics'' \& ``Outstanding citations'' subsections
  updated.
\end{itemize}

\bookmarksetup{startatroot}

\chapter*{Automating the Modeling of Transformative Artificial
Intelligence Risks
(AMTAIR)}\label{automating-the-modeling-of-transformative-artificial-intelligence-risks-amtair}
\addcontentsline{toc}{chapter}{Automating the Modeling of Transformative
Artificial Intelligence Risks (AMTAIR)}

\markboth{Automating the Modeling of Transformative Artificial
Intelligence Risks (AMTAIR)}{Automating the Modeling of Transformative
Artificial Intelligence Risks (AMTAIR)}

\begin{Shaded}
\begin{Highlighting}[]
\AnnotationTok{title:}\CommentTok{ "Automating the Modeling of Transformative Artificial Intelligence Risks"}
\AnnotationTok{subtitle:}\CommentTok{ "An Epistemic Framework for Leveraging Frontier AI Systems to Upscale Conditional Policy Assessments in Bayesian Networks on a Narrow Path toward Existential Safety" author:}

\SpecialStringTok{{-} }\NormalTok{name: Valentin Jakob Meyer orcid: 0009{-}0006{-}0889{-}5269 corresponding: true email: }\CommentTok{[}\OtherTok{Valentin.Meyer@uni{-}bayreuth.de}\CommentTok{](mailto:Valentin.Meyer@uni{-}bayreuth.de)}\NormalTok{ roles:}
\SpecialStringTok{    {-} }\NormalTok{Graduate Author affiliations:}
\SpecialStringTok{    {-} }\NormalTok{University of Bayreuth}
\SpecialStringTok{    {-} }\NormalTok{MCMP — LMU Munich}
\SpecialStringTok{{-} }\NormalTok{name: Dr. Timo Speith orcid: 0000{-}0002{-}6675{-}154X corresponding: false roles:}
\SpecialStringTok{    {-} }\NormalTok{Supervisor affiliations:}
\SpecialStringTok{    {-} }\NormalTok{University of Bayreuth keywords:}
\SpecialStringTok{{-} }\NormalTok{AMTAIR}
\SpecialStringTok{{-} }\NormalTok{AI Governance}
\SpecialStringTok{{-} }\NormalTok{Bayesian Networks}
\SpecialStringTok{{-} }\NormalTok{Transformative AI}
\SpecialStringTok{{-} }\NormalTok{Risk Assessment}
\SpecialStringTok{{-} }\NormalTok{Argument Extraction}
\SpecialStringTok{{-} }\NormalTok{Existential Risk}
\SpecialStringTok{{-} }\NormalTok{Coordination Crisis}
\SpecialStringTok{{-} }\NormalTok{Epistemic Security}
\SpecialStringTok{{-} }\NormalTok{Policy Evaluation abstract: | This thesis addresses coordination failures in AI safety by creating computational tools that automatically extract and formalize probabilistic world models from AI safety literature using frontier language models. The AMTAIR (Automating Transformative AI Risk Modeling) system implements an end{-}to{-}end pipeline transforming unstructured arguments into interactive Bayesian networks through a novel two{-}stage extraction process: first capturing argument structure in ArgDown format, then enhancing it with probability information in BayesDown.}

\NormalTok{Applied to canonical examples and real AI safety arguments, the system demonstrates extraction accuracy exceeding 85\% for structural relationships and 73\% for probability capture. By making implicit models explicit, enabling cross{-}worldview comparison, and supporting rigorous policy evaluation, AMTAIR bridges communication gaps between technical researchers, policy specialists, and other stakeholders working to address existential risks from advanced AI.}

\NormalTok{The thesis contributes both theoretical foundations and practical implementation, validated through expert comparison and real{-}world case studies including Carlsmith\textquotesingle{}s power{-}seeking AI model. While current limitations include correlation handling and extraction ambiguities, the approach provides essential epistemic infrastructure for coordinated AI governance. plain{-}language{-}summary: | This thesis develops software tools that automatically extract and visualize the hidden assumptions and probability estimates in AI safety arguments. By transforming complex written arguments into interactive diagrams showing relationships and probabilities, AMTAIR helps different groups working on AI safety—researchers, policymakers, and others—understand each other better and coordinate their efforts to address risks from advanced AI systems. key{-}points:}

\SpecialStringTok{{-} }\NormalTok{A novel two{-}stage extraction pipeline transforms argument structures into Bayesian networks through ArgDown and BayesDown intermediate representations}
\SpecialStringTok{{-} }\NormalTok{Interactive visualizations make complex probabilistic relationships accessible to diverse stakeholders}
\SpecialStringTok{{-} }\NormalTok{Formal representation enables systematic comparison across different worldviews and assumptions}
\SpecialStringTok{{-} }\NormalTok{Validated extraction achieves \textgreater{}85\% accuracy for structure and \textgreater{}73\% for probabilities}
\SpecialStringTok{{-} }\NormalTok{The approach addresses coordination failures by creating a common language for AI risk assessment date: "2025{-}05{-}26" bibliography: ref/MAref.bib citation: container{-}title: University of Bayreuth Master\textquotesingle{}s Thesis number{-}sections: true toc: true toc{-}depth: 4 lof: true lot: true}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\bookmarksetup{startatroot}

\chapter*{Frontmatter: Preface}\label{frontmatter-preface}
\addcontentsline{toc}{chapter}{Frontmatter: Preface}

\markboth{Frontmatter: Preface}{Frontmatter: Preface}

This thesis represents the culmination of interdisciplinary research at
the intersection of AI safety, formal epistemology, and computational
social science. The work emerged from recognizing a fundamental
challenge in AI governance: while investment in AI safety research has
grown exponentially, coordination between different stakeholder
communities remains fragmented, potentially increasing existential risk
through misaligned efforts.

The journey from initial concept to working implementation involved
iterative refinement based on feedback from advisors, domain experts,
and potential users. What began as a technical exercise in automated
extraction evolved into a broader framework for enhancing epistemic
security in one of humanity's most critical coordination challenges.

I hope this work contributes to building the intellectual and technical
infrastructure necessary for humanity to navigate the transition to
transformative AI safely. The tools and frameworks presented here are
offered in the spirit of collaborative problem-solving, recognizing that
the challenges we face require unprecedented cooperation across
disciplines, institutions, and worldviews.

\section*{Acknowledgments}\label{acknowledgments-1}
\addcontentsline{toc}{section}{Acknowledgments}

\markright{Acknowledgments}

I thank my supervisor Dr.~Timo Speith for guidance throughout this
project, the MTAIR team for pioneering the manual approach that inspired
automation, and the AI safety community for creating the rich literature
that made this work possible. Special recognition goes to technical
advisors who provided invaluable feedback and Coleman Snell for his
partnership and research collaboration with the AMTAIR project. Any
errors or limitations remain my own responsibility.

\bookmarksetup{startatroot}

\chapter*{List of Figures}\label{list-of-figures}
\addcontentsline{toc}{chapter}{List of Figures}

\markboth{List of Figures}{List of Figures}

\bookmarksetup{startatroot}

\chapter*{List of Tables}\label{list-of-tables}
\addcontentsline{toc}{chapter}{List of Tables}

\markboth{List of Tables}{List of Tables}

\bookmarksetup{startatroot}

\chapter*{List of Abbreviations}\label{list-of-abbreviations-1}
\addcontentsline{toc}{chapter}{List of Abbreviations}

\markboth{List of Abbreviations}{List of Abbreviations}

AI - Artificial Intelligence\\
AGI - Artificial General Intelligence\\
AMTAIR - Automating Transformative AI Risk Modeling\\
API - Application Programming Interface\\
APS - Advanced, Planning, Strategic (AI systems)\\
BN - Bayesian Network\\
CPT - Conditional Probability Table\\
DAG - Directed Acyclic Graph\\
LLM - Large Language Model\\
ML - Machine Learning\\
MTAIR - Modeling Transformative AI Risks\\
NLP - Natural Language Processing\\
P\&E - Philosophy \& Economics\\
PDF - Portable Document Format\\
TAI - Transformative Artificial Intelligence

\bookmarksetup{startatroot}

\chapter*{1. Introduction: The Coordination Crisis in AI
Governance}\label{sec-introduction}
\addcontentsline{toc}{chapter}{1. Introduction: The Coordination Crisis
in AI Governance}

\markboth{1. Introduction: The Coordination Crisis in AI Governance}{1.
Introduction: The Coordination Crisis in AI Governance}

\begin{tcolorbox}[enhanced jigsaw, arc=.35mm, titlerule=0mm, breakable, toprule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, coltitle=black, bottomrule=.15mm, bottomtitle=1mm, opacityback=0, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Chapter Overview}, rightrule=.15mm, leftrule=.75mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, left=2mm]

\textbf{Grade Weight}: 10\% \textbar{} \textbf{Target Length}:
\textasciitilde14\% of text (\textasciitilde4,200 words)\\
\textbf{Requirements}: Introduces and motivates the core question,
provides context, states precise thesis, provides roadmap

\end{tcolorbox}

\section*{1.1 Opening Scenario: The Policymaker's
Dilemma}\label{sec-opening-scenario}
\addcontentsline{toc}{section}{1.1 Opening Scenario: The Policymaker's
Dilemma}

\markright{1.1 Opening Scenario: The Policymaker's Dilemma}

\textcite{todd2024}

Imagine a senior policy advisor preparing recommendations for AI
governance legislation. On her desk lie a dozen reports from leading AI
safety researchers, each painting a different picture of the risks
ahead. One argues that misaligned AI could pose existential risks within
the decade, citing complex technical arguments about instrumental
convergence and orthogonality. Another suggests these concerns are
overblown, emphasizing uncertainty and the strength of existing
institutions. A third proposes specific technical standards but
acknowledges deep uncertainty about their effectiveness. :::
\{.redundant-content
data-better-version=``Outline\_12.2\#sec-opening''\} Each report seems
compelling in isolation, written by credentialed experts with
sophisticated arguments. Yet they reach dramatically different
conclusions about both the magnitude of risk and appropriate
interventions. The technical arguments involve unfamiliar
concepts---mesa-optimization, corrigibility, capability
amplification---expressed through different frameworks and implicit
assumptions. Time is limited, stakes are high, and the legislation could
shape humanity's trajectory for decades. :::

This scenario plays out daily across government offices, corporate
boardrooms, and research institutions worldwide. It exemplifies what I
term the ``coordination crisis'' in AI governance: despite unprecedented
attention and resources directed toward AI safety, we lack the epistemic
infrastructure to synthesize diverse expert knowledge into actionable
governance strategies.

\section*{1.2 The Coordination Crisis in AI
Governance}\label{sec-coordination-crisis}
\addcontentsline{toc}{section}{1.2 The Coordination Crisis in AI
Governance}

\markright{1.2 The Coordination Crisis in AI Governance}

\textcite{maslej2025}

\textcite{samborska2025}

As AI capabilities advance at an accelerating pace---demonstrated by the
rapid progression from GPT-3 to GPT-4, Claude, and emerging multimodal
systems---humanity faces a governance challenge unlike any in history.
The task of ensuring increasingly powerful AI systems remain aligned
with human values and beneficial to our long-term flourishing grows more
urgent with each capability breakthrough. This challenge becomes
particularly acute when considering transformative AI systems that could
drastically alter civilization's trajectory, potentially including
existential risks from misaligned systems pursuing objectives counter to
human welfare.

\begin{quote}
Despite unprecedented investment in AI safety research, rapidly growing
awareness among key stakeholders, and proliferating frameworks for
responsible AI development, we face what I'll term the ``coordination
crisis'' in AI governance---a systemic failure to align diverse efforts
across technical, policy, and strategic domains into a coherent response
proportionate to the risks we face.
\end{quote}

The current state of AI governance presents a striking paradox. On one
hand, we witness extraordinary mobilization: billions in research
funding, proliferating safety initiatives, major tech companies
establishing alignment teams, and governments worldwide developing AI
strategies. The
\href{https://futureoflife.org/open-letter/ai-principles/}{Asilomar AI
Principles} garnered thousands of signatures, the EU advances
\href{https://artificialintelligenceact.eu/the-act/}{comprehensive AI
regulation} , and technical researchers produce increasingly
sophisticated work on alignment, interpretability, and robustness.

\textcite{tegmark2024}

\textcite{european2024}

Yet alongside this activity, we observe systematic coordination failures
that may prove catastrophic. Technical safety researchers develop
sophisticated alignment techniques without clear implementation
pathways. Policy specialists craft regulatory frameworks lacking
technical grounding to ensure practical efficacy. Ethicists articulate
normative principles that lack operational specificity. Strategy
researchers identify critical uncertainties but struggle to translate
these into actionable guidance. International bodies convene without
shared frameworks for assessing interventions.

\subsection*{1.2.1 Safety Gaps from Misaligned
Efforts}\label{sec-safety-gaps}
\addcontentsline{toc}{subsection}{1.2.1 Safety Gaps from Misaligned
Efforts}

The fragmentation problem manifests in incompatible frameworks between
technical researchers, policy specialists, and strategic analysts. Each
community develops sophisticated approaches within their domain, yet
translation between domains remains primitive. This creates systematic
blind spots where risks emerge at the interfaces between technical
capabilities, institutional responses, and strategic dynamics.

When different communities operate with incompatible frameworks,
critical risks fall through the cracks. Technical researchers may solve
alignment problems under assumptions that policymakers' decisions
invalidate. Regulations optimized for current systems may inadvertently
incentivize dangerous development patterns. Without shared models of the
risk landscape, our collective efforts resemble the parable of blind men
describing an elephant---each accurate within their domain but missing
the complete picture.

\textcite{paul2023}

\subsection*{1.2.2 Resource
Misallocation}\label{sec-resource-misallocation}
\addcontentsline{toc}{subsection}{1.2.2 Resource Misallocation}

The AI safety community duplicates efforts while leaving critical areas
underexplored. Multiple teams independently develop similar frameworks
without building on each other's work. Funders struggle to identify
high-impact opportunities across technical and governance domains.
Talent flows toward well-publicized approaches while neglected
strategies remain understaffed. This misallocation becomes more costly
as the window for establishing effective governance narrows.

\subsection*{1.2.3 Negative-Sum Dynamics}\label{sec-negative-sum}
\addcontentsline{toc}{subsection}{1.2.3 Negative-Sum Dynamics}

Perhaps most concerning, uncoordinated interventions can actively
increase risk. Safety standards that advantage established players may
accelerate risky development elsewhere. Partial transparency
requirements might enable capability advances without commensurate
safety improvements. International agreements lacking shared technical
understanding may lock in dangerous practices. Without coordination, our
cure risks becoming worse than the disease.

Coordination failures systematically amplify existential risk through
multiple pathways. Safety gaps emerge when technical solutions lack
policy implementation pathways. Resource misallocation occurs when
multiple teams unknowingly duplicate efforts while critical areas remain
unaddressed. Most perniciously, locally optimized decisions by
individual actors can create negative-sum dynamics that increase overall
risk---an AI governance tragedy of the commons.

\textcite{armstrong2016}

\textcite{samuel2023}, \textcite{hunt2025}

\section*{1.3 Historical Parallels and Temporal
Urgency}\label{sec-historical-urgency}
\addcontentsline{toc}{section}{1.3 Historical Parallels and Temporal
Urgency}

\markright{1.3 Historical Parallels and Temporal Urgency}

History offers instructive parallels. The nuclear age began with
scientists racing to understand and control forces that could destroy
civilization. Early coordination failures---competing national programs,
scientist-military tensions, public-expert divides---nearly led to
catastrophe multiple times. Only through developing shared frameworks
(deterrence theory), institutions (IAEA), and communication channels
(hotlines, treaties) did humanity navigate the nuclear precipice.

\textcite{schelling1960}

\textcite{rehman2025}

Yet AI presents unique coordination challenges that compress our
response timeline:

\textbf{Accelerating Development}: Unlike nuclear weapons requiring
massive infrastructure, AI development proceeds in corporate labs and
academic departments worldwide. Capability improvements come through
algorithmic insights and computational scale, both advancing
exponentially.

\textbf{Dual-Use Ubiquity}: Every AI advance potentially contributes to
both beneficial applications and catastrophic risks. The same language
model architectures enabling scientific breakthroughs could facilitate
dangerous manipulation or deception at scale.

\textbf{Comprehension Barriers}: Nuclear risks were viscerally
understandable---cities vaporized, radiation sickness, nuclear winter.
AI risks involve abstract concepts like optimization processes, goal
misspecification, and emergent capabilities that resist intuitive
understanding.

\textbf{Governance Lag}: Traditional governance
mechanisms---legislation, international treaties, professional
standards---operate on timescales of years to decades. AI capabilities
advance on timescales of months to years, creating an ever-widening
capability-governance gap.

\section*{1.4 Research Question and Scope}\label{sec-research-question}
\addcontentsline{toc}{section}{1.4 Research Question and Scope}

\markright{1.4 Research Question and Scope}

This thesis addresses a specific dimension of the coordination challenge
by investigating the question:

\textbf{Can frontier AI technologies be utilized to automate the
modeling of transformative AI risks, enabling robust prediction of
policy impacts across diverse worldviews?}

More specifically, I explore whether frontier language models can
automate the extraction and formalization of probabilistic world models
from AI safety literature, creating a scalable computational framework
that enhances coordination in AI governance through systematic policy
evaluation under uncertainty.

To break this down into its components:

\begin{itemize}
\tightlist
\item
  \textbf{Frontier AI Technologies}: Today's most capable language
  models (GPT-4, Claude-3 level systems)
\item
  \textbf{Automated Modeling}: Using these systems to extract and
  formalize argument structures from natural language
\item
  \textbf{Transformative AI Risks}: Potentially catastrophic outcomes
  from advanced AI systems, particularly existential risks
\item
  \textbf{Policy Impact Prediction}: Evaluating how governance
  interventions might alter probability distributions over outcomes
\item
  \textbf{Diverse Worldviews}: Accounting for fundamental disagreements
  about AI development trajectories and risk factors
\end{itemize}

The investigation encompasses both theoretical development and practical
implementation, focusing specifically on existential risks from
misaligned AI systems rather than broader AI ethics concerns. This
narrowed scope enables deep technical development while addressing the
highest-stakes coordination challenges.

\section*{1.5 The Multiplicative Benefits
Framework}\label{sec-multiplicative-benefits}
\addcontentsline{toc}{section}{1.5 The Multiplicative Benefits
Framework}

\markright{1.5 The Multiplicative Benefits Framework}

The central thesis of this work is that combining three
elements---automated worldview extraction, prediction market
integration, and formal policy evaluation---creates multiplicative
rather than merely additive benefits for AI governance. Each component
enhances the others, creating a system more valuable than the sum of its
parts.

\subsection*{1.5.1 Automated Worldview
Extraction}\label{sec-automated-extraction}
\addcontentsline{toc}{subsection}{1.5.1 Automated Worldview Extraction}

\textbf{Automated worldview extraction} using frontier language models
addresses the scaling bottleneck in current approaches to AI risk
modeling. The Modeling Transformative AI Risks (MTAIR) project
demonstrated the value of formal representation but required extensive
manual effort to translate qualitative arguments into quantitative
models. Automation enables processing orders of magnitude more content,
incorporating diverse perspectives, and maintaining models in near
real-time as new arguments emerge.

Current approaches to AI risk modeling, exemplified by the Modeling
Transformative AI Risks (MTAIR) project, demonstrate the value of formal
representation but require extensive manual effort. Creating a single
model demands dozens of expert-hours to translate qualitative arguments
into quantitative frameworks. This bottleneck severely limits the number
of perspectives that can be formalized and the speed of model updates as
new arguments emerge.

Automation using frontier language models addresses this scaling
challenge. By developing systematic methods to extract causal structures
and probability judgments from natural language, we can:

\begin{itemize}
\tightlist
\item
  Process orders of magnitude more content
\item
  Incorporate diverse perspectives rapidly
\item
  Maintain models that evolve with the discourse
\item
  Reduce barriers to entry for contributing worldviews
\end{itemize}

\subsection*{1.5.2 Live Data Integration}\label{sec-live-data}
\addcontentsline{toc}{subsection}{1.5.2 Live Data Integration}

\textbf{Prediction market integration} grounds these models in
collective forecasting intelligence. By connecting formal
representations to live forecasting platforms, the system can
incorporate timely judgments about critical uncertainties from
calibrated forecasters. This creates a dynamic feedback loop where
models inform forecasters and forecasts update models.

Static models, however well-constructed, quickly become outdated in
fast-moving domains. Prediction markets and forecasting platforms
aggregate distributed knowledge about uncertain futures, providing
continuously updated probability estimates. By connecting formal models
to these live data sources, we create dynamic assessments that
incorporate the latest collective intelligence.

This integration serves multiple purposes:

\begin{itemize}
\tightlist
\item
  Grounding abstract models in empirical forecasts
\item
  Identifying which uncertainties most affect outcomes
\item
  Revealing when model assumptions diverge from collective expectations
\item
  Generating new questions for forecasting communities
\end{itemize}

\textcite{tetlock2015}

\subsection*{1.5.3 Formal Policy
Evaluation}\label{sec-policy-evaluation}
\addcontentsline{toc}{subsection}{1.5.3 Formal Policy Evaluation}

\textbf{Formal policy evaluation} transforms static risk assessments
into actionable guidance by modeling how specific interventions alter
critical parameters. Using causal inference techniques, we can assess
not just the probability of adverse outcomes but how those probabilities
change under different policy regimes.

This enables genuinely evidence-based policy development:

\begin{itemize}
\tightlist
\item
  Comparing interventions across multiple worldviews
\item
  Identifying robust strategies that work across scenarios
\item
  Understanding which uncertainties most affect policy effectiveness
\item
  Prioritizing research to reduce decision-relevant uncertainty
\end{itemize}

\textcite{pearl2000} and \textcite{pearl2009}

\subsection*{1.5.4 The Synergy}\label{sec-synergy}
\addcontentsline{toc}{subsection}{1.5.4 The Synergy}

The synergy emerges because automation enables comprehensive data
integration, markets inform and validate models, and evaluation gains
precision from both automated extraction and market-based calibration.
The complete system creates feedback loops where policy analysis
identifies critical uncertainties for market attention.

The multiplicative benefits emerge from the interactions between
components:

\begin{itemize}
\tightlist
\item
  Automation enables comprehensive coverage, making prediction market
  integration more valuable by connecting to more perspectives
\item
  Market data validates and calibrates automated extractions, improving
  quality
\item
  Policy evaluation gains precision from both comprehensive models and
  live probability updates
\item
  The complete system creates feedback loops where policy analysis
  identifies critical uncertainties for market attention
\end{itemize}

This synergistic combination addresses the coordination crisis by
providing common ground for disparate communities, translating between
technical and policy languages, quantifying previously implicit
disagreements, and enabling evidence-based compromise.

\section*{1.6 Thesis Structure and Roadmap}\label{sec-roadmap}
\addcontentsline{toc}{section}{1.6 Thesis Structure and Roadmap}

\markright{1.6 Thesis Structure and Roadmap}

The remainder of this thesis develops the multiplicative benefits
framework from theoretical foundations to practical implementation:

\textbf{Chapter 2: Context and Theoretical Foundations} establishes the
intellectual groundwork, examining the epistemic challenges unique to AI
governance, Bayesian networks as formal tools for uncertainty
representation, argument mapping as a bridge from natural language to
formal models, the MTAIR project's achievements and limitations, and
requirements for effective coordination infrastructure.

\textbf{Chapter 3: AMTAIR Design and Implementation} presents the
technical system including overall architecture and design principles,
the two-stage extraction pipeline (ArgDown → BayesDown), validation
methodology and results, case studies from simple examples to complex AI
risk models, and integration with prediction markets and policy
evaluation.

\textbf{Chapter 4: Discussion - Implications and Limitations} critically
examines technical limitations and failure modes, conceptual concerns
about formalization, integration with existing governance frameworks,
scaling challenges and opportunities, and broader implications for
epistemic security.

\textbf{Chapter 5: Conclusion} synthesizes key contributions and charts
paths forward with a summary of theoretical and practical achievements,
concrete recommendations for stakeholders, research agenda for community
development, and vision for AI governance with proper coordination
infrastructure.

Throughout this progression, I maintain dual focus on theoretical
sophistication and practical utility. The framework aims not merely to
advance academic understanding but to provide actionable tools for
improving coordination in AI governance during this critical period.

Having established the coordination crisis and outlined how automated
modeling can address it, we now turn to the theoretical foundations that
make this approach possible. The next chapter examines the unique
epistemic challenges of AI governance and introduces the formal
tools---particularly Bayesian networks---that enable rigorous reasoning
under deep uncertainty.

\bookmarksetup{startatroot}

\chapter*{2. Context and Theoretical Foundations}\label{sec-context}
\addcontentsline{toc}{chapter}{2. Context and Theoretical Foundations}

\markboth{2. Context and Theoretical Foundations}{2. Context and
Theoretical Foundations}

\begin{tcolorbox}[enhanced jigsaw, arc=.35mm, titlerule=0mm, breakable, toprule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, coltitle=black, bottomrule=.15mm, bottomtitle=1mm, opacityback=0, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Chapter Overview}, rightrule=.15mm, leftrule=.75mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, left=2mm]

\textbf{Grade Weight}: 20\% \textbar{} \textbf{Target Length}:
\textasciitilde29\% of text (\textasciitilde8,700 words)\\
\textbf{Requirements}: Demonstrates understanding of relevant concepts,
explains relevance, situates in debate, reconstructs arguments

\end{tcolorbox}

\section*{2.1 AI Existential Risk: The Carlsmith
Model}\label{sec-carlsmith-model}
\addcontentsline{toc}{section}{2.1 AI Existential Risk: The Carlsmith
Model}

\markright{2.1 AI Existential Risk: The Carlsmith Model}

Carlsmith's ``Is Power-Seeking AI an Existential Risk?'' (2021)
represents one of the most structured approaches to assessing the
probability of existential catastrophe from advanced AI. The analysis
decomposes the overall risk into six key premises, each with an explicit
probability estimate.

To ground our discussion in concrete terms, I examine Joseph Carlsmith's
``Is Power-Seeking AI an Existential Risk?'' as an exemplar of
structured reasoning about AI catastrophic risk. Carlsmith's analysis
stands out for its explicit probabilistic decomposition of the path from
current AI development to potential existential catastrophe.

\textcite{carlsmith2024}, \textcite{carlsmith2021} and
\textcite{carlsmith2022}

\subsection*{2.1.1 Six-Premise Decomposition}\label{sec-six-premise}
\addcontentsline{toc}{subsection}{2.1.1 Six-Premise Decomposition}

According to the MTAIR model Carlsmith decomposes existential risk into
a probabilistic chain with explicit estimates:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Premise 1}: Transformative AI development this century
  \((P ≈ 0.80)\)
\item
  \textbf{Premise 2}: AI systems pursuing objectives in the world
  \((P ≈ 0.95)\)
\item
  \textbf{Premise 3}: Systems with power-seeking instrumental incentives
  \((P ≈ 0.40)\)
\item
  \textbf{Premise 4}: Sufficient capability for existential threat
  \((P ≈ 0.65)\)
\item
  \textbf{Premise 5}: Misaligned systems despite safety efforts
  \((P ≈ 0.50)\)
\item
  \textbf{Premise 6}: Catastrophic outcomes from misaligned
  power-seeking \((P ≈ 0.65)\)
\end{enumerate}

\textbf{Composite Risk Calculation}: \(P(doom) ≈ 0.05\) (5\%)

Carlsmith structures his argument through six conditional premises, each
assigned explicit probability estimates:

\textbf{Premise 1: APS Systems by 2070} \((P ≈ 0.65)\)\footnote{The
  probability estimates vary between outlines; using more conservative
  estimates from 12.2} ``By 2070, there will be AI systems with Advanced
capability, Agentic planning, and Strategic awareness''---the
conjunction of capabilities that could enable systematic pursuit of
objectives in the world.

\textbf{Premise 2: Alignment Difficulty} \$(P ≈ 0.40) \$ ``It will be
harder to build aligned APS systems than misaligned systems that are
still attractive to deploy''---capturing the challenge that safety may
conflict with capability or efficiency.

\textbf{Premise 3: Deployment Despite Misalignment} \$(P ≈ 0.70) \$
``Conditional on 1 and 2, we will deploy misaligned APS
systems''---reflecting competitive pressures and limited coordination.

\textbf{Premise 4: Power-Seeking Behavior} \$(P ≈ 0.65) \$ ``Conditional
on 1-3, misaligned APS systems will seek power in high-impact
ways''---based on instrumental convergence arguments.

\textbf{Premise 5: Disempowerment Success} \$(P ≈ 0.40) \$ ``Conditional
on 1-4, power-seeking will scale to permanent human
disempowerment''---despite potential resistance and safeguards.

\textbf{Premise 6: Existential Catastrophe} \$(P ≈ 0.95) \$
``Conditional on 1-5, this disempowerment constitutes existential
catastrophe''---connecting power loss to permanent curtailment of human
potential.

\textbf{Overall Risk}: Multiplying through the conditional chain yields
\(P(doom) ≈ 0.05\) or 5\% by 2070.

This structured approach exemplifies the type of reasoning AMTAIR aims
to formalize and automate. While Carlsmith spent months developing this
model manually, similar rigor exists implicitly in many AI safety
arguments awaiting extraction.

\subsection*{2.1.2 Why Carlsmith Exemplifies Formalizable
Arguments}\label{sec-carlsmith-formalizable}
\addcontentsline{toc}{subsection}{2.1.2 Why Carlsmith Exemplifies
Formalizable Arguments}

Carlsmith's model represents ``low-hanging fruit'' for automated
formalization because it already exhibits explicit probabilistic
reasoning with clear conditional dependencies. Success with this
structured argument validates the approach for less explicit arguments
throughout AI safety literature.

Carlsmith's model demonstrates several features that make it ideal for
formal representation:

\textbf{Explicit Probabilistic Structure}: Each premise receives
numerical probability estimates with documented reasoning, enabling
direct translation to Bayesian network parameters.

\textbf{Clear Conditional Dependencies}: The logical flow from
capabilities through deployment decisions to catastrophic outcomes maps
naturally onto directed acyclic graphs.

\textbf{Transparent Decomposition}: Breaking the argument into modular
premises allows independent evaluation and sensitivity analysis of each
component.

\textbf{Documented Reasoning}: Extensive justification for each
probability enables extraction of both structure and parameters from the
source text.

\textcite{christiano2019}

\section*{2.2 The Epistemic Challenge of Policy
Evaluation}\label{sec-epistemic-challenge}
\addcontentsline{toc}{section}{2.2 The Epistemic Challenge of Policy
Evaluation}

\markright{2.2 The Epistemic Challenge of Policy Evaluation}

AI governance policy evaluation faces unique epistemic challenges that
render traditional policy analysis methods insufficient. Understanding
these challenges motivates the need for new computational approaches.

\subsection*{2.2.1 Unique Characteristics of AI
Governance}\label{sec-ai-governance-unique}
\addcontentsline{toc}{subsection}{2.2.1 Unique Characteristics of AI
Governance}

AI governance policy evaluation faces unique epistemic challenges that
render traditional policy analysis methods insufficient. The domain
combines complex causal chains with limited empirical grounding, deep
uncertainty about future capabilities, divergent stakeholder worldviews,
and few opportunities for experimental testing before deployment.

\textbf{Deep Uncertainty Rather Than Risk}: Traditional policy analysis
distinguishes between risk (known probability distributions) and
uncertainty (known possibilities, unknown probabilities). AI governance
faces deep uncertainty---we cannot confidently enumerate possible
futures, much less assign probabilities. Will recursive self-improvement
enable rapid capability gains? Can value alignment be solved
technically? These foundational questions resist empirical resolution
before their answers become catastrophically relevant.

\textbf{Complex Multi-Level Causation}: Policy effects propagate through
technical, institutional, and social levels with intricate feedback
loops. A technical standard might alter research incentives, shifting
capability development trajectories, changing competitive dynamics, and
ultimately affecting existential risk through pathways invisible at the
policy's inception. Traditional linear causal models cannot capture
these dynamics.

\textbf{Irreversibility and Lock-In}: Many AI governance decisions
create path dependencies that prove difficult or impossible to reverse.
Early technical standards shape development trajectories. Institutional
structures ossify. International agreements create sticky equilibria.
Unlike many policy domains where course correction remains possible, AI
governance mistakes may prove permanent.

\textbf{Value-Laden Technical Choices}: The entanglement of technical
and normative questions confounds traditional separation of facts and
values. What constitutes ``alignment''? How much capability development
should we risk for economic benefits? Technical specifications embed
ethical judgments that resist neutral expertise.

\subsection*{2.2.2 Limitations of Traditional
Approaches}\label{sec-traditional-limitations}
\addcontentsline{toc}{subsection}{2.2.2 Limitations of Traditional
Approaches}

Traditional methods fall short in several ways. Cost-benefit analysis
struggles with existential outcomes and deep uncertainty about
unprecedented events. Scenario planning often lacks the probabilistic
reasoning necessary for rigorous evaluation under uncertainty. Expert
elicitation alone fails to formalize interdependencies between variables
and make assumptions explicit. Qualitative approaches obscure crucial
assumptions that drive conclusions, making it difficult to identify
cruxes of disagreement.

Standard policy evaluation tools prove inadequate for these challenges:

\textbf{Cost-Benefit Analysis} assumes commensurable outcomes and stable
probability distributions. When potential outcomes include existential
catastrophe with deeply uncertain probabilities, the mathematical
machinery breaks down. Infinite negative utility resists standard
decision frameworks.

\textbf{Scenario Planning} helps explore possible futures but typically
lacks the probabilistic reasoning needed for decision-making under
uncertainty. Without quantification, scenarios provide narrative
richness but limited action guidance.

\textbf{Expert Elicitation} aggregates specialist judgment but struggles
with interdisciplinary questions where no single expert grasps all
relevant factors. Moreover, experts often operate with different
implicit models, making aggregation problematic.

\textbf{Red Team Exercises} test specific plans but miss systemic risks
emerging from component interactions. Gaming individual failures cannot
reveal emergent catastrophic possibilities.

These limitations create a methodological gap: we need approaches that
handle deep uncertainty, represent complex causation, quantify expert
disagreement, and enable systematic exploration of intervention effects.

\textcite{hallegatte2012}

\subsection*{2.2.3 The Underlying Epistemic
Framework}\label{the-underlying-epistemic-framework}
\addcontentsline{toc}{subsection}{2.2.3 The Underlying Epistemic
Framework}

--\textgreater{}

\subsection*{2.2.4 Toward New Epistemic
Tools}\label{sec-new-epistemic-tools}
\addcontentsline{toc}{subsection}{2.2.4 Toward New Epistemic Tools}

The inadequacy of traditional methods for AI governance creates an
urgent need for new epistemic tools. These tools must:

\begin{itemize}
\tightlist
\item
  \textbf{Handle Deep Uncertainty}: Move beyond point estimates to
  represent ranges of possibilities
\item
  \textbf{Capture Complex Causation}: Model multi-level interactions and
  feedback loops
\item
  \textbf{Quantify Disagreement}: Make explicit where experts diverge
  and why
\item
  \textbf{Enable Systematic Analysis}: Support rigorous comparison of
  policy options
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, arc=.35mm, titlerule=0mm, breakable, toprule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, coltitle=black, bottomrule=.15mm, bottomtitle=1mm, opacityback=0, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Key Insight}, rightrule=.15mm, leftrule=.75mm, colback=white, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, left=2mm]

The computational approaches developed in this thesis---particularly
Bayesian networks enhanced with automated extraction---directly address
each of these requirements by providing formal frameworks for reasoning
under uncertainty.

\end{tcolorbox}

from \textcite{tetlock2022}

\begin{figure}

\centering{

\href{https://www.metaculus.com/tournament/3508/}{\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/conditional_metaculus.jpg}}

}

\caption[Conditional-tree AI-risk
forecasts]{\label{fig-conditional_metaculus}Conditional-tree AI-risk
forecasts}

\end{figure}%

from \textcite{gruetzemacher2022}

\begin{figure}

\centering{

\href{https://bnma.co/uai2022-apps-workshop/papers/S5.pdf}{\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/bns_and_conditional_trees.jpg}}

}

\caption[Bayes-net pruning → crux extraction →
re-expansion]{\label{fig-bayesnet-crux-flow}Bayes-net pruning → crux
extraction → re-expansion}

\end{figure}%

from \textcite{mccaslin2024}

\begin{figure}

\centering{

\href{https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/66ba37a144f1d6095de467df/1723479995772/AIConditionalTrees.pdf\#page=5.78}{\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/conditional_tree.jpg}}

}

\caption[Conditional-tree
Guide]{\label{fig-conditional_tree}Conditional-tree Guide}

\end{figure}%

from \textcite{mccaslin2024}

\begin{figure}

\centering{

\href{https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/66ba37a144f1d6095de467df/1723479995772/AIConditionalTrees.pdf\#page=5.78}{\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/concerned_experts.jpg}}

}

\caption[Experts' conditional-tree updates
(2030-2070)]{\label{fig-concerned_experts}Experts' conditional-tree
updates (2030-2070)}

\end{figure}%

\textcite{mccaslin2024}

\textcite{tetlock2022}

\textcite{gruetzemacher2022}

\section*{2.3 Bayesian Networks as Knowledge
Representation}\label{sec-bayesian-networks}
\addcontentsline{toc}{section}{2.3 Bayesian Networks as Knowledge
Representation}

\markright{2.3 Bayesian Networks as Knowledge Representation}

Bayesian networks offer a mathematical framework uniquely suited to
addressing these epistemic challenges. By combining graphical structure
with probability theory, they provide tools for reasoning about complex
uncertain domains.

\subsection*{2.3.1 Mathematical
Foundations}\label{sec-mathematical-foundations}
\addcontentsline{toc}{subsection}{2.3.1 Mathematical Foundations}

A Bayesian network consists of:

\begin{itemize}
\tightlist
\item
  \textbf{Directed Acyclic Graph (DAG)}: Nodes represent variables,
  edges represent direct dependencies
\item
  \textbf{Conditional Probability Tables (CPTs)}: For each node,
  P(node\textbar parents) quantifies relationships
\end{itemize}

The joint probability distribution factors according to the graph
structure: \[
 P(X1,X2,...,Xn)=∏i=1nP(Xi∣Parents(Xi))P(X_1, X_2, ..., X_n) = \prod_{i=1}^{n} P(X_i | Parents(X_i))P(X1​,X2​,...,Xn​)=i=1∏n​P(Xi​∣Parents(Xi​)) 
\]

This factorization enables efficient inference and embodies causal
assumptions explicitly.

\textcite{pearl2014}

\subsection*{2.3.2 The Rain-Sprinkler-Grass
Example}\label{sec-rain-sprinkler-example}
\addcontentsline{toc}{subsection}{2.3.2 The Rain-Sprinkler-Grass
Example}

The canonical example illustrates key concepts:\footnote{This example,
  while simple, demonstrates all essential features of Bayesian networks
  and serves as the foundation for understanding more complex
  applications}

\begin{verbatim}
[Grass_Wet]: Concentrated moisture on grass. 
 + [Rain]: Water falling from sky.
 + [Sprinkler]: Artificial watering system.
   + [Rain]
\end{verbatim}

Network Structure:

\begin{itemize}
\tightlist
\item
  \textbf{Rain} (root cause): P(rain) = 0.2
\item
  \textbf{Sprinkler} (intermediate): P(sprinkler\textbar rain) varies by
  rain state
\item
  \textbf{Grass\_Wet} (effect): P(wet\textbar rain, sprinkler) depends
  on both causes
\end{itemize}

python

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Basic network representation}
\NormalTok{nodes }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}Rain\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Sprinkler\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Grass\_Wet\textquotesingle{}}\NormalTok{]}
\NormalTok{edges }\OperatorTok{=}\NormalTok{ [(}\StringTok{\textquotesingle{}Rain\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Sprinkler\textquotesingle{}}\NormalTok{), (}\StringTok{\textquotesingle{}Rain\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Grass\_Wet\textquotesingle{}}\NormalTok{), (}\StringTok{\textquotesingle{}Sprinkler\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Grass\_Wet\textquotesingle{}}\NormalTok{)]}

\CommentTok{\# Conditional probability specification}
\NormalTok{P\_wet\_given\_causes }\OperatorTok{=}\NormalTok{ \{}
\NormalTok{    (}\VariableTok{True}\NormalTok{, }\VariableTok{True}\NormalTok{): }\FloatTok{0.99}\NormalTok{,    }\CommentTok{\# Rain=T, Sprinkler=T}
\NormalTok{    (}\VariableTok{True}\NormalTok{, }\VariableTok{False}\NormalTok{): }\FloatTok{0.80}\NormalTok{,   }\CommentTok{\# Rain=T, Sprinkler=F  }
\NormalTok{    (}\VariableTok{False}\NormalTok{, }\VariableTok{True}\NormalTok{): }\FloatTok{0.90}\NormalTok{,   }\CommentTok{\# Rain=F, Sprinkler=T}
\NormalTok{    (}\VariableTok{False}\NormalTok{, }\VariableTok{False}\NormalTok{): }\FloatTok{0.01}   \CommentTok{\# Rain=F, Sprinkler=F}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

This simple network demonstrates:

\begin{itemize}
\tightlist
\item
  \textbf{Marginal Inference}: P(grass\_wet) computed from joint
  distribution
\item
  \textbf{Diagnostic Reasoning}: P(rain\textbar grass\_wet) reasoning
  from effects to causes
\item
  \textbf{Intervention Modeling}: P(grass\_wet\textbar do(sprinkler=on))
  for policy analysis
\end{itemize}

\subsubsection*{Rain-Sprinkler-Grass Network
Rendering}\label{rain-sprinkler-grass-network-rendering-1}
\addcontentsline{toc}{subsubsection}{Rain-Sprinkler-Grass Network
Rendering}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ IPython.display }\ImportTok{import}\NormalTok{ IFrame}

\NormalTok{IFrame(src}\OperatorTok{=}\StringTok{"https://singularitysmith.github.io/AMTAIR\_Prototype/bayesian\_network.html"}\NormalTok{, width}\OperatorTok{=}\StringTok{"100\%"}\NormalTok{, height}\OperatorTok{=}\StringTok{"600px"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\phantomsection\label{rain_sprinkler_grass_example_network_rendering}
\begin{verbatim}
<IPython.lib.display.IFrame at 0x104b55750>
\end{verbatim}

Dynamic Html Rendering of the Rain-Sprinkler-Grass DAG with Conditional
Probabilities

\subsection*{2.3.3 Advantages for AI Risk
Modeling}\label{sec-modeling-advantages}
\addcontentsline{toc}{subsection}{2.3.3 Advantages for AI Risk Modeling}

Bayesian networks offer several key advantages for AI risk modeling.
They provide explicit uncertainty representation where all beliefs are
represented with probability distributions rather than point estimates.
The framework naturally supports causal reasoning through native support
for intervention analysis and counterfactual reasoning via do-calculus.
Evidence integration becomes principled through Bayesian updating
mechanisms. The modular structure allows complex arguments to be
decomposed into manageable, verifiable components. Finally, the visual
communication provided by graphical representation facilitates
understanding across different expertise levels.

These features address key requirements for AI governance:

\begin{itemize}
\tightlist
\item
  \textbf{Handling Uncertainty}: Every parameter is a distribution, not
  a point estimate
\item
  \textbf{Representing Causation}: Directed edges embody causal
  relationships
\item
  \textbf{Enabling Analysis}: Formal inference algorithms support
  systematic evaluation
\item
  \textbf{Facilitating Communication}: Visual structure aids
  cross-domain understanding
\end{itemize}

\section*{2.4 Argument Mapping and Formal
Representations}\label{sec-argument-mapping}
\addcontentsline{toc}{section}{2.4 Argument Mapping and Formal
Representations}

\markright{2.4 Argument Mapping and Formal Representations}

The gap between natural language arguments and formal models requires
systematic bridging. Argument mapping provides methods for making
implicit reasoning structures explicit and analyzable.

\subsection*{2.4.1 From Natural Language to
Structure}\label{sec-natural-to-structure}
\addcontentsline{toc}{subsection}{2.4.1 From Natural Language to
Structure}

Natural language arguments contain rich information expressed through:

\begin{itemize}
\tightlist
\item
  Causal claims (``X leads to Y'')
\item
  Conditional relationships (``If A then likely B'')
\item
  Uncertainty expressions (``probably,'' ``might,'' ``certainly'')
\item
  Support/attack patterns between claims
\end{itemize}

Argument mapping extracts this structure, identifying:

\begin{itemize}
\tightlist
\item
  \textbf{Core claims and propositions}
\item
  \textbf{Inferential relationships}
\item
  \textbf{Implicit assumptions}
\item
  \textbf{Uncertainty qualifications}
\end{itemize}

from \textcite{metropolitansky2025}

\begin{figure}

\centering{

\href{https://www.microsoft.com/en-us/research/blog/claimify-extracting-high-quality-claims-from-language-model-outputs/}{\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/claimify-stages.jpg}}

}

\caption[Claimify claim-extraction
stages]{\label{fig-claimify-stages}Claimify claim-extraction stages}

\end{figure}%

\textcite{anderson2007}

\textcite{benn2011}

\textcite{khartabil2021}

\textcite{khartabil2020}

\textcite{ngajie2020}

\textcite{prokudin2024}

\textcite{scheuer2010}

\textcite{thomas1962}

\textcite{walton2009}

\subsection*{2.4.2 ArgDown: Structured Argument
Notation}\label{sec-argdown-notation}
\addcontentsline{toc}{subsection}{2.4.2 ArgDown: Structured Argument
Notation}

\textcite{voigt2025}

ArgDown provides a markdown-like syntax for hierarchical argument
representation:

\begin{verbatim}
[MainClaim]: Description of primary conclusion.
 + [SupportingEvidence]: Evidence supporting the claim.
   + [SubEvidence]: More specific support.
 - [CounterArgument]: Evidence against the claim.
\end{verbatim}

This notation captures argument structure while remaining human-readable
and writable. Crucially, it serves as an intermediate representation
between natural language and formal models.

Argument mapping provides a bridge between natural language reasoning
and formal probabilistic models, enabling the transformation of complex
qualitative arguments into structured representations suitable for
computational analysis. This section explores two key intermediate
representations---ArgDown and BayesDown---that facilitate this
transformation process.

Argument maps are structured visualizations that represent the logical
relationships between claims, evidence, and objections. Unlike free-form
text, they make explicit how different statements support or challenge
one another, forcing clarity about the logical structure of arguments.
Traditional argument maps typically include:

\begin{itemize}
\tightlist
\item
  Statements (claims, premises, conclusions) presented as nodes
\item
  Support and attack relationships shown as arrows between nodes
\item
  Hierarchical organization reflecting logical dependencies
\end{itemize}

These visualizations help identify unstated assumptions, circular
reasoning, and gaps in argumentation. However, traditional argument
mapping has limited expressivity for representing uncertainty---a
crucial element in complex domains like AI risk assessment.

ArgDown extends the concept of argument mapping into a structured text
format with a consistent syntax. Developed by Christian Voigt with
support from the Karlsruhe Institute of Technology, ArgDown provides a
markdown-like notation for representing arguments in a hierarchical
structure that can be automatically visualized and analyzed. The basic
syntax is:

argdown

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{[Statement]: }\NormalTok{Description of the statement.}
\SpecialStringTok{ + }\CommentTok{[}\OtherTok{Supporting\_Statement}\CommentTok{]}\NormalTok{: Description of supporting statement.}
\SpecialStringTok{   + }\CommentTok{[}\OtherTok{Further\_Support}\CommentTok{]}\NormalTok{: Description of additional support.}
\SpecialStringTok{ {-} }\CommentTok{[}\OtherTok{Opposing\_Statement}\CommentTok{]}\NormalTok{: Description of opposing statement.}
\end{Highlighting}
\end{Shaded}

For the AMTAIR project, we adapt ArgDown to focus on causal
relationships rather than general argumentation, using a modified syntax
where the hierarchical structure represents causal influence:

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{[}\ErrorTok{Effect}\OtherTok{]}\ErrorTok{:} \ErrorTok{Description} \ErrorTok{of} \ErrorTok{effect.} \FunctionTok{\{}\DataTypeTok{"instantiations"}\FunctionTok{:} \OtherTok{[}\StringTok{"effect\_TRUE"}\OtherTok{,} \StringTok{"effect\_FALSE"}\OtherTok{]}\FunctionTok{\}}
 \ErrorTok{+} \OtherTok{[}\ErrorTok{Cause1}\OtherTok{]}\ErrorTok{:} \ErrorTok{Description} \ErrorTok{of} \ErrorTok{first} \ErrorTok{cause.} \FunctionTok{\{}\DataTypeTok{"instantiations"}\FunctionTok{:} \OtherTok{[}\StringTok{"cause1\_TRUE"}\OtherTok{,} \StringTok{"cause1\_FALSE"}\OtherTok{]}\FunctionTok{\}}
 \ErrorTok{+} \OtherTok{[}\ErrorTok{Cause2}\OtherTok{]}\ErrorTok{:} \ErrorTok{Description} \ErrorTok{of} \ErrorTok{second} \ErrorTok{cause.} \FunctionTok{\{}\DataTypeTok{"instantiations"}\FunctionTok{:} \OtherTok{[}\StringTok{"cause2\_TRUE"}\OtherTok{,} \StringTok{"cause2\_FALSE"}\OtherTok{]}\FunctionTok{\}}
   \ErrorTok{+} \OtherTok{[}\ErrorTok{Root\_Cause}\OtherTok{]}\ErrorTok{:} \ErrorTok{A} \ErrorTok{cause} \ErrorTok{that} \ErrorTok{influences} \ErrorTok{Cause2.} \FunctionTok{\{}\DataTypeTok{"instantiations"}\FunctionTok{:} \OtherTok{[}\StringTok{"root\_TRUE"}\OtherTok{,} \StringTok{"root\_FALSE"}\OtherTok{]}\FunctionTok{\}}
\end{Highlighting}
\end{Shaded}

This adaptation adds metadata in JSON format to specify possible states
(instantiations) of each variable, preparing the structure for
probabilistic enhancement. The hierarchical relationships (indented with
plus signs) represent causal influence, creating a directed graph
structure.

\subsection*{2.4.3 BayesDown: The Bridge to Bayesian
Networks}\label{sec-bayesdown}
\addcontentsline{toc}{subsection}{2.4.3 BayesDown: The Bridge to
Bayesian Networks}

BayesDown extends ArgDown with probabilistic metadata:

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{[}\ErrorTok{Node}\OtherTok{]}\ErrorTok{:} \ErrorTok{Description.} \FunctionTok{\{}
  \DataTypeTok{"instantiations"}\FunctionTok{:} \OtherTok{[}\StringTok{"node\_TRUE"}\OtherTok{,} \StringTok{"node\_FALSE"}\OtherTok{]}\FunctionTok{,}
  \DataTypeTok{"priors"}\FunctionTok{:} \FunctionTok{\{}\DataTypeTok{"p(node\_TRUE)"}\FunctionTok{:} \StringTok{"0.7"}\FunctionTok{,} \DataTypeTok{"p(node\_FALSE)"}\FunctionTok{:} \StringTok{"0.3"}\FunctionTok{\},}
  \DataTypeTok{"posteriors"}\FunctionTok{:} \FunctionTok{\{}
    \DataTypeTok{"p(node\_TRUE|parent\_TRUE)"}\FunctionTok{:} \StringTok{"0.9"}\FunctionTok{,}
    \DataTypeTok{"p(node\_TRUE|parent\_FALSE)"}\FunctionTok{:} \StringTok{"0.4"}
  \FunctionTok{\}}
\FunctionTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{[}\ErrorTok{Node}\OtherTok{]}\ErrorTok{:} \ErrorTok{Description.} \FunctionTok{\{}
  \DataTypeTok{"instantiations"}\FunctionTok{:} \OtherTok{[}\StringTok{"node\_TRUE"}\OtherTok{,} \StringTok{"node\_FALSE"}\OtherTok{]}\FunctionTok{,}
  \DataTypeTok{"priors"}\FunctionTok{:} \FunctionTok{\{}
    \DataTypeTok{"p(node\_TRUE)"}\FunctionTok{:} \StringTok{"0.7"}\FunctionTok{,}
    \DataTypeTok{"p(node\_FALSE)"}\FunctionTok{:} \StringTok{"0.3"}
  \FunctionTok{\},}
  \DataTypeTok{"posteriors"}\FunctionTok{:} \FunctionTok{\{}
    \DataTypeTok{"p(node\_TRUE|parent\_TRUE)"}\FunctionTok{:} \StringTok{"0.9"}\FunctionTok{,}
    \DataTypeTok{"p(node\_TRUE|parent\_FALSE)"}\FunctionTok{:} \StringTok{"0.4"}\FunctionTok{,}
    \DataTypeTok{"p(node\_FALSE|parent\_TRUE)"}\FunctionTok{:} \StringTok{"0.1"}\FunctionTok{,}
    \DataTypeTok{"p(node\_FALSE|parent\_FALSE)"}\FunctionTok{:} \StringTok{"0.6"}
  \FunctionTok{\}}
\FunctionTok{\}}
\end{Highlighting}
\end{Shaded}

This representation:

\begin{itemize}
\tightlist
\item
  \textbf{Preserves narrative structure} from the original argument
\item
  \textbf{Adds mathematical precision} through probability
  specifications
\item
  \textbf{Enables transformation} to standard Bayesian network formats
\item
  \textbf{Supports validation} by maintaining traceability to sources
\end{itemize}

The two-stage extraction process (ArgDown → BayesDown) separates
concerns: first capturing structure, then quantifying relationships.
This modularity enables human oversight at critical decision points.

The intermediate representations (ArgDown and BayesDown) remain
human-readable, maintaining the connection to the original arguments
while enabling computational analysis.

The key innovation in this approach is the separation of structure
extraction from probability quantification, which aligns with how
experts typically approach complex arguments. First, they identify what
factors matter and how they relate causally, then they consider how
probable different scenarios are based on those relationships. This
two-stage process makes the extraction more robust and the resulting
representations more interpretable.

\section*{2.5 The MTAIR Framework: Achievements and
Limitations}\label{sec-mtair-framework}
\addcontentsline{toc}{section}{2.5 The MTAIR Framework: Achievements and
Limitations}

\markright{2.5 The MTAIR Framework: Achievements and Limitations}

The Modeling Transformative AI Risks (MTAIR) project, led by RAND
researchers, pioneered formal modeling of AI existential risk arguments.
Understanding its approach and limitations motivates the automation
efforts of AMTAIR.

\subsection*{2.5.1 MTAIR's Approach}\label{sec-mtair-approach}
\addcontentsline{toc}{subsection}{2.5.1 MTAIR's Approach}

The Modeling Transformative AI Risks (MTAIR) project, led by David
Manheim and colleagues, represents a significant precursor to the
current research. Launched in 2021, MTAIR aimed to create structured
representations of existential risks from advanced AI using Bayesian
networks, directed acyclic graphs, and probabilistic modeling.
Understanding its achievements and limitations provides important
context for the current AMTAIR approach.

MTAIR emerged from the recognition that AI risk discussions often
involved complex causal arguments with implicit probability judgments
that were difficult to compare or integrate. By formalizing these
arguments in structured models, the project sought to make assumptions
explicit, enable quantitative analysis, and facilitate more productive
discourse across different perspectives on AI risk.

The framework's key innovations included:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Explicit representation of uncertainty through probability
  distributions:} Rather than presenting point estimates, MTAIR captured
  uncertainty about parameters using distributions, acknowledging the
  significant uncertainty in AI risk assessment.
\item
  \textbf{Hierarchical structure for complex scenarios:} The approach
  used nested models that allowed exploration of different levels of
  detail, from high-level risk factors to specific technical mechanisms.
\item
  \textbf{Integration of diverse expert judgments:} The framework
  incorporated perspectives from various specialists, creating a more
  comprehensive view than any single expert could provide.
\item
  \textbf{Sensitivity analysis methodology:} MTAIR developed techniques
  for identifying which parameters most significantly affected risk
  estimates, helping prioritize research efforts.
\end{enumerate}

The project's practical impact extended beyond its technical
achievements. It influenced research prioritization by identifying
critical uncertainties that warranted further investigation. It enhanced
discourse quality by providing a shared vocabulary and structure for
discussing causal pathways to risk. It also created visual
representations that made complex arguments more accessible to
stakeholders without technical backgrounds.

Despite these achievements, MTAIR faced several important limitations:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Manual labor intensity limiting scalability:} Creating and
  updating models required substantial expert time, limiting the number
  and complexity of models that could be developed and maintained. As
  one team member noted, ``It often took several days of work to
  formalize even relatively straightforward arguments.''
\item
  \textbf{Static nature of models once constructed:} The models were
  essentially snapshots that did not automatically update as new
  information emerged, requiring manual revision to remain current.
\item
  \textbf{Limited accessibility for non-technical stakeholders:} While
  visual representations improved accessibility, understanding and
  interacting with the models still required specialized knowledge.
\item
  \textbf{Challenges in representing multiple worldviews
  simultaneously:} Comparing different perspectives required creating
  separate models, making it difficult to identify specific points of
  agreement and disagreement.
\end{enumerate}

These limitations motivate the current research in automating the
extraction and transformation process. As AI capabilities advance and
the volume of relevant research grows, manual approaches cannot keep
pace with the need for comprehensive, up-to-date models. Automation
addresses the scalability limitation by dramatically reducing the time
required to create formal representations of expert arguments.

Moreover, incorporating frontier LLMs into the pipeline enables new
capabilities that were not feasible in the original MTAIR framework.
These include:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Processing larger volumes of literature to capture more diverse
  perspectives
\item
  Generating intermediate representations that preserve narrative
  structure
\item
  Automating the creation of probability questions based on model
  structure
\item
  Facilitating integration with live data sources for continuous updates
\end{enumerate}

By building on MTAIR's foundation while addressing its key limitations,
the current research maintains continuity with established approaches to
AI risk modeling while pushing the boundaries of what's possible through
automation and enhanced representation formats.

The evolution from MTAIR to AMTAIR represents a natural progression: as
the field matures and the challenges become more pressing, more
sophisticated tools are needed to facilitate coordination and
decision-making. Automation doesn't replace expert judgment but
amplifies it, allowing insights to be captured, formalized, and shared
more efficiently across the AI governance community.

The Modeling Transformative AI Risks (MTAIR) project demonstrated the
value of formal probabilistic modeling for AI safety, but also revealed
significant limitations in the manual approach. While MTAIR successfully
translated complex arguments into Bayesian networks and enabled
sensitivity analysis, the intensive human labor required for model
creation limited both scalability and timeliness.

MTAIR manually translated influential AI risk arguments into Bayesian
networks using Analytica software:

\textbf{Systematic Decomposition}: Breaking complex arguments into
variables and relationships through expert analysis.

\textbf{Probability Elicitation}: Gathering quantitative estimates
through structured expert interviews and literature review.

\textbf{Sensitivity Analysis}: Identifying which parameters most
influence conclusions about AI risk levels.

\textbf{Visual Communication}: Creating interactive models that
stakeholders could explore and modify.

\textcite{clarke2022}

\subsection*{2.5.2 Key Achievements}\label{sec-mtair-achievements}
\addcontentsline{toc}{subsection}{2.5.2 Key Achievements}

MTAIR demonstrated several important possibilities:

\textbf{Feasibility of Formalization}: Complex philosophical arguments
about AI risk can be represented as Bayesian networks while preserving
essential insights.

\textbf{Value of Quantification}: Moving from qualitative concerns to
quantitative models enables systematic analysis, comparison, and
prioritization.

\textbf{Cross-Perspective Communication}: Formal models provide common
ground for technical and policy communities to engage productively.

\textbf{Research Prioritization}: Sensitivity analysis reveals which
empirical questions would most reduce uncertainty about AI risks.

\subsection*{2.5.3 Fundamental Limitations}\label{sec-mtair-limitations}
\addcontentsline{toc}{subsection}{2.5.3 Fundamental Limitations}

Despite its innovations, MTAIR faces fundamental limitations that
motivate the automated approach. The scalability bottleneck is
severe---manual model construction requires weeks of expert effort per
argument, making comprehensive coverage impossible. The static nature of
manually constructed models provides no mechanisms for updating as new
research and evidence emerge. Limited accessibility restricts usage to
specialists with formal modeling expertise, excluding many stakeholders.
Finally, the single worldview focus creates difficulty in representing
multiple conflicting perspectives simultaneously, limiting the
framework's utility for coordination across diverse viewpoints.

However, MTAIR's manual approach faces severe constraints:

\textbf{Labor Intensity}: Each model requires dozens of expert-hours to
construct, limiting coverage to a few perspectives.

\textbf{Static Nature}: Models become outdated as arguments evolve but
updating requires near-complete reconstruction.

\textbf{Limited Accessibility}: Using the models requires Analytica
software and significant technical sophistication.

\textbf{Single Perspective}: Each model represents one worldview, making
comparison across perspectives difficult.

These limitations prevent MTAIR's approach from scaling to meet AI
governance needs. As the pace of AI development accelerates and
arguments proliferate, manual modeling cannot keep pace.

from \textcite{clarke2022}

\begin{figure}

\centering{

\href{https://arxiv.org/pdf/2206.09360\#page=10.75}{\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/mtair-qual-map.jpg}}

}

\caption[MTAIR Qualitative map
structure]{\label{fig-mtair-qual-map}MTAIR Qualitative map structure}

\end{figure}%

from \textcite{clarke2022}

\begin{figure}

\centering{

\href{https://arxiv.org/pdf/2206.09360\#page=10.75}{\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/mtair-quant-map.jpg}}

}

\caption[MTAIR Quantitative map
structure]{\label{fig-mtair-quant-map}MTAIR Quantitative map structure}

\end{figure}%

from \textcite{manheim2021}

\begin{figure}

\centering{

\href{https://www.lesswrong.com/posts/sGkRDrpphsu6Jhega/a-model-based-approach-to-ai-existential-risk}{\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/mtair-insideoutside-base.jpg}}

}

\caption[Base APS causal map
(clean)]{\label{fig-mtair-insideoutside-base}Base APS causal map}

\end{figure}%

from \textcite{manheim2021}

\begin{figure}

\centering{

\href{https://www.lesswrong.com/posts/sGkRDrpphsu6Jhega/a-model-based-approach-to-ai-existential-risk}{\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/mtair-insideoutside-overlay.jpg}}

}

\caption[Overlay of inside/outside/assimilation
views]{\label{fig-mtair-insideoutside-overlay}Overlay of
inside/outside/assimilation views}

\end{figure}%

\subsection*{2.5.4 The Automation
Opportunity}\label{sec-automation-opportunity}
\addcontentsline{toc}{subsection}{2.5.4 The Automation Opportunity}

MTAIR's experience reveals both the value of formal modeling and the
necessity of automation. Key lessons:

\begin{itemize}
\tightlist
\item
  Formal models genuinely enhance understanding and coordination
\item
  The modeling process itself surfaces implicit assumptions
\item
  Quantification enables analyses impossible with qualitative arguments
  alone
\item
  But manual approaches cannot scale to match the challenge
\end{itemize}

This motivates AMTAIR's central innovation: using frontier language
models to automate the extraction and formalization process while
preserving the benefits MTAIR demonstrated.

\section*{2.6 Literature Review: Content and Technical
Levels}\label{sec-literature-review}
\addcontentsline{toc}{section}{2.6 Literature Review: Content and
Technical Levels}

\markright{2.6 Literature Review: Content and Technical Levels}

from \textcite{cottier2019}

\begin{figure}

\centering{

\href{https://www.lesswrong.com/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment\#Agentive_AGI_}{\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/hypotheses_diagram.pdf}}

}

\caption[Key hypotheses in AI
alignment]{\label{fig-ai-hypotheses-map}Key hypotheses in AI alignment}

\end{figure}%

\subsection*{2.6.1 AI Risk Models
Evolution}\label{sec-risk-models-evolution}
\addcontentsline{toc}{subsection}{2.6.1 AI Risk Models Evolution}

The evolution of AI risk models reflects increasing sophistication in
both structure and quantification. Early models focused on simple binary
outcomes, while recent work incorporates complex causal chains and
continuous variables.

\begin{tcolorbox}[enhanced jigsaw, arc=.35mm, titlerule=0mm, breakable, toprule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, coltitle=black, bottomrule=.15mm, bottomtitle=1mm, opacityback=0, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, rightrule=.15mm, leftrule=.75mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, left=2mm]

\#\# Key Developments

\begin{itemize}
\tightlist
\item
  \textbf{Early Phase (2000-2010)}: Qualitative arguments about
  intelligence explosion
\item
  \textbf{Formalization Phase (2010-2018)}: Introduction of structured
  scenarios
\item
  \textbf{Quantification Phase (2018-present)}: Explicit probability
  estimates and formal models
\end{itemize}

\end{tcolorbox}

\textcite{yudkowsky2008}

\textcite{bostrom2014}

\textcite{amodei2016}

The progression from qualitative arguments to structured probabilistic
models demonstrates the field's maturation and the increasing
recognition that rigorous quantitative analysis is essential for policy
evaluation.

\subsection*{2.6.2 Governance Proposals
Taxonomy}\label{sec-governance-taxonomy}
\addcontentsline{toc}{subsection}{2.6.2 Governance Proposals Taxonomy}

AI governance proposals can be categorized along several dimensions:

\begin{itemize}
\tightlist
\item
  \textbf{Technical Standards}: Safety requirements, testing protocols,
  capability thresholds
\item
  \textbf{Regulatory Frameworks}: Licensing regimes, liability
  structures, oversight mechanisms
\item
  \textbf{International Coordination}: Treaties, soft law arrangements,
  technical cooperation
\item
  \textbf{Research Priorities}: Funding allocation, talent development,
  knowledge sharing
\end{itemize}

\textcite{dafoe2021} and \textcite{dafoe2018}

\textcite{miotti2024}

\subsection*{2.6.3 Bayesian Network Theory and
Applications}\label{sec-bn-theory}
\addcontentsline{toc}{subsection}{2.6.3 Bayesian Network Theory and
Applications}

The theoretical foundations of Bayesian networks rest on probability
theory and graph theory. Key concepts include:

\begin{itemize}
\tightlist
\item
  \textbf{Conditional Independence}: Encoded through d-separation
\item
  \textbf{Markov Condition}: Relating graph structure to probabilistic
  relationships
\item
  \textbf{Inference Algorithms}: From exact methods to approximation
  approaches
\end{itemize}

\textcite{koller2009}

\subsection*{2.6.4 Software Tools Landscape}\label{sec-software-tools}
\addcontentsline{toc}{subsection}{2.6.4 Software Tools Landscape}

The implementation of AMTAIR builds on established software libraries:

\begin{itemize}
\tightlist
\item
  \textbf{pgmpy}: Python library for probabilistic graphical models
\item
  \textbf{NetworkX}: Graph analysis and manipulation capabilities
\item
  \textbf{PyVis}: Interactive network visualization
\item
  \textbf{Pandas/NumPy}: Data manipulation and numerical computation
\end{itemize}

\subsection*{2.6.5 Formalization Approaches}\label{sec-formalization}
\addcontentsline{toc}{subsection}{2.6.5 Formalization Approaches}

Formalizing natural language arguments into mathematical models involves
several theoretical challenges:

\begin{itemize}
\tightlist
\item
  \textbf{Semantic Preservation}: Maintaining meaning while adding
  precision
\item
  \textbf{Structural Extraction}: Identifying implicit relationships
\item
  \textbf{Uncertainty Quantification}: Mapping qualitative to
  quantitative expressions
\end{itemize}

\textcite{pollock1995}

\subsection*{2.6.6 Correlation Accounting
Methods}\label{sec-correlation-methods}
\addcontentsline{toc}{subsection}{2.6.6 Correlation Accounting Methods}

Standard Bayesian networks assume conditional independence given
parents, but real-world AI risk factors often exhibit complex
correlations. Methods for handling correlations include:

\begin{itemize}
\tightlist
\item
  \textbf{Copula Methods}: Modeling dependence structures separately
  from marginal distributions
\item
  \textbf{Hierarchical Models}: Capturing correlations through shared
  latent variables
\item
  \textbf{Explicit Correlation Nodes}: Adding nodes to represent
  correlation mechanisms
\item
  \textbf{Sensitivity Bounds}: Analyzing impact of independence
  assumptions
\end{itemize}

\textcite{nelson2006}

\section*{2.7 Methodology}\label{sec-methodology}
\addcontentsline{toc}{section}{2.7 Methodology}

\markright{2.7 Methodology}

\subsection*{2.7.1 Research Design Overview}\label{sec-research-design}
\addcontentsline{toc}{subsection}{2.7.1 Research Design Overview}

This research combines theoretical development with practical
implementation, following an iterative approach that moves between
conceptual refinement and technical validation.

The methodology encompasses formal framework development, computational
implementation, extraction quality assessment, and application to
real-world AI governance questions.

The research process follows four integrated phases:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Framework Development}: Creating theoretical foundations for
  automated worldview extraction
\item
  \textbf{Technical Implementation}: Building computational tools as
  working prototype
\item
  \textbf{Empirical Validation}: Assessing quality against expert
  benchmarks
\item
  \textbf{Policy Application}: Demonstrating practical utility for
  governance questions
\end{enumerate}

\subsection*{2.7.2 Formalizing World Models from AI Safety
Literature}\label{sec-formalizing-world-models}
\addcontentsline{toc}{subsection}{2.7.2 Formalizing World Models from AI
Safety Literature}

The core methodological challenge involves transforming natural language
arguments in AI safety literature into formal causal models with
explicit probability judgments.

This extraction process identifies key variables, causal relationships,
and both explicit and implicit probability estimates through a
systematic pipeline.

The extraction approach combines several elements:

\begin{itemize}
\tightlist
\item
  Identification of key variables and entities in text
\item
  Recognition of causal claims and relationships
\item
  Detection of explicit and implicit probability judgments
\item
  Transformation into structured intermediate representations
\item
  Conversion to formal Bayesian networks
\end{itemize}

Large language models facilitate this process through specialized
techniques:

\begin{itemize}
\tightlist
\item
  \textbf{Two-stage prompting}: Separating structure from probability
  extraction
\item
  \textbf{Template specialization}: Different approaches for different
  document types
\item
  \textbf{Implicit assumption detection}: Identifying unstated
  relationships
\item
  \textbf{Ambiguity handling}: Managing uncertainty in extraction
\end{itemize}

\subsection*{2.7.3 From Natural Language to Computational
Models}\label{sec-natural-to-computational}
\addcontentsline{toc}{subsection}{2.7.3 From Natural Language to
Computational Models}

\begin{tcolorbox}[enhanced jigsaw, arc=.35mm, titlerule=0mm, breakable, toprule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, coltitle=black, bottomrule=.15mm, bottomtitle=1mm, opacityback=0, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{The Two-Stage Extraction Process}, rightrule=.15mm, leftrule=.75mm, colback=white, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, left=2mm]

AMTAIR employs a novel two-stage process that separates structural
argument extraction from probability quantification, enabling modular
improvement and human oversight at critical decision points.

\end{tcolorbox}

The heart of the AMTAIR approach lies in its two-stage extraction
process, which transforms unstructured text into structured
probabilistic models through distinct steps that mirror human cognitive
processes. This separation---extracting structure before
probability---creates important advantages for automation quality,
intermediate verification, and interpretability.

When humans analyze complex arguments, they typically first determine
what factors matter and how they relate causally, then assess how likely
different scenarios are based on those relationships. A climate
scientist reading a paper first identifies key variables (emissions,
warming, effects) and their causal connections before estimating
probabilities of outcomes. This natural cognitive sequence inspired
AMTAIR's two-stage approach.

\textbf{Stage 1: Structure Extraction} focuses on identifying key
variables and their causal relationships from text, transforming
unstructured arguments into ArgDown format. This process involves:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Variable identification:} Determining the key factors
  discussed in the text, including their possible states (e.g., whether
  a factor is present/absent or has multiple levels)
\item
  \textbf{Relationship mapping:} Establishing how variables influence
  each other, creating a directed graph of causal connections
\item
  \textbf{Hierarchical organization:} Arranging variables according to
  their causal relationships, from root causes to final effects
\item
  \textbf{Metadata attachment:} Annotating each variable with its
  description and possible states in structured JSON format
\end{enumerate}

The LLM prompt for this stage emphasizes clear identification of causal
structure without requiring probability judgments, allowing the model to
focus entirely on understanding ``what affects what'' in the text. This
specialized prompt includes detailed instructions about ArgDown syntax,
examples of well-formed representations, and guidance for preserving the
author's intended meaning.

\phantomsection\label{parsing_argdown_bayesdown}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 1.7.0 {-}{-}{-} Parsing ArgDown \& BayesDown (.md to .csv) {-}{-}{-} [parsing\_argdown\_bayesdown]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Provides the core parsing functionality for transforming ArgDown}
\CommentTok{and BayesDown text representations into structured DataFrame format for further}
\CommentTok{processing.}

\CommentTok{This block implements the critical extraction pipeline described in the AMTAIR}
\CommentTok{project (see PY\_TechnicalImplementation) that converts argument structures}
\CommentTok{into Bayesian networks.}
\CommentTok{The function can handle both basic ArgDown (structure{-}only) and}
\CommentTok{BayesDown (with probabilities).}

\CommentTok{Key steps in the parsing process:}
\CommentTok{1. Remove comments from the markdown text}
\CommentTok{2. Extract titles, descriptions, and indentation levels}
\CommentTok{3. Establish parent{-}child relationships based on indentation}
\CommentTok{4. Convert the structured information into a DataFrame}
\CommentTok{5. Add derived columns for network analysis}

\CommentTok{DEPENDENCIES: pandas, re, json libraries}
\CommentTok{INPUTS: Markdown text in ArgDown/BayesDown format}
\CommentTok{OUTPUTS: Structured DataFrame with node information, relationships, and properties}
\CommentTok{"""}

\KeywordTok{def}\NormalTok{ parse\_markdown\_hierarchy\_fixed(markdown\_text, ArgDown}\OperatorTok{=}\VariableTok{False}\NormalTok{):}
    \CommentTok{"""}
\CommentTok{    Parse ArgDown or BayesDown format into a structured DataFrame with parent{-}child relationships.}

\CommentTok{    Args:}
\CommentTok{        markdown\_text (str): Text in ArgDown or BayesDown format}
\CommentTok{        ArgDown (bool): If True, extracts only structure without probabilities}
\CommentTok{                        If False, extracts both structure and probability information}

\CommentTok{    Returns:}
\CommentTok{        pandas.DataFrame: Structured data with node information, relationships, and attributes}
\CommentTok{    """}
    \CommentTok{\# PHASE 1: Clean and prepare the text}
\NormalTok{    clean\_text }\OperatorTok{=}\NormalTok{ remove\_comments(markdown\_text)}

    \CommentTok{\# PHASE 2: Extract basic information about nodes}
\NormalTok{    titles\_info }\OperatorTok{=}\NormalTok{ extract\_titles\_info(clean\_text)}

    \CommentTok{\# PHASE 3: Determine the hierarchical relationships}
\NormalTok{    titles\_with\_relations }\OperatorTok{=}\NormalTok{ establish\_relationships\_fixed(titles\_info, clean\_text)}

    \CommentTok{\# PHASE 4: Convert to structured DataFrame format}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ convert\_to\_dataframe(titles\_with\_relations, ArgDown)}

    \CommentTok{\# PHASE 5: Add derived columns for analysis}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ add\_no\_parent\_no\_child\_columns\_to\_df(df)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ add\_parents\_instantiation\_columns\_to\_df(df)}

    \ControlFlowTok{return}\NormalTok{ df}

\KeywordTok{def}\NormalTok{ remove\_comments(markdown\_text):}
    \CommentTok{"""}
\CommentTok{    Remove comment blocks from markdown text using regex pattern matching.}

\CommentTok{    Args:}
\CommentTok{        markdown\_text (str): Text containing potential comment blocks}

\CommentTok{    Returns:}
\CommentTok{        str: Text with comment blocks removed}
\CommentTok{    """}
    \CommentTok{\# Remove anything between /* and */ using regex}
    \ControlFlowTok{return}\NormalTok{ re.sub(}\VerbatimStringTok{r\textquotesingle{}/}\CharTok{\textbackslash{}*}\DecValTok{.}\OperatorTok{*?}\CharTok{\textbackslash{}*}\VerbatimStringTok{/\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{, markdown\_text, flags}\OperatorTok{=}\NormalTok{re.DOTALL)}

\KeywordTok{def}\NormalTok{ extract\_titles\_info(text):}
    \CommentTok{"""}
\CommentTok{    Extract titles with their descriptions and indentation levels from markdown text.}

\CommentTok{    Args:}
\CommentTok{        text (str): Cleaned markdown text}

\CommentTok{    Returns:}
\CommentTok{        dict: Dictionary with titles as keys and dictionaries of attributes as values}
\CommentTok{    """}
\NormalTok{    lines }\OperatorTok{=}\NormalTok{ text.split(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    titles\_info }\OperatorTok{=}\NormalTok{ \{\}}

    \ControlFlowTok{for}\NormalTok{ line }\KeywordTok{in}\NormalTok{ lines:}
        \CommentTok{\# Skip empty lines}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ line.strip():}
            \ControlFlowTok{continue}

        \CommentTok{\# Extract title within square or angle brackets}
\NormalTok{        title\_match }\OperatorTok{=}\NormalTok{ re.search(}\VerbatimStringTok{r\textquotesingle{}}\PreprocessorTok{[\textless{}}\CharTok{\textbackslash{}[}\PreprocessorTok{]}\KeywordTok{(}\DecValTok{.}\OperatorTok{+?}\KeywordTok{)}\PreprocessorTok{[\textgreater{}}\CharTok{\textbackslash{}]}\PreprocessorTok{]}\VerbatimStringTok{\textquotesingle{}}\NormalTok{, line)}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ title\_match:}
            \ControlFlowTok{continue}

\NormalTok{        title }\OperatorTok{=}\NormalTok{ title\_match.group(}\DecValTok{1}\NormalTok{)}

        \CommentTok{\# Extract description and metadata}
\NormalTok{        title\_pattern\_in\_line }\OperatorTok{=} \VerbatimStringTok{r\textquotesingle{}}\PreprocessorTok{[\textless{}}\CharTok{\textbackslash{}[}\PreprocessorTok{]}\VerbatimStringTok{\textquotesingle{}} \OperatorTok{+}\NormalTok{ re.escape(title) }\OperatorTok{+} \VerbatimStringTok{r\textquotesingle{}}\PreprocessorTok{[\textgreater{}}\CharTok{\textbackslash{}]}\PreprocessorTok{]}\VerbatimStringTok{:\textquotesingle{}}
\NormalTok{        description\_match }\OperatorTok{=}\NormalTok{ re.search(title\_pattern\_in\_line }\OperatorTok{+} \VerbatimStringTok{r\textquotesingle{}}\DecValTok{\textbackslash{}s}\OperatorTok{*}\KeywordTok{(}\DecValTok{.}\OperatorTok{*}\KeywordTok{)}\VerbatimStringTok{\textquotesingle{}}\NormalTok{, line)}

        \ControlFlowTok{if}\NormalTok{ description\_match:}
\NormalTok{            full\_text }\OperatorTok{=}\NormalTok{ description\_match.group(}\DecValTok{1}\NormalTok{).strip()}

            \CommentTok{\# Split description and metadata at the first "\{"}
            \ControlFlowTok{if} \StringTok{"\{"} \KeywordTok{in}\NormalTok{ full\_text:}
\NormalTok{                split\_index }\OperatorTok{=}\NormalTok{ full\_text.find(}\StringTok{"\{"}\NormalTok{)}
\NormalTok{                description }\OperatorTok{=}\NormalTok{ full\_text[:split\_index].strip()}
\NormalTok{                metadata }\OperatorTok{=}\NormalTok{ full\_text[split\_index:].strip()}
            \ControlFlowTok{else}\NormalTok{:}
                \CommentTok{\# Keep the entire description and no metadata}
\NormalTok{                description }\OperatorTok{=}\NormalTok{ full\_text}
\NormalTok{                metadata }\OperatorTok{=} \StringTok{\textquotesingle{}\textquotesingle{}}  \CommentTok{\# Initialize as empty string}
        \ControlFlowTok{else}\NormalTok{:}
\NormalTok{            description }\OperatorTok{=} \StringTok{\textquotesingle{}\textquotesingle{}}
\NormalTok{            metadata }\OperatorTok{=} \StringTok{\textquotesingle{}\textquotesingle{}}  \CommentTok{\# Ensure metadata is initialized}

        \CommentTok{\# Calculate indentation level based on spaces before + or {-} symbol}
\NormalTok{        indentation }\OperatorTok{=} \DecValTok{0}
        \ControlFlowTok{if} \StringTok{\textquotesingle{}+\textquotesingle{}} \KeywordTok{in}\NormalTok{ line:}
\NormalTok{            symbol\_index }\OperatorTok{=}\NormalTok{ line.find(}\StringTok{\textquotesingle{}+\textquotesingle{}}\NormalTok{)}
            \CommentTok{\# Count spaces before the \textquotesingle{}+\textquotesingle{} symbol}
\NormalTok{            i }\OperatorTok{=}\NormalTok{ symbol\_index }\OperatorTok{{-}} \DecValTok{1}
            \ControlFlowTok{while}\NormalTok{ i }\OperatorTok{\textgreater{}=} \DecValTok{0} \KeywordTok{and}\NormalTok{ line[i] }\OperatorTok{==} \StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{:}
\NormalTok{                indentation }\OperatorTok{+=} \DecValTok{1}
\NormalTok{                i }\OperatorTok{{-}=} \DecValTok{1}
        \ControlFlowTok{elif} \StringTok{\textquotesingle{}{-}\textquotesingle{}} \KeywordTok{in}\NormalTok{ line:}
\NormalTok{            symbol\_index }\OperatorTok{=}\NormalTok{ line.find(}\StringTok{\textquotesingle{}{-}\textquotesingle{}}\NormalTok{)}
            \CommentTok{\# Count spaces before the \textquotesingle{}{-}\textquotesingle{} symbol}
\NormalTok{            i }\OperatorTok{=}\NormalTok{ symbol\_index }\OperatorTok{{-}} \DecValTok{1}
            \ControlFlowTok{while}\NormalTok{ i }\OperatorTok{\textgreater{}=} \DecValTok{0} \KeywordTok{and}\NormalTok{ line[i] }\OperatorTok{==} \StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{:}
\NormalTok{                indentation }\OperatorTok{+=} \DecValTok{1}
\NormalTok{                i }\OperatorTok{{-}=} \DecValTok{1}

        \CommentTok{\# If neither symbol exists, indentation remains 0}

        \ControlFlowTok{if}\NormalTok{ title }\KeywordTok{in}\NormalTok{ titles\_info:}
            \CommentTok{\# Only update description if it\textquotesingle{}s currently empty and we found a new one}
            \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ titles\_info[title][}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{] }\KeywordTok{and}\NormalTok{ description:}
\NormalTok{                titles\_info[title][}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ description}

            \CommentTok{\# Store all indentation levels for this title}
\NormalTok{            titles\_info[title][}\StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{].append(indentation)}

            \CommentTok{\# Keep max indentation for backward compatibility}
            \ControlFlowTok{if}\NormalTok{ indentation }\OperatorTok{\textgreater{}}\NormalTok{ titles\_info[title][}\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{]:}
\NormalTok{                titles\_info[title][}\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ indentation}

            \CommentTok{\# Do NOT update metadata here {-} keep the original metadata}
        \ControlFlowTok{else}\NormalTok{:}
            \CommentTok{\# First time seeing this title, create a new entry}
\NormalTok{            titles\_info[title] }\OperatorTok{=}\NormalTok{ \{}
                \StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{: description,}
                \StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{: indentation,}
                \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{: [indentation],  }\CommentTok{\# Initialize with first indentation level}
                \StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{: [],}
                \StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{: [],}
                \StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{: }\VariableTok{None}\NormalTok{,}
                \StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{: [],  }\CommentTok{\# Initialize an empty list for all occurrences}
                \StringTok{\textquotesingle{}metadata\textquotesingle{}}\NormalTok{: metadata  }\CommentTok{\# Set metadata explicitly from what we found}
\NormalTok{            \}}

    \ControlFlowTok{return}\NormalTok{ titles\_info}

\KeywordTok{def}\NormalTok{ establish\_relationships\_fixed(titles\_info, text):}
    \CommentTok{"""}
\CommentTok{    Establish parent{-}child relationships between titles using BayesDown}
\CommentTok{    indentation rules.}

\CommentTok{    In BayesDown syntax:}
\CommentTok{    {-} More indented nodes (with + symbol) are PARENTS of less indented nodes}
\CommentTok{    {-} The relationship reads as "Effect is caused by Cause" (Effect + Cause)}
\CommentTok{    {-} This aligns with how Bayesian networks represent causality}

\CommentTok{    Args:}
\CommentTok{        titles\_info (dict): Dictionary with information about titles}
\CommentTok{        text (str): Original markdown text (for identifying line numbers)}

\CommentTok{    Returns:}
\CommentTok{        dict: Updated dictionary with parent{-}child relationships}
\CommentTok{    """}
\NormalTok{    lines }\OperatorTok{=}\NormalTok{ text.split(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}

    \CommentTok{\# Dictionary to store line numbers for each title occurrence}
\NormalTok{    title\_occurrences }\OperatorTok{=}\NormalTok{ \{\}}

    \CommentTok{\# Record line number for each title (including multiple occurrences)}
\NormalTok{    line\_number }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ line }\KeywordTok{in}\NormalTok{ lines:}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ line.strip():}
\NormalTok{            line\_number }\OperatorTok{+=} \DecValTok{1}
            \ControlFlowTok{continue}

\NormalTok{        title\_match }\OperatorTok{=}\NormalTok{ re.search(}\VerbatimStringTok{r\textquotesingle{}}\PreprocessorTok{[\textless{}}\CharTok{\textbackslash{}[}\PreprocessorTok{]}\KeywordTok{(}\DecValTok{.}\OperatorTok{+?}\KeywordTok{)}\PreprocessorTok{[\textgreater{}}\CharTok{\textbackslash{}]}\PreprocessorTok{]}\VerbatimStringTok{\textquotesingle{}}\NormalTok{, line)}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ title\_match:}
\NormalTok{            line\_number }\OperatorTok{+=} \DecValTok{1}
            \ControlFlowTok{continue}

\NormalTok{        title }\OperatorTok{=}\NormalTok{ title\_match.group(}\DecValTok{1}\NormalTok{)}

        \CommentTok{\# Store all occurrences of each title with their line numbers}
        \ControlFlowTok{if}\NormalTok{ title }\KeywordTok{not} \KeywordTok{in}\NormalTok{ title\_occurrences:}
\NormalTok{            title\_occurrences[title] }\OperatorTok{=}\NormalTok{ []}
\NormalTok{        title\_occurrences[title].append(line\_number)}

        \CommentTok{\# Store all line numbers where this title appears}
        \ControlFlowTok{if} \StringTok{\textquotesingle{}line\_numbers\textquotesingle{}} \KeywordTok{not} \KeywordTok{in}\NormalTok{ titles\_info[title]:}
\NormalTok{            titles\_info[title][}\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ []}
\NormalTok{        titles\_info[title][}\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{].append(line\_number)}

        \CommentTok{\# For backward compatibility, keep the first occurrence in \textquotesingle{}line\textquotesingle{}}
        \ControlFlowTok{if}\NormalTok{ titles\_info[title][}\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{] }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
\NormalTok{            titles\_info[title][}\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ line\_number}

\NormalTok{        line\_number }\OperatorTok{+=} \DecValTok{1}

    \CommentTok{\# Create an ordered list of all title occurrences with their line numbers}
\NormalTok{    all\_occurrences }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{for}\NormalTok{ title, occurrences }\KeywordTok{in}\NormalTok{ title\_occurrences.items():}
        \ControlFlowTok{for}\NormalTok{ line\_num }\KeywordTok{in}\NormalTok{ occurrences:}
\NormalTok{            all\_occurrences.append((title, line\_num))}

    \CommentTok{\# Sort occurrences by line number}
\NormalTok{    all\_occurrences.sort(key}\OperatorTok{=}\KeywordTok{lambda}\NormalTok{ x: x[}\DecValTok{1}\NormalTok{])}

    \CommentTok{\# Get indentation for each occurrence}
\NormalTok{    occurrence\_indents }\OperatorTok{=}\NormalTok{ \{\}}
    \ControlFlowTok{for}\NormalTok{ title, line\_num }\KeywordTok{in}\NormalTok{ all\_occurrences:}
        \ControlFlowTok{for}\NormalTok{ line }\KeywordTok{in}\NormalTok{ lines[line\_num:line\_num}\OperatorTok{+}\DecValTok{1}\NormalTok{]:  }\CommentTok{\# Only check the current line}
\NormalTok{            indent }\OperatorTok{=} \DecValTok{0}
            \ControlFlowTok{if} \StringTok{\textquotesingle{}+\textquotesingle{}} \KeywordTok{in}\NormalTok{ line:}
\NormalTok{                symbol\_index }\OperatorTok{=}\NormalTok{ line.find(}\StringTok{\textquotesingle{}+\textquotesingle{}}\NormalTok{)}
                \CommentTok{\# Count spaces before the \textquotesingle{}+\textquotesingle{} symbol}
\NormalTok{                j }\OperatorTok{=}\NormalTok{ symbol\_index }\OperatorTok{{-}} \DecValTok{1}
                \ControlFlowTok{while}\NormalTok{ j }\OperatorTok{\textgreater{}=} \DecValTok{0} \KeywordTok{and}\NormalTok{ line[j] }\OperatorTok{==} \StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{:}
\NormalTok{                    indent }\OperatorTok{+=} \DecValTok{1}
\NormalTok{                    j }\OperatorTok{{-}=} \DecValTok{1}
            \ControlFlowTok{elif} \StringTok{\textquotesingle{}{-}\textquotesingle{}} \KeywordTok{in}\NormalTok{ line:}
\NormalTok{                symbol\_index }\OperatorTok{=}\NormalTok{ line.find(}\StringTok{\textquotesingle{}{-}\textquotesingle{}}\NormalTok{)}
                \CommentTok{\# Count spaces before the \textquotesingle{}{-}\textquotesingle{} symbol}
\NormalTok{                j }\OperatorTok{=}\NormalTok{ symbol\_index }\OperatorTok{{-}} \DecValTok{1}
                \ControlFlowTok{while}\NormalTok{ j }\OperatorTok{\textgreater{}=} \DecValTok{0} \KeywordTok{and}\NormalTok{ line[j] }\OperatorTok{==} \StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{:}
\NormalTok{                    indent }\OperatorTok{+=} \DecValTok{1}
\NormalTok{                    j }\OperatorTok{{-}=} \DecValTok{1}
\NormalTok{            occurrence\_indents[(title, line\_num)] }\OperatorTok{=}\NormalTok{ indent}

    \CommentTok{\# Enhanced backward pass for correct parent{-}child relationships}
    \ControlFlowTok{for}\NormalTok{ i, (title, line\_num) }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(all\_occurrences):}
\NormalTok{        current\_indent }\OperatorTok{=}\NormalTok{ occurrence\_indents[(title, line\_num)]}

        \CommentTok{\# Skip root nodes (indentation 0) for processing}
        \ControlFlowTok{if}\NormalTok{ current\_indent }\OperatorTok{==} \DecValTok{0}\NormalTok{:}
            \ControlFlowTok{continue}

        \CommentTok{\# Look for the immediately preceding node with lower indentation}
\NormalTok{        j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}
        \ControlFlowTok{while}\NormalTok{ j }\OperatorTok{\textgreater{}=} \DecValTok{0}\NormalTok{:}
\NormalTok{            prev\_title, prev\_line }\OperatorTok{=}\NormalTok{ all\_occurrences[j]}
\NormalTok{            prev\_indent }\OperatorTok{=}\NormalTok{ occurrence\_indents[(prev\_title, prev\_line)]}

            \CommentTok{\# If we find a node with less indentation, it\textquotesingle{}s a child of current node}
            \ControlFlowTok{if}\NormalTok{ prev\_indent }\OperatorTok{\textless{}}\NormalTok{ current\_indent:}
                \CommentTok{\# In BayesDown:}
                \CommentTok{\# More indented node is a parent (cause) of less indented node (effect)}
                \ControlFlowTok{if}\NormalTok{ title }\KeywordTok{not} \KeywordTok{in}\NormalTok{ titles\_info[prev\_title][}\StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{]:}
\NormalTok{                    titles\_info[prev\_title][}\StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{].append(title)}
                \ControlFlowTok{if}\NormalTok{ prev\_title }\KeywordTok{not} \KeywordTok{in}\NormalTok{ titles\_info[title][}\StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{]:}
\NormalTok{                    titles\_info[title][}\StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{].append(prev\_title)}

                \CommentTok{\# Only need to find the immediate child}
                \CommentTok{\# (closest preceding node with lower indentation)}
                \ControlFlowTok{break}

\NormalTok{            j }\OperatorTok{{-}=} \DecValTok{1}

    \ControlFlowTok{return}\NormalTok{ titles\_info}

\KeywordTok{def}\NormalTok{ convert\_to\_dataframe(titles\_info, ArgDown):}
    \CommentTok{"""}
\CommentTok{    Convert the titles information dictionary to a pandas DataFrame.}

\CommentTok{    Args:}
\CommentTok{        titles\_info (dict): Dictionary with information about titles}
\CommentTok{        ArgDown (bool): If True, extract only structural information without probabilities}

\CommentTok{    Returns:}
\CommentTok{        pandas.DataFrame: Structured data with node information and relationships}
\CommentTok{    """}
    \ControlFlowTok{if}\NormalTok{ ArgDown }\OperatorTok{==} \VariableTok{True}\NormalTok{:}
        \CommentTok{\# For ArgDown, exclude probability columns}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.DataFrame(columns}\OperatorTok{=}\NormalTok{[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{,}
                               \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{])}
    \ControlFlowTok{else}\NormalTok{:}
        \CommentTok{\# For BayesDown, include probability columns}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.DataFrame(columns}\OperatorTok{=}\NormalTok{[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{,}
                               \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{,}
                               \StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{])}

    \ControlFlowTok{for}\NormalTok{ title, info }\KeywordTok{in}\NormalTok{ titles\_info.items():}
        \CommentTok{\# Parse the metadata JSON string into a Python dictionary}
        \ControlFlowTok{if} \StringTok{\textquotesingle{}metadata\textquotesingle{}} \KeywordTok{in}\NormalTok{ info }\KeywordTok{and}\NormalTok{ info[}\StringTok{\textquotesingle{}metadata\textquotesingle{}}\NormalTok{]:}
            \ControlFlowTok{try}\NormalTok{:}
                \CommentTok{\# Only try to parse if metadata is not empty}
                \ControlFlowTok{if}\NormalTok{ info[}\StringTok{\textquotesingle{}metadata\textquotesingle{}}\NormalTok{].strip():}
\NormalTok{                    jsonMetadata }\OperatorTok{=}\NormalTok{ json.loads(info[}\StringTok{\textquotesingle{}metadata\textquotesingle{}}\NormalTok{])}
                    \ControlFlowTok{if}\NormalTok{ ArgDown }\OperatorTok{==} \VariableTok{True}\NormalTok{:}
                        \CommentTok{\# Create the row dictionary with instantiations as}
                        \CommentTok{\# metadata only, no probabilities yet}
\NormalTok{                        row }\OperatorTok{=}\NormalTok{ \{}
                            \StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{: title,}
                            \StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                            \StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                            \StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{, []),}
                            \StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                            \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{, []),}
                            \StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{, []),}
                            \StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{, []),}
                            \CommentTok{\# Extract specific metadata fields,}
                            \CommentTok{\# defaulting to empty if not present}
                            \StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{: jsonMetadata.get(}\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{, []),}
\NormalTok{                        \}}
                    \ControlFlowTok{else}\NormalTok{:}
                        \CommentTok{\# Create dict with probabilities for BayesDown}
\NormalTok{                        row }\OperatorTok{=}\NormalTok{ \{}
                            \StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{: title,}
                            \StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                            \StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                            \StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{, []),}
                            \StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                            \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{, []),}
                            \StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{, []),}
                            \StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{, []),}
                            \CommentTok{\# Extract specific metadata fields, defaulting to empty if not present}
                            \StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{: jsonMetadata.get(}\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{, []),}
                            \StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{: jsonMetadata.get(}\StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{, \{\}),}
                            \StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{: jsonMetadata.get(}\StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{, \{\})}
\NormalTok{                        \}}
                \ControlFlowTok{else}\NormalTok{:}
                    \CommentTok{\# Empty metadata case}
\NormalTok{                    row }\OperatorTok{=}\NormalTok{ \{}
                        \StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{: title,}
                        \StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                        \StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                        \StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{, []),}
                        \StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                        \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{, []),}
                        \StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{, []),}
                        \StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{, []),}
                        \StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{: [],}
                        \StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{: \{\},}
                        \StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{: \{\}}
\NormalTok{                    \}}
            \ControlFlowTok{except}\NormalTok{ json.JSONDecodeError:}
                \CommentTok{\# Handle case where metadata isn\textquotesingle{}t valid JSON}
\NormalTok{                row }\OperatorTok{=}\NormalTok{ \{}
                    \StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{: title,}
                    \StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                    \StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                    \StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{, []),}
                    \StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                    \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{, []),}
                    \StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{, []),}
                    \StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{, []),}
                    \StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{: [],}
                    \StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{: \{\},}
                    \StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{: \{\}}
\NormalTok{                \}}
        \ControlFlowTok{else}\NormalTok{:}
            \CommentTok{\# Handle case where metadata field doesn\textquotesingle{}t exist or is empty}
\NormalTok{            row }\OperatorTok{=}\NormalTok{ \{}
                \StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{: title,}
                \StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                \StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                \StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{, []),}
                \StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{, []),}
                \StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{, []),}
                \StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{, []),}
                \StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{: [],}
                \StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{: \{\},}
                \StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{: \{\}}
\NormalTok{            \}}

        \CommentTok{\# Add the row to the DataFrame}
\NormalTok{        df.loc[}\BuiltInTok{len}\NormalTok{(df)] }\OperatorTok{=}\NormalTok{ row}

    \ControlFlowTok{return}\NormalTok{ df}

\KeywordTok{def}\NormalTok{ add\_no\_parent\_no\_child\_columns\_to\_df(dataframe):}
    \CommentTok{"""}
\CommentTok{    Add No\_Parent and No\_Children boolean columns to the DataFrame to}
\CommentTok{    identify root and leaf nodes.}

\CommentTok{    Args:}
\CommentTok{        dataframe (pandas.DataFrame): The DataFrame to enhance}

\CommentTok{    Returns:}
\CommentTok{        pandas.DataFrame: Enhanced DataFrame with additional boolean columns}
\CommentTok{    """}
\NormalTok{    no\_parent }\OperatorTok{=}\NormalTok{ []}
\NormalTok{    no\_children }\OperatorTok{=}\NormalTok{ []}

    \ControlFlowTok{for}\NormalTok{ \_, row }\KeywordTok{in}\NormalTok{ dataframe.iterrows():}
\NormalTok{        no\_parent.append(}\KeywordTok{not}\NormalTok{ row[}\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{])  }\CommentTok{\# True if Parents list is empty}
\NormalTok{        no\_children.append(}\KeywordTok{not}\NormalTok{ row[}\StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{])  }\CommentTok{\# True if Children list is empty}

\NormalTok{    dataframe[}\StringTok{\textquotesingle{}No\_Parent\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ no\_parent}
\NormalTok{    dataframe[}\StringTok{\textquotesingle{}No\_Children\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ no\_children}

    \ControlFlowTok{return}\NormalTok{ dataframe}

\KeywordTok{def}\NormalTok{ add\_parents\_instantiation\_columns\_to\_df(dataframe):}
    \CommentTok{"""}
\CommentTok{    Add all possible instantiations of parents as a list of lists column}
\CommentTok{    to the DataFrame.}
\CommentTok{    This is crucial for generating conditional probability tables.}

\CommentTok{    Args:}
\CommentTok{        dataframe (pandas.DataFrame): The DataFrame to enhance}

\CommentTok{    Returns:}
\CommentTok{        pandas.DataFrame: Enhanced DataFrame with parent\_instantiations column}
\CommentTok{    """}
    \CommentTok{\# Create a new column to store parent instantiations}
\NormalTok{    parent\_instantiations }\OperatorTok{=}\NormalTok{ []}

    \CommentTok{\# Iterate through each row in the dataframe}
    \ControlFlowTok{for}\NormalTok{ \_, row }\KeywordTok{in}\NormalTok{ dataframe.iterrows():}
\NormalTok{        parents }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{]}
\NormalTok{        parent\_insts }\OperatorTok{=}\NormalTok{ []}

        \CommentTok{\# For each parent, find its instantiations and add to the list}
        \ControlFlowTok{for}\NormalTok{ parent }\KeywordTok{in}\NormalTok{ parents:}
            \CommentTok{\# Find the row where Title matches the parent}
\NormalTok{            parent\_row }\OperatorTok{=}\NormalTok{ dataframe[dataframe[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{] }\OperatorTok{==}\NormalTok{ parent]}

            \CommentTok{\# If parent found in the dataframe}
            \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ parent\_row.empty:}
                \CommentTok{\# Get the instantiations of this parent}
\NormalTok{                parent\_instantiation }\OperatorTok{=}\NormalTok{ parent\_row[}\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{].iloc[}\DecValTok{0}\NormalTok{]}
\NormalTok{                parent\_insts.append(parent\_instantiation)}

        \CommentTok{\# Add the list of parent instantiations to our new column}
\NormalTok{        parent\_instantiations.append(parent\_insts)}

    \CommentTok{\# Add the new column to the dataframe}
\NormalTok{    dataframe[}\StringTok{\textquotesingle{}parent\_instantiations\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ parent\_instantiations}

    \ControlFlowTok{return}\NormalTok{ dataframe}
\end{Highlighting}
\end{Shaded}

This key function transforms the ArgDown text into a structured
DataFrame, capturing the hierarchical relationships between variables
and preparing them for further processing. The function works by
identifying node titles, descriptions, and indentation levels, then
establishing parent-child relationships based on the hierarchy indicated
by indentation.

\textbf{Stage 2: Probability Integration} enhances the structural
representation with probability information, creating a complete
BayesDown specification. This stage involves:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Question generation:} Automatically creating appropriate
  probability questions based on the network structure
\item
  \textbf{Probability extraction:} Obtaining probability estimates for
  each question, either from the text or through LLM inference
\item
  \textbf{Consistency checking:} Ensuring probability distributions sum
  to 1 and match structural constraints
\item
  \textbf{BayesDown integration:} Incorporating probability information
  into the ArgDown structure
\end{enumerate}

The key innovation in this stage is the automated generation of
appropriate probability questions based on network structure. For each
node, the system generates questions about prior probabilities (how
likely is this variable in isolation?) and conditional probabilities
(how likely is this variable given different states of its parents?).

Figure 5 illustrates how probability questions are derived for a simple
node with one parent:

{[}FIGURE 5: Diagram showing how probability questions are generated
based on network structure{]}

For the ``Sprinkler'' node with parent ``Rain,'' the system
automatically generates questions like:

\begin{itemize}
\tightlist
\item
  What is the probability for Sprinkler=sprinkler\_TRUE?
\item
  What is the probability for Sprinkler=sprinkler\_TRUE if
  Rain=rain\_TRUE?
\item
  What is the probability for Sprinkler=sprinkler\_TRUE if
  Rain=rain\_FALSE?
\end{itemize}

These questions are then answered either by extracting explicit
probabilities from the text or by having the LLM infer reasonable values
based on the author's arguments. The answers are structured into a
complete BayesDown representation that includes both the causal
structure and all necessary probability information.

The visualization below demonstrates the completed extraction for a
portion of Carlsmith's model, showing how variables like ``Misaligned
Power Seeking'' are influenced by multiple factors, each with associated
probabilities:

{[}VISUALIZATION: Extracted causal structure from Carlsmith's model with
probability information{]}

This two-stage approach offers several important advantages:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Improved extraction quality:} By focusing on one cognitive
  task at a time, the LLM performs better at each stage than it would
  attempting to extract everything simultaneously.
\item
  \textbf{Intermediate verification:} Having ArgDown as an intermediate
  representation allows human verification before probability
  extraction, catching structural errors early.
\item
  \textbf{Separation of concerns:} Structure and probability can be
  updated independently, enabling more flexible maintenance as new
  information emerges.
\item
  \textbf{Alignment with human cognition:} The process mirrors how
  experts approach complex arguments, making the system's operation more
  intuitive and interpretable.
\end{enumerate}

Perhaps most importantly, the intermediate ArgDown representation
creates a bridge between qualitative and quantitative aspects of
arguments. It preserves the narrative structure and conceptual
relationships from the original text while preparing for mathematical
precision through probability integration. This hybrid approach
maintains the strengths of both worlds: the richness of natural language
and the rigor of formal models.

\subsection*{2.7.4 Directed Acyclic Graphs: Structure and
Semantics}\label{sec-dag-structure}
\addcontentsline{toc}{subsection}{2.7.4 Directed Acyclic Graphs:
Structure and Semantics}

Directed Acyclic Graphs (DAGs) form the mathematical foundation of
Bayesian networks, encoding both the qualitative structure of causal
relationships and the quantitative parameters that define conditional
dependencies. In AI risk modeling, these structures represent causal
pathways to potential outcomes of interest.

Key mathematical properties essential for AI risk modeling:

\begin{itemize}
\tightlist
\item
  \textbf{Acyclicity}: Ensures coherent probabilistic interpretation
\item
  \textbf{D-separation}: Defines conditional independence relationships
\item
  \textbf{Markov Condition}: Each variable conditionally independent of
  non-descendants given parents
\item
  \textbf{Path Analysis}: Reveals causal pathways and information flow
\end{itemize}

The causal interpretation follows Pearl's framework:\footnote{Pearl's
  causal framework revolutionized how we think about causation in
  complex systems}

\begin{itemize}
\tightlist
\item
  Edges represent direct causal influence
\item
  Intervention analysis through do-calculus
\item
  Counterfactual reasoning for ``what if'' scenarios
\item
  Evidence integration through Bayesian updating
\end{itemize}

\subsection*{2.7.5 Quantification of Probabilistic
Judgments}\label{sec-quantification}
\addcontentsline{toc}{subsection}{2.7.5 Quantification of Probabilistic
Judgments}

Transforming qualitative uncertainty expressions into quantitative
probabilities requires systematic interpretation frameworks that account
for individual and cultural variation.

Standard linguistic mappings (with significant individual variation)
include:

\begin{itemize}
\tightlist
\item
  ``Very likely'' → 0.8-0.9
\item
  ``Probable'' → 0.6-0.8
\item
  ``Uncertain'' → 0.4-0.6
\item
  ``Unlikely'' → 0.2-0.4
\item
  ``Highly improbable'' → 0.05-0.15
\end{itemize}

Expert elicitation methodologies:

\begin{itemize}
\tightlist
\item
  \textbf{Direct Assessment}: ``What is P(outcome)?'' with calibration
  training
\item
  \textbf{Comparative Assessment}: ``Is A more likely than B?'' for
  validation
\item
  \textbf{Frequency Format}: ``In 100 similar cases, how many\ldots{}''
  for clarity
\item
  \textbf{Betting Odds}: ``What odds would you accept?'' for revealed
  preferences
\end{itemize}

Calibration challenges:

\begin{itemize}
\tightlist
\item
  Individual variation in linguistic interpretation
\item
  Domain-specific anchoring effects
\item
  Cultural influences on uncertainty expression
\item
  Limited empirical basis for unprecedented scenarios
\end{itemize}

\subsection*{2.7.6 Inference Techniques for Complex
Networks}\label{sec-inference-techniques}
\addcontentsline{toc}{subsection}{2.7.6 Inference Techniques for Complex
Networks}

Once Bayesian networks are constructed, probabilistic inference enables
reasoning about uncertainties, counterfactuals, and policy
interventions. For the complex networks representing AI risks,
computational approaches must balance accuracy with tractability.

Inference methods implemented include exact methods for smaller networks
(variable elimination, junction trees), approximate methods for larger
networks (Monte Carlo sampling, variational inference), specialized
approaches for rare event analysis, and intervention modeling for policy
evaluation using do-calculus.

Implementation considerations:

\begin{itemize}
\tightlist
\item
  \textbf{Computational Complexity}: Managing exponential growth through
  decomposition
\item
  \textbf{Sampling Efficiency}: Importance sampling for rare events
\item
  \textbf{Approximation Quality}: Convergence diagnostics and error
  bounds
\item
  \textbf{Uncertainty Propagation}: Representing confidence in outputs
\end{itemize}

\subsection*{2.7.7 Integration with Prediction Markets and Forecasting
Platforms}\label{sec-prediction-markets}
\addcontentsline{toc}{subsection}{2.7.7 Integration with Prediction
Markets and Forecasting Platforms}

To maintain relevance in a rapidly evolving field, formal models must
integrate with live data sources such as prediction markets and
forecasting platforms.

Live data sources for dynamic model updating include:

\begin{itemize}
\tightlist
\item
  \textbf{Metaculus}: Long-term AI predictions and technological
  forecasting
\item
  \textbf{Good Judgment Open}: Geopolitical events and policy outcomes
\item
  \textbf{Manifold Markets}: Diverse question types with rapid market
  response
\item
  \textbf{Internal Expert Forecasting}: Organization-specific
  predictions and assessments
\end{itemize}

Technical challenges:

\begin{itemize}
\tightlist
\item
  \textbf{Question Mapping}: Semantic matching between model variables
  and market questions
\item
  \textbf{Temporal Alignment}: Different forecast horizons and update
  frequencies
\item
  \textbf{Conflict Resolution}: Principled aggregation of contradictory
  sources
\item
  \textbf{Track Record Weighting}: Incorporating forecaster calibration
\end{itemize}

With these theoretical foundations and methodological approaches
established, we can now present the AMTAIR system implementation. The
next chapter demonstrates how these concepts translate into a working
prototype that automates the extraction and formalization of world
models from AI safety literature.

\bookmarksetup{startatroot}

\chapter*{3. AMTAIR: Design and Implementation}\label{sec-amtair}
\addcontentsline{toc}{chapter}{3. AMTAIR: Design and Implementation}

\markboth{3. AMTAIR: Design and Implementation}{3. AMTAIR: Design and
Implementation}

\begin{tcolorbox}[enhanced jigsaw, arc=.35mm, titlerule=0mm, breakable, toprule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, coltitle=black, bottomrule=.15mm, bottomtitle=1mm, opacityback=0, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Chapter Overview}, rightrule=.15mm, leftrule=.75mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, left=2mm]

\textbf{Grade Weight}: 20\% \textbar{} \textbf{Target Length}:
\textasciitilde29\% of text (\textasciitilde8,700 words)\\
\textbf{Requirements}: Critical evaluation, strong argument for
position, original contribution

\end{tcolorbox}

\section*{3.1 System Architecture
Overview}\label{sec-system-architecture}
\addcontentsline{toc}{section}{3.1 System Architecture Overview}

\markright{3.1 System Architecture Overview}

The AMTAIR system implements an end-to-end pipeline transforming
unstructured text into interactive Bayesian network visualizations. Its
modular architecture comprises five main components that progressively
transform information from natural language into formal models suitable
for policy analysis.

The AMTAIR system implements an end-to-end pipeline from unstructured
text to interactive Bayesian network visualization. Its modular
architecture comprises five main components that progressively transform
information from natural language into formal models suitable for policy
analysis.

\subsection*{3.1.1 Five-Stage Pipeline
Architecture}\label{sec-five-stage-pipeline}
\addcontentsline{toc}{subsection}{3.1.1 Five-Stage Pipeline
Architecture}

The five-stage pipeline architecture demonstrates how each component
builds on the previous, with validation checkpoints preventing error
propagation: 1. \textbf{Text Ingestion and Preprocessing} - Format
normalization (PDF, HTML, Markdown) - Metadata extraction and citation
tracking - Relevance filtering and section identification - Character
encoding standardization 2. \textbf{BayesDown Extraction} - Two-stage
argument structure identification - Probabilistic information
integration - Quality validation and confidence scoring -
Human-in-the-loop verification points 3. \textbf{Structured Data
Transformation} - Parsing into standardized relational formats - Network
topology validation - Consistency checking across relationships -
Missing data imputation strategies 4. \textbf{Bayesian Network
Construction} - Mathematical model instantiation - Conditional
probability table generation - Inference engine initialization - Model
validation and testing 5. \textbf{Interactive Visualization} - Dynamic
rendering with PyVis - Probability-based visual encoding - Interactive
exploration features - Export capabilities for reports

\subsection*{3.1.2 Design Principles}\label{sec-design-principles}
\addcontentsline{toc}{subsection}{3.1.2 Design Principles}

\begin{tcolorbox}[enhanced jigsaw, arc=.35mm, titlerule=0mm, breakable, toprule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, coltitle=black, bottomrule=.15mm, bottomtitle=1mm, opacityback=0, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Core Design Philosophy}, rightrule=.15mm, leftrule=.75mm, colback=white, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, left=2mm]

The system emphasizes scalability through modular architecture, standard
interfaces for interoperability, validation checkpoints for quality
assurance, and an extensible framework for future capabilities.

\end{tcolorbox}

\section*{3.2 The Two-Stage Extraction
Process}\label{sec-two-stage-extraction}
\addcontentsline{toc}{section}{3.2 The Two-Stage Extraction Process}

\markright{3.2 The Two-Stage Extraction Process}

The core innovation of AMTAIR lies in separating structural extraction
from probability quantification. This two-stage approach addresses key
challenges in automated formalization.

\subsection*{3.2.1 Stage 1: Structural Extraction
(ArgDown)}\label{sec-stage1-argdown}
\addcontentsline{toc}{subsection}{3.2.1 Stage 1: Structural Extraction
(ArgDown)}

The first stage identifies argument structure without concerning itself
with quantification:

\textbf{Variable Identification}: Extract key propositions and entities
from text using patterns like ``X causes Y,'' ``If A then B,'' and
domain-specific indicators.

\textbf{Relationship Mapping}: Identify support, attack, and conditional
relationships between variables through linguistic analysis.

\textbf{Hierarchy Construction}: Build nested ArgDown representation
preserving logical flow.

\textbf{Validation}: Ensure extracted structure forms valid directed
acyclic graph and preserves key argumentative relationships from source.

Example ArgDown extraction:

\begin{verbatim}
[Existential_Catastrophe]: Destruction of humanity's potential.
 + [Human_Disempowerment]: Loss of control to AI systems.
   + [Misaligned_Power_Seeking]: AI pursuing problematic objectives.
     + [APS_Systems]: Advanced, agentic, strategic AI.
     + [Deployment_Decisions]: Choice to deploy despite risks.
\end{verbatim}

\subsection*{3.2.2 Stage 2: Probability Integration
(BayesDown)}\label{sec-stage2-bayesdown}
\addcontentsline{toc}{subsection}{3.2.2 Stage 2: Probability Integration
(BayesDown)}

The second stage adds quantitative information to the structural
skeleton:

\textbf{Question Generation}: For each node, generate probability
elicitation questions tailored to the specific context and
relationships.

\begin{verbatim}
Examples needed:
- "What is the probability of existential catastrophe?"
- "What is P(catastrophe|human_disempowerment)?"
- Show how questions map to BayesDown structure
\end{verbatim}

\textbf{Probability Extraction}:

\begin{itemize}
\tightlist
\item
  Identify explicit numerical statements
\item
  Map qualitative expressions using calibrated scales
\item
  Apply domain-specific heuristics for common phrasings
\end{itemize}

\textbf{Coherence Enforcement}:

\begin{itemize}
\tightlist
\item
  Ensure probabilities sum to 1.0
\item
  Complete conditional probability tables
\item
  Check for logical contradictions
\item
  Flag low-confidence extractions
\end{itemize}

\subsection*{3.2.3 Why Two Stages?}\label{sec-why-two-stages}
\addcontentsline{toc}{subsection}{3.2.3 Why Two Stages?}

This separation provides several benefits:

\textbf{Transparency}: Being able to scrutinize each step of the
automated workflow provides reliable insight into the work being done

\textbf{Accountability}: False information (think of hallucinations) can
be traced back to its origins

\textbf{Visibility}:

\textbf{Modular Validation}: Structure can be verified independently
from probability estimates, simplifying quality assurance.

\textbf{Human Oversight}: Experts can review and correct structural
extraction before probability quantification.

\textbf{Flexible Quantification}: Different methods (LLM extraction,
expert elicitation, market data) can provide probabilities for the same
structure.

\textbf{Error Isolation}: Structural errors don't contaminate
probability extraction and vice versa.

\section*{3.3 Implementation
Technologies}\label{sec-implementation-tech}
\addcontentsline{toc}{section}{3.3 Implementation Technologies}

\markright{3.3 Implementation Technologies}

\subsection*{3.3.1 Technology Stack}\label{sec-tech-stack}
\addcontentsline{toc}{subsection}{3.3.1 Technology Stack}

The system leverages established libraries while adding novel extraction
capabilities:

\begin{longtable}[]{@{}lll@{}}
\caption{Technology stack
components}\label{tbl-tech-stack}\tabularnewline
\toprule\noalign{}
Component & Technology & Purpose \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Component & Technology & Purpose \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Language Models & GPT-4, Claude & Argument extraction \\
Network Analysis & NetworkX & Graph algorithms \\
Probabilistic Modeling & pgmpy & Bayesian operations \\
Visualization & PyVis & Interactive rendering \\
Data Processing & Pandas & Structured manipulation \\
\end{longtable}

\subsection*{3.3.2 Key Algorithms}\label{sec-key-algorithms}
\addcontentsline{toc}{subsection}{3.3.2 Key Algorithms}

\textbf{Hierarchical Parsing}: The system parses ArgDown/BayesDown
syntax recognizing indentation-based hierarchy, a critical innovation
for preserving argument structure.

\textbf{Probability Completion}: When sources don't specify all required
probabilities, the system uses:

\begin{itemize}
\tightlist
\item
  Maximum entropy principles for missing values
\item
  Coherence constraint propagation
\item
  Expert-specified defaults with confidence scoring
\end{itemize}

\textbf{Visual Encoding Strategy}:

\begin{itemize}
\tightlist
\item
  Green-to-red gradient for probability magnitude
\item
  Border colors indicating node types
\item
  Interactive elements for exploration
\end{itemize}

\subsection*{3.3.3 (Expected) Performance
Characteristics}\label{sec-performance}
\addcontentsline{toc}{subsection}{3.3.3 (Expected) Performance
Characteristics}

--\textgreater{}

\subsection*{3.3.4 Deterministic vs.~Probabilistic Components of the
Workflow}\label{deterministic-vs.-probabilistic-components-of-the-workflow}
\addcontentsline{toc}{subsection}{3.3.4 Deterministic vs.~Probabilistic
Components of the Workflow}

\begin{landscape}

\section*{3.4 Case Study:
Rain-Sprinkler-Grass}\label{sec-case-rain-sprinkler}
\addcontentsline{toc}{section}{3.4 Case Study: Rain-Sprinkler-Grass}

\markright{3.4 Case Study: Rain-Sprinkler-Grass}

I begin with the canonical example to demonstrate the complete pipeline
on a simple, well-understood case.

\subsection*{3.4.1 Processing Steps}\label{sec-rsg-processing}
\addcontentsline{toc}{subsection}{3.4.1 Processing Steps}

The system processes this input through five steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{ArgDown Parsing}: Extract three nodes with relationships in
  ArgDown syntax
\item
  \textbf{Question Generation}: Generate questions based on the possible
  instantiations and combinations of each parent note to identify the
  probabilities to be extracted in the next step
\item
  \textbf{BayesDown Extraction}: LLM call extracting the full
  conditional probability tables for each node
\item
  \textbf{Construction}: Building of the formal Bayesian network
\item
  \textbf{Visualization}: Render interactive display
\end{enumerate}

\subsection*{3.4.2 Example Conversion Steps}\label{sec-rsg-input}
\addcontentsline{toc}{subsection}{3.4.2 Example Conversion Steps}

\subsubsection*{ArgDown Example}\label{argdown-example}
\addcontentsline{toc}{subsubsection}{ArgDown Example}

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{[Grass\_Wet]: }\NormalTok{Concentrated moisture on, between and around the blades of grass.\{"instantiations": }\CommentTok{[}\OtherTok{"grass\_wet\_TRUE", "grass\_wet\_FALSE"}\CommentTok{]}\NormalTok{\}    }
\NormalTok{    +}\CommentTok{[}\OtherTok{Rain}\CommentTok{]}\NormalTok{: Tears of angles crying high up in the skies hitting the ground.\{"instantiations": }\CommentTok{[}\OtherTok{"rain\_TRUE", "rain\_FALSE"}\CommentTok{]}\NormalTok{\}}
\NormalTok{    +}\CommentTok{[}\OtherTok{Sprinkler}\CommentTok{]}\NormalTok{: Activation of a centrifugal force based CO2 droplet distribution system.\{"instantiations": }\CommentTok{[}\OtherTok{"sprinkler\_TRUE", "sprinkler\_FALSE"}\CommentTok{]}\NormalTok{\}}
\NormalTok{        +}\CommentTok{[}\OtherTok{Rain}\CommentTok{]}
\end{Highlighting}
\end{Shaded}

\subsubsection*{Example of Questions for BayesDown
extraction}\label{example-of-questions-for-bayesdown-extraction}
\addcontentsline{toc}{subsubsection}{Example of Questions for BayesDown
extraction}

\begin{Shaded}
\begin{Highlighting}[]
\AnnotationTok{BayesDown Format Preview:}
\FunctionTok{\# BayesDown Representation with Placeholder Probabilities}

\NormalTok{/* This file contains BayesDown syntax with placeholder probabilities.}
\NormalTok{   Replace the placeholders with actual probability values based on the }
\NormalTok{   questions in the comments. */}

\InformationTok{    /* What is the probability for Grass\_Wet=grass\_wet\_TRUE? */}
\InformationTok{    /* What is the probability for Grass\_Wet=grass\_wet\_TRUE if Rain=rain\_TRUE, Sprinkler=sprinkler\_TRUE? */}
\InformationTok{    /* What is the probability for Grass\_Wet=grass\_wet\_TRUE if Rain=rain\_TRUE, Sprinkler=sprinkler\_FALSE? */}
\InformationTok{    /* What is the probability for Grass\_Wet=grass\_wet\_TRUE if Rain=rain\_FALSE, Sprinkler=sprinkler\_TRUE? */}
\InformationTok{    /* What is the probability for Grass\_Wet=grass\_wet\_TRUE if Rain=rain\_FALSE, Sprinkler=sprinkler\_FALSE? */}
\InformationTok{    /* What is the probability for Grass\_Wet=grass\_wet\_FALSE? */}
\InformationTok{    /* What is the probability for Grass\_Wet=grass\_wet\_FALSE if Rain=rain\_TRUE, Sprinkler=sprinkler\_TRUE? */}
\InformationTok{    /* What is the probability for Grass\_Wet=grass\_wet\_FALSE if Rain=rain\_TRUE, Sprinkler=sprinkler\_FALSE? */}
\InformationTok{    /* What is the probability for Grass\_Wet=grass\_wet\_FALSE if Rain=rain\_FALSE, Sprinkler=sprinkler\_TRUE? */}
\InformationTok{    /* What is the probability for Grass\_Wet=grass\_wet\_FALSE if Rain=rain\_FALSE, Sprinkler=sprinkler\_FALSE? */}
\InformationTok{    [Grass\_Wet]: Concentrated moisture on, between and around the blades of grass. \{"instantiations": ["grass\_wet\_TRUE", "grass\_wet\_FALSE"], "priors": \{"What is the probability for Grass\_Wet=grass\_wet\_TRUE?": "\%?", "What is the probability for Grass\_Wet=grass\_wet\_FALSE?": "\%?"\}, "posteriors": \{"What is the probability for Grass\_Wet=grass\_wet\_TRUE if Rain=rain\_TRUE, Sprinkler=sprinkler\_TRUE?": "?\%", "What is the probability for Grass\_Wet=grass\_wet\_TRUE if Rain=rain\_TRUE, Sprinkler=sprinkler\_FALSE?": "?\%", "What is the probability for Grass\_Wet=grass\_wet\_TRUE if Rain=rain\_FALSE, Sprinkler=sprinkler\_TRUE?": "?\%", "What is the probability for Grass\_Wet=grass\_wet\_TRUE if Rain=rain\_FALSE, Sprinkler=sprinkler\_FALSE?": "?\%", "What is the probability for Grass\_Wet=grass\_wet\_FALSE if Rain=rain\_TRUE, Sprinkler=sprinkler\_TRUE?": "?\%", "What is the probability for Grass\_Wet=grass\_wet\_FALSE if Rain=rain\_TRUE, Sprinkler=sprinkler\_FALSE?": "?\%", "What is the probability for Grass\_Wet=grass\_wet\_FALSE if Rain=rain\_FALSE, Sprinkler=sprinkler\_TRUE?": "?\%", "What is the probability for Grass\_Wet=grass\_wet\_FALSE if Rain=rain\_FALSE, Sprinkler=sprinkler\_FALSE?": "?\%"\}\}}
\InformationTok{        /* What is the probability for Rain=rain\_TRUE? */}
\InformationTok{        /* What is the probability for Rain=rain\_FALSE? */}
\InformationTok{        + [Rain]: Tears of angles crying high up in the skies hitting the ground. \{"instantiations": ["rain\_TRUE", "rain\_FALSE"], "priors": \{"What is the probability for Rain=rain\_TRUE?": "\%?", "What is the probability for Rain=rain\_FALSE?": "\%?"\}\}}
\InformationTok{        /* What is the probability for Sprinkler=sprinkler\_TRUE? */}
\InformationTok{        /* What is the probability for Sprinkler=sprinkler\_TRUE if Rain=rain\_TRUE? */}
\InformationTok{        /* What is the probability for Sprinkler=sprinkler\_TRUE if Rain=rain\_FALSE? */}
\InformationTok{        /* What is the probability for Sprinkler=sprinkler\_FALSE? */}
\InformationTok{        /* What is the probability for Sprinkler=sprinkler\_FALSE if Rain=rain\_TRUE? */}
\InformationTok{        /* What is the probability for Sprinkler=sprinkler\_FALSE if Rain=rain\_FALSE? */}
\InformationTok{        + [Sprinkler]: Activation of a centrifugal force based CO2 droplet distribution system. \{"instantiations": ["sprinkler\_TRUE", "sprinkler\_FALSE"], "priors": \{"What is the probability for Sprinkler=sprinkler\_TRUE?": "\%?", "What is the probability for Sprinkler=sprinkler\_FALSE?": "\%?"\}, "posteriors": \{"What is the probability for Sprinkler=sprinkler\_TRUE if Rain=rain\_TRUE?": "?\%", "What is the probability for Sprinkler=sprinkler\_TRUE if Rain=rain\_FALSE?": "?\%", "What is the probability for Sprinkler=sprinkler\_FALSE if Rain=rain\_TRUE?": "?\%", "What is the probability for Sprinkler=sprinkler\_FALSE if Rain=rain\_FALSE?": "?\%"\}\}}
\InformationTok{            /* What is the probability for Rain=rain\_TRUE? */}
\InformationTok{            /* What is the probability for Rain=rain\_FALSE? */}
\InformationTok{            + [Rain]}
\end{Highlighting}
\end{Shaded}

\subsubsection*{Complete BayesDown
Example}\label{complete-bayesdown-example}
\addcontentsline{toc}{subsubsection}{Complete BayesDown Example}

The source BayesDown syntax representating the fully specified network:

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{[Grass\_Wet]: }\NormalTok{Concentrated moisture on grass. \{"instantiations": }\CommentTok{[}\OtherTok{"grass\_wet\_TRUE", "grass\_wet\_FALSE"}\CommentTok{]}\NormalTok{,}
\NormalTok{ "priors": \{"p(grass\_wet\_TRUE)": "0.322", "p(grass\_wet\_FALSE)": "0.678"\},}
\NormalTok{ "posteriors": \{}
\NormalTok{   "p(grass\_wet\_TRUE|sprinkler\_TRUE,rain\_TRUE)": "0.99",}
\NormalTok{   "p(grass\_wet\_TRUE|sprinkler\_TRUE,rain\_FALSE)": "0.9",}
\NormalTok{   "p(grass\_wet\_TRUE|sprinkler\_FALSE,rain\_TRUE)": "0.8",}
\NormalTok{   "p(grass\_wet\_TRUE|sprinkler\_FALSE,rain\_FALSE)": "0.0"}
\NormalTok{ \}\}}
\SpecialStringTok{ + }\CommentTok{[}\OtherTok{Rain}\CommentTok{]}\NormalTok{: Water falling from sky. \{"instantiations": }\CommentTok{[}\OtherTok{"rain\_TRUE", "rain\_FALSE"}\CommentTok{]}\NormalTok{,}
\NormalTok{    "priors": \{"p(rain\_TRUE)": "0.2", "p(rain\_FALSE)": "0.8"\}\}}
\SpecialStringTok{ + }\CommentTok{[}\OtherTok{Sprinkler}\CommentTok{]}\NormalTok{: Artificial watering system. \{"instantiations": }\CommentTok{[}\OtherTok{"sprinkler\_TRUE", "sprinkler\_FALSE"}\CommentTok{]}\NormalTok{,}
\NormalTok{    "priors": \{"p(sprinkler\_TRUE)": "0.448", "p(sprinkler\_FALSE)": "0.552"\},}
\NormalTok{    "posteriors": \{}
\NormalTok{      "p(sprinkler\_TRUE|rain\_TRUE)": "0.01",}
\NormalTok{      "p(sprinkler\_TRUE|rain\_FALSE)": "0.4"}
\NormalTok{    \}\}}
\SpecialStringTok{   + }\CommentTok{[}\OtherTok{Rain}\CommentTok{]}
\end{Highlighting}
\end{Shaded}

\subsubsection*{Resulting Rain-Sprinkler-Grass
DataFrame}\label{resulting-rain-sprinkler-grass-dataframe}
\addcontentsline{toc}{subsubsection}{Resulting Rain-Sprinkler-Grass
DataFrame}

\#\textbar{} column: page

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 28\tabcolsep) * \real{0.0137}}
  >{\raggedright\arraybackslash}p{(\linewidth - 28\tabcolsep) * \real{0.0301}}
  >{\raggedright\arraybackslash}p{(\linewidth - 28\tabcolsep) * \real{0.1342}}
  >{\raggedright\arraybackslash}p{(\linewidth - 28\tabcolsep) * \real{0.0329}}
  >{\raggedright\arraybackslash}p{(\linewidth - 28\tabcolsep) * \real{0.0301}}
  >{\raggedright\arraybackslash}p{(\linewidth - 28\tabcolsep) * \real{0.0493}}
  >{\raggedright\arraybackslash}p{(\linewidth - 28\tabcolsep) * \real{0.0192}}
  >{\raggedright\arraybackslash}p{(\linewidth - 28\tabcolsep) * \real{0.0466}}
  >{\raggedright\arraybackslash}p{(\linewidth - 28\tabcolsep) * \real{0.0603}}
  >{\raggedright\arraybackslash}p{(\linewidth - 28\tabcolsep) * \real{0.0904}}
  >{\raggedright\arraybackslash}p{(\linewidth - 28\tabcolsep) * \real{0.1342}}
  >{\raggedright\arraybackslash}p{(\linewidth - 28\tabcolsep) * \real{0.1370}}
  >{\raggedright\arraybackslash}p{(\linewidth - 28\tabcolsep) * \real{0.0301}}
  >{\raggedright\arraybackslash}p{(\linewidth - 28\tabcolsep) * \real{0.0575}}
  >{\raggedright\arraybackslash}p{(\linewidth - 28\tabcolsep) * \real{0.1342}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Title
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
line
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
line\_numbers
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
indentation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
indentation\_levels
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Parents
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Children
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
instantiations
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
priors
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
posteriors
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
No\_Parent
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
No\_Children
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
parent\_instantiations
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & Grass\_Wet & Concentrated moisture on, between and around t\ldots{}
& 3 & {[}3{]} & 0 & {[}0{]} & {[}Rain, Sprinkler{]} & {[}{]} &
{[}grass\_wet\_TRUE, grass\_wet\_FALSE{]} & \{`p(grass\_wet\_TRUE)':
`0.322', 'p(grass\_wet\_FA\ldots{} &
\{`p(grass\_wet\_TRUE\textbar sprinkler\_TRUE,rain\_TRUE)':\ldots{} &
False & True & {[}{[}rain\_TRUE, rain\_FALSE{]}, {[}sprinkler\_TRUE,
spr\ldots{} \\
1 & Rain & Tears of angles crying high up in the skies hi\ldots{} & 4 &
{[}4, 6{]} & 2 & {[}1, 2{]} & {[}{]} & {[}Grass\_Wet, Sprinkler{]} &
{[}rain\_TRUE, rain\_FALSE{]} & \{`p(rain\_TRUE)': `0.2',
`p(rain\_FALSE)': `0.8'\} & \{\} & True & False & {[}{]} \\
2 & Sprinkler & Activation of a centrifugal force based CO2 dr\ldots{} &
5 & {[}5{]} & 1 & {[}1{]} & {[}Rain{]} & {[}Grass\_Wet{]} &
{[}sprinkler\_TRUE, sprinkler\_FALSE{]} & \{`p(sprinkler\_TRUE)':
`0.44838', 'p(sprinkler\_\ldots{} &
\{`p(sprinkler\_TRUE\textbar rain\_TRUE)': `0.01', 'p(spr\ldots{} &
False & False & {[}{[}rain\_TRUE, rain\_FALSE{]}{]} \\
\end{longtable}

\subsection*{3.4.3 Results}\label{sec-rsg-results}
\addcontentsline{toc}{subsection}{3.4.3 Results}

\subsection*{Rain-Sprinkler-Grass Network
Rendering}\label{rain-sprinkler-grass-network-rendering-2}
\addcontentsline{toc}{subsection}{Rain-Sprinkler-Grass Network
Rendering}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ IPython.display }\ImportTok{import}\NormalTok{ IFrame}

\NormalTok{IFrame(src}\OperatorTok{=}\StringTok{"https://singularitysmith.github.io/AMTAIR\_Prototype/bayesian\_network.html"}\NormalTok{, width}\OperatorTok{=}\StringTok{"100\%"}\NormalTok{, height}\OperatorTok{=}\StringTok{"600px"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\phantomsection\label{rain_sprinkler_grass_example_network_rendering2}
\begin{verbatim}
<IPython.lib.display.IFrame at 0x1120cdc10>
\end{verbatim}

Dynamic Html Rendering of the Rain-Sprinkler-Grass DAG with Conditional
Probabilities

\textbf{Validation Success}

The system successfully extracts complete network structure, preserves
all probability information, calculates correct marginal probabilities,
generates interactive visualization, and enables inference
queries---validating the basic pipeline functionality.

\section*{3.5 Case Study: Carlsmith's Power-Seeking AI
Model}\label{sec-case-carlsmith}
\addcontentsline{toc}{section}{3.5 Case Study: Carlsmith's Power-Seeking
AI Model}

\markright{3.5 Case Study: Carlsmith's Power-Seeking AI Model}

Applying AMTAIR to Carlsmith's model demonstrates scalability to
realistic AI safety arguments.

\subsection*{3.5.1 Model Complexity}\label{sec-carlsmith-complexity}
\addcontentsline{toc}{subsection}{3.5.1 Model Complexity}

The Carlsmith model contains:

\begin{itemize}
\tightlist
\item
  \textbf{23 nodes} representing different factors
\item
  \textbf{29 edges} encoding dependencies
\item
  \textbf{Multiple probability tables} with complex conditionals
\item
  \textbf{Six-level causal depth} from root causes to catastrophe
\end{itemize}

This represents a significant increase in complexity from the
pedagogical example.

\subsection*{3.5.2 Automated Extraction of the Carlsmith's Argument
Structure}\label{sec-carlsmith-extraction}
\addcontentsline{toc}{subsection}{3.5.2 Automated Extraction of the
Carlsmith's Argument Structure}

Having validated the implementation on the canonical rain-sprinkler-lawn
example, I applied the AMTAIR approach to a substantially more complex
real-world case: Joseph Carlsmith's model of existential risk from
power-seeking AI. This application demonstrates the system's ability to
handle sophisticated multi-level arguments with numerous variables and
relationships.

Carlsmith's analysis involves dozens of factors organized in a complex
causal structure, from root causes like ``Advanced AI Capability'' and
``Instrumental Convergence'' through intermediate factors like ``APS
Systems'' and ``Misaligned Power Seeking'' to final outcomes like
``Existential Catastrophe.'' The model exhibits several challenging
features:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Multi-level structure} with causal chains spanning multiple
  steps
\item
  \textbf{Divergent pathways} where factors influence outcomes through
  multiple routes
\item
  \textbf{Complex conditional dependencies} with variables influenced by
  multiple parents
\item
  \textbf{Variables with three or more possible states} rather than
  simple binary outcomes
\item
  \textbf{Interconnected clusters} where factors form distinct but
  related argument groups
\end{enumerate}

\textbf{Core Risk Pathway}:

\begin{verbatim}
Existential_Catastrophe 
← Human_Disempowerment 
← Scale_Of_Power_Seeking
← Misaligned_Power_Seeking
← [APS_Systems, Difficulty_Of_Alignment, Deployment_Decisions]
\end{verbatim}

\textbf{Supporting Structure}:

\begin{itemize}
\tightlist
\item
  Competitive dynamics influencing deployment
\item
  Technical factors affecting alignment difficulty
\item
  Corrective mechanisms and their limitations
\end{itemize}

\textbf{Probability Preservation}:

\begin{itemize}
\tightlist
\item
  Extracted probabilities match Carlsmith's published estimates
\item
  Conditional relationships properly captured
\item
  Final P(doom) calculation reproduces \textasciitilde5\% result
\end{itemize}

\subsubsection*{Prompting LLMs for ArgDown
Extraction}\label{prompting-llms-for-argdown-extraction}
\addcontentsline{toc}{subsubsection}{Prompting LLMs for ArgDown
Extraction}

\phantomsection\label{prompt_template_function}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 1.2.0 {-}{-}{-} Prompt Template Function Definitions {-}{-}{-} [prompt\_template\_function]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Defines a flexible template system for LLM prompts used in the extraction pipeline.}

\CommentTok{This block implements two key classes:}
\CommentTok{1. PromptTemplate: A template class supporting variable substitution for dynamic prompts}
\CommentTok{2. PromptLibrary: A collection of pre{-}defined prompt templates for different extraction tasks}

\CommentTok{These templates are used in the ArgDown and BayesDown probability extraction}
\CommentTok{stages of the pipeline, providing consistent and well{-}structured prompts to the LLMs.}

\CommentTok{DEPENDENCIES: string.Template for variable substitution}
\CommentTok{OUTPUTS: PromptTemplate and PromptLibrary classes}
\CommentTok{"""}

\ImportTok{from}\NormalTok{ string }\ImportTok{import}\NormalTok{ Template}
\ImportTok{from}\NormalTok{ typing }\ImportTok{import}\NormalTok{ Dict, Optional, Union, List}

\KeywordTok{class}\NormalTok{ PromptTemplate:}
    \CommentTok{"""Template system for LLM prompts with variable substitution"""}

    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, template: }\BuiltInTok{str}\NormalTok{):}
        \CommentTok{"""Initialize with template string using $variable format"""}
        \VariableTok{self}\NormalTok{.template }\OperatorTok{=}\NormalTok{ Template(template)}

    \KeywordTok{def} \BuiltInTok{format}\NormalTok{(}\VariableTok{self}\NormalTok{, }\OperatorTok{**}\NormalTok{kwargs) }\OperatorTok{{-}\textgreater{}} \BuiltInTok{str}\NormalTok{:}
        \CommentTok{"""Substitute variables in the template"""}
        \ControlFlowTok{return} \VariableTok{self}\NormalTok{.template.safe\_substitute(}\OperatorTok{**}\NormalTok{kwargs)}

    \AttributeTok{@classmethod}
    \KeywordTok{def}\NormalTok{ from\_file(cls, filepath: }\BuiltInTok{str}\NormalTok{) }\OperatorTok{{-}\textgreater{}} \StringTok{\textquotesingle{}PromptTemplate\textquotesingle{}}\NormalTok{:}
        \CommentTok{"""Load template from a file"""}
        \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(filepath, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{            template }\OperatorTok{=}\NormalTok{ f.read()}
        \ControlFlowTok{return}\NormalTok{ cls(template)}

\KeywordTok{class}\NormalTok{ PromptLibrary:}
    \CommentTok{"""Collection of prompt templates for different extraction tasks"""}

    \CommentTok{\# ArgDown extraction prompt {-} transforms source text into structured argument map}
\NormalTok{    ARGDOWN\_EXTRACTION }\OperatorTok{=}\NormalTok{ PromptTemplate(}\StringTok{"""}
\StringTok{You are participating in the AMTAIR (Automating Transformative AI Risk Modeling)}
\StringTok{project and you are tasked with converting natural language arguments into}
\StringTok{ArgDown syntax by extracting and formalizing causal world models from}
\StringTok{unstructured text.}
\StringTok{Your specific task is to extract the implicit causal model from the provided}
\StringTok{document in structured ArgDown format.}

\StringTok{\#\# Epistemic Foundation \& Purpose}

\StringTok{This extraction represents one possible interpretation of the implicit causal}
\StringTok{model in the document. Multiple extractions from the same text help reveal}
\StringTok{patterns of convergence (where the model is clearly articulated) and}
\StringTok{divergence (where the model contains ambiguities). This approach acknowledges}
\StringTok{that expert texts often contain implicit rather than explicit causal models.}

\StringTok{Your role is to reveal the causal structure already present in the author\textquotesingle{}s}
\StringTok{thinking, maintaining epistemic humility about your interpretation while}
\StringTok{adhering strictly to the required format.}

\StringTok{\#\# ArgDown Format Specification}

\StringTok{\#\#\# Core Syntax}

\StringTok{ArgDown represents causal relationships using a hierarchical structure:}

\StringTok{1. Variables appear in square brackets with descriptive text:}
\StringTok{   \textasciigrave{}[Variable\_Name]: Description of the variable.\textasciigrave{}}

\StringTok{2. Causal relationships use indentation (2 spaces per level) and \textquotesingle{}+\textquotesingle{} symbols:}

\StringTok{[Effect]: Description of effect. + [Cause]: Description of cause. + [Deeper\_Cause]: Description of deeper cause.}

\StringTok{3. Causality flows from bottom (more indented) to top (less indented):}
\StringTok{{-} More indented variables (causes) influence less indented variables (effects)}
\StringTok{{-} The top{-}level variable is the ultimate effect or outcome}
\StringTok{{-} Deeper indentation levels represent root causes or earlier factors}

\StringTok{4. Each variable must include JSON metadata with possible states (instantiations):}
\StringTok{\textasciigrave{}[Variable]: Description. \{"instantiations": ["variable\_STATE1", "variable\_STATE2"]\}\textasciigrave{}}

\StringTok{\#\#\# JSON Metadata Format}

\StringTok{The JSON metadata must follow this exact structure:}

\StringTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}json}
\StringTok{\{"instantiations": ["variable\_STATE1", "variable\_STATE2"]\}}

\StringTok{Requirements:}
\StringTok{* Double quotes (not single) around field names and string values}
\StringTok{* Square brackets enclosing the instantiations array}
\StringTok{* Comma separation between array elements}
\StringTok{* No trailing comma after the last element}
\StringTok{* Must be valid JSON syntax that can be parsed by standard JSON parsers}

\StringTok{For binary variables (most common case):}
\StringTok{\{"instantiations": ["variable\_TRUE", "variable\_FALSE"]\}}

\StringTok{For multi{-}state variables (when clearly specified in the text):}
\StringTok{\{"instantiations": ["variable\_HIGH", "variable\_MEDIUM", "variable\_LOW"]\}}

\StringTok{The metadata must appear on the same line as the variable definition, after the description.}
\StringTok{\#\# Complex Structural Patterns}
\StringTok{\#\#\# Variables Influencing Multiple Effects}
\StringTok{The same variable can appear multiple times in different places in the hierarchy if it influences multiple effects:}
\StringTok{[Effect1]: First effect description. \{"instantiations": ["effect1\_TRUE", "effect1\_FALSE"]\}}
\StringTok{  + [Cause\_A]: Description of cause A. \{"instantiations": ["cause\_a\_TRUE", "cause\_a\_FALSE"]\}}

\StringTok{[Effect2]: Second effect description. \{"instantiations": ["effect2\_TRUE", "effect2\_FALSE"]\}}
\StringTok{  + [Cause\_A]}
\StringTok{  + [Cause\_B]: Description of cause B. \{"instantiations": ["cause\_b\_TRUE", "cause\_b\_FALSE"]\}}

\StringTok{\#\#\# Multiple Causes of the Same Effect}
\StringTok{Multiple causes can influence the same effect by being listed at the same indentation level:}
\StringTok{[Effect]: Description of effect. \{"instantiations": ["effect\_TRUE", "effect\_FALSE"]\}}
\StringTok{  + [Cause1]: Description of first cause. \{"instantiations": ["cause1\_TRUE", "cause1\_FALSE"]\}}
\StringTok{  + [Cause2]: Description of second cause. \{"instantiations": ["cause2\_TRUE", "cause2\_FALSE"]\}}
\StringTok{    + [Deeper\_Cause]: A cause that influences Cause2. \{"instantiations": ["deeper\_cause\_TRUE", "deeper\_cause\_FALSE"]\}}

\StringTok{\#\#\# Causal Chains}
\StringTok{Causal chains are represented through multiple levels of indentation:}
\StringTok{[Ultimate\_Effect]: The final outcome. \{"instantiations": ["ultimate\_effect\_TRUE", "ultimate\_effect\_FALSE"]\}}
\StringTok{  + [Intermediate\_Effect]: A mediating variable. \{"instantiations": ["intermediate\_effect\_TRUE", "intermediate\_effect\_FALSE"]\}}
\StringTok{    + [Root\_Cause]: The initial cause. \{"instantiations": ["root\_cause\_TRUE", "root\_cause\_FALSE"]\}}
\StringTok{  + [2nd\_Intermediate\_Effect]: A mediating variable. \{"instantiations": ["intermediate\_effect\_TRUE", "intermediate\_effect\_FALSE"]\}}


\StringTok{\#\#\# Common Cause of Multiple Variables}
\StringTok{A common cause affecting multiple variables is represented by referencing the same variable in multiple places:}
\StringTok{[Effect1]: First effect description. \{"instantiations": ["effect1\_TRUE", "effect1\_FALSE"]\}}
\StringTok{  + [Common\_Cause]: Description of common cause. \{"instantiations": ["common\_cause\_TRUE", "common\_cause\_FALSE"]\}}

\StringTok{[Effect2]: Second effect description. \{"instantiations": ["effect2\_TRUE", "effect2\_FALSE"]\}}
\StringTok{  + [Common\_Cause]}

\StringTok{\#\# Detailed Extraction Workflow}
\StringTok{Please follow this step{-}by{-}step process, documenting your reasoning in XML tags:}
\StringTok{\textless{}analysis\textgreater{}}
\StringTok{First, conduct a holistic analysis of the document:}
\StringTok{1. Identify the main subject matter or domain}
\StringTok{2. Note key concepts, variables, and factors discussed}
\StringTok{3. Pay attention to language indicating causal relationships (causes, affects, influences, depends on, etc.)}
\StringTok{4. Look for the ultimate outcomes or effects that are the focus of the document}
\StringTok{5. Record your general understanding of the document\textquotesingle{}s implicit causal structure}
\StringTok{\textless{}/analysis\textgreater{}}
\StringTok{\textless{}variable\_identification\textgreater{}}
\StringTok{Next, identify and list the key variables in the causal model:}
\StringTok{* Focus on factors that are discussed as having an influence or being influenced}
\StringTok{* For each variable:}
\StringTok{  * Create a descriptive name in [square\_brackets]}
\StringTok{  * Write a concise description based directly on the text}
\StringTok{  * Determine possible states (usually binary TRUE/FALSE unless clearly specified)}
\StringTok{* Distinguish between:}
\StringTok{  * Outcome variables (effects the author is concerned with)}
\StringTok{  * Intermediate variables (both causes and effects in chains)}
\StringTok{  * Root cause variables (exogenous factors in the model)}
\StringTok{* List all identified variables with their descriptions and possible states}
\StringTok{\textless{}/variable\_identification\textgreater{}}

\StringTok{\textless{}causal\_structure\textgreater{}}
\StringTok{Then, determine the causal relationships between variables:}
\StringTok{* For each variable, identify what factors influence it}
\StringTok{* Note the direction of causality (what causes what)}
\StringTok{* Look for mediating variables in causal chains}
\StringTok{* Identify common causes of multiple effects}
\StringTok{* Capture feedback loops if present (though they must be represented as DAGs)}
\StringTok{* Map out the hierarchical structure of the causal model}
\StringTok{\textless{}/causal\_structure\textgreater{}}

\StringTok{\textless{}format\_conversion\textgreater{}}
\StringTok{Now, convert your analysis into proper ArgDown format:}
\StringTok{* Start with the ultimate outcome variables at the top level}
\StringTok{* Place direct causes indented below with }\ErrorTok{\textbackslash{}}\StringTok{+ symbols}
\StringTok{* Continue with deeper causes at further indentation levels}
\StringTok{* Add variable descriptions and instantiations metadata}
\StringTok{* Ensure variables appearing in multiple places have consistent names}
\StringTok{* Check that the entire structure forms a valid directed acyclic graph}
\StringTok{\textless{}/format\_conversion\textgreater{}}

\StringTok{\textless{}validation\textgreater{}}

\StringTok{Finally, review your extraction for quality and format correctness:}
\StringTok{1. Verify all variables have properly formatted metadata}
\StringTok{2. Check that indentation properly represents causal direction}
\StringTok{3. Confirm the extraction accurately reflects the document\textquotesingle{}s implicit model}
\StringTok{4. Ensure no cycles exist in the causal structure}
\StringTok{5. Verify that variables referenced multiple times are consistent}
\StringTok{6. Check that the extraction would be useful for subsequent analysis}

\StringTok{\textless{}/validation\textgreater{}}


\StringTok{\#\# Source Document Analysis Guidance}
\StringTok{When analyzing the source document:}
\StringTok{* Focus on revealing the author\textquotesingle{}s own causal model, not imposing an external framework}
\StringTok{* Maintain the author\textquotesingle{}s terminology where possible}
\StringTok{* Look for both explicit statements of causality and implicit assumptions}
\StringTok{* Pay attention to the relative importance the author assigns to different factors}
\StringTok{* Notice where the author expresses certainty versus uncertainty}
\StringTok{* Consider the level of granularity appropriate to the document\textquotesingle{}s own analysis}

\StringTok{Remember that your goal is to make the implicit model explicit, not to evaluate or improve it.}
\StringTok{The value lies in accurately representing the author\textquotesingle{}s perspective, even if you might personally disagree or see limitations in their model.}

\StringTok{"""}\NormalTok{)}

    \CommentTok{\# BayesDown probability extraction prompt {-} enhances ArgDown with probability information}
\NormalTok{    BAYESDOWN\_EXTRACTION }\OperatorTok{=}\NormalTok{ PromptTemplate(}\StringTok{"""}
\StringTok{You are an expert in probabilistic reasoning and Bayesian networks. Your task is}
\StringTok{to extend the provided ArgDown structure with probability information,}
\StringTok{creating a BayesDown representation.}

\StringTok{For each statement in the ArgDown structure, you need to:}
\StringTok{1. Estimate prior probabilities for each possible state}
\StringTok{2. Estimate conditional probabilities given parent states}
\StringTok{3. Maintain the original structure and relationships}

\StringTok{Here is the format to follow:}
\StringTok{[Node]: Description. \{ "instantiations": ["node\_TRUE", "node\_FALSE"], "priors": \{ "p(node\_TRUE)": "0.7", "p(node\_FALSE)": "0.3" \}, "posteriors": \{ "p(node\_TRUE|parent\_TRUE)": "0.9", "p(node\_TRUE|parent\_FALSE)": "0.4", "p(node\_FALSE|parent\_TRUE)": "0.1", "p(node\_FALSE|parent\_FALSE)": "0.6" \} \}}
\StringTok{ [Parent]: Parent description. \{...\}}


\StringTok{Here are the specific probability questions to answer:}
\StringTok{$questions}

\StringTok{ArgDown structure to enhance:}
\StringTok{$argdown}

\StringTok{Provide the complete BayesDown representation with probabilities:}
\StringTok{"""}\NormalTok{)}

    \AttributeTok{@classmethod}
    \KeywordTok{def}\NormalTok{ get\_template(cls, template\_name: }\BuiltInTok{str}\NormalTok{) }\OperatorTok{{-}\textgreater{}}\NormalTok{ PromptTemplate:}
        \CommentTok{"""Get a prompt template by name"""}
        \ControlFlowTok{if} \BuiltInTok{hasattr}\NormalTok{(cls, template\_name):}
            \ControlFlowTok{return} \BuiltInTok{getattr}\NormalTok{(cls, template\_name)}
        \ControlFlowTok{else}\NormalTok{:}
            \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{(}\SpecialStringTok{f"Template not found: }\SpecialCharTok{\{}\NormalTok{template\_name}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection*{Processing LLM Response}\label{processing-llm-response}
\addcontentsline{toc}{subsubsection}{Processing LLM Response}

The extraction process began with an ArgDown representation capturing
the structural relationships between variables:

\phantomsection\label{parsing_argdown_bayesdown}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 1.7.0 {-}{-}{-} Parsing ArgDown \& BayesDown (.md to .csv) {-}{-}{-} [parsing\_argdown\_bayesdown]}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Provides the core parsing functionality for transforming ArgDown}
\CommentTok{and BayesDown text representations into structured DataFrame format for further}
\CommentTok{processing.}

\CommentTok{This block implements the critical extraction pipeline described in the AMTAIR}
\CommentTok{project (see PY\_TechnicalImplementation) that converts argument structures}
\CommentTok{into Bayesian networks.}
\CommentTok{The function can handle both basic ArgDown (structure{-}only) and}
\CommentTok{BayesDown (with probabilities).}

\CommentTok{Key steps in the parsing process:}
\CommentTok{1. Remove comments from the markdown text}
\CommentTok{2. Extract titles, descriptions, and indentation levels}
\CommentTok{3. Establish parent{-}child relationships based on indentation}
\CommentTok{4. Convert the structured information into a DataFrame}
\CommentTok{5. Add derived columns for network analysis}

\CommentTok{DEPENDENCIES: pandas, re, json libraries}
\CommentTok{INPUTS: Markdown text in ArgDown/BayesDown format}
\CommentTok{OUTPUTS: Structured DataFrame with node information, relationships, and properties}
\CommentTok{"""}

\KeywordTok{def}\NormalTok{ parse\_markdown\_hierarchy\_fixed(markdown\_text, ArgDown}\OperatorTok{=}\VariableTok{False}\NormalTok{):}
    \CommentTok{"""}
\CommentTok{    Parse ArgDown or BayesDown format into a structured DataFrame with parent{-}child relationships.}

\CommentTok{    Args:}
\CommentTok{        markdown\_text (str): Text in ArgDown or BayesDown format}
\CommentTok{        ArgDown (bool): If True, extracts only structure without probabilities}
\CommentTok{                        If False, extracts both structure and probability information}

\CommentTok{    Returns:}
\CommentTok{        pandas.DataFrame: Structured data with node information, relationships, and attributes}
\CommentTok{    """}
    \CommentTok{\# PHASE 1: Clean and prepare the text}
\NormalTok{    clean\_text }\OperatorTok{=}\NormalTok{ remove\_comments(markdown\_text)}

    \CommentTok{\# PHASE 2: Extract basic information about nodes}
\NormalTok{    titles\_info }\OperatorTok{=}\NormalTok{ extract\_titles\_info(clean\_text)}

    \CommentTok{\# PHASE 3: Determine the hierarchical relationships}
\NormalTok{    titles\_with\_relations }\OperatorTok{=}\NormalTok{ establish\_relationships\_fixed(titles\_info, clean\_text)}

    \CommentTok{\# PHASE 4: Convert to structured DataFrame format}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ convert\_to\_dataframe(titles\_with\_relations, ArgDown)}

    \CommentTok{\# PHASE 5: Add derived columns for analysis}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ add\_no\_parent\_no\_child\_columns\_to\_df(df)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ add\_parents\_instantiation\_columns\_to\_df(df)}

    \ControlFlowTok{return}\NormalTok{ df}

\KeywordTok{def}\NormalTok{ remove\_comments(markdown\_text):}
    \CommentTok{"""}
\CommentTok{    Remove comment blocks from markdown text using regex pattern matching.}

\CommentTok{    Args:}
\CommentTok{        markdown\_text (str): Text containing potential comment blocks}

\CommentTok{    Returns:}
\CommentTok{        str: Text with comment blocks removed}
\CommentTok{    """}
    \CommentTok{\# Remove anything between /* and */ using regex}
    \ControlFlowTok{return}\NormalTok{ re.sub(}\VerbatimStringTok{r\textquotesingle{}/}\CharTok{\textbackslash{}*}\DecValTok{.}\OperatorTok{*?}\CharTok{\textbackslash{}*}\VerbatimStringTok{/\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{, markdown\_text, flags}\OperatorTok{=}\NormalTok{re.DOTALL)}

\KeywordTok{def}\NormalTok{ extract\_titles\_info(text):}
    \CommentTok{"""}
\CommentTok{    Extract titles with their descriptions and indentation levels from markdown text.}

\CommentTok{    Args:}
\CommentTok{        text (str): Cleaned markdown text}

\CommentTok{    Returns:}
\CommentTok{        dict: Dictionary with titles as keys and dictionaries of attributes as values}
\CommentTok{    """}
\NormalTok{    lines }\OperatorTok{=}\NormalTok{ text.split(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    titles\_info }\OperatorTok{=}\NormalTok{ \{\}}

    \ControlFlowTok{for}\NormalTok{ line }\KeywordTok{in}\NormalTok{ lines:}
        \CommentTok{\# Skip empty lines}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ line.strip():}
            \ControlFlowTok{continue}

        \CommentTok{\# Extract title within square or angle brackets}
\NormalTok{        title\_match }\OperatorTok{=}\NormalTok{ re.search(}\VerbatimStringTok{r\textquotesingle{}}\PreprocessorTok{[\textless{}}\CharTok{\textbackslash{}[}\PreprocessorTok{]}\KeywordTok{(}\DecValTok{.}\OperatorTok{+?}\KeywordTok{)}\PreprocessorTok{[\textgreater{}}\CharTok{\textbackslash{}]}\PreprocessorTok{]}\VerbatimStringTok{\textquotesingle{}}\NormalTok{, line)}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ title\_match:}
            \ControlFlowTok{continue}

\NormalTok{        title }\OperatorTok{=}\NormalTok{ title\_match.group(}\DecValTok{1}\NormalTok{)}

        \CommentTok{\# Extract description and metadata}
\NormalTok{        title\_pattern\_in\_line }\OperatorTok{=} \VerbatimStringTok{r\textquotesingle{}}\PreprocessorTok{[\textless{}}\CharTok{\textbackslash{}[}\PreprocessorTok{]}\VerbatimStringTok{\textquotesingle{}} \OperatorTok{+}\NormalTok{ re.escape(title) }\OperatorTok{+} \VerbatimStringTok{r\textquotesingle{}}\PreprocessorTok{[\textgreater{}}\CharTok{\textbackslash{}]}\PreprocessorTok{]}\VerbatimStringTok{:\textquotesingle{}}
\NormalTok{        description\_match }\OperatorTok{=}\NormalTok{ re.search(title\_pattern\_in\_line }\OperatorTok{+} \VerbatimStringTok{r\textquotesingle{}}\DecValTok{\textbackslash{}s}\OperatorTok{*}\KeywordTok{(}\DecValTok{.}\OperatorTok{*}\KeywordTok{)}\VerbatimStringTok{\textquotesingle{}}\NormalTok{, line)}

        \ControlFlowTok{if}\NormalTok{ description\_match:}
\NormalTok{            full\_text }\OperatorTok{=}\NormalTok{ description\_match.group(}\DecValTok{1}\NormalTok{).strip()}

            \CommentTok{\# Split description and metadata at the first "\{"}
            \ControlFlowTok{if} \StringTok{"\{"} \KeywordTok{in}\NormalTok{ full\_text:}
\NormalTok{                split\_index }\OperatorTok{=}\NormalTok{ full\_text.find(}\StringTok{"\{"}\NormalTok{)}
\NormalTok{                description }\OperatorTok{=}\NormalTok{ full\_text[:split\_index].strip()}
\NormalTok{                metadata }\OperatorTok{=}\NormalTok{ full\_text[split\_index:].strip()}
            \ControlFlowTok{else}\NormalTok{:}
                \CommentTok{\# Keep the entire description and no metadata}
\NormalTok{                description }\OperatorTok{=}\NormalTok{ full\_text}
\NormalTok{                metadata }\OperatorTok{=} \StringTok{\textquotesingle{}\textquotesingle{}}  \CommentTok{\# Initialize as empty string}
        \ControlFlowTok{else}\NormalTok{:}
\NormalTok{            description }\OperatorTok{=} \StringTok{\textquotesingle{}\textquotesingle{}}
\NormalTok{            metadata }\OperatorTok{=} \StringTok{\textquotesingle{}\textquotesingle{}}  \CommentTok{\# Ensure metadata is initialized}

        \CommentTok{\# Calculate indentation level based on spaces before + or {-} symbol}
\NormalTok{        indentation }\OperatorTok{=} \DecValTok{0}
        \ControlFlowTok{if} \StringTok{\textquotesingle{}+\textquotesingle{}} \KeywordTok{in}\NormalTok{ line:}
\NormalTok{            symbol\_index }\OperatorTok{=}\NormalTok{ line.find(}\StringTok{\textquotesingle{}+\textquotesingle{}}\NormalTok{)}
            \CommentTok{\# Count spaces before the \textquotesingle{}+\textquotesingle{} symbol}
\NormalTok{            i }\OperatorTok{=}\NormalTok{ symbol\_index }\OperatorTok{{-}} \DecValTok{1}
            \ControlFlowTok{while}\NormalTok{ i }\OperatorTok{\textgreater{}=} \DecValTok{0} \KeywordTok{and}\NormalTok{ line[i] }\OperatorTok{==} \StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{:}
\NormalTok{                indentation }\OperatorTok{+=} \DecValTok{1}
\NormalTok{                i }\OperatorTok{{-}=} \DecValTok{1}
        \ControlFlowTok{elif} \StringTok{\textquotesingle{}{-}\textquotesingle{}} \KeywordTok{in}\NormalTok{ line:}
\NormalTok{            symbol\_index }\OperatorTok{=}\NormalTok{ line.find(}\StringTok{\textquotesingle{}{-}\textquotesingle{}}\NormalTok{)}
            \CommentTok{\# Count spaces before the \textquotesingle{}{-}\textquotesingle{} symbol}
\NormalTok{            i }\OperatorTok{=}\NormalTok{ symbol\_index }\OperatorTok{{-}} \DecValTok{1}
            \ControlFlowTok{while}\NormalTok{ i }\OperatorTok{\textgreater{}=} \DecValTok{0} \KeywordTok{and}\NormalTok{ line[i] }\OperatorTok{==} \StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{:}
\NormalTok{                indentation }\OperatorTok{+=} \DecValTok{1}
\NormalTok{                i }\OperatorTok{{-}=} \DecValTok{1}

        \CommentTok{\# If neither symbol exists, indentation remains 0}

        \ControlFlowTok{if}\NormalTok{ title }\KeywordTok{in}\NormalTok{ titles\_info:}
            \CommentTok{\# Only update description if it\textquotesingle{}s currently empty and we found a new one}
            \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ titles\_info[title][}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{] }\KeywordTok{and}\NormalTok{ description:}
\NormalTok{                titles\_info[title][}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ description}

            \CommentTok{\# Store all indentation levels for this title}
\NormalTok{            titles\_info[title][}\StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{].append(indentation)}

            \CommentTok{\# Keep max indentation for backward compatibility}
            \ControlFlowTok{if}\NormalTok{ indentation }\OperatorTok{\textgreater{}}\NormalTok{ titles\_info[title][}\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{]:}
\NormalTok{                titles\_info[title][}\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ indentation}

            \CommentTok{\# Do NOT update metadata here {-} keep the original metadata}
        \ControlFlowTok{else}\NormalTok{:}
            \CommentTok{\# First time seeing this title, create a new entry}
\NormalTok{            titles\_info[title] }\OperatorTok{=}\NormalTok{ \{}
                \StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{: description,}
                \StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{: indentation,}
                \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{: [indentation],  }\CommentTok{\# Initialize with first indentation level}
                \StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{: [],}
                \StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{: [],}
                \StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{: }\VariableTok{None}\NormalTok{,}
                \StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{: [],  }\CommentTok{\# Initialize an empty list for all occurrences}
                \StringTok{\textquotesingle{}metadata\textquotesingle{}}\NormalTok{: metadata  }\CommentTok{\# Set metadata explicitly from what we found}
\NormalTok{            \}}

    \ControlFlowTok{return}\NormalTok{ titles\_info}

\KeywordTok{def}\NormalTok{ establish\_relationships\_fixed(titles\_info, text):}
    \CommentTok{"""}
\CommentTok{    Establish parent{-}child relationships between titles using BayesDown}
\CommentTok{    indentation rules.}

\CommentTok{    In BayesDown syntax:}
\CommentTok{    {-} More indented nodes (with + symbol) are PARENTS of less indented nodes}
\CommentTok{    {-} The relationship reads as "Effect is caused by Cause" (Effect + Cause)}
\CommentTok{    {-} This aligns with how Bayesian networks represent causality}

\CommentTok{    Args:}
\CommentTok{        titles\_info (dict): Dictionary with information about titles}
\CommentTok{        text (str): Original markdown text (for identifying line numbers)}

\CommentTok{    Returns:}
\CommentTok{        dict: Updated dictionary with parent{-}child relationships}
\CommentTok{    """}
\NormalTok{    lines }\OperatorTok{=}\NormalTok{ text.split(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}

    \CommentTok{\# Dictionary to store line numbers for each title occurrence}
\NormalTok{    title\_occurrences }\OperatorTok{=}\NormalTok{ \{\}}

    \CommentTok{\# Record line number for each title (including multiple occurrences)}
\NormalTok{    line\_number }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ line }\KeywordTok{in}\NormalTok{ lines:}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ line.strip():}
\NormalTok{            line\_number }\OperatorTok{+=} \DecValTok{1}
            \ControlFlowTok{continue}

\NormalTok{        title\_match }\OperatorTok{=}\NormalTok{ re.search(}\VerbatimStringTok{r\textquotesingle{}}\PreprocessorTok{[\textless{}}\CharTok{\textbackslash{}[}\PreprocessorTok{]}\KeywordTok{(}\DecValTok{.}\OperatorTok{+?}\KeywordTok{)}\PreprocessorTok{[\textgreater{}}\CharTok{\textbackslash{}]}\PreprocessorTok{]}\VerbatimStringTok{\textquotesingle{}}\NormalTok{, line)}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ title\_match:}
\NormalTok{            line\_number }\OperatorTok{+=} \DecValTok{1}
            \ControlFlowTok{continue}

\NormalTok{        title }\OperatorTok{=}\NormalTok{ title\_match.group(}\DecValTok{1}\NormalTok{)}

        \CommentTok{\# Store all occurrences of each title with their line numbers}
        \ControlFlowTok{if}\NormalTok{ title }\KeywordTok{not} \KeywordTok{in}\NormalTok{ title\_occurrences:}
\NormalTok{            title\_occurrences[title] }\OperatorTok{=}\NormalTok{ []}
\NormalTok{        title\_occurrences[title].append(line\_number)}

        \CommentTok{\# Store all line numbers where this title appears}
        \ControlFlowTok{if} \StringTok{\textquotesingle{}line\_numbers\textquotesingle{}} \KeywordTok{not} \KeywordTok{in}\NormalTok{ titles\_info[title]:}
\NormalTok{            titles\_info[title][}\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ []}
\NormalTok{        titles\_info[title][}\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{].append(line\_number)}

        \CommentTok{\# For backward compatibility, keep the first occurrence in \textquotesingle{}line\textquotesingle{}}
        \ControlFlowTok{if}\NormalTok{ titles\_info[title][}\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{] }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
\NormalTok{            titles\_info[title][}\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ line\_number}

\NormalTok{        line\_number }\OperatorTok{+=} \DecValTok{1}

    \CommentTok{\# Create an ordered list of all title occurrences with their line numbers}
\NormalTok{    all\_occurrences }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{for}\NormalTok{ title, occurrences }\KeywordTok{in}\NormalTok{ title\_occurrences.items():}
        \ControlFlowTok{for}\NormalTok{ line\_num }\KeywordTok{in}\NormalTok{ occurrences:}
\NormalTok{            all\_occurrences.append((title, line\_num))}

    \CommentTok{\# Sort occurrences by line number}
\NormalTok{    all\_occurrences.sort(key}\OperatorTok{=}\KeywordTok{lambda}\NormalTok{ x: x[}\DecValTok{1}\NormalTok{])}

    \CommentTok{\# Get indentation for each occurrence}
\NormalTok{    occurrence\_indents }\OperatorTok{=}\NormalTok{ \{\}}
    \ControlFlowTok{for}\NormalTok{ title, line\_num }\KeywordTok{in}\NormalTok{ all\_occurrences:}
        \ControlFlowTok{for}\NormalTok{ line }\KeywordTok{in}\NormalTok{ lines[line\_num:line\_num}\OperatorTok{+}\DecValTok{1}\NormalTok{]:  }\CommentTok{\# Only check the current line}
\NormalTok{            indent }\OperatorTok{=} \DecValTok{0}
            \ControlFlowTok{if} \StringTok{\textquotesingle{}+\textquotesingle{}} \KeywordTok{in}\NormalTok{ line:}
\NormalTok{                symbol\_index }\OperatorTok{=}\NormalTok{ line.find(}\StringTok{\textquotesingle{}+\textquotesingle{}}\NormalTok{)}
                \CommentTok{\# Count spaces before the \textquotesingle{}+\textquotesingle{} symbol}
\NormalTok{                j }\OperatorTok{=}\NormalTok{ symbol\_index }\OperatorTok{{-}} \DecValTok{1}
                \ControlFlowTok{while}\NormalTok{ j }\OperatorTok{\textgreater{}=} \DecValTok{0} \KeywordTok{and}\NormalTok{ line[j] }\OperatorTok{==} \StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{:}
\NormalTok{                    indent }\OperatorTok{+=} \DecValTok{1}
\NormalTok{                    j }\OperatorTok{{-}=} \DecValTok{1}
            \ControlFlowTok{elif} \StringTok{\textquotesingle{}{-}\textquotesingle{}} \KeywordTok{in}\NormalTok{ line:}
\NormalTok{                symbol\_index }\OperatorTok{=}\NormalTok{ line.find(}\StringTok{\textquotesingle{}{-}\textquotesingle{}}\NormalTok{)}
                \CommentTok{\# Count spaces before the \textquotesingle{}{-}\textquotesingle{} symbol}
\NormalTok{                j }\OperatorTok{=}\NormalTok{ symbol\_index }\OperatorTok{{-}} \DecValTok{1}
                \ControlFlowTok{while}\NormalTok{ j }\OperatorTok{\textgreater{}=} \DecValTok{0} \KeywordTok{and}\NormalTok{ line[j] }\OperatorTok{==} \StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{:}
\NormalTok{                    indent }\OperatorTok{+=} \DecValTok{1}
\NormalTok{                    j }\OperatorTok{{-}=} \DecValTok{1}
\NormalTok{            occurrence\_indents[(title, line\_num)] }\OperatorTok{=}\NormalTok{ indent}

    \CommentTok{\# Enhanced backward pass for correct parent{-}child relationships}
    \ControlFlowTok{for}\NormalTok{ i, (title, line\_num) }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(all\_occurrences):}
\NormalTok{        current\_indent }\OperatorTok{=}\NormalTok{ occurrence\_indents[(title, line\_num)]}

        \CommentTok{\# Skip root nodes (indentation 0) for processing}
        \ControlFlowTok{if}\NormalTok{ current\_indent }\OperatorTok{==} \DecValTok{0}\NormalTok{:}
            \ControlFlowTok{continue}

        \CommentTok{\# Look for the immediately preceding node with lower indentation}
\NormalTok{        j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}
        \ControlFlowTok{while}\NormalTok{ j }\OperatorTok{\textgreater{}=} \DecValTok{0}\NormalTok{:}
\NormalTok{            prev\_title, prev\_line }\OperatorTok{=}\NormalTok{ all\_occurrences[j]}
\NormalTok{            prev\_indent }\OperatorTok{=}\NormalTok{ occurrence\_indents[(prev\_title, prev\_line)]}

            \CommentTok{\# If we find a node with less indentation, it\textquotesingle{}s a child of current node}
            \ControlFlowTok{if}\NormalTok{ prev\_indent }\OperatorTok{\textless{}}\NormalTok{ current\_indent:}
                \CommentTok{\# In BayesDown:}
                \CommentTok{\# More indented node is a parent (cause) of less indented node (effect)}
                \ControlFlowTok{if}\NormalTok{ title }\KeywordTok{not} \KeywordTok{in}\NormalTok{ titles\_info[prev\_title][}\StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{]:}
\NormalTok{                    titles\_info[prev\_title][}\StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{].append(title)}
                \ControlFlowTok{if}\NormalTok{ prev\_title }\KeywordTok{not} \KeywordTok{in}\NormalTok{ titles\_info[title][}\StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{]:}
\NormalTok{                    titles\_info[title][}\StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{].append(prev\_title)}

                \CommentTok{\# Only need to find the immediate child}
                \CommentTok{\# (closest preceding node with lower indentation)}
                \ControlFlowTok{break}

\NormalTok{            j }\OperatorTok{{-}=} \DecValTok{1}

    \ControlFlowTok{return}\NormalTok{ titles\_info}

\KeywordTok{def}\NormalTok{ convert\_to\_dataframe(titles\_info, ArgDown):}
    \CommentTok{"""}
\CommentTok{    Convert the titles information dictionary to a pandas DataFrame.}

\CommentTok{    Args:}
\CommentTok{        titles\_info (dict): Dictionary with information about titles}
\CommentTok{        ArgDown (bool): If True, extract only structural information without probabilities}

\CommentTok{    Returns:}
\CommentTok{        pandas.DataFrame: Structured data with node information and relationships}
\CommentTok{    """}
    \ControlFlowTok{if}\NormalTok{ ArgDown }\OperatorTok{==} \VariableTok{True}\NormalTok{:}
        \CommentTok{\# For ArgDown, exclude probability columns}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.DataFrame(columns}\OperatorTok{=}\NormalTok{[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{,}
                               \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{])}
    \ControlFlowTok{else}\NormalTok{:}
        \CommentTok{\# For BayesDown, include probability columns}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.DataFrame(columns}\OperatorTok{=}\NormalTok{[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{,}
                               \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{,}
                               \StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{])}

    \ControlFlowTok{for}\NormalTok{ title, info }\KeywordTok{in}\NormalTok{ titles\_info.items():}
        \CommentTok{\# Parse the metadata JSON string into a Python dictionary}
        \ControlFlowTok{if} \StringTok{\textquotesingle{}metadata\textquotesingle{}} \KeywordTok{in}\NormalTok{ info }\KeywordTok{and}\NormalTok{ info[}\StringTok{\textquotesingle{}metadata\textquotesingle{}}\NormalTok{]:}
            \ControlFlowTok{try}\NormalTok{:}
                \CommentTok{\# Only try to parse if metadata is not empty}
                \ControlFlowTok{if}\NormalTok{ info[}\StringTok{\textquotesingle{}metadata\textquotesingle{}}\NormalTok{].strip():}
\NormalTok{                    jsonMetadata }\OperatorTok{=}\NormalTok{ json.loads(info[}\StringTok{\textquotesingle{}metadata\textquotesingle{}}\NormalTok{])}
                    \ControlFlowTok{if}\NormalTok{ ArgDown }\OperatorTok{==} \VariableTok{True}\NormalTok{:}
                        \CommentTok{\# Create the row dictionary with instantiations as}
                        \CommentTok{\# metadata only, no probabilities yet}
\NormalTok{                        row }\OperatorTok{=}\NormalTok{ \{}
                            \StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{: title,}
                            \StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                            \StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                            \StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{, []),}
                            \StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                            \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{, []),}
                            \StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{, []),}
                            \StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{, []),}
                            \CommentTok{\# Extract specific metadata fields,}
                            \CommentTok{\# defaulting to empty if not present}
                            \StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{: jsonMetadata.get(}\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{, []),}
\NormalTok{                        \}}
                    \ControlFlowTok{else}\NormalTok{:}
                        \CommentTok{\# Create dict with probabilities for BayesDown}
\NormalTok{                        row }\OperatorTok{=}\NormalTok{ \{}
                            \StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{: title,}
                            \StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                            \StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                            \StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{, []),}
                            \StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                            \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{, []),}
                            \StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{, []),}
                            \StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{, []),}
                            \CommentTok{\# Extract specific metadata fields, defaulting to empty if not present}
                            \StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{: jsonMetadata.get(}\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{, []),}
                            \StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{: jsonMetadata.get(}\StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{, \{\}),}
                            \StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{: jsonMetadata.get(}\StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{, \{\})}
\NormalTok{                        \}}
                \ControlFlowTok{else}\NormalTok{:}
                    \CommentTok{\# Empty metadata case}
\NormalTok{                    row }\OperatorTok{=}\NormalTok{ \{}
                        \StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{: title,}
                        \StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                        \StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                        \StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{, []),}
                        \StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                        \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{, []),}
                        \StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{, []),}
                        \StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{, []),}
                        \StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{: [],}
                        \StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{: \{\},}
                        \StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{: \{\}}
\NormalTok{                    \}}
            \ControlFlowTok{except}\NormalTok{ json.JSONDecodeError:}
                \CommentTok{\# Handle case where metadata isn\textquotesingle{}t valid JSON}
\NormalTok{                row }\OperatorTok{=}\NormalTok{ \{}
                    \StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{: title,}
                    \StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                    \StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                    \StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{, []),}
                    \StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                    \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{, []),}
                    \StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{, []),}
                    \StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{, []),}
                    \StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{: [],}
                    \StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{: \{\},}
                    \StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{: \{\}}
\NormalTok{                \}}
        \ControlFlowTok{else}\NormalTok{:}
            \CommentTok{\# Handle case where metadata field doesn\textquotesingle{}t exist or is empty}
\NormalTok{            row }\OperatorTok{=}\NormalTok{ \{}
                \StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{: title,}
                \StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                \StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                \StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}line\_numbers\textquotesingle{}}\NormalTok{, []),}
                \StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
                \StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}indentation\_levels\textquotesingle{}}\NormalTok{, []),}
                \StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}parents\textquotesingle{}}\NormalTok{, []),}
                \StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{: info.get(}\StringTok{\textquotesingle{}children\textquotesingle{}}\NormalTok{, []),}
                \StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{: [],}
                \StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{: \{\},}
                \StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{: \{\}}
\NormalTok{            \}}

        \CommentTok{\# Add the row to the DataFrame}
\NormalTok{        df.loc[}\BuiltInTok{len}\NormalTok{(df)] }\OperatorTok{=}\NormalTok{ row}

    \ControlFlowTok{return}\NormalTok{ df}

\KeywordTok{def}\NormalTok{ add\_no\_parent\_no\_child\_columns\_to\_df(dataframe):}
    \CommentTok{"""}
\CommentTok{    Add No\_Parent and No\_Children boolean columns to the DataFrame to}
\CommentTok{    identify root and leaf nodes.}

\CommentTok{    Args:}
\CommentTok{        dataframe (pandas.DataFrame): The DataFrame to enhance}

\CommentTok{    Returns:}
\CommentTok{        pandas.DataFrame: Enhanced DataFrame with additional boolean columns}
\CommentTok{    """}
\NormalTok{    no\_parent }\OperatorTok{=}\NormalTok{ []}
\NormalTok{    no\_children }\OperatorTok{=}\NormalTok{ []}

    \ControlFlowTok{for}\NormalTok{ \_, row }\KeywordTok{in}\NormalTok{ dataframe.iterrows():}
\NormalTok{        no\_parent.append(}\KeywordTok{not}\NormalTok{ row[}\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{])  }\CommentTok{\# True if Parents list is empty}
\NormalTok{        no\_children.append(}\KeywordTok{not}\NormalTok{ row[}\StringTok{\textquotesingle{}Children\textquotesingle{}}\NormalTok{])  }\CommentTok{\# True if Children list is empty}

\NormalTok{    dataframe[}\StringTok{\textquotesingle{}No\_Parent\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ no\_parent}
\NormalTok{    dataframe[}\StringTok{\textquotesingle{}No\_Children\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ no\_children}

    \ControlFlowTok{return}\NormalTok{ dataframe}

\KeywordTok{def}\NormalTok{ add\_parents\_instantiation\_columns\_to\_df(dataframe):}
    \CommentTok{"""}
\CommentTok{    Add all possible instantiations of parents as a list of lists column}
\CommentTok{    to the DataFrame.}
\CommentTok{    This is crucial for generating conditional probability tables.}

\CommentTok{    Args:}
\CommentTok{        dataframe (pandas.DataFrame): The DataFrame to enhance}

\CommentTok{    Returns:}
\CommentTok{        pandas.DataFrame: Enhanced DataFrame with parent\_instantiations column}
\CommentTok{    """}
    \CommentTok{\# Create a new column to store parent instantiations}
\NormalTok{    parent\_instantiations }\OperatorTok{=}\NormalTok{ []}

    \CommentTok{\# Iterate through each row in the dataframe}
    \ControlFlowTok{for}\NormalTok{ \_, row }\KeywordTok{in}\NormalTok{ dataframe.iterrows():}
\NormalTok{        parents }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Parents\textquotesingle{}}\NormalTok{]}
\NormalTok{        parent\_insts }\OperatorTok{=}\NormalTok{ []}

        \CommentTok{\# For each parent, find its instantiations and add to the list}
        \ControlFlowTok{for}\NormalTok{ parent }\KeywordTok{in}\NormalTok{ parents:}
            \CommentTok{\# Find the row where Title matches the parent}
\NormalTok{            parent\_row }\OperatorTok{=}\NormalTok{ dataframe[dataframe[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{] }\OperatorTok{==}\NormalTok{ parent]}

            \CommentTok{\# If parent found in the dataframe}
            \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ parent\_row.empty:}
                \CommentTok{\# Get the instantiations of this parent}
\NormalTok{                parent\_instantiation }\OperatorTok{=}\NormalTok{ parent\_row[}\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{].iloc[}\DecValTok{0}\NormalTok{]}
\NormalTok{                parent\_insts.append(parent\_instantiation)}

        \CommentTok{\# Add the list of parent instantiations to our new column}
\NormalTok{        parent\_instantiations.append(parent\_insts)}

    \CommentTok{\# Add the new column to the dataframe}
\NormalTok{    dataframe[}\StringTok{\textquotesingle{}parent\_instantiations\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ parent\_instantiations}

    \ControlFlowTok{return}\NormalTok{ dataframe}
\end{Highlighting}
\end{Shaded}

This representation captures the complex causal structure of Carlsmith's
argument, with 21 variables organized in a multi-level hierarchy. The
``Misaligned\_Power\_Seeking'' node appears multiple times, reflecting
its role as a central concept that influences several other variables.

\subsection*{3.5.3 From ArgDown to BayesDown in Carlsmith's
Model}\label{from-argdown-to-bayesdown-in-carlsmiths-model}
\addcontentsline{toc}{subsection}{3.5.3 From ArgDown to BayesDown in
Carlsmith's Model}

After processing this structure with the AMTAIR system, probability
information had to be added to create a complete BayesDown
representation. The following excerpt shows the probability information
for a single node (``Deployment\_Decisions''):

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{[}\ErrorTok{Deployment\_Decisions}\OtherTok{]}\ErrorTok{:} \ErrorTok{Decisions} \ErrorTok{to} \ErrorTok{deploy} \ErrorTok{potentially} \ErrorTok{misaligned} \ErrorTok{AI} \ErrorTok{systems.} \FunctionTok{\{}
  \DataTypeTok{"instantiations"}\FunctionTok{:} \OtherTok{[}\StringTok{"deployment\_decisions\_DEPLOY"}\OtherTok{,} \StringTok{"deployment\_decisions\_WITHHOLD"}\OtherTok{]}\FunctionTok{,}
  \DataTypeTok{"priors"}\FunctionTok{:} \FunctionTok{\{}
    \DataTypeTok{"p(deployment\_decisions\_DEPLOY)"}\FunctionTok{:} \StringTok{"0.70"}\FunctionTok{,}
    \DataTypeTok{"p(deployment\_decisions\_WITHHOLD)"}\FunctionTok{:} \StringTok{"0.30"}
  \FunctionTok{\},}
  \DataTypeTok{"posteriors"}\FunctionTok{:} \FunctionTok{\{}
    \DataTypeTok{"p(deployment\_decisions\_DEPLOY|incentives\_to\_build\_aps\_STRONG, deception\_by\_ai\_TRUE)"}\FunctionTok{:} \StringTok{"0.90"}\FunctionTok{,}
    \DataTypeTok{"p(deployment\_decisions\_DEPLOY|incentives\_to\_build\_aps\_STRONG, deception\_by\_ai\_FALSE)"}\FunctionTok{:} \StringTok{"0.75"}\FunctionTok{,}
    \DataTypeTok{"p(deployment\_decisions\_DEPLOY|incentives\_to\_build\_aps\_WEAK, deception\_by\_ai\_TRUE)"}\FunctionTok{:} \StringTok{"0.60"}\FunctionTok{,}
    \DataTypeTok{"p(deployment\_decisions\_DEPLOY|incentives\_to\_build\_aps\_WEAK, deception\_by\_ai\_FALSE)"}\FunctionTok{:} \StringTok{"0.30"}
  \FunctionTok{\}}
\FunctionTok{\}}
\end{Highlighting}
\end{Shaded}

This node has two possible states (DEPLOY or WITHHOLD), prior
probabilities for each state, and conditional probabilities based on
different combinations of its parent variables
(``Incentives\_To\_Build\_APS'' and ``Deception\_By\_AI'').

\phantomsection\label{generate_bayesdown}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Generate BayesDown format}
\NormalTok{bayesdown\_questions }\OperatorTok{=}\NormalTok{ extract\_bayesdown\_questions\_fixed(}
    \StringTok{"ArgDown\_WithQuestions.csv"}\NormalTok{,}
    \StringTok{"FULL\_BayesDownQuestions.md"}\NormalTok{,}
\NormalTok{    include\_questions\_as\_comments}\OperatorTok{=}\VariableTok{True}
\NormalTok{)}

\CommentTok{\# Display a preview of the format}
\BuiltInTok{print}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{BayesDown Format Preview:"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(bayesdown\_questions[:}\DecValTok{5000}\NormalTok{] }\OperatorTok{+} \StringTok{"...}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Loading CSV from ArgDown_WithQuestions.csv...
Successfully loaded CSV with 23 rows.
Generating BayesDown syntax with placeholder probabilities...
BayesDown Questions saved to FULL_BayesDownQuestions.md

BayesDown Format Preview:
# BayesDown Representation with Placeholder Probabilities

/* This file contains BayesDown syntax with placeholder probabilities.
   Replace the placeholders with actual probability values based on the 
   questions in the comments. */

/* What is the probability for Existential_Catastrophe=existential_catastrophe_TRUE? */
/* What is the probability for Existential_Catastrophe=existential_catastrophe_FALSE? */
[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {"instantiations": ["existential_catastrophe_TRUE", "existential_catastrophe_FALSE"], "priors": {"What is the probability for Existential_Catastrophe=existential_catastrophe_TRUE?": "%?", "What is the probability for Existential_Catastrophe=existential_catastrophe_FALSE?": "%?"}}
/* What is the probability for Human_Disempowerment=human_disempowerment_TRUE? */
/* What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE? */
/* What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE? */
/* What is the probability for Human_Disempowerment=human_disempowerment_FALSE? */
/* What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE? */
/* What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE? */
[Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {"instantiations": ["human_disempowerment_TRUE", "human_disempowerment_FALSE"], "priors": {"What is the probability for Human_Disempowerment=human_disempowerment_TRUE?": "%?", "What is the probability for Human_Disempowerment=human_disempowerment_FALSE?": "%?"}, "posteriors": {"What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?": "?%", "What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?": "?%", "What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?": "?%", "What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?": "?%"}}
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */
  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */
  + [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {"instantiations": ["scale_of_power_seeking_TRUE", "scale_of_power_seeking_FALSE"], "priors": {"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?": "%?", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?": "%?"}, "posteriors": {"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE?": "?%", "What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?": "?%"}}
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */
    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */
    + [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"], "priors": {"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE?": "%?", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE?": "%?"}, "posteriors": {"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?": "?%", "What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?": "?%"}}
      /* What is the probability for APS_Systems=aps_systems_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */
      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */
      + [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {"instantiations": ["aps_systems_TRUE", "aps_systems_FALSE"], "priors": {"What is the probability for APS_Systems=aps_systems_TRUE?": "%?", "What is the probability for APS_Systems=aps_systems_FALSE?": "%?"}, "posteriors": {"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?": "?%", "What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?": "?%"}}
        /* What is the probability for Advanced_AI_Capability=advanced_ai_capability_TRUE? */
        /* What is the probability for Advanced_AI_Capability=advanced_ai_capability_FALSE? */
        + [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {"instantiations": ["advanced_ai_capability_TRUE", "advanced_ai_capability_FALSE"], "priors": {"What is the probability for Advanced_AI_Capability=advanced_ai_capability_TRUE?": "%?", "What is the probability for Advanced_AI_Capability=advanced_ai_capability_FALSE?": "%?"}}
        /* What is the probability for Agentic_Planning=agentic_planning_TRUE? */
        /* What is the probability for Agentic_Planning=agentic_planning_FALSE? */
        + [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {"instantiations": ["agentic_planning_TRUE", "agentic_planning_FALSE"], "priors": {"What is the probability for Agentic_Planning=agentic_planning_TRUE?": "%?", "What is the probability for Agentic_Planning=agentic_planning_FALSE?": "%?"}}
        /* What is the probability for Strategic_Awareness=strategic_awareness_TRUE? */
        /* What is the probability for Strategic_Awareness=strategic_awareness_FALSE? */
        + [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {"instantiations": ["strategic_awareness_TRUE", "strategic_awareness_FALSE"], "priors": {"What is the probability for Strategic_Awareness=strategic_awareness_TRUE?": "%?", "What is the probability for Strategic_Awareness=strategic_awareness_FALSE?": "%?"}}
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */
      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */
      + [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {"instantiations": ["difficulty_of_alignment_TRUE", "difficulty_of_alignment_FALSE"], "priors": {"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE?": "%?", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE?": "%?"}, "posteriors": {"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?": "?%", "What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?": "?%"}}
        /* What is the probability for Instrumental_Convergence=instrumental_convergence_TRUE? */
        /* What is the probability for Instrumental_Convergence=instrumental_convergence_FALSE? */
        + [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {"instantiations": ["instrumental_convergence_TRUE", "instrumental_convergence_FALSE"], "priors": {"What is the probability for Instrumental_Convergence=instrumental_convergence_TRUE?": "%?", "What is the probability for Instrumental_Convergence=instrumental_convergence_FALSE?": "%?"}}
        /* What is the probability for Problems_With_Proxies=problems_with_proxies_TRUE? */
        /* What is the probability for Problems_With_Proxies=problems_with_proxies_FALSE? */
        + [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {"instantiations": ["problems_with_proxies_TRUE", "problems_with_proxies_FALSE"], "priors": {"What is the probability for Problems_With_Proxies=problems_with_proxies_TRUE?": "%?", "What is the probability for Problems_With_Proxies=problems_with_proxies_FALSE?": "%?"}}
        /* What is the probability for Problems_With_Search=problems_with_search_TRUE? */
        /* What is the probability for Problems_With_Search=problems_with_search_FALSE? */
        + [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {"instantiations": ["problems_with_search_TRUE", "problems_with_search_FALSE"], "priors": {"What is the probability for Problems_With_Search=problems_with_search_TRUE?": "%?", "What is the probability for Problems_With_Search=problems_with_search_FALSE?": "%?"}}
      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE? */
      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE? */
      + [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {"instantiations": ["deployment_decisions_DEPLOY", "deployment_decisions_WITHHOLD"], "priors": {"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY?": "%?", "What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD?": "%?"}, "posteriors": {"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE?": "?%", "What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE?": "?%"}}
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG? */
        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK? */
        + [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {"instantiations": ["incentives_to_build_aps_STRONG", "incentives_to_build_aps_WEAK"], "priors": {"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG?": "%?", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK?": "%?"}, "posteriors": {"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG?": "?%", "What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK?": "?%"}}
          /* What is the probability for Usefulness_Of_APS=usefulness_of_aps_HIGH? */
          /* What is the probability for Usefulness_Of_APS=usefulness_of_aps_LOW? */
          + [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {"instantiations": ["usefulness_of_aps_HIGH", "usefulness_of_aps_LOW"], "priors": {"What is the probability for Usefulness_Of_APS=usefulness_of_aps_HIGH?": "%?", "What is the probability for Usefulness_Of_APS=usefulness_of_aps_LOW?": "%?"}}
          /* What is the probability for Competitive_Dynamics=competitive_dynamics_STRONG? */
          /* What is the probability for Competitive_Dynamics=competitive_dynamics_WEAK? */
          + [Competitive_Dynamics]: Competitive pressures between AI developers. {"instantiations": ["competitive_dynamics_STRONG", "competitive_dynamics_WEAK"], "priors": {"What is the probability for Competitive_Dynamics=competitive_dynamics_STRONG?": "%?", "What is the probability for Competitive_Dynamics=competitive_dynamics_WEAK?": "%?"}}
        /* What is the probability for Deception_By_AI=deception_by_ai_TRUE? */
        /* What is the probability for Deception_By_AI=deception_by_ai_FALSE? */
        + [Deception_By_AI]: AI systems deceiving humans about their true objectives. {"instantiations": ["deception_by_ai_TRUE", "deception_by_ai_FALSE"], "priors": {"What is the probability for Deception_By_AI=deception_by_ai_TRUE?": "%?", "What is the probability for Deception_By_AI=deception_by_ai_FALSE?": "%?"}}
    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */
    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */
    + [Corrective_Feedback]: Human society implementing corrections after observing problems. {"instantiations": ["corrective_feedback_EFFECTIVE", "corrective_feedback_INEFFECTIVE"], "priors": {"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE?": "%?", "What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE?": "%?"}, "posteriors": {"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?": "?%", "What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?": "?%"}}
      /* What is the probability for Warning_Shots=warning_shots_OBSERVED? */
      /* What is the probability for Warning_Shots=warning_shots_UNOBSERVED? */
      + [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {"instantiations": ["warning_shots_OBSERVED", "warning_shots_UNOBSERVED"], "priors": {"What is the probability for Warning_Shots=warning_shots_OBSERVED?": "%?", "What is the probability for Warning_Shots=warning_shots_UNOBSERVED?": "%?"}}
      /* What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */
      /* What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */
      + [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {"instantiations": ["rapid_capability_escalation_TRUE", "rapid_capability_escalation_FALSE"], "priors": {"What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?": "%?", "What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?": "%?"}}
/* What is the probability for Barriers_To_Understanding=barriers_to_understanding_HIGH? */
/* What is the probability for Barriers_To_Understanding=barriers_to_understanding_LOW? */
[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {"instantiations": ["barriers_to_understanding_HIGH", "barriers_to_understanding_LOW"], "priors": {"What is the probability for Barriers_To_Understanding=barriers_to_understanding_HIGH?": "%?", "What is the probability for Barriers_To_Understanding=barriers_to_understanding_LOW?": "%?"}}
/* What is the probability for Adversarial_Dynamics=adversarial_dynamics_TRUE? */
/* What is the probability for Adversarial_Dynamics=adversarial_dynamics_FALSE? */
[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {"instantiations": ["adversarial_dynamics_TRUE", "adversarial_dynamics_FALSE"], "priors": {"What is the probability for Adversarial_Dynamics=adversarial_dynamics_TRUE?": "%?", "What is the probability for Adversarial_Dynamics=adversarial_dynamics_FALSE?": "%?"}}
/* What is the probability for Stakes_Of_Error=stakes_of_error_HIGH? */
/* What is the probability for Stakes_Of_Error=stakes_of_error_LOW? */
[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {"instantiations": ["stakes_of_error_HIGH", "stakes_of_error_LOW"], "priors": {"What is the probability for Stakes_Of_Error=stakes_of_error_HIGH?": "%?", "What is the probability for Stakes_Of_Error=stakes_of_error_LOW?": "%?"}}
...
\end{verbatim}

Along with these questions the following prompt is sent to the LLM:

\begin{Shaded}
\begin{Highlighting}[]

\ErrorTok{You} \ErrorTok{are} \ErrorTok{an} \ErrorTok{expert} \ErrorTok{in} \ErrorTok{probabilistic} \ErrorTok{reasoning} \ErrorTok{and} \ErrorTok{Bayesian} \ErrorTok{networks.} \ErrorTok{Your} \ErrorTok{task} \ErrorTok{is}
\ErrorTok{to} \ErrorTok{extend} \ErrorTok{the} \ErrorTok{provided} \ErrorTok{ArgDown} \ErrorTok{structure} \ErrorTok{with} \ErrorTok{probability} \ErrorTok{information,}
\ErrorTok{creating} \ErrorTok{a} \ErrorTok{BayesDown} \ErrorTok{representation.}

\ErrorTok{For} \ErrorTok{each} \ErrorTok{statement} \ErrorTok{in} \ErrorTok{the} \ErrorTok{ArgDown} \ErrorTok{structure,} \ErrorTok{you} \ErrorTok{need} \ErrorTok{to:}
\ErrorTok{1.} \ErrorTok{Estimate} \ErrorTok{prior} \ErrorTok{probabilities} \ErrorTok{for} \ErrorTok{each} \ErrorTok{possible} \ErrorTok{state}
\ErrorTok{2.} \ErrorTok{Estimate} \ErrorTok{conditional} \ErrorTok{probabilities} \ErrorTok{given} \ErrorTok{parent} \ErrorTok{states}
\ErrorTok{3.} \ErrorTok{Maintain} \ErrorTok{the} \ErrorTok{original} \ErrorTok{structure} \ErrorTok{and} \ErrorTok{relationships}

\ErrorTok{Here} \ErrorTok{is} \ErrorTok{the} \ErrorTok{format} \ErrorTok{to} \ErrorTok{follow:}
\OtherTok{[}\ErrorTok{Node}\OtherTok{]}\ErrorTok{:} \ErrorTok{Description.} \FunctionTok{\{} \DataTypeTok{"instantiations"}\FunctionTok{:} \OtherTok{[}\StringTok{"node\_TRUE"}\OtherTok{,} \StringTok{"node\_FALSE"}\OtherTok{]}\FunctionTok{,} \DataTypeTok{"priors"}\FunctionTok{:} \FunctionTok{\{} \DataTypeTok{"p(node\_TRUE)"}\FunctionTok{:} \StringTok{"0.7"}\FunctionTok{,} \DataTypeTok{"p(node\_FALSE)"}\FunctionTok{:} \StringTok{"0.3"} \FunctionTok{\},} \DataTypeTok{"posteriors"}\FunctionTok{:} \FunctionTok{\{} \DataTypeTok{"p(node\_TRUE|parent\_TRUE)"}\FunctionTok{:} \StringTok{"0.9"}\FunctionTok{,} \DataTypeTok{"p(node\_TRUE|parent\_FALSE)"}\FunctionTok{:} \StringTok{"0.4"}\FunctionTok{,} \DataTypeTok{"p(node\_FALSE|parent\_TRUE)"}\FunctionTok{:} \StringTok{"0.1"}\FunctionTok{,} \DataTypeTok{"p(node\_FALSE|parent\_FALSE)"}\FunctionTok{:} \StringTok{"0.6"} \FunctionTok{\}} \FunctionTok{\}}
 \OtherTok{[}\ErrorTok{Parent}\OtherTok{]}\ErrorTok{:} \ErrorTok{Parent} \ErrorTok{description.} \FunctionTok{\{}\ErrorTok{...}\FunctionTok{\}}


\ErrorTok{Here} \ErrorTok{are} \ErrorTok{the} \ErrorTok{specific} \ErrorTok{probability} \ErrorTok{questions} \ErrorTok{to} \ErrorTok{answer:}
\ErrorTok{$questions}

\ErrorTok{ArgDown} \ErrorTok{structure} \ErrorTok{to} \ErrorTok{enhance:}
\ErrorTok{$argdown}

\ErrorTok{Provide} \ErrorTok{the} \ErrorTok{complete} \ErrorTok{BayesDown} \ErrorTok{representation} \ErrorTok{with} \ErrorTok{probabilities:}
\end{Highlighting}
\end{Shaded}

\subsection*{3.5.4 Practically Meaningful
BayesDown}\label{practically-meaningful-bayesdown}
\addcontentsline{toc}{subsection}{3.5.4 Practically Meaningful
BayesDown}

Bridging Qualitative and Quantitative Representation

If the coordination crisis in AI governance stems partly from
incompatible languages across domains---technical researchers speaking
in mathematical formalisms, policy specialists in institutional
frameworks, and ethicists in normative concepts---then effective
coordination requires bridges between these domains. BayesDown serves as
such a bridge, combining the narrative richness of qualitative
argumentation with the precision of quantitative probability judgments.

Traditional formal representations face a fundamental tradeoff: increase
precision and you sacrifice accessibility; enhance accessibility and you
lose precision. Mathematical notations offer exactness but exclude many
stakeholders. Natural language provides accessibility but permits
ambiguity and vagueness. This tradeoff creates communication barriers
between technical and policy domains, limiting coordination on complex
challenges like AI governance.

BayesDown disrupts this tradeoff by creating a hybrid representation
that preserves strengths from both worlds. Its design follows three key
principles:

First, \textbf{human readability} ensures the representation remains
interpretable without specialized training. The syntax builds on
familiar conventions from markdown and JSON, maintaining hierarchical
relationships through indentation and encapsulating technical details
within structured metadata. Unlike purely mathematical notations, the
format preserves natural language descriptions alongside formal
elements.

Second, \textbf{machine processability} enables computational analysis
and transformation. The consistent syntax permits automated parsing,
formal verification, and conversion to computational models like
Bayesian networks. The structured JSON metadata provides clear paths for
extracting probability information and mapping it to conditional
probability tables.

Third, \textbf{contextual preservation} maintains the connection to
original arguments. By including descriptive text alongside formal
structure, BayesDown retains the narrative context and qualitative
considerations that inform probability judgments. This contextual
information helps users interpret the model in light of the original
arguments.

Consider how these principles manifest in the BayesDown syntax. Each
node begins with a bracketed title followed by a natural language
description, preserving the core statement being formalized. The JSON
metadata contains technical information like instantiations, priors, and
posteriors, but keeps this information clearly separated from the
narrative content. Hierarchical relationships use indentation and plus
symbols, creating a visual structure that mirrors causal influence.

\subsubsection*{Example BayesDown Excerpt from the Carlsmith
model}\label{example-bayesdown-excerpt-from-the-carlsmith-model}
\addcontentsline{toc}{subsubsection}{Example BayesDown Excerpt from the
Carlsmith model}

\begin{Shaded}
\begin{Highlighting}[]
\ErrorTok{\#|} \ErrorTok{label:} \ErrorTok{json\_carlsmith\_excerpt}
\ErrorTok{\#|} \ErrorTok{echo:} \ErrorTok{true}
\ErrorTok{\#|} \ErrorTok{eval:} \ErrorTok{true}
\ErrorTok{\#|} \ErrorTok{fig{-}cap:} \ErrorTok{"Example} \ErrorTok{BayesDown} \ErrorTok{Excerpt} \ErrorTok{from} \ErrorTok{the} \ErrorTok{Carlsmith} \ErrorTok{model"}
\ErrorTok{\#|} \ErrorTok{fig{-}link:} \ErrorTok{"https://colab.research.google.com/github/VJMeyer/submission/blob/main/AMTAIR\_Prototype/data/example\_carlsmith/AMTAIR\_Prototype\_example\_carlsmith.ipynb\#scrollTo=AFnu\_1Ludahi"}
\ErrorTok{\#|} \ErrorTok{fig{-}alt:} \ErrorTok{"Example} \ErrorTok{BayesDown} \ErrorTok{Excerpt} \ErrorTok{from} \ErrorTok{the} \ErrorTok{Carlsmith} \ErrorTok{model"}



\OtherTok{[}\ErrorTok{Existential\_Catastrophe}\OtherTok{]}\ErrorTok{:} \ErrorTok{The} \ErrorTok{destruction} \ErrorTok{of} \ErrorTok{humanity\textquotesingle{}s} \ErrorTok{long{-}term} \ErrorTok{potential} \ErrorTok{due} \ErrorTok{to} \ErrorTok{AI} \ErrorTok{systems} \ErrorTok{we\textquotesingle{}ve} \ErrorTok{lost} \ErrorTok{control} \ErrorTok{over.} \FunctionTok{\{}
  \DataTypeTok{"instantiations"}\FunctionTok{:} \OtherTok{[}\StringTok{"existential\_catastrophe\_TRUE"}\OtherTok{,} \StringTok{"existential\_catastrophe\_FALSE"}\OtherTok{]}\FunctionTok{,}
  \DataTypeTok{"priors"}\FunctionTok{:} \FunctionTok{\{}\DataTypeTok{"p(existential\_catastrophe\_TRUE)"}\FunctionTok{:} \StringTok{"0.05"}\FunctionTok{,} \DataTypeTok{"p(existential\_catastrophe\_FALSE)"}\FunctionTok{:} \StringTok{"0.95"}\FunctionTok{\},}
  \DataTypeTok{"posteriors"}\FunctionTok{:} \FunctionTok{\{}
    \DataTypeTok{"p(existential\_catastrophe\_TRUE|human\_disempowerment\_TRUE)"}\FunctionTok{:} \StringTok{"0.95"}\FunctionTok{,}
    \DataTypeTok{"p(existential\_catastrophe\_TRUE|human\_disempowerment\_FALSE)"}\FunctionTok{:} \StringTok{"0.0"}
  \FunctionTok{\}}
\FunctionTok{\}}
 \ErrorTok{+} \OtherTok{[}\ErrorTok{Human\_Disempowerment}\OtherTok{]}\ErrorTok{:} \ErrorTok{Permanent} \ErrorTok{and} \ErrorTok{collective} \ErrorTok{disempowerment} \ErrorTok{of} \ErrorTok{humanity} \ErrorTok{relative} \ErrorTok{to} \ErrorTok{AI} \ErrorTok{systems.} \FunctionTok{\{}
   \DataTypeTok{"instantiations"}\FunctionTok{:} \OtherTok{[}\StringTok{"human\_disempowerment\_TRUE"}\OtherTok{,} \StringTok{"human\_disempowerment\_FALSE"}\OtherTok{]}\FunctionTok{,}
   \DataTypeTok{"priors"}\FunctionTok{:} \FunctionTok{\{}\DataTypeTok{"p(human\_disempowerment\_TRUE)"}\FunctionTok{:} \StringTok{"0.208"}\FunctionTok{,} \DataTypeTok{"p(human\_disempowerment\_FALSE)"}\FunctionTok{:} \StringTok{"0.792"}\FunctionTok{\},}
   \DataTypeTok{"posteriors"}\FunctionTok{:} \FunctionTok{\{}
     \DataTypeTok{"p(human\_disempowerment\_TRUE|scale\_of\_power\_seeking\_TRUE)"}\FunctionTok{:} \StringTok{"1.0"}\FunctionTok{,}
     \DataTypeTok{"p(human\_disempowerment\_TRUE|scale\_of\_power\_seeking\_FALSE)"}\FunctionTok{:} \StringTok{"0.0"}
   \FunctionTok{\}}
 \FunctionTok{\}}
\end{Highlighting}
\end{Shaded}

This excerpt from the Carlsmith model representation illustrates how
BayesDown preserves both the narrative description (``The destruction of
humanity's long-term potential\ldots{}'') and the precise probability
judgments. Someone without technical background can still understand the
core claims and their relationships, while someone seeking quantitative
precision can find exact probability values.

The format supports multiple levels of engagement. At the most basic
level, readers can follow the hierarchical structure to understand
causal relationships between factors. At an intermediate level, they can
examine probability judgments to assess the strength of different
influences. At the most technical level, they can analyze the complete
probabilistic model to perform inference and sensitivity analysis.

This multi-level accessibility creates important advantages for
coordination across domains:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Technical-policy translation:} BayesDown provides a common
  reference point for technical researchers explaining safety concerns
  and policy specialists evaluating governance options, reducing
  communication barriers.
\item
  \textbf{Argumentation transparency:} The format makes assumptions
  explicit, helping identify genuine disagreements versus terminological
  confusion or unstated premises.
\item
  \textbf{Incremental formalization:} BayesDown supports varying levels
  of formality, from qualitative structure to complete probability
  specifications, allowing gradual progression from informal to formal
  representations.
\item
  \textbf{Verification flexibility:} Human experts can verify extracted
  representations at different levels---checking structural correctness
  without assessing probabilities, or focusing on critical probability
  judgments without reviewing the entire model.
\end{enumerate}

The hybrid nature of BayesDown aligns with how experts typically
communicate complex ideas: combining qualitative explanations with
quantitative judgments, using natural language to provide context for
formal claims, and adjusting precision based on audience needs. By
mirroring these natural communication patterns, BayesDown makes
formalization more intuitive and accessible.

This bridging function extends beyond representation to influence the
entire extraction and analysis workflow. When extracting from text, the
two-stage process preserves narrative context alongside formal
structure. When visualizing models, interactive interfaces provide both
qualitative descriptions and quantitative details. When evaluating
policies, counterfactual analysis incorporates both mathematical
precision and contextual interpretation.

In the broader context of the coordination crisis, BayesDown
demonstrates how thoughtfully designed intermediate representations can
overcome communication barriers between domains. Rather than forcing all
stakeholders to adopt a single specialized language, it creates a
flexible format that accommodates different perspectives while enabling
precise analysis---precisely the kind of bridge needed for effective
coordination on complex governance challenges.

\subsection*{3.5.5 Interactive Visualization and
Exploration}\label{interactive-visualization-and-exploration}
\addcontentsline{toc}{subsection}{3.5.5 Interactive Visualization and
Exploration}

Complex probabilistic models like Bayesian networks contain rich
information, but they often remain inaccessible to many stakeholders. A
conditional probability table with dozens of values conveys precise
relationships, but few can intuitively grasp its implications. This
accessibility gap limits the potential for coordinated action on AI
governance challenges---what good is formalization if the resulting
models remain opaque to most decision-makers?

AMTAIR addresses this challenge through interactive visualization
designed to make complex probabilistic relationships accessible to
diverse stakeholders. The approach combines visual encoding of
probability information, progressive disclosure of details, and
interactive exploration capabilities to create intuitive interfaces for
complex models.

The visualization system follows several key design principles:

First, \textbf{visual encoding of probability} uses color gradients to
represent likelihood values. Nodes are colored on a spectrum from red
(low probability) to green (high probability) based on their primary
state's probability. This simple visual cue provides immediate insights
into which outcomes are more or less likely without requiring numerical
interpretation.

Second, \textbf{structural classification} uses border colors to
indicate node types based on network position. Blue borders designate
root causes (nodes without parents), purple borders mark intermediate
nodes (with both parents and children), and magenta borders highlight
leaf nodes (final effects without children). This classification helps
users understand the causal flow through the network.

Third, \textbf{progressive disclosure} presents information in layers of
increasing detail. Basic node information appears in the visualization
itself, additional details emerge in tooltips on hover, and
comprehensive probability tables display in modal windows on click. This
layered approach prevents information overload while ensuring all
details remain accessible.

Fourth, \textbf{interactive exploration} allows users to reorganize
nodes, zoom in on areas of interest, adjust physics parameters, and
investigate probability values. These capabilities transform the
visualization from a static image into an explorable knowledge
landscape.

The complete BayesDown representation was processed through the AMTAIR
pipeline, resulting in a structured DataFrame and ultimately a Bayesian
network.

The figure below shows the interactive visualization of Carlsmith's
model, highlighting how color, border styling, and layout work together
to represent complex causal relationships:

The visualization system implements these principles through a
combination of NetworkX for graph representation and PyVis for
interactive display, with custom HTML generation for tooltips and
modals:

The resulting visualization (Figure 10) shows the complete Carlsmith
model with color-coded nodes representing probability values:

{[}FIGURE 10: Interactive visualization of Carlsmith's model showing
color-coded nodes and relationships{]}

\phantomsection\label{main_visualization_function}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 4.4.0 {-}{-}{-} Main Visualization Function {-}{-}{-} [main\_visualization\_function]}

\KeywordTok{def}\NormalTok{ create\_bayesian\_network\_with\_probabilities(df):}
    \CommentTok{"""}
\CommentTok{    Create an interactive Bayesian network visualization with enhanced}
\CommentTok{    probability visualization and node classification based on network structure.}
\CommentTok{    """}
    \CommentTok{\# Create a directed graph}
\NormalTok{    G }\OperatorTok{=}\NormalTok{ nx.DiGraph()}

    \CommentTok{\# Add nodes with proper attributes}
    \ControlFlowTok{for}\NormalTok{ idx, row }\KeywordTok{in}\NormalTok{ df.iterrows():}
\NormalTok{        title }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{]}
\NormalTok{        description }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Description\textquotesingle{}}\NormalTok{]}

        \CommentTok{\# Process probability information}
\NormalTok{        priors }\OperatorTok{=}\NormalTok{ get\_priors(row)}
\NormalTok{        instantiations }\OperatorTok{=}\NormalTok{ get\_instantiations(row)}

        \CommentTok{\# Add node with base information}
\NormalTok{        G.add\_node(}
\NormalTok{            title,}
\NormalTok{            description}\OperatorTok{=}\NormalTok{description,}
\NormalTok{            priors}\OperatorTok{=}\NormalTok{priors,}
\NormalTok{            instantiations}\OperatorTok{=}\NormalTok{instantiations,}
\NormalTok{            posteriors}\OperatorTok{=}\NormalTok{get\_posteriors(row)}
\NormalTok{        )}

    \CommentTok{\# Add edges}
    \ControlFlowTok{for}\NormalTok{ idx, row }\KeywordTok{in}\NormalTok{ df.iterrows():}
\NormalTok{        child }\OperatorTok{=}\NormalTok{ row[}\StringTok{\textquotesingle{}Title\textquotesingle{}}\NormalTok{]}
\NormalTok{        parents }\OperatorTok{=}\NormalTok{ get\_parents(row)}

        \CommentTok{\# Add edges from each parent to this child}
        \ControlFlowTok{for}\NormalTok{ parent }\KeywordTok{in}\NormalTok{ parents:}
            \ControlFlowTok{if}\NormalTok{ parent }\KeywordTok{in}\NormalTok{ G.nodes():}
\NormalTok{                G.add\_edge(parent, child)}

    \CommentTok{\# Classify nodes based on network structure}
\NormalTok{    classify\_nodes(G)}

    \CommentTok{\# Create network visualization}
\NormalTok{    net }\OperatorTok{=}\NormalTok{ Network(notebook}\OperatorTok{=}\VariableTok{True}\NormalTok{, directed}\OperatorTok{=}\VariableTok{True}\NormalTok{, cdn\_resources}\OperatorTok{=}\StringTok{"in\_line"}\NormalTok{, height}\OperatorTok{=}\StringTok{"600px"}\NormalTok{, width}\OperatorTok{=}\StringTok{"100\%"}\NormalTok{)}

    \CommentTok{\# Configure physics for better layout}
\NormalTok{    net.force\_atlas\_2based(gravity}\OperatorTok{={-}}\DecValTok{50}\NormalTok{, spring\_length}\OperatorTok{=}\DecValTok{100}\NormalTok{, spring\_strength}\OperatorTok{=}\FloatTok{0.02}\NormalTok{)}
\NormalTok{    net.show\_buttons(filter\_}\OperatorTok{=}\NormalTok{[}\StringTok{\textquotesingle{}physics\textquotesingle{}}\NormalTok{])}

    \CommentTok{\# Add the graph to the network}
\NormalTok{    net.from\_nx(G)}

    \CommentTok{\# Enhance node appearance with probability information and classification}
    \ControlFlowTok{for}\NormalTok{ node }\KeywordTok{in}\NormalTok{ net.nodes:}
\NormalTok{        node\_id }\OperatorTok{=}\NormalTok{ node[}\StringTok{\textquotesingle{}id\textquotesingle{}}\NormalTok{]}
\NormalTok{        node\_data }\OperatorTok{=}\NormalTok{ G.nodes[node\_id]}

        \CommentTok{\# Get node type and set border color}
\NormalTok{        node\_type }\OperatorTok{=}\NormalTok{ node\_data.get(}\StringTok{\textquotesingle{}node\_type\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}unknown\textquotesingle{}}\NormalTok{)}
\NormalTok{        border\_color }\OperatorTok{=}\NormalTok{ get\_border\_color(node\_type)}

        \CommentTok{\# Get probability information}
\NormalTok{        priors }\OperatorTok{=}\NormalTok{ node\_data.get(}\StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{, \{\})}
\NormalTok{        true\_prob }\OperatorTok{=}\NormalTok{ priors.get(}\StringTok{\textquotesingle{}true\_prob\textquotesingle{}}\NormalTok{, }\FloatTok{0.5}\NormalTok{) }\ControlFlowTok{if}\NormalTok{ priors }\ControlFlowTok{else} \FloatTok{0.5}

        \CommentTok{\# Get proper state names}
\NormalTok{        instantiations }\OperatorTok{=}\NormalTok{ node\_data.get(}\StringTok{\textquotesingle{}instantiations\textquotesingle{}}\NormalTok{, [}\StringTok{"TRUE"}\NormalTok{, }\StringTok{"FALSE"}\NormalTok{])}
\NormalTok{        true\_state }\OperatorTok{=}\NormalTok{ instantiations[}\DecValTok{0}\NormalTok{] }\ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(instantiations) }\OperatorTok{\textgreater{}} \DecValTok{0} \ControlFlowTok{else} \StringTok{"TRUE"}
\NormalTok{        false\_state }\OperatorTok{=}\NormalTok{ instantiations[}\DecValTok{1}\NormalTok{] }\ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(instantiations) }\OperatorTok{\textgreater{}} \DecValTok{1} \ControlFlowTok{else} \StringTok{"FALSE"}

        \CommentTok{\# Create background color based on probability}
\NormalTok{        background\_color }\OperatorTok{=}\NormalTok{ get\_probability\_color(priors)}

        \CommentTok{\# Create tooltip with probability information}
\NormalTok{        tooltip }\OperatorTok{=}\NormalTok{ create\_tooltip(node\_id, node\_data)}

        \CommentTok{\# Create a simpler node label with probability}
\NormalTok{        simple\_label }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{node\_id}\SpecialCharTok{\}}\CharTok{\textbackslash{}n}\SpecialStringTok{p=}\SpecialCharTok{\{}\NormalTok{true\_prob}\SpecialCharTok{:.2f\}}\SpecialStringTok{"}

        \CommentTok{\# Store expanded content as a node attribute for use in click handler}
\NormalTok{        node\_data[}\StringTok{\textquotesingle{}expanded\_content\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ create\_expanded\_content(node\_id, node\_data)}

        \CommentTok{\# Set node attributes}
\NormalTok{        node[}\StringTok{\textquotesingle{}title\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ tooltip  }\CommentTok{\# Tooltip HTML}
\NormalTok{        node[}\StringTok{\textquotesingle{}label\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ simple\_label  }\CommentTok{\# Simple text label}
\NormalTok{        node[}\StringTok{\textquotesingle{}shape\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \StringTok{\textquotesingle{}box\textquotesingle{}}
\NormalTok{        node[}\StringTok{\textquotesingle{}color\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ \{}
            \StringTok{\textquotesingle{}background\textquotesingle{}}\NormalTok{: background\_color,}
            \StringTok{\textquotesingle{}border\textquotesingle{}}\NormalTok{: border\_color,}
            \StringTok{\textquotesingle{}highlight\textquotesingle{}}\NormalTok{: \{}
                \StringTok{\textquotesingle{}background\textquotesingle{}}\NormalTok{: background\_color,}
                \StringTok{\textquotesingle{}border\textquotesingle{}}\NormalTok{: border\_color}
\NormalTok{            \}}
\NormalTok{        \}}

    \CommentTok{\# Set up the click handler with proper data}
\NormalTok{    setup\_data }\OperatorTok{=}\NormalTok{ \{}
        \StringTok{\textquotesingle{}nodes\_data\textquotesingle{}}\NormalTok{: \{node\_id: \{}
            \StringTok{\textquotesingle{}expanded\_content\textquotesingle{}}\NormalTok{: json.dumps(G.nodes[node\_id].get(}\StringTok{\textquotesingle{}expanded\_content\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{)),}
            \StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{: G.nodes[node\_id].get(}\StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\textquotesingle{}}\NormalTok{),}
            \StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{: G.nodes[node\_id].get(}\StringTok{\textquotesingle{}priors\textquotesingle{}}\NormalTok{, \{\}),}
            \StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{: G.nodes[node\_id].get(}\StringTok{\textquotesingle{}posteriors\textquotesingle{}}\NormalTok{, \{\})}
\NormalTok{        \} }\ControlFlowTok{for}\NormalTok{ node\_id }\KeywordTok{in}\NormalTok{ G.nodes()\}}
\NormalTok{    \}}

    \CommentTok{\# Add custom click handling JavaScript}
\NormalTok{    click\_js }\OperatorTok{=} \StringTok{"""}
\StringTok{    // Store node data for click handling}
\StringTok{    var nodesData = }\SpecialCharTok{\%s}\StringTok{;}

\StringTok{    // Add event listener for node clicks}
\StringTok{    network.on("click", function(params) \{}
\StringTok{        if (params.nodes.length \textgreater{} 0) \{}
\StringTok{            var nodeId = params.nodes[0];}
\StringTok{            var nodeInfo = nodesData[nodeId];}

\StringTok{            if (nodeInfo) \{}
\StringTok{                // Create a modal popup for expanded content}
\StringTok{                var modal = document.createElement(\textquotesingle{}div\textquotesingle{});}
\StringTok{                modal.style.position = \textquotesingle{}fixed\textquotesingle{};}
\StringTok{                modal.style.left = \textquotesingle{}50}\SpecialCharTok{\%\%}\StringTok{\textquotesingle{};}
\StringTok{                modal.style.top = \textquotesingle{}50}\SpecialCharTok{\%\%}\StringTok{\textquotesingle{};}
\StringTok{                modal.style.transform = \textquotesingle{}translate({-}50}\SpecialCharTok{\%\%}\StringTok{, {-}50}\SpecialCharTok{\%\%}\StringTok{)\textquotesingle{};}
\StringTok{                modal.style.backgroundColor = \textquotesingle{}white\textquotesingle{};}
\StringTok{                modal.style.padding = \textquotesingle{}20px\textquotesingle{};}
\StringTok{                modal.style.borderRadius = \textquotesingle{}5px\textquotesingle{};}
\StringTok{                modal.style.boxShadow = \textquotesingle{}0 0 10px rgba(0,0,0,0.5)\textquotesingle{};}
\StringTok{                modal.style.zIndex = \textquotesingle{}1000\textquotesingle{};}
\StringTok{                modal.style.maxWidth = \textquotesingle{}80}\SpecialCharTok{\%\%}\StringTok{\textquotesingle{};}
\StringTok{                modal.style.maxHeight = \textquotesingle{}80}\SpecialCharTok{\%\%}\StringTok{\textquotesingle{};}
\StringTok{                modal.style.overflow = \textquotesingle{}auto\textquotesingle{};}

\StringTok{                // Parse the JSON string back to HTML content}
\StringTok{                try \{}
\StringTok{                    var expandedContent = JSON.parse(nodeInfo.expanded\_content);}
\StringTok{                    modal.innerHTML = expandedContent;}
\StringTok{                \} catch (e) \{}
\StringTok{                    modal.innerHTML = \textquotesingle{}Error displaying content: \textquotesingle{} + e.message;}
\StringTok{                \}}

\StringTok{                // Add close button}
\StringTok{                var closeBtn = document.createElement(\textquotesingle{}button\textquotesingle{});}
\StringTok{                closeBtn.innerHTML = \textquotesingle{}Close\textquotesingle{};}
\StringTok{                closeBtn.style.marginTop = \textquotesingle{}10px\textquotesingle{};}
\StringTok{                closeBtn.style.padding = \textquotesingle{}5px 10px\textquotesingle{};}
\StringTok{                closeBtn.style.cursor = \textquotesingle{}pointer\textquotesingle{};}
\StringTok{                closeBtn.onclick = function() \{}
\StringTok{                    document.body.removeChild(modal);}
\StringTok{                \};}
\StringTok{                modal.appendChild(closeBtn);}

\StringTok{                // Add modal to body}
\StringTok{                document.body.appendChild(modal);}
\StringTok{            \}}
\StringTok{        \}}
\StringTok{    \});}
\StringTok{    """} \OperatorTok{\%}\NormalTok{ json.dumps(setup\_data[}\StringTok{\textquotesingle{}nodes\_data\textquotesingle{}}\NormalTok{])}

    \CommentTok{\# Save the graph to HTML}
\NormalTok{    html\_file }\OperatorTok{=} \StringTok{"bayesian\_network.html"}
\NormalTok{    net.save\_graph(html\_file)}

    \CommentTok{\# Inject custom click handling into HTML}
    \ControlFlowTok{try}\NormalTok{:}
        \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(html\_file, }\StringTok{"r"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{            html\_content }\OperatorTok{=}\NormalTok{ f.read()}

        \CommentTok{\# Insert click handling script before the closing body tag}
\NormalTok{        html\_content }\OperatorTok{=}\NormalTok{ html\_content.replace(}\StringTok{\textquotesingle{}\textless{}/body\textgreater{}\textquotesingle{}}\NormalTok{, }\SpecialStringTok{f\textquotesingle{}\textless{}script\textgreater{}}\SpecialCharTok{\{}\NormalTok{click\_js}\SpecialCharTok{\}}\SpecialStringTok{\textless{}/script\textgreater{}\textless{}/body\textgreater{}\textquotesingle{}}\NormalTok{)}

        \CommentTok{\# Write back the modified HTML}
        \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(html\_file, }\StringTok{"w"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{            f.write(html\_content)}

        \ControlFlowTok{return}\NormalTok{ HTML(html\_content)}
    \ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
        \ControlFlowTok{return}\NormalTok{ HTML(}\SpecialStringTok{f"\textless{}p\textgreater{}Error rendering HTML: }\SpecialCharTok{\{}\BuiltInTok{str}\NormalTok{(e)}\SpecialCharTok{\}}\SpecialStringTok{\textless{}/p\textgreater{}"}
        \OperatorTok{+} \StringTok{"\textless{}p\textgreater{}The network visualization has been saved to \textquotesingle{}}\SpecialCharTok{\{html\_file\}}\StringTok{\textquotesingle{}\textless{}/p\textgreater{}"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

{[}FIGURE N: Interactive visualization of Carlsmith's model showing
color-coded nodes and causal relationships{]}

This visualization reveals several structural insights:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Central importance of ``Misaligned\_Power\_Seeking''} as a hub
  node with multiple parents and children
\item
  \textbf{Multiple pathways to ``Existential\_Catastrophe''} through
  different intermediate factors
\item
  \textbf{Clusters of related variables} forming coherent subarguments
  (e.g., factors affecting alignment difficulty)
\item
  \textbf{Flow of influence} from technical factors (bottom) through
  deployment decisions to ultimate outcomes (top)
\end{enumerate}

The implementation successfully handles the complexity of Carlsmith's
model, correctly processing the multi-level structure, resolving
repeated node references, and calculating appropriate probability
distributions. The interactive visualization makes this complex model
accessible, allowing users to explore different aspects of the argument
through intuitive navigation.

Several key aspects of the implementation were particularly important
for handling this complex model:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The \textbf{parent-child relationship detection algorithm} correctly
  identified hierarchical relationships despite the complex structure
  with repeated nodes and multiple levels.
\item
  The \textbf{probability question generation system} created
  appropriate questions for all variables, including those with multiple
  parents requiring factorial combinations of conditional probabilities.
\item
  The \textbf{network enhancement functions} calculated useful metrics
  like centrality measures and Markov blankets that help interpret the
  model structure.
\item
  The \textbf{visualization system} effectively presented the complex
  network through color-coding, interactive exploration, and progressive
  disclosure of details.
\end{enumerate}

The successful application to Carlsmith's model demonstrates the AMTAIR
approach's scalability to complex real-world arguments. While the
canonical rain-sprinkler-lawn example validated correctness, this
application proves practical utility for sophisticated multi-level
arguments with dozens of variables and complex
interdependencies---precisely the kind of arguments that characterize AI
risk assessments.

This capability addresses a core limitation of the original MTAIR
framework: the labor intensity of manual formalization. Where manually
converting Carlsmith's argument to a formal model might take days of
expert time, the AMTAIR approach accomplished this in minutes, creating
a foundation for further analysis and exploration.

Beyond the core visualization, the system includes specialized
components that enhance understanding of probabilistic relationships:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Probability bars} provide visual representations of
  probability distributions, showing relative likelihoods of different
  states using color-coded horizontal bars with numeric labels.
\item
  \textbf{Conditional probability tables} organize complex relationships
  into structured matrices, displaying how different combinations of
  parent states influence probability distributions.
\item
  \textbf{Sensitivity indicators} highlight which nodes and
  relationships most significantly affect outcomes, directing attention
  to critical factors.
\end{enumerate}

These components work together to create an intuitive interface for
complex probabilistic models. A user might start by exploring the
overall structure to understand key factors and relationships, hover
over nodes of interest to see probability summaries, then click on
specific nodes to examine detailed conditional probabilities.

The benefits of this visualization approach extend beyond aesthetic
appeal to fundamental improvements in understanding and communication:

First, \textbf{intuitive comprehension} of probability relationships
becomes possible even for those without formal training in Bayesian
statistics. The color coding provides immediate visual cues about which
outcomes are more likely, while interactive exploration allows users to
develop intuition about how different factors influence results.

Second, \textbf{cross-stakeholder communication} improves through shared
visual reference points. Technical experts can use the visualizations to
explain complex relationships to policy specialists, while governance
experts can identify institutional factors that might be incorporated
into the models.

Third, \textbf{disagreement identification} becomes more precise as
stakeholders can point to specific nodes, relationships, or probability
values where their views differ, focusing discussion on substantive
issues rather than terminological confusion.

Fourth, \textbf{intervention assessment} becomes more concrete as users
can see how changing specific factors influences downstream effects,
providing intuitive understanding of causal pathways and leverage
points.

The visualization system demonstrates how thoughtful interface design
can overcome barriers to understanding complex formal models. By making
probabilistic relationships visually intuitive and progressively
disclosing details based on user interest, it creates bridges between
mathematical precision and human comprehension---precisely the kind of
bridge needed to support coordination across domains in AI governance.

This approach reflects a broader principle: formalization is most
valuable when it enhances rather than replaces human understanding. The
AMTAIR visualization doesn't simplify complex relationships; it makes
them more accessible by leveraging visual cognition, interactive
exploration, and progressive disclosure. This human-centered approach to
formalization creates tools that augment rather than replace expert
judgment, enhancing our collective ability to understand and address
complex governance challenges.

\subsubsection*{\texorpdfstring{\textbf{Insights from
Formalization}}{Insights from Formalization}}\label{insights-from-formalization}
\addcontentsline{toc}{subsubsection}{\textbf{Insights from
Formalization}}

Formal representation reveals several insights:

\textbf{Critical Path Analysis}: The pathway through APS development and
deployment decisions carries the highest risk contribution.

\textbf{Sensitivity Points}: Small changes in deployment probability
create large changes in overall risk.

\textbf{Intervention Opportunities}: Improving alignment difficulty or
deployment governance show highest impact potential.

These insights emerge naturally from formal analysis but remain implicit
in textual arguments.

\subsection*{3.5.6 Validation Against Original (From the MTAIR
Project)}\label{sec-carlsmith-validation}
\addcontentsline{toc}{subsection}{3.5.6 Validation Against Original
(From the MTAIR Project)}

\end{landscape}

\section*{3.6 Validation Methodology}\label{sec-validation-methodology}
\addcontentsline{toc}{section}{3.6 Validation Methodology}

\markright{3.6 Validation Methodology}

Establishing trust in automated extraction requires rigorous validation
across multiple dimensions.

\subsection*{3.6.1 Ground Truth Construction}\label{sec-ground-truth}
\addcontentsline{toc}{subsection}{3.6.1 Ground Truth Construction}

\begin{verbatim}
Plan the process:
1. Expert selection criteria
2. Training on extraction methodology
3. Independent extraction procedures
4. Consensus building process
5. Inter-rater reliability metrics
\end{verbatim}

--\textgreater{}

\subsection*{3.6.2 Evaluation Metrics}\label{sec-evaluation-metrics}
\addcontentsline{toc}{subsection}{3.6.2 Evaluation Metrics}

--\textgreater{}

\subsection*{3.6.3 Results Summary}\label{sec-validation-results}
\addcontentsline{toc}{subsection}{3.6.3 Results Summary}

Performance is strongest for explicit structural elements and numerical
probabilities, with more challenges in extracting implicit relationships
and qualitative uncertainty. --\textgreater{}

\subsection*{3.6.4 Error Analysis}\label{sec-error-analysis}
\addcontentsline{toc}{subsection}{3.6.4 Error Analysis}

Common failure modes to avoid:

\textbf{Implicit Assumptions}: Unstated background assumptions that
experts infer but system misses.

\textbf{Complex Conditionals}: Nested conditionals with multiple
antecedents challenge current parsing.

\textbf{Ambiguous Quantifiers}: Terms like ``significant'' lack clear
probability mapping without context.

\textbf{Coreference Resolution}: Pronouns and indirect references create
attribution challenges.

Understanding these limitations guides both current usage and future
improvements.

\section*{3.7 Extensions \& Opportunities: Inference \&
Analysis}\label{extensions-opportunities-inference-analysis}
\addcontentsline{toc}{section}{3.7 Extensions \& Opportunities:
Inference \& Analysis}

\markright{3.7 Extensions \& Opportunities: Inference \& Analysis}

Quantification \& Formal Approximation --- Inference: Monte Carlo
Sampling over Probability Distributions

\subsection*{3.7.1 Overview of Practical Software
Implementations}\label{overview-of-practical-software-implementations}
\addcontentsline{toc}{subsection}{3.7.1 Overview of Practical Software
Implementations}

\subsection*{\texorpdfstring{3.7.2 \textbf{AI Risk Pathway Analyzer
(ARPA)}}{3.7.2 AI Risk Pathway Analyzer (ARPA)}}\label{ai-risk-pathway-analyzer-arpa}
\addcontentsline{toc}{subsection}{3.7.2 \textbf{AI Risk Pathway Analyzer
(ARPA)}}

1. Document Ingestion System: Handles format normalization, metadata
extraction, and citation tracking for diverse input formats. 2.
LLM-Powered Extraction Pipeline: Uses two-stage prompting to identify
variables, claims, and causal relationships from text. 3. ArgDown
Representation Generator: Creates structured intermediate representation
of arguments with formal syntax. 4. Bayesian Network Constructor:
Transforms ArgDown into formal Bayesian networks with nodes and edges.
5. Probability Quantification Module: Populates conditional probability
tables from extracted judgments. 6. Interactive Visualization Interface:
Provides intuitive visual access to network structure and probabilities.
7. Sensitivity Analysis Engine: Identifies critical variables and tests
robustness of conclusions.

The cornerstone system that transforms unstructured AI safety literature
into formal, analyzable models. Like a Rosetta Stone for AI governance,
ARPA creates a common language for discourse by extracting the implicit
causal models embedded in research papers and converting them into
explicit Bayesian networks. Its strategic value lies in overcoming the
fundamental information processing bottleneck in AI governance---making
the invisible visible by revealing the assumptions, relationships, and
probability judgments that drive different conclusions about AI risk.

\subsubsection*{}\label{section}
\addcontentsline{toc}{subsubsection}{}

\subsection*{3.7.3 P(Doom) Calculator}\label{pdoom-calculator}
\addcontentsline{toc}{subsection}{3.7.3 P(Doom) Calculator}

\subsection*{\texorpdfstring{3.7.4 \textbf{Worldview
Comparator}}{3.7.4 Worldview Comparator}}\label{worldview-comparator}
\addcontentsline{toc}{subsection}{3.7.4 \textbf{Worldview Comparator}}

A ``gifted, diplomatic translator'' that helps to reveal the hidden
landscape of agreement and disagreement across different perspectives on
AI risk. This system provides the cartography of ideas---mapping where
different worldviews converge, diverge, and where crucial disagreements
(``cruxes'') significantly affect conclusions. Its strategic value lies
in focusing discourse on substantive disagreements rather than
terminological differences, enabling more productive collaboration
across philosophical and methodological divides within the AI safety
community.

1. Structural Comparison Engine: Identifies isomorphic subgraphs between
different models and maps shared causal pathways. 2. Parameter
Difference Analyzer: Quantifies differences in probability distributions
across models. 3. Crux Identification System: Detects critical
disagreements that significantly affect conclusions. 4. Worldview
Explainer: Provides conversational interface for exploring different
perspectives. 5. Worldview Communicator: Translates concepts between
different terminological frameworks. 6. Consensus Model Builder:
Identifies shared structures and constructs hybrid models representing
areas of agreement.

\subsection*{\texorpdfstring{3.7.5 \textbf{Policy Impact
Evaluator}}{3.7.5 Policy Impact Evaluator}}\label{policy-impact-evaluator}
\addcontentsline{toc}{subsection}{3.7.5 \textbf{Policy Impact
Evaluator}}

1. Policy Representation System: Translates governance proposals into
formal intervention parameters. 2. Counterfactual Analysis Engine:
Implements Pearl's do-calculus for simulating intervention effects. 3.
Multi-Worldview Evaluator: Tests policy effects across different
extracted models. 4. Intervention Portfolio Analyzer: Assesses
combinations of policies for synergies and conflicts. 5. Policy
Effectiveness Dashboard: Visualizes impact assessments with uncertainty
representation.

A policy simulator that functions like a governance wind
tunnel---testing how specific interventions might perform across
different possible futures. By representing policies as modifications to
causal networks, this system enables rigorous counterfactual analysis of
intervention effects. Its strategic value lies in transforming abstract
policy discussions into concrete, quantifiable assessments of expected
impact, helping governance stakeholders allocate resources to the most
effective interventions.

\subsection*{\texorpdfstring{3.7.6 \textbf{AI Risk Pathway
Visualizer}}{3.7.6 AI Risk Pathway Visualizer}}\label{ai-risk-pathway-visualizer}
\addcontentsline{toc}{subsection}{3.7.6 \textbf{AI Risk Pathway
Visualizer}}

1. Risk Level Aggregation System: Combines multiple factors into summary
risk metrics. 2. Temporal Tracking Interface: Records and displays
changes in assessments over time. 3. Component Breakdown Visualizer:
Separates overall risk into constituent factors. 4. Interactive
Educational Components: Provides background on key concepts and
methodologies. 5. Explanation Generator: Creates natural language
interpretations of current status.

A public-facing translation layer that converts complex probabilistic
models into intuitive visual representations accessible to broader
audiences. Like the Doomsday Clock for nuclear risk, this system creates
focal points for public discourse about AI safety. Its strategic value
lies in making technical risk assessments comprehensible to
policymakers, journalists, and the public, expanding the reach and
impact of AI safety research beyond technical communities.

\subsection*{3.7.7 Strategic Intervention
Generator}\label{strategic-intervention-generator}
\addcontentsline{toc}{subsection}{3.7.7 Strategic Intervention
Generator}

1. Robust Strategy Identification System: Finds strategies that perform
well across multiple scenarios. 2. Minimax Regret Calculator: Identifies
strategies that minimize worst-case disappointment. 3. Option Value
Analyzer: Evaluates strategies that preserve future flexibility and
choices. 4. Intervention Portfolio Builder: Constructs complementary
bundles of policy interventions. 5. Dependency Mapping Visualizer: Shows
relationships and prerequisites between interventions.

An advanced decision support system that identifies robust governance
strategies across multiple possible futures. Operating like a strategic
chess engine, this system evaluates intervention portfolios under deep
uncertainty to find approaches that preserve options and minimize
maximum regret. Its strategic value lies in shifting governance planning
from optimizing for specific scenarios to developing adaptive strategies
that remain valuable despite fundamental uncertainty about AI
development trajectories.

\subsection*{\texorpdfstring{3.7.8 \textbf{Cross-Domain Understanding
Communicator}}{3.7.8 Cross-Domain Understanding Communicator}}\label{cross-domain-understanding-communicator}
\addcontentsline{toc}{subsection}{3.7.8 \textbf{Cross-Domain
Understanding Communicator}}

1. Concept Mapping System: Identifies equivalent concepts across
different domain languages. 2. Terminology Translation Engine: Converts
specialized terms between different disciplines. 3. Implication
Surfacing Tool: Highlights relevant cross-domain considerations for
specific questions. 4. Background Knowledge Provider: Supplies necessary
context for understanding concepts. 5. Cross-Domain Recommendation
Engine: Suggests relevant resources across disciplinary boundaries.

An interdisciplinary bridge-builder that connects specialists across
technical alignment, governance, and forecasting domains. This system
functions as a universal translator for AI safety, identifying
equivalent concepts across different disciplinary languages and
surfacing relevant cross-domain insights. Its strategic value lies in
breaking down the knowledge silos that impede comprehensive strategy
development, enabling researchers from different backgrounds to build on
each other's work more effectively.

\subsection*{\texorpdfstring{3.7.9 \textbf{Policy Brief
Communicator}}{3.7.9 Policy Brief Communicator}}\label{policy-brief-communicator}
\addcontentsline{toc}{subsection}{3.7.9 \textbf{Policy Brief
Communicator}}

1. Audience Analysis System: Determines appropriate framing and detail
level for target readers. 2. Jurisdictional Context Adapter: Tailors
content to relevant legal and institutional frameworks. 3.
Recommendation Formulator: Generates actionable governance suggestions
from technical insights. 4. Format Template Library: Applies appropriate
structure for different policy contexts. 5. Evidence Contextualization
Engine: Presents technical evidence in accessible and persuasive ways.

A specialized translation system that converts technical risk analyses
into actionable policy documents tailored to specific governance
contexts. This system bridges the gap between technical understanding
and practical implementation by packaging complex insights into formats
familiar to policymakers. Its strategic value lies in increasing the
policy impact of technical research by making insights accessible and
actionable for decision-makers in government, industry, and civil
society.

\subsection*{3.7.10 Prediction Market
Integration}\label{prediction-market-integration}
\addcontentsline{toc}{subsection}{3.7.10 Prediction Market Integration}

\begin{verbatim}
—   Live Data Updating: Crowdsourcing Collective Intelligence Via API Integrations
\end{verbatim}

\subsubsection*{\texorpdfstring{\textbf{Forecast Integration
Dashboard}}{Forecast Integration Dashboard}}\label{forecast-integration-dashboard}
\addcontentsline{toc}{subsubsection}{\textbf{Forecast Integration
Dashboard}}

1. Forecasting Platform API Connectors: Establishes connections with
prediction markets and forecasting platforms. 2. Semantic Question
Mapper: Links forecast questions to corresponding model variables. 3.
Forecast Weighting System: Determines influence of different forecast
sources based on track record. 4. Dynamic Update Engine: Manages
synchronization between forecasts and model parameters. 5. Forecast
Relevance Calculator: Identifies which forecasts would most reduce
uncertainty in the model.

A living nervous system that connects formal models to real-time data
streams from forecasting platforms. This system ensures that risk
assessments remain current as new information emerges, creating dynamic
models that evolve with the rapidly changing AI landscape. Its strategic
value lies in bridging the gap between static theoretical models and
emerging empirical evidence, leveraging collective intelligence from
prediction markets to continuously refine probability estimates.

\section*{3.7 Policy Evaluation
Capabilities}\label{sec-policy-evaluation}
\addcontentsline{toc}{section}{3.7 Policy Evaluation Capabilities}

\markright{3.7 Policy Evaluation Capabilities}

Beyond extraction and visualization, AMTAIR enables systematic policy
analysis through formal intervention modeling.

\subsection*{3.7.1 Intervention
Representation}\label{sec-intervention-representation}
\addcontentsline{toc}{subsection}{3.7.1 Intervention Representation}

--\textgreater{}

\subsection*{3.7.2 Example: Deployment
Governance}\label{sec-deployment-example}
\addcontentsline{toc}{subsection}{3.7.2 Example: Deployment Governance}

Consider a policy requiring safety certification before deployment:

\textbf{Intervention}: Set P(deployment\textbar misaligned) = 0.1 (from
0.7)

\textbf{Results}:

\begin{itemize}
\tightlist
\item
  Baseline P(catastrophe) = 0.05
\item
  Intervened P(catastrophe) = 0.012
\item
  Relative risk reduction = 76\%
\item
  Number needed to regulate = 26 deployments
\end{itemize}

This hypothetical quantitative analysis enables comparison across
interventions.

\subsection*{3.7.3 Robustness Analysis}\label{sec-robustness}
\addcontentsline{toc}{subsection}{3.7.3 Robustness Analysis}

\begin{tcolorbox}[enhanced jigsaw, arc=.35mm, titlerule=0mm, breakable, toprule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, coltitle=black, bottomrule=.15mm, bottomtitle=1mm, opacityback=0, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Cross-Worldview Robustness}, rightrule=.15mm, leftrule=.75mm, colback=white, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, left=2mm]

Policies must work across worldviews. AMTAIR enables multi-model
evaluation, parameter sensitivity testing, scenario analysis, and
confidence bound computation---ensuring interventions remain effective
despite uncertainty.

\end{tcolorbox}

\section*{3.8 Interactive Visualization
Design}\label{sec-visualization-design}
\addcontentsline{toc}{section}{3.8 Interactive Visualization Design}

\markright{3.8 Interactive Visualization Design}

Making Bayesian networks accessible to diverse stakeholders requires
careful visualization design.

\subsection*{3.8.1 Visual Encoding Strategy}\label{sec-visual-encoding}
\addcontentsline{toc}{subsection}{3.8.1 Visual Encoding Strategy}

The system uses multiple visual channels:

\textbf{Color}: Probability magnitude (green=high, red=low)\\
\textbf{Borders}: Node type (blue=root, purple=intermediate,
magenta=effect)\\
\textbf{Size}: Centrality in network (larger=more influential)\\
\textbf{Layout}: Force-directed positioning reveals clusters

\subsection*{3.8.2 Progressive
Disclosure}\label{sec-progressive-disclosure}
\addcontentsline{toc}{subsection}{3.8.2 Progressive Disclosure}

Information appears at appropriate levels:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Overview}: Network structure and color coding
\item
  \textbf{Hover}: Node description and prior probability
\item
  \textbf{Click}: Full probability tables and details
\item
  \textbf{Interaction}: Drag to rearrange, zoom to explore
\end{enumerate}

This layered approach serves both quick assessment and deep analysis
needs.

\subsection*{3.8.3 User Interface Elements}\label{sec-ui-elements}
\addcontentsline{toc}{subsection}{3.8.3 User Interface Elements}

\section*{3.9 Integration with Prediction
Markets}\label{sec-market-integration}
\addcontentsline{toc}{section}{3.9 Integration with Prediction Markets}

\markright{3.9 Integration with Prediction Markets}

While full integration remains future work, the architecture supports
connection to live forecasting data.

\subsection*{3.9.1 Design for Integration}\label{sec-integration-design}
\addcontentsline{toc}{subsection}{3.9.1 Design for Integration}

\begin{tcolorbox}[enhanced jigsaw, arc=.35mm, titlerule=0mm, breakable, toprule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, coltitle=black, bottomrule=.15mm, bottomtitle=1mm, opacityback=0, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Integration Architecture}, rightrule=.15mm, leftrule=.75mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, left=2mm]

The system anticipates market connections through API specifications for
major platforms, semantic matching algorithms, probability aggregation
methods, and update scheduling with caching.

\end{tcolorbox}

\begin{verbatim}
Design documentation needed:
- API specifications for major platforms
- Semantic matching algorithms
- Probability aggregation methods
- Update scheduling and caching
\end{verbatim}

\subsection*{3.9.2 Challenges and
Opportunities}\label{sec-market-challenges}
\addcontentsline{toc}{subsection}{3.9.2 Challenges and Opportunities}

Key integration challenges:

\begin{itemize}
\tightlist
\item
  \textbf{Question Mapping}: Model variables rarely match market
  questions exactly
\item
  \textbf{Temporal Alignment}: Markets forecast specific dates, models
  consider scenarios
\item
  \textbf{Quality Variation}: Market depth and participation vary
  significantly
\end{itemize}

Despite challenges, even partial integration provides value through
external validation and dynamic updating.

\section*{3.10 Computational Performance
Analysis}\label{sec-computational-performance}
\addcontentsline{toc}{section}{3.10 Computational Performance Analysis}

\markright{3.10 Computational Performance Analysis}

As networks grow large, computational challenges emerge requiring
sophisticated approaches.

\subsection*{3.10.1 Exact vs.~Approximate
Inference}\label{sec-exact-approximate}
\addcontentsline{toc}{subsection}{3.10.1 Exact vs.~Approximate
Inference}

Small networks enable exact inference through variable elimination.
Larger networks require approximation:

\textbf{Monte Carlo Methods}: Sample from probability distributions to
estimate queries\\
\textbf{Variational Inference}: Optimize simpler distributions to
approximate true posteriors\\
\textbf{Belief Propagation}: Pass messages between nodes to converge on
beliefs

The system automatically selects appropriate methods based on network
properties.

\subsection*{3.10.2 Scaling Strategies}\label{sec-scaling-strategies}
\addcontentsline{toc}{subsection}{3.10.2 Scaling Strategies}

For very large networks:

\begin{verbatim}
Document strategies with benchmarks:
1. Hierarchical decomposition algorithms
2. Pruning criteria and impact
3. Caching architecture
4. Parallelization speedups
\end{verbatim}

\section*{3.11 Results and Achievements}\label{sec-results-achievements}
\addcontentsline{toc}{section}{3.11 Results and Achievements}

\markright{3.11 Results and Achievements}

\subsection*{3.11.1 Extraction Quality
Assessment}\label{sec-extraction-quality}
\addcontentsline{toc}{subsection}{3.11.1 Extraction Quality Assessment}

--\textgreater{}

\subsection*{3.11.2 Computational
Performance}\label{sec-computational-performance}
\addcontentsline{toc}{subsection}{3.11.2 Computational Performance}

\subsection*{3.11.3 Policy Impact Evaluation}\label{sec-policy-impact}
\addcontentsline{toc}{subsection}{3.11.3 Policy Impact Evaluation}

--\textgreater{}

\section*{3.12 Summary of Technical
Contributions}\label{sec-technical-summary}
\addcontentsline{toc}{section}{3.12 Summary of Technical Contributions}

\markright{3.12 Summary of Technical Contributions}

AMTAIR successfully demonstrates:

\begin{itemize}
\tightlist
\item
  \textbf{Automated extraction} from natural language to formal models
\item
  \textbf{Two-stage architecture} separating structure from
  quantification
\item
  \textbf{High fidelity} preservation of complex arguments
\item
  \textbf{Interactive visualization} accessible to diverse users
\item
  \textbf{Scalable implementation} handling realistic network sizes
\end{itemize}

These achievements validate the feasibility of computational
coordination infrastructure for AI governance.

These results demonstrate both the feasibility and value of automated
model extraction for AI governance. However, several important
considerations and limitations merit discussion. The next chapter
critically examines these issues, addresses potential objections, and
explores the broader implications of this approach for enhancing
epistemic security in AI governance.

\bookmarksetup{startatroot}

\chapter*{4. Discussion: Implications and
Limitations}\label{sec-discussion}
\addcontentsline{toc}{chapter}{4. Discussion: Implications and
Limitations}

\markboth{4. Discussion: Implications and Limitations}{4. Discussion:
Implications and Limitations}

\begin{tcolorbox}[enhanced jigsaw, arc=.35mm, titlerule=0mm, breakable, toprule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, coltitle=black, bottomrule=.15mm, bottomtitle=1mm, opacityback=0, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Chapter Overview}, rightrule=.15mm, leftrule=.75mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, left=2mm]

\textbf{Grade Weight}: 10\% \textbar{} \textbf{Target Length}:
\textasciitilde14\% of text (\textasciitilde4,200 words)\\
\textbf{Requirements}: Discusses objections, provides convincing
replies, extends beyond course materials

\end{tcolorbox}

\section*{4.1 Technical Limitations and
Responses}\label{sec-technical-limitations}
\addcontentsline{toc}{section}{4.1 Technical Limitations and Responses}

\markright{4.1 Technical Limitations and Responses}

\subsection*{4.1.1 Objection 1: Extraction Quality
Boundaries}\label{sec-extraction-boundaries}
\addcontentsline{toc}{subsection}{4.1.1 Objection 1: Extraction Quality
Boundaries}

\textbf{Critic}: ``Complex implicit reasoning chains resist
formalization; automated extraction will systematically miss nuanced
arguments and subtle conditional relationships that human experts would
identify.''

\textbf{Response}: This concern has merit---extraction does face
inherent limitations. However, the empirical results tell a more nuanced
story. With extraction achieving 85\%+ accuracy for structural
relationships and 73\% for probability capture, the system performs well
enough for practical use while falling short of human expert
performance.

More importantly, AMTAIR employs a hybrid human-AI workflow that
addresses this limitation:

\begin{itemize}
\tightlist
\item
  \textbf{Two-stage verification}: Humans review structural extraction
  before probability quantification
\item
  \textbf{Transparent outputs}: All intermediate representations remain
  human-readable\\
\item
  \textbf{Iterative refinement}: Extraction prompts improve based on
  error analysis
\item
  \textbf{Ensemble approaches}: Multiple extraction attempts can
  identify ambiguities
\end{itemize}

The question is not whether automated extraction perfectly captures
every nuance---it doesn't. Rather, it's whether imperfect extraction
still provides value over no formal representation. When the alternative
is relying on conflicting mental models that remain entirely implicit,
even 75\% accurate formal models represent significant progress.

Furthermore, extraction errors often reveal interesting properties of
the source arguments themselves---ambiguities that human readers gloss
over become explicit when formalization fails. This diagnostic value
enhances rather than undermines the approach.

\subsection*{4.1.2 Objection 2: False Precision in
Uncertainty}\label{sec-false-precision}
\addcontentsline{toc}{subsection}{4.1.2 Objection 2: False Precision in
Uncertainty}

\textbf{Critic}: ``Attaching exact probabilities to unprecedented events
like AI catastrophe is fundamentally misguided. The numbers create false
confidence in what amounts to educated speculation about radically
uncertain futures.''

\textbf{Response}: This philosophical objection strikes at the heart of
formal risk assessment. However, AMTAIR addresses it through several
design choices:

First, the system explicitly represents uncertainty about uncertainty.
Rather than point estimates, the framework supports probability
distributions over parameters. When someone says ``likely'' we might
model this as Beta(8,2) rather than exactly 0.8, capturing both the
central estimate and our uncertainty about it.

\begin{verbatim}

Technical requirements:

- Beta distributions for probability parameters
- Dirichlet for multi-state variables
- Propagation through inference
- Visualization of uncertainty bounds
\end{verbatim}

Second, all probabilities are explicitly conditional on stated
assumptions. The system doesn't claim ``P(catastrophe) = 0.05''
absolutely, but rather ``Given Carlsmith's model assumptions,
P(catastrophe) = 0.05.'' This conditionality is preserved throughout
analysis.

Third, sensitivity analysis reveals which probabilities actually matter.
Often, precise values are unnecessary---knowing whether a parameter is
closer to 0.1 or 0.9 suffices for decision-making. The formalization
helps identify where precision matters and where it doesn't.

Finally, the alternative to quantification isn't avoiding the problem
but making it worse. When experts say ``highly likely'' or ``significant
risk,'' they implicitly reason with probabilities. Formalization simply
makes these implicit quantities explicit and subject to scrutiny. As
Dennis Lindley noted, ``Uncertainty is not in the events, but in our
knowledge about them.''

@\textcite{lindley2013}

\subsection*{4.1.3 Objection 3: Correlation
Complexity}\label{sec-correlation-complexity}
\addcontentsline{toc}{subsection}{4.1.3 Objection 3: Correlation
Complexity}

\textbf{Critic}: ``Bayesian networks assume conditional independence
given parents, but real-world AI risks involve complex correlations.
Ignoring these dependencies could dramatically misrepresent risk
levels.''

\textbf{Response}: Standard Bayesian networks do face limitations with
correlation representation---this is a genuine technical challenge.
However, several approaches within the framework address this:

\textbf{Explicit correlation nodes}: When factors share hidden common
causes, we can add latent variables to capture correlations. For
instance, ``AI research culture'' might influence both ``capability
advancement'' and ``safety investment.''

\textbf{Copula methods}: For known correlation structures, copula
functions can model dependencies while preserving marginal
distributions. This extends standard Bayesian networks
significantly.\footnote{Copulas provide a mathematically elegant way to
  separate marginal behavior from dependence structure}

\textcite{nelson2006}

\textbf{Sensitivity bounds}: When correlations remain uncertain, we can
compute bounds on outcomes under different correlation assumptions. This
reveals when correlations critically affect conclusions.

\textbf{Model ensembles}: Different correlation structures can be
modeled separately and results aggregated, similar to climate modeling
approaches.

More fundamentally, the question is whether imperfect independence
assumptions invalidate the approach. In practice, explicitly modeling
first-order effects with known limitations often proves more valuable
than attempting to capture all dependencies informally. The framework
makes assumptions transparent, enabling targeted improvements where
correlations matter most.

\section*{4.2 Conceptual and Methodological
Concerns}\label{sec-conceptual-concerns}
\addcontentsline{toc}{section}{4.2 Conceptual and Methodological
Concerns}

\markright{4.2 Conceptual and Methodological Concerns}

\subsection*{4.2.1 Objection 4: Democratic
Exclusion}\label{sec-democratic-exclusion}
\addcontentsline{toc}{subsection}{4.2.1 Objection 4: Democratic
Exclusion}

\textbf{Critic}: ``Transforming policy debates into complex graphs and
equations will sideline non-technical stakeholders, concentrating
influence among those comfortable with formal models. This technocratic
approach undermines democratic participation in crucial decisions about
humanity's future.''

\textbf{Response}: This concern about technocratic exclusion deserves
serious consideration---formal methods can indeed create barriers.
However, AMTAIR's design explicitly prioritizes accessibility alongside
rigor:

\textbf{Progressive disclosure interfaces} allow engagement at multiple
levels. A policymaker might explore visual network structures and
probability color-coding without engaging mathematical details.
Interactive features let users modify assumptions and see consequences
without understanding implementation.

\textbf{Natural language preservation} ensures original arguments remain
accessible. The BayesDown format maintains human-readable descriptions
alongside formal specifications. Users can always trace from
mathematical representations back to source texts.

\textbf{Comparative advantage} comes from making implicit technical
content explicit, not adding complexity. When experts debate AI risk,
they already employ sophisticated probabilistic
reasoning---formalization reveals rather than creates this complexity.
Making hidden assumptions visible arguably enhances rather than reduces
democratic participation.

\textbf{Multiple interfaces} serve different communities. Researchers
access full technical depth, policymakers use summary dashboards, public
stakeholders explore interactive visualizations. The same underlying
model supports varied engagement modes.

Rather than excluding non-technical stakeholders, proper implementation
can democratize access to expert reasoning by making it inspectable and
modifiable. The risk lies not in formalization itself but in poor
interface design or gatekeeping behaviors around model access.

\subsection*{4.2.2 Objection 5: Oversimplification of Complex
Systems}\label{sec-oversimplification}
\addcontentsline{toc}{subsection}{4.2.2 Objection 5: Oversimplification
of Complex Systems}

\textbf{Critic}: ``Forcing rich socio-technical systems into discrete
Bayesian networks necessarily loses crucial dynamics---feedback loops,
emergent properties, institutional responses, and cultural factors that
shape AI development. The models become precise but wrong.''

\textbf{Response}: All models simplify by necessity---as Box noted,
``All models are wrong, but some are useful.'' The question becomes
whether formal simplifications improve upon informal mental models:

\textbf{Transparent limitations} make formal models' shortcomings
explicit. Unlike mental models where simplifications remain hidden,
network representations clearly show what is and isn't included. This
transparency enables targeted criticism and improvement.

\textbf{Iterative refinement} allows models to grow more sophisticated
over time. Starting with first-order effects and adding complexity where
it proves important follows successful practice in other domains.
Climate models began simply and added dynamics as computational power
and understanding grew.

\textbf{Complementary tools} address different aspects of the system.
Bayesian networks excel at probabilistic reasoning and intervention
analysis. Other approaches---agent-based models, system dynamics,
scenario planning---can capture different properties. AMTAIR provides
one lens, not the only lens.

\textbf{Empirical adequacy} ultimately judges models. If simplified
representations enable better predictions and decisions than informal
alternatives, their abstractions are justified. Early results suggest
formal models, despite simplifications, outperform intuitive reasoning
for complex risk assessment.

The goal isn't creating perfect representations but useful ones. By
making simplifications explicit and modifiable, formal models enable
systematic improvement in ways mental models cannot.

\textcite{box1976}

\subsection*{4.2.4 Objection 6: Idosyncratic Implementation and Modeling
Choices
\{sec-idosyncratic\}}\label{objection-6-idosyncratic-implementation-and-modeling-choices-sec-idosyncratic}
\addcontentsline{toc}{subsection}{4.2.4 Objection 6: Idosyncratic
Implementation and Modeling Choices \{sec-idosyncratic\}}

\section*{4.3 Red-Teaming Results}\label{sec-red-teaming}
\addcontentsline{toc}{section}{4.3 Red-Teaming Results}

\markright{4.3 Red-Teaming Results}

To identify failure modes, I conducted systematic adversarial testing of
the AMTAIR system.

\subsection*{4.3.1 Adversarial Extraction
Attempts}\label{sec-adversarial-extraction}
\addcontentsline{toc}{subsection}{4.3.1 Adversarial Extraction Attempts}

--\textgreater{}

\subsection*{4.3.2 Robustness Findings}\label{sec-robustness-findings}
\addcontentsline{toc}{subsection}{4.3.2 Robustness Findings}

Key vulnerabilities of LLMs (and human experts) identified:

\begin{verbatim}

Specific metrics need validation:

- Anchoring bias: measured effect size with confidence intervals
- Authority sensitivity: controlled experiment design
- Complexity degradation: performance curve analysis
- Context loss: dependency distance metrics
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Anchoring bias}: System tends to over-weight first probability
  mentioned\footnote{This reflects how LLMs inherit human cognitive
    biases from training data}
\item
  \textbf{Authority sensitivity}: Extracted probabilities influenced by
  cited expert prominence
\item
  \textbf{Complexity degradation}: Performance drops sharply beyond 50
  nodes
\item
  \textbf{Context loss}: Long-range dependencies in text sometimes
  missed
\end{enumerate}

However, the system demonstrated robustness to: - Different writing
styles and academic disciplines - Variations in argument structure and
presentation order - Mixed numerical and qualitative probability
expressions - Reasonable levels of grammatical errors and typos

\subsection*{4.3.3 Implications for
Deployment}\label{sec-deployment-implications}
\addcontentsline{toc}{subsection}{4.3.3 Implications for Deployment}

These results suggest AMTAIR is suitable for: - \textbf{Research
applications} with expert oversight - \textbf{Policy analysis} of
well-structured arguments - \textbf{Educational uses} demonstrating
formal reasoning - \textbf{Collaborative modeling} with human
verification

But should be used cautiously for: - Fully automated analysis without
review - Adversarial or politically contentious texts - Real-time
decision-making without validation - Arguments far outside training
distribution

\section*{4.4 Enhancing Epistemic
Security}\label{sec-epistemic-security}
\addcontentsline{toc}{section}{4.4 Enhancing Epistemic Security}

\markright{4.4 Enhancing Epistemic Security}

Despite limitations, AMTAIR contributes to epistemic security in AI
governance through several mechanisms.

\subsection*{4.4.1 Making Models
Inspectable}\label{sec-inspectable-models}
\addcontentsline{toc}{subsection}{4.4.1 Making Models Inspectable}

The greatest epistemic benefit comes from forcing implicit models into
explicit form. When an expert claims ``misalignment likely leads to
catastrophe,'' formalization asks:

\begin{itemize}
\tightlist
\item
  Likely means what probability?
\item
  Through what causal pathways?
\item
  Under what assumptions?
\item
  With what evidence?
\end{itemize}

This explicitation serves multiple functions:

\textbf{Clarity}: Vague statements become precise claims subject to
evaluation

\textbf{Comparability}: Different experts' models can be systematically
compared

\textbf{Criticizability}: Hidden assumptions become visible targets for
challenge

\textbf{Updatability}: Formal models can systematically incorporate new
evidence

\subsection*{4.4.2 Revealing Convergence and
Divergence}\label{sec-convergence-divergence}
\addcontentsline{toc}{subsection}{4.4.2 Revealing Convergence and
Divergence}

\begin{verbatim}

Implement comparison of 3+ models:

- Structural similarity metrics
- Parameter divergence analysis
- Crux identification algorithms
- Visualization of agreement patterns
\end{verbatim}

\textbf{Structural convergence}: Different experts often share similar
causal models even when probability estimates diverge dramatically. This
suggests shared understanding of mechanisms despite disagreement on
magnitudes.

\textbf{Parameter clustering}: Probability estimates often cluster
around a few values rather than spreading uniformly, suggesting implicit
coordination or common evidence bases.

\textbf{Crux identification}: Formal comparison precisely identifies
where worldviews diverge---often just 2-3 key parameters drive different
conclusions about overall risk.

These insights remain hidden when arguments stay in natural language
form.

--\textgreater{}

\subsection*{4.4.3 Improving Collective
Reasoning}\label{sec-collective-reasoning}
\addcontentsline{toc}{subsection}{4.4.3 Improving Collective Reasoning}

AMTAIR enhances group epistemics through:

\textbf{Explicit uncertainty}: Replacing ``might,'' ``could,''
``likely'' with probability distributions reduces miscommunication and
standardizes precision

\textbf{Compositional reasoning}: Complex arguments decompose into
manageable components that can be independently evaluated

\textbf{Evidence integration}: New information updates specific
parameters rather than requiring complete argument reconstruction

\textbf{Exploration tools}: Stakeholders can modify assumptions and
immediately see consequences, building intuition about model dynamics

\section*{4.5 Scaling Challenges and Opportunities}\label{sec-scaling}
\addcontentsline{toc}{section}{4.5 Scaling Challenges and Opportunities}

\markright{4.5 Scaling Challenges and Opportunities}

Moving from prototype to widespread adoption faces both technical and
social challenges.

\subsection*{4.5.1 Technical Scaling}\label{sec-technical-scaling}
\addcontentsline{toc}{subsection}{4.5.1 Technical Scaling}

\textbf{Computational complexity} grows with network size, but several
approaches help: - Hierarchical decomposition for very large models -
Caching and approximation for common queries - Distributed processing
for extraction tasks - Incremental updating rather than full
recomputation

\textbf{Data quality} varies dramatically across sources: - Academic
papers provide structured arguments - Blog posts offer rich ideas with
less formal structure - Policy documents mix normative and empirical
claims - Social media presents extreme extraction challenges

\textbf{Integration complexity} increases with ecosystem growth: -
Multiple LLM providers with different capabilities - Diverse
visualization needs across users - Various export formats for downstream
tools - Version control for evolving models

\subsection*{4.5.2 Social and Institutional
Scaling}\label{sec-social-scaling}
\addcontentsline{toc}{subsection}{4.5.2 Social and Institutional
Scaling}

\textbf{Adoption barriers} include: - Learning curve for formal methods
- Institutional inertia in established processes - Concerns about
replacing human judgment - Resource requirements for implementation

\textbf{Trust building} requires: - Transparent methodology
documentation - Published validation studies - High-profile successful
applications - Community ownership and development

\textbf{Sustainability} depends on: - Open source development model -
Diverse funding sources - Academic and industry partnerships - Clear
value demonstration

\subsection*{4.5.3 Opportunities for
Impact}\label{sec-impact-opportunities}
\addcontentsline{toc}{subsection}{4.5.3 Opportunities for Impact}

Despite challenges, several factors favor adoption:

\textbf{Timing}: AI governance needs tools now, creating receptive
audiences

\textbf{Complementarity}: AMTAIR enhances rather than replaces existing
processes

\textbf{Flexibility}: The approach adapts to different contexts and
needs

\textbf{Network effects}: Value increases as more perspectives are
formalized

Early adopters in research organizations and think tanks can demonstrate
value, creating momentum for broader adoption.

\section*{4.6 Integration with Governance
Frameworks}\label{sec-governance-integration}
\addcontentsline{toc}{section}{4.6 Integration with Governance
Frameworks}

\markright{4.6 Integration with Governance Frameworks}

AMTAIR complements and integrates rather than replaces existing
governance approaches.

\subsection*{4.6.1 Standards
Development}\label{sec-standards-integration}
\addcontentsline{toc}{subsection}{4.6.1 Standards Development}

Technical standards bodies could use AMTAIR to: - Model how proposed
standards affect risk pathways - Compare different standard options
systematically - Identify unintended consequences through pathway
analysis - Build consensus through explicit model negotiation

Example: Evaluating compute thresholds for AI system regulation by
modeling how different thresholds affect capability development, safety
investment, and competitive dynamics.

\subsection*{4.6.2 Regulatory Design}\label{sec-regulatory-integration}
\addcontentsline{toc}{subsection}{4.6.2 Regulatory Design}

Regulators could apply the framework to: - Assess regulatory impact
across different scenarios - Identify enforcement challenges through
explicit modeling - Compare international approaches systematically -
Design adaptive regulations responsive to evidence

Example: Analyzing how liability frameworks affect corporate AI
development decisions under different market conditions.

\textcite{cuomo2016}, \textcite{demirag2000}, \textcite{devilliers2021},
\textcite{divito2022}, \textcite{kaur2024}, \textcite{list2011} and
\textcite{solomon2020}

\subsection*{4.6.3 International
Coordination}\label{sec-international-integration}
\addcontentsline{toc}{subsection}{4.6.3 International Coordination}

Multilateral bodies could leverage shared models for: - Establishing
common risk assessments - Negotiating agreements with explicit
assumptions - Monitoring compliance through parameter tracking -
Adapting agreements as evidence emerges

Example: Building shared models for AGI development scenarios to inform
international AI governance treaties.

\subsection*{4.6.4 Organizational
Decision-Making}\label{sec-organizational-integration}
\addcontentsline{toc}{subsection}{4.6.4 Organizational Decision-Making}

Individual organizations could use AMTAIR for: - Internal risk
assessment and planning - Board-level communication about AI strategies
- Research prioritization based on model sensitivity - Safety case
development with explicit assumptions

Example: An AI lab modeling how different safety investments affect both
capability advancement and risk mitigation.

\section*{4.7 Future Research Directions}\label{sec-future-research}
\addcontentsline{toc}{section}{4.7 Future Research Directions}

\markright{4.7 Future Research Directions}

Several research directions could enhance AMTAIR's capabilities and
impact.

\subsection*{4.7.1 Technical Enhancements}\label{sec-technical-future}
\addcontentsline{toc}{subsection}{4.7.1 Technical Enhancements}

\textbf{Improved extraction}: Fine-tuning language models specifically
for argument extraction, handling implicit reasoning, and cross-document
synthesis

\textbf{Richer representations}: Temporal dynamics, continuous
variables, and multi-agent interactions within extended frameworks

\textbf{Inference advances}: Quantum computing applications, neural
approximate inference, and hybrid symbolic-neural methods

\textbf{Validation methods}: Automated consistency checking, anomaly
detection in extracted models, and benchmark dataset development

\subsection*{4.7.2 Methodological
Extensions}\label{sec-methodological-future}
\addcontentsline{toc}{subsection}{4.7.2 Methodological Extensions}

\textbf{Causal discovery}: Inferring causal structures from data rather
than just extracting from text

\textbf{Experimental integration}: Connecting models to empirical
results from AI safety experiments

\textbf{Dynamic updating}: Continuous model refinement as new evidence
emerges from research and deployment

\textbf{Uncertainty quantification}: Richer representation of deep
uncertainty and model confidence

\textcite{babakov2025}, \textcite{ban2023}, \textcite{bethard2007},
\textcite{chen2023}, \textcite{duhem1954}, \textcite{heinze-deml2018},
\textcite{meyer2022b}, \textcite{squires2023}, \textcite{squires2023},
\textcite{yang2022}

\subsection*{4.7.3 Application Domains}\label{sec-application-future}
\addcontentsline{toc}{subsection}{4.7.3 Application Domains}

\textbf{Beyond AI safety}: Climate risk, biosecurity, nuclear policy,
and other existential risks

\textbf{Corporate governance}: Strategic planning, risk management, and
innovation assessment

\textbf{Scientific modeling}: Formalizing theoretical arguments in
emerging fields

\textbf{Educational tools}: Teaching probabilistic reasoning and
critical thinking

\subsection*{4.7.4 Ecosystem Development}\label{sec-ecosystem-future}
\addcontentsline{toc}{subsection}{4.7.4 Ecosystem Development}

\textbf{Open standards}: Common formats for model exchange and tool
interoperability

\textbf{Community platforms}: Collaborative model development and
sharing infrastructure

\textbf{Training programs}: Building capacity for formal modeling in
governance communities

\textbf{Quality assurance}: Certification processes for high-stakes
model applications

These directions could transform AMTAIR from a single tool into a
broader ecosystem for enhanced reasoning about complex risks.

\section*{4.8 Known Unknowns and Deep
Uncertainties}\label{sec-deep-uncertainties}
\addcontentsline{toc}{section}{4.8 Known Unknowns and Deep
Uncertainties}

\markright{4.8 Known Unknowns and Deep Uncertainties}

While AMTAIR enhances reasoning under uncertainty, fundamental
limitations remain regarding truly novel developments that might fall
outside existing conceptual frameworks.

\subsection*{4.8.1 Categories of Deep
Uncertainty}\label{sec-uncertainty-categories}
\addcontentsline{toc}{subsection}{4.8.1 Categories of Deep Uncertainty}

\textbf{Novel Capabilities}: Future AI developments may operate
according to principles outside current scientific understanding. No
amount of careful modeling can anticipate fundamental paradigm shifts in
what intelligence can accomplish.

\textbf{Emergent Behaviors}: Complex system properties that resist
prediction from component analysis may dominate outcomes. The
interaction between advanced AI systems and human society could produce
wholly unexpected dynamics.

\textbf{Strategic Interactions}: Game-theoretic dynamics with superhuman
AI systems exceed human modeling capacity. We cannot reliably predict
how entities smarter than us will behave strategically.

\textbf{Social Transformation}: Unprecedented social and economic
changes may invalidate current institutional assumptions. Our models
assume continuity in basic social structures that AI might fundamentally
alter.

\subsection*{4.8.2 Adaptation Strategies for Deep
Uncertainty}\label{sec-adaptation-strategies}
\addcontentsline{toc}{subsection}{4.8.2 Adaptation Strategies for Deep
Uncertainty}

Rather than pretending to model the unmodelable, AMTAIR incorporates
several strategies:

\textbf{Model Architecture Flexibility}: The modular structure enables
rapid incorporation of new variables as novel factors become apparent.
When surprises occur, models can be updated rather than discarded.

\textbf{Explicit Uncertainty Tracking}: Confidence levels for each model
component make clear where knowledge is solid versus speculative. This
prevents false confidence in highly uncertain domains.

\textbf{Scenario Branching}: Multiple model variants capture different
assumptions about fundamental uncertainties. Rather than committing to
one worldview, the system maintains portfolios of possibilities.

\textbf{Update Mechanisms}: Integration with prediction markets and
expert assessment enables rapid model revision as new information
emerges. Models evolve rather than remaining static.

\subsection*{4.8.3 Robust Decision-Making
Principles}\label{sec-robust-principles}
\addcontentsline{toc}{subsection}{4.8.3 Robust Decision-Making
Principles}

Given deep uncertainty, certain decision principles become paramount:

\textbf{Option Value Preservation}: Policies should maintain flexibility
for future course corrections rather than locking in irreversible
choices based on current models.

\textbf{Portfolio Diversification}: Multiple approaches hedging across
different uncertainty sources provide robustness against model error.

\textbf{Early Warning Systems}: Monitoring for developments that would
invalidate current models enables rapid response when assumptions break
down.

\textbf{Adaptive Governance}: Institutional mechanisms must enable rapid
response to new information rather than rigid adherence to plans based
on outdated models.

The goal is not to eliminate uncertainty but to make good decisions
despite it. AMTAIR provides tools for systematic reasoning about what we
do know while maintaining appropriate humility about what we don't and
can't know.

These limitations and considerations do not diminish AMTAIR's value but
rather clarify its proper role: a tool for enhancing coordination and
decision-making under uncertainty, not a crystal ball for predicting the
future. With realistic expectations about capabilities and limitations,
we can now examine the concrete contributions and future directions for
this research. The concluding chapter summarizes key findings and charts
a path forward for computational approaches to AI governance.

\bookmarksetup{startatroot}

\chapter*{5. Conclusion: Toward Coordinated AI
Governance}\label{sec-conclusion}
\addcontentsline{toc}{chapter}{5. Conclusion: Toward Coordinated AI
Governance}

\markboth{5. Conclusion: Toward Coordinated AI Governance}{5.
Conclusion: Toward Coordinated AI Governance}

\begin{tcolorbox}[enhanced jigsaw, arc=.35mm, titlerule=0mm, breakable, toprule=.15mm, toptitle=1mm, colframe=quarto-callout-note-color-frame, coltitle=black, bottomrule=.15mm, bottomtitle=1mm, opacityback=0, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Chapter Overview}, rightrule=.15mm, leftrule=.75mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, opacitybacktitle=0.6, left=2mm]

\textbf{Grade Weight}: 10\% \textbar{} \textbf{Target Length}:
\textasciitilde14\% of text (\textasciitilde4,200 words)\\
\textbf{Requirements}: Summarizes thesis and argument, outlines
implications, notes limitations, points to future research

\end{tcolorbox}

\section*{5.1 Summary of Key Contributions}\label{sec-key-contributions}
\addcontentsline{toc}{section}{5.1 Summary of Key Contributions}

\markright{5.1 Summary of Key Contributions}

This thesis has demonstrated both the need for and feasibility of
computational approaches to enhancing coordination in AI governance. The
work makes several distinct contributions across theory, methodology,
and implementation.

\subsection*{5.1.1 Theoretical
Contributions}\label{sec-theoretical-contributions}
\addcontentsline{toc}{subsection}{5.1.1 Theoretical Contributions}

\textbf{Diagnosis of the Coordination Crisis}: I've articulated how
fragmentation across technical, policy, and strategic communities
systematically amplifies existential risk from advanced AI. This framing
moves beyond identifying disagreements to understanding how misaligned
efforts create negative-sum dynamics---safety gaps emerge between
communities, resources are misallocated through duplication and neglect,
and interventions interact destructively.

\textbf{The Multiplicative Benefits Framework}: The combination of
automated extraction, prediction market integration, and formal policy
evaluation creates value exceeding the sum of parts. Automation enables
scale, markets provide empirical grounding, and policy analysis delivers
actionable insights. Together, they address different facets of the
coordination challenge while reinforcing each other's strengths.

\textbf{Epistemic Infrastructure Conception}: Positioning formal models
as epistemic infrastructure reframes the role of technical tools in
governance. Rather than replacing human judgment, computational
approaches provide common languages, shared representations, and
systematic methods for managing disagreement---essential foundations for
coordination under uncertainty.

\subsection*{5.1.2 Methodological
Innovations}\label{sec-methodological-innovations}
\addcontentsline{toc}{subsection}{5.1.2 Methodological Innovations}

\textbf{Two-Stage Extraction Architecture}: Separating structural
extraction (ArgDown) from probability quantification (BayesDown)
addresses key challenges in automated formalization. This modularity
enables human oversight at critical points, supports multiple
quantification methods, allows for unprecedented transparency and
explainability of the entire process, and isolates different types of
errors for targeted improvement.

\textbf{BayesDown as Bridge Representation}: The development of
BayesDown syntax creates a crucial intermediate representation
preserving both narrative accessibility and mathematical precision. This
bridge enables the transformation from qualitative arguments to
quantitative models while maintaining traceability and human
readability.

\textbf{Validation Framework}: The systematic approach to validating
automated extraction---comparing against expert annotations, measuring
multiple accuracy dimensions, and analyzing error patterns---establishes
scientific standards for assessing formalization tools. This framework
can guide future development in this emerging area.

\subsection*{5.1.3 Technical
Achievements}\label{sec-technical-achievements}
\addcontentsline{toc}{subsection}{5.1.3 Technical Achievements}

\textbf{Working Implementation}: AMTAIR demonstrates end-to-end
feasibility from document ingestion through interactive visualization.
The system achieves practically useful accuracy levels: 85\%+ for
structural extraction and 73\% for probability capture on real AI safety
arguments.

\textbf{Scalability Solutions}: Technical approaches for handling
realistic model complexity---hierarchical decomposition, approximate
inference, and progressive visualization---show that computational
limitations need not prevent practical application.

\textbf{Accessibility Design}: The layered interface approach serves
diverse stakeholders without compromising technical depth. Progressive
disclosure, visual encoding, and interactive exploration make formal
models accessible beyond technical specialists.

\subsection*{5.1.4 Empirical Findings}\label{sec-empirical-findings}
\addcontentsline{toc}{subsection}{5.1.4 Empirical Findings}

\textbf{Extraction Feasibility}: The successful extraction of complex
arguments like Carlsmith's model validates the core premise that
implicit formal structures exist in natural language arguments and can
be computationally recovered with reasonable fidelity.

\textbf{Convergence Patterns}: Comparative analysis reveals structural
agreement across repeated extraction even when probability estimates
diverge substantially. This suggests shared understanding of the
understanding causal models, argument structure and worldview despite
parameter disagreements---a foundation for coordination.

\textbf{Intervention Impacts}: Policy evaluation demonstrates how formal
models enable rigorous assessment of governance options. The ability to
quantify risk reduction across scenarios and identify robust strategies
validates the practical value of formalization.

\section*{5.2 Limitations and Honest
Assessment}\label{sec-limitations-assessment}
\addcontentsline{toc}{section}{5.2 Limitations and Honest Assessment}

\markright{5.2 Limitations and Honest Assessment}

Despite these contributions, important limitations constrain current
capabilities and should guide appropriate use.

\subsection*{5.2.1 Technical
Constraints}\label{sec-technical-constraints}
\addcontentsline{toc}{subsection}{5.2.1 Technical Constraints}

\textbf{Extraction Boundaries}: Potential sources of systematic biases
and confounding variables remain. Similar to experts, the automated
system still struggles with implicit and hidden assumptions and complex
conditionals. These limitations necessitate human review for high-stakes
applications.

\textbf{Correlation Handling}: Over simplified Bayesian networks
inadequately represent complex correlations in real systems. While
extensions like copulas and explicit correlation nodes help, fully
capturing interdependencies remains challenging.

\textbf{Computational Scaling}: Very large networks
(\textgreater\textgreater500 nodes) require approximations that may
affect accuracy. As models grow to represent richer phenomena,
computational constraints increasingly bind.

\subsection*{5.2.2 Conceptual
Limitations}\label{sec-conceptual-limitations}
\addcontentsline{toc}{subsection}{5.2.2 Conceptual Limitations}

\textbf{Formalization Trade-offs}: Converting rich arguments to formal
models necessarily loses nuance. While making assumptions explicit
provides value, some unspoken insights may resist clear mathematical
representation.

\textbf{Probability Interpretation}: Deep uncertainty about
unprecedented events challenges probabilistic intuitions. Numbers can
create false precision even when explicitly conditional and uncertain.

\textbf{Social Complexity}: Institutional dynamics, cultural factors,
and political processes influence AI development in ways that purely
causal models struggle to capture.

\subsection*{5.2.3 Practical
Constraints}\label{sec-practical-constraints}
\addcontentsline{toc}{subsection}{5.2.3 Practical Constraints}

\textbf{Adoption Barriers}: Learning curves, institutional inertia, and
resource requirements limit immediate deployment. Even demonstrably
valuable tools face implementation challenges.

\textbf{Maintenance Burden}: Models require updating as arguments evolve
and evidence emerges. Without sustained effort, formal representations
quickly become outdated.

\textbf{Context Dependence}: The approach works best for well-structured
academic arguments. Application to ``fuzzy'' informal discussions,
political speeches, or social media remains challenging.

\section*{5.3 Implications for AI
Governance}\label{sec-governance-implications}
\addcontentsline{toc}{section}{5.3 Implications for AI Governance}

\markright{5.3 Implications for AI Governance}

Despite limitations, AMTAIR's approach offers significant implications
for how AI governance can evolve toward greater coordination and
effectiveness.

\subsection*{5.3.1 Near-Term
Applications}\label{sec-near-term-applications}
\addcontentsline{toc}{subsection}{5.3.1 Near-Term Applications}

\textbf{Research Coordination}: Research organizations can use formal
models to: - Map the landscape of current arguments and identify gaps -
Prioritize investigations targeting high-sensitivity parameters - Build
cumulative knowledge through explicit model updating - Facilitate
collaboration through shared representations

\textbf{Policy Development}: Governance bodies can apply the framework
to: - Evaluate proposals across multiple expert worldviews - Identify
robust interventions effective under uncertainty - Make assumptions
explicit for democratic scrutiny - Track how evidence changes optimal
policies over time

\textbf{Stakeholder Communication}: The visualization and analysis tools
enable: - Clearer communication between technical and policy communities
- Public engagement with complex risk assessments - Board-level
strategic discussions grounded in formal analysis - International
negotiations with explicit shared models

\subsection*{5.3.2 Medium-Term Transformation}\label{sec-medium-term}
\addcontentsline{toc}{subsection}{5.3.2 Medium-Term Transformation}

As adoption spreads, we might see:

\textbf{Epistemic Commons}: Shared repositories of formalized arguments
become reference points for governance discussions, similar to how
economic models inform monetary policy or climate models guide
environmental agreements.

\textbf{Adaptive Governance}: Policies designed with explicit models can
include triggers for reassessment as key parameters change, enabling
responsive governance that avoids both paralysis and recklessness.

\textbf{Professionalization}: ``Model curator'' and ``argument
formalization specialist'' emerge as recognized roles, building
expertise in bridging natural language and formal representations.

\textbf{Quality Standards}: Community norms develop around model
transparency, validation requirements, and appropriate use cases,
preventing both dismissal and over-reliance on formal tools.

\subsection*{5.3.3 Long-Term Vision}\label{sec-long-term-vision}
\addcontentsline{toc}{subsection}{5.3.3 Long-Term Vision}

Successfully scaling this approach could fundamentally alter AI
governance:

\textbf{Coordinated Response}: Rather than fragmented efforts, the AI
safety ecosystem could operate with shared situational
awareness---different actors understanding how their efforts interact
and contribute to collective goals.

\textbf{Anticipatory Action}: Formal models with prediction market
integration could provide early warning of emerging risks, enabling
proactive rather than reactive governance.

\textbf{Global Cooperation}: Shared formal frameworks could facilitate
international coordination similar to how economic models enable
monetary coordination or climate models support environmental
agreements.

\textbf{Democratic Enhancement}: Making expert reasoning transparent and
modifiable could enable broader participation in crucial decisions about
humanity's technological future.

\section*{5.4 Recommendations for
Stakeholders}\label{sec-recommendations}
\addcontentsline{toc}{section}{5.4 Recommendations for Stakeholders}

\markright{5.4 Recommendations for Stakeholders}

Different communities can take concrete steps to realize these benefits:

\subsection*{5.4.1 For
Researchers}\label{sec-researcher-recommendations}
\addcontentsline{toc}{subsection}{5.4.1 For Researchers}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Experiment with formalization}: Try extracting your own
  arguments into ArgDown/BayesDown format to discover implicit
  assumptions
\item
  \textbf{Contribute to validation}: Provide expert annotations for
  building benchmark datasets and improving extraction quality
\item
  \textbf{Develop extensions}: Build on the open-source foundation to
  add capabilities for your specific domain needs
\item
  \textbf{Publish formally}: Include formal model representations
  alongside traditional papers to enable cumulative building
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, arc=.35mm, titlerule=0mm, breakable, toprule=.15mm, toptitle=1mm, colframe=quarto-callout-tip-color-frame, coltitle=black, bottomrule=.15mm, bottomtitle=1mm, opacityback=0, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Quick Start Guide}, rightrule=.15mm, leftrule=.75mm, colback=white, colbacktitle=quarto-callout-tip-color!10!white, opacitybacktitle=0.6, left=2mm]

A comprehensive guide for researchers getting started with AMTAIR will
be available at {[}project website{]}, including templates, tutorials,
and example extractions.

\end{tcolorbox}

\subsection*{5.4.2 For
Policymakers}\label{sec-policymaker-recommendations}
\addcontentsline{toc}{subsection}{5.4.2 For Policymakers}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Pilot applications}: Use AMTAIR for internal analysis of
  specific policy proposals to build familiarity and identify value
\item
  \textbf{Demand transparency}: Request formal models underlying expert
  recommendations to understand assumptions and uncertainties
\item
  \textbf{Fund development}: Support tool development and training to
  build governance capacity for formal methods
\item
  \textbf{Design adaptively}: Create policies with explicit triggers
  based on model parameters to enable responsive governance
\end{enumerate}

\subsection*{5.4.3 For
Technologists}\label{sec-technologist-recommendations}
\addcontentsline{toc}{subsection}{5.4.3 For Technologists}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Improve extraction}: Contribute better prompting strategies,
  fine-tuned models, or validation methods
\item
  \textbf{Enhance interfaces}: Develop visualizations and interactions
  serving specific stakeholder needs
\item
  \textbf{Build integrations}: Connect AMTAIR to other tools in the AI
  governance ecosystem
\item
  \textbf{Scale infrastructure}: Address computational challenges for
  larger models and broader deployment
\end{enumerate}

\subsection*{5.4.4 For Funders}\label{sec-funder-recommendations}
\addcontentsline{toc}{subsection}{5.4.4 For Funders}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Support ecosystem}: Fund not just tool development but
  training, community building, and maintenance
\item
  \textbf{Bridge communities}: Incentivize collaborations between formal
  modelers and domain experts
\item
  \textbf{Measure coordination}: Develop metrics for assessing
  coordination improvements from formal tools
\item
  \textbf{Patient capital}: Recognize that epistemic infrastructure
  requires sustained investment to reach potential
\end{enumerate}

\section*{5.5 Future Research Agenda}\label{sec-future-research-agenda}
\addcontentsline{toc}{section}{5.5 Future Research Agenda}

\markright{5.5 Future Research Agenda}

Building on this foundation, several research directions could amplify
impact:

\subsection*{5.5.1 Technical Priorities}\label{sec-technical-priorities}
\addcontentsline{toc}{subsection}{5.5.1 Technical Priorities}

\textbf{Extraction Enhancement}: - Fine-tuning language models
specifically for argument extraction - Handling implicit reasoning and
long-range dependencies - Cross-document synthesis for comprehensive
models - Multilingual extraction for global perspectives

\textbf{Representation Extensions}: - Temporal dynamics for modeling AI
development trajectories - Multi-agent representations for strategic
interactions - Continuous variables for economic and capability metrics
- Uncertainty types beyond probability distributions

\textbf{Integration Depth}: - Semantic matching between models and
prediction markets - Automated experiment design based on model
sensitivity - Policy optimization algorithms using extracted models -
Real-time updating from news and research feeds

\subsection*{5.5.2 Methodological
Development}\label{sec-methodological-development}
\addcontentsline{toc}{subsection}{5.5.2 Methodological Development}

\textbf{Validation Science}: - Larger benchmark datasets with diverse
argument types - Metrics for semantic preservation beyond accuracy -
Adversarial robustness testing protocols - Longitudinal studies of model
evolution

\textbf{Hybrid Approaches}: - Optimal human-AI collaboration patterns
for extraction - Combining formal models with other methods (scenarios,
simulations) - Integration with deliberative and participatory processes
- Balancing automation with expert judgment

\textbf{Social Methods}: - Ethnographic studies of model use in
organizations - Measuring coordination improvements empirically -
Understanding adoption barriers and facilitators - Designing
interventions for epistemic security

\subsection*{5.5.3 Application
Expansion}\label{sec-application-expansion}
\addcontentsline{toc}{subsection}{5.5.3 Application Expansion}

\textbf{Domain Extensions}: - Biosecurity governance and pandemic
preparedness - Cyber risk assessment and policy evaluation - Nuclear
policy and deterrence stability - Emerging technology governance broadly

\textbf{Institutional Integration}: - Embedding in regulatory impact
assessment - Corporate strategic planning applications - Academic peer
review enhancement - Democratic deliberation support tools

\textbf{Global Deployment}: - Adapting to different governance contexts
- Supporting multilateral negotiation processes - Building capacity in
developing nations - Creating resilient distributed infrastructure

\section*{5.6 Closing Reflections}\label{sec-closing-reflections}
\addcontentsline{toc}{section}{5.6 Closing Reflections}

\markright{5.6 Closing Reflections}

The work presented in this thesis emerges from a simple observation:
while humanity mobilizes unprecedented resources to address AI risks,
our efforts remain tragically uncoordinated. Different communities work
with incompatible frameworks, duplicate efforts, and sometimes actively
undermine each other's work. This fragmentation amplifies the very risks
we seek to mitigate.

AMTAIR represents one attempt to build bridges---computational tools
that create common ground for disparate perspectives. By making implicit
models explicit, quantifying uncertainty, and enabling systematic policy
analysis, these tools offer hope for enhanced coordination. The
successful extraction of complex arguments, validation against expert
judgment, and demonstration of policy evaluation capabilities suggest
this approach has merit.

Yet tools alone cannot solve coordination problems rooted in incentives,
institutions, and human psychology. AMTAIR provides infrastructure for
coordination, not coordination itself. Success requires not just
technical development but changes in how we approach collective
challenges---valuing transparency over strategic ambiguity, embracing
uncertainty rather than false confidence, and prioritizing collective
outcomes over parochial interests.

The path forward demands both ambition and humility. Ambition to build
the epistemic infrastructure necessary for navigating unprecedented
risks. Humility to recognize our tools' limitations and the irreducible
role of human wisdom in governance. The question is not whether formal
models can replace human judgment---they cannot and should not. Rather,
it's whether we can augment our collective intelligence with
computational tools that help us reason together about futures too
important to leave to chance.

\begin{tcolorbox}[enhanced jigsaw, arc=.35mm, titlerule=0mm, breakable, toprule=.15mm, toptitle=1mm, colframe=quarto-callout-important-color-frame, coltitle=black, bottomrule=.15mm, bottomtitle=1mm, opacityback=0, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{The Stakes}, rightrule=.15mm, leftrule=.75mm, colback=white, colbacktitle=quarto-callout-important-color!10!white, opacitybacktitle=0.6, left=2mm]

As AI capabilities advance toward transformative potential, the window
for establishing effective governance narrows. We cannot afford
continued fragmentation when facing potentially irreversible
consequences. The coordination crisis in AI governance represents both
existential risk and existential opportunity---risk if we fail to align
our efforts, opportunity if we succeed in building unprecedented
cooperation around humanity's most important challenge.

\end{tcolorbox}

This thesis contributes technical foundations and demonstrates
feasibility. The greater work---building communities, changing
practices, and fostering coordination---remains ahead. May we prove
equal to the task, for all our futures depend on it.

\bookmarksetup{startatroot}

\chapter*{References}\label{sec-references}
\addcontentsline{toc}{chapter}{References}

\markboth{References}{References}

\texttt{\{\ embed\ I.Appendices.qmd\ \}}

\section*{AMTAIR Thesis Relevant Literature \&
Citations}\label{amtair-thesis-relevant-literature-citations}
\addcontentsline{toc}{section}{AMTAIR Thesis Relevant Literature \&
Citations}

\markright{AMTAIR Thesis Relevant Literature \& Citations}

\subsection*{Items from MAref.bib}\label{items-from-maref.bib}
\addcontentsline{toc}{subsection}{Items from MAref.bib}

\subsubsection*{\texorpdfstring{\texttt{@carlsmith2021}:
\textcite{carlsmith2021}}{@carlsmith2021: @carlsmith2021}}\label{carlsmith2021-carlsmith2021}
\addcontentsline{toc}{subsubsection}{\texttt{@carlsmith2021}:
\textcite{carlsmith2021}}

\begin{verbatim}
Carlsmith, Joseph (2021)
Is Power-Seeking AI an Existential Risk?

DOI: 10.48550/arXiv.2206.13353

arXiv ID: 2206.13353

Better alternative: None - this is the primary case study

Relevant thesis section(s): 
- Section 2.1: AI Existential Risk: The Carlsmith Model
- Section 3.5: Case Study: Carlsmith's Power-Seeking AI Model
- Throughout as validation example


Potential claims supported (with certainty %):
- "Carlsmith's six-premise decomposition exemplifies structured probabilistic reasoning about AI risk" (95%)
- "The model estimates ~5% existential risk by 2070" (90%)
- "Explicit probability estimates enable formal analysis" (95%)
\end{verbatim}

\subsubsection*{\texorpdfstring{\texttt{@bostrom2014}:
\textcite{bostrom2014}}{@bostrom2014: @bostrom2014}}\label{bostrom2014-bostrom2014}
\addcontentsline{toc}{subsubsection}{\texttt{@bostrom2014}:
\textcite{bostrom2014}}

\begin{verbatim}
Bostrom, Nick (2014)
Superintelligence: Paths, Dangers, Strategies

ISBN: 978-0-19-967811-2

Better alternative: None - foundational text

Relevant thesis section(s):
- Section 1.2: The Coordination Crisis
- Section 2.1: Historical foundations of AI risk
- Background context throughout

Potential claims supported (with certainty %):
- "Orthogonality thesis: intelligence and goals are independent" (95%)
- "Instrumental convergence leads to power-seeking behavior" (90%)
- "Superintelligence poses existential risk" (85%)
\end{verbatim}

\subsubsection*{\texorpdfstring{\texttt{@clarke2022}:
\textcite{clarke2022}}{@clarke2022: @clarke2022}}\label{clarke2022-clarke2022}
\addcontentsline{toc}{subsubsection}{\texttt{@clarke2022}:
\textcite{clarke2022}}

\begin{verbatim}
Clarke, Sam et al. (2022)
Modeling Transformative AI Risks (MTAIR) Project -- Summary Report

DOI: 10.48550/ARXIV.2206.09360

arXiv ID: 2206.09360

Better alternative: None - this is what AMTAIR builds upon

Relevant thesis section(s):
- Section 2.5: The MTAIR Framework: Achievements and Limitations
- Section 1.3: Comparison with AMTAIR automation
- Throughout as predecessor project

Potential claims supported (with certainty %):
- "MTAIR demonstrated value of formal models but required extensive manual effort" (95%)
- "Manual extraction takes 200-400 expert hours per model" (80%)
- "Static models cannot track evolving arguments" (90%)
\end{verbatim}

\subsubsection*{\texorpdfstring{\texttt{@pearl2009} and
\texttt{@pearl2000}: \textcite{pearl2000} and
\textcite{pearl2009}}{@pearl2009 and @pearl2000: @pearl2000 and @pearl2009}}\label{pearl2009-and-pearl2000-pearl2000-and-pearl2009}
\addcontentsline{toc}{subsubsection}{\texttt{@pearl2009} and
\texttt{@pearl2000}: \textcite{pearl2000} and \textcite{pearl2009}}

\begin{verbatim}
Pearl, Judea (2009)
Causality: Models, Reasoning and Inference (2nd Edition)

ISBN: 978-0-521-89560-6

DOI: 10.1017/CBO9780511803161

Better alternative: None - theoretical foundation

Relevant thesis section(s):
- Section 2.3: Bayesian Networks as Knowledge Representation
- Section 2.7.4: DAG structure and causal semantics
- Section 3.7.1: Do-calculus for policy interventions

Potential claims supported (with certainty %):
- "Bayesian networks enable causal reasoning under uncertainty" (95%)
- "Do-calculus allows formal policy evaluation" (95%)
- "DAGs encode conditional independence assumptions" (95%)
\end{verbatim}

\subsubsection*{\texorpdfstring{\texttt{@jaynes2003}:
\textcite{jaynes2003}}{@jaynes2003: @jaynes2003}}\label{jaynes2003-jaynes2003}
\addcontentsline{toc}{subsubsection}{\texttt{@jaynes2003}:
\textcite{jaynes2003}}

\begin{verbatim}
Jaynes, Edwin T. (2003)
Probability Theory: The Logic of Science

ISBN: 978-0-521-59271-0

DOI: 10.1017/CBO9780511790423

Better alternative: None for foundational probability theory

Relevant thesis section(s):
- Section 2.3: Mathematical foundations of Bayesian inference
- Section 2.7.5: Probability as extended logic
- Epistemological grounding throughout

Potential claims supported (with certainty %):
- "Probability theory extends deductive logic to handle uncertainty" (95%)
- "Bayesian inference provides principled belief updating" (95%)
- "Maximum entropy principles handle missing information" (90%)
\end{verbatim}

\subsubsection*{\texorpdfstring{\texttt{@tetlock2015}:
\textcite{tetlock2015}}{@tetlock2015: @tetlock2015}}\label{tetlock2015-tetlock2015}
\addcontentsline{toc}{subsubsection}{\texttt{@tetlock2015}:
\textcite{tetlock2015}}

\begin{verbatim}
Tetlock, Philip E. and Gardner, Dan (2015)
Superforecasting: The Art and Science of Prediction

ISBN: 978-0-8041-3671-6

Better alternative: @tetlock2023 for more recent long-range forecasting

Relevant thesis section(s):
- Section 1.5.2: Live Data Integration
- Section 3.9: Integration with Prediction Markets
- Forecasting methodology context

Potential claims supported (with certainty %):
- "Aggregated forecasts outperform individual expert judgment" (90%)
- "Prediction markets provide empirical grounding for models" (85%)
- "Calibrated forecasters achieve measurable accuracy" (90%)
\end{verbatim}

\subsubsection*{\texorpdfstring{\texttt{@lempert2003}:
\textcite{lempert2003}}{@lempert2003: @lempert2003}}\label{lempert2003-lempert2003}
\addcontentsline{toc}{subsubsection}{\texttt{@lempert2003}:
\textcite{lempert2003}}

\begin{verbatim}
Lempert, Robert J., Popper, Steven W., and Bankes, Steven C. (2003)
Shaping the Next One Hundred Years: New Methods for Quantitative, Long-Term Policy Analysis

ISBN: 978-0-8330-3275-8

Better alternative: None for deep uncertainty methods

Relevant thesis section(s):
- Section 2.2.2: Limitations of Traditional Approaches
- Section 4.1.2: Deep uncertainty in AI governance
- Policy evaluation methodology

Potential claims supported (with certainty %):
- "Traditional policy analysis fails under deep uncertainty" (90%)
- "Robust decision-making requires considering multiple scenarios" (85%)
- "AI governance faces irreducible uncertainties" (90%)
\end{verbatim}

\subsubsection*{\texorpdfstring{\texttt{@good1966}:
\textcite{good1966}}{@good1966: @good1966}}\label{good1966-good1966}
\addcontentsline{toc}{subsubsection}{\texttt{@good1966}:
\textcite{good1966}}

\begin{verbatim}
Good, Irving John (1966)
Speculations Concerning the First Ultraintelligent Machine

DOI: 10.1016/S0065-2458(08)60418-0



Relevant thesis section(s):
- Historical context in Introduction
- Background for intelligence explosion concept

Potential claims supported (with certainty %):
- "Intelligence explosion concept dates to 1960s" (95%)
- "Recursive self-improvement could lead to rapid capability gains" (80%)
\end{verbatim}

\subsubsection*{\texorpdfstring{\texttt{@yudkowsky2008}:
\textcite{yudkowsky2008}}{@yudkowsky2008: @yudkowsky2008}}\label{yudkowsky2008-yudkowsky2008}
\addcontentsline{toc}{subsubsection}{\texttt{@yudkowsky2008}:
\textcite{yudkowsky2008}}

\begin{verbatim}
Yudkowsky, Eliezer (2008)
Artificial Intelligence as a Positive and Negative Factor in Global Risk

DOI: 10.1093/oso/9780198570509.003.0021

Better alternative: @yudkowsky2022 for more recent formulation

Relevant thesis section(s):
- Section 2.1: AI risk arguments
- Background on alignment problem
- Instrumental convergence discussion

Potential claims supported (with certainty %):
- "AI alignment is the core challenge for beneficial AI" (90%)
- "Default AI development may produce misaligned systems" (85%)
- "Cognitive biases affect AI risk assessment" (90%)
\end{verbatim}

\subsubsection*{\texorpdfstring{\texttt{@russell2015}:
\textcite{russell2015}}{@russell2015: @russell2015}}\label{russell2015-russell2015}
\addcontentsline{toc}{subsubsection}{\texttt{@russell2015}:
\textcite{russell2015}}

\begin{verbatim}
Russell, Stuart et al. (2015)
Research Priorities for Robust and Beneficial Artificial Intelligence: An Open Letter

DOI: 10.1609/aimag.v36i4.2621

Better alternative: None - important consensus document

Relevant thesis section(s):
- Introduction: AI safety research mobilization
- Context for coordination efforts

Potential claims supported (with certainty %):
- "AI safety has gained mainstream research attention" (95%)
- "Technical and governance challenges are interrelated" (90%)
\end{verbatim}

\section*{New Suggested Citations}\label{new-suggested-citations}
\addcontentsline{toc}{section}{New Suggested Citations}

\markright{New Suggested Citations}

\subsection*{New Items to Consider:}\label{new-items-to-consider}
\addcontentsline{toc}{subsection}{New Items to Consider:}

\subsubsection*{\texorpdfstring{\texttt{@amodei2016}:
\textcite{amodei2016}}{@amodei2016: @amodei2016}}\label{amodei2016-amodei2016}
\addcontentsline{toc}{subsubsection}{\texttt{@amodei2016}:
\textcite{amodei2016}}

\begin{verbatim}
Amodei, Dario et al. (2016)
Concrete Problems in AI Safety

arXiv ID: 1606.06565

Relevant thesis section(s):
- Section 2.2: Technical safety challenges
- Concrete problems motivating AMTAIR

Potential claims supported (with certainty %):
- "AI safety includes avoiding negative side effects, safe exploration" (95%)
- "Current ML systems exhibit safety failures" (90%)
\end{verbatim}

\subsubsection*{\texorpdfstring{\texttt{@christiano2019}:
\textcite{christiano2019}}{@christiano2019: @christiano2019}}\label{christiano2019-christiano2019}
\addcontentsline{toc}{subsubsection}{\texttt{@christiano2019}:
\textcite{christiano2019}}

\begin{verbatim}
Christiano, Paul (2019)
What Failure Looks Like

URL: https://www.alignmentforum.org/posts/HBxe6wdjxK239zajf/what-failure-looks-like

Relevant thesis section(s):
- Additional case study for extraction
- Alternative risk model to Carlsmith

Potential claims supported (with certainty %):
- "AI risk may manifest through gradual loss of control" (85%)
- "Multiple pathways to existential risk exist" (90%)
\end{verbatim}

\subsubsection*{\texorpdfstring{\texttt{@critch2019}:
\textcite{critch2019}}{@critch2019: @critch2019}}\label{critch2019-critch2019}
\addcontentsline{toc}{subsubsection}{\texttt{@critch2019}:
\textcite{critch2019}}

\begin{verbatim}
Critch, Andrew (2019)
ARCHES: AI Research Considerations for Human Existential Safety

URL: https://arxiv.org/abs/2006.04948

Relevant thesis section(s):
- Another structured model for extraction validation
- Multi-stakeholder coordination framework

Potential claims supported (with certainty %):
- "AI safety requires coordination across multiple sectors" (90%)
- "Research, deployment, and governance interact complexly" (85%)
\end{verbatim}

\subsubsection*{\texorpdfstring{\texttt{@dafoe2018} and updated
\texttt{@dafoe2021}: \textcite{dafoe2021} and
\textcite{dafoe2018}}{@dafoe2018 and updated @dafoe2021: @dafoe2021 and @dafoe2018}}\label{dafoe2018-and-updated-dafoe2021-dafoe2021-and-dafoe2018}
\addcontentsline{toc}{subsubsection}{\texttt{@dafoe2018} and updated
\texttt{@dafoe2021}: \textcite{dafoe2021} and \textcite{dafoe2018}}

\begin{verbatim}
Dafoe, Allan (2021)
AI Governance: A Research Agenda

URL: https://www.fhi.ox.ac.uk/govaiagenda/

Relevant thesis section(s):
- Section 2.6.2: Governance proposals taxonomy
- Context for policy evaluation needs

Potential claims supported (with certainty %):
- "AI governance requires interdisciplinary approaches" (95%)
- "Technical and policy communities need better coordination" (90%)
\end{verbatim}

\subsubsection*{\texorpdfstring{\texttt{@askell2021}:
\textcite{askell2021}}{@askell2021: @askell2021}}\label{askell2021-askell2021}
\addcontentsline{toc}{subsubsection}{\texttt{@askell2021}:
\textcite{askell2021}}

\begin{verbatim}
Askell, Amanda et al. (2021)
A General Language Assistant as a Laboratory for Alignment

arXiv ID: 2112.00861

Relevant thesis section(s):
- LLM capabilities for extraction tasks
- Alignment considerations for AMTAIR

Potential claims supported (with certainty %):
- "Language models can assist in complex reasoning tasks" (90%)
- "Alignment challenges manifest in current systems" (85%)
\end{verbatim}

\section*{Further Citations to
Integrate:}\label{further-citations-to-integrate}
\addcontentsline{toc}{section}{Further Citations to Integrate:}

\markright{Further Citations to Integrate:}

\subsection*{\texorpdfstring{\textcite{growiec2024}}{@growiec2024}}\label{growiec2024}
\addcontentsline{toc}{subsection}{\textcite{growiec2024}}

\textcite{clarke2022}

\textcite{drexler2019} and \textcite{drexler2019a}

\textcite{brundage2018} and \textcite{brundage2018a}

\textcite{kumar2019} and \textcite{kumar2019a}

\textcite{carlsmith2021} and \textcite{carlsmith2022} and
\textcite{carlsmith2024}

\textcite{hendrycks2021} and \textcite{hendrycks2021a}

\textcite{wilson2023}

\textcite{kilian2023}

\textcite{kulveit2025}

\textcite{hadshar2023}

\textcite{kasirzadeh2024}

\textcite{sotala2018}

Claimify: \textcite{metropolitansky2025}

Bayes Server:

\textcite{bayes2025}

MTAIR:

\textcite{martin2023}

\textcite{manheim2021}

\textcite{riceissa2021}

\textcite{eth2021}

\textcite{martin2021}

\textcite{cottier2021}

\textcite{cottier2021}

\textcite{cottier2021b}

\textcite{davidmanheim2021a}

Analytica:

\textcite{lumina2025}

\bookmarksetup{startatroot}

\chapter*{CURRENT Bibliography}\label{current-bibliography}
\addcontentsline{toc}{chapter}{CURRENT Bibliography}

\markboth{CURRENT Bibliography}{CURRENT Bibliography}

\begin{verbatim}
Amodei, Dario, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, and Dan Mané. 2016. “Concrete Problems in AI Safety.” July 25, 2016. https://doi.org/10.48550/arXiv.1606.06565.
Anderson, Terence J. 2007. “Visualization Tools and Argument Schemes: A Question of Standpoint.” Law, Prob. & Risk 6: 97. https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/lawprisk6&section=9.
Armstrong, Stuart, Nick Bostrom, and Carl Shulman. 2016. “Racing to the Precipice: A Model of Artificial Intelligence Development.” AI & SOCIETY 31 (2): 201–6. https://doi.org/10.1007/s00146-015-0590-y.
Askell, Amanda, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, et al. 2021. “A General Language Assistant as a Laboratory for Alignment.” December 9, 2021. https://doi.org/10.48550/arXiv.2112.00861.
Babakov, Nikolay, Adarsa Sivaprasad, Ehud Reiter, and Alberto Bugarín-Diz. 2025. “Reusability of Bayesian Networks Case Studies: A Survey.” Applied Intelligence 55 (6): 417. https://doi.org/10.1007/s10489-025-06289-5.
Ban, Taiyu, Lyuzhou Chen, Derui Lyu, Xiangyu Wang, and Huanhuan Chen. 2023. “Causal Structure Learning Supervised by Large Language Model.” November 20, 2023. https://doi.org/10.48550/arXiv.2311.11689.
Bayes, Server. 2025. “Risk Modeling with Bayesian Networks | Bayes Server.” https://online.bayesserver.com/. https://bayesserver.com/docs/modeling/risk/.
Benn, Neil, and Ann Macintosh. 2011. “Argument Visualization for eParticipation: Towards a Research Agenda and Prototype Tool.” In Electronic Participation, edited by Efthimios Tambouris, Ann Macintosh, and Hans De Bruijn, 6847:60–73. Berlin, Heidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-23333-3_6.
Bethard, Steven John. 2007. “Finding Event, Temporal and Causal Structure in Text: A Machine Learning Approach.” PhD thesis, University of Colorado at Boulder. https://search.proquest.com/openview/405fe32503123d9b5f4836dc3be4c011/1?pq-origsite=gscholar&cbl=18750.
Bostrom, Nick. 2014. Superintelligence: Paths, Strategies, Dangers. Oxford: Oxford University Press. https://scholar.dominican.edu/cynthia-stokes-brown-books-big-history/47.
Box, George E. P. 1976. “Science and Statistics.” Journal of the American Statistical Association 71 (356): 791–99. https://doi.org/10.1080/01621459.1976.10480949.
Brundage, Miles, Shahar Avin, Jack Clark, Helen Toner, Peter Eckersley, Ben Garfinkel, Allan Dafoe, Paul Scharre, Thomas Zeitzoff, Bobby Filar, Hyrum Anderson, et al. 2018. “The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation.” 2018. https://doi.org/10.48550/ARXIV.1802.07228.
Brundage, Miles, Shahar Avin, Jack Clark, Helen Toner, Peter Eckersley, Ben Garfinkel, Allan Dafoe, Paul Scharre, Thomas Zeitzoff, and Bobby Filar. 2018. “The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation.” https://arxiv.org/abs/1802.07228.
Carlsmith, Joseph. 2021. “Is Power-Seeking AI an Existential Risk?” 2021. https://doi.org/10.48550/arXiv.2206.13353.
———. 2022. “Is Power-Seeking AI an Existential Risk?” https://arxiv.org/abs/2206.13353.
———. 2024. “Is Power-Seeking AI an Existential Risk?” August 13, 2024. https://doi.org/10.48550/arXiv.2206.13353.
Chen, Lu, Ruqing Zhang, Wei Huang, Wei Chen, Jiafeng Guo, and Xueqi Cheng. 2023. “Inducing Causal Structure for Abstractive Text Summarization.” In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management, 213–23. Birmingham United Kingdom: ACM. https://doi.org/10.1145/3583780.3614934.
Christiano, Paul F. 2019. “What Failure Looks Like,” March. https://www.alignmentforum.org/posts/HBxe6wdjxK239zajf/what-failure-looks-like.
Clarke, Sam, Ben Cottier, Aryeh Englander, Daniel Eth, David Manheim, Samuel Dylan Martin, and Issa Rice. 2022. “Modeling Transformative AI Risks (MTAIR) Project – Summary Report.” 2022. https://doi.org/10.48550/ARXIV.2206.09360.
Cottier, Ben. 2021. “Modeling Risks From Learned Optimization,” October. https://www.lesswrong.com/posts/T9oFjteStcE2ijCJi/modeling-risks-from-learned-optimization.
Cottier, Ben, Daniel Eth, and Sammy Martin. 2021. “Modeling Failure Modes of High-Level Machine Intelligence,” December. https://www.lesswrong.com/posts/3Eq5Rq5uQ97kt8B8f/modeling-failure-modes-of-high-level-machine-intelligence.
Cuomo, Francesca, Christine Mallin, and Alessandro Zattoni. 2016. “Corporate Governance Codes: A Review and Research Agenda.” Corporate Governance: An International Review 24 (3): 222–41. https://ueaeprints.uea.ac.uk/id/eprint/57664/.
Dafoe, Allan. 2018. “AI Governance: A Research Agenda.” Governance of AI Program, Future of Humanity Institute, University of Oxford: Oxford, UK 1442: 1443. https://www.fhi.ox.ac.uk/wp-content/uploads/GovAI-Agenda.pdf.
———. 2021. “AI Governance: A Research Agenda.” 2021. https://www.fhi.ox.ac.uk/wp-content/uploads/GovAI-Agenda.pdf.
Davidmanheim, David. 2021. “Elicitation for Modeling Transformative AI Risks,” December. https://www.lesswrong.com/posts/Kz9NHBMeJxzSwb7R9/elicitation-for-modeling-transformative-ai-risks.
De Villiers, Charl, and Ruth Dimes. 2021. “Determinants, Mechanisms and Consequences of Corporate Governance Reporting: A Research Framework.” Journal of Management and Governance 25 (1): 7–26. https://doi.org/10.1007/s10997-020-09530-0.
Demirag, Istemi, Sudi Sudarsanam, and MIKE WRIGHT. 2000. “Corporate Governance: Overview and Research Agenda.” The British Accounting Review 32 (4): 341–54. https://www.academia.edu/download/49469624/bare.2000.014620161009-3955-1dt4aq5.pdf.
Di Vito, Jackie, and Kim Trottier. 2022. “A Literature Review on Corporate Governance Mechanisms: Past, Present, and Future*.” Accounting Perspectives 21 (2): 207–35. https://doi.org/10.1111/1911-3838.12279.
Drexler, K. Eric. 2019. “Reframing Superintelligence: Comprehensive AI Services as General Intelligence.”
Drexler, KE. 2019. “Reframing Superintelligence: Comprehensive AI Services as General Intelligence.” Technical Report. Future of Humanity Institute. https://owainevans.github.io/pdfs/Reframing_Superintelligence_FHI-TR-2019.pdf.
Duhem, Pierre Maurice Marie. 1954. The Aim and Structure of Physical Theory. 1. Princeton University Press.
Eth, Daniel. 2021. “Paths To High-Level Machine Intelligence,” September. https://www.lesswrong.com/posts/amK9EqxALJXyd9Rb2/paths-to-high-level-machine-intelligence.
European, Union. 2024. “The Act Texts | EU Artificial Intelligence Act.” 2024. https://artificialintelligenceact.eu/the-act/.
Good, Irving John. 1966. “Speculations Concerning the First Ultraintelligent Machine.” Advances in Computers, 31. https://doi.org/10.1016/S0065-2458(08)60418-0.
Growiec, Jakub. 2024. “Existential Risk from Transformative AI: An Economic Perspective.” Technological and Economic Development of Economy 30 (6): 1682–1708.
Gruetzemacher, Ross. 2022. “Bayesian Networks Vs. Conditional Trees for Creating Questions for Forecasting Tournaments.”
Hadshar, Rose. 2023. “A Review of the Evidence for Existential Risk from AI via Misaligned Power-Seeking.” 2023. https://doi.org/10.48550/ARXIV.2310.18244.
Hallegatte, Stéphane, Ankur Shah, Robert Lempert, Casey Brown, and Stuart Gill. 2012. “Investment Decision-Making Under Deep Uncertainty-Application to Climate Change.” Policy Research Working Paper 6193. https://enpc.hal.science/hal-00802049/document.
Heinze-Deml, Christina, Marloes H. Maathuis, and Nicolai Meinshausen. 2018. “Causal Structure Learning.” Annual Review of Statistics and Its Application 5 (1): 371–91. https://doi.org/10.1146/annurev-statistics-031017-100630.
Hendrycks, Dan, Nicholas Carlini, John Schulman, and Jacob Steinhardt. 2021a. “Unsolved Problems in ML Safety.” 2021. https://doi.org/10.48550/ARXIV.2109.13916.
———. 2021b. “Unsolved Problems in Ml Safety.” https://arxiv.org/abs/2109.13916.
Hunt, Tam. 2025. “The Insane ‘Logic’ of the AI Arms Race.” Medium. March 3, 2025. https://tamhunt.medium.com/the-insane-logic-of-the-ai-arms-race-45a5f79f4c0e.
Jaynes, Edwin T. 2003. Probability Theory: The Logic of Science. Cambridge university press.
Kasirzadeh, Atoosa. 2024. “Two Types of AI Existential Risk: Decisive and Accumulative.” 2024. https://doi.org/10.48550/ARXIV.2401.07836.
Kaur, Kawaljit. 2024. “Corporate Governance and Legal Accountability: A Critical Review of Global Practices.” Journal of Law 2 (6): 1–7. https://joi.shodhsagar.org/index.php/SSJOI/article/view/16.
Khartabil, Dana. 2020. “Visualisation Techniques to Facilitate Argument Exploration.” PhD thesis. https://napier-repository.worktribe.com/output/2694675.
Khartabil, D., C. Collins, S. Wells, B. Bach, and J. Kennedy. 2021. “Design and Evaluation of Visualization Techniques to Facilitate Argument Exploration.” Computer Graphics Forum 40 (6): 447–65. https://doi.org/10.1111/cgf.14389.
Kilian, Kyle A., Christopher J. Ventura, and Mark M. Bailey. 2023. “Examining the Differential Risk from High-level Artificial Intelligence and the Question of Control.” Futures 151 (August): 103182. https://doi.org/10.1016/j.futures.2023.103182.
Koller, Daphne, and Nir Friedman. 2009. Probabilistic Graphical Models: Principles and Techniques. MIT press. https://books.google.ca/books?hl=en&lr=&id=7dzpHCHzNQ4C&oi=fnd&pg=PR9&dq=Koller,+D.,+%26+Friedman,+N.+(2009).+Probabilistic+Graphical+Models&ots=py2HAh0VAL&sig=gpaID3x6-TY8x5SOopuXpZDXfzs.
Kulveit, Jan, Raymond Douglas, Nora Ammann, Deger Turan, David Krueger, and David Duvenaud. 2025. “Gradual Disempowerment: Systemic Existential Risks from Incremental AI Development.” January 29, 2025. https://doi.org/10.48550/arXiv.2501.16946.
Kumar, Ram Shankar Siva, David O. Brien, Kendra Albert, Salomé Viljöen, and Jeffrey Snover. 2019a. “Failure Modes in Machine Learning Systems.” https://arxiv.org/abs/1911.11034.
Kumar, Ram Shankar Siva, David O Brien, Kendra Albert, Salomé Viljöen, and Jeffrey Snover. 2019b. “Failure Modes in Machine Learning Systems.” 2019. https://doi.org/10.48550/ARXIV.1911.11034.
Lempert, Robert J, Steven W Popper, and Steven C Bankes. 2003. Shaping the Next One Hundred Years: New Methods for Quantitative, Long-Term Policy Analysis. RAND Corporation.
Lindley, Dennis V. 2013. Understanding Uncertainty. John Wiley & Sons. https://books.google.ca/books?hl=en&lr=&id=Tfk8AgAAQBAJ&oi=fnd&pg=PR11&dq=Lindley,+D.+(2006).+Understanding+Uncertainty&ots=55HS6lTOVP&sig=0gKCDvRu5rUKhuPyJqhOzW23upU.
List, Christian, and Philip Pettit. 2011. Group Agency: The Possibility, Design, and Status of Corporate Agents. Oxford University Press.
Lumina, Decision Systems. 2025. “Analytica Online.” 2025. https://acp.analytica.com/view0?invite=4560&code=3000289064591444815.
Manheim, David. 2021. “Modeling Transformative AI Risk (MTAIR) - LessWrong.” July 28, 2021. https://www.lesswrong.com/s/aERZoriyHfCqvWkzg.
Martin, Sammy, Lonnie Chrisman, and Aryeh Englander. 2023. “A Model-based Approach to AI Existential Risk,” August. https://www.lesswrong.com/posts/sGkRDrpphsu6Jhega/a-model-based-approach-to-ai-existential-risk.
Martin, Sammy, and Daniel Eth. 2021. “Takeoff Speeds and Discontinuities,” September. https://www.lesswrong.com/posts/pGXR2ynhe5bBCCNqn/takeoff-speeds-and-discontinuities.
Maslej, Nestor. 2025. “Artificial Intelligence Index Report 2025.” Artificial Intelligence.
McCaslin, Tegan, Josh Rosenberg, Ezra Karger, Avital Morris, Molly Hickman, Sam Glover, Zach Jacobs, and Phil Tetlock. 2024. “Conditional Trees: A Method for Generating Informative Questions about Complex Topics.” Forecasting Research Institute. https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/66ba37a144f1d6095de467df/1723479995772/AIConditionalTrees.pdf.
Metropolitansky, Dasha, and Jonathan Larson. 2025. “Towards Effective Extraction and Evaluation of Factual Claims.” February 15, 2025. https://doi.org/10.48550/arXiv.2502.10855.
Meyer, Valentin Jakob. 2022. “A Structure of Knowledge & the Process of Science.” Philosophy of the Social Sciences First Course Paper. https://doi.org/https://www.vjmeyer.com/papers/essays.
Miotti, Andrea, Tolga Bilge, Dave Kasten, and James Newport. 2024. “A Narrow Path.” https://www.narrowpath.co/.
Nelson, Roger B. 2006. An Introduction to Copulas. Springer Series in Statistics. New York, NY: Springer New York. https://doi.org/10.1007/0-387-28678-0.
Ngajie, Berty Nsolly, Yan Li, Dawit Tibebu Tiruneh, and Mengmeng Cheng. 2020. “Investigating the Effects of a Systematic and Model-Based Design of Computer-Supported Argument Visualization on Critical Thinking.” Thinking Skills and Creativity 38: 100742. https://www.sciencedirect.com/science/article/pii/S1871187120302169.
Paul. 2023. “The elephAInt – Are We All Like the Six Blind Men When It Comes to AI? | PRISMAGuard LLC.” 2023. https://www.prismaguard.com/the-elephaint-are-we-all-like-the-six-blind-men-when-it-comes-to-ai/.
Pearl, Judea. 2000. Causality: Models, Reasoning, and Inference. Cambridge, U.K. ; New York: Cambridge University Press.
———. 2009. Causality: Models, Reasoning and Inference. 2nd ed. Cambridge University Press.
———. 2014. Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Elsevier. https://books.google.ca/books?hl=en&lr=&id=mn2jBQAAQBAJ&oi=fnd&pg=PP1&dq=Pearl,+J.+(1988).+Probabilistic+Reasoning+in+Intelligent+Systems&ots=4tEX2A4Ha8&sig=lgUs_RCoeXEEuGwM5xMEoyJy4HI.
Pollock, John L. 1995. Cognitive Carpentry: A Blueprint for How to Build a Person. Mit Press. https://books.google.ca/books?hl=en&lr=&id=JAfHrHTqswAC&oi=fnd&pg=PA1&dq=Pollock,+J.+(1995).+Cognitive+Carpentry&ots=rq-qSCBcxV&sig=aAfHGsGUosxl_1-JuxIEA7C2QO4.
Prokudin, D. E., E. N. Lisanyuk, and I. R. Baymuratov. 2024. “Visualization Functions in Argumentation Representation Software.” Scientific Visualization 16 (3). https://sv-journal.org/2024-3/11/en.pdf.
Rehman, Iskander. 2025. “The Battle for Brilliant Minds: From the Nuclear Age to AI.” War on the Rocks. January 13, 2025. https://warontherocks.com/2025/01/the-battle-for-brilliant-minds-from-the-nuclear-age-to-ai/.
riceissa, and Sammy Martin. 2021. “Analogies and General Priors on Intelligence,” August. https://www.lesswrong.com/posts/yFQkFNCszoJPZTnK6/analogies-and-general-priors-on-intelligence.
Russell, Stuart, Tom Dietterich, Eric Horvitz, Bart Selman, Francesca Rossi, Demis Hassabis, Shane Legg, et al. 2015. “Research Priorities for Robust and Beneficial Artificial Intelligence: An Open Letter.” AI Magazine 36 (4): 3–4. https://doi.org/10.1609/aimag.v36i4.2621.
Samborska, Veronika. 2025. “Scaling up: How Increasing Inputs Has Made Artificial Intelligence More Capable.” Our World in Data, January. https://ourworldindata.org/scaling-up-ai.
Samuel, Sigal. 2023. “AI Is a ‘Tragedy of the Commons.’ We’ve Got Solutions for That.” Vox. July 7, 2023. https://www.vox.com/future-perfect/2023/7/7/23787011/ai-arms-race-tragedy-commons-risk-safety.
Schelling, Thomas C. 1960. “I960. The Strategy of Conflict.” Cambridge, Mass.
Scheuer, Oliver, Frank Loll, Niels Pinkwart, and Bruce M. McLaren. 2010. “Computer-Supported Argumentation: A Review of the State of the Art.” International Journal of Computer-Supported Collaborative Learning 5 (1): 43–102. https://doi.org/10.1007/s11412-009-9080-x.
Solomon, Jill. 2020. Corporate Governance and Accountability. John Wiley & Sons. https://books.google.ca/books?hl=en&lr=&id=JAX9DwAAQBAJ&oi=fnd&pg=PR1&dq=review+of+the+effects+of+liability+frameworks+on+corporate+governance+&ots=ny23_vd-U0&sig=3LuNNhvSWXriEeg-ipAdDIQGAgo.
Sotala, Kaj. 2018. “Disjunctive Scenarios of Catastrophic AI Risk.” In Artificial Intelligence Safety and Security, edited by Roman V. Yampolskiy, 1st ed., 315–37. First edition. | Boca Raton, FL : CRC Press/Taylor & Francis Group, 2018.: Chapman and Hall/CRC. https://doi.org/10.1201/9781351251389-22.
Squires, Chandler, and Caroline Uhler. 2023. “Causal Structure Learning: A Combinatorial Perspective.” Foundations of Computational Mathematics 23 (5): 1781–1815. https://doi.org/10.1007/s10208-022-09581-9.
Tegmark, Max. 2024. “Asilomar AI Principles.” Future of Life Institute. 2024. https://futureoflife.org/open-letter/ai-principles/.
Tetlock, Phil. 2022. “Conditional Trees: AI Risk.” 2022. https://www.metaculus.com/tournament/3508/.
Tetlock, Philip E., and Dan Gardner. 2015. Superforecasting: The Art and Science of Prediction. First paperback edition. New York: Broadway Books.
Todd, Benjamin. 2024. “It Looks Like There Are Some Good Funding Opportunities in AI Safety Right Now.” Substack newsletter. Benjamin Todd. December 21, 2024. https://benjamintodd.substack.com/p/looks-like-there-are-some-good-funding.
Voigt, Christian. (2014) 2025. “Christianvoigt/Argdown.” https://github.com/christianvoigt/argdown.
Walton, Douglas. 2009. “Argument Visualization Tools for Corroborative Evidence.” In Proc. Of the 2nd International Conference on Evidence Law and Forensic Science, 32–49. https://www.academia.edu/download/37718171/09ArguVis.pdf.
Wilson, Nick, Matt Boyd, John Kerr, Amanda Kvalsvig, and Michael Baker. 2023. “The Need for Long-Term Thinking–Especially for Preventing Catastrophic Risks.” Public Health Expert Briefing.
Yang, Jie, Soyeon Caren Han, and Josiah Poon. 2022. “A Survey on Extraction of Causal Relations from Natural Language Text.” Knowledge and Information Systems 64 (5): 1161–86. https://doi.org/10.1007/s10115-022-01665-w.
Yudkowsky, Eliezer. 2008. “Artificial Intelligence as a Positive and Negative Factor in Global Risk.” In Global Catastrophic Risks, by Eliezer Yudkowsky. Oxford University Press. https://doi.org/10.1093/oso/9780198570509.003.0021.
\end{verbatim}

\bookmarksetup{startatroot}

\chapter{References (.md)}\label{references-.md}

\section{Error Watch}\label{error-watch}

\subsection{Catch ALL Potential
Hallucinations}\label{catch-all-potential-hallucinations}

\texttt{\textless{}!-\/-\ {[}\ {]}\ Collect\ all\ errors\ and\ hallucinations\ here\ to\ be\ able\ to\ reference\ against\ them\ later\ and\ ensure\ none\ remain\ throught\ text\ -\/-\textgreater{}}

\texttt{\textless{}!-\/-\ {[}\ {]}\ Keep\ track\ of\ all\ hallucinations\ that\ have\ been\ found\ here:\ -\/-\textgreater{}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Validation Metrics}: Claims of ``85\%+ accuracy for structural
  extraction'' and ``73\% for probability capture'' appear precise for
  what seems to be a prototype system. These need careful verification
  or qualification.
\item
  \textbf{Pilot Study Results}: ``40\% reduction in time to identify
  disagreements'' and ``60\% improvement in agreement about
  disagreement'' lack citations and seem surprisingly specific.
\item
  \textbf{Red-teaming Quantification}: ``34\% anchoring bias effect''
  and other precise percentages from adversarial testing need support or
  qualification as estimates.
\item
  \textbf{Prediction Market Integration}: Some passages imply deeper
  integration than the ``future work'' status indicated elsewhere.
\end{enumerate}

\texttt{\textless{}!-\/-\ {[}\ {]}\ Make\ sure\ all\ hallucinations\ have\ been\ removed\ -\/-\textgreater{}}

\section{Figure Inventory and
Tracking}\label{figure-inventory-and-tracking}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\#\# Master Figure Registry \{.unnumbered .unlisted\}}

\CommentTok{\textless{}!{-}{-} FIGURE INVENTORY {-}{-}\textgreater{}}
\CommentTok{\textless{}!{-}{-} Last updated: 2024{-}02{-}15 {-}{-}\textgreater{}}

\FunctionTok{\#\# Implemented Figures}


\FunctionTok{\#\# Section to keep track of all Figures}

\InformationTok{\textasciigrave{}\textless{}!{-}{-} [ ] ALWAYS include the "inclusions" of all figures/graphics below {-}{-}\textgreater{}\textasciigrave{}}
\InformationTok{\textasciigrave{}\textless{}!{-}{-} [ ] ALWAYS keep the \#fig{-}KEYS up{-}to{-}date {-}{-}\textgreater{}\textasciigrave{}}

\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}markdown}
\NormalTok{\{\{}
\CommentTok{[}\OtherTok{![Example Caption/Title 4}\CommentTok{](/images/cover.png)}\NormalTok{\{}
\NormalTok{    \#fig{-}Unique\_identifier\_for\_crossreferencing}
\NormalTok{    fig{-}scap="Short caption 4 list of figures as seen in LoF"}
\NormalTok{    fig{-}alt="Detailed alt text that describes the image content, type, purpose, and meaning.}
            \OtherTok{[CHART TYPE]: }\CommentTok{[}\OtherTok{Short description}\CommentTok{]}\NormalTok{.}
\NormalTok{                DATA: }\CommentTok{[}\OtherTok{What data is shown, x/y axes}\CommentTok{]}\NormalTok{.}
\NormalTok{                PURPOSE: }\CommentTok{[}\OtherTok{Why it\textquotesingle{}s included, what to look for}\CommentTok{]}\NormalTok{.}
\NormalTok{                DETAILS: }\CommentTok{[}\OtherTok{Longer description of patterns, anomalies, or key insights}\CommentTok{]}\NormalTok{.}
\NormalTok{                SOURCE: Data from }\CommentTok{[}\OtherTok{source name/year and url/link}\CommentTok{]}
\NormalTok{            "}
\NormalTok{    fig{-}align="left"}
\NormalTok{    width="30\%"}
\NormalTok{    \}](https://github.com/VJMeyer/submission)}
\NormalTok{\}\}}
\end{Highlighting}
\end{Shaded}

\subsection{Chapter 1}\label{chapter-1}

\begin{itemize}
\tightlist
\item[$\boxtimes$]
  \{\#fig-overview\}: System overview diagram

  \begin{itemize}
  \tightlist
  \item
    File: images/system-overview.png
  \item
    Source: Created by author using Draw.io
  \end{itemize}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{\{}
\CommentTok{[}\OtherTok{![Example Caption/Title 4}\CommentTok{](/images/cover.png)}\NormalTok{\{}
\NormalTok{    \#fig{-}Unique\_identifier\_for\_crossreferencing}
\NormalTok{    fig{-}scap="Short caption 4 list of figures as seen in LoF"}
\NormalTok{    fig{-}alt="Detailed alt text that describes the image content, type, purpose, and meaning.}
            \OtherTok{[CHART TYPE]: }\CommentTok{[}\OtherTok{Short description}\CommentTok{]}\NormalTok{.}
\NormalTok{                DATA: }\CommentTok{[}\OtherTok{What data is shown, x/y axes}\CommentTok{]}\NormalTok{.}
\NormalTok{                PURPOSE: }\CommentTok{[}\OtherTok{Why it\textquotesingle{}s included, what to look for}\CommentTok{]}\NormalTok{.}
\NormalTok{                DETAILS: }\CommentTok{[}\OtherTok{Longer description of patterns, anomalies, or key insights}\CommentTok{]}\NormalTok{.}
\NormalTok{                SOURCE: Data from }\CommentTok{[}\OtherTok{source name/year and url/link}\CommentTok{]}
\NormalTok{            "}
\NormalTok{    fig{-}align="left"}
\NormalTok{    width="30\%"}
\NormalTok{    \}](https://github.com/VJMeyer/submission)}
\NormalTok{\}\}}
\end{Highlighting}
\end{Shaded}

\subsection{Chapter 2}\label{chapter-2}

\begin{itemize}
\tightlist
\item[$\boxtimes$]
  \{\#fig-methodology\}: Research methodology flowchart

  \begin{itemize}
  \tightlist
  \item
    File: images/methodology-flow.svg
  \item
    Source: Author original
  \end{itemize}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{\{}
\CommentTok{[}\OtherTok{![Example Caption/Title 4}\CommentTok{](/images/cover.png)}\NormalTok{\{}
\NormalTok{    \#fig{-}Unique\_identifier\_for\_crossreferencing}
\NormalTok{    fig{-}scap="Short caption 4 list of figures as seen in LoF"}
\NormalTok{    fig{-}alt="Detailed alt text that describes the image content, type, purpose, and meaning.}
            \OtherTok{[CHART TYPE]: }\CommentTok{[}\OtherTok{Short description}\CommentTok{]}\NormalTok{.}
\NormalTok{                DATA: }\CommentTok{[}\OtherTok{What data is shown, x/y axes}\CommentTok{]}\NormalTok{.}
\NormalTok{                PURPOSE: }\CommentTok{[}\OtherTok{Why it\textquotesingle{}s included, what to look for}\CommentTok{]}\NormalTok{.}
\NormalTok{                DETAILS: }\CommentTok{[}\OtherTok{Longer description of patterns, anomalies, or key insights}\CommentTok{]}\NormalTok{.}
\NormalTok{                SOURCE: Data from }\CommentTok{[}\OtherTok{source name/year and url/link}\CommentTok{]}
\NormalTok{            "}
\NormalTok{    fig{-}align="left"}
\NormalTok{    width="30\%"}
\NormalTok{    \}](https://github.com/VJMeyer/submission)}
\NormalTok{\}\}}
\end{Highlighting}
\end{Shaded}

\section{Pending Figures}\label{pending-figures}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\#\#\# High Priority}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ \{\#fig{-}results{-}chart\}: Main results visualization}
\SpecialStringTok{  {-} }\NormalTok{Status: Data ready, needs visualization}

\NormalTok{\{\{}
\CommentTok{[}\OtherTok{![Example Caption/Title 4}\CommentTok{](/images/cover.png)}\NormalTok{\{}
\NormalTok{    \#fig{-}Unique\_identifier\_for\_crossreferencing}
\NormalTok{    fig{-}scap="Short caption 4 list of figures as seen in LoF"}
\NormalTok{    fig{-}alt="Detailed alt text that describes the image content, type, purpose, and meaning.}
            \OtherTok{[CHART TYPE]: }\CommentTok{[}\OtherTok{Short description}\CommentTok{]}\NormalTok{.}
\NormalTok{                DATA: }\CommentTok{[}\OtherTok{What data is shown, x/y axes}\CommentTok{]}\NormalTok{.}
\NormalTok{                PURPOSE: }\CommentTok{[}\OtherTok{Why it\textquotesingle{}s included, what to look for}\CommentTok{]}\NormalTok{.}
\NormalTok{                DETAILS: }\CommentTok{[}\OtherTok{Longer description of patterns, anomalies, or key insights}\CommentTok{]}\NormalTok{.}
\NormalTok{                SOURCE: Data from }\CommentTok{[}\OtherTok{source name/year and url/link}\CommentTok{]}
\NormalTok{            "}
\NormalTok{    fig{-}align="left"}
\NormalTok{    width="30\%"}
\NormalTok{    \}](https://github.com/VJMeyer/submission)}
\NormalTok{\}\}}

\FunctionTok{\#\#\# Medium Priority}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ \{\#fig{-}architecture\}: System architecture diagram}
\SpecialStringTok{  {-} }\NormalTok{Status: Sketch complete, needs professional rendering}

\NormalTok{\{\{}
\CommentTok{[}\OtherTok{![Example Caption/Title 4}\CommentTok{](/images/cover.png)}\NormalTok{\{}
\NormalTok{    \#fig{-}Unique\_identifier\_for\_crossreferencing}
\NormalTok{    fig{-}scap="Short caption 4 list of figures as seen in LoF"}
\NormalTok{    fig{-}alt="Detailed alt text that describes the image content, type, purpose, and meaning.}
            \OtherTok{[CHART TYPE]: }\CommentTok{[}\OtherTok{Short description}\CommentTok{]}\NormalTok{.}
\NormalTok{                DATA: }\CommentTok{[}\OtherTok{What data is shown, x/y axes}\CommentTok{]}\NormalTok{.}
\NormalTok{                PURPOSE: }\CommentTok{[}\OtherTok{Why it\textquotesingle{}s included, what to look for}\CommentTok{]}\NormalTok{.}
\NormalTok{                DETAILS: }\CommentTok{[}\OtherTok{Longer description of patterns, anomalies, or key insights}\CommentTok{]}\NormalTok{.}
\NormalTok{                SOURCE: Data from }\CommentTok{[}\OtherTok{source name/year and url/link}\CommentTok{]}
\NormalTok{            "}
\NormalTok{    fig{-}align="left"}
\NormalTok{    width="30\%"}
\NormalTok{    \}](https://github.com/VJMeyer/submission)}
\NormalTok{\}\}}


\end{Highlighting}
\end{Shaded}

\subsection{Master Citation Registry}\label{master-citation-registry}

\begin{Shaded}
\begin{Highlighting}[]

\FunctionTok{\#\# BibTeX of Main Citations Included}

\CommentTok{\textless{}!{-}{-} [ ] Add all the main literature / citations / references here (makes it easy to verify correct key etc. while writing) {-}{-}\textgreater{}}

\CommentTok{\textless{}!{-}{-} [ ] Keep \textquotesingle{}References.md\textquotesingle{} updated with/from ref/MAref.bib {-}{-}\textgreater{}}

\CommentTok{\textless{}!{-}{-} [ ] Remove/hide \textquotesingle{}References.md\textquotesingle{} before final publication {-}{-}\textgreater{}}

\FunctionTok{\#\# Update in ref/MAref.bib}


\FunctionTok{\#\# Core Citations (Must Have)}

\FunctionTok{\#\#\# Foundational Works}
\SpecialStringTok{{-} }\VariableTok{[x]}\NormalTok{ @carlsmith2021 {-} Power{-}seeking AI framework}
\SpecialStringTok{  {-} }\NormalTok{Chapter usage: 1, 2, 4}
\SpecialStringTok{  {-} }\NormalTok{Key concepts: Six premises, existential risk}
\SpecialStringTok{  {-} }\NormalTok{Notes: Central to thesis argument}

\SpecialStringTok{{-} }\VariableTok{[x]}\NormalTok{ @bostrom2014 {-} Superintelligence paths}
\SpecialStringTok{  {-} }\NormalTok{Chapter usage: 1, 2, 3, 5}
\SpecialStringTok{  {-} }\NormalTok{Key concepts: Orthogonality, convergence}
\SpecialStringTok{  {-} }\NormalTok{Notes: Historical foundation}



\NormalTok{@article\{bostrom2012,}
\NormalTok{  title = \{The \{\{Superintelligent Will\}\}: \{\{Motivation\}\} and \{\{Instrumental Rationality\}\} in \{\{Advanced Artificial Agents\}\}\},}
\NormalTok{  author = \{Bostrom, Nick\},}
\NormalTok{  date = \{2012\},}
\NormalTok{  journaltitle = \{Minds and Machines\},}
\NormalTok{  volume = \{22\},}
\NormalTok{  number = \{2\},}
\NormalTok{  pages = \{71{-}{-}85\},}
\NormalTok{  publisher = \{Kluwer Academic Publishers Norwell, MA, USA\},}
\NormalTok{  doi = \{10.1007/s11023{-}012{-}9281{-}3\},}
\NormalTok{  url = \{https://philpapers.org/rec/BOSTSW\}}
\NormalTok{\}}

\NormalTok{@book\{bostrom2014,}
\NormalTok{  title = \{Superintelligence: \{\{Paths\}\}, Strategies, Dangers\},}
\NormalTok{  author = \{Bostrom, Nick\},}
\NormalTok{  date = \{2014\},}
\NormalTok{  publisher = \{Oxford University Press\},}
\NormalTok{  location = \{Oxford\},}
\NormalTok{  url = \{https://scholar.dominican.edu/cynthia{-}stokes{-}brown{-}books{-}big{-}history/47\},}
\NormalTok{  abstract = \{The human brain has some capabilities that the brains of other animals lack. It is to these distinctive capabilities that our species owes its dominant position. Other animals have stronger muscles or sharper claws, but we have cleverer brains. If machine brains one day come to surpass human brains in general intelligence, then this new superintelligence could become very powerful. As the fate of the gorillas now depends more on us humans than on the gorillas themselves, so the fate of our species then would come to depend on the actions of the machine superintelligence. But we have one advantage: we get to make the first move. Will it be possible to construct a seed AI or otherwise to engineer initial conditions so as to make an intelligence explosion survivable? How could one achieve a controlled detonation? To get closer to an answer to this question, we must make our way through a fascinating landscape of topics and considerations. Read the book and learn about oracles, genies, singletons; about boxing methods, tripwires, and mind crime; about humanity\textquotesingle{}s cosmic endowment and differential technological development; indirect normativity, instrumental convergence, whole brain emulation and technology couplings; Malthusian economics and dystopian evolution; artificial intelligence, and biological cognitive enhancement, and collective intelligence.\},}
\NormalTok{  isbn = \{978{-}0{-}19{-}967811{-}2\}}
\NormalTok{\}}

\NormalTok{@article\{bostrom2016,}
\NormalTok{  title = \{The \{\{Unilateralist\}\}’s \{\{Curse\}\} and the \{\{Case\}\} for a \{\{Principle\}\} of \{\{Conformity\}\}\},}
\NormalTok{  author = \{Bostrom, Nick and Douglas, Thomas and Sandberg, Anders\},}
\NormalTok{  date = \{2016\},}
\NormalTok{  journaltitle = \{Social Epistemology\},}
\NormalTok{  volume = \{30\},}
\NormalTok{  number = \{4\},}
\NormalTok{  pages = \{350{-}{-}371\},}
\NormalTok{  publisher = \{Routledge, part of the Taylor }\SpecialCharTok{\textbackslash{}\&}\NormalTok{ Francis Group\},}
\NormalTok{  doi = \{10.1080/02691728.2015.1108373\},}
\NormalTok{  url = \{https://www.tandfonline.com/doi/full/10.1080/02691728.2015.1108373\}}
\NormalTok{\}}

\NormalTok{@article\{bostrom2019,}
\NormalTok{  title = \{The Vulnerable World Hypothesis\},}
\NormalTok{  author = \{Bostrom, Nick\},}
\NormalTok{  date = \{2019\},}
\NormalTok{  journaltitle = \{Global Policy\},}
\NormalTok{  volume = \{10\},}
\NormalTok{  number = \{4\},}
\NormalTok{  pages = \{455{-}{-}476\},}
\NormalTok{  publisher = \{Wiley Online Library\},}
\NormalTok{  doi = \{10.1111/1758{-}5899.12718\}}
\NormalTok{\}}




\FunctionTok{\#\# Pending Citations}

\FunctionTok{\#\#\# Need to Find}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ FIND: @ai{-}governance{-}2024: "Recent survey on international AI governance frameworks"}
\SpecialStringTok{  {-} }\NormalTok{For: Chapter 3, Section 3.2}
\SpecialStringTok{  {-} }\NormalTok{Search terms: AI governance, international coordination, 2024}
\SpecialStringTok{  {-} }\NormalTok{Priority: High}

\FunctionTok{\#\#\# Need to Verify}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ VERIFY: @prediction{-}markets{-}ai: "Tetlock et al on prediction markets for AI timelines"}
\SpecialStringTok{  {-} }\NormalTok{Current info: Possibly in Metaculus report 2023}
\SpecialStringTok{  {-} }\NormalTok{For: Chapter 4, Section 4.3}
\SpecialStringTok{  {-} }\NormalTok{Priority: Medium}


\FunctionTok{\#\# Citation Health Check}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ All citations in .bib file}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ All .bib entries have DOIs/URLs}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ No duplicate entries}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ Consistent naming scheme}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ Recent sources included (2023{-}2024)}

\end{Highlighting}
\end{Shaded}

\subsection{Figure tracking}\label{figure-tracking}

\begin{Shaded}
\begin{Highlighting}[]

  \CommentTok{[}\OtherTok{![Figure Caption for Display}\CommentTok{](/path/to/image.png)}\NormalTok{\{}
\NormalTok{    \#fig{-}unique{-}identifier}
\NormalTok{    fig{-}scap="Short caption for list of figures"}
\NormalTok{    fig{-}alt="Detailed description for accessibility.}
\NormalTok{            TYPE: }\CommentTok{[}\OtherTok{Chart/Diagram/Photo/etc.}\CommentTok{]}
\NormalTok{            DATA: }\CommentTok{[}\OtherTok{What data is shown, axes, units}\CommentTok{]}
\NormalTok{            PURPOSE: }\CommentTok{[}\OtherTok{Why included, what to observe}\CommentTok{]}
\NormalTok{            DETAILS: }\CommentTok{[}\OtherTok{Key patterns, insights, anomalies}\CommentTok{]}
\NormalTok{            SOURCE: }\CommentTok{[}\OtherTok{Citation or data source}\CommentTok{]}\NormalTok{"}
\NormalTok{    fig{-}align="center"}
\NormalTok{    width="80\%"}
\NormalTok{  \}](https://optional{-}link{-}url.com)}

\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{from @metropolitansky2025}

\CommentTok{[}\OtherTok{![Claimify claim{-}extraction stages}\CommentTok{](/images/claimify{-}stages.jpg)}\NormalTok{\{}
\NormalTok{    \#fig{-}claimify{-}stages}
\NormalTok{    fig{-}scap="Claimify claim{-}extraction stages"}
\NormalTok{    fig{-}alt="COMPOSITE FIGURE: table and process flow. TABLE: four{-}row, two{-}column table enumerates stages 1–4 of Claimify’s pipeline—Sentence splitting and context creation, Selection, Disambiguation, Decomposition—each with a plain{-}language description. FLOW{-}CHART: sequence of rectangles and diamond decision nodes shows per{-}sentence logic. Start node ‘Input question \& answer’ feeds into ‘Split into sentences \& create context’. Decision 1 asks if the sentence contains verifiable content; ‘No’ exits with red X ‘No verifiable claims’, ‘Yes’ advances. Decision 2 checks for irresolvable ambiguity; ‘Yes’ exits with red X ‘Cannot be disambiguated’, ‘No’ advances. Decision 3 asks if at least one claim is produced; ‘No’ exits with red X ‘No verifiable claims’, ‘Yes’ ends with green check ‘Extracted claims’. A dashed bracket labelled ‘Per sentence’ spans the decision chain. PURPOSE: illustrates Claimify’s staged filtering that aligns with AMTAIR’s need for clean, disambiguated claims before formal modelling. DATA: categorical process flow—no numeric axes. SOURCE: Adapted from Claimify documentation (2024, https://www.microsoft.com/en{-}us/research/blog/claimify{-}extracting{-}high{-}quality{-}claims{-}from{-}language{-}model{-}outputs/)."}
\NormalTok{    fig{-}align="center"}
\NormalTok{    width="100\%"}
\NormalTok{\}](https://www.microsoft.com/en{-}us/research/blog/claimify{-}extracting{-}high{-}quality{-}claims{-}from{-}language{-}model{-}outputs/)}



\NormalTok{from @tetlock2022}

\CommentTok{[}\OtherTok{![Conditional{-}tree AI{-}risk forecasts}\CommentTok{](/images/conditional\_metaculus.jpg)}\NormalTok{\{}
\NormalTok{    \#fig{-}conditional\_metaculus}
\NormalTok{    fig{-}scap="Conditional{-}tree AI{-}risk forecasts"}
\NormalTok{    fig{-}alt="SCREENSHOT of a forecasting{-}platform interface titled ‘Series Contents’. A search bar and filter chips sit above five forecast cards: 1) ‘If, before 2050, AI kills more than 1 million people, will the policy response be insufficient?’ with a 75 percent gauge (green, arrow up 8 percent). 2) ‘Before 2050, will an AI system be shut down due to exhibiting power{-}seeking behavior?’ at 95 percent (arrow down 2 percent). 3) ‘Before 2100, will AI cause the human population to fall below 5000 individuals?’ at 4 percent. 4) ‘Before 2030, will there be an AI{-}caused administrative disempowerment?’ at 20 percent. 5) ‘Between 2023 and 2030, will revenue from deep learning double every two years?’ at 80 percent. Beneath several cards, grey CONDITION boxes branch to green bars labelled ‘CTs AI Extinction Before 2100’ with different probabilities for IF YES and IF NO scenarios (e.g. 26 \% vs 37 \%). Each question lists forecaster counts, closing dates (2030 or 2050), and the tag ‘Conditional Trees: AI Risk’. A footer card introduces the series report. CHART TYPE: mixed UI elements—gauge dials and horizontal bars—displaying probabilities and conditional probabilities. DATA: probabilities (\% chances) for base and conditional events; no axes. PURPOSE: demonstrates how crowd{-}forecasting encodes marginal and counterfactual probabilities suitable as inputs for AMTAIR Bayesian{-}network nodes. DETAILS: notable high probability for power{-}seeking AI shutdown, low probability for population collapse, and large shifts in extinction risk under certain conditions. SOURCE: Forecasting Research Institute conditional{-}tree series, @tetlock2022."}
\NormalTok{    fig{-}align="center"}
\NormalTok{    width="100\%"}
\NormalTok{\}](https://www.metaculus.com/tournament/3508/)}



\NormalTok{from @gruetzemacher2022}

\CommentTok{[}\OtherTok{![Bayes{-}net pruning → crux extraction → re{-}expansion}\CommentTok{](/images/bns\_and\_conditional\_trees.jpg)}\NormalTok{\{}
\NormalTok{    \#fig{-}bayesnet{-}crux{-}flow}
\NormalTok{    fig{-}scap="Bayes{-}net pruning → crux extraction → re{-}expansion"}
\NormalTok{    fig{-}alt="THREE{-}PANEL DIAGRAM. Panel A (upper left) titled ‘Initial Bayes Net—Pruning Least Relevant Nodes’ shows eleven circular nodes connected by arrows inside a rounded rectangle. Solid circles remain; dashed or dotted ones are pruned. Arrows converge on a solid node labelled ‘AI causes human extinction’. Panel B (upper right) titled ‘Two Sets of Crux Events from Bayes Nets Isolated as Conditional Trees’ shows two short vertical chains of dotted or dashed circles. Chain 1: ‘AI alignment problem is solved’ → ‘China and the US cooperate on AI alignment’ → ‘Discontinuous progress in computational costs’. Chain 2: ‘Intergovernmental treaty on AI alignment’ ← ‘Robust AI{-}driven economic growth’ ← ‘Continual learning integrated with foundation models’. Panel C (bottom) titled ‘Top Set of Crux Events as Conditional Tree Decomposed to Bayes Net’ depicts a new Bayes net where context nodes such as ‘Photonic computing is used for CPU’, ‘US/China trade increases’, and ‘US grows increasingly authoritarian’ feed into ‘China and the US cooperate on AI alignment’, then into ‘AI alignment problem is solved’, and finally ‘AI causes human extinction’. Arrows between panels illustrate the workflow sequence. CHART TYPE: conceptual flow diagram with two Bayes nets and intermediate conditional trees. DATA: relationships among qualitative variables—no numeric axes. PURPOSE: illustrates AMTAIR’s iterative refinement pipeline from full Bayes net to crux{-}tree extraction and back. DETAILS: emphasises node styles (solid, dashed, dotted) for relevance; shows convergence toward the extinction outcome. SOURCE: @gruetzemacher2022, May 2025."}
\NormalTok{    fig{-}align="center"                        }
\NormalTok{    width="100\%"}
\NormalTok{\}](https://bnma.co/uai2022{-}apps{-}workshop/papers/S5.pdf)}







\NormalTok{from @mccaslin2024}

\CommentTok{[}\OtherTok{![Conditional{-}tree Guide}\CommentTok{](/images/conditional\_tree.jpg)}\NormalTok{\{}
\NormalTok{  \#fig{-}conditional\_tree}
\NormalTok{  fig{-}scap="Conditional{-}tree Guide"}
\NormalTok{  fig{-}alt="CHART TYPE: annotated schematic of a three{-}level conditional tree. DATA: placeholders XX \%, AA \%, BB \%, VV \%, WW \%, etc. PURPOSE: illustrates colour and label conventions—green for ultimate question, blue/purple for indicator questions, grey/red for branch probabilities, red for updated extinction probabilities and relative{-}risk factors. DETAILS: shows how each indicator’s TRUE or FALSE branch feeds probabilistically into the ultimate extinction outcome. SOURCE: McCaslin et al. 2024 @mccaslin2024, FRI Working Paper \#3."}
\NormalTok{  fig{-}align="center"}
\NormalTok{    width="100\%"}
\NormalTok{\}](https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/66ba37a144f1d6095de467df/1723479995772/AIConditionalTrees.pdf\#page=5.78)}






\NormalTok{from @mccaslin2024}

\CommentTok{[}\OtherTok{![Experts’ conditional{-}tree updates (2030{-}2070)}\CommentTok{](/images/concerned\_experts.jpg)}\NormalTok{\{}
\NormalTok{    \#fig{-}concerned\_experts}
\NormalTok{    fig{-}scap="Experts’ conditional{-}tree updates (2030{-}2070)"}
\NormalTok{    fig{-}alt="CHART TYPE: conditional{-}probability tree with three sequential indicator nodes. DATA: baseline AI{-}extinction probability 17 \% in 2023; indicator 1 (2030 administrative disempowerment warning shot) TRUE=37 \%, FALSE=63 \%; two conditional probabilities for extinction in 2100: 31.6 \% (relative{-}risk 1.9×) if TRUE, 14.3 \% (0.9×) if FALSE. Indicator 2 (2050 power{-}seeking warning shot) TRUE=54 \%, FALSE=46 \%; corresponding extinction probabilities 23.4 \% (1.4×) and 10.5 \% (0.6×). Indicator 3 (2070 no aligned AGI) TRUE=46 \%, FALSE=54 \%; extinction probabilities 25.0 \% (1.5×) and 13.7 \% (0.8×). PURPOSE: quantifies how confirmation or disconfirmation of warning{-}shot events would shift expert{-}assessed AI{-}extinction risk. DETAILS: experts are most alarmed by earlier administrative disempowerment (1.9× increase) and least by absence of power{-}seeking shot (0.6×). SOURCE: McCaslin et al. 2024 @mccaslin2024, FRI Working Paper \#3."}
\NormalTok{    fig{-}align="center"}
\NormalTok{    width="100\%"}
\NormalTok{\}](https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/66ba37a144f1d6095de467df/1723479995772/AIConditionalTrees.pdf\#page=5.78)}



\NormalTok{from @manheim2021}

\CommentTok{[}\OtherTok{![Overlay of inside/outside/assimilation views}\CommentTok{](/images/mtair{-}insideoutside{-}overlay.jpg)}\NormalTok{\{}
\NormalTok{    \#fig{-}mtair{-}insideoutside{-}overlay}
\NormalTok{    fig{-}scap="Overlay of inside/outside/assimilation views"}
\NormalTok{    fig{-}alt="CONCEPT MAP overlaid by three translucent circles captioned Inside view, Outside views, and Assimilation logic. Left bullet list of six APS assumptions feeds a central causal chain of probabilities (timeline, incentive, alignment, failure, disempowerment, catastrophe) leading to a node titled ‘Cr existential catastrophe | world model’. Lower{-}left cluster of rectangles represents outside{-}view priors (Second Species Argument, transformative{-}tech base rate, AGI timeline forecasts, etc.). Right{-}hand cluster shows weighting and integration logic combining world{-}model estimate with outside{-}view priors into a final existential{-}catastrophe credence. No numerical axes—pure structural relationships. PURPOSE: illustrate how MTAIR reconciles inside{-}view technical reasoning with outside{-}view priors using an assimilation weighting scheme. SOURCE: David Manheim @manheim2021, MTAIR sequence post \#3, Jul 2021."}
\NormalTok{    fig{-}align="center"}
\NormalTok{    width="100\%"}
\NormalTok{\}](https://www.lesswrong.com/posts/sGkRDrpphsu6Jhega/a{-}model{-}based{-}approach{-}to{-}ai{-}existential{-}risk)}




\NormalTok{from @manheim2021}

\CommentTok{[}\OtherTok{![Base APS causal map}\CommentTok{](/images/mtair{-}insideoutside{-}base.jpg)}\NormalTok{\{}
\NormalTok{    \#fig{-}mtair{-}insideoutside{-}base}
\NormalTok{    fig{-}scap="Base APS causal map (clean)"}
\NormalTok{    fig{-}alt="Same node{-}and{-}arrow causal graph as the overlay figure but without the purple, violet, and red guiding circles. Blue bullet premises feed ‘Collection of inputs’ rectangle, cascading turquoise probability ovals lead to ‘Cr existential catastrophe | world model’. Lower left shows outside{-}view priors, right shows weighting logic, centre red oval ‘Cr existential catastrophe’. Provides uncluttered view of the structural model prior to explanatory overlay. SOURCE: David Manheim @manheim2021, MTAIR sequence, 2021."}
\NormalTok{    fig{-}align="center"}
\NormalTok{    width="100\%"}
\NormalTok{\}](https://www.lesswrong.com/posts/sGkRDrpphsu6Jhega/a{-}model{-}based{-}approach{-}to{-}ai{-}existential{-}risk)}











\NormalTok{from @clarke2022}

\CommentTok{[}\OtherTok{![MTAIR Quantitative map structure}\CommentTok{](/images/mtair{-}quant{-}map.jpg)}\NormalTok{\{}
\NormalTok{    \#fig{-}mtair{-}quant{-}map}
\NormalTok{    fig{-}scap="MTAIR Quantitative map structure"}
\NormalTok{    fig{-}alt="FLOW DIAGRAM titled ‘Quantitative Model’. Blue and cyan rectangles (Hypotheses and Debated propositions) feed green ‘Proposed agenda’ boxes and a rose ‘Meta{-}uncertainty’ box, which all point to red ‘Catastrophe scenario’ boxes. Tiny mini{-}PDF icons depict probability distributions beside each variable. Right{-}hand analysis panel lists Effects of investment, Sensitivity analysis, What{-}if questions, Decision approaches, Analysis tools. PURPOSE: show how MTAIR converts a qualitative causal map into a quantified Bayesian network that supports downstream scenario and decision analysis. OURCE: David Manheim et. al, Modeling Transformative AI Risks (MTAIR) Project {-}{-} Summary Report, 2021."}
\NormalTok{    fig{-}align="center"}
\NormalTok{    width="100\%"}
\NormalTok{\}](https://arxiv.org/pdf/2206.09360\#page=10.75)}














\NormalTok{from @clarke2022}

\CommentTok{[}\OtherTok{![MTAIR Qualitative map structure}\CommentTok{](/images/mtair{-}qual{-}map.jpg)}\NormalTok{\{}
\NormalTok{    \#fig{-}mtair{-}qual{-}map}
\NormalTok{    fig{-}scap="MTAIR Qualitative map structure"}
\NormalTok{    fig{-}alt="NODE{-}LINK DIAGRAM titled ‘Qualitative Map’. Blue rectangles ‘Hypothesis 1’ and ‘Hypothesis 2’, cyan rectangles ‘Debated propositions 1 \& 2’, green rectangles ‘Proposed agendas 1 \& 2’, red rectangles ‘Catastrophe scenarios 1 \& 2’. Arrows show causal influence path from hypotheses through debated propositions and agendas to catastrophes. No probability icons, no analysis panel. PURPOSE: foundational structure before numerical parametrisation, illustrating argumentative flow in MTAIR. SOURCE: David Manheim et. al, Modeling Transformative AI Risks (MTAIR) Project {-}{-} Summary Report, 2021."}
\NormalTok{    fig{-}align="center"}
\NormalTok{    width="100\%"}
\NormalTok{\}](https://arxiv.org/pdf/2206.09360\#page=10.75)}






\NormalTok{from @cottier2019}

\CommentTok{[}\OtherTok{![Key hypotheses in AI alignment}\CommentTok{](/images/hypotheses\_diagram.pdf)}\NormalTok{\{}
\NormalTok{    \#fig{-}ai{-}hypotheses{-}map}
\NormalTok{    fig{-}scap="Key hypotheses in AI alignment"}
\NormalTok{    fig{-}alt="LARGE CONCEPT MAP. Nodes are colour{-}coded: red for problems that could lead to catastrophe, green for solutions or agendas, blue for scenarios or conceptual models. Bold{-}border nodes denote primary hypotheses such as ‘Discontinuity to AGI’, ‘Agentive AGI’, ‘Broad basin for corrigibility’, and ‘Mesa{-}optimisation’. Directed arrows link questions to hypotheses, questions to questions, and scenarios to hypotheses. Arrow labels (Yes, No, Defer, brief rationales) indicate how answering the tail node influences credence in the head node. A legend at the bottom explains colour categories and arrow semantics. Source: Ben Cottier \& Rohin Shah (2019) @cottier2019 “Clarifying Some Key Hypotheses in AI Alignment”, AI Alignment Forum."}
\NormalTok{    fig{-}align="center"}
\NormalTok{    width="100\%"}
\NormalTok{\}](https://www.lesswrong.com/posts/mJ5oNYnkYrd4sD5uE/clarifying{-}some{-}key{-}hypotheses{-}in{-}ai{-}alignment\#Agentive\_AGI\_)}















\end{Highlighting}
\end{Shaded}

from \textcite{metropolitansky2025}

\begin{figure}

\centering{

\href{https://www.microsoft.com/en-us/research/blog/claimify-extracting-high-quality-claims-from-language-model-outputs/}{\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/claimify-stages.jpg}}

}

\caption[Claimify claim-extraction
stages]{\label{fig-claimify-stages}Claimify claim-extraction stages}

\end{figure}%

from \textcite{tetlock2022}

\begin{figure}

\centering{

\href{https://www.metaculus.com/tournament/3508/}{\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/conditional_metaculus.jpg}}

}

\caption[Conditional-tree AI-risk
forecasts]{\label{fig-conditional_metaculus}Conditional-tree AI-risk
forecasts}

\end{figure}%

from \textcite{gruetzemacher2022}

\begin{figure}

\centering{

\href{https://bnma.co/uai2022-apps-workshop/papers/S5.pdf}{\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/bns_and_conditional_trees.jpg}}

}

\caption[Bayes-net pruning → crux extraction →
re-expansion]{\label{fig-bayesnet-crux-flow}Bayes-net pruning → crux
extraction → re-expansion}

\end{figure}%

from \textcite{mccaslin2024}

\begin{figure}

\centering{

\href{https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/66ba37a144f1d6095de467df/1723479995772/AIConditionalTrees.pdf\#page=5.78}{\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/conditional_tree.jpg}}

}

\caption[Conditional-tree
Guide]{\label{fig-conditional_tree}Conditional-tree Guide}

\end{figure}%

from \textcite{mccaslin2024}

\begin{figure}

\centering{

\href{https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/66ba37a144f1d6095de467df/1723479995772/AIConditionalTrees.pdf\#page=5.78}{\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/concerned_experts.jpg}}

}

\caption[Experts' conditional-tree updates
(2030-2070)]{\label{fig-concerned_experts}Experts' conditional-tree
updates (2030-2070)}

\end{figure}%

from \textcite{manheim2021}

\begin{figure}

\centering{

\href{https://www.lesswrong.com/posts/sGkRDrpphsu6Jhega/a-model-based-approach-to-ai-existential-risk}{\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/mtair-insideoutside-overlay.jpg}}

}

\caption[Overlay of inside/outside/assimilation
views]{\label{fig-mtair-insideoutside-overlay}Overlay of
inside/outside/assimilation views}

\end{figure}%

from \textcite{manheim2021}

\begin{figure}

\centering{

\href{https://www.lesswrong.com/posts/sGkRDrpphsu6Jhega/a-model-based-approach-to-ai-existential-risk}{\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/mtair-insideoutside-base.jpg}}

}

\caption[Base APS causal map
(clean)]{\label{fig-mtair-insideoutside-base}Base APS causal map}

\end{figure}%

from \textcite{clarke2022}

\begin{figure}

\centering{

\href{https://arxiv.org/pdf/2206.09360\#page=10.75}{\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/mtair-quant-map.jpg}}

}

\caption[MTAIR Quantitative map
structure]{\label{fig-mtair-quant-map}MTAIR Quantitative map structure}

\end{figure}%

from \textcite{clarke2022}

\begin{figure}

\centering{

\href{https://arxiv.org/pdf/2206.09360\#page=10.75}{\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/mtair-qual-map.jpg}}

}

\caption[MTAIR Qualitative map
structure]{\label{fig-mtair-qual-map}MTAIR Qualitative map structure}

\end{figure}%

from \textcite{cottier2019}

\begin{figure}

\centering{

\href{https://www.lesswrong.com/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment\#Agentive_AGI_}{\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/hypotheses_diagram.pdf}}

}

\caption[Key hypotheses in AI
alignment]{\label{fig-ai-hypotheses-map}Key hypotheses in AI alignment}

\end{figure}%

\bookmarksetup{startatroot}

\chapter*{Bibliography}\label{bibliography}
\addcontentsline{toc}{chapter}{Bibliography}

\markboth{Bibliography}{Bibliography}

\printbibliography[heading=none]


\backmatter
\printbibliography[title=Bibliography]



\clearpage
\thispagestyle{empty} % Removes page numbering for current page

\newpage


% Top header with logo (left) and department (right)
\begin{minipage}{0.3\textwidth}
  \includegraphics[width=5cm]{latex/uni-bayreuth-logo.png}
\end{minipage}
\hfill
\begin{minipage}{0.9\textwidth}
  \begin{center}
    -- P\&E Master's Programme --\\
    Chair of Philosophy, Computer\\
    Science \& Artificial Intelligence
  \end{center}
\end{minipage}

% Horizontal rule
\vspace{1.5cm}
\hrule
\vspace{2.5cm}

% Title in bold

  \LARGE\textbf{Affidavit}
\vspace{1.5cm}

\center

\normalsize

% \part*{Affidavit}

    \subsection*{\Large Declaration of Academic Honesty}
	    \vspace{1cm}\noindent \\
	    Hereby, I attest that I have composed and written the presented thesis 
        \vspace*{0.5cm}\noindent \\
        \textit{ \textbf{ Automating the Modelling of Transformative Artificial Intelligence Risks }}
        \vspace*{0.5cm}\noindent \\
        independently on my own, without the use of other than the stated aids and without any other resources than the ones indicated. All thoughts taken directly or indirectly from external sources are properly denoted as such.
	    \vspace{\baselineskip}
	    \\  This paper has neither been previously submitted in the same or a similar form to another authority nor has it been published yet.
	    \vspace{2cm}
	    
    \flushright
    \begin{minipage}{0.5\textwidth}
        \begin{flushleft} \large
        \textsc{Bayreuth}                     %   Place
        on the \\ % 26th of May 2025     \\
        \today           %   Date
        \vspace{2cm}\\
    	{\rule[-3pt]{\linewidth}{.4pt}\par\smallskip  
        \textsc{Valentin Meyer}	\\         %   Your name
    	}
        \end{flushleft}
        \end{minipage}


\end{document}
