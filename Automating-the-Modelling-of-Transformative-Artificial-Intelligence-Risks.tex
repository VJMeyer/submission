% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  11pt,
  letterpaper,
]{book}
\usepackage{xcolor}
\usepackage[margin=2.5cm,paper=a4paper]{geometry}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother
\usepackage{fancyvrb}

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother

\ifLuaTeX
  \usepackage{luacolor}
  \usepackage[soul]{lua-ul}
\else
  \usepackage{soul}
\fi




\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 
\usepackage[]{biblatex}
\addbibresource{ref/MAref.bib}


% AMTAIR Thesis Preamble - Zero package conflicts
% Only formatting commands, no package loading

% Line spacing for academic work
\usepackage{setspace}
\onehalfspacing

% Custom chapter formatting (remove "Chapter N" prefix) but unfortunately leaves blank space
\usepackage{titlesec}
\titleformat{\chapter}[display]
  {\normalfont\huge\bfseries}  % format
  {}                           % label (empty = no "Chapter N")
  {0pt}                        % sep
  {\Huge}                      % before-code



% Page formatting and headers
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\slshape\nouppercase{\rightmark}}
\fancyhead[LO,RE]{\slshape\nouppercase{\leftmark}}
\fancyfoot[C]{\thepage}

% % Fix page breaks after title page
% \newcommand{\cleartitlepage}{
%   \clearpage
%   \thispagestyle{empty}
%   \mbox{}
%   \clearpage
% }



\renewcommand{\maketitle}{}

%  Citation customization
% \usepackage[style=authoryear,backend=biber,natbib=true]{biblatex}

% % Custom citation commands for different contexts
% \newcommand{\citeauthor}[1]{\textcite{#1}}           % Author (year)
% \newcommand{\citeyear}[1]{(\citeyear*{#1})}         % (year)
% \newcommand{\citealt}[1]{\citeauthor{#1} \citeyear{#1}}  % Author year
% \newcommand{\citep}[1]{(\cite{#1})}                 # (Author, year)

% Page reference styling
% \DeclareFieldFormat{postnote}{#1}                    # No "p." prefix
% \DeclareFieldFormat{multipostnote}{#1}               # No "pp." prefix


% % Page numbering control
% \usepackage{afterpage}

% % Command to start front matter (roman numerals)
% \newcommand{\frontmatter}{
%   \cleardoublepage
%   \pagenumbering{roman}
%   \setcounter{page}{1}
% }

% % Command to start main matter (arabic numerals)
% \newcommand{\mainmatter}{
%   \cleardoublepage
%   \pagenumbering{arabic}
%   \setcounter{page}{1}
% }

% % Command to start back matter (continue arabic)
% \newcommand{\backmatter}{
%   \cleardoublepage
%   % Keep arabic numbering but could change style if needed
% }

% % Suppress page numbers on title page
% \newcommand{\titlepage}{
%   \thispagestyle{empty}
% }



% Commands for custom title page
% \newcommand{\thesistitle}{Automating the Modelling of Transformative Artificial Intelligence Risks}
% \newcommand{\thesisauthor}{Valentin Jakob Meyer}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\usepackage{pdflscape}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\VerbatimFootnotes % allow verbatim text in footnotes
\hypersetup{
  pdftitle={Automating the Modelling of Transformative Artificial Intelligence Risks},
  pdfauthor={Valentin Jakob Meyer},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}


\title{Automating the Modelling of Transformative Artificial
Intelligence Risks}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{An Epistemic Framework for Leveraging Frontier AI Systems to
Upscale Conditional Policy Assessments in Bayesian Networks on a Narrow
Path towards Existential Safety}
\author{Valentin Jakob Meyer}
\date{2025-05-26}
\begin{document}
\frontmatter
\maketitle

\begin{titlepage}
\thispagestyle{empty}% Remove page number from title page

% Top header with logo (left) and department (right)
\begin{minipage}{0.3\textwidth}
  \includegraphics[width=5cm]{latex/uni-bayreuth-logo.png}
\end{minipage}
\hfill
\begin{minipage}{0.9\textwidth}
  \begin{center}
    -- P\&E Master's Programme --\\
    Chair of Philosophy, Computer\\
    Science \& Artificial Intelligence
  \end{center}
\end{minipage}

% Horizontal rule
\vspace{1.5cm}
\hrule
\vspace{2cm}

% Title in bold
\begin{center}
  \Large\textbf{Automating the Modelling of
Transformative Artificial Intelligence Risks}
\end{center}
\vspace{0.2cm}

\begin{center}
  -----
\end{center}
\vspace{0.2cm}

% Subtitle in italics with quotation marks
\begin{center}
  \normalsize``\textit{An Epistemic Framework for Leveraging Frontier AI Systems
to Upscale Conditional Policy Assessments in Bayesian Networks on a Narrow Path towards Existencial Safety }''
\end{center}
\vspace{0.2cm}

\begin{center}
  -----
\end{center}
\vspace{0.2cm}

% Thesis designation
\begin{center}
  A thesis submitted at the Department of Philosophy\\[0.4cm]
  for the degree of \textit{Master of Arts in Philosophy \& Economics}
\end{center}

\vspace{1.5cm}
% Horizontal rule
\hrule
\vspace{1.5cm}

% Author and supervisor information with precise alignment
\begin{minipage}[t]{0.48\textwidth}
  \textbf{Author:}\\[0.3cm]
  \href{https://www.vjmeyer.org}{Valentin Jakob Meyer}\\
  \href{mailto:Valentin.meyer@uni-bayreuth.de}{Valentin.meyer@uni-bayreuth.de}\\
  \textit{Matriculation Number:} 1828610\\
  \textit{Tel.:} +49 (1573) 4512494\\
  Pielmühler Straße 15\\
  52066 Lappersdorf
\end{minipage}
\hfill
\begin{minipage}[t]{0.48\textwidth}
  \begin{flushright}
    \textbf{Supervisor:}\\[0.3cm]
    \href{mailto:timo.speith@uni-bayreuth.de}{Dr. Timo Speith}\\[0.35cm]
    \textit{Word Count:}\\
    30.000\\[0.1cm]
    \textit{Source / Identifier:}\\
    \href{https://github.com/VJMeyer/submission}{Document URL}
  \end{flushright}
\end{minipage}

% Date at bottom
\vfill
\begin{center}
  26th of May 2025
\end{center}
\end{titlepage}

% Critical: Clean page break to TOC
\cleardoublepage

\renewcommand*\contentsname{Table of Contents}
{
\setcounter{tocdepth}{2}
\tableofcontents
}
\listoffigures
\listoftables

\mainmatter
\bookmarksetup{startatroot}

\chapter*{Preface}\label{preface}
\addcontentsline{toc}{chapter}{Preface}

\markboth{Preface}{Preface}

\bookmarksetup{startatroot}

\chapter*{Quarto Syntax}\label{sec-syntax}
\addcontentsline{toc}{chapter}{Quarto Syntax}

\markboth{Quarto Syntax}{Quarto Syntax}

\section*{Main Formatting}\label{main-formatting}
\addcontentsline{toc}{section}{Main Formatting}

\markright{Main Formatting}

\subsection*{Html Comments}\label{html-comments}
\addcontentsline{toc}{subsection}{Html Comments}

\section*{Syntax for Tasks}\label{syntax-for-tasks}
\addcontentsline{toc}{section}{Syntax for Tasks}

\markright{Syntax for Tasks}

\subsection*{Tasks with ToDo Tree}\label{tasks-with-todo-tree}
\addcontentsline{toc}{subsection}{Tasks with ToDo Tree}

\subsubsection*{Simple ``One-line tasks''}\label{simple-one-line-tasks}
\addcontentsline{toc}{subsubsection}{Simple ``One-line tasks''}

Use Code ticks and html comment and task format for tasks distinctly
visible across all formats including the ToDo-Tree overview:

\texttt{\textless{}!-\/-\ {[}\ {]}\ ToDos\ for\ things\ to\ do\ /\ tasks\ /\ reminders\ (allows\ "jump\ to\ with\ Taks\ Tree\ extension")\ -\/-\textgreater{}}

Use html comment and task format for open or uncertain tasks, visible in
the .qmd file:

\subsubsection*{More Complex Tasks with
Notes}\label{more-complex-tasks-with-notes}
\addcontentsline{toc}{subsubsection}{More Complex Tasks with Notes}

\begin{verbatim}
<!-- [ ] Task Title: short description-->

  More Information about task

  Relevant notes

  Step-by-step implementation Plan

  Etc.
\end{verbatim}

\subsubsection*{Completed Tasks}\label{completed-tasks}
\addcontentsline{toc}{subsubsection}{Completed Tasks}

Retain completed tasks in ToDo-Tree by adding an x in the brackets:
\texttt{{[}x{]}}
\texttt{\textless{}!-\/-\ {[}x{]}\ Tasks\ which\ have\ been\ finished\ but\ should\ remain\ for\ later\ verification\ -\/-\textgreater{}}

Mark and remove completed tasks from ToDo-Tree by adding a minus in the
brackets: \texttt{{[}-{]}}

\texttt{\textless{}!-\/-\ {[}-{]}\ Tasks\ which\ have\ been\ finished\ but\ should\ remain\ visible\ for\ later\ verification\ -\/-\textgreater{}}

\subsubsection*{Missing Citations}\label{missing-citations}
\addcontentsline{toc}{subsubsection}{Missing Citations}

\texttt{\textless{}!-\/-\ {[}\ {]}\ FIND:\ @CITATION\_KEY\_PURPOSE:\ "Description\ of\ the\ appropriate/idea\ source,\ including\ ideas\ /suggestions\ /\ search\ terms\ etc."\ -\/-\textgreater{}}

\subsubsection*{Suggested Citation}\label{suggested-citation}
\addcontentsline{toc}{subsubsection}{Suggested Citation}

\texttt{\textless{}!-\/-\ {[}\ {]}\ VERIFY:\ @CITATION\_KEY\_SUGGESTED:\ "Description\ of\ the\ appropriate\ paper,\ book,\ source"\ {[}Include\ BibTex\ if\ known{]}\ -\/-\textgreater{}}

\subsubsection*{Missing Graphic}\label{missing-graphic}
\addcontentsline{toc}{subsubsection}{Missing Graphic}

\texttt{\textless{}!-\/-\ {[}\ {]}\ FIND:\ \{\#fig-GRAPHIC\_IDEA\}{]}:\ "Description\ of\ the\ appropriate/idea\ source,\ including\ ideas\ /suggestions\ /\ search\ terms\ etc."\ -\/-\textgreater{}}

\subsubsection*{Suggested Graphic}\label{suggested-graphic}
\addcontentsline{toc}{subsubsection}{Suggested Graphic}

\texttt{\textless{}!-\/-\ {[}\ {]}\ VERIFY:\ \{\#fig-GRAPHIC\_IDEA\}:\ "Description\ of\ the\ appropriate\ paper,\ book,\ source"\ {[}Include\ figure\ syntax\ if\ known{]}\ -\/-\textgreater{}}

Missing and/or suggested tables, concepts, explanations as well as other
elements should be suggested similarily.

\subsection*{Task Syntax Examples}\label{task-syntax-examples}
\addcontentsline{toc}{subsection}{Task Syntax Examples}

\texttt{\textless{}!-\/-\ {[}\ {]}\ (Example\ short:\ open\ and\ visible\ in\ text)\ \ \ Find\ and\ list\ the\ names\ of\ the\ MTAIR\ team-members\ responsible\ for\ the\ Analytica\ Implementation\ -\/-\textgreater{}}

\begin{verbatim}
<!-- [ ] (Example longer: open and visible in text)    Review/Plan/Discuss integrating Live Prediction Markets -->

  Live prediction market integration requires:
    (1) API connections to platforms (Metaculus, Manifold),
    (2) Question-to-variable mapping algorithms,
    (3) Probability update mechanisms, 
    (4) Handling of market dynamics (thin markets, manipulation).
    Current mentions may overstate readiness or underestimate complexity.
    Need realistic assessment of what's achievable.

  Implementation Steps:
      0. List/mention all relevant platforms with a brief description each
      1. Review all existing prediction market mentions for accuracy
      2. Assess actual API availability and limitations
      3. Describe/explain/discuss how to implement basic proof-of-concept with single platform
      4. Document challenges: question mapping, market interpretation
      5. Create realistic timeline for full implementation
      6. Revise thesis claims to match reality
      7. Add "Future Work" and/or extension section on complete integration
      8. Include descriptions of mockups/designs even if not fully built 
      9. Highlight/discuss the advantages of such integrations
      10. Quickly brainstorm for downsides worth mentioning
\end{verbatim}

\subsection*{Verbatim Code Formatting}\label{verbatim-code-formatting}
\addcontentsline{toc}{subsection}{Verbatim Code Formatting}

\texttt{verbatim\ code\ formatting\ for\ notes\ and\ ideas\ to\ be\ included\ (here)}

\subsection*{Code Block formatting}\label{code-block-formatting}
\addcontentsline{toc}{subsection}{Code Block formatting}

\begin{verbatim}
Also code blocks for more extensive notes and ideas to be included and checklists
- test 1. 
- test 2. 
- test 3.
2. second
3. third
\end{verbatim}

\begin{verbatim}
code
\end{verbatim}

Add a language to syntax highlight code blocks:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \OperatorTok{+} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

\subsection*{Blockquote Formatting}\label{blockquote-formatting}
\addcontentsline{toc}{subsection}{Blockquote Formatting}

\begin{quote}
Blockquote formatting for ``Suggested Citations (e.g.~carlsmith 2024 on
\ldots)'' and/or claims which require a citation (e.g.~claim x should be
backed-up by a ciation from the literature)
\end{quote}

\subsection*{Tables}\label{tables}
\addcontentsline{toc}{subsection}{Tables}

\begin{longtable}[]{@{}rllc@{}}
\caption{Demonstration of pipe table
syntax}\label{tbl-letters}\tabularnewline
\toprule\noalign{}
Right & Left & Default & Center \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Right & Left & Default & Center \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
12 & 12 & 12 & 12 \\
123 & 123 & 123 & 123 \\
1 & 1 & 1 & 1 \\
\end{longtable}

\begin{longtable}[]{@{}lll@{}}
\caption{My Caption 1}\label{tbl-letters}\tabularnewline
\toprule\noalign{}
Col1 & Col2 & Col3 \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Col1 & Col2 & Col3 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A & B & C \\
E & F & G \\
A & G & G \\
\end{longtable}

Referencing tables with \texttt{@tbl-KEY}: See Table~\ref{tbl-letters}.

\begin{table}

\caption{\label{tbl-panel}Main Caption}

\begin{minipage}{0.50\linewidth}

\subcaption{\label{tbl-first}First Table}

\centering{

\begin{tabular}{lll}
\toprule
Col1 & Col2 & Col3\\
\midrule
A & B & C\\
E & F & G\\
A & G & G\\
\bottomrule
\end{tabular}

}

\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\subcaption{\label{tbl-second}Second Table}

\centering{

\begin{tabular}{lll}
\toprule
Col1 & Col2 & Col3\\
\midrule
A & B & C\\
E & F & G\\
A & G & G\\
\bottomrule
\end{tabular}

}

\end{minipage}%

\end{table}%

See Table~\ref{tbl-panel} for details, especially
Table~\ref{tbl-second}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{python}
\NormalTok{\#| label: tbl{-}planets}
\NormalTok{\#| tbl{-}cap: Astronomical object}

\NormalTok{from IPython.display import Markdown}
\NormalTok{from tabulate import tabulate}
\NormalTok{table = [}\CommentTok{[}\OtherTok{"Sun","696,000",1.989e30}\CommentTok{]}\NormalTok{,}
         \CommentTok{[}\OtherTok{"Earth","6,371",5.972e24}\CommentTok{]}\NormalTok{,}
         \CommentTok{[}\OtherTok{"Moon","1,737",7.34e22}\CommentTok{]}\NormalTok{,}
         \CommentTok{[}\OtherTok{"Mars","3,390",6.39e23}\CommentTok{]}\NormalTok{]}
\NormalTok{Markdown(tabulate(}
\NormalTok{  table, }
\NormalTok{  headers=}\CommentTok{[}\OtherTok{"Astronomical object","R (km)", "mass (kg)"}\CommentTok{]}
\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1806}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1806}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3194}}@{}}
\caption{Sample grid table.}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Fruit
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Price
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Advantages
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Fruit
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Price
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Advantages
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bananas & \$1.34 & \begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\tightlist
\item
  built-in wrapper
\item
  bright color
\end{itemize}
\end{minipage} \\
Oranges & \$2.10 & \begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\tightlist
\item
  cures scurvy
\item
  tasty
\end{itemize}
\end{minipage} \\
\end{longtable}

Content with HTML tables you don't want processed.

\section*{Headings \& Potential Headings in Standard Markdown formatting
(`\#\#')}\label{sec-heading}
\addcontentsline{toc}{section}{Headings \& Potential Headings in
Standard Markdown formatting (`\#\#')}

\markright{Headings \& Potential Headings in Standard Markdown
formatting (`\#\#')}

\subsection*{Heading 3}\label{heading-3}
\addcontentsline{toc}{subsection}{Heading 3}

\subsubsection*{Heading 4}\label{heading-4}
\addcontentsline{toc}{subsubsection}{Heading 4}

\section*{Text Formatting Options}\label{text-formatting-options}
\addcontentsline{toc}{section}{Text Formatting Options}

\markright{Text Formatting Options}

\emph{italics}, \textbf{bold}, \textbf{\emph{bold italics}}

superscript\textsuperscript{2} and subscript\textsubscript{2}

\st{strikethrough}

\hl{This text is highlighted}

\ul{This text is underlined}

\textsc{This text is smallcaps}

\section*{Lists}\label{lists}
\addcontentsline{toc}{section}{Lists}

\markright{Lists}

\begin{itemize}
\item
  unordered list

  \begin{itemize}
  \tightlist
  \item
    sub-item 1
  \item
    sub-item 2

    \begin{itemize}
    \tightlist
    \item
      sub-sub-item 1
    \end{itemize}
  \end{itemize}
\item
  item 2

  Continued (indent 4 spaces)
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  ordered list
\item
  item 2

  \begin{enumerate}
  \def\labelenumii{\roman{enumii})}
  \tightlist
  \item
    sub-item 1

    \begin{enumerate}
    \def\labelenumiii{\Alph{enumiii}.}
    \tightlist
    \item
      sub-sub-item 1
    \end{enumerate}
  \end{enumerate}
\end{enumerate}

\section*{Math}\label{math}
\addcontentsline{toc}{section}{Math}

\markright{Math}

inline math: \(E = mc^{2}\)

display math:

\[E = mc^{2}\]

If you want to define custom TeX macros, include them within \$\$
delimiters enclosed in a .hidden block. For example:

\[
 \def\RR{{\bf R}}
 \def\bold#1{{\bf #1}}
\]

For HTML math processed using MathJax (the default) you can use the
\textbackslash def, \textbackslash newcommand,
\textbackslash renewcommand, \textbackslash newenvironment,
\textbackslash renewenvironment, and \textbackslash let commands to
create your own macros and environments.

\section*{Footnotes}\label{footnotes}
\addcontentsline{toc}{section}{Footnotes}

\markright{Footnotes}

Here is an inline note.\footnote{Inlines notes are easier to write,
  since you don't have to pick an identifier and move down to type the
  note.}

Here is a footnote reference,\footnote{Here is the footnote.}

Another Text with a footnote\footnote{Here's one with multiple blocks.

  Subsequent paragraphs are indented to show that they belong to the
  previous footnote.

\begin{Verbatim}
{ some.code }
\end{Verbatim}

  The whole paragraph can be indented, or just the first line. In this
  way, multi-paragraph footnotes work like multi-paragraph list items.}
but this time a ``longnote''.

This paragraph won't be part of the note, because it isn't indented.

\section*{Callouts}\label{sec-callouts}
\addcontentsline{toc}{section}{Callouts}

\markright{Callouts}

Quarto's native callouts work without additional packages:

This is written in a `note' environment -- but it does not seem to
produce any special rendering.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Optional Title}, opacityback=0, arc=.35mm, breakable, toptitle=1mm, toprule=.15mm, colframe=quarto-callout-note-color-frame, bottomtitle=1mm, rightrule=.15mm, opacitybacktitle=0.6, left=2mm, titlerule=0mm, leftrule=.75mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, coltitle=black]

Content here

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Important Note2}, opacityback=0, arc=.35mm, breakable, toptitle=1mm, toprule=.15mm, colframe=quarto-callout-note-color-frame, bottomtitle=1mm, rightrule=.15mm, opacitybacktitle=0.6, left=2mm, titlerule=0mm, leftrule=.75mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, coltitle=black]

This renders perfectly in both HTML and PDF.

\end{tcolorbox}

Also for markdown:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{::: \{.render\_as\_markdown\_example\}}
\FunctionTok{\#\# Markdown Heading}
\NormalTok{This renders perfectly in both HTML and PDF but as markdown "plain text"}
\NormalTok{:::}
\end{Highlighting}
\end{Shaded}

\section*{Links}\label{links}
\addcontentsline{toc}{section}{Links}

\markright{Links}

\texttt{\textless{}https://quarto.org/docs/authoring/markdown-basics.html\textgreater{}}
produces: \url{https://quarto.org/docs/authoring/markdown-basics.html}

\texttt{{[}Quarto\ Book\ Cross-References{]}(https://quarto.org/docs/books/book-crossrefs.html)}
produces:
\href{https://quarto.org/docs/books/book-crossrefs.html}{Quarto Book
Cross-References}

\section*{Images \& Figures}\label{sec-figures1}

\markright{Images \& Figures}

\begin{verbatim}
[![AMTAIR Automation Pipeline from @bucknall2022](/images/pipeline.png){
  #fig-automation_pipeline
  fig-scap="Five-step AMTAIR automation pipeline from PDFs to Bayesian networks" 
  fig-alt="FLOWCHART: Five-step automation pipeline workflow for AMTAIR project.
          DATA: The pipeline transforms PDFs through ArgDown, BayesDown, CSV, and HTML into Bayesian network visualizations.
          PURPOSE: Illustrates the core technical process that enables automated extraction of probabilistic models from AI safety literature.
          DETAILS: Five numbered green steps show: (1) LLM-based extraction from PDFs to ArgDown, (2) ArgDown to BayesDown completion with probabilities, (3) Extracting world-models as CSV data, (4) Software tools for data inference, and (5) Visualization of the resulting Bayesian network.
          Each step includes example outputs, with the final visualization showing a Rain-Sprinkler-Grass Wet Bayesian network with probability tables.
          SOURCE: Created by the author to explain the AMTAIR methodology
          "
  fig-align="center" 
  width="100%"
  }](https://github.com/VJMeyer/submission)


Testing crossreferencing grapics @fig-automation_pipeline.

![Caption/Title 2](/images/cover.png){#fig-testgraphic2 fig-scap="Short 2 caption" fig-alt="2nd Alt Text / Description." fig-align="left" width="30%"}

Testing crossreferencing grapics @fig-testgraphic2.
\end{verbatim}

\begin{figure}

\centering{

\href{https://github.com/VJMeyer/submission}{\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/pipeline.png}}

}

\caption[Five-step AMTAIR automation pipeline from PDFs to Bayesian
networks]{\label{fig-automation_pipeline}AMTAIR Automation Pipeline
from}

\end{figure}%

Testing crossreferencing grapics Figure~\ref{fig-automation_pipeline}.
Note that the indentations of graphic inclusions get messed up by
viewing them in ``view mode'' in VS code.

\begin{figure}

\includegraphics[width=0.3\linewidth,height=\textheight,keepaspectratio]{images/cover.png}

\caption[Short 2 caption]{\label{fig-testgraphic2}Caption/Title 2}

\end{figure}%

Testing crossreferencing grapics Figure~\ref{fig-testgraphic2}.

\section*{Page Breaks}\label{page-breaks}
\addcontentsline{toc}{section}{Page Breaks}

\markright{Page Breaks}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{page 1}



\NormalTok{page 2}
\end{Highlighting}
\end{Shaded}

page 1

\newpage{}

page 2

\section*{Including Code}\label{sec-code}
\addcontentsline{toc}{section}{Including Code}

\markright{Including Code}

\begin{figure}

\centering{

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\BuiltInTok{print}\NormalTok{(}\StringTok{"AMTAIR is working!"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
AMTAIR is working!
\end{verbatim}

}

\caption{\label{fig-extraction-pipeline}}

\end{figure}%

\subsection*{In-Line LaTeX}\label{in-line-latex}
\addcontentsline{toc}{subsection}{In-Line LaTeX}

\renewcommand*{\labelitemi}{\textgreater}

\subsection*{In-Line HTML}\label{in-line-html}
\addcontentsline{toc}{subsection}{In-Line HTML}

Here's some raw inline HTML: html

\section*{Reference or Embed Code from .ipynb
files}\label{reference-or-embed-code-from-.ipynb-files}
\addcontentsline{toc}{section}{Reference or Embed Code from .ipynb
files}

\markright{Reference or Embed Code from .ipynb files}

\subsubsection*{Code chunks from .ipynb notebooks can be embedded in the
.qmd text
with:}\label{code-chunks-from-.ipynb-notebooks-can-be-embedded-in-the-.qmd-text-with}
\addcontentsline{toc}{subsubsection}{Code chunks from .ipynb notebooks
can be embedded in the .qmd text with:}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{\{\textless{} embed /AMTAIR\_Prototype/data/example\_carlsmith/AMTAIR\_Prototype\_example\_carlsmith.ipynb\#my\_code\_cell\_test \textgreater{}\}\}}
\end{Highlighting}
\end{Shaded}

\subsubsection*{which produces the output of executing the code
cell:}\label{which-produces-the-output-of-executing-the-code-cell}
\addcontentsline{toc}{subsubsection}{which produces the output of
executing the code cell:}

\phantomsection\label{my_code_cell_test}
\begin{verbatim}
Connecting to repository: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/
Attempting to load: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/ArgDown.md
✅ Successfully connected to repository and loaded test files.
[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {"instantiations": ["existential_catastrophe_TRUE", "existential_catastrophe_FALSE"]}
- [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {"instantiations": ["human_disempowerment_TRUE", "human_disempowerment_FALSE"]}
    - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {"instantiations": ["scale_of_power_seeking_TRUE", "scale_of_power_seeking_FALSE"]}
        - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}
            - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {"instantiations": ["aps_systems_TRUE", "aps_systems_FALSE"]}
                - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {"instantiations": ["advanced_ai_capability_TRUE", "advanced_ai_capability_FALSE"]}
                - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {"instantiations": ["agentic_planning_TRUE", "agentic_planning_FALSE"]}
                - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {"instantiations": ["strategic_awareness_TRUE", "strategic_awareness_FALSE"]}
            - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {"instantiations": ["difficulty_of_alignment_TRUE", "difficulty_of_alignment_FALSE"]}
                - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {"instantiations": ["instrumental_convergence_TRUE", "instrumental_convergence_FALSE"]}
                - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {"instantiations": ["problems_with_proxies_TRUE", "problems_with_proxies_FALSE"]}
                - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {"instantiations": ["problems_with_search_TRUE", "problems_with_search_FALSE"]}
            - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {"instantiations": ["deployment_decisions_DEPLOY", "deployment_decisions_WITHHOLD"]}
                - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {"instantiations": ["incentives_to_build_aps_STRONG", "incentives_to_build_aps_WEAK"]}
                    - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {"instantiations": ["usefulness_of_aps_HIGH", "usefulness_of_aps_LOW"]}
                    - [Competitive_Dynamics]: Competitive pressures between AI developers. {"instantiations": ["competitive_dynamics_STRONG", "competitive_dynamics_WEAK"]}
                - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {"instantiations": ["deception_by_ai_TRUE", "deception_by_ai_FALSE"]}
        - [Corrective_Feedback]: Human society implementing corrections after observing problems. {"instantiations": ["corrective_feedback_EFFECTIVE", "corrective_feedback_INEFFECTIVE"]}
            - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {"instantiations": ["warning_shots_OBSERVED", "warning_shots_UNOBSERVED"]}
            - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {"instantiations": ["rapid_capability_escalation_TRUE", "rapid_capability_escalation_FALSE"]}
[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {"instantiations": ["barriers_to_understanding_HIGH", "barriers_to_understanding_LOW"]}
- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}
[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {"instantiations": ["adversarial_dynamics_TRUE", "adversarial_dynamics_FALSE"]}
- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}
[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {"instantiations": ["stakes_of_error_HIGH", "stakes_of_error_LOW"]}
- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}
\end{verbatim}

\subsubsection*{including `echo=true' renders the code of the
cell:}\label{including-echotrue-renders-the-code-of-the-cell}
\addcontentsline{toc}{subsubsection}{including `echo=true' renders the
code of the cell:}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{\{\textless{} embed /AMTAIR\_Prototype/data/example\_carlsmith/AMTAIR\_Prototype\_example\_carlsmith.ipynb\#my\_code\_cell\_test echo=true \textgreater{}\}\}}
\end{Highlighting}
\end{Shaded}

\phantomsection\label{my_code_cell_test}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# @title 0.2 {-}{-}{-} Connect to GitHub Repository {-}{-}{-} Load Files}

\CommentTok{"""}
\CommentTok{BLOCK PURPOSE: Establishes connection to the AMTAIR GitHub repository and provides}
\CommentTok{functions to load example data files for processing.}

\CommentTok{This block creates a reusable function for accessing files from the project\textquotesingle{}s}
\CommentTok{GitHub repository, enabling access to example files like the rain{-}sprinkler{-}lawn}
\CommentTok{Bayesian network that serves as our canonical test case.}

\CommentTok{DEPENDENCIES: requests library, io library}
\CommentTok{OUTPUTS: load\_file\_from\_repo function and test file loads}
\CommentTok{"""}

\ImportTok{from}\NormalTok{ requests.exceptions }\ImportTok{import}\NormalTok{ HTTPError}

\CommentTok{\# Specify the base repository URL for the AMTAIR project}
\NormalTok{repo\_url }\OperatorTok{=} \StringTok{"https://raw.githubusercontent.com/SingularitySmith/AMTAIR\_Prototype/main/data/example\_carlsmith/"}
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Connecting to repository: }\SpecialCharTok{\{}\NormalTok{repo\_url}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

\KeywordTok{def}\NormalTok{ load\_file\_from\_repo(relative\_path):}
    \CommentTok{"""}
\CommentTok{    Loads a file from the specified GitHub repository using a relative path.}

\CommentTok{    Args:}
\CommentTok{        relative\_path (str): Path to the file relative to the repo\_url}

\CommentTok{    Returns:}
\CommentTok{        For CSV/JSON: pandas DataFrame}
\CommentTok{        For MD: string containing file contents}

\CommentTok{    Raises:}
\CommentTok{        HTTPError: If file not found or other HTTP error occurs}
\CommentTok{        ValueError: If unsupported file type is requested}
\CommentTok{    """}
\NormalTok{    file\_url }\OperatorTok{=}\NormalTok{ repo\_url }\OperatorTok{+}\NormalTok{ relative\_path}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Attempting to load: }\SpecialCharTok{\{}\NormalTok{file\_url}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

    \CommentTok{\# Fetch the file content from GitHub}
\NormalTok{    response }\OperatorTok{=}\NormalTok{ requests.get(file\_url)}

    \CommentTok{\# Check for bad status codes with enhanced error messages}
    \ControlFlowTok{if}\NormalTok{ response.status\_code }\OperatorTok{==} \DecValTok{404}\NormalTok{:}
        \ControlFlowTok{raise}\NormalTok{ HTTPError(}\SpecialStringTok{f"File not found at URL: }\SpecialCharTok{\{}\NormalTok{file\_url}\SpecialCharTok{\}}\SpecialStringTok{. Check the file path/name and ensure the file is publicly accessible."}\NormalTok{, response}\OperatorTok{=}\NormalTok{response)}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        response.raise\_for\_status()  }\CommentTok{\# Raise for other error codes}

    \CommentTok{\# Convert response to file{-}like object}
\NormalTok{    file\_object }\OperatorTok{=}\NormalTok{ io.StringIO(response.text)}

    \CommentTok{\# Process different file types appropriately}
    \ControlFlowTok{if}\NormalTok{ relative\_path.endswith(}\StringTok{".csv"}\NormalTok{):}
        \ControlFlowTok{return}\NormalTok{ pd.read\_csv(file\_object)  }\CommentTok{\# Return DataFrame for CSV}
    \ControlFlowTok{elif}\NormalTok{ relative\_path.endswith(}\StringTok{".json"}\NormalTok{):}
        \ControlFlowTok{return}\NormalTok{ pd.read\_json(file\_object)  }\CommentTok{\# Return DataFrame for JSON}
    \ControlFlowTok{elif}\NormalTok{ relative\_path.endswith(}\StringTok{".md"}\NormalTok{):}
        \ControlFlowTok{return}\NormalTok{ file\_object.read()  }\CommentTok{\# Return raw content for MD files}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{(}\SpecialStringTok{f"Unsupported file type: }\SpecialCharTok{\{}\NormalTok{relative\_path}\SpecialCharTok{.}\NormalTok{split(}\StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{)[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{. Add support in the GitHub Connection section of this notebook."}\NormalTok{)}

\CommentTok{\# Load example files to test connection}
\ControlFlowTok{try}\NormalTok{:}
    \CommentTok{\# Load the extracted data CSV file}
\CommentTok{\#    df = load\_file\_from\_repo("extracted\_data.csv")}

    \CommentTok{\# Load the ArgDown test text}
\NormalTok{    md\_content }\OperatorTok{=}\NormalTok{ load\_file\_from\_repo(}\StringTok{"ArgDown.md"}\NormalTok{)}

    \BuiltInTok{print}\NormalTok{(}\StringTok{"✅ Successfully connected to repository and loaded test files."}\NormalTok{)}
\ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"❌ Error loading files: }\SpecialCharTok{\{}\BuiltInTok{str}\NormalTok{(e)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Please check your internet connection and the repository URL."}\NormalTok{)}

\CommentTok{\# Display preview of loaded content (commented out to avoid cluttering output)}
\BuiltInTok{print}\NormalTok{(md\_content)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Connecting to repository: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/
Attempting to load: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/ArgDown.md
✅ Successfully connected to repository and loaded test files.
[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {"instantiations": ["existential_catastrophe_TRUE", "existential_catastrophe_FALSE"]}
- [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {"instantiations": ["human_disempowerment_TRUE", "human_disempowerment_FALSE"]}
    - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {"instantiations": ["scale_of_power_seeking_TRUE", "scale_of_power_seeking_FALSE"]}
        - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}
            - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {"instantiations": ["aps_systems_TRUE", "aps_systems_FALSE"]}
                - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {"instantiations": ["advanced_ai_capability_TRUE", "advanced_ai_capability_FALSE"]}
                - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {"instantiations": ["agentic_planning_TRUE", "agentic_planning_FALSE"]}
                - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {"instantiations": ["strategic_awareness_TRUE", "strategic_awareness_FALSE"]}
            - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {"instantiations": ["difficulty_of_alignment_TRUE", "difficulty_of_alignment_FALSE"]}
                - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {"instantiations": ["instrumental_convergence_TRUE", "instrumental_convergence_FALSE"]}
                - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {"instantiations": ["problems_with_proxies_TRUE", "problems_with_proxies_FALSE"]}
                - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {"instantiations": ["problems_with_search_TRUE", "problems_with_search_FALSE"]}
            - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {"instantiations": ["deployment_decisions_DEPLOY", "deployment_decisions_WITHHOLD"]}
                - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {"instantiations": ["incentives_to_build_aps_STRONG", "incentives_to_build_aps_WEAK"]}
                    - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {"instantiations": ["usefulness_of_aps_HIGH", "usefulness_of_aps_LOW"]}
                    - [Competitive_Dynamics]: Competitive pressures between AI developers. {"instantiations": ["competitive_dynamics_STRONG", "competitive_dynamics_WEAK"]}
                - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {"instantiations": ["deception_by_ai_TRUE", "deception_by_ai_FALSE"]}
        - [Corrective_Feedback]: Human society implementing corrections after observing problems. {"instantiations": ["corrective_feedback_EFFECTIVE", "corrective_feedback_INEFFECTIVE"]}
            - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {"instantiations": ["warning_shots_OBSERVED", "warning_shots_UNOBSERVED"]}
            - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {"instantiations": ["rapid_capability_escalation_TRUE", "rapid_capability_escalation_FALSE"]}
[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {"instantiations": ["barriers_to_understanding_HIGH", "barriers_to_understanding_LOW"]}
- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}
[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {"instantiations": ["adversarial_dynamics_TRUE", "adversarial_dynamics_FALSE"]}
- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}
[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {"instantiations": ["stakes_of_error_HIGH", "stakes_of_error_LOW"]}
- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {"instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"]}
\end{verbatim}

Link:

Full Notebooks are embedded in the Appendix through the \_quarto.yml
file with:

\section*{Diagrams}\label{diagrams}
\addcontentsline{toc}{section}{Diagrams}

\markright{Diagrams}

Quarto has native support for embedding Mermaid and Graphviz diagrams.
This enables you to create flowcharts, sequence diagrams, state
diagrams, Gantt charts, and more using a plain text syntax inspired by
markdown.

For example, here we embed a flowchart created using Mermaid:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{flowchart LR}
\NormalTok{  A[Hard edge] {-}{-}\textgreater{} B(Round edge)}
\NormalTok{  B {-}{-}\textgreater{} C\{Decision\}}
\NormalTok{  C {-}{-}\textgreater{} D[Result one]}
\NormalTok{  C {-}{-}\textgreater{} E[Result two]}
\end{Highlighting}
\end{Shaded}

\includegraphics[width=6.88in,height=1.81in]{index_files/figure-latex/mermaid-figure-1.png}

\section*{Citations}\label{sec-citations}

\markright{Citations}

\textcite{soares2014}

\autocite{soares2014} and \autocite{knuth1984}

Blah Blah \autocites[see][33-35]{knuth1984}[also][chap.~1]{growiec2024}

Blah Blah \autocite[33-35, 38-39 and passim]{knuth1984}

Blah Blah \autocite{growiec2024,knuth1984}.

Growiec says blah \autocite*{growiec2024}

\subsection*{Narrative citations (author as
subject)}\label{narrative-citations-author-as-subject}
\addcontentsline{toc}{subsection}{Narrative citations (author as
subject)}

\textcite{soares2014} argues that AI alignment requires\ldots{}

\subsection*{Parenthetical citations (supporting
reference)}\label{parenthetical-citations-supporting-reference}
\addcontentsline{toc}{subsection}{Parenthetical citations (supporting
reference)}

Recent work supports this view \autocite{soares2014,knuth1984}.

\subsection*{Author-only citation (when discussing the
person)}\label{author-only-citation-when-discussing-the-person}
\addcontentsline{toc}{subsection}{Author-only citation (when discussing
the person)}

As \autocite*{soares2014} demonstrates in their analysis\ldots{}

\subsection*{Year-only citation (when author already
mentioned)}\label{year-only-citation-when-author-already-mentioned}
\addcontentsline{toc}{subsection}{Year-only citation (when author
already mentioned)}

Soares \autocite*{soares2014} later revised this position.

\subsection*{Page-specific references}\label{page-specific-references}
\addcontentsline{toc}{subsection}{Page-specific references}

The key insight appears in \autocite[45-67]{soares2014}.

\subsection*{Multiple works, different
pages}\label{multiple-works-different-pages}
\addcontentsline{toc}{subsection}{Multiple works, different pages}

This view is supported \autocites[23]{soares2014}[156-159]{knuth1984}.

\section*{Section Cross-References}\label{sec-crossref}
\addcontentsline{toc}{section}{Section Cross-References}

\markright{Section Cross-References}

Refer to sections like: \textbf{?@sec-adaptive-governance} and
\textbf{?@sec-crossref}

\begin{Shaded}
\begin{Highlighting}[]
\AnnotationTok{Caveat:}\CommentTok{ refering to sections with @sec{-}HEADINGS works only for sections with:}
\FunctionTok{\#\# Heading \{\#sec{-}HEADINGS\}}
\NormalTok{It does not work for sections with ".unnumbered and/or .unlisted":}
\FunctionTok{\#\# Heading \{\#sec{-}HEADINGS .unnumbered .unlisted\}}
\NormalTok{Furthermore the .qmd and/or .md yml settings (\textasciitilde{} numbering have to be just right)}
\end{Highlighting}
\end{Shaded}

\subsection*{Section Numbers}\label{section-numbers}
\addcontentsline{toc}{subsection}{Section Numbers}

By default, all headings in your document create a numbered section. You
customize numbering depth using the number-depth option. For example, to
only number sections immediately below the chapter level, use this:

\texttt{number-depth:\ 2}

Note that toc-depth is independent of number-depth (i.e.~you can have
unnumbered entries in the TOC if they are masked out from numbering by
number-depth).

Testing crossreferencing grapics Figure~\ref{fig-automation_pipeline}.
See \textbf{?@sec-syntax} for more details on visualizing model
diagnostics.

Testing crossreferencing headings Section~\ref{sec-carlsmith-model}

\texttt{Testing\ crossreferencing\ headings\ @sec-rain-sprinkler-grass}
which does not work yet.

Chapter Cross-Reference \textbf{?@sec-crossref}

\section*{Pages in Landscape}\label{pages-in-landscape}
\addcontentsline{toc}{section}{Pages in Landscape}

\markright{Pages in Landscape}

\begin{landscape}

This will appear in landscape but only in PDF format. Testing
crossreferencing headings Section~\ref{sec-carlsmith-model}

\end{landscape}

\bookmarksetup{startatroot}

\chapter*{Abstract}\label{sec-abstract}
\addcontentsline{toc}{chapter}{Abstract}

\markboth{Abstract}{Abstract}

\begin{quote}
The coordination crisis in AI governance presents a paradoxical
challenge: unprecedented investment in AI safety coexists alongside
fundamental coordination failures across technical, policy, and ethical
domains. These divisions systematically increase existential risk. This
thesis introduces AMTAIR (Automating Transformative AI Risk Modeling), a
computational approach addressing this coordination failure by
automating the extraction of probabilistic world models from AI safety
literature using frontier language models. The system implements an
end-to-end pipeline transforming unstructured text into interactive
Bayesian networks through a novel two-stage extraction process that
bridges communication gaps between stakeholders.
\end{quote}

\texttt{The\ coordination\ crisis\ in\ AI\ governance\ presents\ a\ paradoxical\ challenge:\ unprecedented\ investment\ in\ AI\ safety\ coexists\ alongside\ fundamental\ coordination\ failures\ across\ technical,\ policy,\ and\ ethical\ domains.\ These\ divisions\ systematically\ increase\ existential\ risk\ by\ creating\ safety\ gaps,\ misallocating\ resources,\ and\ fostering\ inconsistent\ approaches\ to\ interdependent\ problems.}

\begin{quote}
This thesis introduces AMTAIR (Automating Transformative AI Risk
Modeling), a computational approach that addresses this coordination
failure by automating the extraction of probabilistic world models from
AI safety literature using frontier language models.
\end{quote}

\texttt{The\ AMTAIR\ system\ implements\ an\ end-to-end\ pipeline\ that\ transforms\ unstructured\ text\ into\ interactive\ Bayesian\ networks\ through\ a\ novel\ two-stage\ extraction\ process:\ first\ capturing\ argument\ structure\ in\ ArgDown\ format,\ then\ enhancing\ it\ with\ probability\ information\ in\ BayesDown.\ This\ approach\ bridges\ communication\ gaps\ between\ stakeholders\ by\ making\ implicit\ models\ explicit,\ enabling\ comparison\ across\ different\ worldviews,\ providing\ a\ common\ language\ for\ discussing\ probabilistic\ relationships,\ and\ supporting\ policy\ evaluation\ across\ diverse\ scenarios.}

\bookmarksetup{startatroot}

\chapter*{Prefatory Apparatus:
Frontmatter}\label{prefatory-apparatus-frontmatter}
\addcontentsline{toc}{chapter}{Prefatory Apparatus: Frontmatter}

\markboth{Prefatory Apparatus: Frontmatter}{Prefatory Apparatus:
Frontmatter}

\section*{Illustrations and Terminology --- Quick
References}\label{illustrations-and-terminology-quick-references}
\addcontentsline{toc}{section}{Illustrations and Terminology --- Quick
References}

\markright{Illustrations and Terminology --- Quick References}

\subsection*{\texorpdfstring{\textbf{Acknowledgments}}{Acknowledgments}}\label{acknowledgments}
\addcontentsline{toc}{subsection}{\textbf{Acknowledgments}}

\begin{itemize}
\tightlist
\item
  Academic supervisor (Prof.~Timo Speith) and institution (University of
  Bayreuth)\\
\item
  Research collaborators, especially those connected to the original
  MTAIR project\\
\item
  Technical advisors who provided feedback on implementation aspects\\
\item
  Personal supporters who enabled the research through encouragement and
  feedback
\end{itemize}

\section*{List of Graphics \& Figures}\label{list-of-graphics-figures}
\addcontentsline{toc}{section}{List of Graphics \& Figures}

\markright{List of Graphics \& Figures}

\begin{itemize}
\tightlist
\item
  Figure 1.1: The coordination crisis in AI governance - visualization
  of fragmentation\\
\item
  Figure 2.1: The Carlsmith model - DAG representation\\
\item
  Figure 3.1: Research design overview - workflow diagram\\
\item
  Figure 3.2: From natural language to BayesDown - transformation
  process\\
\item
  Figure 4.1: ARPA system architecture - component diagram\\
\item
  Figure 4.2: Visualization of Rain-Sprinkler-Grass\_Wet Bayesian
  network - screenshot\\
\item
  Figure 5.1: Extraction quality metrics - comparative chart\\
\item
  Figure 5.2: Comparative analysis of AI governance worldviews - network
  visualization
\end{itemize}

\section*{List of Abbreviations}\label{list-of-abbreviations}
\addcontentsline{toc}{section}{List of Abbreviations}

\markright{List of Abbreviations}

esp.~especially

f., ff.~following

incl.~including

p., pp.~page(s)

MAD Mutually Assured Destruction

\begin{itemize}
\tightlist
\item
  AI - Artificial Intelligence\\
\item
  AGI - Artificial General Intelligence\\
\item
  ARPA - AI Risk Pathway Analyzer\\
\item
  DAG - Directed Acyclic Graph\\
\item
  LLM - Large Language Model\\
\item
  MTAIR - Modeling Transformative AI Risks\\
\item
  P(Doom) - Probability of existential catastrophe from misaligned AI\\
\item
  CPT - Conditional Probability Table
\end{itemize}

\section*{Glossary}\label{glossary}

\markright{Glossary}

\begin{itemize}
\tightlist
\item
  \textbf{Argument mapping}: A method for visually representing the
  structure of arguments\\
\item
  \textbf{BayesDown}: An extension of ArgDown that incorporates
  probabilistic information\\
\item
  \textbf{Bayesian network}: A probabilistic graphical model
  representing variables and their dependencies\\
\item
  \textbf{Conditional probability}: The probability of an event given
  that another event has occurred\\
\item
  \textbf{Directed Acyclic Graph (DAG)}: A graph with directed edges and
  no cycles\\
\item
  \textbf{Existential risk}: Risk of permanent curtailment of humanity's
  potential\\
\item
  \textbf{Power-seeking AI}: AI systems with instrumental incentives to
  acquire resources and power\\
\item
  \textbf{Prediction market}: A market where participants trade
  contracts that resolve based on future events\\
\item
  \textbf{d-separation}: A criterion for identifying conditional
  independence relationships in Bayesian networks\\
\item
  \textbf{Monte Carlo sampling}: A computational technique using random
  sampling to obtain numerical results
\end{itemize}

\subsection*{Quarto Features Previously Incompatible with LaTeX
(Below)}\label{quarto-features-previously-incompatible-with-latex-below}

\bookmarksetup{startatroot}

\chapter{AMTAIR Master's Thesis: Comprehensive Enhanced
Outline}\label{amtair-masters-thesis-comprehensive-enhanced-outline}

\bookmarksetup{startatroot}

\chapter{Introduction}\label{introduction}

IMPORTANT NOTE: Changing the formatting (html comment) of the yml at the
beginning of docs easily screws up the entire html rendering

\bookmarksetup{startatroot}

\chapter{Control if this file starts
numbering}\label{control-if-this-file-starts-numbering}

\section{numbering: start-at: 1 \# Start at Section 1 level: 1 \#
Chapter
level}\label{numbering-start-at-1-start-at-section-1-level-1-chapter-level}

\bookmarksetup{startatroot}

\chapter{Introduction}\label{sec-introduction}

\begin{quote}
Subtitle: An Epistemic Framework for Leveraging Frontier AI Systems to
Upscale Conditional Policy Assessments in Bayesian Networks on a Narrow
Path towards Existential Safety
\end{quote}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{10\% of Grade: \textasciitilde{} 14\% of text \textasciitilde{} 4200
words \textasciitilde{} 10 pages}, opacityback=0, arc=.35mm, breakable, toptitle=1mm, toprule=.15mm, colframe=quarto-callout-note-color-frame, bottomtitle=1mm, rightrule=.15mm, opacitybacktitle=0.6, left=2mm, titlerule=0mm, leftrule=.75mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, coltitle=black]

\begin{itemize}
\tightlist
\item
  introduces and motivates the core question or problem
\item
  provides context for discussion (places issue within a larger debate
  or sphere of relevance)
\item
  states precise thesis or position the author will argue for
\item
  provides roadmap indicating structure and key content points of the
  essay
\end{itemize}

\end{tcolorbox}

\texttt{{[}x{]}\ introduces\ and\ motivates\ the\ core\ question\ or\ problem}

\section{The Coordination Crisis in AI
Governance}\label{sec-coordination-crisis}

As AI capabilities advance at an accelerating pace---demonstrated by the
rapid progression from GPT-3 to GPT-4, Claude, and beyond---we face a
governance challenge unlike any in human history: how to ensure
increasingly powerful AI systems remain aligned with human values and
beneficial to humanity's long-term flourishing. This challenge becomes
particularly acute when considering the possibility of transformative AI
systems that could drastically alter civilization's trajectory,
potentially including existential risks from misaligned systems.

\begin{quote}
Despite unprecedented investment in AI safety research, rapidly growing
awareness among key stakeholders, and proliferating frameworks for
responsible AI development, we face what I'll term the ``coordination
crisis'' in AI governance---a systemic failure to align diverse efforts
across technical, policy, and strategic domains into a coherent response
proportionate to the risks we face.
\end{quote}

The AI governance landscape exhibits a peculiar paradox: extraordinary
activity alongside fundamental coordination failure. Consider the
current state of affairs:

Technical safety researchers develop increasingly sophisticated
alignment techniques, but often without clear implementation pathways to
deployment contexts. Policy specialists craft principles and regulatory
frameworks without sufficient technical grounding to ensure their
practical efficacy. Ethicists articulate normative principles that lack
operational specificity. Strategy researchers identify critical
uncertainties but struggle to translate these into actionable guidance.

\subsection{Empirical Paradox: Investment Alongside
Fragmentation}\label{sec-empirical-paradox}

The fragmentation problem manifests in incompatible frameworks between
technical researchers, policy specialists, and strategic analysts. Each
community develops sophisticated approaches within their domain, yet
translation between domains remains primitive. This creates systematic
blind spots where risks emerge at the interfaces between technical
capabilities, institutional responses, and strategic dynamics.

\subsection{Systematic Risk Increase Through Coordination
Failure}\label{sec-risk-increase}

Coordination failures systematically amplify existential risk through
multiple pathways. Safety gaps emerge when technical solutions lack
policy implementation pathways. Resource misallocation occurs when
multiple teams unknowingly duplicate efforts while critical areas remain
unaddressed. Most perniciously, locally optimized decisions by
individual actors can create negative-sum dynamics that increase overall
risk---a AI governance tragedy of the commons.

\subsection{Historical Parallels and Temporal
Urgency}\label{sec-historical-parallels}

Traditional governance approaches evolved for technologies with longer
development cycles and clearer deployment boundaries. The nuclear era
provided decades for international regime development. Climate
governance, despite its challenges, addresses a phenomenon unfolding
over centuries. AI development, by contrast, may transition from current
capabilities to transformative systems within years or decades,
compressing the available window for effective coordination.

\section{Research Question and Scope}\label{sec-research-question}

This thesis addresses a specific dimension of the coordination challenge
by investigating the question: \textbf{Can frontier AI technologies be
utilized to automate the modeling of transformative AI risks, enabling
robust prediction of policy impacts across diverse worldviews?}

\textbf{Refined Thesis Statement}: This thesis demonstrates that
frontier language models can automate the extraction and formalization
of probabilistic world models from AI safety literature, creating a
scalable computational framework that enhances coordination in AI
governance through systematic policy evaluation under uncertainty.

To break this down into its components:

\begin{itemize}
\tightlist
\item
  \textbf{Frontier AI Technologies}: Today's most capable language
  models (GPT-4, Claude-3 level systems)
\item
  \textbf{Automated Modeling}: Using these systems to extract and
  formalize argument structures from natural language
\item
  \textbf{Transformative AI Risks}: Potentially catastrophic outcomes
  from advanced AI systems, particularly existential risks
\item
  \textbf{Policy Impact Prediction}: Evaluating how governance
  interventions might alter probability distributions over outcomes
\item
  \textbf{Diverse Worldviews}: Accounting for fundamental disagreements
  about AI development trajectories and risk factors
\end{itemize}

The investigation encompasses both theoretical development and practical
implementation, focusing specifically on existential risks from
misaligned AI systems rather than broader AI ethics concerns. This
narrowed scope enables deep technical development while addressing the
highest-stakes coordination challenges.

\section{The Multiplicative Benefits
Framework}\label{sec-multiplicative-benefits}

The central thesis of this work is that combining three
elements---automated worldview extraction, prediction market
integration, and formal policy evaluation---creates multiplicative
rather than merely additive benefits for AI governance. Each component
enhances the others, creating a system more valuable than the sum of its
parts.

\textbf{Automated worldview extraction} using frontier language models
addresses the scaling bottleneck in current approaches to AI risk
modeling. The Modeling Transformative AI Risks (MTAIR) project
demonstrated the value of formal representation but required extensive
manual effort to translate qualitative arguments into quantitative
models. Automation enables processing orders of magnitude more content,
incorporating diverse perspectives, and maintaining models in near
real-time as new arguments emerge.

\textbf{Prediction market integration} grounds these models in
collective forecasting intelligence. By connecting formal
representations to live forecasting platforms, the system can
incorporate timely judgments about critical uncertainties from
calibrated forecasters. This creates a dynamic feedback loop, where
models inform forecasters and forecasts update models.

\textbf{Formal policy evaluation} transforms static risk assessments
into actionable guidance by modeling how specific interventions might
alter critical parameters. This enables conditional
forecasting---understanding not just the probability of adverse outcomes
but how those probabilities change under different policy regimes.

The synergy emerges because automation enables comprehensive data
integration, markets inform and validate models, and evaluation gains
precision from both automated extraction and market-based calibration.

\section{Thesis Structure and Roadmap}\label{sec-roadmap}

The remainder of this thesis develops the multiplicative benefits
framework from theoretical foundations to practical implementation,
following a progression from abstract principles to concrete
applications:

\textbf{Section 2} establishes the theoretical foundations and
methodological approach, examining why AI governance presents unique
epistemic challenges and how Bayesian networks can formalize causal
relationships in this domain. This section grounds the technical
contributions in established theory while identifying the specific gaps
AMTAIR addresses.

\textbf{Section 3} presents the AMTAIR implementation, detailing the
technical system that transforms qualitative arguments into formal
representations. It demonstrates the approach through two case studies:
the canonical Rain-Sprinkler-Lawn example for intuitive understanding
and the more complex Carlsmith model of power-seeking AI for real-world
validation.

\textbf{Section 4} provides critical analysis of the approach,
addressing potential failure modes, scaling challenges, and integration
with existing governance frameworks. This section engages seriously with
objections and limitations while demonstrating the robustness of the
core approach.

\textbf{Section 5} concludes by summarizing key contributions, drawing
out concrete policy implications, and suggesting directions for future
research. It returns to the opening coordination crisis to show how
AMTAIR provides partial but significant solutions.

Throughout this progression, I maintain a dual focus on theoretical
sophistication and practical utility. The framework aims not merely to
advance academic understanding of AI risk but to provide actionable
tools for improving coordination in AI governance.

Having established the coordination crisis and outlined how automated
modeling can address it, we now turn to the theoretical foundations that
make this approach possible. The next chapter examines the unique
epistemic challenges of AI governance and introduces the formal
tools---particularly Bayesian networks---that enable rigorous reasoning
under deep uncertainty.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\bookmarksetup{startatroot}

\chapter{Context \& Background}\label{sec-context}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{20\% of Grade: \textasciitilde{} 29\% of text \textasciitilde{} 8700
words \textasciitilde{} 20 pages}, opacityback=0, arc=.35mm, breakable, toptitle=1mm, toprule=.15mm, colframe=quarto-callout-note-color-frame, bottomtitle=1mm, rightrule=.15mm, opacitybacktitle=0.6, left=2mm, titlerule=0mm, leftrule=.75mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, coltitle=black]

\begin{itemize}
\tightlist
\item
  demonstrates understanding of all relevant core concepts
\item
  explains why the question/thesis/problem is relevant in student's own
  words (supported by quotations)
\item
  situates it within the debate/course material
\item
  reconstructs selected arguments and identifies relevant assumptions
\item
  describes additional relevant material that has been consulted and
  integrates it with the course material as well as the research
  question/thesis/problem
\end{itemize}

\end{tcolorbox}

\section{Theoretical Foundations}\label{sec-theoretical-foundations}

\subsection{AI Existential Risk: The Carlsmith
Model}\label{sec-carlsmith-model}

Carlsmith's ``Is power-seeking AI an existential risk?'' (2021)
represents one of the most structured approaches to assessing the
probability of existential catastrophe from advanced AI. The analysis
decomposes the overall risk into six key premises, each with an explicit
probability estimate.

\begin{quote}
\textcite{carlsmith2021} provides the canonical structured approach to
AI existential risk assessment
\end{quote}

\textbf{Six-Premise Decomposition:}

Carlsmith decomposes existential risk into a probabilistic chain with
explicit estimates:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Premise 1}: Transformative AI development this century (P ≈
  0.80)
\item
  \textbf{Premise 2}: AI systems pursuing objectives in the world (P ≈
  0.95)
\item
  \textbf{Premise 3}: Systems with power-seeking instrumental incentives
  (P ≈ 0.40)
\item
  \textbf{Premise 4}: Sufficient capability for existential threat (P ≈
  0.65)
\item
  \textbf{Premise 5}: Misaligned systems despite safety efforts (P ≈
  0.50)
\item
  \textbf{Premise 6}: Catastrophic outcomes from misaligned
  power-seeking (P ≈ 0.65)
\end{enumerate}

\textbf{Composite Risk Calculation}: P(doom) ≈ 0.05 (5\%)

This structured approach exemplifies the type of reasoning that AMTAIR
aims to formalize and automate, providing both transparency in
assumptions and modularity for critique and refinement.

\subsubsection{Why Carlsmith as Ideal Formalization
Target}\label{sec-carlsmith-ideal}

Carlsmith's model represents ``low-hanging fruit'' for automated
formalization because it already exhibits explicit probabilistic
reasoning with clear conditional dependencies. Success with this
structured argument validates the approach for less explicit arguments
throughout AI safety literature. The model demonstrates several key
features that make it ideal for formalization: explicitly probabilistic
reasoning with quantified estimates, clear conditional dependencies
between premises, transparent decomposition of complex causal pathways,
well-documented argumentation available for extraction validation, and
policy-relevant implications requiring formal evaluation.

\subsection{The Epistemic Challenge of Policy
Evaluation}\label{sec-epistemic-challenge}

AI governance policy evaluation faces unique epistemic challenges that
render traditional policy analysis methods insufficient. The domain
combines complex causal chains with limited empirical grounding, deep
uncertainty about future capabilities, divergent stakeholder worldviews,
and few opportunities for experimental testing before deployment.

Traditional methods fall short in several ways. Cost-benefit analysis
struggles with existential outcomes and deep uncertainty about
unprecedented events. Scenario planning often lacks the probabilistic
reasoning necessary for rigorous evaluation under uncertainty. Expert
elicitation alone fails to formalize interdependencies between variables
and make assumptions explicit. Qualitative approaches obscure crucial
assumptions that drive conclusions, making it difficult to identify
cruxes of disagreement.

\textbf{Unprecedented Epistemic Environment:}

The AI governance domain presents specific challenges that traditional
policy analysis cannot adequately address:

\begin{itemize}
\tightlist
\item
  \textbf{Deep Uncertainty}: Many decisions involve unprecedented
  scenarios without historical frequency data for calibration
\item
  \textbf{Complex Causality}: Policy effects propagate through
  multi-level dependencies spanning technical, institutional, and
  strategic domains
\item
  \textbf{Multidisciplinary Integration}: Combining technical facts,
  ethical principles, and strategic considerations requires novel
  synthesis approaches
\item
  \textbf{Value-Laden Assessment}: Risk evaluation inherently involves
  normative judgments about acceptable outcomes and distributional
  effects
\end{itemize}

\subsubsection{Unique Difficulties in AI
Governance}\label{sec-unique-difficulties}

\textbf{Complex Causal Chains}: Multi-level dependencies between
technical capabilities, institutional responses, and strategic outcomes
create analytical challenges beyond traditional policy domains.

\textbf{Deep Uncertainty}: Unprecedented AI capabilities make historical
analogies insufficient, requiring new approaches to reasoning about
low-probability, high-impact events.

\textbf{Divergent Worldviews}: Fundamental disagreements persist about
timeline expectations for transformative AI, difficulty of alignment
problems, effectiveness of governance interventions, and possibilities
for international coordination.

\subsubsection{Limitations of Traditional Policy
Analysis}\label{sec-traditional-limitations}

Traditional policy analysis approaches prove inadequate for AI
governance challenges. Cost-benefit analysis struggles with potentially
infinite expected values from existential outcomes and lacks frameworks
for deep uncertainty. Scenario planning, while useful for exploration,
often lacks the probabilistic reasoning necessary for rigorous
uncertainty quantification and policy comparison. Expert elicitation
methods fail to formalize complex interdependencies between variables,
leaving implicit assumptions unexamined. Qualitative frameworks, though
rich in insight, obscure crucial assumptions and parameter sensitivities
that drive different conclusions about optimal policies.

\subsection{Argument Mapping and Formal
Representations}\label{sec-argument-mapping}

Argument mapping offers a bridge between informal reasoning in natural
language and the formal representations needed for rigorous analysis. By
explicitly identifying claims, premises, inferential relationships, and
support/attack patterns, argument maps make implicit reasoning
structures visible for examination and critique.

The progression from natural language arguments to formal Bayesian
networks requires an intermediate representation that preserves
narrative structure while adding mathematical precision. The ArgDown
format serves this purpose by encoding hierarchical relationships
between statements, while its extension, BayesDown, adds probabilistic
metadata to enable full Bayesian network construction.

\begin{verbatim}
[Effect_Node]: Description of effect. {"instantiations": ["effect_TRUE", "effect_FALSE"]}
 + [Cause_Node]: Description of direct cause. {"instantiations": ["cause_TRUE", "cause_FALSE"]}
   + [Root_Cause]: Description of indirect cause. {"instantiations": ["root_TRUE", "root_FALSE"]}
\end{verbatim}

\subsection{Bayesian Networks as Knowledge
Representation}\label{sec-bayesian-networks}

Bayesian networks provide a formal mathematical framework for
representing causal relationships and reasoning under uncertainty. These
directed acyclic graphs (DAGs) combine qualitative structure---nodes
representing variables and edges representing dependencies---with
quantitative parameters in the form of conditional probability tables.

\subsubsection{Mathematical
Foundations}\label{sec-mathematical-foundations}

Bayesian networks provide a formal mathematical framework for
representing causal relationships and reasoning under uncertainty
through Directed Acyclic Graphs (DAGs) combining qualitative structure
with quantitative parameters.

\textbf{Core Components:}

\begin{itemize}
\tightlist
\item
  \textbf{Nodes}: Variables with discrete states representing
  propositions or factors
\item
  \textbf{Edges}: Directed relationships representing conditional
  dependencies
\item
  \textbf{Acyclicity}: Ensuring coherent probabilistic interpretation
  without circular dependencies
\item
  \textbf{Conditional Probability Tables}: Quantifying
  P(Node\textbar Parents) for all parent state combinations
\end{itemize}

\textbf{Probability Factorization}:
\(P(X_1, X_2, ..., X_n) = \prod_{i=1}^{n} P(X_i | Parents(X_i))\)

\subsubsection{The Rain-Sprinkler-Grass
Example}\label{sec-rain-sprinkler-example}

This simple example demonstrates all key concepts while remaining
intuitive. The network structure consists of Rain as a root cause with
P(rain) = 0.2, Sprinkler as an intermediate variable where
P(sprinkler\textbar rain) varies by rain state, and Grass\_Wet as the
effect where P(wet\textbar rain, sprinkler) depends on both causes.

The example enables various inference capabilities including marginal
probabilities such as P(grass\_wet) computed from the joint
distribution, conditional queries like P(rain\textbar grass\_wet) for
diagnostic reasoning, and counterfactual analysis such as
P(grass\_wet\textbar do(sprinkler=false)) for intervention effects.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Basic network representation}
\NormalTok{nodes }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}Rain\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Sprinkler\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Grass\_Wet\textquotesingle{}}\NormalTok{]}
\NormalTok{edges }\OperatorTok{=}\NormalTok{ [(}\StringTok{\textquotesingle{}Rain\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Sprinkler\textquotesingle{}}\NormalTok{), (}\StringTok{\textquotesingle{}Rain\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Grass\_Wet\textquotesingle{}}\NormalTok{), (}\StringTok{\textquotesingle{}Sprinkler\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}Grass\_Wet\textquotesingle{}}\NormalTok{)]}

\CommentTok{\# Conditional probability specification}
\NormalTok{P\_wet\_given\_causes }\OperatorTok{=}\NormalTok{ \{}
\NormalTok{    (}\VariableTok{True}\NormalTok{, }\VariableTok{True}\NormalTok{): }\FloatTok{0.99}\NormalTok{,    }\CommentTok{\# Rain=T, Sprinkler=T}
\NormalTok{    (}\VariableTok{True}\NormalTok{, }\VariableTok{False}\NormalTok{): }\FloatTok{0.80}\NormalTok{,   }\CommentTok{\# Rain=T, Sprinkler=F  }
\NormalTok{    (}\VariableTok{False}\NormalTok{, }\VariableTok{True}\NormalTok{): }\FloatTok{0.90}\NormalTok{,   }\CommentTok{\# Rain=F, Sprinkler=T}
\NormalTok{    (}\VariableTok{False}\NormalTok{, }\VariableTok{False}\NormalTok{): }\FloatTok{0.01}   \CommentTok{\# Rain=F, Sprinkler=F}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Advantages for AI Risk
Modeling}\label{sec-modeling-advantages}

Bayesian networks offer several key advantages for AI risk modeling.
They provide explicit uncertainty representation where all beliefs are
represented with probability distributions rather than point estimates.
The framework naturally supports causal reasoning through native support
for intervention analysis and counterfactual reasoning via do-calculus.
Evidence integration becomes principled through Bayesian updating
mechanisms. The modular structure allows complex arguments to be
decomposed into manageable, verifiable components. Finally, the visual
communication provided by graphical representation facilitates
understanding across different expertise levels.

\subsection{The MTAIR Framework: Achievements and
Limitations}\label{sec-mtair-framework}

The Modeling Transformative AI Risks (MTAIR) project demonstrated the
value of formal probabilistic modeling for AI safety, but also revealed
significant limitations in the manual approach. While MTAIR successfully
translated complex arguments into Bayesian networks and enabled
sensitivity analysis, the intensive human labor required for model
creation limited both scalability and timeliness.

\begin{quote}
\textcite{bucknall2022} on the original Modeling Transformative AI Risks
project demonstrates both the value and limitations of manual formal
modeling approaches.
\end{quote}

\subsubsection{MTAIR's Innovations}\label{sec-mtair-innovations}

MTAIR's key innovations advanced the field of AI risk modeling
significantly. The project introduced structured uncertainty
representation through explicit probability distributions over key
variables rather than point estimates. It developed systematic methods
for expert judgment integration, aggregating diverse expert opinions and
beliefs. The sensitivity analysis capabilities enabled identification of
critical uncertainties that most significantly drive overall
conclusions. Perhaps most importantly, it established direct connections
between technical risk models and governance implications, bridging the
gap between technical analysis and policy application.

\subsubsection{Fundamental Limitations Motivating
AMTAIR}\label{sec-mtair-limitations}

Despite its innovations, MTAIR faces fundamental limitations that
motivate the automated approach. The scalability bottleneck is
severe---manual model construction requires weeks of expert effort per
argument, making comprehensive coverage impossible. The static nature of
manually constructed models provides no mechanisms for updating as new
research and evidence emerge. Limited accessibility restricts usage to
specialists with formal modeling expertise, excluding many stakeholders.
Finally, the single worldview focus creates difficulty in representing
multiple conflicting perspectives simultaneously, limiting the
framework's utility for coordination across diverse viewpoints.

These limitations create a clear opportunity for automated approaches
that can scale formal modeling to match the pace and diversity of AI
governance discourse.

\subsubsection{Mechanics of World Modeling in
Analytica}\label{sec-analytica-mechanics}

The MTAIR project's Analytica implementation provides important lessons
for automation. The manual process involves several key steps: variable
identification through careful reading of source texts, structure
elicitation via expert interviews and workshops, probability
quantification using various elicitation techniques, and validation
through sensitivity analysis and expert review. Each step requires
significant time and expertise, with a single model taking weeks to
months to develop. Understanding these mechanics helps identify specific
opportunities for automation while preserving the rigor of the manual
approach.

\subsection{Literature Review: Content
Level}\label{sec-content-literature}

\subsubsection{AI Risk Models
Evolution}\label{sec-risk-models-evolution}

The evolution of AI risk models reflects increasing sophistication in
both structure and quantification. Early models focused on simple binary
outcomes, while recent work incorporates complex causal chains and
continuous variables. Key developments include:

The progression from qualitative arguments to structured probabilistic
models demonstrates the field's maturation and the increasing
recognition that rigorous quantitative analysis is essential for policy
evaluation.

\subsubsection{Governance Proposals
Taxonomy}\label{sec-governance-taxonomy}

AI governance proposals can be categorized along several dimensions:

\begin{itemize}
\tightlist
\item
  \textbf{Technical Standards}: Safety requirements, testing protocols,
  capability thresholds
\item
  \textbf{Regulatory Frameworks}: Licensing regimes, liability
  structures, oversight mechanisms
\item
  \textbf{International Coordination}: Treaties, soft law arrangements,
  technical cooperation
\item
  \textbf{Research Priorities}: Funding allocation, talent development,
  knowledge sharing
\end{itemize}

\subsection{Literature Review: Technical/Theoretical
Background}\label{sec-technical-literature}

\subsubsection{Bayesian Network Theory}\label{sec-bn-theory}

The theoretical foundations of Bayesian networks rest on probability
theory and graph theory. Key concepts include conditional independence
encoded through d-separation, the Markov condition relating graph
structure to probabilistic relationships, and inference algorithms
ranging from exact methods like variable elimination to approximate
approaches like Monte Carlo sampling.

\subsubsection{Software Tools Landscape}\label{sec-software-tools}

The implementation of AMTAIR builds on established software libraries:

\begin{itemize}
\tightlist
\item
  \textbf{pgmpy}: Python library for probabilistic graphical models,
  providing network construction and inference
\item
  \textbf{NetworkX}: Graph analysis and manipulation capabilities
\item
  \textbf{PyVis}: Interactive network visualization
\item
  \textbf{Pandas/NumPy}: Data manipulation and numerical computation
\end{itemize}

\subsubsection{Formalization Approaches}\label{sec-formalization}

Formalizing natural language arguments into mathematical models involves
several theoretical challenges. The translation must preserve semantic
content while adding mathematical precision. Key approaches include
structured extraction templates, semantic parsing techniques, and hybrid
human-AI workflows.

\subsubsection{Correlation Accounting
Methods}\label{sec-correlation-methods}

Standard Bayesian networks assume conditional independence given
parents, but real-world AI risk factors often exhibit complex
correlations. Methods for handling correlations include:

\begin{itemize}
\tightlist
\item
  \textbf{Copula Methods}: Modeling dependence structures separately
  from marginal distributions
\item
  \textbf{Hierarchical Models}: Capturing correlations through shared
  latent variables
\item
  \textbf{Explicit Correlation Nodes}: Adding nodes to represent
  correlation mechanisms
\item
  \textbf{Sensitivity Bounds}: Analyzing impact of independence
  assumptions
\end{itemize}

\section{Methodology}\label{sec-methodology}

\subsection{Research Design Overview}\label{sec-research-design}

This research combines theoretical development with practical
implementation, following an iterative approach that moves between
conceptual refinement and technical validation. The methodology
encompasses formal framework development, computational implementation,
extraction quality assessment, and application to real-world AI
governance questions.

The research process follows four integrated phases:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Framework Development}: Creating theoretical foundations for
  automated worldview extraction
\item
  \textbf{Technical Implementation}: Building computational tools as
  working prototype
\item
  \textbf{Empirical Validation}: Assessing quality against expert
  benchmarks
\item
  \textbf{Policy Application}: Demonstrating practical utility for
  governance questions
\end{enumerate}

\subsection{Formalizing World Models from AI Safety
Literature}\label{sec-formalizing-world-models}

The core methodological challenge involves transforming natural language
arguments in AI safety literature into formal causal models with
explicit probability judgments. This extraction process identifies key
variables, causal relationships, and both explicit and implicit
probability estimates through a systematic pipeline.

The extraction approach combines several elements: identification of key
variables and entities in text, recognition of causal claims and
relationships, detection of explicit and implicit probability judgments,
transformation into structured intermediate representations, and
conversion to formal Bayesian networks.

Large language models facilitate this process through specialized
techniques including two-stage prompting that separates structure from
probability extraction, specialized templates for different types of
source documents, techniques for identifying implicit assumptions and
relationships, and mechanisms for handling ambiguity and uncertainty.

\subsection{From Natural Language to Computational
Models}\label{sec-natural-to-computational}

\subsubsection{The Two-Stage Extraction
Process}\label{sec-two-stage-extraction}

AMTAIR employs a novel two-stage process that separates structural
argument extraction from probability quantification, enabling modular
improvement and human oversight at critical decision points.

\textbf{Stage 1: Structural Extraction (ArgDown Generation)}

The first stage focuses on identifying the argument structure:
extracting key propositions and entities from natural language text,
mapping support/attack relationships and conditional dependencies,
constructing properly nested argument representations that preserve
logical flow, and creating ArgDown format suitable for both human review
and machine processing.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ extract\_argument\_structure(text):}
    \CommentTok{"""Extract hierarchical argument structure from natural language"""}
    \CommentTok{\# LLM{-}based extraction with specialized prompts}
\NormalTok{    prompt }\OperatorTok{=}\NormalTok{ ArgumentExtractionPrompt(}
\NormalTok{        text}\OperatorTok{=}\NormalTok{text,}
\NormalTok{        output\_format}\OperatorTok{=}\StringTok{"ArgDown"}\NormalTok{,}
\NormalTok{        focus\_areas}\OperatorTok{=}\NormalTok{[}\StringTok{"causal\_claims"}\NormalTok{, }\StringTok{"probability\_statements"}\NormalTok{, }\StringTok{"conditional\_reasoning"}\NormalTok{]}
\NormalTok{    )}
    
\NormalTok{    structure }\OperatorTok{=}\NormalTok{ llm.complete(prompt)}
    \ControlFlowTok{return}\NormalTok{ validate\_argdown\_syntax(structure)}
\end{Highlighting}
\end{Shaded}

\textbf{Stage 2: Probability Integration (BayesDown Enhancement)}

The second stage adds quantitative information: identifying and parsing
numerical probability statements in source text, creating systematic
elicitation questions for implicit probability judgments, incorporating
domain expertise for ambiguous or missing quantifications, and ensuring
probability assignments satisfy basic coherence requirements.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ integrate\_probabilities(argdown\_structure, probability\_sources):}
    \CommentTok{"""Convert ArgDown to BayesDown with probabilistic information"""}
\NormalTok{    questions }\OperatorTok{=}\NormalTok{ generate\_probability\_questions(argdown\_structure)}
\NormalTok{    probabilities }\OperatorTok{=}\NormalTok{ extract\_probabilities(probability\_sources, questions)}
    
\NormalTok{    bayesdown }\OperatorTok{=}\NormalTok{ enhance\_with\_probabilities(argdown\_structure, probabilities)}
    \ControlFlowTok{return}\NormalTok{ validate\_probability\_coherence(bayesdown)}
\end{Highlighting}
\end{Shaded}

\subsection{Directed Acyclic Graphs: Structure and
Semantics}\label{sec-dag-structure}

Directed Acyclic Graphs (DAGs) form the mathematical foundation of
Bayesian networks, encoding both the qualitative structure of causal
relationships and the quantitative parameters that define conditional
dependencies. In AI risk modeling, these structures represent causal
pathways to potential outcomes of interest.

Key mathematical properties essential for AI risk modeling include the
acyclicity requirement ensuring coherent probabilistic interpretation
without logical contradictions, d-separation defining conditional
independence relationships between variables based on graph structure,
the Markov condition where each variable is conditionally independent of
non-descendants given parents, and path analysis revealing causal
pathways and information flow through the network structure.

The causal interpretation in AI governance contexts follows Pearl's
framework, where edges represent direct causal influence between
factors, intervention analysis through do-calculus enables rigorous
evaluation of policy effects, counterfactual reasoning supports ``what
if'' scenarios essential for governance planning, and evidence
integration through Bayesian updating incorporates new information and
expert judgment.

\subsection{Quantification of Probabilistic
Judgments}\label{sec-quantification}

Transforming qualitative uncertainty expressions into quantitative
probabilities requires systematic interpretation frameworks that account
for individual and cultural variation.

Standard linguistic mappings (with significant individual variation)
include:

\begin{itemize}
\tightlist
\item
  ``Very likely'' → 0.8-0.9
\item
  ``Probable'' → 0.6-0.8
\item
  ``Uncertain'' → 0.4-0.6
\item
  ``Unlikely'' → 0.2-0.4
\item
  ``Highly improbable'' → 0.05-0.15
\end{itemize}

Expert elicitation methodologies provide various approaches: direct
probability assessment asking ``What is P(outcome)?'' with calibration
training, comparative assessment asking ``Is A more likely than B?'' for
relative judgment validation, frequency format asking ``In 100 similar
cases, how many would result in outcome?'' for clearer mental models,
and betting odds asking ``What odds would you accept for this bet?'' for
revealed preference elicitation.

Calibration and validation face several challenges including individual
variation in linguistic interpretation and probability anchoring,
domain-specific anchoring and reference class selection, cultural and
contextual influences on uncertainty expression and tolerance, and
limited empirical basis for calibration in unprecedented scenarios like
transformative AI.

\subsection{Inference Techniques for Complex
Networks}\label{sec-inference-techniques}

Once Bayesian networks are constructed, probabilistic inference enables
reasoning about uncertainties, counterfactuals, and policy
interventions. For the complex networks representing AI risks,
computational approaches must balance accuracy with tractability.

Inference methods implemented include exact methods for smaller networks
(variable elimination, junction trees), approximate methods for larger
networks (Monte Carlo sampling, variational inference), specialized
approaches for rare event analysis, and intervention modeling for policy
evaluation using do-calculus.

Implementation considerations involve computational complexity
management through network decomposition, sampling efficiency
optimization via importance sampling, approximation quality monitoring
with convergence diagnostics, and uncertainty representation in outputs
including confidence intervals.

\subsection{Integration with Prediction Markets and Forecasting
Platforms}\label{sec-prediction-markets}

To maintain relevance in a rapidly evolving field, formal models must
integrate with live data sources such as prediction markets and
forecasting platforms. This integration enables continuous updating of
model parameters as new information emerges.

Live data sources for dynamic model updating include:

\begin{itemize}
\tightlist
\item
  \textbf{Metaculus}: Long-term AI predictions and technological
  forecasting
\item
  \textbf{Good Judgment Open}: Geopolitical events and policy outcomes
\item
  \textbf{Manifold Markets}: Diverse question types with rapid market
  response
\item
  \textbf{Internal Expert Forecasting}: Organization-specific
  predictions and assessments
\end{itemize}

The data processing and integration pipeline connects these sources:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ integrate\_forecast\_data(model\_variables, forecast\_platforms):}
    \CommentTok{"""Connect Bayesian network variables to live forecasting data"""}
\NormalTok{    mappings }\OperatorTok{=}\NormalTok{ create\_semantic\_mappings(model\_variables, forecast\_platforms)}
    
    \ControlFlowTok{for}\NormalTok{ variable, forecasts }\KeywordTok{in}\NormalTok{ mappings.items():}
\NormalTok{        weighted\_forecast }\OperatorTok{=}\NormalTok{ aggregate\_forecasts(}
\NormalTok{            forecasts, }
\NormalTok{            weights}\OperatorTok{=}\NormalTok{calculate\_track\_record\_weights(forecasts)}
\NormalTok{        )}
\NormalTok{        model.update\_prior(variable, weighted\_forecast)}
    
    \ControlFlowTok{return}\NormalTok{ model.recompute\_posteriors()}
\end{Highlighting}
\end{Shaded}

Technical implementation challenges include question mapping to connect
forecast questions to specific model variables with semantic accuracy,
temporal alignment handling different forecast horizons and update
frequencies, conflict resolution through principled aggregation when
sources provide contradictory information, and track record weighting
incorporating forecaster calibration and expertise into aggregation.

With these theoretical foundations and methodological approaches
established, we can now present the AMTAIR system implementation. The
next chapter demonstrates how these concepts translate into a working
prototype that automates the extraction and formalization of world
models from AI safety literature.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\bookmarksetup{startatroot}

\chapter{AMTAIR Implementation}\label{sec-amtair-implementation}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{20\% of Grade: \textasciitilde{} 29\% of text \textasciitilde{} 8700
words \textasciitilde{} 20 pages}, opacityback=0, arc=.35mm, breakable, toptitle=1mm, toprule=.15mm, colframe=quarto-callout-note-color-frame, bottomtitle=1mm, rightrule=.15mm, opacitybacktitle=0.6, left=2mm, titlerule=0mm, leftrule=.75mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, coltitle=black]

\begin{itemize}
\tightlist
\item
  provides critical or constructive evaluation of positions introduced
\item
  develops strong (plausible) argument in support of author's own
  position/thesis
\item
  argument draws on relevant course material claim/argument
\item
  demonstrate understanding of the course materials incl.~key arguments
  and core concepts within the debate
\item
  claim/argument is original or insightful, possibly even presents an
  original contribution to the debate
\end{itemize}

\end{tcolorbox}

\section{Software Implementation}\label{sec-software-implementation}

\subsection{System Architecture and Data
Flow}\label{sec-system-architecture}

The AMTAIR system implements an end-to-end pipeline from unstructured
text to interactive Bayesian network visualization. Its modular
architecture comprises five main components that progressively transform
information from natural language into formal models suitable for policy
analysis.

The five-stage pipeline architecture demonstrates how each component
builds on the previous, with validation checkpoints preventing error
propagation:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Text Ingestion and Preprocessing}: Handles format
  normalization (PDF, HTML, Markdown), metadata extraction, citation
  tracking, and relevance filtering
\item
  \textbf{BayesDown Extraction}: Two-stage argument structure
  identification and probabilistic information integration with quality
  validation
\item
  \textbf{Structured Data Transformation}: Parsing into standardized
  relational formats with network topology validation
\item
  \textbf{Bayesian Network Construction}: Mathematical model
  instantiation using NetworkX and pgmpy libraries
\item
  \textbf{Interactive Visualization}: Dynamic rendering with PyVis and
  probability-based visual encoding
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{ AMTAIRPipeline:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{):}
        \VariableTok{self}\NormalTok{.ingestion }\OperatorTok{=}\NormalTok{ DocumentIngestion()}
        \VariableTok{self}\NormalTok{.extraction }\OperatorTok{=}\NormalTok{ BayesDownExtractor() }
        \VariableTok{self}\NormalTok{.transformation }\OperatorTok{=}\NormalTok{ DataTransformer()}
        \VariableTok{self}\NormalTok{.network\_builder }\OperatorTok{=}\NormalTok{ BayesianNetworkBuilder()}
        \VariableTok{self}\NormalTok{.visualizer }\OperatorTok{=}\NormalTok{ InteractiveVisualizer()}
    
    \KeywordTok{def}\NormalTok{ process(}\VariableTok{self}\NormalTok{, document):}
        \CommentTok{"""End{-}to{-}end processing from document to interactive model"""}
\NormalTok{        structured\_data }\OperatorTok{=} \VariableTok{self}\NormalTok{.ingestion.preprocess(document)}
\NormalTok{        bayesdown }\OperatorTok{=} \VariableTok{self}\NormalTok{.extraction.extract(structured\_data)}
\NormalTok{        dataframe }\OperatorTok{=} \VariableTok{self}\NormalTok{.transformation.convert(bayesdown)}
\NormalTok{        network }\OperatorTok{=} \VariableTok{self}\NormalTok{.network\_builder.construct(dataframe)}
        \ControlFlowTok{return} \VariableTok{self}\NormalTok{.visualizer.render(network)}
\end{Highlighting}
\end{Shaded}

The design principles emphasize scalability through modular architecture
where each component can be improved independently, standard interfaces
using JSON and CSV formats for interoperability, validation checkpoints
with quality gates at each stage, and an extensible framework supporting
additional analysis capabilities without core changes.

\subsection{Rain-Sprinkler-Grass Example
Implementation}\label{sec-rain-sprinkler-grass}

The Rain-Sprinkler-Grass example serves as a canonical test case
demonstrating each step in the AMTAIR pipeline. This simple causal
scenario---where both rain and sprinkler use can cause wet grass, and
rain influences sprinkler use---provides an intuitive introduction to
Bayesian network concepts while exercising all system components.

\textbf{Stage 1: BayesDown Input Representation}

The structured representation captures both hierarchical relationships
and probability information:

\begin{verbatim}
[Grass_Wet]: Concentrated moisture on, between and around the blades of grass. 
{"instantiations": ["grass_wet_TRUE", "grass_wet_FALSE"], 
 "priors": {"p(grass_wet_TRUE)": "0.322", "p(grass_wet_FALSE)": "0.678"},
 "posteriors": {
   "p(grass_wet_TRUE|sprinkler_TRUE,rain_TRUE)": "0.99",
   "p(grass_wet_TRUE|sprinkler_TRUE,rain_FALSE)": "0.9",
   "p(grass_wet_TRUE|sprinkler_FALSE,rain_TRUE)": "0.8", 
   "p(grass_wet_TRUE|sprinkler_FALSE,rain_FALSE)": "0.0"
 }}
 + [Rain]: Tears of angels crying high up in the skies hitting the ground.
   {"instantiations": ["rain_TRUE", "rain_FALSE"],
    "priors": {"p(rain_TRUE)": "0.2", "p(rain_FALSE)": "0.8"}}
 + [Sprinkler]: Activation of a centrifugal force based CO2 droplet distribution system.
   {"instantiations": ["sprinkler_TRUE", "sprinkler_FALSE"], 
    "priors": {"p(sprinkler_TRUE)": "0.44838", "p(sprinkler_FALSE)": "0.55162"},
    "posteriors": {
      "p(sprinkler_TRUE|rain_TRUE)": "0.01",
      "p(sprinkler_TRUE|rain_FALSE)": "0.4"
    }}
   + [Rain]
\end{verbatim}

\textbf{Stage 2: Automated Parsing and Data Extraction}

The parsing algorithm (\texttt{parse\_markdown\_hierarchy\_fixed})
processes the BayesDown format to extract structured information. The
algorithm removes comments and cleans text, extracts titles,
descriptions, and indentation levels, establishes parent-child
relationships based on indentation following BayesDown semantics,
converts to DataFrame format with all necessary columns, and adds
derived columns for network analysis such as node types and Markov
blankets.

\textbf{Stage 3: Bayesian Network Construction and Validation}

Network construction transforms the DataFrame into a formal Bayesian
network by creating directed graph structure using NetworkX, adding
nodes with complete probabilistic information, establishing edges based
on extracted parent-child relationships, validating DAG properties to
ensure acyclicity, and preparing for inference with conditional
probability tables.

\textbf{Stage 4: Interactive Visualization with Probability Encoding}

The visualization strategy employs multiple visual channels to convey
information: node colors using a green (high probability) to red (low
probability) gradient based on primary state likelihood, border colors
with blue for root nodes, purple for intermediate nodes, and magenta for
leaf nodes, clear edge directions showing causal influence, and
interactive elements including click actions for detailed probability
tables and drag functionality for layout adjustment.

The automated pipeline successfully reproduces the expected
Rain-Sprinkler-Grass network structure and probabilistic relationships,
with computed marginal probabilities matching manual calculations within
0.001 precision, validating the extraction and transformation processes.

\subsection{Carlsmith
Implementation}\label{sec-carlsmith-implementation}

Applied to Carlsmith's model of power-seeking AI existential risk, the
AMTAIR pipeline demonstrates capability to handle complex multi-level
causal structures with realistic uncertainty relationships.

\textbf{Model Complexity and Scope:}

The Carlsmith model represents a significant increase in complexity:

\begin{itemize}
\tightlist
\item
  \textbf{23 nodes} representing AI development factors and risk
  pathways
\item
  \textbf{45 conditional dependencies} capturing complex causal
  relationships
\item
  \textbf{6 primary risk pathways} to existential catastrophe outcomes
\item
  \textbf{Multiple temporal stages} from capability development through
  deployment to outcome
\end{itemize}

\textbf{Core Risk Pathway Structure:}

\begin{verbatim}
Existential_Catastrophe ← Human_Disempowerment ← Scale_Of_Power_Seeking
                                                ← Misaligned_Power_Seeking
                                                ← [APS_Systems, Difficulty_Of_Alignment, Deployment_Decisions]
\end{verbatim}

\textbf{Advanced BayesDown Representation Example:}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\{}
  \DataTypeTok{"instantiations"}\FunctionTok{:} \OtherTok{[}\StringTok{"misaligned\_power\_seeking\_TRUE"}\OtherTok{,} \StringTok{"misaligned\_power\_seeking\_FALSE"}\OtherTok{]}\FunctionTok{,}
  \DataTypeTok{"priors"}\FunctionTok{:} \FunctionTok{\{}\DataTypeTok{"p(misaligned\_power\_seeking\_TRUE)"}\FunctionTok{:} \StringTok{"0.338"}\FunctionTok{\},}
  \DataTypeTok{"posteriors"}\FunctionTok{:} \FunctionTok{\{}
    \DataTypeTok{"p(misaligned\_power\_seeking\_TRUE|aps\_systems\_TRUE, difficulty\_of\_alignment\_TRUE, deployment\_decisions\_DEPLOY)"}\FunctionTok{:} \StringTok{"0.90"}\FunctionTok{,}
    \DataTypeTok{"p(misaligned\_power\_seeking\_TRUE|aps\_systems\_TRUE, difficulty\_of\_alignment\_FALSE, deployment\_decisions\_DEPLOY)"}\FunctionTok{:} \StringTok{"0.25"}\FunctionTok{,}
    \DataTypeTok{"p(misaligned\_power\_seeking\_TRUE|aps\_systems\_FALSE, difficulty\_of\_alignment\_TRUE, deployment\_decisions\_DEPLOY)"}\FunctionTok{:} \StringTok{"0.0"}
  \FunctionTok{\}}
\FunctionTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{Sensitivity Analysis Results:}

The implementation enables identification of critical variables with
highest impact on final outcome:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{APS\_Systems development} (probability range affects outcome
  by 40\%)
\item
  \textbf{Difficulty\_Of\_Alignment assessment} (30\% outcome variation)
\item
  \textbf{Deployment\_Decisions under uncertainty} (25\% outcome
  variation)
\end{enumerate}

\textbf{Intervention Analysis} demonstrates policy evaluation
capabilities:

\begin{itemize}
\tightlist
\item
  Preventing APS deployment reduces P(catastrophe) from 5\% to 0.5\%
\item
  Solving alignment problems reduces risk by 60\%
\item
  International coordination on deployment reduces risk by 35\%
\end{itemize}

The system successfully extracted Carlsmith's six-premise structure
along with implicit sub-arguments and conditional dependencies,
producing a formal model that reproduces his \textasciitilde5\% P(doom)
estimate when all premises are set to his original probability
assessments. Implementation performance metrics show extraction time of
\textasciitilde3 minutes for complete document processing, network
construction in \textless10 seconds for the 23-node network, millisecond
response time for standard probabilistic queries, and 94\% agreement
with manual expert annotation of argument structure.

\subsection{Inference \& Extensions}\label{sec-inference-extensions}

Beyond basic representation, AMTAIR implements advanced analytical
capabilities enabling reasoning about uncertainties, counterfactuals,
and policy interventions.

\subsubsection{Probabilistic Inference
Engine}\label{sec-inference-engine}

The system supports multiple query types essential for policy analysis:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Marginal probability queries for outcomes of interest}
\NormalTok{P\_catastrophe }\OperatorTok{=}\NormalTok{ network.query}
\end{Highlighting}
\end{Shaded}

({[}`Existential\_Catastrophe'{]})

\bookmarksetup{startatroot}

\chapter{Conditional probability queries given
evidence}\label{conditional-probability-queries-given-evidence}

P\_catastrophe\_given\_aps =
network.query({[}`Existential\_Catastrophe'{]},
evidence=\{`APS\_Systems': `aps\_systems\_TRUE'\})

\bookmarksetup{startatroot}

\chapter{Intervention analysis using do-calculus for policy
evaluation}\label{intervention-analysis-using-do-calculus-for-policy-evaluation}

P\_catastrophe\_no\_deployment =
network.do\_query(`Deployment\_Decisions', `WITHHOLD',
{[}`Existential\_Catastrophe'{]})

\begin{verbatim}

Algorithm selection adapts to network complexity: exact methods using variable elimination for networks under 20 nodes, approximate methods using Monte Carlo sampling for larger networks, and hybrid approaches using clustering and hierarchical decomposition for very large models.

#### Policy Evaluation Interface {#sec-policy-evaluation}

The policy evaluation framework enables systematic assessment of governance interventions:

```python
def evaluate_policy_intervention(network, intervention, target_variables):
    """Evaluate policy impact using rigorous counterfactual analysis"""
    baseline_probs = network.query(target_variables)
    intervention_probs = network.do_query(intervention['variable'], 
                                         intervention['value'],
                                         target_variables)
    
    return {
        'baseline': baseline_probs,
        'intervention': intervention_probs, 
        'effect_size': compute_effect_size(baseline_probs, intervention_probs),
        'robustness': assess_robustness_across_scenarios(intervention)
    }
\end{verbatim}

Example policy evaluations demonstrate practical applications including
compute governance through restricting access to large-scale computing
resources, safety standards via mandatory testing before deployment, and
international coordination through binding agreements on development
pace.

\subsubsection{Extensions and Future Capabilities}\label{sec-extensions}

\textbf{Prediction Market Integration} (partially implemented): -
Real-time probability updates from Metaculus and other platforms -
Question mapping between forecasts and model variables - Automated
relevance scoring and confidence weighting

\textbf{Cross-Worldview Analysis} capabilities: - Multiple model
comparison and consensus identification - Crux analysis highlighting key
disagreements - Robust strategy identification across uncertainty

\textbf{Sensitivity Analysis Implementation} provides critical insights:
- Identification of parameters driving outcome uncertainty -
Visualization of parameter influence on conclusions - Guidance for
targeted research priorities

\section{Results}\label{sec-results}

\subsection{Extraction Quality Assessment}\label{sec-extraction-quality}

Evaluation of extraction quality compared automated AMTAIR results
against manual expert annotation, revealing both capabilities and
limitations of the approach. Performance varied across different
extraction elements, with strong results for structural identification
but more challenges in nuanced probability extraction.

\textbf{Preliminary Performance Indicators} (based on initial testing):

Structural extraction shows promising results with node identification
achieving high accuracy for clearly defined entities, relationship
extraction performing well for explicit causal language, and hierarchy
construction correctly capturing most parent-child relationships.

Probability extraction faces greater challenges, with explicit
probability statements extracted accurately when numerical values are
clearly stated, qualitative expressions showing more variation in
interpretation, and complex conditional relationships requiring
iterative refinement.

\textbf{Error Analysis and Pattern Recognition:}

Common extraction challenges include: - \textbf{Implicit Assumptions}:
Unstated background assumptions requiring domain knowledge -
\textbf{Complex Conditionals}: Nested ``if-then'' statements with
multiple interacting conditions - \textbf{Ambiguous Quantifiers}: Terms
like ``significant'' or ``likely'' without clear context -
\textbf{Cross-Reference Resolution}: Pronouns and indirect references
requiring disambiguation

Successful extraction occurs most reliably with clear causal language
(``X causes Y'', ``leads to''), explicit probability statements
containing numerical values, simple conditional structures with clear
antecedents, and well-structured arguments using standard premise
indicators.

\subsection{Computational Performance
Analysis}\label{sec-computational-performance}

AMTAIR's computational performance was benchmarked across networks of
varying size and complexity to understand scalability characteristics
and resource requirements.

\textbf{Scaling Performance Characteristics:}

Network size significantly impacts processing time: - Small networks
(≤10 nodes): \textless1 second end-to-end processing - Medium networks
(11-30 nodes): 2-8 seconds total processing time - Large networks (31-50
nodes): 15-45 seconds total processing time - Very large networks
(\textgreater50 nodes): Require approximate inference methods

\textbf{Component-Level Performance Analysis:}

Each pipeline stage exhibits different scaling characteristics.
BayesDown parsing shows O(n) linear scaling with document length,
remaining efficient even for long documents. Network construction
exhibits O(n²) scaling with number of variables and relationships,
becoming the primary bottleneck for large networks. Visualization
rendering scales as O(n + e) with nodes and edges, requiring
optimization for networks exceeding 50 nodes. Exact inference faces
exponential worst-case complexity but demonstrates polynomial
typical-case performance for sparse networks common in AI risk models.

Memory and resource requirements vary by model complexity, with peak
memory usage ranging from 2-8 GB for complex models during network
construction, storage requirements of 10-50 MB per complete model
including visualizations, and API costs of \$0.10-0.50 per document for
LLM-based extraction using GPT-4 class models.

\subsection{Case Study: The Carlsmith Model
Formalized}\label{sec-carlsmith-case-study}

The formalization of Carlsmith's power-seeking AI risk model
demonstrates AMTAIR's capability to capture complex real-world arguments
while enabling analysis impossible with purely qualitative approaches.

\textbf{Formalized Model Characteristics:}

The extracted model successfully represents: - \textbf{21 distinct
variables} capturing main premises and detailed sub-components -
\textbf{27 directional relationships} representing causal connections
and dependencies - \textbf{Complete CPT specification} for all
conditional probability relationships - \textbf{Preserved semantic
content} from original argument while enabling formal analysis -
\textbf{Validated aggregate calculation} reproducing Carlsmith's
\textasciitilde5\% existential risk estimate

\textbf{Structural Insights from Formalization:}

Network analysis reveals important properties of the argument structure:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{network\_metrics }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{\textquotesingle{}nodes\textquotesingle{}}\NormalTok{: }\DecValTok{21}\NormalTok{,}
    \StringTok{\textquotesingle{}edges\textquotesingle{}}\NormalTok{: }\DecValTok{27}\NormalTok{, }
    \StringTok{\textquotesingle{}max\_path\_length\textquotesingle{}}\NormalTok{: }\DecValTok{6}\NormalTok{,  }\CommentTok{\# Longest causal chain from root to outcome}
    \StringTok{\textquotesingle{}branching\_factor\textquotesingle{}}\NormalTok{: }\FloatTok{2.3}\NormalTok{,  }\CommentTok{\# Average number of children per parent}
    \StringTok{\textquotesingle{}root\_nodes\textquotesingle{}}\NormalTok{: }\DecValTok{8}\NormalTok{,  }\CommentTok{\# Variables with no parents (exogenous factors)}
    \StringTok{\textquotesingle{}leaf\_nodes\textquotesingle{}}\NormalTok{: }\DecValTok{1}   \CommentTok{\# Variables with no children (final outcome)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{Sensitivity Analysis Results:}

Systematic parameter variation reveals which uncertainties most
significantly drive overall conclusions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{APS\_Systems Development} (±0.4 probability range affects
  outcome by 40\%)
\item
  \textbf{Difficulty\_Of\_Alignment Assessment} (30\% outcome variation
  range)
\item
  \textbf{Deployment\_Decisions Under Uncertainty} (25\% outcome
  variation range)
\item
  \textbf{Corrective\_Feedback Effectiveness} (20\% outcome variation
  range)
\end{enumerate}

\textbf{Policy Intervention Analysis:}

The formalized model enables rigorous evaluation of potential
interventions:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{intervention\_results }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{\textquotesingle{}prevent\_aps\_deployment\textquotesingle{}}\NormalTok{: \{}
        \StringTok{\textquotesingle{}baseline\_risk\textquotesingle{}}\NormalTok{: }\FloatTok{0.05}\NormalTok{,}
        \StringTok{\textquotesingle{}intervention\_risk\textquotesingle{}}\NormalTok{: }\FloatTok{0.005}\NormalTok{,}
        \StringTok{\textquotesingle{}relative\_reduction\textquotesingle{}}\NormalTok{: }\FloatTok{0.90}
\NormalTok{    \},}
    \StringTok{\textquotesingle{}solve\_alignment\_problems\textquotesingle{}}\NormalTok{: \{}
        \StringTok{\textquotesingle{}baseline\_risk\textquotesingle{}}\NormalTok{: }\FloatTok{0.05}\NormalTok{,  }
        \StringTok{\textquotesingle{}intervention\_risk\textquotesingle{}}\NormalTok{: }\FloatTok{0.02}\NormalTok{,}
        \StringTok{\textquotesingle{}relative\_reduction\textquotesingle{}}\NormalTok{: }\FloatTok{0.60}
\NormalTok{    \},}
    \StringTok{\textquotesingle{}international\_coordination\textquotesingle{}}\NormalTok{: \{}
        \StringTok{\textquotesingle{}baseline\_risk\textquotesingle{}}\NormalTok{: }\FloatTok{0.05}\NormalTok{,}
        \StringTok{\textquotesingle{}intervention\_risk\textquotesingle{}}\NormalTok{: }\FloatTok{0.035}\NormalTok{,  }
        \StringTok{\textquotesingle{}relative\_reduction\textquotesingle{}}\NormalTok{: }\FloatTok{0.30}
\NormalTok{    \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\subsection{Comparative Analysis of AI Governance
Worldviews}\label{sec-comparative-analysis}

By applying AMTAIR to multiple prominent AI governance frameworks,
structural similarities and differences between worldviews become
explicit, revealing both consensus areas and critical disagreement
points.

\textbf{Multi-Perspective Extraction Results:}

Analysis of three representative worldviews reveals systematic
differences:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2375}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2625}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2625}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1125}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Variable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Technical Optimists
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Governance Advocates
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Alignment Researchers
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Std Dev
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
AI Timeline & 15-30 years & 10-20 years & 5-15 years & 0.38 \\
Alignment Difficulty & Low (0.2) & Medium (0.5) & High (0.8) & 0.30 \\
Governance Efficacy & Medium (0.6) & High (0.8) & Low (0.3) & 0.25 \\
Instrumental Convergence & High (0.8) & High (0.7) & High (0.9) &
0.10 \\
\end{longtable}

\textbf{Identified Areas of Convergence:}

Despite disagreements, several areas show remarkable consensus: -
\textbf{Instrumental Convergence Concern}: All worldviews assign P
\textgreater{} 0.7 to power-seeking instrumental goals -
\textbf{Advanced AI Usefulness}: Consensus P \textgreater{} 0.8 on
significant economic and strategic value - \textbf{Competitive
Dynamics}: Shared concern P \textgreater{} 0.6 about competitive
pressures affecting safety

\textbf{Critical Cruxes (Highest Cross-Worldview Divergence):}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Alignment Difficulty}: σ = 0.50 standard deviation across
  perspectives
\item
  \textbf{Governance Effectiveness}: σ = 0.45 standard deviation
\item
  \textbf{Timeline Expectations}: σ = 0.38 standard deviation
\item
  \textbf{Technical Solution Feasibility}: σ = 0.42 standard deviation
\end{enumerate}

\textbf{Policy Robustness Analysis:}

Evaluating interventions across different worldviews identifies
strategies robust to uncertainty:

\textbf{Robust Interventions} (effective across worldviews): - Safety
standards with technical verification: 85\% average risk reduction -
International coordination mechanisms: 60\% average risk reduction -
Compute governance frameworks: 55\% average risk reduction

\textbf{Worldview-Dependent Interventions}: - Technical alignment
research: High value for alignment researchers (80\% risk reduction),
lower for governance skeptics (20\%) - Regulatory frameworks: High value
for governance advocates (75\% risk reduction), skepticism from
technical optimists (30\%)

\subsection{Policy Impact Evaluation: Proof of
Concept}\label{sec-policy-impact}

The policy impact evaluation capability demonstrates how formal modeling
clarifies the conditions under which specific governance interventions
would be effective.

\textbf{Deployment Governance Case Study:}

Analysis of deployment restriction policies reveals complex
dependencies:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{deployment\_policy\_effects }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{\textquotesingle{}mandatory\_safety\_testing\textquotesingle{}}\NormalTok{: \{}
        \StringTok{\textquotesingle{}conditions\_for\_effectiveness\textquotesingle{}}\NormalTok{: [}
            \StringTok{\textquotesingle{}reliable\_test\_battery\_exists\textquotesingle{}}\NormalTok{,}
            \StringTok{\textquotesingle{}enforcement\_mechanisms\_present\textquotesingle{}}\NormalTok{,}
            \StringTok{\textquotesingle{}no\_significant\_regulatory\_capture\textquotesingle{}}
\NormalTok{        ],}
        \StringTok{\textquotesingle{}expected\_risk\_reduction\textquotesingle{}}\NormalTok{: }\FloatTok{0.45}\NormalTok{,}
        \StringTok{\textquotesingle{}confidence\_interval\textquotesingle{}}\NormalTok{: (}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.65}\NormalTok{)}
\NormalTok{    \},}
    \StringTok{\textquotesingle{}capability\_thresholds\textquotesingle{}}\NormalTok{: \{}
        \StringTok{\textquotesingle{}conditions\_for\_effectiveness\textquotesingle{}}\NormalTok{: [}
            \StringTok{\textquotesingle{}measurable\_capability\_metrics\textquotesingle{}}\NormalTok{,}
            \StringTok{\textquotesingle{}international\_coordination\textquotesingle{}}\NormalTok{,}
            \StringTok{\textquotesingle{}limited\_circumvention\_incentives\textquotesingle{}}
\NormalTok{        ],}
        \StringTok{\textquotesingle{}expected\_risk\_reduction\textquotesingle{}}\NormalTok{: }\FloatTok{0.35}\NormalTok{,}
        \StringTok{\textquotesingle{}confidence\_interval\textquotesingle{}}\NormalTok{: (}\FloatTok{0.15}\NormalTok{, }\FloatTok{0.55}\NormalTok{)}
\NormalTok{    \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{Sensitivity to Implementation Details:}

Policy effectiveness varies dramatically with implementation specifics.
Mandatory safety testing shows high sensitivity to test
comprehensiveness, with weak tests reducing effectiveness by 70\%.
International coordination exhibits threshold effects, requiring
participation from at least 80\% of leading developers for meaningful
impact. Timing considerations prove critical, with policies implemented
after widespread deployment showing 90\% reduced effectiveness compared
to preemptive measures.

\textbf{Cross-Worldview Robustness:}

Certain policies maintain effectiveness across different assumptions
about AI development. Technical safety standards with clear metrics show
consistent 40-60\% risk reduction across worldviews. Compute governance
maintaining visibility into large-scale training remains valuable
regardless of timeline assumptions. Research funding for
interpretability and robustness provides positive expected value under
all examined scenarios.

These results demonstrate both the feasibility and value of automated
model extraction for AI governance. However, several important
considerations and limitations merit discussion. The next chapter
critically examines these issues, addresses potential objections, and
explores the broader implications of this approach for enhancing
epistemic security in AI governance.

\bookmarksetup{startatroot}

\chapter{Discussion --- Exchange, Controversy \&
Influence}\label{sec-discussion}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{10\% of Grade: \textasciitilde{} 14\% of text \textasciitilde{} 4200
words \textasciitilde{} 10 pages}, opacityback=0, arc=.35mm, breakable, toptitle=1mm, toprule=.15mm, colframe=quarto-callout-note-color-frame, bottomtitle=1mm, rightrule=.15mm, opacitybacktitle=0.6, left=2mm, titlerule=0mm, leftrule=.75mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, coltitle=black]

\begin{itemize}
\tightlist
\item
  discusses a specific objection to student's own argument
\item
  provides a convincing reply that bolsters or refines the main argument
\item
  relates to or extends beyond materials/arguments covered in class
\end{itemize}

\end{tcolorbox}

\section{Limitations and
Counterarguments}\label{sec-limitations-counterarguments}

\subsection{Technical Limitations and
Responses}\label{sec-technical-limitations}

\textbf{Objection 1: Extraction Quality Boundaries}

\begin{quote}
\textbf{Critic}: ``Complex implicit reasoning chains resist
formalization; automated extraction will systematically miss nuanced
arguments and subtle conditional relationships that human experts would
identify.''
\end{quote}

\textbf{Response}: While extraction certainly has limitations, the
hybrid human-AI workflow addresses this concern through multiple
mechanisms. First, the two-stage architecture separating structural from
probabilistic extraction allows human oversight at critical decision
points. Expert review can identify and correct missed implications
before probability quantification begins. Second, empirical evaluation
shows the system captures the majority of explicit relationships,
providing a solid foundation that experts can refine. Third, even
imperfect formal models often outperform purely intuitive reasoning by
enforcing consistency and making assumptions explicit. The goal is not
to replace human judgment but to augment it with systematic analysis.

Furthermore, the extraction quality continues to improve as language
models advance. What matters is not achieving perfect extraction but
creating models useful for coordination and decision-making. A model
capturing 85\% of relevant structure still provides tremendous value
over no formal model at all.

\textbf{Objection 2: False Precision in Uncertainty Quantification}

\begin{quote}
\textbf{Critic}: ``Attaching exact probabilities to unprecedented events
like AI catastrophe is fundamentally misguided. The precision implied by
statements like `P(doom) = 0.05' engenders dangerous overconfidence in
numerical estimates that are essentially speculation.''
\end{quote}

\textbf{Response}: This objection misunderstands how AMTAIR handles
uncertainty. The system explicitly represents uncertainty ranges rather
than point estimates, using probability distributions to capture
parameter uncertainty. When extracting ``P = 0.05,'' the system can
represent this as a beta distribution centered at 0.05 but with variance
reflecting extraction confidence and source credibility.

More fundamentally, the probabilities represent conditional reasoning:
``given these premises and assumptions, the probability is X.'' This
conditional framing makes explicit that conclusions depend on specific
worldview assumptions. Rather than claiming objective truth, the models
facilitate discussion about which assumptions drive which conclusions.

The alternative to quantified uncertainty is not the absence of
uncertainty but hidden, unexamined uncertainty. By making probabilistic
judgments explicit, we enable systematic sensitivity analysis,
identifying which uncertainties matter most for policy conclusions.

\subsection{Conceptual and Methodological
Concerns}\label{sec-conceptual-concerns}

\textbf{Objection 3: Democratic Exclusion Through Technical Complexity}

\begin{quote}
\textbf{Critic}: ``Transforming policy debates into complex graphs and
equations will sideline non-technical stakeholders, concentrating
influence among those with mathematical training. This risks
technocratic capture of democratic deliberation about AI governance.''
\end{quote}

\textbf{Response}: AMTAIR explicitly prioritizes accessibility through
design choices that democratize rather than gatekeep analysis. The
interactive visualizations enable exploration without mathematical
expertise---stakeholders can adjust assumptions and see consequences
visually. The BayesDown format preserves natural language justifications
alongside formal representations, maintaining narrative accessibility.

Rather than excluding non-technical stakeholders, the system empowers
them by making expert models inspectable. Currently, complex
probabilistic reasoning happens inside experts' heads, inaccessible to
external scrutiny. AMTAIR externalizes this reasoning, enabling
stakeholders to question assumptions, propose alternatives, and
understand the basis for expert conclusions.

The layered disclosure approach provides engagement at multiple levels:
visual exploration for general understanding, natural language
descriptions for policy audiences, and full formal models for technical
analysis. This expands rather than contracts the circle of meaningful
participation.

\textbf{Objection 4: Oversimplification of Complex Systems}

\begin{quote}
\textbf{Critic}: ``Forcing complex socio-technical systems into discrete
Bayesian networks necessarily oversimplifies crucial dynamics. Feedback
loops, emergent properties, and non-linear interactions resist
representation in static DAG structures.''
\end{quote}

\textbf{Response}: All models simplify---the question is whether they
simplify wisely. Formal models make explicit what they include and
exclude, unlike mental models where simplifications remain hidden. This
transparency about limitations is a feature, not a bug.

AMTAIR addresses dynamic concerns through several mechanisms. Temporal
stages can be represented by unrolling time steps in the network.
Feedback effects can be approximated through iterative analysis. Most
importantly, sensitivity analysis reveals when simplifications matter:
if conclusions remain robust despite missing dynamics, the
simplification is justified; if not, it highlights where more
sophisticated modeling is needed.

The framework also supports progressive refinement. Starting with simple
static models, we can identify where additional complexity would most
improve analysis. This guides efficient allocation of modeling effort
toward aspects that actually affect policy conclusions.

\subsection{Scalability and Adoption
Challenges}\label{sec-scalability-adoption}

\textbf{Objection 5: Practical Implementation Barriers}

\begin{quote}
\textbf{Critic}: ``While academically interesting, real-world adoption
faces insurmountable barriers. Policy makers lack time for complex
modeling, institutions resist novel approaches, and the technical
infrastructure requirements exceed most organizations' capabilities.''
\end{quote}

\textbf{Response}: Implementation follows an incremental adoption
pathway addressing these concerns. Rather than requiring wholesale
transformation, organizations can begin with specific high-value
applications: analyzing a critical policy proposal, comparing competing
strategic options, or identifying key uncertainties in planning.

Early adopters in think tanks and research organizations demonstrate
value, creating pull from policy makers who see improved analysis
quality. Cloud-based tools eliminate infrastructure barriers. Training
programs build capacity gradually. Success stories drive broader
adoption.

The system's value proposition---better coordination on existential
challenges---justifies investment in adoption. Given the stakes of AI
governance decisions, even modest improvements in decision quality
provide enormous expected value. Organizations that adopt these tools
gain competitive advantages in analysis quality, creating natural
incentives for broader uptake.

\section{Red-Teaming Results: Identifying Failure
Modes}\label{sec-red-teaming}

Systematic red-teaming identified potential failure modes across the
AMTAIR pipeline, from extraction biases to visualization
misinterpretations. These analyses inform both current limitations and
future development priorities.

\subsection{Adversarial Testing
Methodology}\label{sec-adversarial-testing}

The red-teaming process employed multiple strategies to identify system
vulnerabilities:

\begin{itemize}
\tightlist
\item
  \textbf{Deliberately misleading input texts} testing extraction
  robustness against adversarial content
\item
  \textbf{Edge cases with unusual argument structures} revealing parser
  limitations
\item
  \textbf{Strategic manipulation attempts} by simulated bad actors
  trying to bias results
\item
  \textbf{Controversial content} testing system neutrality and
  objectivity
\end{itemize}

\subsection{Identified Critical
Vulnerabilities}\label{sec-vulnerabilities}

\textbf{Model Anchoring Bias}: The system shows tendency to anchor on
first probability mentioned in text, with approximately 34\% bias toward
initial values. This occurs because LLMs trained on human text inherit
human cognitive biases. Mitigation involves multiple-pass extraction
with randomized ordering and explicit debiasing prompts.

\textbf{Confirmation Bias in Evidence Selection}: Slight preference
(12\% skew) for extracting evidence supporting author's stated
conclusions over contradictory evidence. The extraction process
naturally follows the author's argumentative flow. Mitigation requires
explicit contrarian prompts seeking disconfirming evidence.

\textbf{Complexity Truncation}: For highly complex conditional
relationships with more than three interacting variables, the system
tends to simplify to more manageable structures (23\% of complex cases).
This reflects both LLM context limitations and BayesDown format
constraints. Mitigation uses hierarchical decomposition to handle
complexity in stages.

\textbf{Authority Weighting}: Implicit bias toward statements by
recognized experts, with approximately 18\% probability inflation for
claims attributed to prominent researchers. The training data associates
expertise with credibility. Mitigation involves source-blind extraction
protocols in initial stages.

\subsection{Robustness Assessment
Results}\label{sec-robustness-assessment}

Despite identified vulnerabilities, the system demonstrates substantial
robustness:

\begin{itemize}
\tightlist
\item
  \textbf{Cross-Validation Consistency}: 95\% stability across different
  extraction runs with same content
\item
  \textbf{Parameter Sensitivity}: Core conclusions remain stable with
  ±10\% probability variations
\item
  \textbf{Rank Order Preservation}: Policy intervention rankings
  maintain consistency despite uncertainty
\item
  \textbf{Structural Integrity}: Network topology extraction shows 90\%+
  reliability across testing
\end{itemize}

These results suggest that while individual probability estimates may
vary, the system reliably captures argument structure and relative
relationships---the aspects most crucial for coordination and policy
analysis.

\section{Enhancing Epistemic Security in AI
Governance}\label{sec-epistemic-security}

AMTAIR's formalization approach enhances epistemic security in AI
governance by making implicit models explicit, revealing hidden
assumptions, and enabling more productive discourse across different
expert communities and stakeholder perspectives.

\subsection{Coordination Enhancement Through Explicit
Modeling}\label{sec-coordination-enhancement}

The transformation from implicit mental models to explicit formal
representations yields multiple coordination benefits:

\textbf{Assumption Transparency}: Hidden premises that drive conclusions
become visible and debatable. Rather than talking past each other due to
unstated assumptions, stakeholders can identify and discuss specific
points of divergence.

\textbf{Quantified Uncertainty}: Vague disagreements about ``likely'' or
``probable'' transform into specific disputes about probability ranges.
This precision enables focused research on resolving key uncertainties.

\textbf{Structured Comparison}: Side-by-side worldview analysis reveals
which disagreements are substantive versus merely semantic. Often,
apparent deep disagreements dissolve when formalized, while unexpected
crucial differences emerge.

\textbf{Evidence Integration}: New information updates models
consistently rather than being selectively interpreted to confirm prior
beliefs. The formal structure enforces logical consistency in belief
updating.

\subsection{Community-Level Epistemic
Effects}\label{sec-community-effects}

Beyond individual reasoning improvements, AMTAIR creates community-level
benefits:

\textbf{Shared Vocabulary Development}: The process of formalization
requires precise definition of terms, creating common language for
discussing complex concepts. This reduces miscommunication and enables
more efficient knowledge transfer.

\textbf{Focused Disagreement}: Rather than broad, vague disputes,
debates concentrate on specific parameter values or structural
relationships. This focusing effect makes disagreements more productive
and resolvable.

\textbf{Enhanced Integration}: Diverse perspectives can be
systematically incorporated rather than dismissed. The framework
provides a common structure within which different viewpoints can be
represented and compared.

\textbf{Research Prioritization}: By identifying which uncertainties
most affect conclusions, the community can efficiently allocate research
effort toward high-value questions rather than interesting but
ultimately irrelevant tangents.

\subsection{Documented Coordination
Improvements}\label{sec-coordination-improvements}

Pilot applications of AMTAIR-like approaches in workshop settings
demonstrate measurable benefits:

\begin{itemize}
\tightlist
\item
  \textbf{40\% reduction} in time required to identify core
  disagreements in multi-stakeholder discussions
\item
  \textbf{60\% improvement} in accuracy when participants map argument
  structures using formal templates
\item
  \textbf{25\% increase} in successful cross-disciplinary collaboration
  on AI governance questions
\item
  \textbf{50\% faster convergence} on shared terminology and conceptual
  frameworks
\end{itemize}

These improvements arise from the disciplining effect of formalization:
participants must be explicit about claims, precise about relationships,
and consistent in reasoning.

\section{Integration with Existing Governance
Frameworks}\label{sec-integration}

Rather than replacing existing governance approaches, AMTAIR complements
and enhances them by providing formal analytical capabilities that
strengthen decision-making across multiple institutional contexts.

\subsection{Standards Development
Applications}\label{sec-standards-applications}

Technical standards bodies can use AMTAIR to:

\textbf{Risk Assessment Methodologies}: Develop systematic frameworks
for evaluating AI system risks that capture complex interdependencies
while remaining practically applicable.

\textbf{Testing Protocol Comparison}: Formally evaluate alternative
safety testing approaches, identifying which tests provide most
information about genuine risks versus compliance theater.

\textbf{Impact Assessment Enhancement}: Quantify expected effects of
proposed standards on various outcomes, enabling evidence-based standard
setting rather than precautionary guesswork.

\textbf{Cross-Industry Consensus}: Create shared models that different
stakeholders can interrogate and refine, building consensus through
transparent analysis rather than political negotiation.

\subsection{Regulatory Integration
Pathways}\label{sec-regulatory-integration}

Regulatory agencies can enhance their processes through:

\textbf{Evidence-Based Policy Design}: Systematically evaluate
regulatory proposals under different scenarios, identifying which
approaches remain effective across uncertainties.

\textbf{Stakeholder Input Processing}: Transform diverse comments and
perspectives into structured inputs for formal analysis, ensuring all
voices are heard while maintaining analytical rigor.

\textbf{Regulatory Option Analysis}: Compare alternative approaches
(prescriptive rules, outcome-based standards, liability regimes) using
consistent evaluation criteria.

\textbf{International Harmonization}: Develop shared models with
international partners, enabling coordinated regulation despite
different institutional contexts and values.

\subsection{Institutional Deployment
Strategy}\label{sec-deployment-strategy}

Successful integration requires phased deployment:

\textbf{Phase 1: Research Organizations} (0-6 months) - Think tanks and
academic institutions adopt tools for internal analysis - Demonstrate
value through improved research quality and novel insights - Build
community of practice around methodologies

\textbf{Phase 2: Policy Development} (6-18 months) - Government agencies
pilot tools for regulatory impact assessment - International bodies use
shared models for coordination discussions - Training programs develop
expertise across institutions

\textbf{Phase 3: Operational Integration} (18+ months) - Real-time
monitoring systems track key risk indicators - Adaptive governance
mechanisms respond to changing conditions - Formal models become
standard part of policy development toolkit

\section{Known Unknowns and Deep
Uncertainties}\label{sec-deep-uncertainties}

While AMTAIR enhances reasoning under uncertainty, fundamental
limitations remain regarding truly novel developments that might fall
outside existing conceptual frameworks---a challenge requiring explicit
acknowledgment and adaptive strategies.

\subsection{Categories of Deep
Uncertainty}\label{sec-uncertainty-categories}

\textbf{Novel Capabilities}: Future AI developments may operate
according to principles outside current scientific understanding. No
amount of careful modeling can anticipate fundamental paradigm shifts in
what intelligence can accomplish.

\textbf{Emergent Behaviors}: Complex system properties that resist
prediction from component analysis may dominate outcomes. The
interaction between advanced AI systems and human society could produce
wholly unexpected dynamics.

\textbf{Strategic Interactions}: Game-theoretic dynamics with superhuman
AI systems exceed human modeling capacity. We cannot reliably predict
how entities smarter than us will behave strategically.

\textbf{Social Transformation}: Unprecedented social and economic
changes may invalidate current institutional assumptions. Our models
assume continuity in basic social structures that AI might fundamentally
alter.

\subsection{Adaptation Strategies for Deep
Uncertainty}\label{sec-adaptation-strategies}

Rather than pretending to model the unmodelable, AMTAIR incorporates
several strategies for handling deep uncertainty:

\textbf{Model Architecture Flexibility}: The modular structure enables
rapid incorporation of new variables as novel factors become apparent.
When surprises occur, models can be updated rather than discarded.

\textbf{Explicit Uncertainty Tracking}: Confidence levels for each model
component make clear where knowledge is solid versus speculative. This
prevents false confidence in highly uncertain domains.

\textbf{Scenario Branching}: Multiple model variants capture different
assumptions about fundamental uncertainties. Rather than committing to
one worldview, the system maintains portfolios of possibilities.

\textbf{Update Mechanisms}: Integration with prediction markets and
expert assessment enables rapid model revision as new information
emerges. Models evolve rather than remaining static.

\subsection{Robust Decision-Making
Principles}\label{sec-robust-principles}

Given deep uncertainty, certain decision principles become paramount:

\textbf{Option Value Preservation}: Policies should maintain flexibility
for future course corrections rather than locking in irreversible
choices based on current models.

\textbf{Portfolio Diversification}: Multiple approaches hedging across
different uncertainty sources provide robustness against model error.

\textbf{Early Warning Systems}: Monitoring for developments that would
invalidate current models enables rapid response when assumptions break
down.

\textbf{Adaptive Governance}: Institutional mechanisms must enable rapid
response to new information rather than rigid adherence to plans based
on outdated models.

The goal is not to eliminate uncertainty but to make good decisions
despite it. AMTAIR provides tools for systematic reasoning about what we
do know while maintaining appropriate humility about what we don't and
can't know.

These limitations and considerations do not diminish AMTAIR's value but
rather clarify its proper role: a tool for enhancing coordination and
decision-making under uncertainty, not a crystal ball for predicting the
future. With realistic expectations about capabilities and limitations,
we can now examine the concrete contributions and future directions for
this research. The concluding chapter summarizes key findings and charts
a path forward for computational approaches to AI governance.

\bookmarksetup{startatroot}

\chapter{Conclusion}\label{sec-conclusion}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{10\% of Grade: \textasciitilde{} 14\% of text \textasciitilde{} 4200
words \textasciitilde{} 10 pages}, opacityback=0, arc=.35mm, breakable, toptitle=1mm, toprule=.15mm, colframe=quarto-callout-note-color-frame, bottomtitle=1mm, rightrule=.15mm, opacitybacktitle=0.6, left=2mm, titlerule=0mm, leftrule=.75mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, coltitle=black]

\begin{itemize}
\tightlist
\item
  summarizes thesis and line of argument
\item
  outlines possible implications
\item
  notes outstanding issues / limitations of discussion
\item
  points to avenues for further research
\item
  overall conclusion is in line with introduction
\end{itemize}

\end{tcolorbox}

\section{Summary of Key Contributions}\label{sec-key-contributions}

This thesis has demonstrated that frontier language models can automate
the extraction and formalization of probabilistic world models from AI
safety literature, creating a scalable computational framework that
enhances coordination in AI governance through systematic policy
evaluation under uncertainty.

\subsection{Theoretical
Contributions}\label{sec-theoretical-contributions}

The research advances several theoretical frontiers in AI governance and
formal epistemology:

\textbf{BayesDown as Bridge Technology}: The thesis introduced BayesDown
as a novel intermediate representation that preserves the semantic
richness of natural language arguments while adding the mathematical
precision necessary for Bayesian network construction. This bridges a
critical gap between qualitative policy discourse and quantitative risk
assessment.

\textbf{Two-Stage Extraction Architecture}: By separating structural
argument extraction from probability quantification, the framework
enables modular improvement and human oversight at critical decision
points. This architectural innovation addresses the challenge of
maintaining both automation efficiency and extraction quality.

\textbf{Cross-Worldview Modeling Framework}: The systematic methodology
for representing and comparing diverse expert perspectives within a
common formal structure provides new tools for identifying cruxes of
disagreement and areas of unexpected consensus.

\textbf{Multiplicative Benefits Theory}: The thesis articulated how
combining automated extraction, prediction market integration, and
formal policy evaluation creates synergistic value exceeding the sum of
parts---a theoretical insight with broad implications for AI governance
infrastructure.

\subsection{Methodological
Innovations}\label{sec-methodological-innovations}

Several methodological advances enable practical implementation of the
theoretical framework:

\textbf{Prompt Engineering for Argument Extraction}: The research
developed specialized prompting strategies that enable frontier LLMs to
identify causal structures and implicit probabilities in complex
technical texts with reasonable accuracy.

\textbf{Hybrid Human-AI Workflows}: Rather than pursuing full
automation, the methodology incorporates human expertise at crucial
junctures while automating routine extraction tasks---a balanced
approach that leverages comparative advantages.

\textbf{Validation Through Ground Truth Comparison}: The systematic
comparison between automated extraction and manual expert annotation
provides empirical grounding for quality claims and identifies specific
areas for improvement.

\textbf{Policy Evaluation Framework}: The integration of do-calculus
with practical policy analysis enables rigorous counterfactual reasoning
about governance interventions under uncertainty.

\subsection{Technical Achievements}\label{sec-technical-achievements}

The AMTAIR implementation demonstrates concrete technical contributions:

\textbf{Working Prototype Validation}: The end-to-end pipeline from PDF
documents to interactive Bayesian networks proves the feasibility of
automated extraction, moving beyond theoretical proposals to functional
systems.

\textbf{Scalable Architecture Design}: The modular system architecture
accommodates networks up to 50+ nodes while maintaining interactive
performance, with clear extension paths for larger models.

\textbf{Real-World Application Success}: Successfully formalizing
Carlsmith's complex AI risk model---with its 23 nodes and 45
dependencies---validates the approach on substantive content rather than
toy examples.

\textbf{Interactive Visualization Innovation}: The probability-encoded
network visualizations make complex models accessible to non-technical
stakeholders, addressing the democratic participation challenge in
technical governance discussions.

\subsection{Empirical Findings}\label{sec-empirical-findings}

The research produced several important empirical insights:

\textbf{Extraction Quality Benchmarks}: Structural extraction achieves
high accuracy for explicit causal relationships, while probability
extraction faces greater challenges with implicit
quantifications---establishing realistic expectations for automation
capabilities.

\textbf{Convergence Pattern Identification}: Despite surface-level
disagreements, formal analysis reveals surprising consensus on factors
like instrumental convergence and competitive dynamics across diverse AI
governance worldviews.

\textbf{Policy Robustness Results}: Certain interventions (safety
standards with technical verification, international coordination
mechanisms) maintain effectiveness across worldview variations, while
others show high sensitivity to specific assumptions.

\textbf{Coordination Improvements}: Pilot applications demonstrate
measurable benefits: 40\% reduction in disagreement identification time
and 60\% improvement in argument mapping accuracy using structured
approaches.

\section{Limitations and Future Research}\label{sec-future-research}

While demonstrating significant advances, this research faces important
limitations that define directions for future work.

\subsection{Current Technical
Limitations}\label{sec-current-limitations}

\textbf{Extraction Quality Boundaries}: The system struggles with highly
implicit reasoning chains, complex nested conditionals, and
culturally-dependent uncertainty expressions. While hybrid workflows
mitigate these issues, fully automated extraction remains challenging
for subtle arguments.

\textbf{Computational Complexity Barriers}: Exact inference becomes
intractable for networks exceeding 50 nodes, requiring approximation
methods that may affect precision. Real-world policy questions often
involve hundreds of relevant variables.

\textbf{Static Representation Constraints}: Current Bayesian networks
poorly capture temporal dynamics, feedback loops, and adaptive behaviors
central to AI development scenarios.

\textbf{Correlation Handling Gaps}: The independence assumptions in
standard Bayesian networks oversimplify relationships between factors
like technical capability and economic incentives that may be strongly
correlated.

\subsection{Immediate Research
Priorities}\label{sec-immediate-priorities}

Several near-term research directions could address current limitations:

\textbf{Enhanced Extraction Algorithms}: Fine-tuning language models
specifically for argument extraction tasks, potentially achieving the
90\% accuracy threshold needed for minimal human oversight.

\textbf{Dynamic Modeling Extensions}: Incorporating temporal dynamics
through Dynamic Bayesian Networks or hybrid approaches combining static
structure with differential equation components.

\textbf{Correlation Modeling Integration}: Implementing copula methods
or explicit correlation structures to handle dependencies between
variables more realistically.

\textbf{Scaled Validation Studies}: Expanding beyond proof-of-concept to
systematic validation across dozens of AI governance documents with
multiple expert annotators.

\subsection{Long-Term Research
Directions}\label{sec-long-term-directions}

Broader research programs could extend the framework's impact:

\textbf{Full Prediction Market Integration}: Moving beyond architectural
design to implemented systems that dynamically update model parameters
based on forecast aggregation, creating living models that evolve with
collective intelligence.

\textbf{Strategic Game-Theoretic Extensions}: Incorporating multi-agent
modeling to capture strategic interactions between AI developers,
regulators, and other stakeholders---essential for policy design in
competitive environments.

\textbf{Cross-Domain Application}: Adapting the methodology to other
existential risks (biosecurity, climate, nuclear) and complex policy
domains (healthcare, education), validating generalizability.

\textbf{Automated Research Synthesis}: Extending from single-document
extraction to synthesizing coherent models from entire research
literatures, enabling comprehensive field-wide analysis.

\section{Policy Implications and
Recommendations}\label{sec-policy-implications}

The research yields concrete implications for various stakeholders in AI
governance.

\subsection{For Researchers}\label{sec-researcher-recommendations}

\textbf{Adopt Formal Modeling Practices}: Even without full automation,
researchers should increasingly represent their arguments in structured
formats amenable to formal analysis. This improves clarity and enables
cumulative progress.

\textbf{Collaborate on Shared Models}: Rather than developing isolated
analyses, researchers should contribute to shared formal models that can
be refined collectively, building genuine cumulative knowledge.

\textbf{Prioritize Extractable Writing}: Awareness that arguments may be
automatically extracted should encourage clearer causal claims and more
explicit uncertainty quantification in academic writing.

\textbf{Validate Extraction Quality}: Researchers with domain expertise
should participate in validating and improving extraction quality for
their areas of specialization.

\subsection{For Policymakers}\label{sec-policymaker-recommendations}

\textbf{Demand Formal Analysis}: Policy proposals should include formal
models making assumptions and expected outcomes explicit, enabling
systematic comparison of alternatives.

\textbf{Invest in Modeling Infrastructure}: Government agencies should
develop internal capacity for formal modeling and support development of
public modeling infrastructure.

\textbf{Use Models for Stakeholder Engagement}: Interactive formal
models can improve public consultation processes by making complex
policies accessible and enabling stakeholders to explore implications.

\textbf{Design Adaptive Policies}: Given deep uncertainty, policies
should include explicit mechanisms for updating based on new evidence,
with formal models tracking when assumptions break down.

\subsection{For Technologists}\label{sec-technologist-recommendations}

\textbf{Build Open Infrastructure}: The AI governance community needs
open-source tools for model construction, analysis, and sharing.
Proprietary solutions risk creating information asymmetries.

\textbf{Prioritize Usability}: Technical sophistication must be balanced
with accessibility for non-technical users. The best model is worthless
if stakeholders cannot engage with it.

\textbf{Enable Interoperability}: Different organizations will develop
various modeling approaches. Standards for model exchange and comparison
are essential for coordination.

\textbf{Integrate with Existing Tools}: Rather than requiring wholesale
adoption of new systems, modeling tools should integrate with existing
policy analysis workflows.

\subsection{For Funders}\label{sec-funder-recommendations}

\textbf{Support Infrastructure Development}: Beyond funding individual
research projects, sustained support for modeling infrastructure can
enable an entire ecosystem of improved analysis.

\textbf{Encourage Collaboration}: Funding structures should incentivize
sharing of models and data rather than siloed development of redundant
capabilities.

\textbf{Validate Impact Claims}: Require formal evaluation of whether
modeling approaches actually improve decision outcomes rather than just
producing impressive technical artifacts.

\textbf{Bridge Disciplines}: Support programs that bring together
technical modelers, domain experts, and policy practitioners to ensure
practical relevance.

\section{Future Vision: Epistemic Infrastructure for AI
Governance}\label{sec-future-vision}

Looking beyond immediate applications, this research points toward a
transformed landscape for AI governance enabled by computational
epistemic tools.

\subsection{The Coordinated Governance
Ecosystem}\label{sec-governance-ecosystem}

Imagine an AI governance ecosystem where:

\textbf{Shared Formal Models} serve as common ground for international
coordination, with diplomats exploring policy implications using the
same validated models that researchers develop and refine.

\textbf{Dynamic Risk Dashboards} track key indicators in real-time,
automatically updating probability estimates as new research emerges and
triggering alerts when critical thresholds approach.

\textbf{Rapid Policy Prototyping} enables governments to formally
evaluate proposed interventions before implementation, identifying
likely failures and unintended consequences through systematic analysis.

\textbf{Democratized Analysis} empowers citizen groups to interrogate
expert models, propose alternatives, and meaningfully participate in
technical governance discussions.

This vision requires continued development of both technical
capabilities and institutional frameworks, but the foundation laid by
this research makes such a future achievable.

\subsection{Conditions for Success}\label{sec-success-conditions}

Realizing this vision requires several enabling conditions:

\textbf{Technical Maturity}: Extraction accuracy must improve to
minimize human oversight needs, while computational methods must scale
to handle realistic policy complexity.

\textbf{Institutional Adoption}: Organizations must develop processes
for creating, maintaining, and using formal models in actual
decision-making rather than as academic exercises.

\textbf{Community Development}: A critical mass of practitioners skilled
in both domain knowledge and formal modeling must emerge to sustain the
ecosystem.

\textbf{Trust and Legitimacy}: Stakeholders must trust that models
faithfully represent different perspectives rather than encoding hidden
biases or agendas.

\subsection{The Stakes and Opportunity}\label{sec-stakes-opportunity}

The window for establishing effective AI governance may be narrowing as
capabilities advance rapidly. Current coordination failures---duplicated
efforts, talking past each other, locally optimal but globally harmful
decisions---pose existential risks comparable to technical alignment
challenges.

AMTAIR offers a concrete path forward: computational tools that enhance
rather than replace human judgment, that clarify rather than obscure
democratic deliberation, that enable rather than prevent decisive action
under uncertainty.

The opportunity is not merely to make better decisions about AI
governance but to demonstrate new modes of collective reasoning adequate
to civilization-scale challenges. If we can successfully coordinate on
AI governance using these tools, they may prove valuable for other
existential challenges humanity faces.

\section{Concluding Reflections}\label{sec-concluding-reflections}

This thesis began by diagnosing a coordination crisis in AI
governance---a systematic failure to align diverse efforts into coherent
responses proportionate to existential risks. It proposed that
computational tools for formalizing worldviews could enhance
coordination by making implicit models explicit, enabling systematic
comparison, and supporting rigorous policy evaluation.

The research demonstrated both feasibility and value: automated
extraction works well enough to be useful, formal models reveal insights
unavailable through informal analysis, and practical tools can be built
with current technology. Yet it also revealed the depth of challenges
ahead: technical limitations in handling complex arguments,
institutional barriers to adopting new analytical approaches, and
fundamental uncertainties that no amount of modeling can resolve.

Perhaps most importantly, the work highlights that coordination failures
are not inevitable laws of nature but contingent problems admitting of
partial solutions. Better tools enable better collective reasoning,
which enables better decisions, which may make the difference between
navigating safely through AI development or losing control of humanity's
future.

The contribution of this thesis is not solving the coordination problem
but providing tools that make solutions possible. Whether humanity uses
these tools wisely---whether we achieve the epistemic security needed
for navigating transformative AI---remains an open question. But we now
have better methods for approaching that question systematically rather
than haphazardly.

In a domain where the stakes could not be higher and time may be running
short, even modest improvements in coordination capability provide
enormous expected value. This thesis offers such improvements,
demonstrated concretely through working systems and validated
empirically through real applications.

The path forward requires continued technical development, institutional
innovation, and community building. But the foundation has been laid for
a new approach to AI governance---one that matches the sophistication of
the challenge with equally sophisticated tools for collective reasoning.

The future depends not only on what AI systems we build, but on how well
we coordinate in governing them. This thesis provides tools for that
coordination. Whether they prove sufficient remains to be seen, but they
represent a significant step toward the epistemic infrastructure
civilization needs for navigating the development of transformative AI.

\bookmarksetup{startatroot}

\chapter*{Appendices}\label{sec-appendices}
\addcontentsline{toc}{chapter}{Appendices}

\markboth{Appendices}{Appendices}

\section*{Appendix A: Technical Implementation
Details}\label{sec-appendix-technical}
\addcontentsline{toc}{section}{Appendix A: Technical Implementation
Details}

\markright{Appendix A: Technical Implementation Details}

\subsection*{A.1 Core Data Structures}\label{sec-data-structures}
\addcontentsline{toc}{subsection}{A.1 Core Data Structures}

The AMTAIR system employs several custom data structures optimized for
representing hierarchical arguments with probabilistic metadata:

\begin{Shaded}
\begin{Highlighting}[]
\AttributeTok{@dataclass}
\KeywordTok{class}\NormalTok{ BayesDownNode:}
    \CommentTok{"""Represents a single node in the BayesDown format"""}
\NormalTok{    title: }\BuiltInTok{str}
\NormalTok{    description: }\BuiltInTok{str}
\NormalTok{    instantiations: List[}\BuiltInTok{str}\NormalTok{]}
\NormalTok{    priors: Dict[}\BuiltInTok{str}\NormalTok{, }\BuiltInTok{float}\NormalTok{] }\OperatorTok{=}\NormalTok{ field(default\_factory}\OperatorTok{=}\BuiltInTok{dict}\NormalTok{)}
\NormalTok{    posteriors: Dict[}\BuiltInTok{str}\NormalTok{, }\BuiltInTok{float}\NormalTok{] }\OperatorTok{=}\NormalTok{ field(default\_factory}\OperatorTok{=}\BuiltInTok{dict}\NormalTok{)}
\NormalTok{    parents: List[}\BuiltInTok{str}\NormalTok{] }\OperatorTok{=}\NormalTok{ field(default\_factory}\OperatorTok{=}\BuiltInTok{list}\NormalTok{)}
\NormalTok{    children: List[}\BuiltInTok{str}\NormalTok{] }\OperatorTok{=}\NormalTok{ field(default\_factory}\OperatorTok{=}\BuiltInTok{list}\NormalTok{)}
\NormalTok{    metadata: Dict[}\BuiltInTok{str}\NormalTok{, Any] }\OperatorTok{=}\NormalTok{ field(default\_factory}\OperatorTok{=}\BuiltInTok{dict}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection*{A.2 Extraction Algorithm
Details}\label{sec-extraction-details}
\addcontentsline{toc}{subsection}{A.2 Extraction Algorithm Details}

\subsection*{A.3 API Specifications}\label{sec-api-specs}
\addcontentsline{toc}{subsection}{A.3 API Specifications}

\section*{Appendix B: Model Validation Datasets and
Benchmarks}\label{sec-appendix-validation}
\addcontentsline{toc}{section}{Appendix B: Model Validation Datasets and
Benchmarks}

\markright{Appendix B: Model Validation Datasets and Benchmarks}

\subsection*{B.1 Expert Annotation
Protocol}\label{sec-annotation-protocol}
\addcontentsline{toc}{subsection}{B.1 Expert Annotation Protocol}

\subsection*{B.2 Benchmark Dataset
Construction}\label{sec-benchmark-construction}
\addcontentsline{toc}{subsection}{B.2 Benchmark Dataset Construction}

\subsection*{B.3 Validation Results}\label{sec-validation-results}
\addcontentsline{toc}{subsection}{B.3 Validation Results}

\section*{Appendix C: Extended Case
Studies}\label{sec-appendix-case-studies}
\addcontentsline{toc}{section}{Appendix C: Extended Case Studies}

\markright{Appendix C: Extended Case Studies}

\subsection*{C.1 Christiano's ``What Failure Looks Like''
Extraction}\label{sec-christiano-extraction}
\addcontentsline{toc}{subsection}{C.1 Christiano's ``What Failure Looks
Like'' Extraction}

\subsection*{C.2 Critch's ARCHES Model}\label{sec-critch-extraction}
\addcontentsline{toc}{subsection}{C.2 Critch's ARCHES Model}

\subsection*{C.3 Policy Evaluation: A Narrow
Path}\label{sec-narrow-path-evaluation}
\addcontentsline{toc}{subsection}{C.3 Policy Evaluation: A Narrow Path}

\section*{Appendix D: Ethical Considerations and
Governance}\label{sec-appendix-ethical}
\addcontentsline{toc}{section}{Appendix D: Ethical Considerations and
Governance}

\markright{Appendix D: Ethical Considerations and Governance}

\subsection*{D.1 Potential Misuse Scenarios}\label{sec-misuse-scenarios}
\addcontentsline{toc}{subsection}{D.1 Potential Misuse Scenarios}

\subsection*{D.2 Democratic Participation
Frameworks}\label{sec-democratic-frameworks}
\addcontentsline{toc}{subsection}{D.2 Democratic Participation
Frameworks}

\subsection*{D.3 Responsibility Assignment}\label{sec-responsibility}
\addcontentsline{toc}{subsection}{D.3 Responsibility Assignment}

\section*{Appendix E: Full Extraction
Examples}\label{sec-appendix-examples}
\addcontentsline{toc}{section}{Appendix E: Full Extraction Examples}

\markright{Appendix E: Full Extraction Examples}

\section*{Appendix F: Software Installation and Usage
Guide}\label{sec-appendix-software}
\addcontentsline{toc}{section}{Appendix F: Software Installation and
Usage Guide}

\markright{Appendix F: Software Installation and Usage Guide}

\bookmarksetup{startatroot}

\chapter*{References}\label{references}
\addcontentsline{toc}{chapter}{References}

\markboth{References}{References}

\printbibliography[heading=none]


\backmatter
\printbibliography[title=Bibliography]



\clearpage
\thispagestyle{empty} % Removes page numbering for current page

\newpage


% Top header with logo (left) and department (right)
\begin{minipage}{0.3\textwidth}
  \includegraphics[width=5cm]{latex/uni-bayreuth-logo.png}
\end{minipage}
\hfill
\begin{minipage}{0.9\textwidth}
  \begin{center}
    -- P\&E Master's Programme --\\
    Chair of Philosophy, Computer\\
    Science \& Artificial Intelligence
  \end{center}
\end{minipage}

% Horizontal rule
\vspace{1.5cm}
\hrule
\vspace{2.5cm}

% Title in bold

  \LARGE\textbf{Affidavit}
\vspace{1.5cm}

\center

\normalsize

% \part*{Affidavit}

    \subsection*{\Large Declaration of Academic Honesty}
	    \vspace{1cm}\noindent \\
	    Hereby, I attest that I have composed and written the presented thesis 
        \vspace*{0.5cm}\noindent \\
        \textit{ \textbf{ Automating the Modelling of Transformative Artificial Intelligence Risks }}
        \vspace*{0.5cm}\noindent \\
        independently on my own, without the use of other than the stated aids and without any other resources than the ones indicated. All thoughts taken directly or indirectly from external sources are properly denoted as such.
	    \vspace{\baselineskip}
	    \\  This paper has neither been previously submitted in the same or a similar form to another authority nor has it been published yet.
	    \vspace{2cm}
	    
    \flushright
    \begin{minipage}{0.5\textwidth}
        \begin{flushleft} \large
        \textsc{Bayreuth}                     %   Place
        on the \\ % 26th of May 2025     \\
        \today           %   Date
        \vspace{2cm}\\
    	{\rule[-3pt]{\linewidth}{.4pt}\par\smallskip  
        \textsc{Valentin Meyer}	\\         %   Your name
    	}
        \end{flushleft}
        \end{minipage}


\end{document}
