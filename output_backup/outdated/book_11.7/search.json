[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#main-formatting",
    "href": "index.html#main-formatting",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Main Formatting",
    "text": "Main Formatting\n\nHtml Comments",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#syntax-for-tasks",
    "href": "index.html#syntax-for-tasks",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Syntax for Tasks",
    "text": "Syntax for Tasks\n\nTasks with ToDo Tree\n\nSimple “One-line tasks”\nUse Code ticks and html comment and task format for tasks distinctly visible across all formats including the ToDo-Tree overview:\n&lt;!-- [ ] ToDos for things to do / tasks / reminders (allows \"jump to with Taks Tree extension\") --&gt;\nUse html comment and task format for open or uncertain tasks, visible in the .qmd file:\n\n\n\nMore Complex Tasks with Notes\n&lt;!-- [ ] Task Title: short description--&gt;\n\n  More Information about task\n\n  Relevant notes\n\n  Step-by-step implementation Plan\n\n  Etc.\n\n\n\nCompleted Tasks\nRetain completed tasks in ToDo-Tree by adding an x in the brackets: [x] &lt;!-- [x] Tasks which have been finished but should remain for later verification --&gt;\n\nMark and remove completed tasks from ToDo-Tree by adding a minus in the brackets: [-]\n&lt;!-- [-] Tasks which have been finished but should remain visible for later verification --&gt;\n\n\n\nMissing Citations\n&lt;!-- [ ] FIND: @CITATION_KEY_PURPOSE: \"Description of the appropriate/idea source, including ideas /suggestions / search terms etc.\" --&gt;\n\n\nSuggested Citation\n&lt;!-- [ ] VERIFY: @CITATION_KEY_SUGGESTED: \"Description of the appropriate paper, book, source\" [Include BibTex if known] --&gt;\n\n\nMissing Graphic\n&lt;!-- [ ] FIND: {#fig-GRAPHIC_IDEA}]: \"Description of the appropriate/idea source, including ideas /suggestions / search terms etc.\" --&gt;\n\n\nSuggested Graphic\n&lt;!-- [ ] VERIFY: {#fig-GRAPHIC_IDEA}: \"Description of the appropriate paper, book, source\" [Include figure syntax if known] --&gt;\nMissing and/or suggested tables, concepts, explanations as well as other elements should be suggested similarily.\n\n\n\nTask Syntax Examples\n&lt;!-- [ ] (Example short: open and visible in text)   Find and list the names of the MTAIR team-members responsible for the Analytica Implementation --&gt;\n&lt;!-- [ ] (Example longer: open and visible in text)    Review/Plan/Discuss integrating Live Prediction Markets --&gt;\n\n  Live prediction market integration requires:\n    (1) API connections to platforms (Metaculus, Manifold),\n    (2) Question-to-variable mapping algorithms,\n    (3) Probability update mechanisms, \n    (4) Handling of market dynamics (thin markets, manipulation).\n    Current mentions may overstate readiness or underestimate complexity.\n    Need realistic assessment of what's achievable.\n\n  Implementation Steps:\n      0. List/mention all relevant platforms with a brief description each\n      1. Review all existing prediction market mentions for accuracy\n      2. Assess actual API availability and limitations\n      3. Describe/explain/discuss how to implement basic proof-of-concept with single platform\n      4. Document challenges: question mapping, market interpretation\n      5. Create realistic timeline for full implementation\n      6. Revise thesis claims to match reality\n      7. Add \"Future Work\" and/or extension section on complete integration\n      8. Include descriptions of mockups/designs even if not fully built \n      9. Highlight/discuss the advantages of such integrations\n      10. Quickly brainstorm for downsides worth mentioning\n\n\n\n\nVerbatim Code Formatting\nverbatim code formatting for notes and ideas to be included (here)\n\n\nCode Block formatting\nAlso code blocks for more extensive notes and ideas to be included and checklists\n- test 1. \n- test 2. \n- test 3.\n2. second\n3. third\ncode\nAdd a language to syntax highlight code blocks:\n1 + 1\n\n\nBlockquote Formatting\n\nBlockquote formatting for “Suggested Citations (e.g. carlsmith 2024 on …)” and/or claims which require a citation (e.g. claim x should be backed-up by a ciation from the literature)\n\n\n\nTables\n\n\n\nTable 1.1: Demonstration of pipe table syntax\n\n\n\n\n\nRight\nLeft\nDefault\nCenter\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1\n\n\n\n\n\n\n\n\n\nTable 1.2: My Caption 1\n\n\n\n\n\nCol1\nCol2\nCol3\n\n\n\n\nA\nB\nC\n\n\nE\nF\nG\n\n\nA\nG\nG\n\n\n\n\n\n\nReferencing tables with @tbl-KEY: See Table 5.2.\n\n\n\nTable 1.3: Main Caption\n\n\n\n\n\n\n\n(a) First Table\n\n\n\n\n\nCol1\nCol2\nCol3\n\n\n\n\nA\nB\nC\n\n\nE\nF\nG\n\n\nA\nG\nG\n\n\n\n\n\n\n\n\n\n\n\n(b) Second Table\n\n\n\n\n\nCol1\nCol2\nCol3\n\n\n\n\nA\nB\nC\n\n\nE\nF\nG\n\n\nA\nG\nG\n\n\n\n\n\n\n\n\n\n\n\nSee Table 1.3 for details, especially Table 1.3 (b).\npython\n#| label: tbl-planets\n#| tbl-cap: Astronomical object\n\nfrom IPython.display import Markdown\nfrom tabulate import tabulate\ntable = [[\"Sun\",\"696,000\",1.989e30],\n         [\"Earth\",\"6,371\",5.972e24],\n         [\"Moon\",\"1,737\",7.34e22],\n         [\"Mars\",\"3,390\",6.39e23]]\nMarkdown(tabulate(\n  table, \n  headers=[\"Astronomical object\",\"R (km)\", \"mass (kg)\"]\n))\n\nSample grid table.\n\n\n\n\n\n\n\nFruit\nPrice\nAdvantages\n\n\n\n\nBananas\n$1.34\n\nbuilt-in wrapper\nbright color\n\n\n\nOranges\n$2.10\n\ncures scurvy\ntasty\n\n\n\n\nContent with HTML tables you don’t want processed.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#sec-heading",
    "href": "index.html#sec-heading",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Headings & Potential Headings in Standard Markdown formatting (‘##’)",
    "text": "Headings & Potential Headings in Standard Markdown formatting (‘##’)\n\nHeading 3\n\nHeading 4",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#text-formatting-options",
    "href": "index.html#text-formatting-options",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Text Formatting Options",
    "text": "Text Formatting Options\nitalics, bold, bold italics\nsuperscript2 and subscript2\nstrikethrough\nThis text is highlighted\nThis text is underlined\nThis text is smallcaps",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#lists",
    "href": "index.html#lists",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Lists",
    "text": "Lists\n\nunordered list\n\nsub-item 1\nsub-item 2\n\nsub-sub-item 1\n\n\nitem 2\nContinued (indent 4 spaces)\n\n\nordered list\nitem 2\n\nsub-item 1\n\nsub-sub-item 1",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#math",
    "href": "index.html#math",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Math",
    "text": "Math\ninline math: \\(E = mc^{2}\\)\ndisplay math:\n\\[E = mc^{2}\\]\nIf you want to define custom TeX macros, include them within $$ delimiters enclosed in a .hidden block. For example:\n\n\\[\n\\def\\RR{{\\bf R}}\n\\def\\bold#1{{\\bf #1}}\n\\]\n\nFor HTML math processed using MathJax (the default) you can use the \\def, \\newcommand, \\renewcommand, \\newenvironment, \\renewenvironment, and \\let commands to create your own macros and environments.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "",
    "text": "Inlines notes are easier to write, since you don’t have to pick an identifier and move down to type the note.↩︎\nHere is the footnote.↩︎\nHere’s one with multiple blocks.\nSubsequent paragraphs are indented to show that they belong to the previous footnote.\n{ some.code }\nThe whole paragraph can be indented, or just the first line. In this way, multi-paragraph footnotes work like multi-paragraph list items.↩︎",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#sec-callouts",
    "href": "index.html#sec-callouts",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Callouts",
    "text": "Callouts\nQuarto’s native callouts work without additional packages:\n\nThis is written in a ‘note’ environment – but it does not seem to produce any special rendering.\n\n\n\n\n\n\n\nOptional Title\n\n\n\nContent here\n\n\n\n\n\n\n\n\nImportant Note2\n\n\n\nThis renders perfectly in both HTML and PDF.\n\n\nAlso for markdown:\n::: {.render_as_markdown_example}\n## Markdown Heading\nThis renders perfectly in both HTML and PDF but as markdown \"plain text\"\n:::",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#links",
    "href": "index.html#links",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Links",
    "text": "Links\n&lt;https://quarto.org/docs/authoring/markdown-basics.html&gt; produces: https://quarto.org/docs/authoring/markdown-basics.html\n[Quarto Book Cross-References](https://quarto.org/docs/books/book-crossrefs.html) produces: Quarto Book Cross-References",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#sec-figures1",
    "href": "index.html#sec-figures1",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Images & Figures",
    "text": "Images & Figures\n[![AMTAIR Automation Pipeline from @bucknall2022](/images/pipeline.png){\n  #fig-automation_pipeline\n  fig-scap=\"Five-step AMTAIR automation pipeline from PDFs to Bayesian networks\" \n  fig-alt=\"FLOWCHART: Five-step automation pipeline workflow for AMTAIR project.\n          DATA: The pipeline transforms PDFs through ArgDown, BayesDown, CSV, and HTML into Bayesian network visualizations.\n          PURPOSE: Illustrates the core technical process that enables automated extraction of probabilistic models from AI safety literature.\n          DETAILS: Five numbered green steps show: (1) LLM-based extraction from PDFs to ArgDown, (2) ArgDown to BayesDown completion with probabilities, (3) Extracting world-models as CSV data, (4) Software tools for data inference, and (5) Visualization of the resulting Bayesian network.\n          Each step includes example outputs, with the final visualization showing a Rain-Sprinkler-Grass Wet Bayesian network with probability tables.\n          SOURCE: Created by the author to explain the AMTAIR methodology\n          \"\n  fig-align=\"center\" \n  width=\"100%\"\n  }](https://github.com/VJMeyer/submission)\n\n\nTesting crossreferencing grapics @fig-automation_pipeline.\n\n![Caption/Title 2](/images/cover.png){#fig-testgraphic2 fig-scap=\"Short 2 caption\" fig-alt=\"2nd Alt Text / Description.\" fig-align=\"left\" width=\"30%\"}\n\nTesting crossreferencing grapics @fig-testgraphic2.\n\n\n\n\n\n\nFigure 1.1: AMTAIR Automation Pipeline from\n\n\n\nTesting crossreferencing grapics Figure 1.1. Note that the indentations of graphic inclusions get messed up by viewing them in “view mode” in VS code.\n\n\n\n\n\n\nFigure 1.2: Caption/Title 2\n\n\n\nTesting crossreferencing grapics Figure 5.1.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#page-breaks",
    "href": "index.html#page-breaks",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Page Breaks",
    "text": "Page Breaks\npage 1\n\n\n\npage 2\npage 1\n\npage 2",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#sec-code",
    "href": "index.html#sec-code",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Including Code",
    "text": "Including Code\n\nCode\nimport pandas as pd\nprint(\"AMTAIR is working!\")\n\n\n\n\n\nAMTAIR is working!\n\n\n\nFigure 1.3\n\n\n\n\nIn-Line LaTeX\n\n\n\nIn-Line HTML\nHere’s some raw inline HTML: html",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#reference-or-embed-code-from-.ipynb-files",
    "href": "index.html#reference-or-embed-code-from-.ipynb-files",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Reference or Embed Code from .ipynb files",
    "text": "Reference or Embed Code from .ipynb files\n\nCode chunks from .ipynb notebooks can be embedded in the .qmd text with:\n{{&lt; embed /AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb#my_code_cell_test &gt;}}\n\n\nwhich produces the output of executing the code cell:\n\n\n\nConnecting to repository: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/\nAttempting to load: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/ArgDown.md\n✅ Successfully connected to repository and loaded test files.\n[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {\"instantiations\": [\"existential_catastrophe_TRUE\", \"existential_catastrophe_FALSE\"]}\n- [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {\"instantiations\": [\"human_disempowerment_TRUE\", \"human_disempowerment_FALSE\"]}\n    - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {\"instantiations\": [\"scale_of_power_seeking_TRUE\", \"scale_of_power_seeking_FALSE\"]}\n        - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n            - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {\"instantiations\": [\"aps_systems_TRUE\", \"aps_systems_FALSE\"]}\n                - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {\"instantiations\": [\"advanced_ai_capability_TRUE\", \"advanced_ai_capability_FALSE\"]}\n                - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {\"instantiations\": [\"agentic_planning_TRUE\", \"agentic_planning_FALSE\"]}\n                - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {\"instantiations\": [\"strategic_awareness_TRUE\", \"strategic_awareness_FALSE\"]}\n            - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {\"instantiations\": [\"difficulty_of_alignment_TRUE\", \"difficulty_of_alignment_FALSE\"]}\n                - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {\"instantiations\": [\"instrumental_convergence_TRUE\", \"instrumental_convergence_FALSE\"]}\n                - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {\"instantiations\": [\"problems_with_proxies_TRUE\", \"problems_with_proxies_FALSE\"]}\n                - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {\"instantiations\": [\"problems_with_search_TRUE\", \"problems_with_search_FALSE\"]}\n            - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {\"instantiations\": [\"deployment_decisions_DEPLOY\", \"deployment_decisions_WITHHOLD\"]}\n                - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {\"instantiations\": [\"incentives_to_build_aps_STRONG\", \"incentives_to_build_aps_WEAK\"]}\n                    - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {\"instantiations\": [\"usefulness_of_aps_HIGH\", \"usefulness_of_aps_LOW\"]}\n                    - [Competitive_Dynamics]: Competitive pressures between AI developers. {\"instantiations\": [\"competitive_dynamics_STRONG\", \"competitive_dynamics_WEAK\"]}\n                - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {\"instantiations\": [\"deception_by_ai_TRUE\", \"deception_by_ai_FALSE\"]}\n        - [Corrective_Feedback]: Human society implementing corrections after observing problems. {\"instantiations\": [\"corrective_feedback_EFFECTIVE\", \"corrective_feedback_INEFFECTIVE\"]}\n            - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {\"instantiations\": [\"warning_shots_OBSERVED\", \"warning_shots_UNOBSERVED\"]}\n            - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {\"instantiations\": [\"rapid_capability_escalation_TRUE\", \"rapid_capability_escalation_FALSE\"]}\n[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {\"instantiations\": [\"barriers_to_understanding_HIGH\", \"barriers_to_understanding_LOW\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {\"instantiations\": [\"adversarial_dynamics_TRUE\", \"adversarial_dynamics_FALSE\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {\"instantiations\": [\"stakes_of_error_HIGH\", \"stakes_of_error_LOW\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n\n\n\n\n\n\nincluding ‘echo=true’ renders the code of the cell:\n{{&lt; embed /AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb#my_code_cell_test echo=true &gt;}}\n\n\n\nCode\n# @title 0.2 --- Connect to GitHub Repository --- Load Files\n\n\"\"\"\nBLOCK PURPOSE: Establishes connection to the AMTAIR GitHub repository and provides\nfunctions to load example data files for processing.\n\nThis block creates a reusable function for accessing files from the project's\nGitHub repository, enabling access to example files like the rain-sprinkler-lawn\nBayesian network that serves as our canonical test case.\n\nDEPENDENCIES: requests library, io library\nOUTPUTS: load_file_from_repo function and test file loads\n\"\"\"\n\nfrom requests.exceptions import HTTPError\n\n# Specify the base repository URL for the AMTAIR project\nrepo_url = \"https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/\"\nprint(f\"Connecting to repository: {repo_url}\")\n\ndef load_file_from_repo(relative_path):\n    \"\"\"\n    Loads a file from the specified GitHub repository using a relative path.\n\n    Args:\n        relative_path (str): Path to the file relative to the repo_url\n\n    Returns:\n        For CSV/JSON: pandas DataFrame\n        For MD: string containing file contents\n\n    Raises:\n        HTTPError: If file not found or other HTTP error occurs\n        ValueError: If unsupported file type is requested\n    \"\"\"\n    file_url = repo_url + relative_path\n    print(f\"Attempting to load: {file_url}\")\n\n    # Fetch the file content from GitHub\n    response = requests.get(file_url)\n\n    # Check for bad status codes with enhanced error messages\n    if response.status_code == 404:\n        raise HTTPError(f\"File not found at URL: {file_url}. Check the file path/name and ensure the file is publicly accessible.\", response=response)\n    else:\n        response.raise_for_status()  # Raise for other error codes\n\n    # Convert response to file-like object\n    file_object = io.StringIO(response.text)\n\n    # Process different file types appropriately\n    if relative_path.endswith(\".csv\"):\n        return pd.read_csv(file_object)  # Return DataFrame for CSV\n    elif relative_path.endswith(\".json\"):\n        return pd.read_json(file_object)  # Return DataFrame for JSON\n    elif relative_path.endswith(\".md\"):\n        return file_object.read()  # Return raw content for MD files\n    else:\n        raise ValueError(f\"Unsupported file type: {relative_path.split('.')[-1]}. Add support in the GitHub Connection section of this notebook.\")\n\n# Load example files to test connection\ntry:\n    # Load the extracted data CSV file\n#    df = load_file_from_repo(\"extracted_data.csv\")\n\n    # Load the ArgDown test text\n    md_content = load_file_from_repo(\"ArgDown.md\")\n\n    print(\"✅ Successfully connected to repository and loaded test files.\")\nexcept Exception as e:\n    print(f\"❌ Error loading files: {str(e)}\")\n    print(\"Please check your internet connection and the repository URL.\")\n\n# Display preview of loaded content (commented out to avoid cluttering output)\nprint(md_content)\n\n\nConnecting to repository: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/\nAttempting to load: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/ArgDown.md\n✅ Successfully connected to repository and loaded test files.\n[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {\"instantiations\": [\"existential_catastrophe_TRUE\", \"existential_catastrophe_FALSE\"]}\n- [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {\"instantiations\": [\"human_disempowerment_TRUE\", \"human_disempowerment_FALSE\"]}\n    - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {\"instantiations\": [\"scale_of_power_seeking_TRUE\", \"scale_of_power_seeking_FALSE\"]}\n        - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n            - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {\"instantiations\": [\"aps_systems_TRUE\", \"aps_systems_FALSE\"]}\n                - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {\"instantiations\": [\"advanced_ai_capability_TRUE\", \"advanced_ai_capability_FALSE\"]}\n                - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {\"instantiations\": [\"agentic_planning_TRUE\", \"agentic_planning_FALSE\"]}\n                - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {\"instantiations\": [\"strategic_awareness_TRUE\", \"strategic_awareness_FALSE\"]}\n            - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {\"instantiations\": [\"difficulty_of_alignment_TRUE\", \"difficulty_of_alignment_FALSE\"]}\n                - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {\"instantiations\": [\"instrumental_convergence_TRUE\", \"instrumental_convergence_FALSE\"]}\n                - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {\"instantiations\": [\"problems_with_proxies_TRUE\", \"problems_with_proxies_FALSE\"]}\n                - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {\"instantiations\": [\"problems_with_search_TRUE\", \"problems_with_search_FALSE\"]}\n            - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {\"instantiations\": [\"deployment_decisions_DEPLOY\", \"deployment_decisions_WITHHOLD\"]}\n                - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {\"instantiations\": [\"incentives_to_build_aps_STRONG\", \"incentives_to_build_aps_WEAK\"]}\n                    - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {\"instantiations\": [\"usefulness_of_aps_HIGH\", \"usefulness_of_aps_LOW\"]}\n                    - [Competitive_Dynamics]: Competitive pressures between AI developers. {\"instantiations\": [\"competitive_dynamics_STRONG\", \"competitive_dynamics_WEAK\"]}\n                - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {\"instantiations\": [\"deception_by_ai_TRUE\", \"deception_by_ai_FALSE\"]}\n        - [Corrective_Feedback]: Human society implementing corrections after observing problems. {\"instantiations\": [\"corrective_feedback_EFFECTIVE\", \"corrective_feedback_INEFFECTIVE\"]}\n            - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {\"instantiations\": [\"warning_shots_OBSERVED\", \"warning_shots_UNOBSERVED\"]}\n            - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {\"instantiations\": [\"rapid_capability_escalation_TRUE\", \"rapid_capability_escalation_FALSE\"]}\n[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {\"instantiations\": [\"barriers_to_understanding_HIGH\", \"barriers_to_understanding_LOW\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {\"instantiations\": [\"adversarial_dynamics_TRUE\", \"adversarial_dynamics_FALSE\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {\"instantiations\": [\"stakes_of_error_HIGH\", \"stakes_of_error_LOW\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n\n\n\n\nLink:\nFull Notebooks are embedded in the Appendix through the _quarto.yml file with:",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#diagrams",
    "href": "index.html#diagrams",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Diagrams",
    "text": "Diagrams\nQuarto has native support for embedding Mermaid and Graphviz diagrams. This enables you to create flowcharts, sequence diagrams, state diagrams, Gantt charts, and more using a plain text syntax inspired by markdown.\nFor example, here we embed a flowchart created using Mermaid:\n\n\nCode\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#sec-citations",
    "href": "index.html#sec-citations",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Citations",
    "text": "Citations\nSoares and Fallenstein (2014) \n(Soares and Fallenstein 2014) and (Knuth 1984)\nBlah Blah (see Knuth 1984, 33–35; also Growiec 2024, chap. 1)\nBlah Blah (Knuth 1984, 33–35, 38–39 and passim)\nBlah Blah (Growiec 2024; Knuth 1984).\nGrowiec says blah (2024)\n\nNarrative citations (author as subject)\nSoares and Fallenstein (2014) argues that AI alignment requires…\n\n\nParenthetical citations (supporting reference)\nRecent work supports this view (Soares and Fallenstein 2014; Knuth 1984).\n\n\nAuthor-only citation (when discussing the person)\nAs (2014) demonstrates in their analysis…\n\n\nYear-only citation (when author already mentioned)\nSoares (2014) later revised this position.\n\n\nPage-specific references\nThe key insight appears in (Soares and Fallenstein 2014, 45–67).\n\n\nMultiple works, different pages\nThis view is supported (Soares and Fallenstein 2014, 23; Knuth 1984, 156–59).",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#sec-crossref",
    "href": "index.html#sec-crossref",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Section Cross-References",
    "text": "Section Cross-References\nRefer to sections like: ?sec-adaptive-governance and Section Cross-References \nCaveat: refering to sections with @sec-HEADINGS works only for sections with:\n## Heading {#sec-HEADINGS}\nIt does not work for sections with \".unnumbered and/or .unlisted\":\n## Heading {#sec-HEADINGS .unnumbered .unlisted}\nFurthermore the .qmd and/or .md yml settings (~ numbering have to be just right)\n\nSection Numbers\nBy default, all headings in your document create a numbered section. You customize numbering depth using the number-depth option. For example, to only number sections immediately below the chapter level, use this:\nnumber-depth: 2\nNote that toc-depth is independent of number-depth (i.e. you can have unnumbered entries in the TOC if they are masked out from numbering by number-depth).\nTesting crossreferencing grapics Figure 1.1. See Chapter Quarto Syntax for more details on visualizing model diagnostics.\nTesting crossreferencing headings AI Existential Risk: The Carlsmith Model\nTesting crossreferencing headings @sec-rain-sprinkler-grass which does not work yet. \nChapter Cross-Reference Section Cross-References",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#pages-in-landscape",
    "href": "index.html#pages-in-landscape",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Pages in Landscape",
    "text": "Pages in Landscape\n\nThis will appear in landscape but only in PDF format. Testing crossreferencing headings AI Existential Risk: The Carlsmith Model",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#illustrations-and-terminology-quick-references",
    "href": "index.html#illustrations-and-terminology-quick-references",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Illustrations and Terminology — Quick References",
    "text": "Illustrations and Terminology — Quick References\n\nAcknowledgments\n\nAcademic supervisor (Prof. Timo Speith) and institution (University of Bayreuth)\n\nResearch collaborators, especially those connected to the original MTAIR project\n\nTechnical advisors who provided feedback on implementation aspects\n\nPersonal supporters who enabled the research through encouragement and feedback",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#list-of-graphics-figures",
    "href": "index.html#list-of-graphics-figures",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "List of Graphics & Figures",
    "text": "List of Graphics & Figures\n\n\n\nFigure 1.1: The coordination crisis in AI governance - visualization of fragmentation\n\nFigure 2.1: The Carlsmith model - DAG representation\n\nFigure 3.1: Research design overview - workflow diagram\n\nFigure 3.2: From natural language to BayesDown - transformation process\n\nFigure 4.1: ARPA system architecture - component diagram\n\nFigure 4.2: Visualization of Rain-Sprinkler-Grass_Wet Bayesian network - screenshot\n\nFigure 5.1: Extraction quality metrics - comparative chart\n\nFigure 5.2: Comparative analysis of AI governance worldviews - network visualization",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#list-of-abbreviations",
    "href": "index.html#list-of-abbreviations",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "List of Abbreviations",
    "text": "List of Abbreviations\n\n\nesp. especially\nf., ff. following\nincl. including\np., pp. page(s)\nMAD Mutually Assured Destruction\n\nAI - Artificial Intelligence\n\nAGI - Artificial General Intelligence\n\nARPA - AI Risk Pathway Analyzer\n\nDAG - Directed Acyclic Graph\n\nLLM - Large Language Model\n\nMTAIR - Modeling Transformative AI Risks\n\nP(Doom) - Probability of existential catastrophe from misaligned AI\n\nCPT - Conditional Probability Table",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#glossary",
    "href": "index.html#glossary",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Glossary",
    "text": "Glossary\n\n\n\nArgument mapping: A method for visually representing the structure of arguments\n\nBayesDown: An extension of ArgDown that incorporates probabilistic information\n\nBayesian network: A probabilistic graphical model representing variables and their dependencies\n\nConditional probability: The probability of an event given that another event has occurred\n\nDirected Acyclic Graph (DAG): A graph with directed edges and no cycles\n\nExistential risk: Risk of permanent curtailment of humanity’s potential\n\nPower-seeking AI: AI systems with instrumental incentives to acquire resources and power\n\nPrediction market: A market where participants trade contracts that resolve based on future events\n\nd-separation: A criterion for identifying conditional independence relationships in Bayesian networks\n\nMonte Carlo sampling: A computational technique using random sampling to obtain numerical results\n\n\n\n\nQuarto Features Previously Incompatible with LaTeX (Below)\n\n\n\n\n\n\n\n\n\nGrowiec, Jakub. 2024. “Existential Risk from Transformative AI: An Economic Perspective.” Technological and Economic Development of Economy, 1–27.\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Computer Journal 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nSoares, Nate, and Benja Fallenstein. 2014. “Aligning Superintelligence with Human Interests: A Technical Research Agenda.”",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html",
    "href": "chapters/Outlines/Outline_11.7_0.5.html",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "",
    "text": "1.0.1 1. Structural Alignment with Thesis",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#step-by-step-outline-improvement-process",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#step-by-step-outline-improvement-process",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "1.1 Step-by-Step Outline Improvement Process",
    "text": "1.1 Step-by-Step Outline Improvement Process\n\n1.1.1 Step 1: American Spelling Consistency\nReasoning: The first improvement note emphasizes American spelling throughout. This affects every section and should be done first to avoid inconsistency.\nChanges Applied:\n\nTitle: “Modelling” → “Modeling”\nThroughout: “analyse” → “analyze”, “optimisation” → “optimization”, “behaviour” → “behavior”\nAdded task: &lt;!-- [ ] Verify American spelling throughout document using US English spell checker --&gt;\n\n\n\n1.1.2 Step 2: Thesis Statement Refinement\nReasoning: The thesis statement frames the entire work. The current statement is too vague (“Explain how the MTAIR can be automated”). Needs specificity about contribution and impact.\nChanges Applied:\n\nMoved from vague technical description to specific claim about capabilities and benefits\nNew statement: “This thesis demonstrates that frontier language models can automate the extraction and formalization of probabilistic world models from AI safety literature, creating a scalable computational framework that enhances coordination in AI governance through systematic policy evaluation under uncertainty.”\nPositioned after coordination crisis explanation for logical flow\n\n\n\n1.1.3 Step 3: Manual Extraction Examples\nReasoning: Manual examples provide ground truth for validation and demonstrate deep understanding. Should include 2-3 examples as specified.\nChanges Applied:\n\nAdded task for Carlsmith manual extraction (already complete)\nAdded task for Christiano’s “What Failure Looks Like” extraction\nAdded task for Critch’s “ARCHES” extraction\nSpecified comparison table creation and validation dataset\n\n\n\n1.1.4 Step 4: Literature Review Structure\nReasoning: The dual-track literature review (content and technical) needs clear organization.\nChanges Applied:\n\nSeparated content review (AI risk models, governance proposals) from technical review (Bayesian networks, software)\nAdded specific subtopics under each track\nIncluded correlation handling as specified limitation\n\n\n\n1.1.5 Step 5: Policy Examples Integration\nReasoning: Concrete policy examples (“A Narrow Path”, SB 1047) ground the theoretical framework in real governance questions.\nChanges Applied:\n\nAdded dedicated sections for each policy example\nSpecified analysis requirements: intervention identification, parameter mapping, impact estimation\nAdded tasks for 2-3 additional policies\n\n\n\n1.1.6 Step 6: Code Reduction Strategy\nReasoning: Note #20 emphasizes “less code in text”. Code should illustrate key concepts, not implementation details.\nChanges Applied:\n\nAdded explicit limits: 3-5 key code snippets maximum\nSpecified what to keep (conceptual algorithms) vs. remove (implementation details)\nAdded tasks to move code to appendices and create visual alternatives\n\n\n\n1.1.7 Step 7: Graphics Planning\nReasoning: Note #33 emphasizes strategic graphics throughout. Visual elements dramatically improve comprehension.\nChanges Applied:\n\nAdded specific graphics tasks with figure IDs and descriptions\nPrioritized 5 key visuals: coordination crisis, pipeline, transformation, convergence, policy dashboard\nUsed proper Quarto figure syntax with tasks\n\n\n\n1.1.8 Step 8: Section Transitions\nReasoning: Note #24 emphasizes smooth transitions between chapters for narrative coherence.\nChanges Applied:\n\nAdded specific transition text between each major section\nCreated preview/summary pattern for chapter boundaries\nAdded task to revise introduction to preview structure\n\n\n\n1.1.9 Step 9: Lists to Prose Conversion\nReasoning: Note #25 specifies fewer lists, more flowing prose for sophisticated academic writing.\nChanges Applied:\n\nAdded tasks to identify and convert lists in each section\nSpecified transitional phrases to use\nReserved lists only for true enumerations\n\n\n\n1.1.10 Step 10: Validation Framework\nReasoning: Multiple notes emphasize validation and verification of extraction quality.\nChanges Applied:\n\nAdded comprehensive validation section with specific metrics\nIncluded inter-rater reliability testing\nSpecified manual ground truth creation\nAdded performance benchmarking tasks\n\n\n\n1.1.11 Step 11: Advanced Features\nReasoning: Correlation handling and prediction markets represent advanced capabilities mentioned in multiple notes.\nChanges Applied:\n\nAdded correlation workaround implementations\nSpecified prediction market integration architecture\nMarked these clearly as extensions/future work where not fully implemented\n\n\n\n1.1.12 Step 12: Implementation Status Clarity\nReasoning: Note #46 emphasizes distinguishing implemented vs. planned features to avoid overpromising.\nChanges Applied:\n\nAdded explicit status markers for each feature\nCreated categories: fully implemented, partially implemented, designed, future\nAdded task to create feature status matrix\n\n\n\n1.1.13 Step 13: Notebook Integration\nReasoning: The notebook is a crucial technical demonstration that needs tight integration with thesis claims.\nChanges Applied:\n\nAdded cross-referencing tasks between thesis and notebook\nSpecified cell labeling convention\nCreated mapping of thesis claims to supporting code\nAdded validation cells for specific accuracy claims\n\n\n\n1.1.14 Step 14: Final Polish Elements\nReasoning: Various notes about formatting, citations, and professional presentation.\nChanges Applied:\n\nAdded comprehensive citation tasks using proper Quarto syntax\nIncluded glossary and abbreviation list updates\nAdded index creation task\nSpecified accessibility requirements for all graphics\n\n\n\n1.1.15 Step 15: Quality Control Structure\nReasoning: The thesis needs systematic quality control given its complexity.\nChanges Applied:\n\nAdded milestone review tasks throughout\nCreated verification checklists for each improvement area\nSpecified advisor review points\nAdded final verification against all 52 improvement notes",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#numbering-start-at-0-start-at-section-1-level-1-chapter-level",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#numbering-start-at-0-start-at-section-1-level-1-chapter-level",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "4.1 numbering: start-at: 0 # Start at Section 1 level: 1 # Chapter level",
    "text": "4.1 numbering: start-at: 0 # Start at Section 1 level: 1 # Chapter level",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#main-formatting",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#main-formatting",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "5.1 Main Formatting",
    "text": "5.1 Main Formatting\n\n5.1.1 Html Comments",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#syntax-for-tasks",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#syntax-for-tasks",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "5.2 Syntax for Tasks",
    "text": "5.2 Syntax for Tasks\n\n5.2.1 Tasks with ToDo Tree\n\n5.2.1.1 Simple “One-line tasks”\nUse Code ticks and html comment and task format for tasks distinctly visible across all formats including the ToDo-Tree overview:\n&lt;!-- [ ] ToDos for things to do / tasks / reminders (allows \"jump to with Task Tree extension\") --&gt;\nUse html comment and task format for open or uncertain tasks, visible in the .qmd file:\n\n\n\n5.2.1.2 More Complex Tasks with Notes\n&lt;!-- [ ] Task Title: short description--&gt;\n\n  More Information about task\n\n  Relevant notes\n\n  Step-by-step implementation Plan\n\n  Etc.\n\n\n5.2.1.3 Completed Tasks\nRetain completed tasks in ToDo-Tree by adding an x in the brackets: [x] &lt;!-- [x] Tasks which have been finished but should remain for later verification --&gt;\n\nMark and remove completed tasks from ToDo-Tree by adding a minus in the brackets: [-]\n&lt;!-- [-] Tasks which have been finished but should remain visible for later verification --&gt;\n\n\n\n5.2.1.4 Missing Citations\n&lt;!-- [ ] FIND: @CITATION_KEY_PURPOSE: \"Description of the appropriate/idea source, including ideas /suggestions / search terms etc.\" --&gt;\n\n\n5.2.1.5 Suggested Citation\n&lt;!-- [ ] VERIFY: @CITATION_KEY_SUGGESTED: \"Description of the appropriate paper, book, source\" [Include BibTeX if known] --&gt;\n\n\n5.2.1.6 Missing Graphic\n&lt;!-- [ ] FIND: {#fig-GRAPHIC_IDEA}: \"Description of the appropriate/idea source, including ideas /suggestions / search terms etc.\" --&gt;\n\n\n5.2.1.7 Suggested Graphic\n&lt;!-- [ ] VERIFY: {#fig-GRAPHIC_IDEA}: \"Description of the appropriate paper, book, source\" [Include figure syntax if known] --&gt;\nMissing and/or suggested tables, concepts, explanations as well as other elements should be suggested similarly.\n\n\n\n5.2.2 Task Syntax Examples\n&lt;!-- [ ] (Example short: open and visible in text) Find and list the names of the MTAIR team-members responsible for the Analytica Implementation --&gt;\n&lt;!-- [ ] (Example longer: open and visible in text)    Review/Plan/Discuss integrating Live Prediction Markets --&gt;\n\n  Live prediction market integration requires:\n    (1) API connections to platforms (Metaculus, Manifold),\n    (2) Question-to-variable mapping algorithms,\n    (3) Probability update mechanisms, \n    (4) Handling of market dynamics (thin markets, manipulation).\n    Current mentions may overstate readiness or underestimate complexity.\n    Need realistic assessment of what's achievable.\n\n  Implementation Steps:\n      0. List/mention all relevant platforms with a brief description each\n      1. Review all existing prediction market mentions for accuracy\n      2. Assess actual API availability and limitations\n      3. Describe/explain/discuss how to implement basic proof-of-concept with single platform\n      4. Document challenges: question mapping, market interpretation\n      5. Create realistic timeline for full implementation\n      6. Revise thesis claims to match reality\n      7. Add \"Future Work\" and/or extension section on complete integration\n      8. Include descriptions of mockups/designs even if not fully built \n      9. Highlight/discuss the advantages of such integrations\n      10. Quickly brainstorm for downsides worth mentioning\n\n\n\n\n5.2.3 Verbatim Code Formatting\nverbatim code formatting for notes and ideas to be included (here)\n\n\n5.2.4 Code Block formatting\nAlso code blocks for more extensive notes and ideas to be included and checklists\n- test 1. \n- test 2. \n- test 3.\n2. second\n3. third\ncode\nAdd a language to syntax highlight code blocks:\n1 + 1\n\n\n5.2.5 Blockquote Formatting\n\nBlockquote formatting for “Suggested Citations (e.g. Carlsmith 2024 on …)” and/or claims which require a citation (e.g. claim x should be backed-up by a citation from the literature)\n\n\n\n5.2.6 Tables\n\n\n\nTable 5.1: Demonstration of pipe table syntax\n\n\n\n\n\nRight\nLeft\nDefault\nCenter\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1\n\n\n\n\n\n\n\n\n\nTable 5.2: My Caption 1\n\n\n\n\n\nCol1\nCol2\nCol3\n\n\n\n\nA\nB\nC\n\n\nE\nF\nG\n\n\nA\nG\nG\n\n\n\n\n\n\nReferencing tables with @tbl-KEY: See Table 5.2.\nSee Table 1.3 for details, especially Table 1.3 (b).\npython\n#| label: tbl-planets\n#| tbl-cap: Astronomical object\n\nfrom IPython.display import Markdown\nfrom tabulate import tabulate\ntable = [[\"Sun\",\"696,000\",1.989e30],\n         [\"Earth\",\"6,371\",5.972e24],\n         [\"Moon\",\"1,737\",7.34e22],\n         [\"Mars\",\"3,390\",6.39e23]]\nMarkdown(tabulate(\n  table, \n  headers=[\"Astronomical object\",\"R (km)\", \"mass (kg)\"]\n))\n\n+————+————+———————-+ | Fruit | Price | Advantages | +============+============+======================+ | Bananas | $1.34 | - built-in wrapper | | | | - bright color | +————+————+———————-+ | Oranges | $2.10 | - cures scurvy | | | | - tasty | +————+————+———————-+\n\nSample grid table.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#sec-heading",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#sec-heading",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "5.3 Headings & Potential Headings in Standard Markdown formatting (‘##’)",
    "text": "5.3 Headings & Potential Headings in Standard Markdown formatting (‘##’)\n\n5.3.1 Heading 3\n\n5.3.1.1 Heading 4",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#text-formatting-options",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#text-formatting-options",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "5.4 Text Formatting Options",
    "text": "5.4 Text Formatting Options\nitalics, bold, bold italics\nsuperscript2 and subscript2\nstrikethrough\nThis text is highlighted\nThis text is underlined\nThis text is smallcaps",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#lists",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#lists",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "5.5 Lists",
    "text": "5.5 Lists\n\nunordered list\n\nsub-item 1\nsub-item 2\n\nsub-sub-item 1\n\n\nitem 2\nContinued (indent 4 spaces)\n\n\nordered list\nitem 2 i) sub-item 1 A. sub-sub-item 1",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#math",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#math",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "5.6 Math",
    "text": "5.6 Math\ninline math: \\(E = mc^{2}\\)\ndisplay math:\n\\[E = mc^{2}\\]\nIf you want to define custom TeX macros, include them within $$ delimiters enclosed in a .hidden block. For example:\nFor HTML math processed using MathJax (the default) you can use the \\def, \\newcommand, \\renewcommand, \\newenvironment, \\renewenvironment, and \\let commands to create your own macros and environments.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#footnotes",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#footnotes",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "",
    "text": "Inlines notes are easier to write, since you don’t have to pick an identifier and move down to type the note.↩︎\nHere is the footnote.↩︎\nHere’s one with multiple blocks.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#sec-callouts",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#sec-callouts",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "5.8 Callouts",
    "text": "5.8 Callouts\nQuarto’s native callouts work without additional packages:\n\nThis is written in a ‘note’ environment – but it does not seem to produce any special rendering.\n\n\n\n\n\n\n\nOptional Title\n\n\n\nContent here\n\n\n\n\n\n\n\n\nImportant Note2\n\n\n\nThis renders perfectly in both HTML and PDF.\n\n\nAlso for markdown:\n::: {.render_as_markdown_example}\n## Markdown Heading\nThis renders perfectly in both HTML and PDF but as markdown \"plain text\"\n:::",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#links",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#links",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "5.9 Links",
    "text": "5.9 Links\n&lt;https://quarto.org/docs/authoring/markdown-basics.html&gt; produces: https://quarto.org/docs/authoring/markdown-basics.html\n[Quarto Book Cross-References](https://quarto.org/docs/books/book-crossrefs.html) produces: Quarto Book Cross-References",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#sec-figures1",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#sec-figures1",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "Images & Figures",
    "text": "Images & Figures\n[![AMTAIR Automation Pipeline from @bucknall2022](/images/pipeline.png){\n  #fig-automation_pipeline\n  fig-scap=\"Five-step AMTAIR automation pipeline from PDFs to Bayesian networks\" \n  fig-alt=\"FLOWCHART: Five-step automation pipeline workflow for AMTAIR project.\n          DATA: The pipeline transforms PDFs through ArgDown, BayesDown, CSV, and HTML into Bayesian network visualizations.\n          PURPOSE: Illustrates the core technical process that enables automated extraction of probabilistic models from AI safety literature.\n          DETAILS: Five numbered green steps show: (1) LLM-based extraction from PDFs to ArgDown, (2) ArgDown to BayesDown completion with probabilities, (3) Extracting world-models as CSV data, (4) Software tools for data inference, and (5) Visualization of the resulting Bayesian network.\n          Each step includes example outputs, with the final visualization showing a Rain-Sprinkler-Grass Wet Bayesian network with probability tables.\n          SOURCE: Created by the author to explain the AMTAIR methodology\n          \"\n  fig-align=\"center\" \n  width=\"100%\"\n  }](https://github.com/VJMeyer/submission)\n\n\nTesting cross-referencing graphics @fig-automation_pipeline.\n\n![Caption/Title 2](/images/cover.png){#fig-testgraphic2 fig-scap=\"Short 2 caption\" fig-alt=\"2nd Alt Text / Description.\" fig-align=\"left\" width=\"30%\"}\n\nTesting cross-referencing graphics @fig-testgraphic2.\n\nTesting cross-referencing graphics Figure 1.1. Note that the indentations of graphic inclusions get messed up by viewing them in “view mode” in VS code.\n\n\n\n\n\n\nFigure 5.1: Caption/Title 2\n\n\n\nTesting cross-referencing graphics Figure 5.1.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#page-breaks",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#page-breaks",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "5.10 Page Breaks",
    "text": "5.10 Page Breaks\npage 1\n\n\n\npage 2\npage 1\n\npage 2",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#sec-code",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#sec-code",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "5.11 Including Code",
    "text": "5.11 Including Code\n\nCode\nimport pandas as pd\nprint(\"AMTAIR is working!\")\n\n\n\n\n\nAMTAIR is working!\n\n\n\nFigure 5.2\n\n\n\n\n5.11.1 In-Line LaTeX\n\n\n\n5.11.2 In-Line HTML\nHere’s some raw inline HTML: html",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#reference-or-embed-code-from-.ipynb-files",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#reference-or-embed-code-from-.ipynb-files",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "5.12 Reference or Embed Code from .ipynb files",
    "text": "5.12 Reference or Embed Code from .ipynb files\n\n5.12.0.1 Code chunks from .ipynb notebooks can be embedded in the .qmd text with:\n{{&lt; embed /AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb#my_code_cell_test &gt;}}\n\n\n5.12.0.2 which produces the output of executing the code cell:\n\n\n\nConnecting to repository: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/\nAttempting to load: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/ArgDown.md\n✅ Successfully connected to repository and loaded test files.\n[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {\"instantiations\": [\"existential_catastrophe_TRUE\", \"existential_catastrophe_FALSE\"]}\n- [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {\"instantiations\": [\"human_disempowerment_TRUE\", \"human_disempowerment_FALSE\"]}\n    - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {\"instantiations\": [\"scale_of_power_seeking_TRUE\", \"scale_of_power_seeking_FALSE\"]}\n        - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n            - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {\"instantiations\": [\"aps_systems_TRUE\", \"aps_systems_FALSE\"]}\n                - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {\"instantiations\": [\"advanced_ai_capability_TRUE\", \"advanced_ai_capability_FALSE\"]}\n                - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {\"instantiations\": [\"agentic_planning_TRUE\", \"agentic_planning_FALSE\"]}\n                - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {\"instantiations\": [\"strategic_awareness_TRUE\", \"strategic_awareness_FALSE\"]}\n            - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {\"instantiations\": [\"difficulty_of_alignment_TRUE\", \"difficulty_of_alignment_FALSE\"]}\n                - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {\"instantiations\": [\"instrumental_convergence_TRUE\", \"instrumental_convergence_FALSE\"]}\n                - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {\"instantiations\": [\"problems_with_proxies_TRUE\", \"problems_with_proxies_FALSE\"]}\n                - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {\"instantiations\": [\"problems_with_search_TRUE\", \"problems_with_search_FALSE\"]}\n            - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {\"instantiations\": [\"deployment_decisions_DEPLOY\", \"deployment_decisions_WITHHOLD\"]}\n                - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {\"instantiations\": [\"incentives_to_build_aps_STRONG\", \"incentives_to_build_aps_WEAK\"]}\n                    - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {\"instantiations\": [\"usefulness_of_aps_HIGH\", \"usefulness_of_aps_LOW\"]}\n                    - [Competitive_Dynamics]: Competitive pressures between AI developers. {\"instantiations\": [\"competitive_dynamics_STRONG\", \"competitive_dynamics_WEAK\"]}\n                - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {\"instantiations\": [\"deception_by_ai_TRUE\", \"deception_by_ai_FALSE\"]}\n        - [Corrective_Feedback]: Human society implementing corrections after observing problems. {\"instantiations\": [\"corrective_feedback_EFFECTIVE\", \"corrective_feedback_INEFFECTIVE\"]}\n            - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {\"instantiations\": [\"warning_shots_OBSERVED\", \"warning_shots_UNOBSERVED\"]}\n            - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {\"instantiations\": [\"rapid_capability_escalation_TRUE\", \"rapid_capability_escalation_FALSE\"]}\n[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {\"instantiations\": [\"barriers_to_understanding_HIGH\", \"barriers_to_understanding_LOW\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {\"instantiations\": [\"adversarial_dynamics_TRUE\", \"adversarial_dynamics_FALSE\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {\"instantiations\": [\"stakes_of_error_HIGH\", \"stakes_of_error_LOW\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n\n\n\n\n\n\n5.12.0.3 including ‘echo=true’ renders the code of the cell:\n{{&lt; embed /AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb#my_code_cell_test echo=true &gt;}}\n\n\n\nCode\n# @title 0.2 --- Connect to GitHub Repository --- Load Files\n\n\"\"\"\nBLOCK PURPOSE: Establishes connection to the AMTAIR GitHub repository and provides\nfunctions to load example data files for processing.\n\nThis block creates a reusable function for accessing files from the project's\nGitHub repository, enabling access to example files like the rain-sprinkler-lawn\nBayesian network that serves as our canonical test case.\n\nDEPENDENCIES: requests library, io library\nOUTPUTS: load_file_from_repo function and test file loads\n\"\"\"\n\nfrom requests.exceptions import HTTPError\n\n# Specify the base repository URL for the AMTAIR project\nrepo_url = \"https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/\"\nprint(f\"Connecting to repository: {repo_url}\")\n\ndef load_file_from_repo(relative_path):\n    \"\"\"\n    Loads a file from the specified GitHub repository using a relative path.\n\n    Args:\n        relative_path (str): Path to the file relative to the repo_url\n\n    Returns:\n        For CSV/JSON: pandas DataFrame\n        For MD: string containing file contents\n\n    Raises:\n        HTTPError: If file not found or other HTTP error occurs\n        ValueError: If unsupported file type is requested\n    \"\"\"\n    file_url = repo_url + relative_path\n    print(f\"Attempting to load: {file_url}\")\n\n    # Fetch the file content from GitHub\n    response = requests.get(file_url)\n\n    # Check for bad status codes with enhanced error messages\n    if response.status_code == 404:\n        raise HTTPError(f\"File not found at URL: {file_url}. Check the file path/name and ensure the file is publicly accessible.\", response=response)\n    else:\n        response.raise_for_status()  # Raise for other error codes\n\n    # Convert response to file-like object\n    file_object = io.StringIO(response.text)\n\n    # Process different file types appropriately\n    if relative_path.endswith(\".csv\"):\n        return pd.read_csv(file_object)  # Return DataFrame for CSV\n    elif relative_path.endswith(\".json\"):\n        return pd.read_json(file_object)  # Return DataFrame for JSON\n    elif relative_path.endswith(\".md\"):\n        return file_object.read()  # Return raw content for MD files\n    else:\n        raise ValueError(f\"Unsupported file type: {relative_path.split('.')[-1]}. Add support in the GitHub Connection section of this notebook.\")\n\n# Load example files to test connection\ntry:\n    # Load the extracted data CSV file\n#    df = load_file_from_repo(\"extracted_data.csv\")\n\n    # Load the ArgDown test text\n    md_content = load_file_from_repo(\"ArgDown.md\")\n\n    print(\"✅ Successfully connected to repository and loaded test files.\")\nexcept Exception as e:\n    print(f\"❌ Error loading files: {str(e)}\")\n    print(\"Please check your internet connection and the repository URL.\")\n\n# Display preview of loaded content (commented out to avoid cluttering output)\nprint(md_content)\n\n\nConnecting to repository: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/\nAttempting to load: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/ArgDown.md\n✅ Successfully connected to repository and loaded test files.\n[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {\"instantiations\": [\"existential_catastrophe_TRUE\", \"existential_catastrophe_FALSE\"]}\n- [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {\"instantiations\": [\"human_disempowerment_TRUE\", \"human_disempowerment_FALSE\"]}\n    - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {\"instantiations\": [\"scale_of_power_seeking_TRUE\", \"scale_of_power_seeking_FALSE\"]}\n        - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n            - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {\"instantiations\": [\"aps_systems_TRUE\", \"aps_systems_FALSE\"]}\n                - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {\"instantiations\": [\"advanced_ai_capability_TRUE\", \"advanced_ai_capability_FALSE\"]}\n                - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {\"instantiations\": [\"agentic_planning_TRUE\", \"agentic_planning_FALSE\"]}\n                - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {\"instantiations\": [\"strategic_awareness_TRUE\", \"strategic_awareness_FALSE\"]}\n            - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {\"instantiations\": [\"difficulty_of_alignment_TRUE\", \"difficulty_of_alignment_FALSE\"]}\n                - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {\"instantiations\": [\"instrumental_convergence_TRUE\", \"instrumental_convergence_FALSE\"]}\n                - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {\"instantiations\": [\"problems_with_proxies_TRUE\", \"problems_with_proxies_FALSE\"]}\n                - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {\"instantiations\": [\"problems_with_search_TRUE\", \"problems_with_search_FALSE\"]}\n            - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {\"instantiations\": [\"deployment_decisions_DEPLOY\", \"deployment_decisions_WITHHOLD\"]}\n                - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {\"instantiations\": [\"incentives_to_build_aps_STRONG\", \"incentives_to_build_aps_WEAK\"]}\n                    - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {\"instantiations\": [\"usefulness_of_aps_HIGH\", \"usefulness_of_aps_LOW\"]}\n                    - [Competitive_Dynamics]: Competitive pressures between AI developers. {\"instantiations\": [\"competitive_dynamics_STRONG\", \"competitive_dynamics_WEAK\"]}\n                - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {\"instantiations\": [\"deception_by_ai_TRUE\", \"deception_by_ai_FALSE\"]}\n        - [Corrective_Feedback]: Human society implementing corrections after observing problems. {\"instantiations\": [\"corrective_feedback_EFFECTIVE\", \"corrective_feedback_INEFFECTIVE\"]}\n            - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {\"instantiations\": [\"warning_shots_OBSERVED\", \"warning_shots_UNOBSERVED\"]}\n            - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {\"instantiations\": [\"rapid_capability_escalation_TRUE\", \"rapid_capability_escalation_FALSE\"]}\n[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {\"instantiations\": [\"barriers_to_understanding_HIGH\", \"barriers_to_understanding_LOW\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {\"instantiations\": [\"adversarial_dynamics_TRUE\", \"adversarial_dynamics_FALSE\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {\"instantiations\": [\"stakes_of_error_HIGH\", \"stakes_of_error_LOW\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n\n\n\n\nLink:\nFull Notebooks are embedded in the Appendix through the _quarto.yml file with:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#diagrams",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#diagrams",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "5.13 Diagrams",
    "text": "5.13 Diagrams\nQuarto has native support for embedding Mermaid and Graphviz diagrams. This enables you to create flowcharts, sequence diagrams, state diagrams, Gantt charts, and more using a plain text syntax inspired by markdown.\nFor example, here we embed a flowchart created using Mermaid:\n\n\nCode\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#sec-citations",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#sec-citations",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "Citations",
    "text": "Citations\nSoares and Fallenstein (2014) \n(Soares and Fallenstein 2014) and (Knuth 1984)\nBlah Blah (see Knuth 1984, 33–35; also Growiec 2024, chap. 1)\nBlah Blah (Knuth 1984, 33–35, 38–39 and passim)\nBlah Blah (Growiec 2024; Knuth 1984).\nGrowiec says blah (2024)\n\n5.13.1 Narrative citations (author as subject)\nSoares and Fallenstein (2014) argues that AI alignment requires…\n\n\n5.13.2 Parenthetical citations (supporting reference)\nRecent work supports this view (Soares and Fallenstein 2014; Knuth 1984).\n\n\n5.13.3 Author-only citation (when discussing the person)\nAs (2014) demonstrates in their analysis…\n\n\n5.13.4 Year-only citation (when author already mentioned)\nSoares (2014) later revised this position.\n\n\n5.13.5 Page-specific references\nThe key insight appears in (Soares and Fallenstein 2014, 45–67).\n\n\n5.13.6 Multiple works, different pages\nThis view is supported (Soares and Fallenstein 2014, 23; Knuth 1984, 156–59).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#sec-crossref",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#sec-crossref",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "5.14 Section Cross-References",
    "text": "5.14 Section Cross-References\nRefer to sections like: ?sec-adaptive-governance and Section 5.14 \nCaveat: referring to sections with @sec-HEADINGS works only for sections with:\n## Heading {#sec-HEADINGS}\nIt does not work for sections with \".unnumbered and/or .unlisted\":\n## Heading {#sec-HEADINGS .unnumbered .unlisted}\nFurthermore the .qmd and/or .md yml settings (~ numbering have to be just right)\n\n5.14.1 Section Numbers\nBy default, all headings in your document create a numbered section. You customize numbering depth using the number-depth option. For example, to only number sections immediately below the chapter level, use this:\nnumber-depth: 2\nNote that toc-depth is independent of number-depth (i.e. you can have unnumbered entries in the TOC if they are masked out from numbering by number-depth).\nTesting cross-referencing graphics Figure 1.1. See Chapter 5 for more details on visualizing model diagnostics.\nTesting cross-referencing headings Section 11.1.1\nTesting cross-referencing headings @sec-rain-sprinkler-grass which does not work yet. \nChapter Cross-Reference Section 5.14",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#pages-in-landscape",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#pages-in-landscape",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "5.15 Pages in Landscape",
    "text": "5.15 Pages in Landscape",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#numbering-start-at-1-start-at-section-1-level-1-chapter-level",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#numbering-start-at-1-start-at-section-1-level-1-chapter-level",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "7.1 numbering: start-at: 1 # Start at Section 1 level: 1 # Chapter level",
    "text": "7.1 numbering: start-at: 1 # Start at Section 1 level: 1 # Chapter level",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#sec-coordination-crisis",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#sec-coordination-crisis",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "8.1 The Coordination Crisis in AI Governance",
    "text": "8.1 The Coordination Crisis in AI Governance\n\n\n\nAs AI capabilities advance at an accelerating pace—demonstrated by the rapid progression from GPT-3 to GPT-4, Claude, and beyond—we face a governance challenge unlike any in human history: how to ensure increasingly powerful AI systems remain aligned with human values and beneficial to humanity’s long-term flourishing. This challenge becomes particularly acute when considering the possibility of transformative AI systems that could drastically alter civilization’s trajectory, potentially including existential risks from misaligned systems.\n\nDespite unprecedented investment in AI safety research, rapidly growing awareness among key stakeholders, and proliferating frameworks for responsible AI development, we face what I’ll term the “coordination crisis” in AI governance—a systemic failure to align diverse efforts across technical, policy, and strategic domains into a coherent response proportionate to the risks we face.\n\nThe AI governance landscape exhibits a peculiar paradox: extraordinary activity alongside fundamental coordination failure. Consider the current state of affairs:\nTechnical safety researchers develop increasingly sophisticated alignment techniques, but often without clear implementation pathways to deployment contexts. Policy specialists craft principles and regulatory frameworks without sufficient technical grounding to ensure their practical efficacy. Ethicists articulate normative principles that lack operational specificity. Strategy researchers identify critical uncertainties but struggle to translate these into actionable guidance.\n\n8.1.1 Empirical Paradox: Investment Alongside Fragmentation\n\n\n\nThe fragmentation problem manifests in incompatible frameworks between technical researchers, policy specialists, and strategic analysts. Each community develops sophisticated approaches within their domain, yet translation between domains remains primitive. This creates systematic blind spots where risks emerge at the interfaces between technical capabilities, institutional responses, and strategic dynamics.\n\n\n8.1.2 Systematic Risk Increase Through Coordination Failure\n\n\n\n\nCoordination failures systematically amplify existential risk through multiple pathways. Safety gaps emerge when technical solutions lack policy implementation pathways. Resource misallocation occurs when multiple teams unknowingly duplicate efforts while critical areas remain unaddressed. Most perniciously, locally optimized decisions by individual actors can create negative-sum dynamics that increase overall risk—a AI governance tragedy of the commons.\n\n\n8.1.3 Historical Parallels and Temporal Urgency\n\n\n\nTraditional governance approaches evolved for technologies with longer development cycles and clearer deployment boundaries. The nuclear era provided decades for international regime development. Climate governance, despite its challenges, addresses a phenomenon unfolding over centuries. AI development, by contrast, may transition from current capabilities to transformative systems within years or decades, compressing the available window for effective coordination.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#sec-research-question",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#sec-research-question",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "8.2 Research Question and Scope",
    "text": "8.2 Research Question and Scope\n\n\n\nThis thesis addresses a specific dimension of the coordination challenge by investigating the question: Can frontier AI technologies be utilized to automate the modeling of transformative AI risks, enabling robust prediction of policy impacts across diverse worldviews?\n\nRefined Thesis Statement: This thesis demonstrates that frontier language models can automate the extraction and formalization of probabilistic world models from AI safety literature, creating a scalable computational framework that enhances coordination in AI governance through systematic policy evaluation under uncertainty.\nTo break this down into its components:\n\nFrontier AI Technologies: Today’s most capable language models (GPT-4, Claude-3 level systems)\nAutomated Modeling: Using these systems to extract and formalize argument structures from natural language\nTransformative AI Risks: Potentially catastrophic outcomes from advanced AI systems, particularly existential risks\nPolicy Impact Prediction: Evaluating how governance interventions might alter probability distributions over outcomes\nDiverse Worldviews: Accounting for fundamental disagreements about AI development trajectories and risk factors\n\nThe investigation encompasses both theoretical development and practical implementation, focusing specifically on existential risks from misaligned AI systems rather than broader AI ethics concerns. This narrowed scope enables deep technical development while addressing the highest-stakes coordination challenges.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#sec-multiplicative-benefits",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#sec-multiplicative-benefits",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "8.3 The Multiplicative Benefits Framework",
    "text": "8.3 The Multiplicative Benefits Framework\n\n\n\n\nThe central thesis of this work is that combining three elements—automated worldview extraction, prediction market integration, and formal policy evaluation—creates multiplicative rather than merely additive benefits for AI governance. Each component enhances the others, creating a system more valuable than the sum of its parts.\nAutomated worldview extraction using frontier language models addresses the scaling bottleneck in current approaches to AI risk modeling. The Modeling Transformative AI Risks (MTAIR) project demonstrated the value of formal representation but required extensive manual effort to translate qualitative arguments into quantitative models. Automation enables processing orders of magnitude more content, incorporating diverse perspectives, and maintaining models in near real-time as new arguments emerge.\nPrediction market integration grounds these models in collective forecasting intelligence. By connecting formal representations to live forecasting platforms, the system can incorporate timely judgments about critical uncertainties from calibrated forecasters. This creates a dynamic feedback loop, where models inform forecasters and forecasts update models.\nFormal policy evaluation transforms static risk assessments into actionable guidance by modeling how specific interventions might alter critical parameters. This enables conditional forecasting—understanding not just the probability of adverse outcomes but how those probabilities change under different policy regimes.\nThe synergy emerges because automation enables comprehensive data integration, markets inform and validate models, and evaluation gains precision from both automated extraction and market-based calibration.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#sec-roadmap",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#sec-roadmap",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "8.4 Thesis Structure and Roadmap",
    "text": "8.4 Thesis Structure and Roadmap\n\n\n\n\nThe remainder of this thesis develops the multiplicative benefits framework from theoretical foundations to practical implementation, following a progression from abstract principles to concrete applications:\nSection 2 establishes the theoretical foundations and methodological approach, examining why AI governance presents unique epistemic challenges and how Bayesian networks can formalize causal relationships in this domain. This section grounds the technical contributions in established theory while identifying the specific gaps AMTAIR addresses.\nSection 3 presents the AMTAIR implementation, detailing the technical system that transforms qualitative arguments into formal representations. It demonstrates the approach through two case studies: the canonical Rain-Sprinkler-Lawn example for intuitive understanding and the more complex Carlsmith model of power-seeking AI for real-world validation.\nSection 4 provides critical analysis of the approach, addressing potential failure modes, scaling challenges, and integration with existing governance frameworks. This section engages seriously with objections and limitations while demonstrating the robustness of the core approach.\nSection 5 concludes by summarizing key contributions, drawing out concrete policy implications, and suggesting directions for future research. It returns to the opening coordination crisis to show how AMTAIR provides partial but significant solutions.\nThroughout this progression, I maintain a dual focus on theoretical sophistication and practical utility. The framework aims not merely to advance academic understanding of AI risk but to provide actionable tools for improving coordination in AI governance.\n\nHaving established the coordination crisis and outlined how automated modeling can address it, we now turn to the theoretical foundations that make this approach possible. The next chapter examines the unique epistemic challenges of AI governance and introduces the formal tools—particularly Bayesian networks—that enable rigorous reasoning under deep uncertainty.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#numbering-start-at-2-start-at-1-in-section-1-level-1-chapter-level",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#numbering-start-at-2-start-at-1-in-section-1-level-1-chapter-level",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "10.1 numbering: start-at: 2 # Start at 1 in Section 1 level: 1 # Chapter level",
    "text": "10.1 numbering: start-at: 2 # Start at 1 in Section 1 level: 1 # Chapter level",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#sec-theoretical-foundations",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#sec-theoretical-foundations",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "11.1 Theoretical Foundations",
    "text": "11.1 Theoretical Foundations\n\n11.1.1 AI Existential Risk: The Carlsmith Model\n\n\n\nCarlsmith’s “Is power-seeking AI an existential risk?” (2021) represents one of the most structured approaches to assessing the probability of existential catastrophe from advanced AI. The analysis decomposes the overall risk into six key premises, each with an explicit probability estimate.\n\nCarlsmith (2021) provides the canonical structured approach to AI existential risk assessment\n\nSix-Premise Decomposition:\nCarlsmith decomposes existential risk into a probabilistic chain with explicit estimates:\n\nPremise 1: Transformative AI development this century (P ≈ 0.80)\nPremise 2: AI systems pursuing objectives in the world (P ≈ 0.95)\nPremise 3: Systems with power-seeking instrumental incentives (P ≈ 0.40)\nPremise 4: Sufficient capability for existential threat (P ≈ 0.65)\nPremise 5: Misaligned systems despite safety efforts (P ≈ 0.50)\nPremise 6: Catastrophic outcomes from misaligned power-seeking (P ≈ 0.65)\n\nComposite Risk Calculation: P(doom) ≈ 0.05 (5%)\nThis structured approach exemplifies the type of reasoning that AMTAIR aims to formalize and automate, providing both transparency in assumptions and modularity for critique and refinement.\n\n11.1.1.1 Why Carlsmith as Ideal Formalization Target\nCarlsmith’s model represents “low-hanging fruit” for automated formalization because it already exhibits explicit probabilistic reasoning with clear conditional dependencies. Success with this structured argument validates the approach for less explicit arguments throughout AI safety literature. The model demonstrates several key features that make it ideal for formalization: explicitly probabilistic reasoning with quantified estimates, clear conditional dependencies between premises, transparent decomposition of complex causal pathways, well-documented argumentation available for extraction validation, and policy-relevant implications requiring formal evaluation.\n\n\n\n\n\n\n11.1.2 The Epistemic Challenge of Policy Evaluation\n\n\nAI governance policy evaluation faces unique epistemic challenges that render traditional policy analysis methods insufficient. The domain combines complex causal chains with limited empirical grounding, deep uncertainty about future capabilities, divergent stakeholder worldviews, and few opportunities for experimental testing before deployment.\nTraditional methods fall short in several ways. Cost-benefit analysis struggles with existential outcomes and deep uncertainty about unprecedented events. Scenario planning often lacks the probabilistic reasoning necessary for rigorous evaluation under uncertainty. Expert elicitation alone fails to formalize interdependencies between variables and make assumptions explicit. Qualitative approaches obscure crucial assumptions that drive conclusions, making it difficult to identify cruxes of disagreement.\nUnprecedented Epistemic Environment:\nThe AI governance domain presents specific challenges that traditional policy analysis cannot adequately address:\n\nDeep Uncertainty: Many decisions involve unprecedented scenarios without historical frequency data for calibration\nComplex Causality: Policy effects propagate through multi-level dependencies spanning technical, institutional, and strategic domains\nMultidisciplinary Integration: Combining technical facts, ethical principles, and strategic considerations requires novel synthesis approaches\nValue-Laden Assessment: Risk evaluation inherently involves normative judgments about acceptable outcomes and distributional effects\n\n\n\n11.1.2.1 Unique Difficulties in AI Governance\nComplex Causal Chains: Multi-level dependencies between technical capabilities, institutional responses, and strategic outcomes create analytical challenges beyond traditional policy domains.\nDeep Uncertainty: Unprecedented AI capabilities make historical analogies insufficient, requiring new approaches to reasoning about low-probability, high-impact events.\nDivergent Worldviews: Fundamental disagreements persist about timeline expectations for transformative AI, difficulty of alignment problems, effectiveness of governance interventions, and possibilities for international coordination.\n\n\n11.1.2.2 Limitations of Traditional Policy Analysis\nTraditional policy analysis approaches prove inadequate for AI governance challenges. Cost-benefit analysis struggles with potentially infinite expected values from existential outcomes and lacks frameworks for deep uncertainty. Scenario planning, while useful for exploration, often lacks the probabilistic reasoning necessary for rigorous uncertainty quantification and policy comparison. Expert elicitation methods fail to formalize complex interdependencies between variables, leaving implicit assumptions unexamined. Qualitative frameworks, though rich in insight, obscure crucial assumptions and parameter sensitivities that drive different conclusions about optimal policies.\n\n\n\n11.1.3 Argument Mapping and Formal Representations\n\nArgument mapping offers a bridge between informal reasoning in natural language and the formal representations needed for rigorous analysis. By explicitly identifying claims, premises, inferential relationships, and support/attack patterns, argument maps make implicit reasoning structures visible for examination and critique.\nThe progression from natural language arguments to formal Bayesian networks requires an intermediate representation that preserves narrative structure while adding mathematical precision. The ArgDown format serves this purpose by encoding hierarchical relationships between statements, while its extension, BayesDown, adds probabilistic metadata to enable full Bayesian network construction.\n[Effect_Node]: Description of effect. {\"instantiations\": [\"effect_TRUE\", \"effect_FALSE\"]}\n + [Cause_Node]: Description of direct cause. {\"instantiations\": [\"cause_TRUE\", \"cause_FALSE\"]}\n   + [Root_Cause]: Description of indirect cause. {\"instantiations\": [\"root_TRUE\", \"root_FALSE\"]}\n\n\n\n11.1.4 Bayesian Networks as Knowledge Representation\n\n\n\nBayesian networks provide a formal mathematical framework for representing causal relationships and reasoning under uncertainty. These directed acyclic graphs (DAGs) combine qualitative structure—nodes representing variables and edges representing dependencies—with quantitative parameters in the form of conditional probability tables.\n\n\n11.1.4.1 Mathematical Foundations\nBayesian networks provide a formal mathematical framework for representing causal relationships and reasoning under uncertainty through Directed Acyclic Graphs (DAGs) combining qualitative structure with quantitative parameters.\nCore Components:\n\nNodes: Variables with discrete states representing propositions or factors\nEdges: Directed relationships representing conditional dependencies\nAcyclicity: Ensuring coherent probabilistic interpretation without circular dependencies\nConditional Probability Tables: Quantifying P(Node|Parents) for all parent state combinations\n\nProbability Factorization: \\(P(X_1, X_2, ..., X_n) = \\prod_{i=1}^{n} P(X_i | Parents(X_i))\\)\n\n\n\n11.1.4.2 The Rain-Sprinkler-Grass Example\nThis simple example demonstrates all key concepts while remaining intuitive. The network structure consists of Rain as a root cause with P(rain) = 0.2, Sprinkler as an intermediate variable where P(sprinkler|rain) varies by rain state, and Grass_Wet as the effect where P(wet|rain, sprinkler) depends on both causes.\nThe example enables various inference capabilities including marginal probabilities such as P(grass_wet) computed from the joint distribution, conditional queries like P(rain|grass_wet) for diagnostic reasoning, and counterfactual analysis such as P(grass_wet|do(sprinkler=false)) for intervention effects.\n# Basic network representation\nnodes = ['Rain', 'Sprinkler', 'Grass_Wet']\nedges = [('Rain', 'Sprinkler'), ('Rain', 'Grass_Wet'), ('Sprinkler', 'Grass_Wet')]\n\n# Conditional probability specification\nP_wet_given_causes = {\n    (True, True): 0.99,    # Rain=T, Sprinkler=T\n    (True, False): 0.80,   # Rain=T, Sprinkler=F  \n    (False, True): 0.90,   # Rain=F, Sprinkler=T\n    (False, False): 0.01   # Rain=F, Sprinkler=F\n}\n\n\n11.1.4.3 Advantages for AI Risk Modeling\nBayesian networks offer several key advantages for AI risk modeling. They provide explicit uncertainty representation where all beliefs are represented with probability distributions rather than point estimates. The framework naturally supports causal reasoning through native support for intervention analysis and counterfactual reasoning via do-calculus. Evidence integration becomes principled through Bayesian updating mechanisms. The modular structure allows complex arguments to be decomposed into manageable, verifiable components. Finally, the visual communication provided by graphical representation facilitates understanding across different expertise levels.\n\n\n\n11.1.5 The MTAIR Framework: Achievements and Limitations\n\n\nThe Modeling Transformative AI Risks (MTAIR) project demonstrated the value of formal probabilistic modeling for AI safety, but also revealed significant limitations in the manual approach. While MTAIR successfully translated complex arguments into Bayesian networks and enabled sensitivity analysis, the intensive human labor required for model creation limited both scalability and timeliness.\n\nBucknall and Dori-Hacohen (2022) on the original Modeling Transformative AI Risks project demonstrates both the value and limitations of manual formal modeling approaches.\n\n\n11.1.5.1 MTAIR’s Innovations\nMTAIR’s key innovations advanced the field of AI risk modeling significantly. The project introduced structured uncertainty representation through explicit probability distributions over key variables rather than point estimates. It developed systematic methods for expert judgment integration, aggregating diverse expert opinions and beliefs. The sensitivity analysis capabilities enabled identification of critical uncertainties that most significantly drive overall conclusions. Perhaps most importantly, it established direct connections between technical risk models and governance implications, bridging the gap between technical analysis and policy application.\n\n\n11.1.5.2 Fundamental Limitations Motivating AMTAIR\nDespite its innovations, MTAIR faces fundamental limitations that motivate the automated approach. The scalability bottleneck is severe—manual model construction requires weeks of expert effort per argument, making comprehensive coverage impossible. The static nature of manually constructed models provides no mechanisms for updating as new research and evidence emerge. Limited accessibility restricts usage to specialists with formal modeling expertise, excluding many stakeholders. Finally, the single worldview focus creates difficulty in representing multiple conflicting perspectives simultaneously, limiting the framework’s utility for coordination across diverse viewpoints.\nThese limitations create a clear opportunity for automated approaches that can scale formal modeling to match the pace and diversity of AI governance discourse.\n\n\n\n11.1.5.3 Mechanics of World Modeling in Analytica\nThe MTAIR project’s Analytica implementation provides important lessons for automation. The manual process involves several key steps: variable identification through careful reading of source texts, structure elicitation via expert interviews and workshops, probability quantification using various elicitation techniques, and validation through sensitivity analysis and expert review. Each step requires significant time and expertise, with a single model taking weeks to months to develop. Understanding these mechanics helps identify specific opportunities for automation while preserving the rigor of the manual approach.\n\n\n\n11.1.6 Literature Review: Content Level\n\n\n\n\n11.1.6.1 AI Risk Models Evolution\nThe evolution of AI risk models reflects increasing sophistication in both structure and quantification. Early models focused on simple binary outcomes, while recent work incorporates complex causal chains and continuous variables. Key developments include:\n\n\n\nThe progression from qualitative arguments to structured probabilistic models demonstrates the field’s maturation and the increasing recognition that rigorous quantitative analysis is essential for policy evaluation.\n\n\n11.1.6.2 Governance Proposals Taxonomy\nAI governance proposals can be categorized along several dimensions:\n\nTechnical Standards: Safety requirements, testing protocols, capability thresholds\nRegulatory Frameworks: Licensing regimes, liability structures, oversight mechanisms\nInternational Coordination: Treaties, soft law arrangements, technical cooperation\nResearch Priorities: Funding allocation, talent development, knowledge sharing\n\n\n\n\n\n\n\n11.1.7 Literature Review: Technical/Theoretical Background\n\n\n11.1.7.1 Bayesian Network Theory\nThe theoretical foundations of Bayesian networks rest on probability theory and graph theory. Key concepts include conditional independence encoded through d-separation, the Markov condition relating graph structure to probabilistic relationships, and inference algorithms ranging from exact methods like variable elimination to approximate approaches like Monte Carlo sampling.\n\n\n\n11.1.7.2 Software Tools Landscape\nThe implementation of AMTAIR builds on established software libraries:\n\npgmpy: Python library for probabilistic graphical models, providing network construction and inference\nNetworkX: Graph analysis and manipulation capabilities\nPyVis: Interactive network visualization\nPandas/NumPy: Data manipulation and numerical computation\n\n\n\n\n11.1.7.3 Formalization Approaches\nFormalizing natural language arguments into mathematical models involves several theoretical challenges. The translation must preserve semantic content while adding mathematical precision. Key approaches include structured extraction templates, semantic parsing techniques, and hybrid human-AI workflows.\n\n\n\n11.1.7.4 Correlation Accounting Methods\nStandard Bayesian networks assume conditional independence given parents, but real-world AI risk factors often exhibit complex correlations. Methods for handling correlations include:\n\nCopula Methods: Modeling dependence structures separately from marginal distributions\nHierarchical Models: Capturing correlations through shared latent variables\nExplicit Correlation Nodes: Adding nodes to represent correlation mechanisms\nSensitivity Bounds: Analyzing impact of independence assumptions",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#sec-methodology",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#sec-methodology",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "11.2 Methodology",
    "text": "11.2 Methodology\n\n11.2.1 Research Design Overview\n\n\nThis research combines theoretical development with practical implementation, following an iterative approach that moves between conceptual refinement and technical validation. The methodology encompasses formal framework development, computational implementation, extraction quality assessment, and application to real-world AI governance questions.\nThe research process follows four integrated phases:\n\nFramework Development: Creating theoretical foundations for automated worldview extraction\nTechnical Implementation: Building computational tools as working prototype\nEmpirical Validation: Assessing quality against expert benchmarks\nPolicy Application: Demonstrating practical utility for governance questions\n\n\n\n11.2.2 Formalizing World Models from AI Safety Literature\n\n\nThe core methodological challenge involves transforming natural language arguments in AI safety literature into formal causal models with explicit probability judgments. This extraction process identifies key variables, causal relationships, and both explicit and implicit probability estimates through a systematic pipeline.\nThe extraction approach combines several elements: identification of key variables and entities in text, recognition of causal claims and relationships, detection of explicit and implicit probability judgments, transformation into structured intermediate representations, and conversion to formal Bayesian networks.\nLarge language models facilitate this process through specialized techniques including two-stage prompting that separates structure from probability extraction, specialized templates for different types of source documents, techniques for identifying implicit assumptions and relationships, and mechanisms for handling ambiguity and uncertainty.\n\n\n11.2.3 From Natural Language to Computational Models\n\n\n11.2.3.1 The Two-Stage Extraction Process\nAMTAIR employs a novel two-stage process that separates structural argument extraction from probability quantification, enabling modular improvement and human oversight at critical decision points.\nStage 1: Structural Extraction (ArgDown Generation)\nThe first stage focuses on identifying the argument structure: extracting key propositions and entities from natural language text, mapping support/attack relationships and conditional dependencies, constructing properly nested argument representations that preserve logical flow, and creating ArgDown format suitable for both human review and machine processing.\ndef extract_argument_structure(text):\n    \"\"\"Extract hierarchical argument structure from natural language\"\"\"\n    # LLM-based extraction with specialized prompts\n    prompt = ArgumentExtractionPrompt(\n        text=text,\n        output_format=\"ArgDown\",\n        focus_areas=[\"causal_claims\", \"probability_statements\", \"conditional_reasoning\"]\n    )\n    \n    structure = llm.complete(prompt)\n    return validate_argdown_syntax(structure)\nStage 2: Probability Integration (BayesDown Enhancement)\nThe second stage adds quantitative information: identifying and parsing numerical probability statements in source text, creating systematic elicitation questions for implicit probability judgments, incorporating domain expertise for ambiguous or missing quantifications, and ensuring probability assignments satisfy basic coherence requirements.\ndef integrate_probabilities(argdown_structure, probability_sources):\n    \"\"\"Convert ArgDown to BayesDown with probabilistic information\"\"\"\n    questions = generate_probability_questions(argdown_structure)\n    probabilities = extract_probabilities(probability_sources, questions)\n    \n    bayesdown = enhance_with_probabilities(argdown_structure, probabilities)\n    return validate_probability_coherence(bayesdown)\n\n\n\n\n\n11.2.4 Directed Acyclic Graphs: Structure and Semantics\n\n\nDirected Acyclic Graphs (DAGs) form the mathematical foundation of Bayesian networks, encoding both the qualitative structure of causal relationships and the quantitative parameters that define conditional dependencies. In AI risk modeling, these structures represent causal pathways to potential outcomes of interest.\nKey mathematical properties essential for AI risk modeling include the acyclicity requirement ensuring coherent probabilistic interpretation without logical contradictions, d-separation defining conditional independence relationships between variables based on graph structure, the Markov condition where each variable is conditionally independent of non-descendants given parents, and path analysis revealing causal pathways and information flow through the network structure.\nThe causal interpretation in AI governance contexts follows Pearl’s framework, where edges represent direct causal influence between factors, intervention analysis through do-calculus enables rigorous evaluation of policy effects, counterfactual reasoning supports “what if” scenarios essential for governance planning, and evidence integration through Bayesian updating incorporates new information and expert judgment.\n\n\n\n11.2.5 Quantification of Probabilistic Judgments\n\n\nTransforming qualitative uncertainty expressions into quantitative probabilities requires systematic interpretation frameworks that account for individual and cultural variation.\nStandard linguistic mappings (with significant individual variation) include:\n\n“Very likely” → 0.8-0.9\n“Probable” → 0.6-0.8\n“Uncertain” → 0.4-0.6\n“Unlikely” → 0.2-0.4\n“Highly improbable” → 0.05-0.15\n\nExpert elicitation methodologies provide various approaches: direct probability assessment asking “What is P(outcome)?” with calibration training, comparative assessment asking “Is A more likely than B?” for relative judgment validation, frequency format asking “In 100 similar cases, how many would result in outcome?” for clearer mental models, and betting odds asking “What odds would you accept for this bet?” for revealed preference elicitation.\nCalibration and validation face several challenges including individual variation in linguistic interpretation and probability anchoring, domain-specific anchoring and reference class selection, cultural and contextual influences on uncertainty expression and tolerance, and limited empirical basis for calibration in unprecedented scenarios like transformative AI.\n\n\n11.2.6 Inference Techniques for Complex Networks\n\n\nOnce Bayesian networks are constructed, probabilistic inference enables reasoning about uncertainties, counterfactuals, and policy interventions. For the complex networks representing AI risks, computational approaches must balance accuracy with tractability.\nInference methods implemented include exact methods for smaller networks (variable elimination, junction trees), approximate methods for larger networks (Monte Carlo sampling, variational inference), specialized approaches for rare event analysis, and intervention modeling for policy evaluation using do-calculus.\nImplementation considerations involve computational complexity management through network decomposition, sampling efficiency optimization via importance sampling, approximation quality monitoring with convergence diagnostics, and uncertainty representation in outputs including confidence intervals.\n\n\n\n\n11.2.7 Integration with Prediction Markets and Forecasting Platforms\n\n\nTo maintain relevance in a rapidly evolving field, formal models must integrate with live data sources such as prediction markets and forecasting platforms. This integration enables continuous updating of model parameters as new information emerges.\nLive data sources for dynamic model updating include:\n\nMetaculus: Long-term AI predictions and technological forecasting\nGood Judgment Open: Geopolitical events and policy outcomes\nManifold Markets: Diverse question types with rapid market response\nInternal Expert Forecasting: Organization-specific predictions and assessments\n\nThe data processing and integration pipeline connects these sources:\ndef integrate_forecast_data(model_variables, forecast_platforms):\n    \"\"\"Connect Bayesian network variables to live forecasting data\"\"\"\n    mappings = create_semantic_mappings(model_variables, forecast_platforms)\n    \n    for variable, forecasts in mappings.items():\n        weighted_forecast = aggregate_forecasts(\n            forecasts, \n            weights=calculate_track_record_weights(forecasts)\n        )\n        model.update_prior(variable, weighted_forecast)\n    \n    return model.recompute_posteriors()\nTechnical implementation challenges include question mapping to connect forecast questions to specific model variables with semantic accuracy, temporal alignment handling different forecast horizons and update frequencies, conflict resolution through principled aggregation when sources provide contradictory information, and track record weighting incorporating forecaster calibration and expertise into aggregation.\n\nWith these theoretical foundations and methodological approaches established, we can now present the AMTAIR system implementation. The next chapter demonstrates how these concepts translate into a working prototype that automates the extraction and formalization of world models from AI safety literature.\n\ntitle: “AMTAIR”",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#numbering-start-at-3-start-at-section-1-level-1-chapter-level",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#numbering-start-at-3-start-at-section-1-level-1-chapter-level",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "12.1 numbering: start-at: 3 # Start at Section 1 level: 1 # Chapter level",
    "text": "12.1 numbering: start-at: 3 # Start at Section 1 level: 1 # Chapter level",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  },
  {
    "objectID": "chapters/Outlines/Outline_11.7_0.5.html#sec-software-implementation",
    "href": "chapters/Outlines/Outline_11.7_0.5.html#sec-software-implementation",
    "title": "1  Comprehensive Jupyter Notebook Enhancement Plan",
    "section": "13.1 Software Implementation",
    "text": "13.1 Software Implementation\n\n13.1.1 System Architecture and Data Flow\n\n\n\nThe AMTAIR system implements an end-to-end pipeline from unstructured text to interactive Bayesian network visualization. Its modular architecture comprises five main components that progressively transform information from natural language into formal models suitable for policy analysis.\nThe five-stage pipeline architecture demonstrates how each component builds on the previous, with validation checkpoints preventing error propagation:\n\nText Ingestion and Preprocessing: Handles format normalization (PDF, HTML, Markdown), metadata extraction, citation tracking, and relevance filtering\nBayesDown Extraction: Two-stage argument structure identification and probabilistic information integration with quality validation\nStructured Data Transformation: Parsing into standardized relational formats with network topology validation\nBayesian Network Construction: Mathematical model instantiation using NetworkX and pgmpy libraries\nInteractive Visualization: Dynamic rendering with PyVis and probability-based visual encoding\n\nclass AMTAIRPipeline:\n    def __init__(self):\n        self.ingestion = DocumentIngestion()\n        self.extraction = BayesDownExtractor() \n        self.transformation = DataTransformer()\n        self.network_builder = BayesianNetworkBuilder()\n        self.visualizer = InteractiveVisualizer()\n    \n    def process(self, document):\n        \"\"\"End-to-end processing from document to interactive model\"\"\"\n        structured_data = self.ingestion.preprocess(document)\n        bayesdown = self.extraction.extract(structured_data)\n        dataframe = self.transformation.convert(bayesdown)\n        network = self.network_builder.construct(dataframe)\n        return self.visualizer.render(network)\nThe design principles emphasize scalability through modular architecture where each component can be improved independently, standard interfaces using JSON and CSV formats for interoperability, validation checkpoints with quality gates at each stage, and an extensible framework supporting additional analysis capabilities without core changes.\n\n\n13.1.2 Rain-Sprinkler-Grass Example Implementation\n\n\n\nThe Rain-Sprinkler-Grass example serves as a canonical test case demonstrating each step in the AMTAIR pipeline. This simple causal scenario—where both rain and sprinkler use can cause wet grass, and rain influences sprinkler use—provides an intuitive introduction to Bayesian network concepts while exercising all system components.\nStage 1: BayesDown Input Representation\nThe structured representation captures both hierarchical relationships and probability information:\n[Grass_Wet]: Concentrated moisture on, between and around the blades of grass. \n{\"instantiations\": [\"grass_wet_TRUE\", \"grass_wet_FALSE\"], \n \"priors\": {\"p(grass_wet_TRUE)\": \"0.322\", \"p(grass_wet_FALSE)\": \"0.678\"},\n \"posteriors\": {\n   \"p(grass_wet_TRUE|sprinkler_TRUE,rain_TRUE)\": \"0.99\",\n   \"p(grass_wet_TRUE|sprinkler_TRUE,rain_FALSE)\": \"0.9\",\n   \"p(grass_wet_TRUE|sprinkler_FALSE,rain_TRUE)\": \"0.8\", \n   \"p(grass_wet_TRUE|sprinkler_FALSE,rain_FALSE)\": \"0.0\"\n }}\n + [Rain]: Tears of angels crying high up in the skies hitting the ground.\n   {\"instantiations\": [\"rain_TRUE\", \"rain_FALSE\"],\n    \"priors\": {\"p(rain_TRUE)\": \"0.2\", \"p(rain_FALSE)\": \"0.8\"}}\n + [Sprinkler]: Activation of a centrifugal force based CO2 droplet distribution system.\n   {\"instantiations\": [\"sprinkler_TRUE\", \"sprinkler_FALSE\"], \n    \"priors\": {\"p(sprinkler_TRUE)\": \"0.44838\", \"p(sprinkler_FALSE)\": \"0.55162\"},\n    \"posteriors\": {\n      \"p(sprinkler_TRUE|rain_TRUE)\": \"0.01\",\n      \"p(sprinkler_TRUE|rain_FALSE)\": \"0.4\"\n    }}\n   + [Rain]\nStage 2: Automated Parsing and Data Extraction\nThe parsing algorithm (parse_markdown_hierarchy_fixed) processes the BayesDown format to extract structured information. The algorithm removes comments and cleans text, extracts titles, descriptions, and indentation levels, establishes parent-child relationships based on indentation following BayesDown semantics, converts to DataFrame format with all necessary columns, and adds derived columns for network analysis such as node types and Markov blankets.\nStage 3: Bayesian Network Construction and Validation\nNetwork construction transforms the DataFrame into a formal Bayesian network by creating directed graph structure using NetworkX, adding nodes with complete probabilistic information, establishing edges based on extracted parent-child relationships, validating DAG properties to ensure acyclicity, and preparing for inference with conditional probability tables.\nStage 4: Interactive Visualization with Probability Encoding\nThe visualization strategy employs multiple visual channels to convey information: node colors using a green (high probability) to red (low probability) gradient based on primary state likelihood, border colors with blue for root nodes, purple for intermediate nodes, and magenta for leaf nodes, clear edge directions showing causal influence, and interactive elements including click actions for detailed probability tables and drag functionality for layout adjustment.\nThe automated pipeline successfully reproduces the expected Rain-Sprinkler-Grass network structure and probabilistic relationships, with computed marginal probabilities matching manual calculations within 0.001 precision, validating the extraction and transformation processes.\n\n\n13.1.3 Carlsmith Implementation\n\n\n\nApplied to Carlsmith’s model of power-seeking AI existential risk, the AMTAIR pipeline demonstrates capability to handle complex multi-level causal structures with realistic uncertainty relationships.\nModel Complexity and Scope:\nThe Carlsmith model represents a significant increase in complexity:\n\n23 nodes representing AI development factors and risk pathways\n45 conditional dependencies capturing complex causal relationships\n6 primary risk pathways to existential catastrophe outcomes\nMultiple temporal stages from capability development through deployment to outcome\n\nCore Risk Pathway Structure:\nExistential_Catastrophe ← Human_Disempowerment ← Scale_Of_Power_Seeking\n                                                ← Misaligned_Power_Seeking\n                                                ← [APS_Systems, Difficulty_Of_Alignment, Deployment_Decisions]\nAdvanced BayesDown Representation Example:\n{\n  \"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"],\n  \"priors\": {\"p(misaligned_power_seeking_TRUE)\": \"0.338\"},\n  \"posteriors\": {\n    \"p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)\": \"0.90\",\n    \"p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)\": \"0.25\",\n    \"p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)\": \"0.0\"\n  }\n}\nSensitivity Analysis Results:\nThe implementation enables identification of critical variables with highest impact on final outcome:\n\nAPS_Systems development (probability range affects outcome by 40%)\nDifficulty_Of_Alignment assessment (30% outcome variation)\nDeployment_Decisions under uncertainty (25% outcome variation)\n\nIntervention Analysis demonstrates policy evaluation capabilities:\n\nPreventing APS deployment reduces P(catastrophe) from 5% to 0.5%\nSolving alignment problems reduces risk by 60%\nInternational coordination on deployment reduces risk by 35%\n\nThe system successfully extracted Carlsmith’s six-premise structure along with implicit sub-arguments and conditional dependencies, producing a formal model that reproduces his ~5% P(doom) estimate when all premises are set to his original probability assessments. Implementation performance metrics show extraction time of ~3 minutes for complete document processing, network construction in &lt;10 seconds for the 23-node network, millisecond response time for standard probabilistic queries, and 94% agreement with manual expert annotation of argument structure.\n\n\n13.1.4 Inference & Extensions\n\n\n\nBeyond basic representation, AMTAIR implements advanced analytical capabilities enabling reasoning about uncertainties, counterfactuals, and policy interventions.\n\n13.1.4.1 Probabilistic Inference Engine\nThe system supports multiple query types essential for policy analysis:\n# Marginal probability queries for outcomes of interest\nP_catastrophe = network.query\n\n\n\n\nBucknall, Benjamin S., and Shiri Dori-Hacohen. 2022. “Current and Near-Term AI as a Potential Existential Risk Factor.” In Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society, 119–29. Oxford United Kingdom: ACM. https://doi.org/10.1145/3514094.3534146.\n\n\nCarlsmith, Joseph. 2021. “Is Power-Seeking AI an Existential Risk?” 2021. https://doi.org/10.48550/arXiv.2206.13353.\n\n\nGrowiec, Jakub. 2024. “Existential Risk from Transformative AI: An Economic Perspective.” Technological and Economic Development of Economy, 1–27.\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Computer Journal 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nSoares, Nate, and Benja Fallenstein. 2014. “Aligning Superintelligence with Human Interests: A Technical Research Agenda.”",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Comprehensive Jupyter Notebook Enhancement Plan</span>"
    ]
  }
]