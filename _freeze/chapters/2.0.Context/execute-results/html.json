{
  "hash": "88947f4795b991c14e3dcc0a1bfb74e2",
  "result": {
    "engine": "jupyter",
    "markdown": "---\n# title: \"Context\"\n# Control if this file starts numbering\nnumbering:\n  start-at: 2      # Start at 1 in Section 1\n  level: 1         # Chapter level\n---\n\n# Context & Background {#sec-context}\n\n```         \n### 20% of Grade: ~ 29% of text ~ 8700 words ~ 20 pages\n\n- demonstrates understanding of all relevant core concepts\n\n- explains why the question/thesis/problem is relevant in student’s own words (supported by quotations)\n\n- situates it within the debate/course material\n\n- reconstructs selected arguments and identifies relevant assumptions\n\n- describes additional relevant material that has been consulted and integrates it with the course material as well as the research question/thesis/problem\n```\n\n```{=html}\n<!-- 1. successively (chunk my chunk) introduce concepts/ideas ---\nand 2. ground each with existing literature -->\n```\n\n\n\n<!-- [ ] Expand this section to ~29% of total text (approximately 8700 words) -->\n\n```{=html}\n<!-- ---\ntitle: \"Background\"\n# Control if this file starts numbering\nnumbering:\n  start-at: 2      # Start at Section 1\n  level: 2         # Chapter level\n--- -->\n```\n\n## Quarto Syntax {#sec-syntax}\n\n::: {#fig-extraction-pipeline .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nprint(\"AMTAIR is working!\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAMTAIR is working!\n```\n:::\n:::\n\n\n## For Callouts\n\nQuarto's native callouts work without additional packages:\n\n\n:::note\nRemember to connect this back to the research question\n:::\n\n\n::: {.callout-note}\n## Optional Title\nContent here\n:::\n::: {.callout-note}\n## Important Note2\nThis renders perfectly in both HTML and PDF.2\n:::\n\nAlso for markdown:\n\n```markdown\n::: {.render_as_markdown_example}\n## Markdown Heading\nThis renders perfectly in both HTML and PDF but as markdown \"plain text\"\n:::\n```\n\n## Section Cross-References\n\nRefer to sections like: @sec-adaptive-governance and @sec-crossref\n<!-- Using @-sec-REFERENCE_HEADING requires that the .qmd file contains a yml section which details the \"numbering\" -->\n\n```markdown\nCaveat: refering to sections with @sec-HEADINGS works only for sections with:\n## Heading \nIt does not work for sections with \".unnumbered and/or .unlisted\":\n## Heading { .unnumbered .unlisted}\n```\n\n\n## Reference or Embed Code from .ipynb files\n\n#### Code chunks from .ipynb notebooks can be embedded in the .qmd text with:\n\n```markdown\n{{< embed /AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb#my_code_cell_test >}}\n```\n#### which produces the output of executing the code cell:\n\n{{< embed /AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb#my_code_cell_test >}}\n\n#### including 'echo=true' renders the code of the cell:\n\n```markdown\n{{< embed /AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb#my_code_cell_test echo=true >}}\n```\n\n{{< embed /AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb#my_code_cell_test echo=true >}}\n\nLink:\n\n\nFull Notebooks are embedded in the Appendix through the _quarto.yml file with:\n\n\n\n\n\n## Figures { .unnumbered .unlisted}\n\n\n[![AMTAIR Automation Pipeline from @bucknall2022](/images/pipeline.png){\n  #fig-automation_pipeline\n  fig-scap=\"Five-step AMTAIR automation pipeline from PDFs to Bayesian networks\" \n  fig-alt=\"FLOWCHART: Five-step automation pipeline workflow for AMTAIR project.\n          DATA: The pipeline transforms PDFs through ArgDown, BayesDown, CSV, and HTML into Bayesian network visualizations.\n          PURPOSE: Illustrates the core technical process that enables automated extraction of probabilistic models from AI safety literature.\n          DETAILS: Five numbered green steps show: (1) LLM-based extraction from PDFs to ArgDown, (2) ArgDown to BayesDown completion with probabilities, (3) Extracting world-models as CSV data, (4) Software tools for data inference, and (5) Visualization of the resulting Bayesian network.\n          Each step includes example outputs, with the final visualization showing a Rain-Sprinkler-Grass Wet Bayesian network with probability tables.\n          SOURCE: Created by the author to explain the AMTAIR methodology\n          \"\n  fig-align=\"center\" \n  width=\"100%\"\n  }](https://github.com/VJMeyer/submission)\n\n\nTesting crossreferencing grapics @fig-automation_pipeline.\n\n![Caption/Title 2](/images/cover.png){#fig-testgraphic2 fig-scap=\"Short 2 caption\" fig-alt=\"2nd Alt Text / Description.\" fig-align=\"left\" width=\"30%\"}\n\nTesting crossreferencing grapics @fig-testgraphic2.\n\n\n## Citations { .unnumbered .unlisted}\n\n\n\n@soares2014 <!-- preferred because it works with both html, latex and pdf -->\n\n[@soares2014] and [@knuth1984]\n\n\nBlah Blah [see @knuth1984, pp. 33-35; also @growiec2024, chap. 1]\n\nBlah Blah [@knuth1984, pp. 33-35, 38-39 and passim]\n\nBlah Blah [@growiec2024; @knuth1984].\n\nGrowiec says blah [-@growiec2024]\n\n### Narrative citations (author as subject)\n@soares2014 argues that AI alignment requires...\n\n### Parenthetical citations (supporting reference)\nRecent work supports this view [@soares2014; @knuth1984].\n\n### Author-only citation (when discussing the person)\nAs [-@soares2014] demonstrates in their analysis...\n\n### Year-only citation (when author already mentioned)\nSoares [-@soares2014] later revised this position.\n\n### Page-specific references\nThe key insight appears in [@soares2014, pp. 45-67].\n\n### Multiple works, different pages\nThis view is supported [@soares2014, p. 23; @knuth1984, pp. 156-159].\n\n\n\n## Headings & Potential Headings \n\n\n<!-- Comments for comments -->\n\n<!-- [ ] ToDos for things to do / tasks / reminders (allows \"jump to with Taks Tree extension\") -->\n\n\n\n`verbatim code formatting for notes and ideas to be included (here)`\n\n```\nAlso code blocks for more extensive notes and ideas to be included and checklists\n- test 1. \n- test 2. \n- test 3.\n2. second\n3. third\n\n```\n\n> Blockquote formatting for \"Suggested Citations (e.g. carlsmith 2024 on ...)\" and/or claims which require a citation (e.g. claim x should be backed-up by a ciation from the literature)\n\n\n\n\nHere is an inline note.^[Inlines notes are easier to write, since you don't have to pick an identifier and move down to type the note.]\n\n\nHere is a footnote reference,[^1] \n\n[^1]: Here is the footnote.\n\n::: {.hidden}\n$$\n \\def\\RR{{\\bf R}}\n \\def\\bold#1{{\\bf #1}}\n$$\n:::\n\n\n\n\n\n\n\n\n\n\n```{=latex}\n\\renewcommand*{\\labelitemi}{\\textgreater}\n```\n\n\nHere's some raw inline HTML: `<a>html</a>`{=html}\n\n\n```markdown\npage 1\n\n{{< pagebreak >}}\n\npage 2\n```\n\npage 1\n\n{{< pagebreak >}}\n\npage 2[^longnote]\n\n\n\n[^longnote]: Here's one with multiple blocks.\n\n    Subsequent paragraphs are indented to show that they\nbelong to the previous footnote.\n\n        { some.code }\n\n    The whole paragraph can be indented, or just the first\n    line.  In this way, multi-paragraph footnotes work like\n    multi-paragraph list items.\n\nThis paragraph won't be part of the note, because it\nisn't indented.\n\n\n```{mermaid}\nflowchart LR\n  A[Hard edge] --> B(Round edge)\n  B --> C{Decision}\n  C --> D[Result one]\n  C --> E[Result two]\n```\n\nTesting crossreferencing grapics @fig-automation_pipeline.\nSee [Chapter @sec-syntax] for more details on visualizing model diagnostics.\n\n## Formatting\n\n[This text is highlighted]{.mark}\n\n[This text is underlined]{.underline}\n\n[This text is smallcaps]{.smallcaps}\n\n\n::: {.landscape}\n\nThis will appear in landscape.\n\n:::\n\n\n\n\n\n\n## Theoretical Foundations {#sec-theoretical-foundations}\n\n<!-- demonstrates understanding of all relevant core concepts -->\n\n<!-- explains why the question/thesis/problem is relevant in student's own words (supported by quotations) -->\n\n<!-- situates it within the debate/course material -->\n\n<!-- reconstructs selected arguments and identifies relevant assumptions -->\n\n### AI Existential Risk: The Carlsmith Model {#sec-carlsmith-model}\n\n<!-- [ ] Examine Joe Carlsmith's probabilistic model of power-seeking AI causing existential catastrophe -->\n\n<!-- [ ] Unpack the six key premises and explain why this structured approach serves as an ideal candidate for formal modeling -->\n\n> Carlsmith's \"Is power-seeking AI an existential risk?\" (2021) represents one of the most structured approaches to assessing the probability of existential catastrophe from advanced AI. The analysis decomposes the overall risk into six key premises, each with an explicit probability estimate.\n\n> @carlsmith2021 provides the canonical structured approach to AI existential risk assessment\n\n**Six-Premise Decomposition:**\n\n`Carlsmith decomposes existential risk into a probabilistic chain with explicit estimates:`\n\n1.  **Premise 1**: Transformative AI development this century (P ≈ 0.80)\n2.  **Premise 2**: AI systems pursuing objectives in the world (P ≈ 0.95)\n3.  **Premise 3**: Systems with power-seeking instrumental incentives (P ≈ 0.40)\n4.  **Premise 4**: Sufficient capability for existential threat (P ≈ 0.65)\n5.  **Premise 5**: Misaligned systems despite safety efforts (P ≈ 0.50)\n6.  **Premise 6**: Catastrophic outcomes from misaligned power-seeking (P ≈ 0.65)\n\n**Composite Risk Calculation**: P(doom) ≈ 0.05 (5%) \\~5% probability of existential catastrophe\n\n> This structured approach exemplifies the type of reasoning that AMTAIR aims to formalize and automate, providing both transparency in assumptions and modularity for critique and refinement.\n\n`Carlsmith's model exemplifies the type of structured reasoning that AMTAIR aims to formalize and automate`\n\n#### Why Carlsmith as Ideal Formalization Target {#sec-carlsmith-ideal}\n\n```         \n- Explicitly probabilistic reasoning with quantified estimates\n- Clear conditional dependencies between premises  \n- Transparent decomposition of complex causal pathways\n- Well-documented argumentation available for extraction validation\n- Policy-relevant implications requiring formal evaluation\n```\n\n**Formalization Potential:**\n\n`Carlsmith's model represents \"low-hanging fruit\" for automated formalization because it already exhibits explicit probabilistic reasoning with clear conditional dependencies. Success with this structured argument validates the approach for less explicit arguments throughout AI safety literature.`\n\n### The Epistemic Challenge of Policy Evaluation {#sec-epistemic-challenge}\n\n<!-- [ ] Explore why evaluating AI governance policies is particularly difficult: complex causal chains, deep uncertainty, divergent worldviews, and limited empirical data -->\n\n<!-- [ ] Establish why traditional policy analysis methods are insufficient -->\n\n> AI governance policy evaluation faces unique epistemic challenges that render traditional policy analysis methods insufficient. The domain combines complex causal chains with limited empirical grounding, deep uncertainty about future capabilities, divergent stakeholder worldviews, and few opportunities for experimental testing before deployment.\n\n\\`Traditional methods fall short in several ways:\n\n-   Cost-benefit analysis struggles with existential outcomes and deep uncertainty\n-   Scenario planning often lacks probabilistic reasoning necessary for rigorous evaluation\n-   Expert elicitation alone fails to formalize interdependencies between variables\n-   Qualitative approaches obscure crucial assumptions that drive conclusions\\`\n\n**Unprecedented Epistemic Environment:**\n\n> AI governance policy evaluation faces challenges that render traditional policy analysis methods insufficient: complex causal chains, deep uncertainty about unprecedented capabilities, divergent stakeholder worldviews, and limited opportunities for empirical validation.\n\n```         \nSpecific challenges include:\n\n• **Deep Uncertainty**: Many decisions involve unprecedented scenarios without historical frequency data\n• **Complex Causality**: Policy effects propagate through multi-level dependencies (technical → institutional → strategic)\n• **Multidisciplinary Integration**: Combining technical facts, ethical principles, and strategic considerations\n• **Value-Laden Assessment**: Risk evaluation inherently involves normative judgments about acceptable outcomes\n```\n\n#### Unique Difficulties in AI Governance {#sec-unique-difficulties}\n\n**Complex Causal Chains**: Multi-level dependencies between technical capabilities, institutional responses, and strategic outcomes\n\n**Deep Uncertainty**: Unprecedented AI capabilities make historical analogies insufficient\n\n> @lempert2003 on robust decision-making under deep uncertainty\n\n**Divergent Worldviews**: Fundamental disagreements about:\n\n-   Timeline expectations for transformative AI\n-   Difficulty of alignment problems\n-   Effectiveness of governance interventions\n-   International coordination possibilities\n\n#### Limitations of Traditional Policy Analysis {#sec-traditional-limitations}\n\n<!-- Critical assessment of existing approaches -->\n\n-   **Cost-Benefit Analysis**: Struggles with existential outcomes and infinite expected values\n-   **Scenario Planning**: Lacks probabilistic reasoning and uncertainty quantification\n-   **Expert Elicitation**: Fails to formalize complex interdependencies between variables\n-   **Qualitative Frameworks**: Obscure crucial assumptions and parameter sensitivities\n\n**Limitations of Traditional Approaches:**\n\n-   **Cost-Benefit Analysis**: Struggles with existential outcomes and infinite expected values\n-   **Scenario Planning**: Often lacks probabilistic reasoning necessary for rigorous uncertainty quantification\n-   **Expert Elicitation**: Fails to formalize complex interdependencies between variables and assumptions\n-   **Qualitative Frameworks**: Obscure crucial assumptions and parameter sensitivities driving conclusions\n\n> @lempert2003 on robust decision-making under deep uncertainty provides methodological foundations, but application to AI governance requires novel integration of argument mapping with probabilistic modeling.\n\n### Argument Mapping and Formal Representations {#sec-argument-mapping}\n\n<!-- [ ] Bridge informal reasoning to formal models by showing how argument maps capture causal relationships and conditional dependencies that can be translated into Bayesian networks -->\n\n> Argument mapping offers a bridge between informal reasoning in natural language and the formal representations needed for rigorous analysis. By explicitly identifying claims, premises, inferential relationships, and support/attack patterns, argument maps make implicit reasoning structures visible for examination and critique.\n\n`The progression from natural language arguments to formal Bayesian networks requires an intermediate representation that preserves narrative structure while adding mathematical precision. The ArgDown format serves this purpose by encoding hierarchical relationships between statements, while its extension, BayesDown, adds probabilistic metadata to enable full Bayesian network construction.`\n\n```         \n[Effect_Node]: Description of effect. {\"instantiations\": [\"effect_TRUE\", \"effect_FALSE\"]}\n + [Cause_Node]: Description of direct cause. {\"instantiations\": [\"cause_TRUE\", \"cause_FALSE\"]}\n   + [Root_Cause]: Description of indirect cause. {\"instantiations\": [\"root_TRUE\", \"root_FALSE\"]}\n```\n\n### Bayesian Networks as Knowledge Representation {#sec-bayesian-networks}\n\n<!-- [ ] Introduce Bayesian networks as formal tools for representing uncertainty, causal relationships, and conditional dependencies -->\n\n<!-- [ ] Explain key concepts: nodes, edges, conditional probability tables, and inference -->\n\n> Bayesian networks provide a formal mathematical framework for representing causal relationships and reasoning under uncertainty. These directed acyclic graphs (DAGs) combine qualitative structure—nodes representing variables and edges representing dependencies—with quantitative parameters in the form of conditional probability tables.\n\n\\`Key properties that make Bayesian networks particularly suited to AI risk modeling include:\n\n-   Natural representation of causal relationships between variables\n-   Explicit handling of uncertainty through probability distributions\n-   Support for evidence updating through Bayesian inference\n-   Capability for interventional reasoning through do-calculus\n-   Balance between mathematical rigor and intuitive visual representation\\`\n\n[![Example Bayesian Network](/images/pipeline.png){#fig-bayesian-network fig-alt=\"A directed acyclic graph showing a simple Bayesian network with nodes and edges\" fig-align=\"center\" width=\"70%\"}](https://claude.ai/chat/ab8988f3-18b7-45a5-8a50-b25aa4b34cbf)\n\n#### Mathematical Foundations {#sec-mathematical-foundations}\n\n`Bayesian networks provide a formal mathematical framework for representing causal relationships and reasoning under uncertainty through Directed Acyclic Graphs (DAGs) combining qualitative structure with quantitative parameters.`\n\n**Directed Acyclic Graphs (DAGs)**:\n\n**Core Components:**\n\n-   **Nodes**: Variables with discrete states representing propositions or factors\n-   **Edges**: Directed relationships representing conditional dependencies\n-   **Acyclicity**: Ensuring coherent probabilistic interpretation without circular dependencies\n\nBNs:<!-- [ ] Explain BNs vs DAGs -->\n\n-   **Conditional Probability Tables**: Quantifying P(Node\\|Parents) for all parent state combinations\n\n**Probability Factorization**: $P(X_1, X_2, ..., X_n) = \\prod_{i=1}^{n} P(X_i | Parents(X_i))$\n\n#### The Rain-Sprinkler-Grass Example {#sec-rain-sprinkler-example}\n\n<!-- Introduce canonical example used throughout thesis -->\n\n**The Rain-Sprinkler-Grass Canonical Example:**\n\n`This simple example demonstrates all key concepts while remaining intuitive`\n\n**Network Structure**:\n\n-   **Rain** (root cause): P(rain) = 0.2\n-   **Sprinkler** (intermediate): P(sprinkler\\|rain) varies by rain state\n-   **Grass_Wet** (effect): P(wet\\|rain, sprinkler) depends on both causes\n\n**Inference Capabilities**:\n\n-   Marginal probabilities: P(grass_wet) = ?\n\n-   Conditional queries: P(rain\\|grass_wet) = ?\n\n-   Counterfactual analysis: P(grass_wet\\|do(sprinkler=false)) = ?\n\n-   Marginal probabilities: P(grass_wet) computed from joint distribution\n\n-   Conditional queries: P(rain\\|grass_wet) for diagnostic reasoning\n\n-   Counterfactual analysis: P(grass_wet\\|do(sprinkler=false)) for intervention effects\n\n```         \npython\n# Basic network representation\nnodes = ['Rain', 'Sprinkler', 'Grass_Wet']\nedges = [('Rain', 'Sprinkler'), ('Rain', 'Grass_Wet'), ('Sprinkler', 'Grass_Wet')]\n\n# Conditional probability specification\nP_wet_given_causes = {\n    (True, True): 0.99,    # Rain=T, Sprinkler=T\n    (True, False): 0.80,   # Rain=T, Sprinkler=F  \n    (False, True): 0.90,   # Rain=F, Sprinkler=T\n    (False, False): 0.01   # Rain=F, Sprinkler=F\n}\n```\n\n#### Advantages for AI Risk Modeling {#sec-modeling-advantages}\n\n-   **Explicit Uncertainty**: All beliefs represented with probability distributions rather than point estimates\n-   **Causal Reasoning**: Native support for intervention analysis and counterfactual reasoning through do-calculus\n-   **Evidence Integration**: Bayesian updating enables principled incorporation of new information\n-   **Modular Structure**: Complex arguments decomposed into manageable, verifiable components\n-   **Visual Communication**: Graphical representation facilitates understanding across expertise levels\n\n<!-- ### Argument Mapping and Formal Representations {#sec-argument-mapping} -->\n\n#### From Natural Language to Formal Models {#sec-natural-to-formal}\n\n**The Representation Challenge**: How to preserve narrative richness while enabling mathematical analysis\n\n`The core methodological challenge involves preserving narrative richness of natural language arguments while enabling mathematical analysis—bridging interpretive reasoning favored in philosophy with quantitative prediction favored in technical fields.`\n\n**ArgDown Syntax**:\n\n```         \n[Conclusion]: Description of the conclusion.\n + [Premise1]: Supporting evidence or reasoning.\n   + [Sub-premise]: More detailed supporting factor.\n + [Premise2]: Additional independent support.\n```\n\n`ArgDown uses hierarchical indentation to capture support/attack relationships between statements, making argument structure explicit while remaining human-readable.`\n\n#### BayesDown: The Critical Innovation {#sec-bayesdown-innovation}\n\n<!-- [ ] Introduce AMTAIR's key technical contribution -->\n\n`BayesDown extends ArgDown with probabilistic metadata, creating a hybrid format that bridges natural language and mathematical modeling:`\n\n```         \njson\n{\n  \"instantiations\": [\"conclusion_TRUE\", \"conclusion_FALSE\"],\n  \"priors\": {\"p(conclusion_TRUE)\": \"0.7\", \"p(conclusion_FALSE)\": \"0.3\"},\n  \"posteriors\": {\n    \"p(conclusion_TRUE|premise1_TRUE,premise2_TRUE)\": \"0.9\",\n    \"p(conclusion_TRUE|premise1_TRUE,premise2_FALSE)\": \"0.6\",\n    \"p(conclusion_TRUE|premise1_FALSE,premise2_TRUE)\": \"0.4\",\n    \"p(conclusion_TRUE|premise1_FALSE,premise2_FALSE)\": \"0.1\"\n  }\n}\n```\n\n**Design Principles**:\n\n-   **Human Readable**: Preserves natural language explanations\n-   **Machine Processable**: Structured for automated analysis\n-   **Probabilistically Complete**: Contains all information for Bayesian network construction\n-   **Extensible**: Supports additional metadata as needed\n\n### The MTAIR Framework: Achievements and Limitations {#sec-mtair-framework}\n\n<!-- [ ] Review the MTAIR project's approach to modeling AI risks using Analytica, highlighting both its innovations and limitations, particularly the manual labor intensity that limits scalability -->\n\n> @bucknall2022 on the original Modeling Transformative AI Risks project demonstrates both the value and limitations of manual formal modeling approaches.\n\n> The Modeling Transformative AI Risks (MTAIR) project demonstrated the value of formal probabilistic modeling for AI safety, but also revealed significant limitations in the manual approach. While MTAIR successfully translated complex arguments into Bayesian networks and enabled sensitivity analysis, the intensive human labor required for model creation limited both scalability and timeliness.\n\n#### MTAIR's Innovations {#sec-mtair-innovations}\n\n> @bucknall2022 on the original Modeling Transformative AI Risks project\n\n-   **Structured Uncertainty Representation**: Explicit probability distributions over key variables\n-   **Expert Judgment Integration**: Systematic methods for aggregating diverse opinions\n-   **Sensitivity Analysis**: Identification of critical uncertainties driving outcomes\n-   **Policy Application**: Connection between technical models and governance implications\n\n**MTAIR's Key Innovations:**\n\n-   **Structured Uncertainty Representation**: Explicit probability distributions over key variables rather than point estimates\n-   **Expert Judgment Integration**: Systematic methods for aggregating diverse expert opinions and beliefs\n-   **Sensitivity Analysis**: Identification of critical uncertainties that most significantly drive overall conclusions\n-   **Policy Application**: Direct connection between technical risk models and governance implications\n\n\\`MTAIR's key innovations included:\n\n-   Explicit representation of uncertainty through probability distributions\n-   Structured decomposition of complex risk scenarios\n-   Integration of diverse expert judgments\n-   Sensitivity analysis to identify critical parameters\n\n#### Fundamental Limitations Motivating AMTAIR {#sec-mtair-limitations}\n\n**Scalability Bottleneck**: Manual model construction requires weeks of expert effort per model\n\n**Static Models**: No mechanisms for updating as new research emerges\n\n**Limited Accessibility**: Technical complexity restricts usage to specialists\n\n**Single Worldview Focus**: Difficulty representing multiple perspectives simultaneously\n\n`These limitations create the opportunity for automated approaches that can scale formal modeling to match the pace of AI governance discourse`\n\n**Fundamental Limitations Motivating AMTAIR:**\n\n```         \nCritical constraints of manual approaches:\n\n• **Scalability Bottleneck**: Manual model construction requires weeks of expert effort per argument\n• **Static Nature**: No mechanisms for updating models as new research and evidence emerges  \n• **Limited Accessibility**: Technical complexity restricts usage to specialists with formal modeling expertise\n• **Single Worldview Focus**: Difficulty representing multiple conflicting perspectives simultaneously\n```\n\n`These limitations create a clear opportunity for automated approaches that can scale formal modeling to match the pace and diversity of AI governance discourse.`\n\nIts limitations motivated the current automated approach:\n\n-   Manual labor intensity limiting scalability\n-   Static nature of models once constructed\n-   Limited accessibility for non-technical stakeholders\n-   Challenges in representing multiple worldviews simultaneously\\`\n\n### \"A Narrow Path\": Conditional Policy Proposals in Practice {#sec-narrow-path}\n\n<!-- [ ] Examine \"A Narrow Path\" as a case study of conditional policy proposals, highlighting how formal modeling could clarify the conditions under which specific policy interventions would be effective -->\n\n<!-- [ ] Examine conditional policy proposals highlighting formal modeling potential -->\n\n> \"A Narrow Path\" represents influential example of conditional policy proposals in AI governance—identifying interventions that could succeed under specific conditions rather than universal prescriptions.\n\n`However, these conditions remain implicitly defined and qualitatively described, limiting rigorous evaluation and comparison across alternative approaches.`\n\n> \"A Narrow Path\" represents an influential example of conditional policy proposals in AI governance—identifying interventions that could succeed under specific conditions rather than absolute prescriptions. However, these conditions remain implicitly defined and qualitatively described, limiting rigorous evaluation.\n\n\\`Formal modeling could enhance such proposals by:\n\n-   Making conditions explicit and quantifiable\n-   Clarifying when interventions would be effective\n-   Identifying which uncertainties most significantly affect outcomes\n-   Enabling systematic comparison of alternative approaches\n-   Supporting robust policy development across possible futures\\`\n\n**Formal Modeling Enhancement Potential:**\n\n-   Making conditions explicit and quantifiable rather than implicit assumptions\n-   Clarifying specific circumstances when interventions would be effective versus ineffective\n-   Identifying which uncertainties most significantly affect intervention outcomes\n-   Enabling systematic comparison of alternative policy approaches under uncertainty\n-   Supporting robust policy development that performs well across multiple possible futures\n\n\n```{=html}\n<!-- ---\ntitle: \"Methodology\"\n# Control if this file starts numbering\nnumbering:\n  start-at: 2      # Start at Section 1\n  level: 2         # Chapter level\n--- -->\n```\n\n## Methodology {#sec-methodology}\n\n### Research Design Overview {#sec-research-design}\n\n<!-- [ ] Present the overall research approach, combining theoretical development, software implementation, validation testing, and policy application -->\n\n<!-- [ ] Clarify the iterative nature of the process -->\n\n> This research combines theoretical development with practical implementation, following an iterative approach that moves between conceptual refinement and technical validation. The methodology encompasses formal framework development, computational implementation, extraction quality assessment, and application to real-world AI governance questions.\n\n\\`The research process follows four main phases:\n\n1.  Framework development: Creating the theoretical foundations and formal representations\n2.  System implementation: Building the computational tools for extraction and analysis\n3.  Validation testing: Assessing extraction quality and system performance\n4.  Application evaluation: Applying the framework to concrete AI governance questions\\`\n\n#### Hybrid Theoretical-Empirical Approach {#sec-hybrid-approach}\n\n<!-- [ ] Present hybrid theoretical-empirical approach with iterative development -->\n\n**Four Integrated Components**:\n\n1.  **Theoretical Development**: Formal framework for automated worldview extraction\n2.  **Technical Implementation**: Working prototype demonstrating feasibility\n3.  **Empirical Validation**: Quality assessment against expert benchmarks\n4.  **Policy Application**: Case studies with real governance questions\n\n**Four Primary Components:**\n\n1.  **Theoretical Development**: Formal framework for automated worldview extraction and representation\n2.  **Technical Implementation**: Working prototype demonstrating feasibility and validation\n3.  **Empirical Validation**: Quality assessment against expert benchmarks and known ground truth\n4.  **Policy Application**: Case studies demonstrating practical utility for real governance questions\n\n**Iterative Development Process:**\n\n```         \nPhase 1: Conceptual Framework Development\n↓\nPhase 2: Prototype Implementation with Simple Validation Examples  \n↓\nPhase 3: Complex Real-World Case Application and Evaluation\n↓\nPhase 4: Policy Impact Assessment and Governance Integration\n```\n\n#### Iterative Development Process {#sec-iterative-process}\n\n```         \nPhase 1: Conceptual Framework Development\nPhase 2: Prototype Implementation with Simple Examples  \nPhase 3: Validation with Complex Real-World Cases\nPhase 4: Policy Application and Evaluation\n```\n\n### Formalizing World Models from AI Safety Literature {#sec-formalizing-world-models}\n\n<!-- [ ] Detail the process of extracting causal relationships, key variables, and probabilistic judgments from AI safety literature -->\n\n<!-- [ ] Explain the role of LLMs in this process and the development of prompt engineering techniques to improve extraction quality -->\n\n> The core methodological challenge involves transforming natural language arguments in AI safety literature into formal causal models with explicit probability judgments. This extraction process identifies key variables, causal relationships, and both explicit and implicit probability estimates through a systematic pipeline.\n\n\\`The extraction approach combines:\n\n-   Identification of key variables and entities in text\n-   Recognition of causal claims and relationships\n-   Detection of explicit and implicit probability judgments\n-   Transformation into structured intermediate representations\n-   Conversion to formal Bayesian networks\n\nLarge language models facilitate this process through:\n\n-   Two-stage prompting that separates structure from probability extraction\n-   Specialized templates for different types of source documents\n-   Techniques for identifying implicit assumptions and relationships\n-   Mechanisms for handling ambiguity and uncertainty\\`\n\n### From Natural Language to Computational Models {#sec-natural-to-computational}\n\n<!-- [ ] Detail the two-stage extraction process that is core to AMTAIR -->\n\n**The Two-Stage Extraction Architecture:**\n\n`AMTAIR employs a novel two-stage process that separates structural argument extraction from probability quantification, enabling modular improvement and human oversight at critical decision points.`\n\n#### The Two-Stage Extraction Process {#sec-two-stage-extraction}\n\n**Stage 1: Structural Extraction (ArgDown)**\n\n-   Identify key variables and causal claims\n-   Extract hierarchical argument structure\n-   Map logical relationships between elements\n-   Generate intermediate representation preserving narrative\n\n**Stage 1: Structural Extraction (ArgDown Generation)**\n\n<!-- [ ] Describe argument structure identification process -->\n\n-   **Variable and Claim Identification**: Extract key propositions and entities from natural language text\n-   **Causal Relationship Mapping**: Identify support/attack relationships and conditional dependencies\n-   **Hierarchical Structure Construction**: Generate properly nested argument representations preserving logical flow\n-   **Intermediate Representation**: Create ArgDown format suitable for human review and machine processing\n\n```         \npython\ndef extract_argument_structure(text):\n    \"\"\"Extract hierarchical argument structure from natural language\"\"\"\n    # LLM-based extraction with specialized prompts\n    prompt = ArgumentExtractionPrompt(\n        text=text,\n        output_format=\"ArgDown\",\n        focus_areas=[\"causal_claims\", \"probability_statements\", \"conditional_reasoning\"]\n    )\n    \n    structure = llm.complete(prompt)\n    return validate_argdown_syntax(structure)\n```\n\n**Stage 2: Probability Integration (BayesDown)**\n\n-   Extract explicit probability statements\n-   Generate questions for implicit judgments\n-   Quantify uncertainty and conditional dependencies\n-   Create complete probabilistic specification\n\n**Stage 2: Probability Integration (BayesDown Enhancement)**\n\n<!-- [ ] Explain quantification and validation processes -->\n\n-   **Explicit Probability Extraction**: Identify and parse numerical probability statements in source text\n-   **Question Generation**: Create systematic elicitation questions for implicit probability judgments\n-   **Expert Input Integration**: Incorporate domain expertise for ambiguous or missing quantifications\n-   **Consistency Validation**: Ensure probability assignments satisfy basic coherence requirements\n\n```         \npython\ndef integrate_probabilities(argdown_structure, probability_sources):\n    \"\"\"Convert ArgDown to BayesDown with probabilistic information\"\"\"\n    questions = generate_probability_questions(argdown_structure)\n    probabilities = extract_probabilities(probability_sources, questions)\n    \n    bayesdown = enhance_with_probabilities(argdown_structure, probabilities)\n    return validate_probability_coherence(bayesdown)\n```\n\n#### LLM Integration Strategy {#sec-llm-integration}\n\n<!-- Explain how frontier AI enables automated extraction -->\n\n**Prompt Engineering Approach**:\n\n-   Specialized prompts for argument structure identification\n-   Two-stage prompting to separate structure from quantification\n-   Validation mechanisms to ensure extraction quality\n-   Iterative refinement based on expert feedback\n\n**Current Capabilities and Limitations**:\n\n> Frontier LLMs show promising extraction quality but require careful validation\n\n**LLM Integration Strategy:**\n\n> Frontier language models enable automated extraction but require careful prompt engineering and validation mechanisms to ensure extraction quality and consistency.\n\n-   **Specialized Prompting**: Domain-specific templates for argument structure identification\n-   **Two-Stage Separation**: Structural and probabilistic extraction handled independently for quality control\n-   **Validation Mechanisms**: Automated and human review processes for extraction accuracy\n-   **Iterative Refinement**: Feedback loops enabling continuous improvement based on expert assessment\n\n### Directed Acyclic Graphs: Structure and Semantics {#sec-dag-structure}\n\n<!-- [ ] Explain the mathematical properties of DAGs and their semantic interpretation in the context of AI risk modeling -->\n\n<!-- [ ] Cover both structural and parametric aspects of the models -->\n\n> Directed Acyclic Graphs (DAGs) form the mathematical foundation of Bayesian networks, encoding both the qualitative structure of causal relationships and the quantitative parameters that define conditional dependencies. In AI risk modeling, these structures represent causal pathways to potential outcomes of interest.\n\n\\`Key mathematical properties include:\n\n-   Acyclicity, ensuring no feedback loops\n-   Path properties defining information flow\n-   D-separation criteria determining conditional independence\n-   Markov blanket defining minimal contextual information\n\n#### Formal Properties {#sec-formal-properties}\n\n**Acyclicity Requirement**: Ensures coherent probabilistic interpretation\n\n**D-Separation**: Conditional independence relationships between variables\n\n**Markov Condition**: Each variable independent of non-descendants given parents\n\n<!-- [ ] Explain mathematical properties and semantic interpretation -->\n\n**Formal Properties Essential for AI Risk Modeling:**\n\n-   **Acyclicity Requirement**: Ensures coherent probabilistic interpretation without logical contradictions\n-   **D-Separation**: Defines conditional independence relationships between variables based on graph structure\n-   **Markov Condition**: Each variable conditionally independent of non-descendants given parents\n-   **Path Analysis**: Causal pathways and information flow through the network structure\n\n**Causal Interpretation in AI Governance Context:**\n\n> @pearl2009 on causal inference and intervention analysis provides mathematical foundations for policy evaluation through do-calculus.\n\n-   **Edges as Causal Relations**: Directed arrows represent direct causal influence between factors\n-   **Intervention Analysis**: Do-calculus enables rigorous evaluation of policy intervention effects\n-   **Counterfactual Reasoning**: \"What if\" scenarios essential for governance planning under uncertainty\n-   **Evidence Integration**: Bayesian updating for incorporating new information and expert judgment\n\n#### Causal Interpretation {#sec-causal-interpretation}\n\n<!-- Connection to Pearl's causal framework -->\n\n> @pearl2009 on causal inference and intervention analysis\n\n-   **Edges as Causal Relations**: Directed arrows represent direct causal influence\n-   **Intervention Analysis**: Do-calculus for policy evaluation\n-   **Counterfactual Reasoning**: \"What if\" scenarios for governance planning\n\nSemantic interpretation in AI risk contexts:\n\n-   Nodes represent key variables in risk pathways\n-   Edges represent causal or inferential relationships\n-   Path blocking corresponds to intervention points\n-   Probability flows represent risk propagation through systems\\`\n\n### Quantification of Probabilistic Judgments {#sec-quantification}\n\n<!-- [ ] Examine methods for converting qualitative judgments into quantitative probabilities, including expert elicitation, calibration techniques, and sensitivity analysis -->\n\n<!-- [ ] Discuss challenges of aggregating diverse probabilistic judgments -->\n\n<!-- [ ] Examine methods for converting qualitative to quantitative assessments -->\n\n**Linguistic Probability Mapping:**\n\n`Transforming qualitative uncertainty expressions into quantitative probabilities requires systematic interpretation frameworks that account for individual and cultural variation.`\n\n```         \nStandard linguistic mappings (with significant individual variation):\n• \"Very likely\" → 0.8-0.9\n• \"Probable\" → 0.6-0.8  \n• \"Uncertain\" → 0.4-0.6\n• \"Unlikely\" → 0.2-0.4\n• \"Highly improbable\" → 0.05-0.15\n```\n\n> Transforming qualitative judgments in AI safety literature into quantitative probabilities requires a systematic approach to interpretation, extraction, and validation. This process combines direct extraction of explicit numerical statements with inference of implicit probability judgments from qualitative language.\n\n\\`Quantification methods include:\n\n-   Direct extraction of explicit numerical statements\n-   Linguistic mapping of qualitative expressions\n-   Expert elicitation techniques for ambiguous cases\n-   Bayesian updating from multiple sources\n\nSpecial challenges in AI risk quantification:\n\n-   Deep uncertainty about unprecedented events\n-   Diverse disciplinary languages and conventions\n-   Limited empirical basis for calibration\n-   Value-laden aspects of risk assessment\\`\n\n#### From Qualitative to Quantitative {#sec-qualitative-to-quantitative}\n\n**Linguistic Probability Expressions**:\n\n-   \"Very likely\" → 0.8-0.9\n-   \"Uncertain\" → 0.4-0.6\n-   \"Highly improbable\" → 0.05-0.15\n\n**Calibration Challenges**:\n\n-   Individual variation in linguistic interpretation\n-   Domain-specific probability anchoring\n-   Cultural and contextual influences on uncertainty expression\n\n**Calibration and Validation Challenges:**\n\n-   Individual variation in linguistic interpretation and probability anchoring\n-   Domain-specific probability anchoring and reference class selection\n-   Cultural and contextual influences on uncertainty expression and tolerance\n-   Limited empirical basis for calibration in unprecedented scenarios like transformative AI\n\n#### Expert Elicitation Methods {#sec-expert-elicitation}\n\n```         \nDirect Probability Assessment: \"What is P(outcome)?\"\nComparative Assessment: \"Is A more likely than B?\"  \nFrequency Format: \"In 100 similar cases, how many would result in outcome?\"\nBetting Odds: \"What odds would you accept for this bet?\"\n```\n\n**Expert Elicitation Methodologies:**\n\n-   **Direct Probability Assessment**: \"What is P(outcome)?\" with calibration training\n-   **Comparative Assessment**: \"Is A more likely than B?\" for relative judgment validation\n-   **Frequency Format**: \"In 100 similar cases, how many would result in outcome?\" for clearer mental models\n-   **Betting Odds**: \"What odds would you accept for this bet?\" for revealed preference elicitation\n\n### Inference Techniques for Complex Networks {#sec-inference-techniques}\n\n<!-- [ ] Review Monte Carlo sampling and other inference techniques for complex Bayesian networks, explaining their application to policy evaluation -->\n\n<!-- [ ] Discuss computational complexity considerations and approximation methods -->\n\n> Once Bayesian networks are constructed, probabilistic inference enables reasoning about uncertainties, counterfactuals, and policy interventions. For the complex networks representing AI risks, computational approaches must balance accuracy with tractability.\n\n\\`Inference methods implemented include:\n\n-   Exact methods for smaller networks (variable elimination, junction trees)\n-   Approximate methods for larger networks (Monte Carlo sampling)\n-   Specialized approaches for rare events\n-   Intervention modeling for policy evaluation\n\nImplementation considerations include:\n\n-   Computational complexity management\n-   Sampling efficiency optimization\n-   Approximation quality monitoring\n-   Uncertainty representation in outputs\\`\n\n### Integration with Prediction Markets and Forecasting Platforms {#sec-prediction-markets}\n\n<!-- [ ] Detail methods for connecting the formal models with live data sources from prediction markets and forecasting platforms -->\n\n<!-- [ ] Explain data standardization, weighting mechanisms, and update procedures -->\n\n> To maintain relevance in a rapidly evolving field, formal models must integrate with live data sources such as prediction markets and forecasting platforms. This integration enables continuous updating of model parameters as new information emerges.\n\n\\`Integration approaches include:\n\n-   API connections to platforms like Metaculus\n-   Semantic mapping between forecast questions and model variables\n-   Weighting mechanisms based on forecaster track records\n-   Update procedures for incorporating new predictions\n-   Feedback loops identifying valuable forecast questions\n\nTechnical implementation involves:\n\n-   Standardized data formats across platforms\n-   Conflict resolution for contradictory sources\n-   Temporal alignment of forecasts\n-   Confidence-weighted aggregation methods\\`\n\n<!-- [ ] Detail methods for connecting models with live data sources -->\n\n**Live Data Sources for Dynamic Model Updating:**\n\n-   **Metaculus**: Long-term AI predictions and technological forecasting\n-   **Good Judgment Open**: Geopolitical events and policy outcomes\n-   **Manifold Markets**: Diverse question types with rapid market response\n-   **Internal Expert Forecasting**: Organization-specific predictions and assessments\n\n**Data Processing and Integration Pipeline:**\n\n```         \npython\ndef integrate_forecast_data(model_variables, forecast_platforms):\n    \"\"\"Connect Bayesian network variables to live forecasting data\"\"\"\n    mappings = create_semantic_mappings(model_variables, forecast_platforms)\n    \n    for variable, forecasts in mappings.items():\n        weighted_forecast = aggregate_forecasts(\n            forecasts, \n            weights=calculate_track_record_weights(forecasts)\n        )\n        model.update_prior(variable, weighted_forecast)\n    \n    return model.recompute_posteriors()\n```\n\n**Technical Implementation Challenges:**\n\n-   **Question Mapping**: Connecting forecast questions to specific model variables with semantic accuracy\n-   **Temporal Alignment**: Handling different forecast horizons and update frequencies across platforms\n-   **Conflict Resolution**: Principled aggregation when sources provide contradictory information\n-   **Track Record Weighting**: Incorporating forecaster calibration and expertise into aggregation weights\n\n#### Live Data Sources {#sec-live-data}\n\n**Forecasting Platforms**:\n\n-   Metaculus for long-term AI predictions\n-   Good Judgment Open for geopolitical events\n-   Manifold Markets for diverse question types\n-   Internal expert forecasting within organizations\n\n#### Data Processing Pipeline {#sec-data-processing}\n\n**Question Mapping**: Connecting forecast questions to model variables\n\n**Temporal Alignment**: Handling different forecast horizons and update frequencies\n\n**Aggregation Methods**: Weighting sources by track record and relevance\n\n<!-- [ ] Add specific examples of forecast integration -->\n\n\n[![AMTAIR Automation Pipeline from CITATION](/images/pipeline.png){#fig-automation_pipeline fig-scap=\"Five-step AMTAIR automation pipeline from PDFs to Bayesian networks\" fig-alt=\"FLOWCHART: Five-step automation pipeline workflow for AMTAIR project.           DATA: The pipeline transforms PDFs through ArgDown, BayesDown, CSV, and HTML into Bayesian network visualizations.           PURPOSE: Illustrates the core technical process that enables automated extraction of probabilistic models from AI safety literature.           DETAILS: Five numbered green steps show: (1) LLM-based extraction from PDFs to ArgDown, (2) ArgDown to BayesDown completion with probabilities, (3) Extracting world-models as CSV data, (4) Software tools for data inference, and (5) Visualization of the resulting Bayesian network.           Each step includes example outputs, with the final visualization showing a Rain-Sprinkler-Grass Wet Bayesian network with probability tables.           SOURCE: Created by the author to explain the AMTAIR methodology           \" fig-align=\"center\" width=\"100%\"}](https://github.com/VJMeyer/submission)\n\nTesting crossreferencing grapics @fig-automation_pipeline.\n\n",
    "supporting": [
      "2.0.Context_files"
    ],
    "filters": [],
    "includes": {}
  }
}