{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt8-AnebGUXr"
      },
      "source": [
        "# [AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22NBzTxxsnfQ"
      },
      "source": [
        "## Instructions --- How to use this notebook:\n",
        "\n",
        "\n",
        "1. **Import Libraries & Install Packages**: Run Section 0.1 to set up the necessary dependencies for data processing and visualization.\n",
        "\n",
        "2. **Connect to GitHub Repository & Load Data files**: Run Section 0.2 to establish connections to the data repository and load example datasets. This step retrieves sample ArgDown files and extracted data for demonstration.\n",
        "\n",
        "3. **Process Source Documents to ArgDown**: Sections 1.0-1.8 demonstrate the extraction of argument structures from source documents (such as PDFs) into ArgDown format, a markdown-like notation for structured arguments.\n",
        "\n",
        "4. **Convert ArgDown to BayesDown**: Sections 2.0-2.3 handle the transformation of ArgDown files into BayesDown format, which incorporates probabilistic information into the argument structure.\n",
        "\n",
        "5. **Extract Data into Structured Format**: Section 3.0 processes BayesDown format into structured database entries (CSV) that can be used for analysis.\n",
        "\n",
        "6. **Create and Analyze Bayesian Networks**: Section 4.0 demonstrates how to build Bayesian networks from the extracted data and provides tools for analyzing risk pathways.\n",
        "\n",
        "7. **Save and Export Results**: Sections 5.0-6.0 provide methods for archiving results and exporting visualizations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "toc",
        "id": "dJYH9hZRbiz6"
      },
      "source": [
        ">[AMTAIR Prototype Demonstration (Public Colab Notebook)](#scrollTo=lt8-AnebGUXr)\n",
        "\n",
        ">>[Instructions --- How to use this notebook:](#scrollTo=22NBzTxxsnfQ)\n",
        "\n",
        ">>[Key Concepts:](#scrollTo=NovjnOw6bzLi)\n",
        "\n",
        ">>[Example Workflow:](#scrollTo=NovjnOw6bzLi)\n",
        "\n",
        ">>[Troubleshooting:](#scrollTo=NovjnOw6bzLi)\n",
        "\n",
        ">[0.1 Prepare Colab/Python Environment --- Import Libraries & Packages](#scrollTo=GtVFO-s74vI_)\n",
        "\n",
        ">>[0.2 Connect to GitHub Repository](#scrollTo=2a3VR0fLhJow)\n",
        "\n",
        ">>[0.3 File Import](#scrollTo=y-ix4Rp5fE9m)\n",
        "\n",
        ">[1.0 Sources (PDF's of Papers) to ArgDown (.md file)](#scrollTo=52XyPlte5HrU)\n",
        "\n",
        ">>[1.1 Specify Source Document (e.g. PDF)](#scrollTo=ESKnZ_4f_a6y)\n",
        "\n",
        ">>[1.2 Generate ArgDown Extraction Prompt](#scrollTo=6ToQFra3_nl9)\n",
        "\n",
        ">>[1.3 Prepare LLM API Call](#scrollTo=pGv2KcZU_9Bn)\n",
        "\n",
        ">>[1.4 Make ArgDown Extraction LLM API Call](#scrollTo=i5xsDYnsAWC4)\n",
        "\n",
        ">>[1.5 Save ArgDown Extraction Response](#scrollTo=Lc2nMp8nAfeU)\n",
        "\n",
        ">>[1.6 Review and Check ArgDown.md File](#scrollTo=5HcCfqE4A0ht)\n",
        "\n",
        ">>[1.6.2 Check the Graph Structure with the ArgDown Sandbox Online](#scrollTo=gSpkvLbCC_PI)\n",
        "\n",
        ">>[1.7 Extract ArgDown Graph Information as DataFrame](#scrollTo=MAm0UKpeBvyr)\n",
        "\n",
        ">>[1.8 Store ArgDown Information as 'ArgDown.csv' file](#scrollTo=iFC6oiyICREn)\n",
        "\n",
        ">[2.0 Probability Extractions: ArgDown (.csv) to BayesDown (.md + plugin JSON syntax)](#scrollTo=7SGB0XMp5VFq)\n",
        "\n",
        ">>[2.1 Probability Extraction Questions --- 'ArgDown.csv' to 'ArgDown_WithQuestions.csv'](#scrollTo=WcF2nHXBZru4)\n",
        "\n",
        ">>[2.2 'ArgDown_WithQuestions.csv' to 'BayesDownQuestions.md'](#scrollTo=-q9UOQ8yaBZn)\n",
        "\n",
        ">>[2.3 Generate BayesDown Probability Extraction Prompt](#scrollTo=Ux4OUCPue6Bu)\n",
        "\n",
        ">>[2.4 Prepare 2nd API call](#scrollTo=d4tB9WD-fIWZ)\n",
        "\n",
        ">>[2.5 Make BayesDown Probability Extraction API Call](#scrollTo=oPWto83lfN9Q)\n",
        "\n",
        ">>[2.6 Save BayesDown with Probability Estimates (.csv)](#scrollTo=L8NWpz8MfZ9_)\n",
        "\n",
        ">>[2.7 Review & Verify BayesDown Probability Estimates](#scrollTo=Q3PTtYgRfsLa)\n",
        "\n",
        ">>[2.7.2 Check the Graph Structure with the ArgDown Sandbox Online](#scrollTo=VwoAgBsafonh)\n",
        "\n",
        ">>>[2.3.1 BayesDown Format Specification](#scrollTo=ivcnd2ml41Nv)\n",
        "\n",
        ">>[2.8 Extract BayesDown with Probability Estimates as Dataframe](#scrollTo=19KDn2mKf309)\n",
        "\n",
        ">[3.0 Data Extraction: BayesDown (.md) to Database (.csv)](#scrollTo=SJ9OIyEv5qqb)\n",
        "\n",
        ">>>[3.1 ExtractBayesDown-Data_v1](#scrollTo=AFnu_1Ludahi)\n",
        "\n",
        ">>[3.1.2 Test BayesDown Extraction](#scrollTo=eUBJh8Qp4yd4)\n",
        "\n",
        ">>[3.1.2.2 Check the Graph Structure with the ArgDown Sandbox Online](#scrollTo=z4Hgs0ICDQyW)\n",
        "\n",
        ">>>[3.1.2.B Test with 'Example_file_combined_withBayesDown_Crossgenerational.md'](#scrollTo=oSDF6M_h3h6O)\n",
        "\n",
        ">>[3.3 Extraction](#scrollTo=mv8f4c4D3yJj)\n",
        "\n",
        ">>>[3.3 Data-Post-Processing](#scrollTo=UcXf3fZ8dahj)\n",
        "\n",
        ">>>[3.4 Download and save finished data frame as .csv file](#scrollTo=xTwPO_J-dahj)\n",
        "\n",
        ">[4.0 Analysis & Inference: Practical Software Tools ()](#scrollTo=LHQm7ydMmPhN)\n",
        "\n",
        ">>[Phase 1: Dependencies/Functions](#scrollTo=LSeSAPvtgIgU)\n",
        "\n",
        ">>[Phase 2: Node Classification and Styling Module](#scrollTo=byAExfek5yFU)\n",
        "\n",
        ">>[Phase 3: HTML Content Generation Module](#scrollTo=gnS3jFGU52OZ)\n",
        "\n",
        ">>[Phase 4: Main Visualization Function](#scrollTo=d2uyG0Pi571f)\n",
        "\n",
        ">[Quickly check HTML Outputs](#scrollTo=bFtxTKmLElSF)\n",
        "\n",
        ">[5.0 Archive_version_histories](#scrollTo=0M9gFpK6ioHk)\n",
        "\n",
        ">>>>>[Heading](#scrollTo=ulwM2lfJcY6g)\n",
        "\n",
        ">>[COMBINED: 2.1 Generate and Extract \"Prior-, Conditional- and Posterior Probability Questions\" from 'ArgDown.csv' to 'ArgDown_WithQuestions.csv'](#scrollTo=-Y7587rHcJ-5)\n",
        "\n",
        ">[6.0 Save Outputs](#scrollTo=kjbIj19epbrF)\n",
        "\n",
        ">>[Convert ipynb to HTML in Colab](#scrollTo=0QqlN6dYpm4s)\n",
        "\n",
        ">>[Convert .ipynb Notebook to MarkDown](#scrollTo=pS6AhdiSCLw4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NovjnOw6bzLi"
      },
      "source": [
        "\n",
        "## Key Concepts:\n",
        "\n",
        "- **ArgDown**: A structured format for representing arguments, with hierarchical relationships between statements.\n",
        "- **BayesDown**: An extension of ArgDown that incorporates probabilistic information, allowing for Bayesian network construction.\n",
        "- **Extraction Pipeline**: The process of converting unstructured text to structured argument representations.\n",
        "- **Bayesian Networks**: Probabilistic graphical models that represent variables and their conditional dependencies.\n",
        "\n",
        "## Example Workflow:\n",
        "\n",
        "1. Load a sample ArgDown file from the repository\n",
        "2. Extract the hierarchical structure and relationships\n",
        "3. Add probabilistic information to create a BayesDown representation\n",
        "4. Generate a Bayesian network visualization\n",
        "5. Analyze conditional probabilities and risk pathways\n",
        "\n",
        "## Troubleshooting:\n",
        "\n",
        "- If connectivity issues occur, ensure you have access to the GitHub repository\n",
        "- For visualization errors, check that all required libraries are properly installed\n",
        "- When processing custom files, ensure they follow the expected format conventions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtVFO-s74vI_"
      },
      "source": [
        "# 0.1 Prepare Colab/Python Environment --- Import Libraries & Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 0.1 --- Install & Import Libraries & Packages (One-Time Setup) ---\n",
        "\n",
        "#  Stores Boolean Flag in Environment runs only when flag is absent\n",
        "#  Check if the setup flag variable exists in the global scope\n",
        "\n",
        "try:\n",
        "    # If this variable exists, setup was already done successfully in this session.\n",
        "    _setup_imports_done\n",
        "    print(\"✅ Libraries already installed and imported in this session. Skipping setup.\")\n",
        "\n",
        "except NameError:\n",
        "    print(\"⏳ Performing one-time library installation and imports...\")\n",
        "\n",
        "    # 1. Install Packages (Quietly using -q) Requiring Installation (not avialable in Colab by default)\n",
        "    !pip install -q pyvis\n",
        "    !apt-get install pandoc -y\n",
        "    # Combine Google-related packages for slightly cleaner install\n",
        "    !pip install -q --upgrade gspread pandas google-auth google-colab\n",
        "    !pip install -q pgmpy\n",
        "    !pip install -q nbconvert  # Often pre-installed, but good to ensure\n",
        "\n",
        "    print(\"   --> Installations complete.\")\n",
        "\n",
        "    # 2. Import Libraries\n",
        "    try:\n",
        "        import requests      # For making HTTP requests\n",
        "        import io            # For working with in-memory file-like objects\n",
        "        import pandas as pd  # For data manipulation\n",
        "        import numpy as np\n",
        "        import json\n",
        "        import re\n",
        "        import matplotlib.pyplot as plt\n",
        "        from IPython.display import HTML, display, Markdown # Combined imports\n",
        "\n",
        "        # Packages not avialable in Colab by default and require above installations below:\n",
        "        import networkx as nx\n",
        "\n",
        "        from pgmpy.models import BayesianNetwork\n",
        "        from pgmpy.factors.discrete import TabularCPD\n",
        "        from pgmpy.inference import VariableElimination\n",
        "\n",
        "        from pyvis.network import Network\n",
        "\n",
        "        # Also good practice to print key library versions after import\n",
        "        print(f\"      pandas version: {pd.__version__}\")\n",
        "        print(f\"      networkx version: {nx.__version__}\")\n",
        "        # Add others if specific versions are critical\n",
        "\n",
        "        print(\"   --> Imports complete.\")\n",
        "\n",
        "        # 3. Set the flag ONLY if all installs and imports were successful\n",
        "        _setup_imports_done = True\n",
        "        print(\"✅ One-time setup finished successfully.\")\n",
        "\n",
        "    except ImportError as e:\n",
        "        print(f\"❌ ERROR during import: {e}\")\n",
        "        print(\"   --> Setup did not complete successfully. Please check installations.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ UNEXPECTED ERROR during setup: {e}\")\n",
        "        print(\"   --> Setup did not complete successfully.\")\n",
        "\n",
        "# --- End of One-Time Setup Cell ---\n",
        "\n",
        "# Now you can proceed with the rest of your code, knowing the imports exist\n",
        "# if the setup cell didn't raise a critical error."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pMZsRONBdOO",
        "outputId": "480ed15a-1c89-4816-eb70-9c32b2c389b3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Libraries already installed and imported in this session. Skipping setup.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a3VR0fLhJow"
      },
      "source": [
        "## 0.2 Connect to GitHub Repository\n",
        "\n",
        "The Public GitHub Repo Url in use:\n",
        "\n",
        "https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/\n",
        "\n",
        "Note:\n",
        "When encountering errors, accessing the data, try using \"RAW\" Urls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5yTj7I_5hvB-",
        "outputId": "14996480-0975-47cf-c817-fc566da36ef4",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grass_Wet]: Concentrated moisture on, between and around the blades of grass.{\"instantiations\": [\"grass_wet_TRUE\", \"grass_wet_FALSE\"]} \n",
            " +[Rain]: Tears of angles crying high up in the skies hitting the ground.{\"instantiations\": [\"rain_TRUE\", \"rain_FALSE\"]} \n",
            " +[Sprinkler]: Activation of a centrifugal force based CO2 droplet distribution system.{\"instantiations\": [\"sprinkler_TRUE\", \"sprinkler_FALSE\"]} \n",
            "  +[Rain]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title 0.2 --- Connect to GitHub Repository --- Load Files\n",
        "\n",
        "\n",
        "# Specify the base repository URL\n",
        "repo_url = \"https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_1/\"\n",
        "\n",
        "def load_file_from_repo(relative_path):\n",
        "  \"\"\"Loads a file from the specified GitHub repository using a relative path.\"\"\"\n",
        "  file_url = repo_url + relative_path\n",
        "  response = requests.get(file_url)\n",
        "\n",
        "  # Check for bad status codes and print more helpful error messages\n",
        "  if response.status_code == 404:\n",
        "    raise HTTPError(f\"File not found at URL: {file_url}. Check the file path/name and ensure the file is publicly accessible.\", response=response)\n",
        "  else:\n",
        "    response.raise_for_status() # Raise for other error codes\n",
        "\n",
        "  file_object = io.StringIO(response.text)\n",
        "\n",
        "  if relative_path.endswith(\".csv\"):\n",
        "    return pd.read_csv(file_object)\n",
        "  elif relative_path.endswith(\".json\"):\n",
        "    return pd.read_json(file_object)\n",
        "  elif relative_path.endswith(\".md\"):\n",
        "    return file_object.read()  # Return the raw content for .md files\n",
        "  else:\n",
        "    raise ValueError(\"Unsupported file type. Add Support in GitHub Connection in the Second Section of this Python Notebook\")\n",
        "\n",
        "# Load files using relative paths\n",
        "\n",
        "df = load_file_from_repo(\"extracted_data.csv\") # Update if the file path is incorrect\n",
        "\n",
        "md_content = load_file_from_repo(\"ArgDown_TestText.md\")\n",
        "\n",
        "# print(df.head()) # To see the output, run the code.\n",
        "\n",
        "print(md_content) # To see the output, run the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "ySUTqVpFjVt2",
        "outputId": "a4d1644b-791e-463c-d6cb-aee71e3fae0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Title                                        Description  line  \\\n",
            "0  Grass_Wet  Concentrated moisture on, between and around t...     3   \n",
            "1       Rain  Tears of angles crying high up in the skies hi...     4   \n",
            "2  Sprinkler  Activation of a centrifugal force based CO2 dr...     5   \n",
            "\n",
            "  line_numbers  indentation indentation_levels                Parents  \\\n",
            "0          [3]            0                [0]  ['Rain', 'Sprinkler']   \n",
            "1       [4, 6]            2             [1, 2]                     []   \n",
            "2          [5]            1                [1]               ['Rain']   \n",
            "\n",
            "                     Children                         instantiations  \\\n",
            "0                          []  ['grass_wet_TRUE', 'grass_wet_FALSE']   \n",
            "1  ['Grass_Wet', 'Sprinkler']            ['rain_TRUE', 'rain_FALSE']   \n",
            "2               ['Grass_Wet']  ['sprinkler_TRUE', 'sprinkler_FALSE']   \n",
            "\n",
            "                                              priors  \\\n",
            "0  {'p(grass_wet_TRUE)': '0.322', 'p(grass_wet_FA...   \n",
            "1    {'p(rain_TRUE)': '0.2', 'p(rain_FALSE)': '0.8'}   \n",
            "2  {'p(sprinkler_TRUE)': '0.44838', 'p(sprinkler_...   \n",
            "\n",
            "                                          posteriors  No_Parent  No_Children  \n",
            "0  {'p(grass_wet_TRUE|sprinkler_TRUE,rain_TRUE)':...      False         True  \n",
            "1                                                 {}       True        False  \n",
            "2  {'p(sprinkler_TRUE|rain_TRUE)': '0.01', 'p(spr...      False        False  \n"
          ]
        }
      ],
      "source": [
        "print(df.head()) # To see the output, run the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-ix4Rp5fE9m"
      },
      "source": [
        "## 0.3 File Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "x7SM8xquWVe5",
        "outputId": "3b572e97-cc65-49cf-f086-68ac6dd7a773"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[Grass_Wet]: Concentrated moisture on, between and around the blades of grass.{\"instantiations\": [\"grass_wet_TRUE\", \"grass_wet_FALSE\"]} \\n +[Rain]: Tears of angles crying high up in the skies hitting the ground.{\"instantiations\": [\"rain_TRUE\", \"rain_FALSE\"]} \\n +[Sprinkler]: Activation of a centrifugal force based CO2 droplet distribution system.{\"instantiations\": [\"sprinkler_TRUE\", \"sprinkler_FALSE\"]} \\n  +[Rain]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "md_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52XyPlte5HrU"
      },
      "source": [
        "# 1.0 Sources (PDF's of Papers) to ArgDown (.md file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESKnZ_4f_a6y"
      },
      "source": [
        "## 1.1 Specify Source Document (e.g. PDF)\n",
        "\n",
        "Review the source document, ensure it is suitable for API call and upload to / store it in the correct location."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1.1.a) --- MTAIR Online Model (Analytica) ---\n",
        "\n",
        "from IPython.display import IFrame\n",
        "\n",
        "IFrame(src=\"https://acp.analytica.com/view0?invite=4560&code=3000289064591444815\", width=\"100%\", height=\"900px\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "m7l8xNd-gxcl",
        "outputId": "bcb85683-e807-4e5f-a735-78b5e01c8adf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x77fe2bafb450>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"900px\"\n",
              "            src=\"https://acp.analytica.com/view0?invite=4560&code=3000289064591444815\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ToQFra3_nl9"
      },
      "source": [
        "## 1.2 Generate ArgDown Extraction Prompt\n",
        "\n",
        "Generate Extraction Prompt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1.2.0 --- Prompt Template Function Definitions ---\n",
        "\n",
        "from string import Template\n",
        "from typing import Dict, Optional, Union, List\n",
        "\n",
        "class PromptTemplate:\n",
        "    \"\"\"Template system for LLM prompts with variable substitution\"\"\"\n",
        "\n",
        "    def __init__(self, template: str):\n",
        "        \"\"\"Initialize with template string using $variable format\"\"\"\n",
        "        self.template = Template(template)\n",
        "\n",
        "    def format(self, **kwargs) -> str:\n",
        "        \"\"\"Substitute variables in the template\"\"\"\n",
        "        return self.template.safe_substitute(**kwargs)\n",
        "\n",
        "    @classmethod\n",
        "    def from_file(cls, filepath: str) -> 'PromptTemplate':\n",
        "        \"\"\"Load template from a file\"\"\"\n",
        "        with open(filepath, 'r') as f:\n",
        "            template = f.read()\n",
        "        return cls(template)\n",
        "\n",
        "class PromptLibrary:\n",
        "    \"\"\"Collection of prompt templates for different extraction tasks\"\"\"\n",
        "\n",
        "    # ArgDown extraction prompt\n",
        "    ARGDOWN_EXTRACTION = PromptTemplate(\"\"\"\n",
        "You are an expert in creating structured argument maps in ArgDown format. Your task is to extract the key arguments, premises, and conclusions from the provided text, and represent them in a hierarchical ArgDown format.\n",
        "\n",
        "Follow these guidelines:\n",
        "1. Use the format [Statement]: Description for main claims\n",
        "2. Use the + symbol and indentation to indicate supporting statements\n",
        "3. Capture the core argumentative structure, focusing on causal relationships and key claims\n",
        "4. Ensure each statement has a clear, concise title followed by a fuller description\n",
        "5. Add the \"instantiations\" field to indicate possible states of each variable\n",
        "\n",
        "Here is the metadata format to include for each node:\n",
        "{\"instantiations\": [\"node_TRUE\", \"node_FALSE\"]}\n",
        "\n",
        "Example:\n",
        "[Thesis]: Main claim of the text. {\"instantiations\": [\"thesis_TRUE\", \"thesis_FALSE\"]}\n",
        " + [Support1]: First supporting argument. {\"instantiations\": [\"support1_TRUE\", \"support1_FALSE\"]}\n",
        "   + [Evidence1]: Evidence for Support1. {\"instantiations\": [\"evidence1_TRUE\", \"evidence1_FALSE\"]}\n",
        " + [Support2]: Second supporting argument. {\"instantiations\": [\"support2_TRUE\", \"support2_FALSE\"]}\n",
        "\n",
        "Text to analyze:\n",
        "$text\n",
        "\n",
        "Create an ArgDown representation that captures the key arguments, their relationships, and possible states:\n",
        "\"\"\")\n",
        "\n",
        "    # BayesDown probability extraction prompt\n",
        "    BAYESDOWN_EXTRACTION = PromptTemplate(\"\"\"\n",
        "You are an expert in probabilistic reasoning and Bayesian networks. Your task is to extend the provided ArgDown structure with probability information, creating a BayesDown representation.\n",
        "\n",
        "For each statement in the ArgDown structure, you need to:\n",
        "1. Estimate prior probabilities for each possible state\n",
        "2. Estimate conditional probabilities given parent states\n",
        "3. Maintain the original structure and relationships\n",
        "\n",
        "Here is the format to follow:\n",
        "[Node]: Description. { \"instantiations\": [\"node_TRUE\", \"node_FALSE\"], \"priors\": { \"p(node_TRUE)\": \"0.7\", \"p(node_FALSE)\": \"0.3\" }, \"posteriors\": { \"p(node_TRUE|parent_TRUE)\": \"0.9\", \"p(node_TRUE|parent_FALSE)\": \"0.4\", \"p(node_FALSE|parent_TRUE)\": \"0.1\", \"p(node_FALSE|parent_FALSE)\": \"0.6\" } }\n",
        " [Parent]: Parent description. {...}\n",
        "\n",
        "\n",
        "Here are the specific probability questions to answer:\n",
        "$questions\n",
        "\n",
        "ArgDown structure to enhance:\n",
        "$argdown\n",
        "\n",
        "Provide the complete BayesDown representation with probabilities:\n",
        "\"\"\")\n",
        "\n",
        "    @classmethod\n",
        "    def get_template(cls, template_name: str) -> PromptTemplate:\n",
        "        \"\"\"Get a prompt template by name\"\"\"\n",
        "        if hasattr(cls, template_name):\n",
        "            return getattr(cls, template_name)\n",
        "        else:\n",
        "            raise ValueError(f\"Template not found: {template_name}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MJpgdepF2Ug3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGv2KcZU_9Bn"
      },
      "source": [
        "## 1.3 Prepare LLM API Call\n",
        "\n",
        "Combine Systemprompt + API Specifications + ArgDown Instructions + Prompt + Source PDF for API Call"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1.3.0 --- Provider-Agnostic LLM API Interface ---\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Dict, List, Optional, Union, Any\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class LLMResponse:\n",
        "    \"\"\"Standard response object for LLM completions\"\"\"\n",
        "    content: str\n",
        "    model: str\n",
        "    usage: Dict[str, int]\n",
        "    raw_response: Dict[str, Any]\n",
        "    created_at: float = time.time()\n",
        "\n",
        "class LLMProvider(ABC):\n",
        "    \"\"\"Abstract base class for LLM providers\"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def complete(self,\n",
        "                prompt: str,\n",
        "                system_prompt: Optional[str] = None,\n",
        "                temperature: float = 0.7,\n",
        "                max_tokens: int = 4000) -> LLMResponse:\n",
        "        \"\"\"Generate a completion from the LLM\"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_available_models(self) -> List[str]:\n",
        "        \"\"\"Return a list of available models from this provider\"\"\"\n",
        "        pass\n",
        "\n",
        "class OpenAIProvider(LLMProvider):\n",
        "    \"\"\"OpenAI API implementation\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: Optional[str] = None, organization: Optional[str] = None):\n",
        "        \"\"\"Initialize with API key from args or environment\"\"\"\n",
        "        self.api_key = api_key or os.environ.get(\"OPENAI_API_KEY\")\n",
        "        if not self.api_key:\n",
        "            raise ValueError(\"OpenAI API key is required. Provide as argument or set OPENAI_API_KEY environment variable.\")\n",
        "\n",
        "        self.organization = organization or os.environ.get(\"OPENAI_ORGANIZATION\")\n",
        "        self.api_base = \"https://api.openai.com/v1\"\n",
        "\n",
        "    def complete(self,\n",
        "                prompt: str,\n",
        "                system_prompt: Optional[str] = None,\n",
        "                model: str = \"gpt-4-turbo\",\n",
        "                temperature: float = 0.7,\n",
        "                max_tokens: int = 4000) -> LLMResponse:\n",
        "        \"\"\"Generate a completion using OpenAI's API\"\"\"\n",
        "\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Authorization\": f\"Bearer {self.api_key}\"\n",
        "        }\n",
        "\n",
        "        if self.organization:\n",
        "            headers[\"OpenAI-Organization\"] = self.organization\n",
        "\n",
        "        messages = []\n",
        "        if system_prompt:\n",
        "            messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
        "\n",
        "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "        data = {\n",
        "            \"model\": model,\n",
        "            \"messages\": messages,\n",
        "            \"temperature\": temperature,\n",
        "            \"max_tokens\": max_tokens\n",
        "        }\n",
        "\n",
        "        response = requests.post(\n",
        "            f\"{self.api_base}/chat/completions\",\n",
        "            headers=headers,\n",
        "            json=data\n",
        "        )\n",
        "\n",
        "        response.raise_for_status()\n",
        "        result = response.json()\n",
        "\n",
        "        return LLMResponse(\n",
        "            content=result[\"choices\"][0][\"message\"][\"content\"],\n",
        "            model=result[\"model\"],\n",
        "            usage=result[\"usage\"],\n",
        "            raw_response=result\n",
        "        )\n",
        "\n",
        "    def get_available_models(self) -> List[str]:\n",
        "        \"\"\"Return a list of available OpenAI models\"\"\"\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {self.api_key}\"\n",
        "        }\n",
        "\n",
        "        if self.organization:\n",
        "            headers[\"OpenAI-Organization\"] = self.organization\n",
        "\n",
        "        response = requests.get(\n",
        "            f\"{self.api_base}/models\",\n",
        "            headers=headers\n",
        "        )\n",
        "\n",
        "        response.raise_for_status()\n",
        "        models = response.json()[\"data\"]\n",
        "        return [model[\"id\"] for model in models]\n",
        "\n",
        "class AnthropicProvider(LLMProvider):\n",
        "    \"\"\"Anthropic Claude API implementation\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: Optional[str] = None):\n",
        "        \"\"\"Initialize with API key from args or environment\"\"\"\n",
        "        self.api_key = api_key or os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "        if not self.api_key:\n",
        "            raise ValueError(\"Anthropic API key is required. Provide as argument or set ANTHROPIC_API_KEY environment variable.\")\n",
        "\n",
        "        self.api_base = \"https://api.anthropic.com/v1\"\n",
        "\n",
        "    def complete(self,\n",
        "                prompt: str,\n",
        "                system_prompt: Optional[str] = None,\n",
        "                model: str = \"claude-3-opus-20240229\",\n",
        "                temperature: float = 0.7,\n",
        "                max_tokens: int = 4000) -> LLMResponse:\n",
        "        \"\"\"Generate a completion using Anthropic's API\"\"\"\n",
        "\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"X-API-Key\": self.api_key,\n",
        "            \"anthropic-version\": \"2023-06-01\"\n",
        "        }\n",
        "\n",
        "        data = {\n",
        "            \"model\": model,\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "            \"temperature\": temperature,\n",
        "            \"max_tokens\": max_tokens\n",
        "        }\n",
        "\n",
        "        if system_prompt:\n",
        "            data[\"system\"] = system_prompt\n",
        "\n",
        "        response = requests.post(\n",
        "            f\"{self.api_base}/messages\",\n",
        "            headers=headers,\n",
        "            json=data\n",
        "        )\n",
        "\n",
        "        response.raise_for_status()\n",
        "        result = response.json()\n",
        "\n",
        "        return LLMResponse(\n",
        "            content=result[\"content\"][0][\"text\"],\n",
        "            model=result[\"model\"],\n",
        "            usage={\"prompt_tokens\": result.get(\"usage\", {}).get(\"input_tokens\", 0),\n",
        "                   \"completion_tokens\": result.get(\"usage\", {}).get(\"output_tokens\", 0)},\n",
        "            raw_response=result\n",
        "        )\n",
        "\n",
        "    def get_available_models(self) -> List[str]:\n",
        "        \"\"\"Return a list of available Anthropic models\"\"\"\n",
        "        # Anthropic doesn't have a models endpoint, so we return a static list\n",
        "        return [\n",
        "            \"claude-3-opus-20240229\",\n",
        "            \"claude-3-sonnet-20240229\",\n",
        "            \"claude-3-haiku-20240307\"\n",
        "        ]\n",
        "\n",
        "class LLMFactory:\n",
        "    \"\"\"Factory for creating LLM providers\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def create_provider(provider_name: str, **kwargs) -> LLMProvider:\n",
        "        \"\"\"Create and return an LLM provider instance\"\"\"\n",
        "        if provider_name.lower() == \"openai\":\n",
        "            return OpenAIProvider(**kwargs)\n",
        "        elif provider_name.lower() == \"anthropic\":\n",
        "            return AnthropicProvider(**kwargs)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported provider: {provider_name}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "T87yG6SH2-4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1.3.0 --- API Call Function Definitions ---\n",
        "\n",
        "def extract_argdown_from_text(text: str, provider_name: str = \"openai\", model: str = None) -> str:\n",
        "    \"\"\"\n",
        "    Extract ArgDown representation from text using LLM\n",
        "\n",
        "    Args:\n",
        "        text: The source text to extract arguments from\n",
        "        provider_name: The LLM provider to use (openai or anthropic)\n",
        "        model: Specific model to use, or None for default\n",
        "\n",
        "    Returns:\n",
        "        Extracted ArgDown representation\n",
        "    \"\"\"\n",
        "    # Create LLM provider\n",
        "    provider = LLMFactory.create_provider(provider_name)\n",
        "\n",
        "    # Get extraction prompt\n",
        "    prompt_template = PromptLibrary.get_template(\"ARGDOWN_EXTRACTION\")\n",
        "    prompt = prompt_template.format(text=text)\n",
        "\n",
        "    # Set model-specific parameters\n",
        "    if provider_name.lower() == \"openai\":\n",
        "        model = model or \"gpt-4-turbo\"\n",
        "        temperature = 0.3  # Lower temperature for more deterministic extraction\n",
        "        max_tokens = 4000\n",
        "    elif provider_name.lower() == \"anthropic\":\n",
        "        model = model or \"claude-3-opus-20240229\"\n",
        "        temperature = 0.2\n",
        "        max_tokens = 4000\n",
        "\n",
        "    # Call the LLM\n",
        "    system_prompt = \"You are an expert in argument mapping and causal reasoning.\"\n",
        "    response = provider.complete(\n",
        "        prompt=prompt,\n",
        "        system_prompt=system_prompt,\n",
        "        model=model,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "\n",
        "    # Extract the ArgDown content (remove any markdown code blocks if present)\n",
        "    argdown_content = response.content\n",
        "    if \"```\" in argdown_content:\n",
        "        # Extract content between code blocks if present\n",
        "        import re\n",
        "        matches = re.findall(r\"```(?:argdown)?\\n([\\s\\S]*?)\\n```\", argdown_content)\n",
        "        if matches:\n",
        "            argdown_content = matches[0]\n",
        "\n",
        "    return argdown_content\n",
        "\n",
        "def validate_argdown(argdown_text: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Validate ArgDown representation to ensure it's well-formed\n",
        "\n",
        "    Args:\n",
        "        argdown_text: ArgDown representation to validate\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with validation results\n",
        "    \"\"\"\n",
        "    # Initialize validation results\n",
        "    results = {\n",
        "        \"is_valid\": True,\n",
        "        \"errors\": [],\n",
        "        \"warnings\": [],\n",
        "        \"stats\": {\n",
        "            \"node_count\": 0,\n",
        "            \"relationship_count\": 0,\n",
        "            \"max_depth\": 0\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Basic syntax checks\n",
        "    lines = argdown_text.split(\"\\n\")\n",
        "    node_pattern = r'\\[(.*?)\\]:'\n",
        "    instantiation_pattern = r'{\"instantiations\":'\n",
        "\n",
        "    # Track nodes and relationships\n",
        "    nodes = set()\n",
        "    relationships = []\n",
        "    current_depth = 0\n",
        "    max_depth = 0\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        # Skip empty lines\n",
        "        if not line.strip():\n",
        "            continue\n",
        "\n",
        "        # Calculate indentation depth\n",
        "        indent = 0\n",
        "        if '+' in line:\n",
        "            indent = line.find('+') // 2\n",
        "\n",
        "        current_depth = indent\n",
        "        max_depth = max(max_depth, current_depth)\n",
        "\n",
        "        # Check for node definitions\n",
        "        import re\n",
        "        node_matches = re.findall(node_pattern, line)\n",
        "        if node_matches:\n",
        "            node = node_matches[0]\n",
        "            nodes.add(node)\n",
        "            results[\"stats\"][\"node_count\"] += 1\n",
        "\n",
        "            # Check for instantiations\n",
        "            if instantiation_pattern not in line:\n",
        "                results[\"warnings\"].append(f\"Line {i+1}: Node '{node}' is missing instantiations metadata\")\n",
        "\n",
        "        # Check parent-child relationships\n",
        "        if indent > 0 and '+' in line and node_matches:\n",
        "            # This is a child node; find its parent\n",
        "            parent_indent = indent - 1\n",
        "            j = i - 1\n",
        "            while j >= 0:\n",
        "                if '+' in lines[j] and lines[j].find('+') // 2 == parent_indent:\n",
        "                    parent_matches = re.findall(node_pattern, lines[j])\n",
        "                    if parent_matches:\n",
        "                        parent = parent_matches[0]\n",
        "                        relationships.append((parent, node))\n",
        "                        results[\"stats\"][\"relationship_count\"] += 1\n",
        "                        break\n",
        "                j -= 1\n",
        "\n",
        "    results[\"stats\"][\"max_depth\"] = max_depth\n",
        "\n",
        "    # If we didn't find any nodes, that's a problem\n",
        "    if results[\"stats\"][\"node_count\"] == 0:\n",
        "        results[\"is_valid\"] = False\n",
        "        results[\"errors\"].append(\"No valid nodes found in ArgDown representation\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def process_source_document(file_path: str, provider_name: str = \"openai\") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Process a source document to extract ArgDown representation\n",
        "\n",
        "    Args:\n",
        "        file_path: Path to the source document\n",
        "        provider_name: The LLM provider to use\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with extraction results\n",
        "    \"\"\"\n",
        "    # Load the source document\n",
        "    text = \"\"\n",
        "    if file_path.endswith(\".pdf\"):\n",
        "        # PDF handling requires additional libraries\n",
        "        try:\n",
        "            import PyPDF2\n",
        "            with open(file_path, 'rb') as file:\n",
        "                reader = PyPDF2.PdfReader(file)\n",
        "                text = \"\"\n",
        "                for page in reader.pages:\n",
        "                    text += page.extract_text() + \"\\n\"\n",
        "        except ImportError:\n",
        "            raise ImportError(\"PyPDF2 is required for PDF processing. Install it with: pip install PyPDF2\")\n",
        "    elif file_path.endswith(\".txt\"):\n",
        "        with open(file_path, 'r') as file:\n",
        "            text = file.read()\n",
        "    elif file_path.endswith(\".md\"):\n",
        "        with open(file_path, 'r') as file:\n",
        "            text = file.read()\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file format: {file_path}\")\n",
        "\n",
        "    # Extract ArgDown\n",
        "    argdown_content = extract_argdown_from_text(text, provider_name)\n",
        "\n",
        "    # Validate the extraction\n",
        "    validation_results = validate_argdown(argdown_content)\n",
        "\n",
        "    # Prepare results\n",
        "    results = {\n",
        "        \"source_path\": file_path,\n",
        "        \"extraction_timestamp\": time.time(),\n",
        "        \"argdown_content\": argdown_content,\n",
        "        \"validation\": validation_results,\n",
        "        \"provider\": provider_name\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "def save_argdown_extraction(results: Dict[str, Any], output_path: str) -> None:\n",
        "    \"\"\"\n",
        "    Save ArgDown extraction results\n",
        "\n",
        "    Args:\n",
        "        results: Extraction results dictionary\n",
        "        output_path: Path to save the results\n",
        "    \"\"\"\n",
        "    # Save the ArgDown content\n",
        "    with open(output_path, 'w') as file:\n",
        "        file.write(results[\"argdown_content\"])\n",
        "\n",
        "    # Save metadata alongside\n",
        "    metadata_path = output_path.replace('.md', '_metadata.json')\n",
        "    metadata = {\n",
        "        \"source_path\": results[\"source_path\"],\n",
        "        \"extraction_timestamp\": results[\"extraction_timestamp\"],\n",
        "        \"validation\": results[\"validation\"],\n",
        "        \"provider\": results[\"provider\"]\n",
        "    }\n",
        "\n",
        "    with open(metadata_path, 'w') as file:\n",
        "        json.dump(metadata, file, indent=2)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LkZDjGLJ183D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1.3 --- Prepare LLM API Call ---\n",
        "def prepare_extraction_call(source_path, provider_name=\"openai\", model=None):\n",
        "    \"\"\"Prepare the LLM API call for ArgDown extraction\"\"\"\n",
        "\n",
        "    # Load the source document\n",
        "    print(f\"Processing source document: {source_path}\")\n",
        "\n",
        "    # Determine provider and model\n",
        "    provider = provider_name.lower()\n",
        "    if provider not in [\"openai\", \"anthropic\"]:\n",
        "        raise ValueError(f\"Unsupported provider: {provider}. Use 'openai' or 'anthropic'.\")\n",
        "\n",
        "    # Set default model if none provided\n",
        "    if model is None:\n",
        "        if provider == \"openai\":\n",
        "            model = \"gpt-4-turbo\"\n",
        "        elif provider == \"anthropic\":\n",
        "            model = \"claude-3-opus-20240229\"\n",
        "\n",
        "    # Print configuration\n",
        "    print(f\"Using provider: {provider}\")\n",
        "    print(f\"Selected model: {model}\")\n",
        "\n",
        "    return {\n",
        "        \"source_path\": source_path,\n",
        "        \"provider\": provider,\n",
        "        \"model\": model\n",
        "    }\n",
        "\n",
        "# Usage example:\n",
        "source_path = \"example_document.pdf\"  # Replace with actual document path\n",
        "extraction_config = prepare_extraction_call(source_path, provider_name=\"openai\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "aKselXiIqeIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5xsDYnsAWC4"
      },
      "source": [
        "## 1.4 Make ArgDown Extraction LLM API Call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "d80R85UyAfKh",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title 1.4 --- Make ArgDown Extraction LLM API Call ---\n",
        "def execute_extraction(extraction_config):\n",
        "    \"\"\"Execute the ArgDown extraction using the LLM API\"\"\"\n",
        "\n",
        "    print(f\"Starting extraction from {extraction_config['source_path']}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        # Process the document\n",
        "        results = process_source_document(\n",
        "            extraction_config[\"source_path\"],\n",
        "            provider_name=extraction_config[\"provider\"]\n",
        "        )\n",
        "\n",
        "        # Print success message\n",
        "        elapsed_time = time.time() - start_time\n",
        "        print(f\"Extraction completed in {elapsed_time:.2f} seconds\")\n",
        "        print(f\"Extracted {results['validation']['stats']['node_count']} nodes with \"\n",
        "              f\"{results['validation']['stats']['relationship_count']} relationships\")\n",
        "\n",
        "        # Print any warnings\n",
        "        if results['validation']['warnings']:\n",
        "            print(\"\\nWarnings:\")\n",
        "            for warning in results['validation']['warnings']:\n",
        "                print(f\"- {warning}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during extraction: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# Usage example:\n",
        "extraction_results = execute_extraction(extraction_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc2nMp8nAfeU"
      },
      "source": [
        "## 1.5 Save ArgDown Extraction Response\n",
        "\n",
        "1. Save and log API return\n",
        "\n",
        "2. Save ArgDown.md file for further Proecessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-BiLLNymAz3c",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title 1.5 --- Save ArgDown Extraction Response ---\n",
        "\n",
        "def save_extraction_results(results, output_directory=\"./outputs\"):\n",
        "    \"\"\"Save the extraction results to file\"\"\"\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    import os\n",
        "    os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "    # Create base filename from source\n",
        "    import os.path\n",
        "    base_name = os.path.basename(results[\"source_path\"]).split('.')[0]\n",
        "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    output_filename = f\"{base_name}_argdown_{timestamp}.md\"\n",
        "    output_path = os.path.join(output_directory, output_filename)\n",
        "\n",
        "    # Save the results\n",
        "    save_argdown_extraction(results, output_path)\n",
        "\n",
        "    print(f\"Saved ArgDown extraction to: {output_path}\")\n",
        "    print(f\"Metadata saved to: {output_path.replace('.md', '_metadata.json')}\")\n",
        "\n",
        "    # Also save to standard location for further processing\n",
        "    standard_path = os.path.join(output_directory, \"ArgDown.md\")\n",
        "    with open(standard_path, 'w') as f:\n",
        "        f.write(results[\"argdown_content\"])\n",
        "    print(f\"Also saved to standard location: {standard_path}\")\n",
        "\n",
        "    return output_path\n",
        "\n",
        "# Usage example:\n",
        "output_path = save_extraction_results(extraction_results)\n",
        "\n",
        "# Preview the extracted ArgDown\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Display the first 500 characters of the extracted ArgDown\n",
        "preview = extraction_results[\"argdown_content\"][:500] + \"...\" if len(extraction_results[\"argdown_content\"]) > 500 else extraction_results[\"argdown_content\"]\n",
        "display(Markdown(f\"## Extracted ArgDown Preview\\n\\n```\\n{preview}\\n```\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HcCfqE4A0ht"
      },
      "source": [
        "## 1.6 Review and Check ArgDown.md File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "collapsed": true,
        "id": "MgxYW5al-e0u",
        "outputId": "00234486-06bc-4c2a-884a-6871477f6c49"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "[Grass_Wet]: Concentrated moisture on, between and around the blades of grass.{\"instantiations\": [\"grass_wet_TRUE\", \"grass_wet_FALSE\"]} \n +[Rain]: Tears of angles crying high up in the skies hitting the ground.{\"instantiations\": [\"rain_TRUE\", \"rain_FALSE\"]} \n +[Sprinkler]: Activation of a centrifugal force based CO2 droplet distribution system.{\"instantiations\": [\"sprinkler_TRUE\", \"sprinkler_FALSE\"]} \n  +[Rain]\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(Markdown(md_content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSpkvLbCC_PI"
      },
      "source": [
        "## 1.6.2 Check the Graph Structure with the ArgDown Sandbox Online\n",
        "Copy and paste the BayesDown formatted ... in the ArgDown Sandbox below to quickly verify that the network renders correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "7_jAnBjf4e4P",
        "outputId": "5cffd304-188d-4fc4-fee5-c015d6aca953"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7c19fc282790>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"600px\"\n",
              "            src=\"https://argdown.org/sandbox/map/\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# @title 1.6.2 --- ArgDown Online Sandbox ---\n",
        "\n",
        "from IPython.display import IFrame\n",
        "\n",
        "IFrame(src=\"https://argdown.org/sandbox/map/\", width=\"100%\", height=\"600px\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAm0UKpeBvyr"
      },
      "source": [
        "## 1.7 Extract ArgDown Graph Information as DataFrame\n",
        "\n",
        "Extract:\n",
        "\n",
        "\n",
        "*   Nodes (Variable_Title)\n",
        "*   Edges (Parents)\n",
        "*   Instantiations\n",
        "*   Description\n",
        "\n",
        "Implementation nodes:\n",
        "- One function for ArgDown and BayesDown extraction, but:\n",
        "- IF YOU ONLY WANT ARGDOWN EXTRACTION: USE ARGUMENT IN FUNCTION CALL \"parse_markdown_hierarchy(markdown_text, ArgDown = True)\"\n",
        "- so if you set ArgDown = True, it gives you only instantiations, no probabilities.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LTDQOBd7COIm",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title 1.7 --- Parsing ArgDown & BayesDown (.md to .csv) ---\n",
        "\n",
        "def parse_markdown_hierarchy_fixed(markdown_text, ArgDown = False):\n",
        "    \"\"\"Main function to parse markdown hierarchy into a DataFrame with correct parent-child relationships\"\"\"\n",
        "\n",
        "    # Remove comments\n",
        "    clean_text = remove_comments(markdown_text)\n",
        "\n",
        "    # Extract all titles with their descriptions and indentation levels\n",
        "    titles_info = extract_titles_info(clean_text)\n",
        "\n",
        "    # Establish parent-child relationships - Use fixed function here\n",
        "    titles_with_relations = establish_relationships_fixed(titles_info, clean_text)\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = convert_to_dataframe(titles_with_relations, ArgDown)\n",
        "\n",
        "    # Add No_Parent and No_Children columns\n",
        "    df = add_no_parent_no_child_columns_to_df(df)\n",
        "\n",
        "    # Add Parents instantiation columns\n",
        "    df = add_parents_instantiation_columns_to_df(df)\n",
        "\n",
        "    return df\n",
        "\n",
        "def remove_comments(markdown_text):\n",
        "    \"\"\"Remove comment blocks from markdown text\"\"\"\n",
        "    return re.sub(r'/\\*.*?\\*/', '', markdown_text, flags=re.DOTALL)\n",
        "\n",
        "def extract_titles_info(text):\n",
        "    \"\"\"Extract titles with their descriptions and indentation levels\"\"\"\n",
        "    lines = text.split('\\n')\n",
        "    titles_info = {}\n",
        "\n",
        "    for line in lines:\n",
        "        if not line.strip():\n",
        "            continue\n",
        "\n",
        "        title_match = re.search(r'[<\\[](.+?)[>\\]]', line)\n",
        "        if not title_match:\n",
        "            continue\n",
        "\n",
        "        title = title_match.group(1)\n",
        "\n",
        "        # Extract description and metadata\n",
        "        title_pattern_in_line = r'[<\\[]' + re.escape(title) + r'[>\\]]:'\n",
        "        description_match = re.search(title_pattern_in_line + r'\\s*(.*)', line)\n",
        "\n",
        "        if description_match:\n",
        "            full_text = description_match.group(1).strip()\n",
        "\n",
        "            # Check if description contains a \"{\" to not include metadata in description\n",
        "            if \"{\" in full_text:\n",
        "                # Split at the first \"{\"\n",
        "                split_index = full_text.find(\"{\")\n",
        "                description = full_text[:split_index].strip()\n",
        "                metadata = full_text[split_index:].strip()\n",
        "            else:\n",
        "                # Keep the entire description and no metadata\n",
        "                description = full_text\n",
        "                metadata = ''\n",
        "        else:\n",
        "            description = ''\n",
        "            metadata = ''  # Ensure metadata is initialized as empty string\n",
        "\n",
        "        indentation = 0\n",
        "        if '+' in line:\n",
        "            symbol_index = line.find('+')\n",
        "            # Count spaces before the '+' symbol\n",
        "            i = symbol_index - 1\n",
        "            while i >= 0 and line[i] == ' ':\n",
        "                indentation += 1\n",
        "                i -= 1\n",
        "        elif '-' in line:\n",
        "            symbol_index = line.find('-')\n",
        "            # Count spaces before the '-' symbol\n",
        "            i = symbol_index - 1\n",
        "            while i >= 0 and line[i] == ' ':\n",
        "                indentation += 1\n",
        "                i -= 1\n",
        "\n",
        "        # If neither symbol exists, indentation remains 0\n",
        "\n",
        "        if title in titles_info:\n",
        "            # Only update description if it's currently empty and we found a new one\n",
        "            if not titles_info[title]['description'] and description:\n",
        "                titles_info[title]['description'] = description\n",
        "\n",
        "            # Store all indentation levels for this title\n",
        "            titles_info[title]['indentation_levels'].append(indentation)\n",
        "\n",
        "            # Keep max indentation for backward compatibility\n",
        "            if indentation > titles_info[title]['indentation']:\n",
        "                titles_info[title]['indentation'] = indentation\n",
        "\n",
        "            # Do NOT update metadata here - keep the original metadata\n",
        "        else:\n",
        "            # First time seeing this title, create a new entry\n",
        "            titles_info[title] = {\n",
        "                'description': description,\n",
        "                'indentation': indentation,\n",
        "                'indentation_levels': [indentation],  # Initialize with first indentation level\n",
        "                'parents': [],\n",
        "                'children': [],\n",
        "                'line': None,\n",
        "                'line_numbers': [],  # Initialize an empty list for all occurrences\n",
        "                'metadata': metadata  # Set metadata explicitly from what we found\n",
        "            }\n",
        "\n",
        "    return titles_info\n",
        "\n",
        "def establish_relationships_fixed(titles_info, text):\n",
        "    \"\"\"\n",
        "    Establish parent-child relationships between titles using BayesDown indentation rules.\n",
        "\n",
        "    In BayesDown syntax:\n",
        "    - More indented nodes (with + symbol) are PARENTS of less indented nodes\n",
        "    - The relationship reads as \"Effect is caused by Cause\" (Effect + Cause)\n",
        "    - This aligns with how Bayesian networks represent causality\n",
        "    \"\"\"\n",
        "    lines = text.split('\\n')\n",
        "\n",
        "    # Dictionary to store line numbers for each title occurrence\n",
        "    title_occurrences = {}\n",
        "\n",
        "    # Record line number for each title (including multiple occurrences)\n",
        "    line_number = 0\n",
        "    for line in lines:\n",
        "        if not line.strip():\n",
        "            line_number += 1\n",
        "            continue\n",
        "\n",
        "        title_match = re.search(r'[<\\[](.+?)[>\\]]', line)\n",
        "        if not title_match:\n",
        "            line_number += 1\n",
        "            continue\n",
        "\n",
        "        title = title_match.group(1)\n",
        "\n",
        "        # Store all occurrences of each title with their line numbers\n",
        "        if title not in title_occurrences:\n",
        "            title_occurrences[title] = []\n",
        "        title_occurrences[title].append(line_number)\n",
        "\n",
        "        # Store all line numbers where this title appears\n",
        "        if 'line_numbers' not in titles_info[title]:\n",
        "            titles_info[title]['line_numbers'] = []\n",
        "        titles_info[title]['line_numbers'].append(line_number)\n",
        "\n",
        "        # For backward compatibility, keep the first occurrence in 'line'\n",
        "        if titles_info[title]['line'] is None:\n",
        "            titles_info[title]['line'] = line_number\n",
        "\n",
        "        line_number += 1\n",
        "\n",
        "    # Create an ordered list of all title occurrences with their line numbers\n",
        "    all_occurrences = []\n",
        "    for title, occurrences in title_occurrences.items():\n",
        "        for line_num in occurrences:\n",
        "            all_occurrences.append((title, line_num))\n",
        "\n",
        "    # Sort occurrences by line number\n",
        "    all_occurrences.sort(key=lambda x: x[1])\n",
        "\n",
        "    # Get indentation for each occurrence\n",
        "    occurrence_indents = {}\n",
        "    for title, line_num in all_occurrences:\n",
        "        for line in lines[line_num:line_num+1]:  # Only check the current line\n",
        "            indent = 0\n",
        "            if '+' in line:\n",
        "                symbol_index = line.find('+')\n",
        "                # Count spaces before the '+' symbol\n",
        "                j = symbol_index - 1\n",
        "                while j >= 0 and line[j] == ' ':\n",
        "                    indent += 1\n",
        "                    j -= 1\n",
        "            elif '-' in line:\n",
        "                symbol_index = line.find('-')\n",
        "                # Count spaces before the '-' symbol\n",
        "                j = symbol_index - 1\n",
        "                while j >= 0 and line[j] == ' ':\n",
        "                    indent += 1\n",
        "                    j -= 1\n",
        "            occurrence_indents[(title, line_num)] = indent\n",
        "\n",
        "    # REMOVED: The problematic forward pass that was reversing relationships\n",
        "\n",
        "    # Enhanced backward pass for correct parent-child relationships\n",
        "    for i, (title, line_num) in enumerate(all_occurrences):\n",
        "        current_indent = occurrence_indents[(title, line_num)]\n",
        "\n",
        "        # Skip root nodes (indentation 0) for processing\n",
        "        if current_indent == 0:\n",
        "            continue\n",
        "\n",
        "        # Look for the immediately preceding node with lower indentation\n",
        "        j = i - 1\n",
        "        while j >= 0:\n",
        "            prev_title, prev_line = all_occurrences[j]\n",
        "            prev_indent = occurrence_indents[(prev_title, prev_line)]\n",
        "\n",
        "            # If we find a node with less indentation, it's a child of current node\n",
        "            if prev_indent < current_indent:\n",
        "                # In BayesDown: More indented node is a parent (cause) of less indented node (effect)\n",
        "                if title not in titles_info[prev_title]['parents']:\n",
        "                    titles_info[prev_title]['parents'].append(title)\n",
        "                if prev_title not in titles_info[title]['children']:\n",
        "                    titles_info[title]['children'].append(prev_title)\n",
        "\n",
        "                # Only need to find the immediate child (closest preceding node with lower indentation)\n",
        "                break\n",
        "\n",
        "            j -= 1\n",
        "\n",
        "    return titles_info\n",
        "\n",
        "def convert_to_dataframe(titles_info, ArgDown):\n",
        "    \"\"\"Convert the titles information dictionary to a pandas DataFrame\"\"\"\n",
        "    if ArgDown == True:\n",
        "        df = pd.DataFrame(columns=['Title', 'Description', 'line', 'line_numbers', 'indentation',\n",
        "                               'indentation_levels', 'Parents', 'Children', 'instantiations'])\n",
        "    else:\n",
        "        df = pd.DataFrame(columns=['Title', 'Description', 'line', 'line_numbers', 'indentation',\n",
        "                               'indentation_levels', 'Parents', 'Children', 'instantiations',\n",
        "                               'priors', 'posteriors'])\n",
        "\n",
        "    for title, info in titles_info.items():\n",
        "        # Parse the metadata JSON string into a Python dictionary\n",
        "        if 'metadata' in info and info['metadata']:\n",
        "            try:\n",
        "                # Only try to parse if metadata is not empty\n",
        "                if info['metadata'].strip():\n",
        "                    jsonMetadata = json.loads(info['metadata'])\n",
        "                    if ArgDown == True:\n",
        "                        # Create the row dictionary with instantitions as metadata only, no probabilites yet\n",
        "                        row = {\n",
        "                            'Title': title,\n",
        "                            'Description': info.get('description', ''),\n",
        "                            'line': info.get('line',''),\n",
        "                            'line_numbers': info.get('line_numbers', []),\n",
        "                            'indentation': info.get('indentation',''),\n",
        "                            'indentation_levels': info.get('indentation_levels', []),\n",
        "                            'Parents': info.get('parents', []),\n",
        "                            'Children': info.get('children', []),\n",
        "                            # Extract specific metadata fields, defaulting to empty if not present\n",
        "                            'instantiations': jsonMetadata.get('instantiations', []),\n",
        "                        }\n",
        "\n",
        "\n",
        "                    else:\n",
        "                        # create dict with probabilites\n",
        "                        row = {\n",
        "                            'Title': title,\n",
        "                            'Description': info.get('description', ''),\n",
        "                            'line': info.get('line',''),\n",
        "                            'line_numbers': info.get('line_numbers', []),\n",
        "                            'indentation': info.get('indentation',''),\n",
        "                            'indentation_levels': info.get('indentation_levels', []),\n",
        "                            'Parents': info.get('parents', []),\n",
        "                            'Children': info.get('children', []),\n",
        "                            # Extract specific metadata fields, defaulting to empty if not present\n",
        "                            'instantiations': jsonMetadata.get('instantiations', []),\n",
        "                            'priors': jsonMetadata.get('priors', {}),\n",
        "                            'posteriors': jsonMetadata.get('posteriors', {})\n",
        "                        }\n",
        "                else:\n",
        "                    # Empty metadata case\n",
        "                    row = {\n",
        "                        'Title': title,\n",
        "                        'Description': info.get('description', ''),\n",
        "                        'line': info.get('line',''),\n",
        "                        'line_numbers': info.get('line_numbers', []),\n",
        "                        'indentation': info.get('indentation',''),\n",
        "                        'indentation_levels': info.get('indentation_levels', []),\n",
        "                        'Parents': info.get('parents', []),\n",
        "                        'Children': info.get('children', []),\n",
        "                        'instantiations': [],\n",
        "                        'priors': {},\n",
        "                        'posteriors': {}\n",
        "                    }\n",
        "            except json.JSONDecodeError:\n",
        "                # Handle case where metadata isn't valid JSON\n",
        "                row = {\n",
        "                    'Title': title,\n",
        "                    'Description': info.get('description', ''),\n",
        "                    'line': info.get('line',''),\n",
        "                    'line_numbers': info.get('line_numbers', []),\n",
        "                    'indentation': info.get('indentation',''),\n",
        "                    'indentation_levels': info.get('indentation_levels', []),\n",
        "                    'Parents': info.get('parents', []),\n",
        "                    'Children': info.get('children', []),\n",
        "                    'instantiations': [],\n",
        "                    'priors': {},\n",
        "                    'posteriors': {}\n",
        "                }\n",
        "        else:\n",
        "            # Handle case where metadata field doesn't exist or is empty\n",
        "            row = {\n",
        "                'Title': title,\n",
        "                'Description': info.get('description', ''),\n",
        "                'line': info.get('line',''),\n",
        "                'line_numbers': info.get('line_numbers', []),\n",
        "                'indentation': info.get('indentation',''),\n",
        "                'indentation_levels': info.get('indentation_levels', []),\n",
        "                'Parents': info.get('parents', []),\n",
        "                'Children': info.get('children', []),\n",
        "                'instantiations': [],\n",
        "                'priors': {},\n",
        "                'posteriors': {}\n",
        "            }\n",
        "\n",
        "        # Add the row to the DataFrame\n",
        "        df.loc[len(df)] = row\n",
        "\n",
        "    return df\n",
        "\n",
        "def add_no_parent_no_child_columns_to_df(dataframe):\n",
        "    \"\"\"Add No_Parent and No_Children boolean columns to the DataFrame\"\"\"\n",
        "    no_parent = []\n",
        "    no_children = []\n",
        "\n",
        "    for _, row in dataframe.iterrows():\n",
        "        no_parent.append(not row['Parents'])\n",
        "        no_children.append(not row['Children'])\n",
        "\n",
        "    dataframe['No_Parent'] = no_parent\n",
        "    dataframe['No_Children'] = no_children\n",
        "\n",
        "    return dataframe\n",
        "\n",
        "def add_parents_instantiation_columns_to_df(dataframe):\n",
        "    \"\"\"Add all possible instantiations of all parents as list with lists column to the DataFrame\"\"\"\n",
        "    # Create a new column to store parent instantiations\n",
        "    parent_instantiations = []\n",
        "\n",
        "    # Iterate through each row in the dataframe\n",
        "    for _, row in dataframe.iterrows():\n",
        "        parents = row['Parents']\n",
        "        parent_insts = []\n",
        "\n",
        "        # For each parent, find its instantiations and add to the list\n",
        "        for parent in parents:\n",
        "            # Find the row where Title matches the parent\n",
        "            parent_row = dataframe[dataframe['Title'] == parent]\n",
        "\n",
        "            # If parent found in the dataframe\n",
        "            if not parent_row.empty:\n",
        "                # Get the instantiations of this parent\n",
        "                parent_instantiation = parent_row['instantiations'].iloc[0]\n",
        "                parent_insts.append(parent_instantiation)\n",
        "\n",
        "        # Add the list of parent instantiations to our new column\n",
        "        parent_instantiations.append(parent_insts)\n",
        "\n",
        "    # Add the new column to the dataframe\n",
        "    dataframe['parent_instantiations'] = parent_instantiations\n",
        "\n",
        "    return dataframe\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ibjjJ34v3sQn",
        "outputId": "482f27eb-02dc-434c-a510-a6d0f864eddb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Title                                        Description  line  \\\n",
              "0  Grass_Wet  Concentrated moisture on, between and around t...     0   \n",
              "1       Rain  Tears of angles crying high up in the skies hi...     1   \n",
              "2  Sprinkler  Activation of a centrifugal force based CO2 dr...     2   \n",
              "\n",
              "  line_numbers  indentation indentation_levels            Parents  \\\n",
              "0          [0]            0                [0]  [Rain, Sprinkler]   \n",
              "1       [1, 3]            2             [1, 2]                 []   \n",
              "2          [2]            1                [1]             [Rain]   \n",
              "\n",
              "                 Children                     instantiations  No_Parent  \\\n",
              "0                      []  [grass_wet_TRUE, grass_wet_FALSE]      False   \n",
              "1  [Grass_Wet, Sprinkler]            [rain_TRUE, rain_FALSE]       True   \n",
              "2             [Grass_Wet]  [sprinkler_TRUE, sprinkler_FALSE]      False   \n",
              "\n",
              "   No_Children                              parent_instantiations  \n",
              "0         True  [[rain_TRUE, rain_FALSE], [sprinkler_TRUE, spr...  \n",
              "1        False                                                 []  \n",
              "2        False                          [[rain_TRUE, rain_FALSE]]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1818d55a-a8d5-4fad-a533-be1afc09f7e8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>line</th>\n",
              "      <th>line_numbers</th>\n",
              "      <th>indentation</th>\n",
              "      <th>indentation_levels</th>\n",
              "      <th>Parents</th>\n",
              "      <th>Children</th>\n",
              "      <th>instantiations</th>\n",
              "      <th>No_Parent</th>\n",
              "      <th>No_Children</th>\n",
              "      <th>parent_instantiations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Grass_Wet</td>\n",
              "      <td>Concentrated moisture on, between and around t...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[Rain, Sprinkler]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[grass_wet_TRUE, grass_wet_FALSE]</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>[[rain_TRUE, rain_FALSE], [sprinkler_TRUE, spr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rain</td>\n",
              "      <td>Tears of angles crying high up in the skies hi...</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 3]</td>\n",
              "      <td>2</td>\n",
              "      <td>[1, 2]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[Grass_Wet, Sprinkler]</td>\n",
              "      <td>[rain_TRUE, rain_FALSE]</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sprinkler</td>\n",
              "      <td>Activation of a centrifugal force based CO2 dr...</td>\n",
              "      <td>2</td>\n",
              "      <td>[2]</td>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[Rain]</td>\n",
              "      <td>[Grass_Wet]</td>\n",
              "      <td>[sprinkler_TRUE, sprinkler_FALSE]</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>[[rain_TRUE, rain_FALSE]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1818d55a-a8d5-4fad-a533-be1afc09f7e8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1818d55a-a8d5-4fad-a533-be1afc09f7e8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1818d55a-a8d5-4fad-a533-be1afc09f7e8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5a44f490-329d-420f-aa26-a597e06c96e2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5a44f490-329d-420f-aa26-a597e06c96e2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5a44f490-329d-420f-aa26-a597e06c96e2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b97a5578-ab39-42a8-8737-3d20dcc8f36f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ex_csv')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b97a5578-ab39-42a8-8737-3d20dcc8f36f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ex_csv');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ex_csv",
              "summary": "{\n  \"name\": \"ex_csv\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Grass_Wet\",\n          \"Rain\",\n          \"Sprinkler\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Concentrated moisture on, between and around the blades of grass.\",\n          \"Tears of angles crying high up in the skies hitting the ground.\",\n          \"Activation of a centrifugal force based CO2 droplet distribution system.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"line\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"line_numbers\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"indentation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"indentation_levels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Parents\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Children\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instantiations\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"No_Parent\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"No_Children\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"parent_instantiations\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# example use case:\n",
        "ex_csv = parse_markdown_hierarchy_fixed(md_content, ArgDown = True)\n",
        "ex_csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFC6oiyICREn"
      },
      "source": [
        "## 1.8 Store ArgDown Information as 'ArgDown.csv' file"
      ]
    },
    {
      "source": [
        "# Assuming 'md_content' holds the markdown text\n",
        "# Store the results of running the function parse_markdown_hierarchy(md_content, ArgDown = True) as the file 'ArgDown.csv'\n",
        "result_df = parse_markdown_hierarchy_fixed(md_content, ArgDown = True)\n",
        "\n",
        "# Save to CSV\n",
        "result_df.to_csv('ArgDown.csv', index=False)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "kysuz6rWU4o2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test if 'ArgDown.csv' has been saved correctly with the correct information\n",
        "# Load the data from the CSV file\n",
        "argdown_df = pd.read_csv('ArgDown.csv')\n",
        "\n",
        "# Display the DataFrame\n",
        "print(argdown_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Kg_GP5NLUaEG",
        "outputId": "7ce123e4-0957-42b6-85c8-25742883d8d1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Title                                        Description  line  \\\n",
            "0  Grass_Wet  Concentrated moisture on, between and around t...     0   \n",
            "1       Rain  Tears of angles crying high up in the skies hi...     1   \n",
            "2  Sprinkler  Activation of a centrifugal force based CO2 dr...     2   \n",
            "\n",
            "  line_numbers  indentation indentation_levels                Parents  \\\n",
            "0          [0]            0                [0]  ['Rain', 'Sprinkler']   \n",
            "1       [1, 3]            2             [1, 2]                     []   \n",
            "2          [2]            1                [1]               ['Rain']   \n",
            "\n",
            "                     Children                         instantiations  \\\n",
            "0                          []  ['grass_wet_TRUE', 'grass_wet_FALSE']   \n",
            "1  ['Grass_Wet', 'Sprinkler']            ['rain_TRUE', 'rain_FALSE']   \n",
            "2               ['Grass_Wet']  ['sprinkler_TRUE', 'sprinkler_FALSE']   \n",
            "\n",
            "   No_Parent  No_Children                              parent_instantiations  \n",
            "0      False         True  [['rain_TRUE', 'rain_FALSE'], ['sprinkler_TRUE...  \n",
            "1       True        False                                                 []  \n",
            "2      False        False                      [['rain_TRUE', 'rain_FALSE']]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SGB0XMp5VFq"
      },
      "source": [
        "# 2.0 Probability Extractions: ArgDown (.csv) to BayesDown (.md + plugin JSON syntax)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Probability Extraction Questions --- 'ArgDown.csv' to 'ArgDown_WithQuestions.csv'"
      ],
      "metadata": {
        "id": "WcF2nHXBZru4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "import itertools\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "\n",
        "\n",
        "def parse_instantiations(instantiations_str):\n",
        "    \"\"\"\n",
        "    Parse instantiations from string or list format.\n",
        "    Handles various input formats flexibly.\n",
        "    \"\"\"\n",
        "    if pd.isna(instantiations_str) or instantiations_str == '':\n",
        "        return []\n",
        "\n",
        "    if isinstance(instantiations_str, list):\n",
        "        return instantiations_str\n",
        "\n",
        "    try:\n",
        "        # Try to parse as JSON\n",
        "        return json.loads(instantiations_str)\n",
        "    except:\n",
        "        # Try to parse as string list\n",
        "        if isinstance(instantiations_str, str):\n",
        "            # Remove brackets and split by comma\n",
        "            clean_str = instantiations_str.strip('[]\"\\'')\n",
        "            if not clean_str:\n",
        "                return []\n",
        "            return [s.strip(' \"\\'') for s in clean_str.split(',') if s.strip()]\n",
        "\n",
        "    return []\n",
        "\n",
        "def parse_parents(parents_str):\n",
        "    \"\"\"\n",
        "    Parse parents from string or list format.\n",
        "    Handles various input formats flexibly.\n",
        "    \"\"\"\n",
        "    if pd.isna(parents_str) or parents_str == '':\n",
        "        return []\n",
        "\n",
        "    if isinstance(parents_str, list):\n",
        "        return parents_str\n",
        "\n",
        "    try:\n",
        "        # Try to parse as JSON\n",
        "        return json.loads(parents_str)\n",
        "    except:\n",
        "        # Try to parse as string list\n",
        "        if isinstance(parents_str, str):\n",
        "            # Remove brackets and split by comma\n",
        "            clean_str = parents_str.strip('[]\"\\'')\n",
        "            if not clean_str:\n",
        "                return []\n",
        "            return [s.strip(' \"\\'') for s in clean_str.split(',') if s.strip()]\n",
        "\n",
        "    return []\n",
        "\n",
        "def get_parent_instantiations(parent, df):\n",
        "    \"\"\"\n",
        "    Get the instantiations for a parent node from the DataFrame.\n",
        "    Returns default instantiations if not found.\n",
        "    \"\"\"\n",
        "    parent_row = df[df['Title'] == parent]\n",
        "    if parent_row.empty:\n",
        "        return [f\"{parent}_TRUE\", f\"{parent}_FALSE\"]\n",
        "\n",
        "    instantiations = parse_instantiations(parent_row.iloc[0]['instantiations'])\n",
        "    if not instantiations:\n",
        "        return [f\"{parent}_TRUE\", f\"{parent}_FALSE\"]\n",
        "\n",
        "    return instantiations\n",
        "\n",
        "def generate_instantiation_questions(title, instantiation, parents, df):\n",
        "    \"\"\"\n",
        "    Generate questions for a specific instantiation of a node.\n",
        "\n",
        "    Args:\n",
        "        title (str): The title of the node\n",
        "        instantiation (str): The specific instantiation (e.g., \"title_TRUE\")\n",
        "        parents (list): List of parent nodes\n",
        "        df (DataFrame): The full DataFrame for looking up parent instantiations\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary mapping questions to estimate keys\n",
        "    \"\"\"\n",
        "    questions = {}\n",
        "\n",
        "    # Always generate a prior probability question, regardless of parents\n",
        "    prior_question = f\"What is the probability for {title}={instantiation}?\"\n",
        "    questions[prior_question] = 'prior'  # Change here: question is the key, 'prior' is the value\n",
        "\n",
        "    # If no parents, return only the prior question\n",
        "    if not parents:\n",
        "        return questions\n",
        "\n",
        "    # For nodes with parents, generate conditional probability questions\n",
        "    # Get all combinations of parent instantiations\n",
        "    parent_instantiations = []\n",
        "    for parent in parents:\n",
        "        parent_insts = get_parent_instantiations(parent, df)\n",
        "        parent_instantiations.append([(parent, inst) for inst in parent_insts])\n",
        "\n",
        "    # Generate all combinations\n",
        "    all_combinations = list(itertools.product(*parent_instantiations))\n",
        "\n",
        "    # Create conditional probability questions for each combination\n",
        "    # and use questions as keys, estimate_i as values\n",
        "    for i, combination in enumerate(all_combinations):\n",
        "        condition_str = \", \".join([f\"{parent}={inst}\" for parent, inst in combination])\n",
        "        question = f\"What is the probability for {title}={instantiation} if {condition_str}?\"\n",
        "        questions[question] = f'estimate_{i + 1}'  # Change here: question is the key, estimate_i is the value\n",
        "\n",
        "    return questions\n",
        "\n",
        "\n",
        "def generate_argdown_with_questions(argdown_csv_path, output_csv_path):\n",
        "    \"\"\"\n",
        "    Generate probability questions based on the ArgDown CSV file and save to a new CSV file.\n",
        "\n",
        "    Args:\n",
        "        argdown_csv_path (str): Path to the input ArgDown CSV file\n",
        "        output_csv_path (str): Path to save the output CSV file with questions\n",
        "    \"\"\"\n",
        "    print(f\"Loading ArgDown CSV from {argdown_csv_path}...\")\n",
        "\n",
        "    # Load the ArgDown CSV file\n",
        "    try:\n",
        "        df = pd.read_csv(argdown_csv_path)\n",
        "        print(f\"Successfully loaded CSV with {len(df)} rows.\")\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Error loading ArgDown CSV: {e}\")\n",
        "\n",
        "    # Validate required columns\n",
        "    required_columns = ['Title', 'Parents', 'instantiations']\n",
        "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "    if missing_columns:\n",
        "        raise Exception(f\"Missing required columns: {', '.join(missing_columns)}\")\n",
        "\n",
        "    # Initialize columns for questions\n",
        "    df['Generate_Positive_Instantiation_Questions'] = None\n",
        "    df['Generate_Negative_Instantiation_Questions'] = None\n",
        "\n",
        "    print(\"Generating probability questions for each node...\")\n",
        "\n",
        "    # Process each row to generate questions\n",
        "    for idx, row in df.iterrows():\n",
        "        title = row['Title']\n",
        "        instantiations = parse_instantiations(row['instantiations'])\n",
        "        parents = parse_parents(row['Parents'])\n",
        "\n",
        "        if len(instantiations) < 2:\n",
        "            # Default instantiations if not provided\n",
        "            instantiations = [f\"{title}_TRUE\", f\"{title}_FALSE\"]\n",
        "\n",
        "        # Generate positive instantiation questions\n",
        "        positive_questions = generate_instantiation_questions(title, instantiations[0], parents, df)\n",
        "\n",
        "        # Generate negative instantiation questions\n",
        "        negative_questions = generate_instantiation_questions(title, instantiations[1], parents, df)\n",
        "\n",
        "        # Update the DataFrame\n",
        "        df.at[idx, 'Generate_Positive_Instantiation_Questions'] = json.dumps(positive_questions)\n",
        "        df.at[idx, 'Generate_Negative_Instantiation_Questions'] = json.dumps(negative_questions)\n",
        "\n",
        "    # Save the enhanced DataFrame\n",
        "    df.to_csv(output_csv_path, index=False)\n",
        "    print(f\"Generated questions saved to {output_csv_path}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Example usage:\n",
        "df_with_questions = generate_argdown_with_questions(\"ArgDown.csv\", \"ArgDown_WithQuestions.csv\")\n",
        "df_with_questions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "iVh-85KaYlyk",
        "outputId": "673efb09-4f3d-4014-d58c-277f6a3c7f50"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading ArgDown CSV from ArgDown.csv...\n",
            "Successfully loaded CSV with 3 rows.\n",
            "Generating probability questions for each node...\n",
            "Generated questions saved to ArgDown_WithQuestions.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Title                                        Description  line  \\\n",
              "0  Grass_Wet  Concentrated moisture on, between and around t...     0   \n",
              "1       Rain  Tears of angles crying high up in the skies hi...     1   \n",
              "2  Sprinkler  Activation of a centrifugal force based CO2 dr...     2   \n",
              "\n",
              "  line_numbers  indentation indentation_levels                Parents  \\\n",
              "0          [0]            0                [0]  ['Rain', 'Sprinkler']   \n",
              "1       [1, 3]            2             [1, 2]                     []   \n",
              "2          [2]            1                [1]               ['Rain']   \n",
              "\n",
              "                     Children                         instantiations  \\\n",
              "0                          []  ['grass_wet_TRUE', 'grass_wet_FALSE']   \n",
              "1  ['Grass_Wet', 'Sprinkler']            ['rain_TRUE', 'rain_FALSE']   \n",
              "2               ['Grass_Wet']  ['sprinkler_TRUE', 'sprinkler_FALSE']   \n",
              "\n",
              "   No_Parent  No_Children                              parent_instantiations  \\\n",
              "0      False         True  [['rain_TRUE', 'rain_FALSE'], ['sprinkler_TRUE...   \n",
              "1       True        False                                                 []   \n",
              "2      False        False                      [['rain_TRUE', 'rain_FALSE']]   \n",
              "\n",
              "           Generate_Positive_Instantiation_Questions  \\\n",
              "0  {\"What is the probability for Grass_Wet=grass_...   \n",
              "1  {\"What is the probability for Rain=rain_TRUE?\"...   \n",
              "2  {\"What is the probability for Sprinkler=sprink...   \n",
              "\n",
              "           Generate_Negative_Instantiation_Questions  \n",
              "0  {\"What is the probability for Grass_Wet=grass_...  \n",
              "1  {\"What is the probability for Rain=rain_FALSE?...  \n",
              "2  {\"What is the probability for Sprinkler=sprink...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f36268f9-e7c2-493f-8424-0dce0a9aa011\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>line</th>\n",
              "      <th>line_numbers</th>\n",
              "      <th>indentation</th>\n",
              "      <th>indentation_levels</th>\n",
              "      <th>Parents</th>\n",
              "      <th>Children</th>\n",
              "      <th>instantiations</th>\n",
              "      <th>No_Parent</th>\n",
              "      <th>No_Children</th>\n",
              "      <th>parent_instantiations</th>\n",
              "      <th>Generate_Positive_Instantiation_Questions</th>\n",
              "      <th>Generate_Negative_Instantiation_Questions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Grass_Wet</td>\n",
              "      <td>Concentrated moisture on, between and around t...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0</td>\n",
              "      <td>[0]</td>\n",
              "      <td>['Rain', 'Sprinkler']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['grass_wet_TRUE', 'grass_wet_FALSE']</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>[['rain_TRUE', 'rain_FALSE'], ['sprinkler_TRUE...</td>\n",
              "      <td>{\"What is the probability for Grass_Wet=grass_...</td>\n",
              "      <td>{\"What is the probability for Grass_Wet=grass_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rain</td>\n",
              "      <td>Tears of angles crying high up in the skies hi...</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 3]</td>\n",
              "      <td>2</td>\n",
              "      <td>[1, 2]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['Grass_Wet', 'Sprinkler']</td>\n",
              "      <td>['rain_TRUE', 'rain_FALSE']</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "      <td>{\"What is the probability for Rain=rain_TRUE?\"...</td>\n",
              "      <td>{\"What is the probability for Rain=rain_FALSE?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sprinkler</td>\n",
              "      <td>Activation of a centrifugal force based CO2 dr...</td>\n",
              "      <td>2</td>\n",
              "      <td>[2]</td>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>['Rain']</td>\n",
              "      <td>['Grass_Wet']</td>\n",
              "      <td>['sprinkler_TRUE', 'sprinkler_FALSE']</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>[['rain_TRUE', 'rain_FALSE']]</td>\n",
              "      <td>{\"What is the probability for Sprinkler=sprink...</td>\n",
              "      <td>{\"What is the probability for Sprinkler=sprink...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f36268f9-e7c2-493f-8424-0dce0a9aa011')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f36268f9-e7c2-493f-8424-0dce0a9aa011 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f36268f9-e7c2-493f-8424-0dce0a9aa011');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c321b8d9-e3c5-43fc-8aea-a6e42838691a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c321b8d9-e3c5-43fc-8aea-a6e42838691a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c321b8d9-e3c5-43fc-8aea-a6e42838691a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d6180a29-3681-4951-a2ed-0282a64e70e3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_with_questions')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d6180a29-3681-4951-a2ed-0282a64e70e3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_with_questions');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_with_questions",
              "summary": "{\n  \"name\": \"df_with_questions\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Grass_Wet\",\n          \"Rain\",\n          \"Sprinkler\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Concentrated moisture on, between and around the blades of grass.\",\n          \"Tears of angles crying high up in the skies hitting the ground.\",\n          \"Activation of a centrifugal force based CO2 droplet distribution system.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"line\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"line_numbers\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"[0]\",\n          \"[1, 3]\",\n          \"[2]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"indentation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"indentation_levels\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"[0]\",\n          \"[1, 2]\",\n          \"[1]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Parents\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"['Rain', 'Sprinkler']\",\n          \"[]\",\n          \"['Rain']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Children\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"[]\",\n          \"['Grass_Wet', 'Sprinkler']\",\n          \"['Grass_Wet']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instantiations\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"['grass_wet_TRUE', 'grass_wet_FALSE']\",\n          \"['rain_TRUE', 'rain_FALSE']\",\n          \"['sprinkler_TRUE', 'sprinkler_FALSE']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"No_Parent\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"No_Children\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"parent_instantiations\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"[['rain_TRUE', 'rain_FALSE'], ['sprinkler_TRUE', 'sprinkler_FALSE']]\",\n          \"[]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Generate_Positive_Instantiation_Questions\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"{\\\"What is the probability for Grass_Wet=grass_wet_TRUE?\\\": \\\"prior\\\", \\\"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_TRUE, Sprinkler=sprinkler_TRUE?\\\": \\\"estimate_1\\\", \\\"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_TRUE, Sprinkler=sprinkler_FALSE?\\\": \\\"estimate_2\\\", \\\"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_FALSE, Sprinkler=sprinkler_TRUE?\\\": \\\"estimate_3\\\", \\\"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_FALSE, Sprinkler=sprinkler_FALSE?\\\": \\\"estimate_4\\\"}\",\n          \"{\\\"What is the probability for Rain=rain_TRUE?\\\": \\\"prior\\\"}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Generate_Negative_Instantiation_Questions\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"{\\\"What is the probability for Grass_Wet=grass_wet_FALSE?\\\": \\\"prior\\\", \\\"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_TRUE, Sprinkler=sprinkler_TRUE?\\\": \\\"estimate_1\\\", \\\"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_TRUE, Sprinkler=sprinkler_FALSE?\\\": \\\"estimate_2\\\", \\\"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_FALSE, Sprinkler=sprinkler_TRUE?\\\": \\\"estimate_3\\\", \\\"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_FALSE, Sprinkler=sprinkler_FALSE?\\\": \\\"estimate_4\\\"}\",\n          \"{\\\"What is the probability for Rain=rain_FALSE?\\\": \\\"prior\\\"}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data from the ArgDown_WithQuestions CSV file\n",
        "argdown_with_questions_df = pd.read_csv('ArgDown_WithQuestions.csv')\n",
        "\n",
        "# Display the DataFrame\n",
        "print(argdown_with_questions_df)\n",
        "argdown_with_questions_df\n"
      ],
      "metadata": {
        "id": "tjMf54VcPPD4",
        "outputId": "0893ac59-f440-42b0-f283-2611b190d860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "collapsed": true
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Title                                        Description  line  \\\n",
            "0  Grass_Wet  Concentrated moisture on, between and around t...     0   \n",
            "1       Rain  Tears of angles crying high up in the skies hi...     1   \n",
            "2  Sprinkler  Activation of a centrifugal force based CO2 dr...     2   \n",
            "\n",
            "  line_numbers  indentation indentation_levels                Parents  \\\n",
            "0          [0]            0                [0]  ['Rain', 'Sprinkler']   \n",
            "1       [1, 3]            2             [1, 2]                     []   \n",
            "2          [2]            1                [1]               ['Rain']   \n",
            "\n",
            "                     Children                         instantiations  \\\n",
            "0                          []  ['grass_wet_TRUE', 'grass_wet_FALSE']   \n",
            "1  ['Grass_Wet', 'Sprinkler']            ['rain_TRUE', 'rain_FALSE']   \n",
            "2               ['Grass_Wet']  ['sprinkler_TRUE', 'sprinkler_FALSE']   \n",
            "\n",
            "   No_Parent  No_Children                              parent_instantiations  \\\n",
            "0      False         True  [['rain_TRUE', 'rain_FALSE'], ['sprinkler_TRUE...   \n",
            "1       True        False                                                 []   \n",
            "2      False        False                      [['rain_TRUE', 'rain_FALSE']]   \n",
            "\n",
            "           Generate_Positive_Instantiation_Questions  \\\n",
            "0  {\"What is the probability for Grass_Wet=grass_...   \n",
            "1  {\"What is the probability for Rain=rain_TRUE?\"...   \n",
            "2  {\"What is the probability for Sprinkler=sprink...   \n",
            "\n",
            "           Generate_Negative_Instantiation_Questions  \n",
            "0  {\"What is the probability for Grass_Wet=grass_...  \n",
            "1  {\"What is the probability for Rain=rain_FALSE?...  \n",
            "2  {\"What is the probability for Sprinkler=sprink...  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Title                                        Description  line  \\\n",
              "0  Grass_Wet  Concentrated moisture on, between and around t...     0   \n",
              "1       Rain  Tears of angles crying high up in the skies hi...     1   \n",
              "2  Sprinkler  Activation of a centrifugal force based CO2 dr...     2   \n",
              "\n",
              "  line_numbers  indentation indentation_levels                Parents  \\\n",
              "0          [0]            0                [0]  ['Rain', 'Sprinkler']   \n",
              "1       [1, 3]            2             [1, 2]                     []   \n",
              "2          [2]            1                [1]               ['Rain']   \n",
              "\n",
              "                     Children                         instantiations  \\\n",
              "0                          []  ['grass_wet_TRUE', 'grass_wet_FALSE']   \n",
              "1  ['Grass_Wet', 'Sprinkler']            ['rain_TRUE', 'rain_FALSE']   \n",
              "2               ['Grass_Wet']  ['sprinkler_TRUE', 'sprinkler_FALSE']   \n",
              "\n",
              "   No_Parent  No_Children                              parent_instantiations  \\\n",
              "0      False         True  [['rain_TRUE', 'rain_FALSE'], ['sprinkler_TRUE...   \n",
              "1       True        False                                                 []   \n",
              "2      False        False                      [['rain_TRUE', 'rain_FALSE']]   \n",
              "\n",
              "           Generate_Positive_Instantiation_Questions  \\\n",
              "0  {\"What is the probability for Grass_Wet=grass_...   \n",
              "1  {\"What is the probability for Rain=rain_TRUE?\"...   \n",
              "2  {\"What is the probability for Sprinkler=sprink...   \n",
              "\n",
              "           Generate_Negative_Instantiation_Questions  \n",
              "0  {\"What is the probability for Grass_Wet=grass_...  \n",
              "1  {\"What is the probability for Rain=rain_FALSE?...  \n",
              "2  {\"What is the probability for Sprinkler=sprink...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98eed15d-d2d2-4b34-b930-922a2b1704f7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>line</th>\n",
              "      <th>line_numbers</th>\n",
              "      <th>indentation</th>\n",
              "      <th>indentation_levels</th>\n",
              "      <th>Parents</th>\n",
              "      <th>Children</th>\n",
              "      <th>instantiations</th>\n",
              "      <th>No_Parent</th>\n",
              "      <th>No_Children</th>\n",
              "      <th>parent_instantiations</th>\n",
              "      <th>Generate_Positive_Instantiation_Questions</th>\n",
              "      <th>Generate_Negative_Instantiation_Questions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Grass_Wet</td>\n",
              "      <td>Concentrated moisture on, between and around t...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0</td>\n",
              "      <td>[0]</td>\n",
              "      <td>['Rain', 'Sprinkler']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['grass_wet_TRUE', 'grass_wet_FALSE']</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>[['rain_TRUE', 'rain_FALSE'], ['sprinkler_TRUE...</td>\n",
              "      <td>{\"What is the probability for Grass_Wet=grass_...</td>\n",
              "      <td>{\"What is the probability for Grass_Wet=grass_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rain</td>\n",
              "      <td>Tears of angles crying high up in the skies hi...</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 3]</td>\n",
              "      <td>2</td>\n",
              "      <td>[1, 2]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['Grass_Wet', 'Sprinkler']</td>\n",
              "      <td>['rain_TRUE', 'rain_FALSE']</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "      <td>{\"What is the probability for Rain=rain_TRUE?\"...</td>\n",
              "      <td>{\"What is the probability for Rain=rain_FALSE?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sprinkler</td>\n",
              "      <td>Activation of a centrifugal force based CO2 dr...</td>\n",
              "      <td>2</td>\n",
              "      <td>[2]</td>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>['Rain']</td>\n",
              "      <td>['Grass_Wet']</td>\n",
              "      <td>['sprinkler_TRUE', 'sprinkler_FALSE']</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>[['rain_TRUE', 'rain_FALSE']]</td>\n",
              "      <td>{\"What is the probability for Sprinkler=sprink...</td>\n",
              "      <td>{\"What is the probability for Sprinkler=sprink...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98eed15d-d2d2-4b34-b930-922a2b1704f7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-98eed15d-d2d2-4b34-b930-922a2b1704f7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-98eed15d-d2d2-4b34-b930-922a2b1704f7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4763fc1d-d42b-4e8b-8a0b-3cd4a2ba924e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4763fc1d-d42b-4e8b-8a0b-3cd4a2ba924e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4763fc1d-d42b-4e8b-8a0b-3cd4a2ba924e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ae839e16-93c9-4065-bf6d-1cdb73d92d33\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('argdown_with_questions_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ae839e16-93c9-4065-bf6d-1cdb73d92d33 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('argdown_with_questions_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "argdown_with_questions_df",
              "summary": "{\n  \"name\": \"argdown_with_questions_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Grass_Wet\",\n          \"Rain\",\n          \"Sprinkler\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Concentrated moisture on, between and around the blades of grass.\",\n          \"Tears of angles crying high up in the skies hitting the ground.\",\n          \"Activation of a centrifugal force based CO2 droplet distribution system.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"line\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"line_numbers\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"[0]\",\n          \"[1, 3]\",\n          \"[2]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"indentation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"indentation_levels\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"[0]\",\n          \"[1, 2]\",\n          \"[1]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Parents\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"['Rain', 'Sprinkler']\",\n          \"[]\",\n          \"['Rain']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Children\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"[]\",\n          \"['Grass_Wet', 'Sprinkler']\",\n          \"['Grass_Wet']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instantiations\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"['grass_wet_TRUE', 'grass_wet_FALSE']\",\n          \"['rain_TRUE', 'rain_FALSE']\",\n          \"['sprinkler_TRUE', 'sprinkler_FALSE']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"No_Parent\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"No_Children\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"parent_instantiations\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"[['rain_TRUE', 'rain_FALSE'], ['sprinkler_TRUE', 'sprinkler_FALSE']]\",\n          \"[]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Generate_Positive_Instantiation_Questions\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"{\\\"What is the probability for Grass_Wet=grass_wet_TRUE?\\\": \\\"prior\\\", \\\"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_TRUE, Sprinkler=sprinkler_TRUE?\\\": \\\"estimate_1\\\", \\\"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_TRUE, Sprinkler=sprinkler_FALSE?\\\": \\\"estimate_2\\\", \\\"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_FALSE, Sprinkler=sprinkler_TRUE?\\\": \\\"estimate_3\\\", \\\"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_FALSE, Sprinkler=sprinkler_FALSE?\\\": \\\"estimate_4\\\"}\",\n          \"{\\\"What is the probability for Rain=rain_TRUE?\\\": \\\"prior\\\"}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Generate_Negative_Instantiation_Questions\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"{\\\"What is the probability for Grass_Wet=grass_wet_FALSE?\\\": \\\"prior\\\", \\\"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_TRUE, Sprinkler=sprinkler_TRUE?\\\": \\\"estimate_1\\\", \\\"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_TRUE, Sprinkler=sprinkler_FALSE?\\\": \\\"estimate_2\\\", \\\"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_FALSE, Sprinkler=sprinkler_TRUE?\\\": \\\"estimate_3\\\", \\\"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_FALSE, Sprinkler=sprinkler_FALSE?\\\": \\\"estimate_4\\\"}\",\n          \"{\\\"What is the probability for Rain=rain_FALSE?\\\": \\\"prior\\\"}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 'ArgDown_WithQuestions.csv' to 'BayesDownQuestions.md'"
      ],
      "metadata": {
        "id": "-q9UOQ8yaBZn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2 Save BayesDown Extraction Questions as 'BayesDownQuestions.md'"
      ],
      "metadata": {
        "id": "AI62qUtQYlIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_bayesdown_questions_fixed(argdown_with_questions_path, output_md_path, include_questions_as_comments=True):\n",
        "  \"\"\"\n",
        "  Generate BayesDown syntax from the ArgDown_WithQuestions CSV file with correct parent-child relationships.\n",
        "\n",
        "  Args:\n",
        "      argdown_with_questions_path (str): Path to the CSV file with probability questions\n",
        "      output_md_path (str): Path to save the output BayesDown file\n",
        "      include_questions_as_comments (bool, optional): Whether to include the original\n",
        "                                                    questions as comments. Defaults to True.\n",
        "  \"\"\"\n",
        "  print(f\"Loading CSV from {argdown_with_questions_path}...\")\n",
        "\n",
        "  # Load the CSV file\n",
        "  try:\n",
        "      df = pd.read_csv(argdown_with_questions_path)\n",
        "      print(f\"Successfully loaded CSV with {len(df)} rows.\")\n",
        "  except Exception as e:\n",
        "      raise Exception(f\"Error loading CSV: {e}\")\n",
        "\n",
        "  # Validate required columns\n",
        "  required_columns = ['Title', 'Description', 'Parents', 'Children', 'instantiations']\n",
        "  missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "  if missing_columns:\n",
        "      raise Exception(f\"Missing required columns: {', '.join(missing_columns)}\")\n",
        "\n",
        "  print(\"Generating BayesDown syntax with placeholder probabilities...\")\n",
        "\n",
        "  # Build a directed graph of nodes\n",
        "  G = nx.DiGraph()\n",
        "\n",
        "  # Add nodes to the graph\n",
        "  for idx, row in df.iterrows():\n",
        "      G.add_node(row['Title'], data=row)\n",
        "\n",
        "  # Add edges to the graph based on parent-child relationships - CORRECTLY\n",
        "  for idx, row in df.iterrows():\n",
        "      child = row['Title']\n",
        "\n",
        "      # Parse parents and add edges\n",
        "      parents = row['Parents']\n",
        "      if isinstance(parents, str):\n",
        "          # Handle string representation of list\n",
        "          if parents.startswith('[') and parents.endswith(']'):\n",
        "              parents = parents.strip('[]')\n",
        "              if parents:  # Check if not empty\n",
        "                  parent_list = [p.strip().strip('\\'\"') for p in parents.split(',')]\n",
        "                  for parent in parent_list:\n",
        "                      if parent in G.nodes():\n",
        "                          # In BayesDown: Parent (cause) -> Child (effect)\n",
        "                          G.add_edge(parent, child)\n",
        "      elif isinstance(parents, list):\n",
        "          # Handle actual list\n",
        "          for parent in parents:\n",
        "              if parent in G.nodes():\n",
        "                  G.add_edge(parent, child)\n",
        "\n",
        "  # Function to safely parse JSON strings\n",
        "  def safe_parse_json(json_str):\n",
        "      if pd.isna(json_str):\n",
        "          return {}\n",
        "\n",
        "      if isinstance(json_str, dict):\n",
        "          return json_str\n",
        "\n",
        "      try:\n",
        "          return json.loads(json_str)\n",
        "      except:\n",
        "          return {}\n",
        "\n",
        "  # Start building the BayesDown content\n",
        "  bayesdown_content = \"\"  # Initialize as empty\n",
        "\n",
        "  if include_questions_as_comments:\n",
        "    bayesdown_content = \"# BayesDown Representation with Placeholder Probabilities\\n\\n\"\n",
        "    bayesdown_content += \"/* This file contains BayesDown syntax with placeholder probabilities.\\n\"\n",
        "    bayesdown_content += \"   Replace the placeholders with actual probability values based on the \\n\"\n",
        "    bayesdown_content += \"   questions in the comments. */\\n\\n\"\n",
        "\n",
        "  # Get leaf nodes (nodes with no outgoing edges) - these are effects without children\n",
        "  leaf_nodes = [n for n in G.nodes() if G.out_degree(n) == 0]\n",
        "\n",
        "  # Helper function to process a node and its parents recursively\n",
        "  def process_node(node, indent_level=0, processed_nodes=None):\n",
        "      if processed_nodes is None:\n",
        "          processed_nodes = set()\n",
        "\n",
        "      # Create the indentation string\n",
        "      indent = ' ' * (indent_level * 2)\n",
        "      prefix = f\"{indent}+ \" if indent_level > 0 else \"\"\n",
        "\n",
        "      # Get node data\n",
        "      node_data = G.nodes[node]['data']\n",
        "      title = node_data['Title']\n",
        "      description = node_data['Description'] if not pd.isna(node_data['Description']) else \"\"\n",
        "\n",
        "      # Parse instantiations from the row data\n",
        "      instantiations = parse_instantiations_safely(node_data['instantiations'])\n",
        "\n",
        "      # Build the node string\n",
        "      node_output = \"\"\n",
        "\n",
        "      # Add comments with questions if requested\n",
        "      if include_questions_as_comments:\n",
        "          # Add positive questions as comments\n",
        "          if 'Generate_Positive_Instantiation_Questions' in node_data:\n",
        "              positive_questions = safe_parse_json(node_data['Generate_Positive_Instantiation_Questions'])\n",
        "              for question in positive_questions.keys():\n",
        "                  node_output += f\"{indent}/* {question} */\\n\"\n",
        "\n",
        "          # Add negative questions as comments\n",
        "          if 'Generate_Negative_Instantiation_Questions' in node_data:\n",
        "              negative_questions = safe_parse_json(node_data['Generate_Negative_Instantiation_Questions'])\n",
        "              for question in negative_questions.keys():\n",
        "                  node_output += f\"{indent}/* {question} */\\n\"\n",
        "\n",
        "      # Check if this node was already fully defined elsewhere\n",
        "      if node in processed_nodes:\n",
        "          # Just add a reference to the node\n",
        "          node_output += f\"{prefix}[{title}]\\n\"\n",
        "          return node_output\n",
        "\n",
        "      # Mark this node as processed\n",
        "      processed_nodes.add(node)\n",
        "\n",
        "      # Prepare the metadata JSON\n",
        "      metadata = {\n",
        "          \"instantiations\": instantiations\n",
        "      }\n",
        "\n",
        "      # Add priors with full questions as keys\n",
        "      priors = {}\n",
        "      if 'Generate_Positive_Instantiation_Questions' in node_data:\n",
        "          positive_questions = safe_parse_json(node_data['Generate_Positive_Instantiation_Questions'])\n",
        "          for question, estimate_key in positive_questions.items():\n",
        "              if estimate_key == 'prior':\n",
        "                  priors[question] = \"%?\"  # Default placeholder\n",
        "\n",
        "      if 'Generate_Negative_Instantiation_Questions' in node_data:\n",
        "          negative_questions = safe_parse_json(node_data['Generate_Negative_Instantiation_Questions'])\n",
        "          for question, estimate_key in negative_questions.items():\n",
        "              if estimate_key == 'prior':\n",
        "                  priors[question] = \"%?\"  # Default placeholder\n",
        "\n",
        "      metadata[\"priors\"] = priors\n",
        "\n",
        "      # Add posteriors with full questions as keys\n",
        "      parents = list(G.predecessors(node))\n",
        "      if parents:\n",
        "          posteriors = {}\n",
        "          if 'Generate_Positive_Instantiation_Questions' in node_data:\n",
        "              positive_questions = safe_parse_json(node_data['Generate_Positive_Instantiation_Questions'])\n",
        "              for question, estimate_key in positive_questions.items():\n",
        "                  if estimate_key.startswith('estimate_'):\n",
        "                      posteriors[question] = \"?%\"  # Default placeholder\n",
        "\n",
        "          if 'Generate_Negative_Instantiation_Questions' in node_data:\n",
        "              negative_questions = safe_parse_json(node_data['Generate_Negative_Instantiation_Questions'])\n",
        "              for question, estimate_key in negative_questions.items():\n",
        "                  if estimate_key.startswith('estimate_'):\n",
        "                      posteriors[question] = \"?%\"  # Default placeholder\n",
        "\n",
        "          metadata[\"posteriors\"] = posteriors\n",
        "\n",
        "      # Format the node with metadata\n",
        "      node_output += f\"{prefix}[{title}]: {description} {json.dumps(metadata)}\\n\"\n",
        "\n",
        "      # Process parent nodes\n",
        "      for parent in parents:\n",
        "          if parent != node:  # Avoid self-references\n",
        "              parent_output = process_node(parent, indent_level + 1, processed_nodes)\n",
        "              node_output += parent_output\n",
        "\n",
        "      return node_output\n",
        "\n",
        "  # Helper function to parse instantiations safely\n",
        "  def parse_instantiations_safely(instantiations_data):\n",
        "      if isinstance(instantiations_data, list):\n",
        "          return instantiations_data if instantiations_data else [f\"TRUE\", f\"FALSE\"]\n",
        "\n",
        "      if isinstance(instantiations_data, str):\n",
        "          try:\n",
        "              parsed = json.loads(instantiations_data)\n",
        "              if isinstance(parsed, list):\n",
        "                  return parsed if parsed else [f\"TRUE\", f\"FALSE\"]\n",
        "          except:\n",
        "              if instantiations_data.startswith('[') and instantiations_data.endswith(']'):\n",
        "                  items = instantiations_data.strip('[]').split(',')\n",
        "                  result = [item.strip(' \"\\'') for item in items if item.strip()]\n",
        "                  return result if result else [f\"TRUE\", f\"FALSE\"]\n",
        "\n",
        "      return [f\"TRUE\", f\"FALSE\"]  # Default\n",
        "\n",
        "  # Process each leaf node and its ancestors\n",
        "  for leaf in leaf_nodes:\n",
        "      bayesdown_content += process_node(leaf)\n",
        "\n",
        "  # Save the BayesDown content\n",
        "  with open(output_md_path, 'w') as f:\n",
        "      f.write(bayesdown_content)\n",
        "\n",
        "  print(f\"BayesDown Questions saved to {output_md_path}\")\n",
        "  return bayesdown_content"
      ],
      "metadata": {
        "id": "NqUj94g8gn4p"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "source": [
        "# Explicitly set the value of include_questions_as_comments\n",
        "include_questions_as_comments=False  # or False, depending on your needs\n",
        "\n",
        "# Get the markdown content\n",
        "bayesdown_questions = extract_bayesdown_questions_fixed(\n",
        "  \"ArgDown_WithQuestions.csv\",\n",
        "  \"BayesDownQuestions.md\", include_questions_as_comments=include_questions_as_comments\n",
        ")\n",
        "\n",
        "# Determine the output file path based on include_questions_as_comments\n",
        "if include_questions_as_comments: # Assuming include_questions_as_comments is defined somewhere in previous cells\n",
        "    output_file_path = \"FULL_BayesDownQuestions.md\"\n",
        "else:\n",
        "    output_file_path = \"BayesDownQuestions.md\"\n",
        "\n",
        "# Save the markdown content to the appropriate file\n",
        "with open(output_file_path, 'w') as f:\n",
        "    f.write(md_content)\n",
        "\n",
        "print(f\"Markdown content saved to {output_file_path}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "V80XYvjYGnbE",
        "outputId": "da1c7dea-a330-4052-c407-55813e55a0c1"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CSV from ArgDown_WithQuestions.csv...\n",
            "Successfully loaded CSV with 3 rows.\n",
            "Generating BayesDown syntax with placeholder probabilities...\n",
            "BayesDown Questions saved to BayesDownQuestions.md\n",
            "Markdown content saved to BayesDownQuestions.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate BayesDown format\n",
        "bayesdown_questions = extract_bayesdown_questions_fixed(\n",
        "    \"ArgDown_WithQuestions.csv\",\n",
        "    \"FULL_BayesDownQuestions.md\",\n",
        "    include_questions_as_comments=True\n",
        ")\n",
        "\n",
        "# Display a preview of the format\n",
        "print(\"\\nBayesDown Format Preview:\")\n",
        "print(bayesdown_questions[:5000] + \"...\\n\")"
      ],
      "metadata": {
        "id": "lBLyoERIT557",
        "outputId": "c84e8f19-16d9-42f2-f097-866e4493df56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CSV from ArgDown_WithQuestions.csv...\n",
            "Successfully loaded CSV with 3 rows.\n",
            "Generating BayesDown syntax with placeholder probabilities...\n",
            "BayesDown Questions saved to FULL_BayesDownQuestions.md\n",
            "\n",
            "BayesDown Format Preview:\n",
            "# BayesDown Representation with Placeholder Probabilities\n",
            "\n",
            "/* This file contains BayesDown syntax with placeholder probabilities.\n",
            "   Replace the placeholders with actual probability values based on the \n",
            "   questions in the comments. */\n",
            "\n",
            "/* What is the probability for Grass_Wet=grass_wet_TRUE? */\n",
            "/* What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_TRUE, Sprinkler=sprinkler_TRUE? */\n",
            "/* What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_TRUE, Sprinkler=sprinkler_FALSE? */\n",
            "/* What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_FALSE, Sprinkler=sprinkler_TRUE? */\n",
            "/* What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_FALSE, Sprinkler=sprinkler_FALSE? */\n",
            "/* What is the probability for Grass_Wet=grass_wet_FALSE? */\n",
            "/* What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_TRUE, Sprinkler=sprinkler_TRUE? */\n",
            "/* What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_TRUE, Sprinkler=sprinkler_FALSE? */\n",
            "/* What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_FALSE, Sprinkler=sprinkler_TRUE? */\n",
            "/* What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_FALSE, Sprinkler=sprinkler_FALSE? */\n",
            "[Grass_Wet]: Concentrated moisture on, between and around the blades of grass. {\"instantiations\": [\"grass_wet_TRUE\", \"grass_wet_FALSE\"], \"priors\": {\"What is the probability for Grass_Wet=grass_wet_TRUE?\": \"%?\", \"What is the probability for Grass_Wet=grass_wet_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_TRUE, Sprinkler=sprinkler_TRUE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_TRUE, Sprinkler=sprinkler_FALSE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_FALSE, Sprinkler=sprinkler_TRUE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_FALSE, Sprinkler=sprinkler_FALSE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_TRUE, Sprinkler=sprinkler_TRUE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_TRUE, Sprinkler=sprinkler_FALSE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_FALSE, Sprinkler=sprinkler_TRUE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_FALSE, Sprinkler=sprinkler_FALSE?\": \"?%\"}}\n",
            "  /* What is the probability for Rain=rain_TRUE? */\n",
            "  /* What is the probability for Rain=rain_FALSE? */\n",
            "  + [Rain]: Tears of angles crying high up in the skies hitting the ground. {\"instantiations\": [\"rain_TRUE\", \"rain_FALSE\"], \"priors\": {\"What is the probability for Rain=rain_TRUE?\": \"%?\", \"What is the probability for Rain=rain_FALSE?\": \"%?\"}}\n",
            "  /* What is the probability for Sprinkler=sprinkler_TRUE? */\n",
            "  /* What is the probability for Sprinkler=sprinkler_TRUE if Rain=rain_TRUE? */\n",
            "  /* What is the probability for Sprinkler=sprinkler_TRUE if Rain=rain_FALSE? */\n",
            "  /* What is the probability for Sprinkler=sprinkler_FALSE? */\n",
            "  /* What is the probability for Sprinkler=sprinkler_FALSE if Rain=rain_TRUE? */\n",
            "  /* What is the probability for Sprinkler=sprinkler_FALSE if Rain=rain_FALSE? */\n",
            "  + [Sprinkler]: Activation of a centrifugal force based CO2 droplet distribution system. {\"instantiations\": [\"sprinkler_TRUE\", \"sprinkler_FALSE\"], \"priors\": {\"What is the probability for Sprinkler=sprinkler_TRUE?\": \"%?\", \"What is the probability for Sprinkler=sprinkler_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Sprinkler=sprinkler_TRUE if Rain=rain_TRUE?\": \"?%\", \"What is the probability for Sprinkler=sprinkler_TRUE if Rain=rain_FALSE?\": \"?%\", \"What is the probability for Sprinkler=sprinkler_FALSE if Rain=rain_TRUE?\": \"?%\", \"What is the probability for Sprinkler=sprinkler_FALSE if Rain=rain_FALSE?\": \"?%\"}}\n",
            "    /* What is the probability for Rain=rain_TRUE? */\n",
            "    /* What is the probability for Rain=rain_FALSE? */\n",
            "    + [Rain]\n",
            "...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and print the content of the 'FULL_BayesDownQuestions.md' file\n",
        "with open(\"FULL_BayesDownQuestions.md\", \"r\") as f:\n",
        "    file_content = f.read()\n",
        "    print(file_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cTZslwsXHUfK",
        "outputId": "e679b486-728a-40c1-ac4e-f994eb6f5208",
        "collapsed": true
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# BayesDown Representation with Placeholder Probabilities\n",
            "\n",
            "/* This file contains BayesDown syntax with placeholder probabilities.\n",
            "   Replace the placeholders with actual probability values based on the \n",
            "   questions in the comments. */\n",
            "\n",
            "/* What is the probability for Grass_Wet=grass_wet_TRUE? */\n",
            "/* What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_TRUE, Sprinkler=sprinkler_TRUE? */\n",
            "/* What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_TRUE, Sprinkler=sprinkler_FALSE? */\n",
            "/* What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_FALSE, Sprinkler=sprinkler_TRUE? */\n",
            "/* What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_FALSE, Sprinkler=sprinkler_FALSE? */\n",
            "/* What is the probability for Grass_Wet=grass_wet_FALSE? */\n",
            "/* What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_TRUE, Sprinkler=sprinkler_TRUE? */\n",
            "/* What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_TRUE, Sprinkler=sprinkler_FALSE? */\n",
            "/* What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_FALSE, Sprinkler=sprinkler_TRUE? */\n",
            "/* What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_FALSE, Sprinkler=sprinkler_FALSE? */\n",
            "[Grass_Wet]: Concentrated moisture on, between and around the blades of grass. {\"instantiations\": [\"grass_wet_TRUE\", \"grass_wet_FALSE\"], \"priors\": {\"What is the probability for Grass_Wet=grass_wet_TRUE?\": \"%?\", \"What is the probability for Grass_Wet=grass_wet_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_TRUE, Sprinkler=sprinkler_TRUE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_TRUE, Sprinkler=sprinkler_FALSE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_FALSE, Sprinkler=sprinkler_TRUE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_FALSE, Sprinkler=sprinkler_FALSE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_TRUE, Sprinkler=sprinkler_TRUE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_TRUE, Sprinkler=sprinkler_FALSE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_FALSE, Sprinkler=sprinkler_TRUE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_FALSE, Sprinkler=sprinkler_FALSE?\": \"?%\"}}\n",
            "  /* What is the probability for Rain=rain_TRUE? */\n",
            "  /* What is the probability for Rain=rain_FALSE? */\n",
            "  + [Rain]: Tears of angles crying high up in the skies hitting the ground. {\"instantiations\": [\"rain_TRUE\", \"rain_FALSE\"], \"priors\": {\"What is the probability for Rain=rain_TRUE?\": \"%?\", \"What is the probability for Rain=rain_FALSE?\": \"%?\"}}\n",
            "  /* What is the probability for Sprinkler=sprinkler_TRUE? */\n",
            "  /* What is the probability for Sprinkler=sprinkler_TRUE if Rain=rain_TRUE? */\n",
            "  /* What is the probability for Sprinkler=sprinkler_TRUE if Rain=rain_FALSE? */\n",
            "  /* What is the probability for Sprinkler=sprinkler_FALSE? */\n",
            "  /* What is the probability for Sprinkler=sprinkler_FALSE if Rain=rain_TRUE? */\n",
            "  /* What is the probability for Sprinkler=sprinkler_FALSE if Rain=rain_FALSE? */\n",
            "  + [Sprinkler]: Activation of a centrifugal force based CO2 droplet distribution system. {\"instantiations\": [\"sprinkler_TRUE\", \"sprinkler_FALSE\"], \"priors\": {\"What is the probability for Sprinkler=sprinkler_TRUE?\": \"%?\", \"What is the probability for Sprinkler=sprinkler_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Sprinkler=sprinkler_TRUE if Rain=rain_TRUE?\": \"?%\", \"What is the probability for Sprinkler=sprinkler_TRUE if Rain=rain_FALSE?\": \"?%\", \"What is the probability for Sprinkler=sprinkler_FALSE if Rain=rain_TRUE?\": \"?%\", \"What is the probability for Sprinkler=sprinkler_FALSE if Rain=rain_FALSE?\": \"?%\"}}\n",
            "    /* What is the probability for Rain=rain_TRUE? */\n",
            "    /* What is the probability for Rain=rain_FALSE? */\n",
            "    + [Rain]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate BayesDown format\n",
        "bayesdown_questions = extract_bayesdown_questions_fixed(\n",
        "    \"ArgDown_WithQuestions.csv\",\n",
        "    \"BayesDownQuestions.md\",\n",
        "    include_questions_as_comments=False\n",
        ")\n",
        "\n",
        "# Display a preview of the format\n",
        "print(\n",
        "\n",
        ")\n",
        "print(bayesdown_questions[:5000] + \"...\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PMIRJVfmT_gO",
        "outputId": "651da58e-eb9b-45e8-e754-ecd59635b5b2"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CSV from ArgDown_WithQuestions.csv...\n",
            "Successfully loaded CSV with 3 rows.\n",
            "Generating BayesDown syntax with placeholder probabilities...\n",
            "BayesDown Questions saved to BayesDownQuestions.md\n",
            "\n",
            "[Grass_Wet]: Concentrated moisture on, between and around the blades of grass. {\"instantiations\": [\"grass_wet_TRUE\", \"grass_wet_FALSE\"], \"priors\": {\"What is the probability for Grass_Wet=grass_wet_TRUE?\": \"%?\", \"What is the probability for Grass_Wet=grass_wet_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_TRUE, Sprinkler=sprinkler_TRUE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_TRUE, Sprinkler=sprinkler_FALSE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_FALSE, Sprinkler=sprinkler_TRUE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_FALSE, Sprinkler=sprinkler_FALSE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_TRUE, Sprinkler=sprinkler_TRUE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_TRUE, Sprinkler=sprinkler_FALSE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_FALSE, Sprinkler=sprinkler_TRUE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_FALSE, Sprinkler=sprinkler_FALSE?\": \"?%\"}}\n",
            "  + [Rain]: Tears of angles crying high up in the skies hitting the ground. {\"instantiations\": [\"rain_TRUE\", \"rain_FALSE\"], \"priors\": {\"What is the probability for Rain=rain_TRUE?\": \"%?\", \"What is the probability for Rain=rain_FALSE?\": \"%?\"}}\n",
            "  + [Sprinkler]: Activation of a centrifugal force based CO2 droplet distribution system. {\"instantiations\": [\"sprinkler_TRUE\", \"sprinkler_FALSE\"], \"priors\": {\"What is the probability for Sprinkler=sprinkler_TRUE?\": \"%?\", \"What is the probability for Sprinkler=sprinkler_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Sprinkler=sprinkler_TRUE if Rain=rain_TRUE?\": \"?%\", \"What is the probability for Sprinkler=sprinkler_TRUE if Rain=rain_FALSE?\": \"?%\", \"What is the probability for Sprinkler=sprinkler_FALSE if Rain=rain_TRUE?\": \"?%\", \"What is the probability for Sprinkler=sprinkler_FALSE if Rain=rain_FALSE?\": \"?%\"}}\n",
            "    + [Rain]\n",
            "...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0MP52SJAamLo"
      }
    },
    {
      "source": [
        "# Load and print the content of the 'BayesDownQuestions.md' file\n",
        "with open(\"BayesDownQuestions.md\", \"r\") as f:\n",
        "    file_content = f.read()\n",
        "    print(file_content)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "SipU4UvPP3_Z",
        "outputId": "cffbcec5-9131-405d-948c-247bc8de20e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grass_Wet]: Concentrated moisture on, between and around the blades of grass. {\"instantiations\": [\"grass_wet_TRUE\", \"grass_wet_FALSE\"], \"priors\": {\"What is the probability for Grass_Wet=grass_wet_TRUE?\": \"%?\", \"What is the probability for Grass_Wet=grass_wet_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_TRUE, Sprinkler=sprinkler_TRUE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_TRUE, Sprinkler=sprinkler_FALSE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_FALSE, Sprinkler=sprinkler_TRUE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_FALSE, Sprinkler=sprinkler_FALSE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_TRUE, Sprinkler=sprinkler_TRUE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_TRUE, Sprinkler=sprinkler_FALSE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_FALSE, Sprinkler=sprinkler_TRUE?\": \"?%\", \"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_FALSE, Sprinkler=sprinkler_FALSE?\": \"?%\"}}\n",
            "  + [Rain]: Tears of angles crying high up in the skies hitting the ground. {\"instantiations\": [\"rain_TRUE\", \"rain_FALSE\"], \"priors\": {\"What is the probability for Rain=rain_TRUE?\": \"%?\", \"What is the probability for Rain=rain_FALSE?\": \"%?\"}}\n",
            "  + [Sprinkler]: Activation of a centrifugal force based CO2 droplet distribution system. {\"instantiations\": [\"sprinkler_TRUE\", \"sprinkler_FALSE\"], \"priors\": {\"What is the probability for Sprinkler=sprinkler_TRUE?\": \"%?\", \"What is the probability for Sprinkler=sprinkler_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Sprinkler=sprinkler_TRUE if Rain=rain_TRUE?\": \"?%\", \"What is the probability for Sprinkler=sprinkler_TRUE if Rain=rain_FALSE?\": \"?%\", \"What is the probability for Sprinkler=sprinkler_FALSE if Rain=rain_TRUE?\": \"?%\", \"What is the probability for Sprinkler=sprinkler_FALSE if Rain=rain_FALSE?\": \"?%\"}}\n",
            "    + [Rain]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V66ZHih3BTC0"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Generate BayesDown Probability Extraction Prompt\n",
        "\n",
        "Generate 2nd Extraction Prompt for Probabilities based on the questions generated from the 'ArgDown.csv' extraction"
      ],
      "metadata": {
        "id": "Ux4OUCPue6Bu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Prepare 2nd API call"
      ],
      "metadata": {
        "id": "d4tB9WD-fIWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 Make BayesDown Probability Extraction API Call"
      ],
      "metadata": {
        "id": "oPWto83lfN9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6 Save BayesDown with Probability Estimates (.csv)"
      ],
      "metadata": {
        "id": "L8NWpz8MfZ9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.7 Review & Verify BayesDown Probability Estimates"
      ],
      "metadata": {
        "id": "Q3PTtYgRfsLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.7.2 Check the Graph Structure with the ArgDown Sandbox Online\n",
        "Copy and paste the BayesDown formatted ... in the ArgDown Sandbox below to quickly verify that the network renders correctly."
      ],
      "metadata": {
        "id": "VwoAgBsafonh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivcnd2ml41Nv"
      },
      "source": [
        "### 2.3.1 BayesDown Format Specification\n",
        "\n",
        "BayesDown augments ArgDown with probability data in a structured JSON format:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"instantiations\": [\"state_TRUE\", \"state_FALSE\"],\n",
        "  \"priors\": {\n",
        "    \"p(state_TRUE)\": \"0.7\",\n",
        "    \"p(state_FALSE)\": \"0.3\"\n",
        "  },\n",
        "  \"posteriors\": {\n",
        "    \"p(state_TRUE|condition1_TRUE,condition2_FALSE)\": \"0.9\",\n",
        "    \"p(state_TRUE|condition1_FALSE,condition2_TRUE)\": \"0.4\"\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncRX492c4-Q7"
      },
      "source": [
        "2.3.2 Probability Extraction Process\n",
        "The probability extraction pipeline follows these steps:\n",
        "\n",
        "\n",
        "Identify variables and their possible states\n",
        "Extract prior probability statements\n",
        "Identify conditional relationships\n",
        "Extract conditional probability statements\n",
        "Format the data in BayesDown syntax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNSbA0Wm5Uzn"
      },
      "source": [
        "2.3.3 Implementation Steps\n",
        "To extract probabilities and create BayesDown format:\n",
        "\n",
        "Run the extract_probabilities function on ArgDown text\n",
        "Process the results into a structured format\n",
        "Validate the probability distributions (ensure they sum to 1)\n",
        "Generate the enhanced BayesDown representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnk9mFMG5kNS"
      },
      "source": [
        "2.3.4 Validation and Quality Control\n",
        "The probability extraction process includes validation steps:\n",
        "\n",
        "Ensuring coherent probability distributions\n",
        "Checking for logical consistency in conditional relationships\n",
        "Verifying that all required probability statements are present\n",
        "Handling missing data with appropriate default values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.8 Extract BayesDown with Probability Estimates as Dataframe"
      ],
      "metadata": {
        "id": "19KDn2mKf309"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ9OIyEv5qqb"
      },
      "source": [
        "# 3.0 Data Extraction: BayesDown (.md) to Database (.csv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFnu_1Ludahi"
      },
      "source": [
        "### 3.1 ExtractBayesDown-Data_v1\n",
        "Build data frame with extractable information from BayesDown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "ka4kLU_sj4nH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "c8e40c43-cde7-45ce-d7ac-f215d8edfa0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'## BayesDown Example\\n\\n\\n[Grass_Wet]: Concentrated moisture on, between and around the blades of grass. {\"instantiations\": [\"grass_wet_TRUE\", \"grass_wet_FALSE\"], \"priors\": {\"p(grass_wet_TRUE)\": \"0.322\",\"p(grass_wet_FALSE)\": \"0.678\"},\"posteriors\": {\"p(grass_wet_TRUE|sprinkler_TRUE,rain_TRUE)\": \"0.99\",\"p(grass_wet_TRUE|sprinkler_TRUE,rain_FALSE)\": \"0.9\",\"p(grass_wet_TRUE|sprinkler_FALSE,rain_TRUE)\": \"0.8\",\"p(grass_wet_TRUE|sprinkler_FALSE,rain_FALSE)\": \"0.0\",\"p(grass_wet_FALSE|sprinkler_TRUE,rain_TRUE)\": \"0.01\",\"p(grass_wet_FALSE|sprinkler_TRUE,rain_FALSE)\": \"0.1\",\"p(grass_wet_FALSE|sprinkler_FALSE,rain_TRUE)\": \"0.2\",\"p(grass_wet_FALSE|sprinkler_FALSE,rain_FALSE)\": \"1.0\"}}\\n + [Rain]: Tears of angles crying high up in the skies hitting the ground.{\"instantiations\": [\"rain_TRUE\", \"rain_FALSE\"],\"priors\": {\"p(rain_TRUE)\": \"0.2\",\"p(rain_FALSE)\": \"0.8\"},\"posteriors\": {}}\\n + [Sprinkler]: Activation of a centrifugal force based CO2 droplet distribution system.{\"instantiations\": [\"sprinkler_TRUE\", \"sprinkler_FALSE\"],\"priors\": {\"p(sprinkler_TRUE)\": \"0.44838\",\"p(sprinkler_FALSE)\": \"0.55162\"},\"posteriors\": {\"p(sprinkler_TRUE|rain_TRUE)\": \"0.01\",\"p(sprinkler_TRUE|rain_FALSE)\": \"0.4\",\"p(sprinkler_FALSE|rain_TRUE)\": \"0.99\",\"p(sprinkler_FALSE|rain_FALSE)\":\"0.6\"}}\\n  + [Rain]\\n\\n\\n/* ArgDown is extremely sensitive w.r.t. syntax. If there are mistakes, eg. double \"\" instead of single \" or brackets or indentation are off or with the wrong indentation, ArgDown will not compile!*/\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# read sprinkler example -- Occam Colab Online\n",
        "file_path_ex_rain = \"https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_1/BayesDown_Example.md\"\n",
        "\n",
        "# Use requests.get to fetch content from URL\n",
        "response = requests.get(file_path_ex_rain)\n",
        "response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "\n",
        "# Read content from the response\n",
        "md_content_ex_rain = response.text\n",
        "\n",
        "md_content_ex_rain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUBJh8Qp4yd4"
      },
      "source": [
        "## 3.1.2 Test BayesDown Extraction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUQbvMLtDQiJ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "xSGQt9Td6XI2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "76831d0c-a32d-4094-90d7-57ec3dacfb9b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## BayesDown Example\n\n\n[Grass_Wet]: Concentrated moisture on, between and around the blades of grass. {\"instantiations\": [\"grass_wet_TRUE\", \"grass_wet_FALSE\"], \"priors\": {\"p(grass_wet_TRUE)\": \"0.322\",\"p(grass_wet_FALSE)\": \"0.678\"},\"posteriors\": {\"p(grass_wet_TRUE|sprinkler_TRUE,rain_TRUE)\": \"0.99\",\"p(grass_wet_TRUE|sprinkler_TRUE,rain_FALSE)\": \"0.9\",\"p(grass_wet_TRUE|sprinkler_FALSE,rain_TRUE)\": \"0.8\",\"p(grass_wet_TRUE|sprinkler_FALSE,rain_FALSE)\": \"0.0\",\"p(grass_wet_FALSE|sprinkler_TRUE,rain_TRUE)\": \"0.01\",\"p(grass_wet_FALSE|sprinkler_TRUE,rain_FALSE)\": \"0.1\",\"p(grass_wet_FALSE|sprinkler_FALSE,rain_TRUE)\": \"0.2\",\"p(grass_wet_FALSE|sprinkler_FALSE,rain_FALSE)\": \"1.0\"}}\n + [Rain]: Tears of angles crying high up in the skies hitting the ground.{\"instantiations\": [\"rain_TRUE\", \"rain_FALSE\"],\"priors\": {\"p(rain_TRUE)\": \"0.2\",\"p(rain_FALSE)\": \"0.8\"},\"posteriors\": {}}\n + [Sprinkler]: Activation of a centrifugal force based CO2 droplet distribution system.{\"instantiations\": [\"sprinkler_TRUE\", \"sprinkler_FALSE\"],\"priors\": {\"p(sprinkler_TRUE)\": \"0.44838\",\"p(sprinkler_FALSE)\": \"0.55162\"},\"posteriors\": {\"p(sprinkler_TRUE|rain_TRUE)\": \"0.01\",\"p(sprinkler_TRUE|rain_FALSE)\": \"0.4\",\"p(sprinkler_FALSE|rain_TRUE)\": \"0.99\",\"p(sprinkler_FALSE|rain_FALSE)\":\"0.6\"}}\n  + [Rain]\n\n\n/* ArgDown is extremely sensitive w.r.t. syntax. If there are mistakes, eg. double \"\" instead of single \" or brackets or indentation are off or with the wrong indentation, ArgDown will not compile!*/\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(Markdown(md_content_ex_rain)) # view BayesDown file formatted as MarkDown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4Hgs0ICDQyW"
      },
      "source": [
        "## 3.1.2.2 Check the Graph Structure with the ArgDown Sandbox Online\n",
        "Copy and paste the BayesDown formatted ... in the ArgDown Sandbox below to quickly verify that the network renders correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSDF6M_h3h6O"
      },
      "source": [
        "### 3.1.2.B Test with 'Example_file_combined_withBayesDown_Crossgenerational.md'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "-HY7vlL3mVJu",
        "outputId": "0473a535-7466-4336-deba-4bc422e9a76b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Unconnected titles with descriptions\\n\\n<a>: I am currently in no relation.\\n\\n<b>: It\\'s complicated.\\n\\n<c>: I feel disconnected.\\n\\n# Two generation connected arguments\\n\\n[Thesis]: Censorship is not wrong in principle.\\n + <P1a>: Freedom of speech is never an absolute right but an aspiration. It ceases to be a right when it causes harm to others. Therefore it is not the case that censorship is wrong in principle.{\"instantiations\": [\"TRUE\", \"FALSE\"],\"priors\": {\"p(TRUE)\": \"0.322\", \"p(FALSE)\": \"0.678\"}, \"posteriors\": {\"p(grass_wet|sprinkler,rain)\": \"0.00198\", \"p(grass_wet|sprinkler,no_rain)\": \"0.288\", \"p(grass_wet|no_sprinkler,rain)\": \"0.1584\", \"p(grass_wet|no_sprinkler,no_rain)\": \"0\", \"p(no_grass_wet|sprinkler,rain)\": \"0.00002\", \"p(no_grass_wet|sprinkler,no_rain)\": \"0.032\", \"p(no_grass_wet|no_sprinkler,rain)\": \"0.0396\", \"p(no_grass_wet|no_sprinkler,no_rain)\": \"0.48\"}}\\n + <P1b>: We all recognise the value of, for example, legislating against incitement to racial hatred. #pro\\n  - <C1b>: Censorship such as legislation against incitement to racial hatred drives racists and others underground and thus entrenches and ghettoises that section of the community rather than drawing its members into open and rational debate. #con\\n + <P2>: Certain types of literature or visual image have been conclusively linked to crime. Excessive sex and violence in film and television has been shown (especially in studies in the US) to contribute to a tendency towards similar behaviour in spectators. There is no excuse for this and such images must be sacrificed, no matter what their artistic merit. #pro\\n  - <C2>: In fact, the link between sex and violence on screen and in real life is far from conclusive. To look at it from another angle, those individuals who _already have tendencies_ to violence are likely to watch violent `video nasties\\', just as those with a predilection for rape are likely to use pornography. The two are therefore connected but the individual\\'s personality is formed first. #con\\n   - <C3>: Trying whether a third generation will also work. /* plus adding a comment to ignore <hallo> */\\n   - [Thesis]\\n - <C1a>: Censorship is wrong in principle. However violently we may disagree with a person\\'s point of view or mode of expression, they must be free to express themselves in a free and civilized society.\\n\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# read basic ArgDown example With BayesDown syntax added and corss generational added\n",
        "import requests  # Import the requests library\n",
        "\n",
        "# **Corrected URL with /main/**\n",
        "file_path_easy_ex_B_CG = \"https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/Example_file_combined_withBayesDown_Crossgenerational.md\"\n",
        "\n",
        "# Use requests.get to fetch content from URL\n",
        "response = requests.get(file_path_easy_ex_B_CG)\n",
        "response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "\n",
        "# Read content from the response\n",
        "md_content_easy_ex_B_CG = response.text\n",
        "\n",
        "md_content_easy_ex_B_CG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv8f4c4D3yJj"
      },
      "source": [
        "## 3.3 Extraction\n",
        "BayesDown Extraction Code already part of ArgDown extraction code, therefore just use same function \"parse_markdown_hierarchy(markdown_data)\" and ignore the extra argument (\"ArgDown\") because it is automatically set to false amd will by default extract BayesDown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "hmoEC7JaHFVn",
        "outputId": "325aa4c9-a115-441c-f352-7a0bb07240e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Title                                        Description  line  \\\n",
              "0  Grass_Wet  Concentrated moisture on, between and around t...     3   \n",
              "1       Rain  Tears of angles crying high up in the skies hi...     4   \n",
              "2  Sprinkler  Activation of a centrifugal force based CO2 dr...     5   \n",
              "\n",
              "  line_numbers  indentation indentation_levels            Parents  \\\n",
              "0          [3]            0                [0]  [Rain, Sprinkler]   \n",
              "1       [4, 6]            2             [1, 2]                 []   \n",
              "2          [5]            1                [1]             [Rain]   \n",
              "\n",
              "                 Children                     instantiations  \\\n",
              "0                      []  [grass_wet_TRUE, grass_wet_FALSE]   \n",
              "1  [Grass_Wet, Sprinkler]            [rain_TRUE, rain_FALSE]   \n",
              "2             [Grass_Wet]  [sprinkler_TRUE, sprinkler_FALSE]   \n",
              "\n",
              "                                              priors  \\\n",
              "0  {'p(grass_wet_TRUE)': '0.322', 'p(grass_wet_FA...   \n",
              "1    {'p(rain_TRUE)': '0.2', 'p(rain_FALSE)': '0.8'}   \n",
              "2  {'p(sprinkler_TRUE)': '0.44838', 'p(sprinkler_...   \n",
              "\n",
              "                                          posteriors  No_Parent  No_Children  \\\n",
              "0  {'p(grass_wet_TRUE|sprinkler_TRUE,rain_TRUE)':...      False         True   \n",
              "1                                                 {}       True        False   \n",
              "2  {'p(sprinkler_TRUE|rain_TRUE)': '0.01', 'p(spr...      False        False   \n",
              "\n",
              "                               parent_instantiations  \n",
              "0  [[rain_TRUE, rain_FALSE], [sprinkler_TRUE, spr...  \n",
              "1                                                 []  \n",
              "2                          [[rain_TRUE, rain_FALSE]]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e54a6dd-78a7-4165-8a81-f8cba7b52758\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>line</th>\n",
              "      <th>line_numbers</th>\n",
              "      <th>indentation</th>\n",
              "      <th>indentation_levels</th>\n",
              "      <th>Parents</th>\n",
              "      <th>Children</th>\n",
              "      <th>instantiations</th>\n",
              "      <th>priors</th>\n",
              "      <th>posteriors</th>\n",
              "      <th>No_Parent</th>\n",
              "      <th>No_Children</th>\n",
              "      <th>parent_instantiations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Grass_Wet</td>\n",
              "      <td>Concentrated moisture on, between and around t...</td>\n",
              "      <td>3</td>\n",
              "      <td>[3]</td>\n",
              "      <td>0</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[Rain, Sprinkler]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[grass_wet_TRUE, grass_wet_FALSE]</td>\n",
              "      <td>{'p(grass_wet_TRUE)': '0.322', 'p(grass_wet_FA...</td>\n",
              "      <td>{'p(grass_wet_TRUE|sprinkler_TRUE,rain_TRUE)':...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>[[rain_TRUE, rain_FALSE], [sprinkler_TRUE, spr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rain</td>\n",
              "      <td>Tears of angles crying high up in the skies hi...</td>\n",
              "      <td>4</td>\n",
              "      <td>[4, 6]</td>\n",
              "      <td>2</td>\n",
              "      <td>[1, 2]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[Grass_Wet, Sprinkler]</td>\n",
              "      <td>[rain_TRUE, rain_FALSE]</td>\n",
              "      <td>{'p(rain_TRUE)': '0.2', 'p(rain_FALSE)': '0.8'}</td>\n",
              "      <td>{}</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sprinkler</td>\n",
              "      <td>Activation of a centrifugal force based CO2 dr...</td>\n",
              "      <td>5</td>\n",
              "      <td>[5]</td>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[Rain]</td>\n",
              "      <td>[Grass_Wet]</td>\n",
              "      <td>[sprinkler_TRUE, sprinkler_FALSE]</td>\n",
              "      <td>{'p(sprinkler_TRUE)': '0.44838', 'p(sprinkler_...</td>\n",
              "      <td>{'p(sprinkler_TRUE|rain_TRUE)': '0.01', 'p(spr...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>[[rain_TRUE, rain_FALSE]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e54a6dd-78a7-4165-8a81-f8cba7b52758')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4e54a6dd-78a7-4165-8a81-f8cba7b52758 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4e54a6dd-78a7-4165-8a81-f8cba7b52758');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b0605449-ec78-434e-8c52-cfcb5ee582dc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0605449-ec78-434e-8c52-cfcb5ee582dc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b0605449-ec78-434e-8c52-cfcb5ee582dc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_20fef9a3-8da8-4920-a4d3-44192583af29\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_20fef9a3-8da8-4920-a4d3-44192583af29 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('result_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result_df",
              "summary": "{\n  \"name\": \"result_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Grass_Wet\",\n          \"Rain\",\n          \"Sprinkler\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Concentrated moisture on, between and around the blades of grass.\",\n          \"Tears of angles crying high up in the skies hitting the ground.\",\n          \"Activation of a centrifugal force based CO2 droplet distribution system.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"line\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          4,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"line_numbers\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"indentation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"indentation_levels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Parents\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Children\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instantiations\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"priors\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"posteriors\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"No_Parent\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"No_Children\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"parent_instantiations\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "result_df = parse_markdown_hierarchy(md_content_ex_rain)\n",
        "result_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcXf3fZ8dahj"
      },
      "source": [
        "### 3.3 Data-Post-Processing\n",
        "Add rows to data frame that can be calculated from the extracted rows"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3.3.1 Data Post-Processing Functions ---\n",
        "\n",
        "# --- 3.3 Data-Post-Processing ---\n",
        "\n",
        "def enhance_extracted_data(df):\n",
        "    \"\"\"\n",
        "    Enhance the extracted data with calculated columns\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with extracted BayesDown data\n",
        "\n",
        "    Returns:\n",
        "        Enhanced DataFrame with additional columns\n",
        "    \"\"\"\n",
        "    # Create a copy to avoid modifying the original\n",
        "    enhanced_df = df.copy()\n",
        "\n",
        "    # 1. Calculate joint probabilities\n",
        "    enhanced_df['joint_probabilities'] = None\n",
        "\n",
        "    for idx, row in enhanced_df.iterrows():\n",
        "        title = row['Title']\n",
        "        priors = row['priors'] if isinstance(row['priors'], dict) else {}\n",
        "        posteriors = row['posteriors'] if isinstance(row['posteriors'], dict) else {}\n",
        "        parents = row['Parents'] if isinstance(row['Parents'], list) else []\n",
        "\n",
        "        # Skip if no parents or no priors\n",
        "        if not parents or not priors:\n",
        "            continue\n",
        "\n",
        "        # Initialize joint probabilities dictionary\n",
        "        joint_probs = {}\n",
        "\n",
        "        # Get instantiations\n",
        "        instantiations = row['instantiations']\n",
        "        if not isinstance(instantiations, list) or not instantiations:\n",
        "            continue\n",
        "\n",
        "        # For each parent and child instantiation combination, calculate joint probability\n",
        "        for inst in instantiations:\n",
        "            # Get this instantiation's prior probability\n",
        "            inst_prior_key = f\"p({inst})\"\n",
        "            if inst_prior_key not in priors:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                inst_prior = float(priors[inst_prior_key])\n",
        "            except (ValueError, TypeError):\n",
        "                continue\n",
        "\n",
        "            # For each parent\n",
        "            for parent in parents:\n",
        "                parent_row = enhanced_df[enhanced_df['Title'] == parent]\n",
        "                if parent_row.empty:\n",
        "                    continue\n",
        "\n",
        "                parent_insts = parent_row.iloc[0]['instantiations']\n",
        "                if not isinstance(parent_insts, list) or not parent_insts:\n",
        "                    continue\n",
        "\n",
        "                for parent_inst in parent_insts:\n",
        "                    # Get conditional probability\n",
        "                    cond_key = f\"p({inst}|{parent}={parent_inst})\"\n",
        "                    if cond_key in posteriors:\n",
        "                        try:\n",
        "                            cond_prob = float(posteriors[cond_key])\n",
        "\n",
        "                            # Get parent's prior\n",
        "                            parent_priors = parent_row.iloc[0]['priors']\n",
        "                            if not isinstance(parent_priors, dict):\n",
        "                                continue\n",
        "\n",
        "                            parent_prior_key = f\"p({parent_inst})\"\n",
        "                            if parent_prior_key not in parent_priors:\n",
        "                                continue\n",
        "\n",
        "                            try:\n",
        "                                parent_prior = float(parent_priors[parent_prior_key])\n",
        "\n",
        "                                # Calculate joint probability: P(A,B) = P(A|B) * P(B)\n",
        "                                joint_prob = cond_prob * parent_prior\n",
        "                                joint_key = f\"p({inst},{parent}={parent_inst})\"\n",
        "                                joint_probs[joint_key] = str(round(joint_prob, 4))\n",
        "                            except (ValueError, TypeError):\n",
        "                                continue\n",
        "                        except (ValueError, TypeError):\n",
        "                            continue\n",
        "\n",
        "        # Store joint probabilities in dataframe\n",
        "        enhanced_df.at[idx, 'joint_probabilities'] = joint_probs\n",
        "\n",
        "    # 2. Calculate network metrics\n",
        "    # Create a directed graph\n",
        "    import networkx as nx\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Add nodes\n",
        "    for idx, row in enhanced_df.iterrows():\n",
        "        G.add_node(row['Title'])\n",
        "\n",
        "    # Add edges\n",
        "    for idx, row in enhanced_df.iterrows():\n",
        "        child = row['Title']\n",
        "        parents = row['Parents'] if isinstance(row['Parents'], list) else []\n",
        "\n",
        "        for parent in parents:\n",
        "            if parent in G.nodes():\n",
        "                G.add_edge(parent, child)\n",
        "\n",
        "    # Calculate centrality measures\n",
        "    degree_centrality = nx.degree_centrality(G)\n",
        "    in_degree_centrality = nx.in_degree_centrality(G)\n",
        "    out_degree_centrality = nx.out_degree_centrality(G)\n",
        "\n",
        "    try:\n",
        "        betweenness_centrality = nx.betweenness_centrality(G)\n",
        "    except:\n",
        "        betweenness_centrality = {node: 0 for node in G.nodes()}\n",
        "\n",
        "    # Add metrics to dataframe\n",
        "    enhanced_df['degree_centrality'] = None\n",
        "    enhanced_df['in_degree_centrality'] = None\n",
        "    enhanced_df['out_degree_centrality'] = None\n",
        "    enhanced_df['betweenness_centrality'] = None\n",
        "\n",
        "    for idx, row in enhanced_df.iterrows():\n",
        "        title = row['Title']\n",
        "        enhanced_df.at[idx, 'degree_centrality'] = degree_centrality.get(title, 0)\n",
        "        enhanced_df.at[idx, 'in_degree_centrality'] = in_degree_centrality.get(title, 0)\n",
        "        enhanced_df.at[idx, 'out_degree_centrality'] = out_degree_centrality.get(title, 0)\n",
        "        enhanced_df.at[idx, 'betweenness_centrality'] = betweenness_centrality.get(title, 0)\n",
        "\n",
        "    # 3. Add Markov blanket information (parents, children, and children's parents)\n",
        "    enhanced_df['markov_blanket'] = None\n",
        "\n",
        "    for idx, row in enhanced_df.iterrows():\n",
        "        title = row['Title']\n",
        "        parents = row['Parents'] if isinstance(row['Parents'], list) else []\n",
        "        children = row['Children'] if isinstance(row['Children'], list) else []\n",
        "\n",
        "        # Get children's parents (excluding this node)\n",
        "        childrens_parents = []\n",
        "        for child in children:\n",
        "            child_row = enhanced_df[enhanced_df['Title'] == child]\n",
        "            if not child_row.empty:\n",
        "                child_parents = child_row.iloc[0]['Parents']\n",
        "                if isinstance(child_parents, list):\n",
        "                    childrens_parents.extend([p for p in child_parents if p != title])\n",
        "\n",
        "        # Remove duplicates\n",
        "        childrens_parents = list(set(childrens_parents))\n",
        "\n",
        "        # Combine to get Markov blanket\n",
        "        markov_blanket = list(set(parents + children + childrens_parents))\n",
        "        enhanced_df.at[idx, 'markov_blanket'] = markov_blanket\n",
        "\n",
        "    return enhanced_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "BBHfjdbVrTN1",
        "outputId": "014215e9-8966-4b38-caf5-917c108ff268"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-14-98a102ccdd99>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-98a102ccdd99>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    --- # @title 3.3.1 Data Post-Processing Functions ---\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0BjD1J1dahj"
      },
      "outputs": [],
      "source": [
        "# here we add all the rows that we have to calculate (joint probability..., maybe in several rounds (e.g. first add conditional proability, then use this column to calc joint probability...)\n",
        "\n",
        "# 3.3 Data Post-Processing\n",
        "\n",
        "# Enhance the extracted dataframe with calculated columns\n",
        "enhanced_df = enhance_extracted_data(result_df)\n",
        "\n",
        "# Display the enhanced dataframe\n",
        "print(\"Enhanced DataFrame with additional calculated columns:\")\n",
        "enhanced_df.head()\n",
        "\n",
        "# Check some calculated metrics\n",
        "print(\"\\nJoint Probabilities Example:\")\n",
        "example_node = enhanced_df.loc[0, 'Title']\n",
        "joint_probs = enhanced_df.loc[0, 'joint_probabilities']\n",
        "print(f\"Joint probabilities for {example_node}:\")\n",
        "print(joint_probs)\n",
        "\n",
        "print(\"\\nNetwork Metrics:\")\n",
        "for idx, row in enhanced_df.iterrows():\n",
        "    print(f\"{row['Title']}:\")\n",
        "    print(f\"  Degree Centrality: {row['degree_centrality']:.3f}\")\n",
        "    print(f\"  Betweenness Centrality: {row['betweenness_centrality']:.3f}\")\n",
        "\n",
        "# Save the enhanced dataframe\n",
        "enhanced_df.to_csv('enhanced_extracted_data.csv', index=False)\n",
        "print(\"\\nEnhanced data saved to 'enhanced_extracted_data.csv'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTwPO_J-dahj"
      },
      "source": [
        "### 3.4 Download and save finished data frame as .csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rJEacladahj"
      },
      "outputs": [],
      "source": [
        "result_df.to_csv('extracted_data.csv', index=False) # save dataframe in environment as .csv file\n",
        "# Attention: if the new or updated .csv file is required later, it needs to be pushed to the GitRepository!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHQm7ydMmPhN"
      },
      "source": [
        "# 4.0 Analysis & Inference: Practical Software Tools ()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSeSAPvtgIgU"
      },
      "source": [
        "## Phase 1: Dependencies/Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ydIAKN4gJIb"
      },
      "outputs": [],
      "source": [
        "from pyvis.network import Network\n",
        "import networkx as nx\n",
        "from IPython.display import HTML\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import base64\n",
        "import colorsys\n",
        "import json\n",
        "\n",
        "def create_bayesian_network_with_probabilities(df):\n",
        "    \"\"\"\n",
        "    Create an interactive Bayesian network visualization with enhanced probability visualization\n",
        "    and node classification based on network structure.\n",
        "    \"\"\"\n",
        "    # Create a directed graph\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Add nodes with proper attributes\n",
        "    for idx, row in df.iterrows():\n",
        "        title = row['Title']\n",
        "        description = row['Description']\n",
        "\n",
        "        # Process probability information\n",
        "        priors = get_priors(row)\n",
        "        instantiations = get_instantiations(row)\n",
        "\n",
        "        # Add node with base information\n",
        "        G.add_node(\n",
        "            title,\n",
        "            description=description,\n",
        "            priors=priors,\n",
        "            instantiations=instantiations,\n",
        "            posteriors=get_posteriors(row)\n",
        "        )\n",
        "\n",
        "    # Add edges\n",
        "    for idx, row in df.iterrows():\n",
        "        child = row['Title']\n",
        "        parents = get_parents(row)\n",
        "\n",
        "        # Add edges from each parent to this child\n",
        "        for parent in parents:\n",
        "            if parent in G.nodes():\n",
        "                G.add_edge(parent, child)\n",
        "\n",
        "    # Classify nodes based on network structure\n",
        "    classify_nodes(G)\n",
        "\n",
        "    # Create network visualization\n",
        "    net = Network(notebook=True, directed=True, cdn_resources=\"in_line\", height=\"600px\", width=\"100%\")\n",
        "\n",
        "    # Configure physics for better layout\n",
        "    net.force_atlas_2based(gravity=-50, spring_length=100, spring_strength=0.02)\n",
        "    net.show_buttons(filter_=['physics'])\n",
        "\n",
        "    # Add the graph to the network\n",
        "    net.from_nx(G)\n",
        "\n",
        "    # Enhance node appearance with probability information and classification\n",
        "    for node in net.nodes:\n",
        "        node_id = node['id']\n",
        "        node_data = G.nodes[node_id]\n",
        "\n",
        "        # Get node type and set border color\n",
        "        node_type = node_data.get('node_type', 'unknown')\n",
        "        border_color = get_border_color(node_type)\n",
        "\n",
        "        # Get probability information\n",
        "        priors = node_data.get('priors', {})\n",
        "        true_prob = priors.get('true_prob', 0.5) if priors else 0.5\n",
        "\n",
        "        # Get proper state names\n",
        "        instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n",
        "        true_state = instantiations[0] if len(instantiations) > 0 else \"TRUE\"\n",
        "        false_state = instantiations[1] if len(instantiations) > 1 else \"FALSE\"\n",
        "\n",
        "        # Create background color based on probability\n",
        "        background_color = get_probability_color(priors)\n",
        "\n",
        "        # Create tooltip with probability information\n",
        "        tooltip = create_tooltip(node_id, node_data)\n",
        "\n",
        "        # Create a simpler node label with probability\n",
        "        simple_label = f\"{node_id}\\np={true_prob:.2f}\"\n",
        "\n",
        "        # Store expanded content as a node attribute for use in click handler\n",
        "        node_data['expanded_content'] = create_expanded_content(node_id, node_data)\n",
        "\n",
        "        # Set node attributes\n",
        "        node['title'] = tooltip  # Tooltip HTML\n",
        "        node['label'] = simple_label  # Simple text label\n",
        "        node['shape'] = 'box'\n",
        "        node['color'] = {\n",
        "            'background': background_color,\n",
        "            'border': border_color,\n",
        "            'highlight': {\n",
        "                'background': background_color,\n",
        "                'border': border_color\n",
        "            }\n",
        "        }\n",
        "\n",
        "    # Set up the click handler with proper data\n",
        "    setup_data = {\n",
        "        'nodes_data': {node_id: {\n",
        "            'expanded_content': json.dumps(G.nodes[node_id].get('expanded_content', '')),\n",
        "            'description': G.nodes[node_id].get('description', ''),\n",
        "            'priors': G.nodes[node_id].get('priors', {}),\n",
        "            'posteriors': G.nodes[node_id].get('posteriors', {})\n",
        "        } for node_id in G.nodes()}\n",
        "    }\n",
        "\n",
        "    # Add custom click handling JavaScript\n",
        "    click_js = \"\"\"\n",
        "    // Store node data for click handling\n",
        "    var nodesData = %s;\n",
        "\n",
        "    // Add event listener for node clicks\n",
        "    network.on(\"click\", function(params) {\n",
        "        if (params.nodes.length > 0) {\n",
        "            var nodeId = params.nodes[0];\n",
        "            var nodeInfo = nodesData[nodeId];\n",
        "\n",
        "            if (nodeInfo) {\n",
        "                // Create a modal popup for expanded content\n",
        "                var modal = document.createElement('div');\n",
        "                modal.style.position = 'fixed';\n",
        "                modal.style.left = '50%%';\n",
        "                modal.style.top = '50%%';\n",
        "                modal.style.transform = 'translate(-50%%, -50%%)';\n",
        "                modal.style.backgroundColor = 'white';\n",
        "                modal.style.padding = '20px';\n",
        "                modal.style.borderRadius = '5px';\n",
        "                modal.style.boxShadow = '0 0 10px rgba(0,0,0,0.5)';\n",
        "                modal.style.zIndex = '1000';\n",
        "                modal.style.maxWidth = '80%%';\n",
        "                modal.style.maxHeight = '80%%';\n",
        "                modal.style.overflow = 'auto';\n",
        "\n",
        "                // Add expanded content\n",
        "                modal.innerHTML = nodeInfo.expanded_content || 'No detailed information available';\n",
        "\n",
        "                // Add close button\n",
        "                var closeBtn = document.createElement('button');\n",
        "                closeBtn.innerHTML = 'Close';\n",
        "                closeBtn.style.marginTop = '10px';\n",
        "                closeBtn.style.padding = '5px 10px';\n",
        "                closeBtn.style.cursor = 'pointer';\n",
        "                closeBtn.onclick = function() {\n",
        "                    document.body.removeChild(modal);\n",
        "                };\n",
        "                modal.appendChild(closeBtn);\n",
        "\n",
        "                // Add modal to body\n",
        "                document.body.appendChild(modal);\n",
        "            }\n",
        "        }\n",
        "    });\n",
        "    \"\"\" % json.dumps(setup_data['nodes_data'])\n",
        "\n",
        "    # Save the graph to HTML\n",
        "    html_file = \"bayesian_network.html\"\n",
        "    net.save_graph(html_file)\n",
        "\n",
        "    # Inject custom click handling into HTML\n",
        "    try:\n",
        "        with open(html_file, \"r\") as f:\n",
        "            html_content = f.read()\n",
        "\n",
        "        # Insert click handling script before the closing body tag\n",
        "        html_content = html_content.replace('</body>', f'<script>{click_js}</script></body>')\n",
        "\n",
        "        # Write back the modified HTML\n",
        "        with open(html_file, \"w\") as f:\n",
        "            f.write(html_content)\n",
        "\n",
        "        return HTML(html_content)\n",
        "    except Exception as e:\n",
        "        return HTML(f\"<p>Error rendering HTML: {str(e)}</p><p>The network visualization has been saved to '{html_file}'</p>\")\n",
        "\n",
        "def classify_nodes(G):\n",
        "    \"\"\"\n",
        "    Classify nodes as parent, child, or leaf based on network structure\n",
        "    \"\"\"\n",
        "    for node in G.nodes():\n",
        "        predecessors = list(G.predecessors(node))\n",
        "        successors = list(G.successors(node))\n",
        "\n",
        "        if not predecessors:  # No parents\n",
        "            if successors:  # Has children\n",
        "                G.nodes[node]['node_type'] = 'parent'\n",
        "            else:  # No children either\n",
        "                G.nodes[node]['node_type'] = 'isolated'\n",
        "        else:  # Has parents\n",
        "            if not successors:  # No children\n",
        "                G.nodes[node]['node_type'] = 'leaf'\n",
        "            else:  # Has both parents and children\n",
        "                G.nodes[node]['node_type'] = 'child'\n",
        "\n",
        "def get_border_color(node_type):\n",
        "    \"\"\"\n",
        "    Return border color based on node type\n",
        "    \"\"\"\n",
        "    if node_type == 'parent':\n",
        "        return '#0000FF'  # Blue\n",
        "    elif node_type == 'child':\n",
        "        return '#800080'  # Purple\n",
        "    elif node_type == 'leaf':\n",
        "        return '#FF00FF'  # Magenta\n",
        "    else:\n",
        "        return '#000000'  # Default black\n",
        "\n",
        "def get_probability_color(priors):\n",
        "    \"\"\"\n",
        "    Create background color based on probability (red to green gradient)\n",
        "    \"\"\"\n",
        "    # Default to neutral color if no probability\n",
        "    if not priors or 'true_prob' not in priors:\n",
        "        return '#F8F8F8'  # Light grey\n",
        "\n",
        "    # Get probability value\n",
        "    prob = priors['true_prob']\n",
        "\n",
        "    # Create color gradient from red (0.0) to green (1.0)\n",
        "    hue = 120 * prob  # 0 = red, 120 = green (in HSL color space)\n",
        "    saturation = 0.75\n",
        "    lightness = 0.8  # Lighter color for better text visibility\n",
        "\n",
        "    # Convert HSL to RGB\n",
        "    r, g, b = colorsys.hls_to_rgb(hue/360, lightness, saturation)\n",
        "\n",
        "    # Convert to hex format\n",
        "    hex_color = \"#{:02x}{:02x}{:02x}\".format(int(r*255), int(g*255), int(b*255))\n",
        "\n",
        "    return hex_color\n",
        "\n",
        "def create_tooltip(node_id, node_data):\n",
        "    \"\"\"\n",
        "    Create rich HTML tooltip with probability information\n",
        "    Uses simplified HTML that works well in tooltips\n",
        "    \"\"\"\n",
        "    description = node_data.get('description', '')\n",
        "    priors = node_data.get('priors', {})\n",
        "    instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n",
        "\n",
        "    # Start building the HTML tooltip\n",
        "    html = f\"\"\"\n",
        "    <div style='max-width:350px; padding:10px; background-color:#f8f9fa; border-radius:5px; font-family:Arial, sans-serif;'>\n",
        "        <h3 style='margin-top:0; color:#202124;'>{node_id}</h3>\n",
        "        <p style='font-style:italic;'>{description}</p>\n",
        "    \"\"\"\n",
        "\n",
        "    # Add probability information if available\n",
        "    if priors and 'true_prob' in priors:\n",
        "        true_prob = priors['true_prob']\n",
        "        false_prob = 1.0 - true_prob\n",
        "\n",
        "        # Get proper state names\n",
        "        true_state = instantiations[0] if len(instantiations) > 0 else \"TRUE\"\n",
        "        false_state = instantiations[1] if len(instantiations) > 1 else \"FALSE\"\n",
        "\n",
        "        html += f\"\"\"\n",
        "        <div style='margin-top:10px; background-color:#fff; padding:8px; border-radius:4px; border:1px solid #ddd;'>\n",
        "            <h4 style='margin-top:0; font-size:14px;'>Probabilities:</h4>\n",
        "            <div>{true_state}: <b>{true_prob:.3f}</b></div>\n",
        "            <div>{false_state}: <b>{false_prob:.3f}</b></div>\n",
        "            <div style='width:100%; height:20px; margin-top:5px; border:1px solid #ccc;'>\n",
        "                <div style='float:left; width:{true_prob*100}%; height:100%; background-color:rgba(0,200,0,0.5); border-right:2px solid green;'></div>\n",
        "                <div style='float:left; width:{false_prob*100}%; height:100%; background-color:rgba(255,0,0,0.5);'></div>\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    # Add click instruction\n",
        "    html += \"\"\"\n",
        "    <div style='margin-top:10px; font-size:12px; text-align:center; color:#666;'>\n",
        "        Click for detailed information\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    # Close the main div\n",
        "    html += \"</div>\"\n",
        "\n",
        "    return html\n",
        "\n",
        "def create_expanded_content(node_id, node_data):\n",
        "    \"\"\"\n",
        "    Create expanded content shown when a node is clicked\n",
        "    This is stored as a string and converted to HTML in the click handler\n",
        "    \"\"\"\n",
        "    description = node_data.get('description', '')\n",
        "    priors = node_data.get('priors', {})\n",
        "    posteriors = node_data.get('posteriors', {})\n",
        "    instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n",
        "\n",
        "    # Get probability values\n",
        "    true_prob = priors.get('true_prob', 0.5) if priors else 0.5\n",
        "    false_prob = 1.0 - true_prob\n",
        "\n",
        "    # Get proper state names\n",
        "    true_state = instantiations[0] if len(instantiations) > 0 else \"TRUE\"\n",
        "    false_state = instantiations[1] if len(instantiations) > 1 else \"FALSE\"\n",
        "\n",
        "    # Start building HTML content\n",
        "    html = f\"\"\"\n",
        "    <div style=\"max-width:600px; padding:20px;\">\n",
        "        <h2 style=\"margin-top:0;\">{node_id}</h2>\n",
        "        <p style=\"font-style:italic;\">{description}</p>\n",
        "\n",
        "        <div style=\"margin-top:20px;\">\n",
        "            <h3>Prior Probabilities</h3>\n",
        "            <table style=\"width:100%; border-collapse:collapse;\">\n",
        "                <tr style=\"background-color:#f0f0f0;\">\n",
        "                    <th style=\"padding:8px; border:1px solid #ddd; text-align:left;\">State</th>\n",
        "                    <th style=\"padding:8px; border:1px solid #ddd; text-align:right;\">Probability</th>\n",
        "                    <th style=\"padding:8px; border:1px solid #ddd;\">Visualization</th>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td style=\"padding:8px; border:1px solid #ddd;\">{true_state}</td>\n",
        "                    <td style=\"padding:8px; border:1px solid #ddd; text-align:right;\">{true_prob:.3f}</td>\n",
        "                    <td style=\"padding:8px; border:1px solid #ddd;\">\n",
        "                        <div style=\"width:100%; height:20px; background-color:#f0f0f0;\">\n",
        "                            <div style=\"width:{true_prob*100}%; height:100%; background-color:rgba(0,200,0,0.5);\"></div>\n",
        "                        </div>\n",
        "                    </td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td style=\"padding:8px; border:1px solid #ddd;\">{false_state}</td>\n",
        "                    <td style=\"padding:8px; border:1px solid #ddd; text-align:right;\">{false_prob:.3f}</td>\n",
        "                    <td style=\"padding:8px; border:1px solid #ddd;\">\n",
        "                        <div style=\"width:100%; height:20px; background-color:#f0f0f0;\">\n",
        "                            <div style=\"width:{false_prob*100}%; height:100%; background-color:rgba(255,0,0,0.5);\"></div>\n",
        "                        </div>\n",
        "                    </td>\n",
        "                </tr>\n",
        "            </table>\n",
        "        </div>\n",
        "    \"\"\"\n",
        "\n",
        "    # Add conditional probabilities if available\n",
        "    if posteriors and len(posteriors) > 0:\n",
        "        html += \"\"\"\n",
        "        <div style=\"margin-top:20px;\">\n",
        "            <h3>Conditional Probabilities</h3>\n",
        "            <table style=\"width:100%; border-collapse:collapse;\">\n",
        "                <tr style=\"background-color:#f0f0f0;\">\n",
        "                    <th style=\"padding:8px; border:1px solid #ddd; text-align:left;\">Condition</th>\n",
        "                    <th style=\"padding:8px; border:1px solid #ddd; text-align:right;\">Value</th>\n",
        "                </tr>\n",
        "        \"\"\"\n",
        "\n",
        "        # Add each conditional probability\n",
        "        for key, value in posteriors.items():\n",
        "            html += f\"\"\"\n",
        "            <tr>\n",
        "                <td style=\"padding:8px; border:1px solid #ddd;\">{key}</td>\n",
        "                <td style=\"padding:8px; border:1px solid #ddd; text-align:right;\">{value}</td>\n",
        "            </tr>\n",
        "            \"\"\"\n",
        "\n",
        "        html += \"\"\"\n",
        "            </table>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    # Close the main container\n",
        "    html += \"\"\"\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    return html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byAExfek5yFU"
      },
      "source": [
        "## Phase 2: Node Classification and Styling Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnRRLVq05yhr"
      },
      "outputs": [],
      "source": [
        "def classify_nodes(G):\n",
        "    \"\"\"\n",
        "    Classify nodes as parent, child, or leaf based on network structure\n",
        "    \"\"\"\n",
        "    for node in G.nodes():\n",
        "        predecessors = list(G.predecessors(node))\n",
        "        successors = list(G.successors(node))\n",
        "\n",
        "        if not predecessors:  # No parents\n",
        "            if successors:  # Has children\n",
        "                G.nodes[node]['node_type'] = 'parent'\n",
        "            else:  # No children either\n",
        "                G.nodes[node]['node_type'] = 'isolated'\n",
        "        else:  # Has parents\n",
        "            if not successors:  # No children\n",
        "                G.nodes[node]['node_type'] = 'leaf'\n",
        "            else:  # Has both parents and children\n",
        "                G.nodes[node]['node_type'] = 'child'\n",
        "\n",
        "def get_border_color(node_type):\n",
        "    \"\"\"\n",
        "    Return border color based on node type\n",
        "    \"\"\"\n",
        "    if node_type == 'parent':\n",
        "        return '#0000FF'  # Blue\n",
        "    elif node_type == 'child':\n",
        "        return '#800080'  # Purple\n",
        "    elif node_type == 'leaf':\n",
        "        return '#FF00FF'  # Magenta\n",
        "    else:\n",
        "        return '#000000'  # Default black\n",
        "\n",
        "def get_probability_color(priors):\n",
        "    \"\"\"\n",
        "    Create background color based on probability (red to green gradient)\n",
        "    \"\"\"\n",
        "    # Default to neutral color if no probability\n",
        "    if not priors or 'true_prob' not in priors:\n",
        "        return '#F8F8F8'  # Light grey\n",
        "\n",
        "    # Get probability value\n",
        "    prob = priors['true_prob']\n",
        "\n",
        "    # Create color gradient from red (0.0) to green (1.0)\n",
        "    hue = 120 * prob  # 0 = red, 120 = green (in HSL color space)\n",
        "    saturation = 0.75\n",
        "    lightness = 0.8  # Lighter color for better text visibility\n",
        "\n",
        "    # Convert HSL to RGB\n",
        "    r, g, b = colorsys.hls_to_rgb(hue/360, lightness, saturation)\n",
        "\n",
        "    # Convert to hex format\n",
        "    hex_color = \"#{:02x}{:02x}{:02x}\".format(int(r*255), int(g*255), int(b*255))\n",
        "\n",
        "    return hex_color\n",
        "\n",
        "def get_parents(row):\n",
        "    \"\"\"\n",
        "    Extract parent nodes from row data, with safe handling for different data types\n",
        "    \"\"\"\n",
        "    if 'Parents' not in row:\n",
        "        return []\n",
        "\n",
        "    parents_data = row['Parents']\n",
        "\n",
        "    # Handle NaN, None, or empty list\n",
        "    if isinstance(parents_data, float) and pd.isna(parents_data):\n",
        "        return []\n",
        "\n",
        "    if parents_data is None:\n",
        "        return []\n",
        "\n",
        "    # Handle different data types\n",
        "    if isinstance(parents_data, list):\n",
        "        # Return a list with NaN and empty strings removed\n",
        "        return [p for p in parents_data if not (isinstance(p, float) and pd.isna(p)) and p != '']\n",
        "\n",
        "    if isinstance(parents_data, str):\n",
        "        if not parents_data.strip():\n",
        "            return []\n",
        "\n",
        "        # Remove brackets and split by comma, removing empty strings and NaN\n",
        "        cleaned = parents_data.strip('[]\"\\'')\n",
        "        if not cleaned:\n",
        "            return []\n",
        "\n",
        "        return [p.strip(' \"\\'') for p in cleaned.split(',') if p.strip()]\n",
        "\n",
        "    # Default: empty list\n",
        "    return []\n",
        "\n",
        "def get_instantiations(row):\n",
        "    \"\"\"\n",
        "    Extract instantiations with safe handling for different data types\n",
        "    \"\"\"\n",
        "    if 'instantiations' not in row:\n",
        "        return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "    inst_data = row['instantiations']\n",
        "\n",
        "    # Handle NaN or None\n",
        "    if isinstance(inst_data, float) and pd.isna(inst_data):\n",
        "        return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "    if inst_data is None:\n",
        "        return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "    # Handle different data types\n",
        "    if isinstance(inst_data, list):\n",
        "        return inst_data if inst_data else [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "    if isinstance(inst_data, str):\n",
        "        if not inst_data.strip():\n",
        "            return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "        # Remove brackets and split by comma\n",
        "        cleaned = inst_data.strip('[]\"\\'')\n",
        "        if not cleaned:\n",
        "            return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "        return [i.strip(' \"\\'') for i in cleaned.split(',') if i.strip()]\n",
        "\n",
        "    # Default\n",
        "    return [\"TRUE\", \"FALSE\"]\n",
        "\n",
        "def get_priors(row):\n",
        "    \"\"\"\n",
        "    Extract prior probabilities with safe handling for different data types\n",
        "    \"\"\"\n",
        "    if 'priors' not in row:\n",
        "        return {}\n",
        "\n",
        "    priors_data = row['priors']\n",
        "\n",
        "    # Handle NaN or None\n",
        "    if isinstance(priors_data, float) and pd.isna(priors_data):\n",
        "        return {}\n",
        "\n",
        "    if priors_data is None:\n",
        "        return {}\n",
        "\n",
        "    result = {}\n",
        "\n",
        "    # Handle dictionary\n",
        "    if isinstance(priors_data, dict):\n",
        "        result = priors_data\n",
        "    # Handle string representation of dictionary\n",
        "    elif isinstance(priors_data, str):\n",
        "        if not priors_data.strip() or priors_data == '{}':\n",
        "            return {}\n",
        "\n",
        "        try:\n",
        "            # Try to evaluate as Python literal\n",
        "            import ast\n",
        "            result = ast.literal_eval(priors_data)\n",
        "        except:\n",
        "            # Simple parsing for items like {'p(TRUE)': '0.2', 'p(FALSE)': '0.8'}\n",
        "            if '{' in priors_data and '}' in priors_data:\n",
        "                content = priors_data[priors_data.find('{')+1:priors_data.rfind('}')]\n",
        "                items = [item.strip() for item in content.split(',')]\n",
        "\n",
        "                for item in items:\n",
        "                    if ':' in item:\n",
        "                        key, value = item.split(':', 1)\n",
        "                        key = key.strip(' \\'\\\"')\n",
        "                        value = value.strip(' \\'\\\"')\n",
        "                        result[key] = value\n",
        "\n",
        "    # Extract main probability for TRUE state\n",
        "    instantiations = get_instantiations(row)\n",
        "    true_state = instantiations[0] if instantiations else \"TRUE\"\n",
        "    true_key = f\"p({true_state})\"\n",
        "\n",
        "    if true_key in result:\n",
        "        try:\n",
        "            result['true_prob'] = float(result[true_key])\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    return result\n",
        "\n",
        "def get_posteriors(row):\n",
        "    \"\"\"\n",
        "    Extract posterior probabilities with safe handling for different data types\n",
        "    \"\"\"\n",
        "    if 'posteriors' not in row:\n",
        "        return {}\n",
        "\n",
        "    posteriors_data = row['posteriors']\n",
        "\n",
        "    # Handle NaN or None\n",
        "    if isinstance(posteriors_data, float) and pd.isna(posteriors_data):\n",
        "        return {}\n",
        "\n",
        "    if posteriors_data is None:\n",
        "        return {}\n",
        "\n",
        "    result = {}\n",
        "\n",
        "    # Handle dictionary\n",
        "    if isinstance(posteriors_data, dict):\n",
        "        result = posteriors_data\n",
        "    # Handle string representation of dictionary\n",
        "    elif isinstance(posteriors_data, str):\n",
        "        if not posteriors_data.strip() or posteriors_data == '{}':\n",
        "            return {}\n",
        "\n",
        "        try:\n",
        "            # Try to evaluate as Python literal\n",
        "            import ast\n",
        "            result = ast.literal_eval(posteriors_data)\n",
        "        except:\n",
        "            # Simple parsing\n",
        "            if '{' in posteriors_data and '}' in posteriors_data:\n",
        "                content = posteriors_data[posteriors_data.find('{')+1:posteriors_data.rfind('}')]\n",
        "                items = [item.strip() for item in content.split(',')]\n",
        "\n",
        "                for item in items:\n",
        "                    if ':' in item:\n",
        "                        key, value = item.split(':', 1)\n",
        "                        key = key.strip(' \\'\\\"')\n",
        "                        value = value.strip(' \\'\\\"')\n",
        "                        result[key] = value\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnS3jFGU52OZ"
      },
      "source": [
        "## Phase 3: HTML Content Generation Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShVDxse152gY"
      },
      "outputs": [],
      "source": [
        "def create_probability_bar(true_prob, false_prob, height=\"15px\", show_values=True, value_prefix=\"\"):\n",
        "    \"\"\"\n",
        "    Creates a reusable HTML component to visualize probability distribution\n",
        "    \"\"\"\n",
        "    true_label = f\"{value_prefix}{true_prob:.3f}\" if show_values else \"\"\n",
        "    false_label = f\"{value_prefix}{false_prob:.3f}\" if show_values else \"\"\n",
        "\n",
        "    html = f\"\"\"\n",
        "    <div style=\"width:100%; height:{height}; display:flex; border:1px solid #ccc; overflow:hidden; border-radius:3px; margin-top:3px; margin-bottom:3px;\">\n",
        "        <div style=\"flex-basis:{true_prob*100}%; background:linear-gradient(to bottom, rgba(0,180,0,0.9), rgba(0,140,0,0.7)); border-right:2px solid #008800; display:flex; align-items:center; justify-content:center; overflow:hidden; min-width:{2 if true_prob > 0 else 0}px;\">\n",
        "            <span style=\"font-size:10px; color:white; text-shadow:0px 0px 2px #000;\">{true_label}</span>\n",
        "        </div>\n",
        "        <div style=\"flex-basis:{false_prob*100}%; background:linear-gradient(to bottom, rgba(220,0,0,0.9), rgba(180,0,0,0.7)); border-left:2px solid #880000; display:flex; align-items:center; justify-content:center; overflow:hidden; min-width:{2 if false_prob > 0 else 0}px;\">\n",
        "            <span style=\"font-size:10px; color:white; text-shadow:0px 0px 2px #000;\">{false_label}</span>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    return html\n",
        "\n",
        "def create_tooltip(node_id, node_data):\n",
        "    \"\"\"\n",
        "    Create rich HTML tooltip with probability information\n",
        "    \"\"\"\n",
        "    description = node_data.get('description', '')\n",
        "    priors = node_data.get('priors', {})\n",
        "    instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n",
        "\n",
        "    # Start building the HTML tooltip\n",
        "    html = f\"\"\"\n",
        "    <div style=\"max-width:350px; padding:10px; background-color:#f8f9fa; border-radius:5px; font-family:Arial, sans-serif;\">\n",
        "        <h3 style=\"margin-top:0; color:#202124;\">{node_id}</h3>\n",
        "        <p style=\"font-style:italic;\">{description}</p>\n",
        "    \"\"\"\n",
        "\n",
        "    # Add prior probabilities section\n",
        "    if priors and 'true_prob' in priors:\n",
        "        true_prob = priors['true_prob']\n",
        "        false_prob = 1.0 - true_prob\n",
        "\n",
        "        # Get proper state names\n",
        "        true_state = instantiations[0] if len(instantiations) > 0 else \"TRUE\"\n",
        "        false_state = instantiations[1] if len(instantiations) > 1 else \"FALSE\"\n",
        "\n",
        "        html += f\"\"\"\n",
        "        <div style=\"margin-top:10px; background-color:#fff; padding:8px; border-radius:4px; border:1px solid #ddd;\">\n",
        "            <h4 style=\"margin-top:0; font-size:14px;\">Prior Probabilities:</h4>\n",
        "            <div style=\"display:flex; justify-content:space-between; margin-bottom:4px;\">\n",
        "                <div style=\"font-size:12px;\">{true_state}: {true_prob:.3f}</div>\n",
        "                <div style=\"font-size:12px;\">{false_state}: {false_prob:.3f}</div>\n",
        "            </div>\n",
        "            {create_probability_bar(true_prob, false_prob, \"20px\", True)}\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    # Add click instruction\n",
        "    html += \"\"\"\n",
        "    <div style=\"margin-top:8px; font-size:12px; color:#666; text-align:center;\">\n",
        "        Click node to see full probability details\n",
        "    </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    return html\n",
        "\n",
        "def create_expanded_content(node_id, node_data):\n",
        "    \"\"\"\n",
        "    Create expanded content shown when a node is clicked\n",
        "    \"\"\"\n",
        "    description = node_data.get('description', '')\n",
        "    priors = node_data.get('priors', {})\n",
        "    posteriors = node_data.get('posteriors', {})\n",
        "    instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n",
        "\n",
        "    # Get proper state names\n",
        "    true_state = instantiations[0] if len(instantiations) > 0 else \"TRUE\"\n",
        "    false_state = instantiations[1] if len(instantiations) > 1 else \"FALSE\"\n",
        "\n",
        "    # Extract probabilities\n",
        "    true_prob = priors.get('true_prob', 0.5)\n",
        "    false_prob = 1.0 - true_prob\n",
        "\n",
        "    # Start building the expanded content\n",
        "    html = f\"\"\"\n",
        "    <div style=\"max-width:500px; padding:15px; font-family:Arial, sans-serif;\">\n",
        "        <h2 style=\"margin-top:0; color:#333;\">{node_id}</h2>\n",
        "        <p style=\"font-style:italic; margin-bottom:15px;\">{description}</p>\n",
        "\n",
        "        <div style=\"margin-bottom:20px; padding:12px; border:1px solid #ddd; background-color:#f9f9f9; border-radius:5px;\">\n",
        "            <h3 style=\"margin-top:0; color:#333;\">Prior Probabilities</h3>\n",
        "            <div style=\"display:flex; justify-content:space-between; margin-bottom:5px;\">\n",
        "                <div><strong>{true_state}:</strong> {true_prob:.3f}</div>\n",
        "                <div><strong>{false_state}:</strong> {false_prob:.3f}</div>\n",
        "            </div>\n",
        "            {create_probability_bar(true_prob, false_prob, \"25px\", True)}\n",
        "        </div>\n",
        "    \"\"\"\n",
        "\n",
        "    # Add conditional probability table if available\n",
        "    if posteriors:\n",
        "        html += \"\"\"\n",
        "        <div style=\"padding:12px; border:1px solid #ddd; background-color:#f9f9f9; border-radius:5px;\">\n",
        "            <h3 style=\"margin-top:0; color:#333;\">Conditional Probabilities</h3>\n",
        "            <table style=\"width:100%; border-collapse:collapse; font-size:13px;\">\n",
        "                <tr style=\"background-color:#eee;\">\n",
        "                    <th style=\"padding:8px; text-align:left; border:1px solid #ddd;\">Condition</th>\n",
        "                    <th style=\"padding:8px; text-align:center; border:1px solid #ddd; width:80px;\">Value</th>\n",
        "                    <th style=\"padding:8px; text-align:center; border:1px solid #ddd;\">Visualization</th>\n",
        "                </tr>\n",
        "        \"\"\"\n",
        "\n",
        "        # Sort posteriors to group by similar conditions\n",
        "        posterior_items = list(posteriors.items())\n",
        "        posterior_items.sort(key=lambda x: x[0])\n",
        "\n",
        "        # Add rows for conditional probabilities\n",
        "        for key, value in posterior_items:\n",
        "            try:\n",
        "                # Try to parse probability value\n",
        "                prob_value = float(value)\n",
        "                inv_prob = 1.0 - prob_value\n",
        "\n",
        "                # Add row with probability visualization\n",
        "                html += f\"\"\"\n",
        "                <tr>\n",
        "                    <td style=\"padding:8px; border:1px solid #ddd;\">{key}</td>\n",
        "                    <td style=\"padding:8px; text-align:center; border:1px solid #ddd;\">{prob_value:.3f}</td>\n",
        "                    <td style=\"padding:8px; border:1px solid #ddd;\">\n",
        "                        {create_probability_bar(prob_value, inv_prob, \"20px\", False)}\n",
        "                    </td>\n",
        "                </tr>\n",
        "                \"\"\"\n",
        "            except:\n",
        "                # Fallback for non-numeric values\n",
        "                html += f\"\"\"\n",
        "                <tr>\n",
        "                    <td style=\"padding:8px; border:1px solid #ddd;\">{key}</td>\n",
        "                    <td style=\"padding:8px; text-align:center; border:1px solid #ddd;\" colspan=\"2\">{value}</td>\n",
        "                </tr>\n",
        "                \"\"\"\n",
        "\n",
        "        html += \"\"\"\n",
        "            </table>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    html += \"</div>\"\n",
        "\n",
        "    return html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2uyG0Pi571f"
      },
      "source": [
        "## Phase 4: Main Visualization Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UkPk-bm5_fm"
      },
      "outputs": [],
      "source": [
        "def create_bayesian_network_with_probabilities(df):\n",
        "    \"\"\"\n",
        "    Create an interactive Bayesian network visualization with enhanced probability visualization\n",
        "    and node classification based on network structure.\n",
        "    \"\"\"\n",
        "    # Create a directed graph\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Add nodes with proper attributes\n",
        "    for idx, row in df.iterrows():\n",
        "        title = row['Title']\n",
        "        description = row['Description']\n",
        "\n",
        "        # Process probability information\n",
        "        priors = get_priors(row)\n",
        "        instantiations = get_instantiations(row)\n",
        "\n",
        "        # Add node with base information\n",
        "        G.add_node(\n",
        "            title,\n",
        "            description=description,\n",
        "            priors=priors,\n",
        "            instantiations=instantiations,\n",
        "            posteriors=get_posteriors(row)\n",
        "        )\n",
        "\n",
        "    # Add edges\n",
        "    for idx, row in df.iterrows():\n",
        "        child = row['Title']\n",
        "        parents = get_parents(row)\n",
        "\n",
        "        # Add edges from each parent to this child\n",
        "        for parent in parents:\n",
        "            if parent in G.nodes():\n",
        "                G.add_edge(parent, child)\n",
        "\n",
        "    # Classify nodes based on network structure\n",
        "    classify_nodes(G)\n",
        "\n",
        "    # Create network visualization\n",
        "    net = Network(notebook=True, directed=True, cdn_resources=\"in_line\", height=\"600px\", width=\"100%\")\n",
        "\n",
        "    # Configure physics for better layout\n",
        "    net.force_atlas_2based(gravity=-50, spring_length=100, spring_strength=0.02)\n",
        "    net.show_buttons(filter_=['physics'])\n",
        "\n",
        "    # Add the graph to the network\n",
        "    net.from_nx(G)\n",
        "\n",
        "    # Enhance node appearance with probability information and classification\n",
        "    for node in net.nodes:\n",
        "        node_id = node['id']\n",
        "        node_data = G.nodes[node_id]\n",
        "\n",
        "        # Get node type and set border color\n",
        "        node_type = node_data.get('node_type', 'unknown')\n",
        "        border_color = get_border_color(node_type)\n",
        "\n",
        "        # Get probability information\n",
        "        priors = node_data.get('priors', {})\n",
        "        true_prob = priors.get('true_prob', 0.5) if priors else 0.5\n",
        "\n",
        "        # Get proper state names\n",
        "        instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n",
        "        true_state = instantiations[0] if len(instantiations) > 0 else \"TRUE\"\n",
        "        false_state = instantiations[1] if len(instantiations) > 1 else \"FALSE\"\n",
        "\n",
        "        # Create background color based on probability\n",
        "        background_color = get_probability_color(priors)\n",
        "\n",
        "        # Create tooltip with probability information\n",
        "        tooltip = create_tooltip(node_id, node_data)\n",
        "\n",
        "        # Create a simpler node label with probability\n",
        "        simple_label = f\"{node_id}\\np={true_prob:.2f}\"\n",
        "\n",
        "        # Store expanded content as a node attribute for use in click handler\n",
        "        node_data['expanded_content'] = create_expanded_content(node_id, node_data)\n",
        "\n",
        "        # Set node attributes\n",
        "        node['title'] = tooltip  # Tooltip HTML\n",
        "        node['label'] = simple_label  # Simple text label\n",
        "        node['shape'] = 'box'\n",
        "        node['color'] = {\n",
        "            'background': background_color,\n",
        "            'border': border_color,\n",
        "            'highlight': {\n",
        "                'background': background_color,\n",
        "                'border': border_color\n",
        "            }\n",
        "        }\n",
        "\n",
        "    # Set up the click handler with proper data\n",
        "    setup_data = {\n",
        "        'nodes_data': {node_id: {\n",
        "            'expanded_content': json.dumps(G.nodes[node_id].get('expanded_content', '')),\n",
        "            'description': G.nodes[node_id].get('description', ''),\n",
        "            'priors': G.nodes[node_id].get('priors', {}),\n",
        "            'posteriors': G.nodes[node_id].get('posteriors', {})\n",
        "        } for node_id in G.nodes()}\n",
        "    }\n",
        "\n",
        "    # Add custom click handling JavaScript\n",
        "    click_js = \"\"\"\n",
        "    // Store node data for click handling\n",
        "    var nodesData = %s;\n",
        "\n",
        "    // Add event listener for node clicks\n",
        "    network.on(\"click\", function(params) {\n",
        "        if (params.nodes.length > 0) {\n",
        "            var nodeId = params.nodes[0];\n",
        "            var nodeInfo = nodesData[nodeId];\n",
        "\n",
        "            if (nodeInfo) {\n",
        "                // Create a modal popup for expanded content\n",
        "                var modal = document.createElement('div');\n",
        "                modal.style.position = 'fixed';\n",
        "                modal.style.left = '50%%';\n",
        "                modal.style.top = '50%%';\n",
        "                modal.style.transform = 'translate(-50%%, -50%%)';\n",
        "                modal.style.backgroundColor = 'white';\n",
        "                modal.style.padding = '20px';\n",
        "                modal.style.borderRadius = '5px';\n",
        "                modal.style.boxShadow = '0 0 10px rgba(0,0,0,0.5)';\n",
        "                modal.style.zIndex = '1000';\n",
        "                modal.style.maxWidth = '80%%';\n",
        "                modal.style.maxHeight = '80%%';\n",
        "                modal.style.overflow = 'auto';\n",
        "\n",
        "                // Parse the JSON string back to HTML content\n",
        "                try {\n",
        "                    var expandedContent = JSON.parse(nodeInfo.expanded_content);\n",
        "                    modal.innerHTML = expandedContent;\n",
        "                } catch (e) {\n",
        "                    modal.innerHTML = 'Error displaying content: ' + e.message;\n",
        "                }\n",
        "\n",
        "                // Add close button\n",
        "                var closeBtn = document.createElement('button');\n",
        "                closeBtn.innerHTML = 'Close';\n",
        "                closeBtn.style.marginTop = '10px';\n",
        "                closeBtn.style.padding = '5px 10px';\n",
        "                closeBtn.style.cursor = 'pointer';\n",
        "                closeBtn.onclick = function() {\n",
        "                    document.body.removeChild(modal);\n",
        "                };\n",
        "                modal.appendChild(closeBtn);\n",
        "\n",
        "                // Add modal to body\n",
        "                document.body.appendChild(modal);\n",
        "            }\n",
        "        }\n",
        "    });\n",
        "    \"\"\" % json.dumps(setup_data['nodes_data'])\n",
        "\n",
        "    # Save the graph to HTML\n",
        "    html_file = \"bayesian_network.html\"\n",
        "    net.save_graph(html_file)\n",
        "\n",
        "    # Inject custom click handling into HTML\n",
        "    try:\n",
        "        with open(html_file, \"r\") as f:\n",
        "            html_content = f.read()\n",
        "\n",
        "        # Insert click handling script before the closing body tag\n",
        "        html_content = html_content.replace('</body>', f'<script>{click_js}</script></body>')\n",
        "\n",
        "        # Write back the modified HTML\n",
        "        with open(html_file, \"w\") as f:\n",
        "            f.write(html_content)\n",
        "\n",
        "        return HTML(html_content)\n",
        "    except Exception as e:\n",
        "        return HTML(f\"<p>Error rendering HTML: {str(e)}</p><p>The network visualization has been saved to '{html_file}'</p>\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFtxTKmLElSF"
      },
      "source": [
        "# Quickly check HTML Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "iY1NNo2NEraS"
      },
      "outputs": [],
      "source": [
        "create_bayesian_network_with_probabilities(result_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cf6OamxLE-bf"
      },
      "outputs": [],
      "source": [
        "# Use the function to create and display the visualization\n",
        "\n",
        "print(result_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M9gFpK6ioHk"
      },
      "source": [
        "# 5.0 Archive_version_histories\n"
      ]
    },
    {
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "\n",
        "def generate_bayesdown_questions_md(argdown_with_questions_path, output_md_path, QuestionsMinimal=False):\n",
        "    \"\"\"\n",
        "    Generate comprehensive BayesDown questions based on the enhanced CSV file.\n",
        "\n",
        "    Args:\n",
        "        argdown_with_questions_path (str): Path to the CSV file with probability questions\n",
        "        output_md_path (str): Path to save the output markdown file\n",
        "        QuestionsMinimal (bool, optional): If True, only return the questions generated for each node,\n",
        "                                           excluding terminology explanations. Defaults to False.\n",
        "    \"\"\"\n",
        "    print(f\"Loading enhanced CSV from {argdown_with_questions_path}...\")\n",
        "\n",
        "    # Load the enhanced CSV file\n",
        "    try:\n",
        "        df = pd.read_csv(argdown_with_questions_path)\n",
        "        print(f\"Successfully loaded CSV with {len(df)} rows.\")\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Error loading CSV: {e}\")\n",
        "\n",
        "    # Validate required columns\n",
        "    required_columns = ['Title', 'Generate_Positive_Instantiation_Questions', 'Generate_Negative_Instantiation_Questions']\n",
        "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "    if missing_columns:\n",
        "        raise Exception(f\"Missing required columns: {', '.join(missing_columns)}\")\n",
        "\n",
        "    print(\"Generating comprehensive BayesDown questions...\")\n",
        "\n",
        "    # Start building the markdown content\n",
        "    md_content = \"\"  # Initialize as empty string\n",
        "\n",
        "    if not QuestionsMinimal:\n",
        "        md_content += \"# BayesDown Probability Questions\\n\\n\"\n",
        "        md_content += \"This document contains questions for extracting probability estimates for BayesDown models.\\n\\n\"\n",
        "\n",
        "        # Add comprehensive terminology explanation\n",
        "        md_content += \"## Probability Terminology\\n\\n\"\n",
        "\n",
        "\n",
        "        md_content += \"### Types of Probabilities\\n\\n\"\n",
        "        md_content += \"- **Prior Probability**: The unconditional probability of a variable having a specific value before considering any evidence or parent variable states. For example, P(X=TRUE) represents the probability that X is TRUE without any additional information.\\n\\n\"\n",
        "        md_content += \"- **Conditional Probability**: The probability of a variable having a specific value given the values of its parent variables. For example, P(X=TRUE|Y=TRUE, Z=FALSE) represents the probability that X is TRUE when we know that Y is TRUE and Z is FALSE.\\n\\n\"\n",
        "        md_content += \"- **Posterior Probability**: The updated probability of a hypothesis after considering new evidence, calculated using Bayes' theorem. This represents a revised belief based on additional information.\\n\\n\"\n",
        "        md_content += \"- **Joint Probability**: The probability of multiple events occurring together. For example, P(X=TRUE, Y=FALSE) represents the probability that X is TRUE and Y is FALSE simultaneously.\\n\\n\"\n",
        "        md_content += \"- **Marginal Probability**: The probability of an event across all possible states of another variable. It can be calculated by summing the joint probability over all possible values of the other variables.\\n\\n\"\n",
        "\n",
        "        md_content += \"### Source of Probability Estimates\\n\\n\"\n",
        "        md_content += \"For each probability estimate, please identify the source using one of the following categories:\\n\\n\"\n",
        "        md_content += \"- **Direct Statement**: The probability is explicitly stated in the text.\\n\"\n",
        "        md_content += \"- **Derived Estimate**: The probability is calculated or inferred from other probabilities mentioned in the text.\\n\"\n",
        "        md_content += \"- **Context-Based Estimate**: The probability is inferred from the general context, tone, or strength of assertions in the text.\\n\"\n",
        "        md_content += \"- **Expert Judgment**: The probability is based on domain expertise, not directly stated in the text.\\n\"\n",
        "        md_content += \"- **Default Assignment**: The probability is assigned a reasonable default value due to lack of information.\\n\\n\"\n",
        "\n",
        "        md_content += \"### Certainty of Estimates\\n\\n\"\n",
        "        md_content += \"For each probability estimate, please assess your certainty using one of the following approaches:\\n\\n\"\n",
        "        md_content += \"- **Confidence Interval**: Provide a range that likely contains the true probability (e.g., \\\"80% confidence interval: 0.3-0.5\\\").\\n\"\n",
        "        md_content += \"- **Confidence Level**: Rate your confidence in the estimate on a scale (e.g., \\\"High confidence: 85%\\\").\\n\"\n",
        "        md_content += \"- **Error Margin**: Specify how much the estimate might vary (e.g., \\\"0.7 ± 0.1\\\").\\n\"\n",
        "        md_content += \"- **Qualitative Assessment**: Describe your certainty qualitatively (e.g., \\\"Very certain\\\", \\\"Moderately certain\\\", \\\"Highly uncertain\\\").\\n\\n\"\n",
        "\n",
        "\n",
        "    # Generate questions for each node\n",
        "    for idx, row in df.iterrows():\n",
        "        title = row['Title']\n",
        "        description = row['Description'] if 'Description' in df.columns and not pd.isna(row['Description']) else \"\"\n",
        "\n",
        "        md_content += f\"## {title}\\n\\n\"  # Still include title even in minimal mode\n",
        "\n",
        "        if description:\n",
        "            md_content += f\"{description}\\n\\n\"\n",
        "\n",
        "        # Process positive instantiation questions\n",
        "        try:\n",
        "            positive_questions = json.loads(row['Generate_Positive_Instantiation_Questions'])\n",
        "\n",
        "            md_content += \"### Positive Instantiation Questions\\n\\n\"\n",
        "\n",
        "            for q_type, question in positive_questions.items():\n",
        "                md_content += f\"1. **{question}**\\n\"\n",
        "\n",
        "                # Add source question with appropriate terminology based on question type\n",
        "                if q_type == 'prior':\n",
        "                    md_content += f\"   - **Source**: What is the source for this prior probability estimate? (Direct statement, derived estimate, context-based, expert judgment, default)\\n\"\n",
        "                else:\n",
        "                    md_content += f\"   - **Source**: What is the source for this conditional probability estimate? (Direct statement, derived estimate, context-based, expert judgment, default)\\n\"\n",
        "\n",
        "                # Add certainty question\n",
        "                md_content += f\"   - **Certainty**: How certain are you about this probability estimate? (Provide a confidence interval, confidence level, error margin, or qualitative assessment)\\n\\n\"\n",
        "        except Exception as e:\n",
        "            md_content += f\"No positive instantiation questions available. Error: {e}\\n\\n\"\n",
        "\n",
        "        # Process negative instantiation questions\n",
        "        try:\n",
        "            negative_questions = json.loads(row['Generate_Negative_Instantiation_Questions'])\n",
        "\n",
        "            md_content += \"### Negative Instantiation Questions\\n\\n\"\n",
        "\n",
        "            for q_type, question in negative_questions.items():\n",
        "                md_content += f\"1. **{question}**\\n\"\n",
        "\n",
        "                # Add source question with appropriate terminology based on question type\n",
        "                if q_type == 'prior':\n",
        "                    md_content += f\"   - **Source**: What is the source for this prior probability estimate? (Direct statement, derived estimate, context-based, expert judgment, default)\\n\"\n",
        "                else:\n",
        "                    md_content += f\"   - **Source**: What is the source for this conditional probability estimate? (Direct statement, derived estimate, context-based, expert judgment, default)\\n\"\n",
        "\n",
        "                # Add certainty question\n",
        "                md_content += f\"   - **Certainty**: How certain are you about this probability estimate? (Provide a confidence interval, confidence level, error margin, or qualitative assessment)\\n\\n\"\n",
        "        except Exception as e:\n",
        "            md_content += f\"No negative instantiation questions available. Error: {e}\\n\\n\"\n",
        "\n",
        "    # Save the markdown content\n",
        "    with open(output_md_path, 'w') as f:\n",
        "        f.write(md_content)\n",
        "\n",
        "    print(f\"BayesDown questions saved to {output_md_path}\")\n",
        "    return md_content\n",
        "\n",
        "# Example usage:\n",
        "md_content = generate_bayesdown_questions_md(\"ArgDown_WithQuestions.csv\", \"BayesDownQuestions.md\", QuestionsMinimal=True)\n",
        "# To get only the questions, set QuestionsMinimal=True\n",
        "\n",
        "print(md_content)  # Print the returned content to see the questions"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "MhCWfghGff3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 0.0.0 --- Install & Import Libraries & Packages (One-Time Colab Setup) ---\n",
        "\n",
        "# implement boolean flags to indicate parts of the code that has to be skipped\n",
        "# best practice in Colab?\n",
        "\n",
        "# !pip install ...    vs.  %pip install ...   vs.  from  ...  import ...  as ...    vs.   !apt-get -qq install -y\n",
        "# \"!\" preceding a code block line in tells Colab/Jupyter to execute as command line\n",
        "\n",
        "# Check if the setup flag variable exists in the global scope\n",
        "if 'setup_complete' not in globals():\n",
        "    print(\"Performing one-time setup...\")\n",
        "    # --- Your one-time code goes here ---\n",
        "    # Example: Install packages, download small files, initialize complex objects\n",
        "    # !pip install -q some_package\n",
        "    # import some_package\n",
        "    # data = download_small_dataset()\n",
        "    my_initialized_object = \"This is initialized\"\n",
        "    # --- End of one-time code ---\n",
        "\n",
        "    # Set the flag to indicate setup is done for this session\n",
        "    setup_complete = True\n",
        "    print(\"One-time setup finished.\")\n",
        "else:\n",
        "    print(\"Setup already completed in this session. Skipping.\")\n",
        "\n",
        "# You can now safely use variables/objects created during setup\n",
        "# print(my_initialized_object)\n",
        "\n",
        "try:\n",
        "    # If this variable exists, the block was already run successfully.\n",
        "    _setup_marker\n",
        "    print(\"Setup already completed in this session. Skipping.\")\n",
        "except NameError:\n",
        "    print(\"Performing one-time setup...\")\n",
        "    # --- Your one-time code goes here ---\n",
        "    # !pip install -q another_package\n",
        "    # configuration = load_config()\n",
        "    # --- End of one-time code ---\n",
        "\n",
        "    # Create the marker variable ONLY after successful execution\n",
        "    _setup_marker = True\n",
        "    print(\"One-time setup finished.\")\n",
        "\n",
        "# Use things created in setup\n",
        "# print(configuration)\n",
        "\n",
        "\n",
        "library_name = \"your_library_name\"\n",
        "try:\n",
        "    __import__(library_name)\n",
        "    print(f\"The library '{library_name}' is available in Colab.\")\n",
        "except ImportError:\n",
        "    print(f\"The library '{library_name}' is not available in Colab.\")"
      ],
      "metadata": {
        "id": "KnNMXPEMwbM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulwM2lfJcY6g"
      },
      "source": [
        "\n",
        "1.   Import Libraries & Install Packages: [Run Section 0.1](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/Public_AMTAIR_Prototype.ipynb#scrollTo=0_1_Import_Libraries_Packages)\n",
        "2.   Connect to GitHub Repository & Load Data files: Run Section 0.2\n",
        "3.   ...\n",
        "4. [Link Text](#cell-id)\n",
        "      Requires:\n",
        "<a name=\"cell-id\"></a>\n",
        "\n",
        "4. [Test](#Preview-MD-Content)\n",
        "\n",
        "\n",
        "##### Heading\n",
        "This is the cell I'm linking to\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: how to title code blocks\n",
        "\n",
        "import requests      # For making HTTP requests\n",
        "import io           # For working with in-memory file-like objects\n",
        "import pandas as pd   # For data manipulation\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML, display\n",
        "from IPython.display import Markdown, display\n",
        "import networkx as nx\n",
        "from pgmpy.models import BayesianNetwork\n",
        "from pgmpy.factors.discrete import TabularCPD\n",
        "from pgmpy.inference import VariableElimination\n",
        "from pyvis.network import Network\n",
        "import os\n",
        "import os.path\n",
        "from IPython.display import IFrame\n",
        "import itertools\n",
        "\n",
        "\n",
        "# --- 2. Data Processing: ArgDown to BayesDown ---\n",
        "# Load the data from the ArgDown_WithQuestions CSV file\n",
        "argdown_with_questions_df = pd.read_csv('ArgDown_WithQuestions.csv')\n",
        "\n",
        "# Display the DataFrame\n",
        "print(argdown_with_questions_df)\n",
        "argdown_with_questions_df\n",
        "\n",
        "\n",
        "# --- 2.2 ArgDown_WithQuestions.csv to BayesDownQuestions.md ---\n",
        "def extract_bayesdown_questions_fixed(argdown_with_questions_path, output_md_path, include_questions_as_comments=True):\n",
        "    # ... (function code as before) ...\n",
        "\n",
        "\n",
        "# --- 2.3 Generate BayesDown Probability Extraction Prompt ---\n",
        "# ... (code for generating the prompt) ...\n",
        "\n",
        "\n",
        "# --- 2.4 Prepare 2nd API call ---\n",
        "# ... (code for preparing the API call) ...\n",
        "\n",
        "\n",
        "# --- 2.5 Make BayesDown Probability Extraction API Call ---\n",
        "# ... (code for making the API call) ...\n",
        "\n",
        "\n",
        "# --- 2.6 Save BayesDown with Probability Estimates (.csv) ---\n",
        "# ... (code for saving the data) ...\n",
        "\n",
        "\n",
        "# --- 2.7 Review & Verify BayesDown Probability Estimates ---\n",
        "# ... (code for review and verification) ...\n",
        "\n",
        "\n",
        "# --- 2.8 Extract BayesDown with Probability Estimates as Dataframe ---\n",
        "# ... (code for extraction) ...\n",
        "\n",
        "\n",
        "# --- 3. Data Extraction: BayesDown (.md) to Database (.csv) ---\n",
        "# --- 3.1 ExtractBayesDown-Data_v1 ---\n",
        "# ... (code for BayesDown data extraction) ...\n",
        "\n",
        "\n",
        "# --- 3.1.2 Test BayesDown Extraction ---\n",
        "# ... (code for testing BayesDown extraction) ...\n",
        "\n",
        "\n",
        "# --- 3.3 Extraction ---\n",
        "# ... (code for extraction) ...\n",
        "\n",
        "\n",
        "# --- 3.3 Data-Post-Processing ---\n",
        "# ... (code for data post-processing) ...\n"
      ],
      "metadata": {
        "id": "TDFVC07xrHCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## COMBINED: 2.1 Generate and Extract \"Prior-, Conditional- and Posterior Probability Questions\" from 'ArgDown.csv' to 'ArgDown_WithQuestions.csv'"
      ],
      "metadata": {
        "id": "-Y7587rHcJ-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function to fix the ArgDown → BayesDown generation pipeline\n",
        "def fix_bayesdown_generation():\n",
        "    # Step 1: Fix the relationship establishment function\n",
        "    def establish_relationships_fixed(titles_info, text):\n",
        "        \"\"\"\n",
        "        Establish parent-child relationships between titles using BayesDown indentation rules.\n",
        "\n",
        "        In BayesDown syntax:\n",
        "        - More indented nodes (with + symbol) are PARENTS of less indented nodes\n",
        "        - The relationship reads as \"Effect is caused by Cause\" (Effect + Cause)\n",
        "        - This aligns with how Bayesian networks represent causality\n",
        "        \"\"\"\n",
        "        lines = text.split('\\n')\n",
        "\n",
        "        # Dictionary to store line numbers for each title occurrence\n",
        "        title_occurrences = {}\n",
        "\n",
        "        # Record line number for each title (including multiple occurrences)\n",
        "        line_number = 0\n",
        "        for line in lines:\n",
        "            if not line.strip():\n",
        "                line_number += 1\n",
        "                continue\n",
        "\n",
        "            title_match = re.search(r'[<\\[](.+?)[>\\]]', line)\n",
        "            if not title_match:\n",
        "                line_number += 1\n",
        "                continue\n",
        "\n",
        "            title = title_match.group(1)\n",
        "\n",
        "            # Store all occurrences of each title with their line numbers\n",
        "            if title not in title_occurrences:\n",
        "                title_occurrences[title] = []\n",
        "            title_occurrences[title].append(line_number)\n",
        "\n",
        "            # Store all line numbers where this title appears\n",
        "            if 'line_numbers' not in titles_info[title]:\n",
        "                titles_info[title]['line_numbers'] = []\n",
        "            titles_info[title]['line_numbers'].append(line_number)\n",
        "\n",
        "            # For backward compatibility, keep the first occurrence in 'line'\n",
        "            if titles_info[title]['line'] is None:\n",
        "                titles_info[title]['line'] = line_number\n",
        "\n",
        "            line_number += 1\n",
        "\n",
        "        # Create an ordered list of all title occurrences with their line numbers\n",
        "        all_occurrences = []\n",
        "        for title, occurrences in title_occurrences.items():\n",
        "            for line_num in occurrences:\n",
        "                all_occurrences.append((title, line_num))\n",
        "\n",
        "        # Sort occurrences by line number\n",
        "        all_occurrences.sort(key=lambda x: x[1])\n",
        "\n",
        "        # Get indentation for each occurrence\n",
        "        occurrence_indents = {}\n",
        "        for title, line_num in all_occurrences:\n",
        "            for line in lines[line_num:line_num+1]:  # Only check the current line\n",
        "                indent = 0\n",
        "                if '+' in line:\n",
        "                    symbol_index = line.find('+')\n",
        "                    # Count spaces before the '+' symbol\n",
        "                    j = symbol_index - 1\n",
        "                    while j >= 0 and line[j] == ' ':\n",
        "                        indent += 1\n",
        "                        j -= 1\n",
        "                elif '-' in line:\n",
        "                    symbol_index = line.find('-')\n",
        "                    # Count spaces before the '-' symbol\n",
        "                    j = symbol_index - 1\n",
        "                    while j >= 0 and line[j] == ' ':\n",
        "                        indent += 1\n",
        "                        j -= 1\n",
        "                occurrence_indents[(title, line_num)] = indent\n",
        "\n",
        "        # For each line, find the proper parent-child relationships\n",
        "        # In BayesDown, a more indented node is a parent of the less indented node above it\n",
        "        for i, (title, line_num) in enumerate(all_occurrences):\n",
        "            current_indent = occurrence_indents[(title, line_num)]\n",
        "\n",
        "            # Find the closest previous node with less indentation\n",
        "            # This will be the child of the current node\n",
        "            j = i - 1\n",
        "            while j >= 0:\n",
        "                prev_title, prev_line = all_occurrences[j]\n",
        "                prev_indent = occurrence_indents[(prev_title, prev_line)]\n",
        "\n",
        "                # If we found a node with less indentation, it's a child of current node\n",
        "                if prev_indent < current_indent:\n",
        "                    # This is the key relationship: more indented node (current) is parent of less indented node (previous)\n",
        "                    if title not in titles_info[prev_title]['parents']:\n",
        "                        titles_info[prev_title]['parents'].append(title)\n",
        "                    if prev_title not in titles_info[title]['children']:\n",
        "                        titles_info[title]['children'].append(prev_title)\n",
        "                    break  # Only need the immediate child\n",
        "\n",
        "                j -= 1\n",
        "\n",
        "        return titles_info\n",
        "\n",
        "    # Step 2: Updated main parsing function\n",
        "    def parse_markdown_hierarchy_fixed(markdown_text, ArgDown=False):\n",
        "        \"\"\"Main function to parse markdown hierarchy into a DataFrame with correct parent-child relationships\"\"\"\n",
        "\n",
        "        # Remove comments\n",
        "        clean_text = remove_comments(markdown_text)\n",
        "\n",
        "        # Extract all titles with their descriptions and indentation levels\n",
        "        titles_info = extract_titles_info(clean_text)\n",
        "\n",
        "        # Establish parent-child relationships - Use fixed function here\n",
        "        titles_with_relations = establish_relationships_fixed(titles_info, clean_text)\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        df = convert_to_dataframe(titles_with_relations, ArgDown)\n",
        "\n",
        "        # Add No_Parent and No_Children columns\n",
        "        df = add_no_parent_no_child_columns_to_df(df)\n",
        "\n",
        "        # Add Parents instantiation columns\n",
        "        df = add_parents_instantiation_columns_to_df(df)\n",
        "\n",
        "        return df\n",
        "\n",
        "    # Helper function to safely parse lists\n",
        "    def parse_list_safely(list_data):\n",
        "        if isinstance(list_data, list):\n",
        "            return list_data\n",
        "\n",
        "        if isinstance(list_data, str):\n",
        "            try:\n",
        "                # Try to parse as JSON\n",
        "                parsed = json.loads(list_data.replace(\"'\", \"\\\"\"))\n",
        "                if isinstance(parsed, list):\n",
        "                    return parsed\n",
        "            except:\n",
        "                # Try to parse as string list\n",
        "                if list_data.startswith('[') and list_data.endswith(']'):\n",
        "                    items = list_data.strip('[]').split(',')\n",
        "                    return [item.strip(' \"\\'') for item in items if item.strip()]\n",
        "                elif list_data.strip():\n",
        "                    # Handle single item\n",
        "                    return [list_data.strip()]\n",
        "\n",
        "        # Default case\n",
        "        return []\n",
        "\n",
        "    # Step 3: Updated BayesDown generation function\n",
        "    def generate_bayesdown_format_md_fixed(argdown_with_questions_path, output_md_path, QuestionsMinimal=False):\n",
        "        \"\"\"\n",
        "        Generate BayesDown format file with correct parent-child relationships.\n",
        "        \"\"\"\n",
        "        print(f\"Loading enhanced CSV from {argdown_with_questions_path}...\")\n",
        "\n",
        "        # Load the enhanced CSV file\n",
        "        try:\n",
        "            df = pd.read_csv(argdown_with_questions_path)\n",
        "            print(f\"Successfully loaded CSV with {len(df)} rows.\")\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Error loading CSV: {e}\")\n",
        "\n",
        "        # Validate required columns\n",
        "        required_columns = ['Title', 'Description', 'Parents', 'instantiations']\n",
        "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "        if missing_columns:\n",
        "            raise Exception(f\"Missing required columns: {', '.join(missing_columns)}\")\n",
        "\n",
        "        print(f\"Generating BayesDown format file...\")\n",
        "\n",
        "        # Start building the markdown content\n",
        "        md_content = \"\"  # Initialize as empty string\n",
        "\n",
        "        # Add explanations if QuestionsMinimal is False\n",
        "        if not QuestionsMinimal:\n",
        "            md_content += \"# BayesDown Format\\n\\n\"\n",
        "            md_content += \"This document contains the BayesDown representation for the Bayesian network.\\n\\n\"\n",
        "            md_content += \"## Format Description\\n\\n\"\n",
        "            md_content += \"BayesDown is a format that extends ArgDown with probabilistic information. It uses:\\n\\n\"\n",
        "            md_content += \"- **Node definitions**: `[Node_Name]: Description {\\\"metadata\\\": ...}`\\n\"\n",
        "            md_content += \"- **Hierarchical relationships**: Parent nodes (causes) are indented and prefixed with `+` below their effects\\n\"\n",
        "            md_content += \"- **Metadata**: JSON structure containing instantiations, priors, and posteriors\\n\\n\"\n",
        "            md_content += \"## Network Structure\\n\\n\"\n",
        "\n",
        "        # Create a dictionary for easy lookup of node information\n",
        "        nodes_dict = {}\n",
        "        for _, row in df.iterrows():\n",
        "            # Parse instantiations\n",
        "            instantiations = parse_list_safely(row['instantiations'])\n",
        "\n",
        "            # Parse parents\n",
        "            parents = parse_list_safely(row['Parents'])\n",
        "\n",
        "            # Create node entry\n",
        "            nodes_dict[row['Title']] = {\n",
        "                'description': row['Description'] if not pd.isna(row['Description']) else \"\",\n",
        "                'instantiations': instantiations if instantiations else [\"TRUE\", \"FALSE\"],\n",
        "                'parents': parents,\n",
        "                'children': []  # Will be filled in based on parent relationships\n",
        "            }\n",
        "\n",
        "        # Set up children based on parent relationships\n",
        "        for node_name, node_info in nodes_dict.items():\n",
        "            for parent in node_info['parents']:\n",
        "                if parent in nodes_dict:\n",
        "                    if node_name not in nodes_dict[parent]['children']:\n",
        "                        nodes_dict[parent]['children'].append(node_name)\n",
        "\n",
        "        # Identify leaf nodes (effects without causes)\n",
        "        leaf_nodes = []\n",
        "        for node_name, node_info in nodes_dict.items():\n",
        "            if not node_info['children']:\n",
        "                leaf_nodes.append(node_name)\n",
        "\n",
        "        # If no leaf nodes found, use nodes without parents\n",
        "        if not leaf_nodes:\n",
        "            leaf_nodes = [node for node, info in nodes_dict.items() if not info['parents']]\n",
        "\n",
        "        # If still no nodes found, use the first node as a starting point\n",
        "        if not leaf_nodes and nodes_dict:\n",
        "            leaf_nodes = [next(iter(nodes_dict))]\n",
        "\n",
        "        # Function to generate BayesDown syntax for a node and its parents\n",
        "        def generate_node_syntax(node_name, indent_level=0, processed_nodes=None):\n",
        "            if processed_nodes is None:\n",
        "                processed_nodes = set()\n",
        "\n",
        "            if node_name not in nodes_dict:\n",
        "                return \"\"\n",
        "\n",
        "            # If we've already fully processed this node, just add a reference\n",
        "            if node_name in processed_nodes:\n",
        "                indent = ' ' * indent_level\n",
        "                return f\"{indent}+ [{node_name}]\\n\"\n",
        "\n",
        "            node_info = nodes_dict[node_name]\n",
        "            indent = \" \" * indent_level\n",
        "            prefix = f\"{indent}+ \" if indent_level > 0 else \"\"\n",
        "\n",
        "            # Mark this node as processed\n",
        "            processed_nodes.add(node_name)\n",
        "\n",
        "            # Create metadata with instantiations\n",
        "            metadata = {\n",
        "                \"instantiations\": node_info['instantiations'],\n",
        "                \"priors\": {},\n",
        "                \"posteriors\": {}\n",
        "            }\n",
        "\n",
        "            # Add placeholder priors based on instantiations\n",
        "            for instantiation in node_info['instantiations']:\n",
        "                metadata[\"priors\"][f\"p({instantiation})\"] = \"0.6\"  # Default placeholder\n",
        "\n",
        "            # Add placeholder posteriors if node has parents\n",
        "            if node_info['parents']:\n",
        "                posteriors = {}\n",
        "                for parent in node_info['parents']:\n",
        "                    if parent in nodes_dict:\n",
        "                        for parent_inst in nodes_dict[parent]['instantiations']:\n",
        "                            for inst in node_info['instantiations']:\n",
        "                                # Create placeholder conditional probabilities\n",
        "                                posteriors[f\"p({inst}|{parent}={parent_inst})\"] = \"0.59\"\n",
        "                metadata[\"posteriors\"] = posteriors\n",
        "\n",
        "            # Format the node definition with metadata\n",
        "            metadata_json = json.dumps(metadata, indent=None).replace('\\n', ' ')\n",
        "            node_syntax = f\"{prefix}[{node_name}]: {node_info['description']} {metadata_json}\\n\"\n",
        "\n",
        "            # Add parents with proper indentation\n",
        "            for parent in node_info['parents']:\n",
        "                if parent in nodes_dict and parent != node_name:  # Avoid self-references\n",
        "                    parent_syntax = generate_node_syntax(parent, indent_level + 2, processed_nodes)\n",
        "                    node_syntax += parent_syntax\n",
        "\n",
        "            return node_syntax\n",
        "\n",
        "        # Generate BayesDown syntax for each leaf node (effect)\n",
        "        for leaf in leaf_nodes:\n",
        "            md_content += generate_node_syntax(leaf) + \"\\n\"\n",
        "\n",
        "        # Save the markdown content\n",
        "        with open(output_md_path, 'w') as f:\n",
        "            f.write(md_content)\n",
        "\n",
        "        print(f\"BayesDown format file saved to {output_md_path}\")\n",
        "        return md_content\n",
        "\n",
        "    # Return the fixed functions\n",
        "    return {\n",
        "        'establish_relationships': establish_relationships_fixed,\n",
        "        'parse_markdown_hierarchy': parse_markdown_hierarchy_fixed,\n",
        "        'generate_bayesdown_format_md': generate_bayesdown_format_md_fixed\n",
        "    }\n",
        "\n",
        "# Usage:\n",
        "fixed_functions = fix_bayesdown_generation()\n",
        "\n",
        "# Replace the original functions with fixed versions\n",
        "establish_relationships = fixed_functions['establish_relationships']\n",
        "parse_markdown_hierarchy = fixed_functions['parse_markdown_hierarchy']\n",
        "generate_bayesdown_format_md = fixed_functions['generate_bayesdown_format_md']\n",
        "\n",
        "# Now use the updated function to process ArgDown content\n",
        "result_df = parse_markdown_hierarchy(md_content)\n",
        "\n",
        "# Generate BayesDown format\n",
        "bayesdown_format = generate_bayesdown_format_md(\n",
        "    \"ArgDown_WithQuestions.csv\",\n",
        "    \"BayesDownFormat.md\",\n",
        "    QuestionsMinimal=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QjgCgzEl9iYY",
        "outputId": "aaed7a3e-779f-4334-c9e8-ab8402096f98"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading enhanced CSV from ArgDown_WithQuestions.csv...\n",
            "Successfully loaded CSV with 3 rows.\n",
            "Generating BayesDown format file...\n",
            "BayesDown format file saved to BayesDownFormat.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMyBz93zFxln"
      },
      "outputs": [],
      "source": [
        "# notebook_name = \"NoHTML_AMTAIR_Prototype\"\n",
        "# repo_url = \"https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_1/\"\n",
        "\n",
        "\n",
        "# !wget {repo_url}{notebook_name}.ipynb\n",
        "# !jupyter nbconvert --to markdown {notebook_name}.ipynb --output {notebook_name}.md --no-input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWiHUcgWpuvx"
      },
      "outputs": [],
      "source": [
        "# Convert ipynb to HTML in Colab\n",
        "# Upload ipynb\n",
        "# from google.colab import files\n",
        "# f = files.upload()\n",
        "\n",
        "# Convert ipynb to html\n",
        "# import subprocess\n",
        "# file0 = list(f.keys())[0]\n",
        "# _ = subprocess.run([\"pip\", \"install\", \"nbconvert\"])\n",
        "# _ = subprocess.run([\"jupyter\", \"nbconvert\", file0, \"--to\", \"html\"])\n",
        "\n",
        "# download the html\n",
        "# files.download(file0[:-5]+\"html\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "4j-25d2HDfZt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c5c28e2e-2d39-43c8-a6b7-fcd647473808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading enhanced CSV from ArgDown_WithQuestions.csv...\n",
            "Successfully loaded CSV with 3 rows.\n",
            "Generating BayesDown format file...\n",
            "BayesDown format file saved to BayesDownFormat.md\n",
            "\n",
            "BayesDown Format Preview:\n",
            "[Grass_Wet]: Concentrated moisture on, between and around the blades of grass. {\"instantiations\": [\"grass_wet_TRUE\", \"grass_wet_FALSE\"], \"priors\": {\"p(grass_wet_TRUE)\": \"? %\", \"p(grass_wet_FALSE)\": \"? %\"}, \"posteriors\": {\"p(grass_wet_TRUE|Rain=rain_TRUE)\": \"?? %\", \"p(grass_wet_FALSE|Rain=rain_TRUE)\": \"?? %\", \"p(grass_wet_TRUE|Rain=rain_FALSE)\": \"?? %\", \"p(grass_wet_FALSE|Rain=rain_FALSE)\": \"?? %\", \"p(grass_wet_TRUE|Sprinkler=sprinkler_TRUE)\": \"?? %\", \"p(grass_wet_FALSE|Sprinkler=sprinkler_TRUE)\": \"?? %\", \"p(grass_wet_TRUE|Sprinkler=sprinkler_FALSE)\": \"?? %\", \"p(grass_wet_FALSE|Sprinkler=sprinkler_FALSE)\": \"?? %\"}}\n",
            "  [Rain]: Tears of angles crying high up in the skies hitting the ground. {\"instantiations\": [\"rain_TRUE\", \"rain_FALSE\"], \"priors\": {\"p(rain_TRUE)\": \"? %\", \"p(rain_FALSE)\": \"? %\"}, \"posteriors\": {}}\n",
            "  [Sprinkler]: Activation of a centrifugal force based CO2 droplet distribution system. {\"instantiations\": [\"sprinkler_TRUE\", \"sprinkler_FALSE\"], \"priors\": {\"p(sprinkler_TRUE)\": \"? %\", \"p(sprinkler_FALSE)\": \"? %\"}, \"posteriors\": {\"p(sprinkler_TRUE|Rain=rain_TRUE)\": \"?? %\", \"p(sprinkler_FALSE|Rain=rain_TRUE)\": \"?? %\", \"p(sprinkler_TRUE|Rain=rain_FALSE)\": \"?? %\", \"p(sprinkler_FALSE|Rain=rain_FALSE)\": \"?? %\"}}\n",
            "    + [Rain]\n",
            "\n",
            "...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Helper function to parse lists safely\n",
        "def parse_list_safely(list_data):\n",
        "    if isinstance(list_data, list):\n",
        "        return list_data\n",
        "\n",
        "    if isinstance(list_data, str):\n",
        "        try:\n",
        "            # Try to parse as JSON\n",
        "            parsed = json.loads(list_data)\n",
        "            if isinstance(parsed, list):\n",
        "                return parsed\n",
        "        except:\n",
        "            # Try to parse as string list\n",
        "            if list_data.startswith('[') and list_data.endswith(']'):\n",
        "                items = list_data.strip('[]').split(',')\n",
        "                return [item.strip(' \"\\'') for item in items if item.strip()]\n",
        "            elif list_data.strip():\n",
        "                # Handle single item\n",
        "                return [list_data.strip()]\n",
        "\n",
        "    # Default case\n",
        "    return []\n",
        "\n",
        "def generate_bayesdown_format_md_fixed(argdown_with_questions_path, output_md_path, QuestionsMinimal=False):\n",
        "    \"\"\"\n",
        "    Generate BayesDown format file based on the enhanced CSV file,\n",
        "    with correct parent-child relationships.\n",
        "\n",
        "    Args:\n",
        "        argdown_with_questions_path (str): Path to the CSV file with probability questions\n",
        "        output_md_path (str): Path to save the output markdown file\n",
        "        QuestionsMinimal (bool, optional): If True, only generate the BayesDown format without explanations.\n",
        "                                        Defaults to False.\n",
        "    \"\"\"\n",
        "    print(f\"Loading enhanced CSV from {argdown_with_questions_path}...\")\n",
        "\n",
        "    # Load the enhanced CSV file\n",
        "    try:\n",
        "        df = pd.read_csv(argdown_with_questions_path)\n",
        "        print(f\"Successfully loaded CSV with {len(df)} rows.\")\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Error loading CSV: {e}\")\n",
        "\n",
        "    # Validate required columns\n",
        "    required_columns = ['Title', 'Description', 'Parents', 'instantiations']\n",
        "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "    if missing_columns:\n",
        "        raise Exception(f\"Missing required columns: {', '.join(missing_columns)}\")\n",
        "\n",
        "    print(f\"Generating BayesDown format file...\")\n",
        "\n",
        "    # Start building the markdown content\n",
        "    md_content = \"\"  # Initialize as empty string\n",
        "\n",
        "    # Add explanations if QuestionsMinimal is False\n",
        "    if not QuestionsMinimal:\n",
        "        md_content += \"# BayesDown Format\\n\\n\"\n",
        "        md_content += \"This document contains the BayesDown representation for the Bayesian network.\\n\\n\"\n",
        "        md_content += \"## Format Description\\n\\n\"\n",
        "        md_content += \"BayesDown is a format that extends ArgDown with probabilistic information. It uses:\\n\\n\"\n",
        "        md_content += \"- **Node definitions**: `[Node_Name]: Description {\\\"metadata\\\": ...}`\\n\"\n",
        "        md_content += \"- **Hierarchical relationships**: Parent nodes are indented and prefixed with `+`\\n\"\n",
        "        md_content += \"- **Metadata**: JSON structure containing instantiations, priors, and posteriors\\n\\n\"\n",
        "        md_content += \"## Network Structure\\n\\n\"\n",
        "\n",
        "    # Create a dictionary for easy lookup of node information\n",
        "    nodes_dict = {}\n",
        "    for _, row in df.iterrows():\n",
        "        # Parse instantiations\n",
        "        instantiations = parse_list_safely(row['instantiations'])\n",
        "\n",
        "        # Parse parents\n",
        "        parents = parse_list_safely(row['Parents'])\n",
        "\n",
        "        # Create node entry\n",
        "        nodes_dict[row['Title']] = {\n",
        "            'description': row['Description'],\n",
        "            'instantiations': instantiations,\n",
        "            'parents': parents,\n",
        "            'children': [],  # Will be filled in based on parent relationships\n",
        "            'questions_positive': row.get('Generate_Positive_Instantiation_Questions', '{}'),\n",
        "            'questions_negative': row.get('Generate_Negative_Instantiation_Questions', '{}')\n",
        "        }\n",
        "\n",
        "    # Set up children based on parent relationships\n",
        "    for node_name, node_info in nodes_dict.items():\n",
        "        for parent in node_info['parents']:\n",
        "            if parent in nodes_dict:\n",
        "                nodes_dict[parent]['children'].append(node_name)\n",
        "\n",
        "    # Identify root nodes (effects that aren't causes for anything else)\n",
        "    root_nodes = []\n",
        "    for node_name, node_info in nodes_dict.items():\n",
        "        if not node_info['children']:\n",
        "            root_nodes.append(node_name)\n",
        "\n",
        "    # If no root nodes found, use the first node as root\n",
        "    if not root_nodes and nodes_dict:\n",
        "        root_nodes = [next(iter(nodes_dict))]\n",
        "\n",
        "    # Function to recursively generate BayesDown syntax\n",
        "    def generate_node_syntax(node_name, indent_level=0, processed_nodes=None):\n",
        "        if processed_nodes is None:\n",
        "            processed_nodes = set()\n",
        "\n",
        "        if node_name not in nodes_dict:\n",
        "            return \"\"\n",
        "\n",
        "        # If we've already fully processed this node, just add a reference\n",
        "        if node_name in processed_nodes:\n",
        "            return f\"{' ' * indent_level}+ [{node_name}]\\n\"\n",
        "\n",
        "        processed_nodes.add(node_name)\n",
        "\n",
        "        node_info = nodes_dict[node_name]\n",
        "        indent = \" \" * indent_level\n",
        "\n",
        "        # Create metadata with instantiations\n",
        "        metadata = {\n",
        "            \"instantiations\": node_info['instantiations'],\n",
        "            \"priors\": {},\n",
        "            \"posteriors\": {}\n",
        "        }\n",
        "\n",
        "        # Add placeholder priors based on instantiations\n",
        "        for instantiation in node_info['instantiations']:\n",
        "            metadata[\"priors\"][f\"p({instantiation})\"] = \"? %\"  # Default placeholder\n",
        "\n",
        "        # Add placeholder posteriors if node has parents\n",
        "        if node_info['parents']:\n",
        "            for parent in node_info['parents']:\n",
        "                if parent in nodes_dict:\n",
        "                    for parent_inst in nodes_dict[parent]['instantiations']:\n",
        "                        for inst in node_info['instantiations']:\n",
        "                            # Create placeholder conditional probabilities\n",
        "                            metadata[\"posteriors\"][f\"p({inst}|{parent}={parent_inst})\"] = \"?? %\"\n",
        "\n",
        "        # Format the node definition with metadata\n",
        "        metadata_json = json.dumps(metadata, indent=None).replace('\\n', ' ')\n",
        "        node_syntax = f\"{indent}[{node_name}]: {node_info['description']} {metadata_json}\\n\"\n",
        "\n",
        "        # Add parents with proper indentation\n",
        "        for parent in node_info['parents']:\n",
        "            if parent in nodes_dict and parent != node_name:  # Avoid self-references\n",
        "                parent_syntax = generate_node_syntax(parent, indent_level + 2, processed_nodes)\n",
        "                node_syntax += parent_syntax\n",
        "\n",
        "        return node_syntax\n",
        "\n",
        "\n",
        "    # Generate BayesDown syntax for each root node\n",
        "    for root in root_nodes:\n",
        "        md_content += generate_node_syntax(root) + \"\\n\"\n",
        "\n",
        "    # Save the markdown content\n",
        "    with open(output_md_path, 'w') as f:\n",
        "        f.write(md_content)\n",
        "\n",
        "    print(f\"BayesDown format file saved to {output_md_path}\")\n",
        "    return md_content\n",
        "\n",
        "\n",
        "\n",
        "# Example of how to use the new functionality:\n",
        "\n",
        "# Generate BayesDown format\n",
        "bayesdown_format_fixed = generate_bayesdown_format_md_fixed(\n",
        "    \"ArgDown_WithQuestions.csv\",\n",
        "    \"BayesDownFormat.md\",\n",
        "    QuestionsMinimal=True\n",
        ")\n",
        "\n",
        "# Display a preview of the format\n",
        "print(\"\\nBayesDown Format Preview:\")\n",
        "print(bayesdown_format_fixed[:5000] + \"...\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjbIj19epbrF"
      },
      "source": [
        "# 6.0 Save Outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QqlN6dYpm4s"
      },
      "source": [
        "## Convert ipynb to HTML in Colab\n",
        "\n",
        "Instruction:\n",
        "\n",
        "Download the ipynb, which you want to convert, on your local computer.\n",
        "Run the code below to upload the ipynb.\n",
        "\n",
        "The html version will be downloaded automatically on your local machine.\n",
        "Enjoy it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HZXrWJrzO7d-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3046f7ec-d100-4f6a-a705-e24a0a4c3056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-22 22:04:54--  https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_1/AMTAIR_Prototype_example1.ipynb\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 352509 (344K) [text/plain]\n",
            "Saving to: ‘AMTAIR_Prototype_example1.ipynb’\n",
            "\n",
            "\r          AMTAIR_Pr   0%[                    ]       0  --.-KB/s               \rAMTAIR_Prototype_ex 100%[===================>] 344.25K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-04-22 22:04:54 (7.22 MB/s) - ‘AMTAIR_Prototype_example1.ipynb’ saved [352509/352509]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Convert ipynb to HTML in Colab\n",
        "import nbformat\n",
        "from nbconvert import HTMLExporter\n",
        "import os\n",
        "\n",
        "repo_url = \"https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_1/\"\n",
        "notebook_name = \"AMTAIR_Prototype_example1\"  #Change Notebook name and path when working on different examples\n",
        "\n",
        "# Download the notebook file\n",
        "!wget {repo_url}{notebook_name}.ipynb -O {notebook_name}.ipynb  # Corrected line\n",
        "\n",
        "# Load the notebook\n",
        "# add error handling for file not found\n",
        "try:\n",
        "  with open(f\"{notebook_name}.ipynb\") as f:\n",
        "    nb = nbformat.read(f, as_version=4)\n",
        "except FileNotFoundError:\n",
        "  print(f\"Error: File '{notebook_name}.ipynb' not found. Please check if it was downloaded correctly.\")\n",
        "\n",
        "# Initialize the HTML exporter\n",
        "exporter = HTMLExporter()\n",
        "\n",
        "# Convert the notebook to HTML\n",
        "(body, resources) = exporter.from_notebook_node(nb)\n",
        "\n",
        "# Save the HTML to a file\n",
        "with open(f\"{notebook_name}IPYNB.html\", \"w\") as f:\n",
        "    f.write(body)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS6AhdiSCLw4"
      },
      "source": [
        "## Convert .ipynb Notebook to MarkDown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-5AfIsfEJ5rM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69d9bbaf-19d4-466c-dccb-de8c59403bb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-22 22:03:58--  https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_1/AMTAIR_Prototype_example1.ipynb\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 352509 (344K) [text/plain]\n",
            "Saving to: ‘AMTAIR_Prototype_example1.ipynb’\n",
            "\n",
            "\r          AMTAIR_Pr   0%[                    ]       0  --.-KB/s               \rAMTAIR_Prototype_ex 100%[===================>] 344.25K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-04-22 22:03:58 (7.53 MB/s) - ‘AMTAIR_Prototype_example1.ipynb’ saved [352509/352509]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title --- Convert .ipynb Notebook to MarkDown ---\n",
        "\n",
        "import nbformat\n",
        "from nbconvert import MarkdownExporter\n",
        "import os\n",
        "\n",
        "repo_url = \"https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_1/\"\n",
        "notebook_name = \"AMTAIR_Prototype_example1\"  #Change Notebook name and path when working on different examples\n",
        "\n",
        "# Download the notebook file\n",
        "!wget {repo_url}{notebook_name}.ipynb -O {notebook_name}.ipynb  # Corrected line\n",
        "\n",
        "# Load the notebook\n",
        "# add error handling for file not found\n",
        "try:\n",
        "  with open(f\"{notebook_name}.ipynb\") as f:\n",
        "    nb = nbformat.read(f, as_version=4)\n",
        "except FileNotFoundError:\n",
        "  print(f\"Error: File '{notebook_name}.ipynb' not found. Please check if it was downloaded correctly.\")\n",
        "\n",
        "\n",
        "# Initialize the Markdown exporter\n",
        "exporter = MarkdownExporter(exclude_output=True)  # Correct initialization\n",
        "\n",
        "# Convert the notebook to Markdown\n",
        "(body, resources) = exporter.from_notebook_node(nb)\n",
        "\n",
        "# Save the Markdown to a file\n",
        "with open(f\"{notebook_name}IPYNB.md\", \"w\") as f:\n",
        "    f.write(body)"
      ]
    },
    {
      "source": [
        "import nbformat\n",
        "from nbconvert import PDFExporter\n",
        "import os\n",
        "import subprocess\n",
        "import re\n",
        "\n",
        "def escape_latex_special_chars(text):\n",
        "  \"\"\"Escapes special LaTeX characters in a string.\"\"\"\n",
        "  latex_special_chars = ['&', '%', '#', '_', '{', '}', '~', '^', '\\\\']\n",
        "  replacement_patterns = [\n",
        "      (char, '\\\\' + char) for char in latex_special_chars\n",
        "  ]\n",
        "\n",
        "  # Escape reserved characters\n",
        "  for original, replacement in replacement_patterns:\n",
        "    text = text.replace(original, replacement) # This is the fix\n",
        "  return text\n",
        "\n",
        "# Function to check if a command is available\n",
        "def is_command_available(command):\n",
        "    try:\n",
        "        subprocess.run([command], capture_output=True, check=True)\n",
        "        return True\n",
        "    except (subprocess.CalledProcessError, FileNotFoundError):\n",
        "        return False\n",
        "\n",
        "# Check if xelatex is installed, and install if necessary\n",
        "if not is_command_available(\"xelatex\"):\n",
        "    print(\"Installing necessary TeX packages...\")\n",
        "    !apt-get install -y texlive-xetex texlive-fonts-recommended texlive-plain-generic\n",
        "    print(\"TeX packages installed successfully.\")\n",
        "else:\n",
        "    print(\"xelatex is already installed. Skipping installation.\")\n",
        "\n",
        "repo_url = \"https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_1/\"\n",
        "notebook_name = \"AMTAIR_Prototype_example1\"  #Change Notebook name and path when working on different examples\n",
        "\n",
        "# Download the notebook file\n",
        "!wget {repo_url}{notebook_name}.ipynb -O {notebook_name}.ipynb  # Corrected line\n",
        "\n",
        "# Load the notebook\n",
        "# add error handling for file not found\n",
        "try:\n",
        "  with open(f\"{notebook_name}.ipynb\") as f:\n",
        "    nb = nbformat.read(f, as_version=4)\n",
        "except FileNotFoundError:\n",
        "  print(f\"Error: File '{notebook_name}.ipynb' not found. Please check if it was downloaded correctly.\")\n",
        "\n",
        "\n",
        "# Initialize the PDF exporter\n",
        "exporter = PDFExporter(exclude_output=True)  # Changed to PDFExporter\n",
        "\n",
        "# Sanitize notebook cell titles to escape special LaTeX characters like '&'\n",
        "for cell in nb.cells:\n",
        "    if 'cell_type' in cell and cell['cell_type'] == 'markdown':\n",
        "        if 'source' in cell and isinstance(cell['source'], str):\n",
        "            # Replace '&' with '\\protect&' in markdown cell titles AND CONTENT\n",
        "            # Updated to use escape_latex_special_chars function\n",
        "            cell['source'] = escape_latex_special_chars(cell['source'])\n",
        "            # Additionally, escape special characters in headings\n",
        "            cell['source'] = re.sub(r'(#+)\\s*(.*)', lambda m: m.group(1) + ' ' + escape_latex_special_chars(m.group(2)), cell['source'])\n",
        "\n",
        "\n",
        "\n",
        "# Convert the notebook to PDF\n",
        "(body, resources) = exporter.from_notebook_node(nb)\n",
        "\n",
        "\n",
        "# Save the PDF to a file\n",
        "with open(f\"{notebook_name}IPYNB.pdf\", \"wb\") as f:  # Changed to 'wb' for binary writing\n",
        "    f.write(body)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "FLQFkvtamPRG",
        "outputId": "bdfb48e9-dfa5-44aa-dd5c-aabb38563763",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing necessary TeX packages...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "texlive-fonts-recommended is already the newest version (2021.20220204-1).\n",
            "texlive-plain-generic is already the newest version (2021.20220204-1).\n",
            "texlive-xetex is already the newest version (2021.20220204-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "TeX packages installed successfully.\n",
            "--2025-04-22 22:23:08--  https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_1/AMTAIR_Prototype_example1.ipynb\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 352509 (344K) [text/plain]\n",
            "Saving to: ‘AMTAIR_Prototype_example1.ipynb’\n",
            "\n",
            "AMTAIR_Prototype_ex 100%[===================>] 344.25K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-04-22 22:23:08 (7.22 MB/s) - ‘AMTAIR_Prototype_example1.ipynb’ saved [352509/352509]\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "57YvCx9dom5J",
        "ZWx7CRfHn8Va",
        "mbRSd0SK5_sA"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}