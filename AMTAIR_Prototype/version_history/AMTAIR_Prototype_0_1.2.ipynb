{"cells":[{"cell_type":"markdown","metadata":{"id":"GtVFO-s74vI_"},"source":["# 0.1 Import Libraries & Packages\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y2Egs32Mqek8"},"outputs":[],"source":["!pip install pyvis\n","!pip install --upgrade gspread pandas google-auth google-colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dkp2mSZg3qCu"},"outputs":[],"source":["import gspread\n","import numpy as np\n","\n","\n","from google.colab import auth\n","from google.auth import default\n","from google.colab import data_table\n","from google.colab import sheets\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rKXQGpjmHFVh"},"outputs":[],"source":["import pandas as pd\n","import re\n","from IPython.display import Markdown, display\n","import json\n","import networkx as nx\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"RbgR04uk4vxG"},"source":["# 0.2 Connect Storage (& Define Repository)\n"]},{"cell_type":"markdown","metadata":{"id":"Ed_WJb0Pe5Tx"},"source":["## 0.2a Ella's Local Storage:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PsTLtunODwWa"},"outputs":[],"source":["file_path = '/Users/ellaalle/code-ws/AMTAIR_Prototype/ArgDown_TestText.md'\n"]},{"cell_type":"markdown","metadata":{"id":"a96Y4-U1e-iH"},"source":["## 0.2b Vale's GDrive Storage"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20378,"status":"ok","timestamp":1743146671084,"user":{"displayName":"Singularity Smith","userId":"08757842931667367012"},"user_tz":-60},"id":"9ghKPkVXDv-M","outputId":"db2b1da2-fc0a-40c9-9a63-3fac42f441b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UQBTO-OGfETr"},"outputs":[],"source":["# correct path when using the 'Occamstester' / Singularity Smith Account\n","file_path = '/content/drive/MyDrive/AIGrandStrategyProject/08_Technical_SoftwareImplementation/04_Prototypes/_repos/AMTAIR_Prototype_0.1.1/ArgDown_TestText.md'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dmetmDPvhfbz"},"outputs":[],"source":["# correct path when using V2M Account\n","file_path = '/content/drive/MyDrive/AMTAIR/08_Technical_SoftwareImplementation/04_Prototypes/_repos/AMTAIR_Prototype_0.1.1/ArgDown_TestText.md'\n","file_path = '/content/drive/MyDrive/AIGrandStrategyProject/08_Technical SoftwareImplementation/04_Prototypes/_repos/AMTAIR_Prototype_0.1.1/AMTAIR_Prototype_0.1'"]},{"cell_type":"markdown","metadata":{"id":"y-ix4Rp5fE9m"},"source":["# 0.3 File Import"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YVJYtj7lDwsz"},"outputs":[],"source":["with open(file_path, 'r') as f:\n","  md_content = f.read()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1743146694951,"user":{"displayName":"Singularity Smith","userId":"08757842931667367012"},"user_tz":-60},"id":"FU8FLHpWDxNG","outputId":"a5fe4c0e-7b9a-47dd-b4ad-d61ac6550420"},"outputs":[{"data":{"text/plain":["'# Main Argument: Current AI as Existential Risk Factor\\n\\n<AI_Existential_Risk_Factor>: Current and near-term AI technologies can contribute to existential risk by acting as intermediate risk factors.\\n  + <AI_Intermediate_Factor>: Current and near-term AI technologies can act as intermediate risk factors, magnifying the likelihood of previously identified sources of existential risk.\\n  + <Risk_Not_Limited_To_AGI>: This potential contribution to existential risk is not limited to the unaligned AGI scenario.\\n  + <Causal_Pathways_Exist>: There exist causal pathways from AI systems to existential risks that do not presuppose hypothetical future AI capabilities.\\n\\n\\n# Power Dynamics Arguments\\n\\n[AI_Affects_Power_Dynamics]: AI can shift or strengthen existing power dynamics between different actors.\\n  + [AI_State_State_Risk]: AI can disturb relationships between nation states, potentially leading to an \"AI arms race.\"\\n  + [AI_State_Corporation_Risk]: The rise of tech corporations affects their relationships with states, creating power imbalances.\\n  + [AI_State_Citizen_Risk]: AI surveillance technologies change the dynamics between states and citizens.\\n   /* => [AI_Existential_Risk_Factor]*/\\n\\n## State-State Relationships\\n\\n[AI_State_State_Risk]: AI affects relationships between states in ways that can increase existential risk./*=> [AI_Affects_Power_Dynamics]*/\\n + <AI_Global_Power_Shift>: AI development contributes to a global shift in power towards nations like China (\"Easternisation\").\\n + <AI_Arms_Race>: Concerns about technological competition can lead to an \"AI arms race\" between nations.\\n + <Competition_Inhibits_Coordination>: Such competitive dynamics may inhibit international coordination and incentivize against AI safety precautions.\\n\\n\\n## State-Corporation Relationships\\n\\n[AI_State_Corporation_Risk]: AI affects relationships between states and corporations in ways that can increase existential risk.\\n + <Tech_Corporation_Rise>: The past two decades have seen a monumental rise of private corporations in the technology sector with revenues comparable to national GDPs.\\n + <Corporate_Global_Reach>: These corporations operate globally, making state regulation challenging.\\n + <Profit_Driven_Goals>: Many corporate goals are profit-driven and can be misaligned with wider societal interests.\\n\\n\\n## State-Citizen Relationships\\n\\n[AI_State_Citizen_Risk]: AI surveillance technologies enable potential stable repressive regimes that could constitute existential catastrophes.\\n/* \\n(4) => [AI_Affects_Power_Dynamics]\\n*/\\n + <AI_Surveillance_Growth>: There\\'s been a rapid increase in the use of AI surveillance systems by states across different political systems.\\n + <Insufficient_Ethical_Frameworks>: Ethical and legal frameworks for these technologies are lagging behind their deployment.\\n + <Surveillance_Privatization>: Private companies develop and sell surveillance technologies to governments, further normalizing mass surveillance.\\n\\n<AI_Existential_Risk_Factor>\\n\\n(1) [AI_State_State_Risk]\\n(2) [AI_Affects_Power_Dynamics]\\n--\\nSome inference rule: p .^. (p .->. q) .->. q {some_additional_data: [1,2]}\\n--\\n(3) [AI_Existential_Risk_Factor_Final]\\n  -> Outgoing relations of the conclusion, are also interpreted as outgoing relations of the whole argument.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n# Specific Existential Risk Pathways\\n\\n## Nuclear Risk\\n\\n<Nuclear_Risk_Argument>:\\n  + <AI_State_State_Risk>: AI affects relationships between states, potentially creating tensions.\\n  +  <AI_Arms_Race_To_Military>: An AI arms race could become military in nature.\\n  + <Cybersecurity_Intelligence_Impact>: Changes in cybersecurity could affect a state\\'s intelligence capabilities.\\n/* \\n(4) [AI_Nuclear_Risk]: AI could increase the probability of a nuclear conflict leading to \"nuclear winter\" and potential human extinction. => [AI_Existential_Risk_Factor]\\n*/\\n\\n## Pandemic Risk\\n\\n<Pandemic_Risk_Argument>: \\n  + <AI_Information_Ecosystem_Risk>: AI threatens the information ecosystem, as seen with COVID-19 misinformation.\\n  + <Response_Requires_Trust>: Effective pandemic response requires public trust in political systems.\\n  + <AI_Biological_Weapons>: AI could be used to design and produce dangerous pathogens.\\n\\n/* \\n(4) [AI_Pandemic_Risk]: AI could increase the risk from engineered pandemics and biotechnology. => [AI_Existential_Risk_Factor]\\n*/\\n\\n## Climate Risk\\n\\n<Climate_Risk_Argument>:\\n  + <AI_Information_Ecosystem_Risk>: AI threatens the information ecosystem through misinformation.\\n  +  <Climate_Misinformation>: Climate change has a history of being clouded by misinformation.\\n  +  <AI_Energy_Consumption>: AI development and training has a significant carbon footprint, with a single NLP model producing 300,000kg of CO2 emissions.\\n\\n/* \\n(4) [AI_Climate_Risk]: AI could increase the risk from climate change through both information distortion and direct emissions. => [AI_Existential_Risk_Factor]\\n*/\\n\\n\\n## Unaligned AGI Risk\\n\\n<AGI_Risk_Argument>:\\n  + <AI_Arms_Race>: Concerns about technological competition can lead to an \"AI arms race\" between nations or corporations.\\n  + <Safety_Corner_Cutting>: Competitive dynamics may incentivize corner-cutting on AI safety.\\n\\n/* \\n(3) [AI_AGI_Risk]: Current AI development patterns could increase future risks from unaligned AGI. => [AI_Existential_Risk_Factor]\\n*/\\n\\n\\n## Stable Repressive Regime Risk\\n\\n\\n<Repressive_Regime_Argument>:\\n  + <AI_Surveillance_Growth>: Rapid increase in AI surveillance technologies globally.\\n  + <Lagging_Ethical_Frameworks>: Even democratic countries fail to meet regulatory standards for surveillance.\\n  + <Surveillance_Privatization>: Private-public partnerships normalize surveillance beyond legal limits.\\n\\n/* \\n(4) [AI_Repressive_Regime_Risk]: AI surveillance enables potentially stable, global repressive autocracies constituting existential catastrophes. => [AI_Existential_Risk_Factor]\\n*/\\n\\n\\n\\n\\n/* \\nFrom: Current and Near-Term AI as a Potential Existential Risk Factor by Benjamin S. Bucknall∗\\n*/\\n'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["md_content"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"executionInfo":{"elapsed":25,"status":"ok","timestamp":1743146698155,"user":{"displayName":"Singularity Smith","userId":"08757842931667367012"},"user_tz":-60},"id":"MgxYW5al-e0u","outputId":"d4fb3563-0c9d-4324-9bcb-e6e9bfae904c"},"outputs":[{"data":{"text/markdown":["# Main Argument: Current AI as Existential Risk Factor\n","\n","<AI_Existential_Risk_Factor>: Current and near-term AI technologies can contribute to existential risk by acting as intermediate risk factors.\n","  + <AI_Intermediate_Factor>: Current and near-term AI technologies can act as intermediate risk factors, magnifying the likelihood of previously identified sources of existential risk.\n","  + <Risk_Not_Limited_To_AGI>: This potential contribution to existential risk is not limited to the unaligned AGI scenario.\n","  + <Causal_Pathways_Exist>: There exist causal pathways from AI systems to existential risks that do not presuppose hypothetical future AI capabilities.\n","\n","\n","# Power Dynamics Arguments\n","\n","[AI_Affects_Power_Dynamics]: AI can shift or strengthen existing power dynamics between different actors.\n","  + [AI_State_State_Risk]: AI can disturb relationships between nation states, potentially leading to an \"AI arms race.\"\n","  + [AI_State_Corporation_Risk]: The rise of tech corporations affects their relationships with states, creating power imbalances.\n","  + [AI_State_Citizen_Risk]: AI surveillance technologies change the dynamics between states and citizens.\n","   /* => [AI_Existential_Risk_Factor]*/\n","\n","## State-State Relationships\n","\n","[AI_State_State_Risk]: AI affects relationships between states in ways that can increase existential risk./*=> [AI_Affects_Power_Dynamics]*/\n"," + <AI_Global_Power_Shift>: AI development contributes to a global shift in power towards nations like China (\"Easternisation\").\n"," + <AI_Arms_Race>: Concerns about technological competition can lead to an \"AI arms race\" between nations.\n"," + <Competition_Inhibits_Coordination>: Such competitive dynamics may inhibit international coordination and incentivize against AI safety precautions.\n","\n","\n","## State-Corporation Relationships\n","\n","[AI_State_Corporation_Risk]: AI affects relationships between states and corporations in ways that can increase existential risk.\n"," + <Tech_Corporation_Rise>: The past two decades have seen a monumental rise of private corporations in the technology sector with revenues comparable to national GDPs.\n"," + <Corporate_Global_Reach>: These corporations operate globally, making state regulation challenging.\n"," + <Profit_Driven_Goals>: Many corporate goals are profit-driven and can be misaligned with wider societal interests.\n","\n","\n","## State-Citizen Relationships\n","\n","[AI_State_Citizen_Risk]: AI surveillance technologies enable potential stable repressive regimes that could constitute existential catastrophes.\n","/* \n","(4) => [AI_Affects_Power_Dynamics]\n","*/\n"," + <AI_Surveillance_Growth>: There's been a rapid increase in the use of AI surveillance systems by states across different political systems.\n"," + <Insufficient_Ethical_Frameworks>: Ethical and legal frameworks for these technologies are lagging behind their deployment.\n"," + <Surveillance_Privatization>: Private companies develop and sell surveillance technologies to governments, further normalizing mass surveillance.\n","\n","<AI_Existential_Risk_Factor>\n","\n","(1) [AI_State_State_Risk]\n","(2) [AI_Affects_Power_Dynamics]\n","--\n","Some inference rule: p .^. (p .->. q) .->. q {some_additional_data: [1,2]}\n","--\n","(3) [AI_Existential_Risk_Factor_Final]\n","  -> Outgoing relations of the conclusion, are also interpreted as outgoing relations of the whole argument.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","# Specific Existential Risk Pathways\n","\n","## Nuclear Risk\n","\n","<Nuclear_Risk_Argument>:\n","  + <AI_State_State_Risk>: AI affects relationships between states, potentially creating tensions.\n","  +  <AI_Arms_Race_To_Military>: An AI arms race could become military in nature.\n","  + <Cybersecurity_Intelligence_Impact>: Changes in cybersecurity could affect a state's intelligence capabilities.\n","/* \n","(4) [AI_Nuclear_Risk]: AI could increase the probability of a nuclear conflict leading to \"nuclear winter\" and potential human extinction. => [AI_Existential_Risk_Factor]\n","*/\n","\n","## Pandemic Risk\n","\n","<Pandemic_Risk_Argument>: \n","  + <AI_Information_Ecosystem_Risk>: AI threatens the information ecosystem, as seen with COVID-19 misinformation.\n","  + <Response_Requires_Trust>: Effective pandemic response requires public trust in political systems.\n","  + <AI_Biological_Weapons>: AI could be used to design and produce dangerous pathogens.\n","\n","/* \n","(4) [AI_Pandemic_Risk]: AI could increase the risk from engineered pandemics and biotechnology. => [AI_Existential_Risk_Factor]\n","*/\n","\n","## Climate Risk\n","\n","<Climate_Risk_Argument>:\n","  + <AI_Information_Ecosystem_Risk>: AI threatens the information ecosystem through misinformation.\n","  +  <Climate_Misinformation>: Climate change has a history of being clouded by misinformation.\n","  +  <AI_Energy_Consumption>: AI development and training has a significant carbon footprint, with a single NLP model producing 300,000kg of CO2 emissions.\n","\n","/* \n","(4) [AI_Climate_Risk]: AI could increase the risk from climate change through both information distortion and direct emissions. => [AI_Existential_Risk_Factor]\n","*/\n","\n","\n","## Unaligned AGI Risk\n","\n","<AGI_Risk_Argument>:\n","  + <AI_Arms_Race>: Concerns about technological competition can lead to an \"AI arms race\" between nations or corporations.\n","  + <Safety_Corner_Cutting>: Competitive dynamics may incentivize corner-cutting on AI safety.\n","\n","/* \n","(3) [AI_AGI_Risk]: Current AI development patterns could increase future risks from unaligned AGI. => [AI_Existential_Risk_Factor]\n","*/\n","\n","\n","## Stable Repressive Regime Risk\n","\n","\n","<Repressive_Regime_Argument>:\n","  + <AI_Surveillance_Growth>: Rapid increase in AI surveillance technologies globally.\n","  + <Lagging_Ethical_Frameworks>: Even democratic countries fail to meet regulatory standards for surveillance.\n","  + <Surveillance_Privatization>: Private-public partnerships normalize surveillance beyond legal limits.\n","\n","/* \n","(4) [AI_Repressive_Regime_Risk]: AI surveillance enables potentially stable, global repressive autocracies constituting existential catastrophes. => [AI_Existential_Risk_Factor]\n","*/\n","\n","\n","\n","\n","/* \n","From: Current and Near-Term AI as a Potential Existential Risk Factor by Benjamin S. Bucknall∗\n","*/\n"],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"}],"source":["display(Markdown(md_content))"]},{"cell_type":"markdown","metadata":{"id":"57YvCx9dom5J"},"source":["## 0.3a Authenticate & Link With Google Drive (For Interactive Sheets)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0U4koSoepB9-"},"outputs":[],"source":["!pip install --upgrade gspread pandas google-auth google-colab\n","\n","import gspread\n","import pandas as pd\n","import numpy as np\n","\n","\n","from google.colab import auth\n","from google.auth import default\n","from google.colab import data_table\n","from google.colab import sheets\n","\n","# Authenticate user\n","auth.authenticate_user()\n","\n","# Set up gspread authorization\n","creds, _ = default()\n","gc = gspread.authorize(creds)\n","\n","\n","sheet = sheets.InteractiveSheet(title='01Extraction', include_column_headers=True)\n","\n","\n","# Create a Pandas DataFrame\n","# Assuming the first row contains column headers\n","df = pd.DataFrame(data[1:], columns=data[0])\n","\n","# Now you can work with the DataFrame 'df'\n","print(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":30395,"status":"error","timestamp":1743096698536,"user":{"displayName":"Singularity Smith","userId":"08757842931667367012"},"user_tz":360},"id":"TWGlSbPhonPy","outputId":"11e04c20-24fb-47ac-f375-639641f579a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.2.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Collecting pandas\n","  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: google-auth in /usr/local/lib/python3.11/dist-packages (2.38.0)\n","Requirement already satisfied: google-colab in /usr/local/lib/python3.11/dist-packages (1.0.0)\n","Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from gspread) (1.2.1)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth) (4.9)\n","Requirement already satisfied: ipykernel==6.17.1 in /usr/local/lib/python3.11/dist-packages (from google-colab) (6.17.1)\n","Requirement already satisfied: ipyparallel==8.8.0 in /usr/local/lib/python3.11/dist-packages (from google-colab) (8.8.0)\n","Requirement already satisfied: ipython==7.34.0 in /usr/local/lib/python3.11/dist-packages (from google-colab) (7.34.0)\n","Requirement already satisfied: notebook==6.5.7 in /usr/local/lib/python3.11/dist-packages (from google-colab) (6.5.7)\n","Requirement already satisfied: portpicker==1.5.2 in /usr/local/lib/python3.11/dist-packages (from google-colab) (1.5.2)\n","Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from google-colab) (2.32.3)\n","Requirement already satisfied: tornado==6.4.2 in /usr/local/lib/python3.11/dist-packages (from google-colab) (6.4.2)\n","Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (1.8.0)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (6.1.12)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (0.1.7)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (1.6.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (5.9.5)\n","Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (24.0.1)\n","Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel==6.17.1->google-colab) (5.7.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (4.4.2)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (0.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from ipyparallel==8.8.0->google-colab) (4.67.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (75.1.0)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (0.19.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (3.0.50)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (2.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython==7.34.0->google-colab) (4.9.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (3.1.6)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (23.1.0)\n","Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (5.7.2)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (0.2.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (5.10.4)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (7.16.6)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (0.21.1)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook==6.5.7->google-colab) (1.2.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->google-colab) (2025.1.31)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython==7.34.0->google-colab) (0.8.4)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.1->notebook==6.5.7->google-colab) (4.3.7)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook==6.5.7->google-colab) (0.2.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (4.13.3)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook==6.5.7->google-colab) (6.2.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (0.3.0)\n","Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (3.0.2)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (3.1.3)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (0.10.2)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook==6.5.7->google-colab) (1.5.1)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook==6.5.7->google-colab) (2.21.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook==6.5.7->google-colab) (4.23.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython==7.34.0->google-colab) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.34.0->google-colab) (0.2.13)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook==6.5.7->google-colab) (21.2.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook==6.5.7->google-colab) (0.5.1)\n","Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook==6.5.7->google-colab) (1.4.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.7->google-colab) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.7->google-colab) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.7->google-colab) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.7->google-colab) (0.23.1)\n","Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.7->google-colab) (1.16.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook==6.5.7->google-colab) (1.17.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook==6.5.7->google-colab) (2.6)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook==6.5.7->google-colab) (4.12.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook==6.5.7->google-colab) (2.22)\n","Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.7->google-colab) (4.9.0)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.7->google-colab) (1.8.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook==6.5.7->google-colab) (1.3.1)\n","https://docs.google.com/spreadsheets/d/1Is4iHkPOAWx7TiuNIa8ND-OiLkvrwoZ25aXBqrgZuv4/edit#gid=84787734\n"]},{"data":{"text/html":["\n","        <iframe\n","            width=\"100%\"\n","            height=\"600\"\n","            src=\"https://docs.google.com/spreadsheets/d/1Is4iHkPOAWx7TiuNIa8ND-OiLkvrwoZ25aXBqrgZuv4/edit?rm=embedded#gid=84787734\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","            \n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.IFrame at 0x7a14cadace10>"]},"metadata":{},"output_type":"display_data"},{"ename":"NameError","evalue":"name 'data' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-df4281be94fd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Create a Pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Assuming the first row contains column headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Now you can work with the DataFrame 'df'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"]}],"source":["\n","# Authenticate user\n","auth.authenticate_user()\n","\n","# Set up gspread authorization\n","creds, _ = default()\n","gc = gspread.authorize(creds)\n","\n","\n","sheet = sheets.InteractiveSheet(title='01Extraction', include_column_headers=True)\n","\n","\n","# Create a Pandas DataFrame\n","# Assuming the first row contains column headers\n","df = pd.DataFrame(data[1:], columns=data[0])\n","\n","# Now you can work with the DataFrame 'df'\n","print(df)"]},{"cell_type":"markdown","metadata":{"id":"ZWx7CRfHn8Va"},"source":["\n","### 0.3a1 Display Interactive Sheet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":638},"executionInfo":{"elapsed":1129,"status":"ok","timestamp":1743096710539,"user":{"displayName":"Singularity Smith","userId":"08757842931667367012"},"user_tz":360},"id":"EkJN9iFHn8vt","outputId":"19594e73-2d25-44f0-c75c-c37ee39e745b"},"outputs":[{"name":"stdout","output_type":"stream","text":["https://docs.google.com/spreadsheets/d/1Is4iHkPOAWx7TiuNIa8ND-OiLkvrwoZ25aXBqrgZuv4/edit#gid=84787734\n"]},{"data":{"text/html":["\n","        <iframe\n","            width=\"100%\"\n","            height=\"600\"\n","            src=\"https://docs.google.com/spreadsheets/d/1Is4iHkPOAWx7TiuNIa8ND-OiLkvrwoZ25aXBqrgZuv4/edit?rm=embedded#gid=84787734\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","            \n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.IFrame at 0x7a14a8403510>"]},"metadata":{},"output_type":"display_data"}],"source":["sheet = sheets.InteractiveSheet(title='01Extraction', include_column_headers=True)"]},{"cell_type":"markdown","metadata":{"id":"52XyPlte5HrU"},"source":["# 1.0 Sources (PDF's of Papers) to ArgDown (.md file)"]},{"cell_type":"markdown","metadata":{"id":"7SGB0XMp5VFq"},"source":["# 2.0 Probability Extractions: ArgDown (.md) to BayesDown (.md + plugin JSON syntax)"]},{"cell_type":"markdown","metadata":{"id":"SJ9OIyEv5qqb"},"source":["# 3.0 Data Extraction: BayesDown (.md) to Database (.csv)\n"]},{"cell_type":"markdown","metadata":{"id":"AFnu_1Ludahi"},"source":["### 3.1 ExtractBayesDown-Data_v1\n","Build data frame with extractable information from BayesDown"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ka4kLU_sj4nH"},"outputs":[],"source":["# read sprinkler example -- Occam Colab Online\n","file_path_ex_rain = \"/content/drive/MyDrive/AIGrandStrategyProject/08_Technical_SoftwareImplementation/04_Prototypes/_repos/AMTAIR_Prototype_0.1.1/BayesDown_Example.md\"\n","with open(file_path_ex_rain, 'r') as f:\n","  md_content_ex_rain = f.read()\n","\n","display(Markdown(md_content_ex_rain))"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"UUDNqjOYcWFT","outputId":"d26058e7-9f42-4561-fa36-2dc9099595c1"},"outputs":[{"data":{"text/markdown":["## BayesDown Example\n","\n","\n","[Grass_Wet]: Concentrated moisture on, between and around the blades of grass. {\"instantiations\": [\"TRUE\", \"FALSE\"], \"priors\": {\"p(TRUE)\": \"0.322\",\"p(FALSE)\": \"0.678\" },\"posteriors\": {\"p(grass_wet|sprinkler,rain)\": \"0.00198\",\"p(grass_wet|sprinkler,no_rain)\": \"0.288\",\"p(grass_wet|no_sprinkler,rain)\": \"0.1584\",\"p(grass_wet|no_sprinkler,no_rain)\": \"0\",\"p(no_grass_wet|sprinkler,rain)\": \"0.00002\",\"p(no_grass_wet|sprinkler,no_rain)\": \"0.032\",\"p(no_grass_wet|no_sprinkler,rain)\": \"0.0396\",\"p(no_grass_wet|no_sprinkler,no_rain)\": \"0.48\"}}\n"," + [Rain]: Tears of angles crying high up in the skies hitting the ground.{\"instantiations\": [\"TRUE\", \"FALSE\"],\"priors\": {\"p(TRUE)\": \"0.2\",\"p(FALSE)\": \"0.8\"},\"posteriors\": {}}\n"," + [Sprinkler]: Activation of a centrifugal force based CO2 droplet distribution system.{\"instantiations\": [\"TRUE\", \"FALSE\"],\"priors\": {\"p(TRUE)\": \"0.44838\",\"p(FALSE)\": \"0.55162\"},\"posteriors\": {\"p(sprinkler|rain)\": \"0.01\",\"p(sprinkler|no_rain)\": \"0.4\",\"p(no_sprinkler|rain)\": \"0.99\",\"p(no_sprinkler|no_rain)\":\"0.6\"}}\n","  + [Rain]\n","\n","\n","/* ArgDown is extremely sensitive w.r.t. syntax. If there are mistakes, eg. double \"\" instead of single \" or brackets or indentation are off or with the wrong indentation, ArgDown will not compile!*/"],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"}],"source":["# read sprinkler example --- Ella VS offline\n","file_path_ex_rain = \"/Users/ellaalle/code-ws/AMTAIR_Prototype/BayesDown_Example.md\"\n","with open(file_path_ex_rain, 'r') as f:\n","  md_content_ex_rain_easy = f.read()\n","\n","display(Markdown(md_content_ex_rain_easy))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UvwxoMu3HFVm","outputId":"ddaac367-93fd-4083-e294-4f6235db9941"},"outputs":[{"data":{"text/markdown":["## BayesDown Example\n","\n","\n","[Grass_Wet]: Concentrated moisture on, between and around the blades of grass. {\"instantiations\": [\"TRUE\", \"FALSE\"], \"priors\": {\"p(TRUE)\": \"0.322\",\"p(FALSE)\": \"0.678\" },\"posteriors\": {\"p(grass_wet|sprinkler,rain)\": \"0.00198\",\"p(grass_wet|sprinkler,no_rain)\": \"0.288\",\"p(grass_wet|no_sprinkler,rain)\": \"0.1584\",\"p(grass_wet|no_sprinkler,no_rain)\": \"0\",\"p(no_grass_wet|sprinkler,rain)\": \"0.00002\",\"p(no_grass_wet|sprinkler,no_rain)\": \"0.032\",\"p(no_grass_wet|no_sprinkler,rain)\": \"0.0396\",\"p(no_grass_wet|no_sprinkler,no_rain)\": \"0.48\"}}\n"," + [Rain]: Tears of angles crying high up in the skies hitting the ground.{\"instantiations\": [\"TRUE\", \"FALSE\"],\"priors\": {\"p(TRUE)\": \"0.2\",\"p(FALSE)\": \"0.8\"},\"posteriors\": {}}\n"," + [Sprinkler]: Activation of a centrifugal force based CO2 droplet distribution system.{\"instantiations\": [\"TRUE\", \"FALSE\"],\"priors\": {\"p(TRUE)\": \"0.44838\",\"p(FALSE)\": \"0.55162\"},\"posteriors\": {\"p(sprinkler|rain)\": \"0.01\",\"p(sprinkler|no_rain)\": \"0.4\",\"p(no_sprinkler|rain)\": \"0.99\",\"p(no_sprinkler|no_rain)\":\"0.6\"}}\n","  + [Rain]\n"," + [NewArgument]: Blabla of a centrifugal force based CO2 droplet distribution system.{\"instantiations\": [\"TRUE\", \"FALSE\"],\"priors\": {\"p(TRUE)\": \"0.44838\",\"p(FALSE)\": \"0.55162\"},\"posteriors\": {\"p(sprinkler|rain)\": \"0.01\",\"p(sprinkler|no_rain)\": \"0.4\",\"p(no_sprinkler|rain)\": \"0.99\",\"p(no_sprinkler|no_rain)\":\"0.6\"}}\n","  + [EvenMoreNew]\n","  + [EvenMoreNewNewNew]\n","\n","\n","/* ArgDown is extremely sensitive w.r.t. syntax. If there are mistakes, eg. double \"\" instead of single \" or brackets or indentation are off or with the wrong indentation, ArgDown will not compile!*/"],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"}],"source":["# read sprinkler example more complicated -- ella\n","file_path_ex_rain = \"/Users/ellaalle/code-ws/AMTAIR_Prototype/BayesDown_Example_moreComplicated.md\"\n","with open(file_path_ex_rain, 'r') as f:\n","  md_content_ex_rain = f.read()\n","\n","display(Markdown(md_content_ex_rain))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2jgzqunEHFVm","outputId":"bfd0dd8d-92ef-4b69-e801-607f40519d9c"},"outputs":[{"data":{"text/plain":["'# Unconnected titles with descriptions\\n\\n<a>: I am currently in no relation.\\n\\n<b>: It\\'s complicated.\\n\\n<c>: I feel disconnected.\\n\\n# Two generation connected arguments\\n\\n[Thesis]: Censorship is not wrong in principle.\\n + <P1a>: Freedom of speech is never an absolute right but an aspiration. It ceases to be a right when it causes harm to others. Therefore it is not the case that censorship is wrong in principle.{\"instantiations\": [\"TRUE\", \"FALSE\"],\"priors\": {\"p(TRUE)\": \"0.322\", \"p(FALSE)\": \"0.678\"}, \"posteriors\": {\"p(grass_wet|sprinkler,rain)\": \"0.00198\", \"p(grass_wet|sprinkler,no_rain)\": \"0.288\", \"p(grass_wet|no_sprinkler,rain)\": \"0.1584\", \"p(grass_wet|no_sprinkler,no_rain)\": \"0\", \"p(no_grass_wet|sprinkler,rain)\": \"0.00002\", \"p(no_grass_wet|sprinkler,no_rain)\": \"0.032\", \"p(no_grass_wet|no_sprinkler,rain)\": \"0.0396\", \"p(no_grass_wet|no_sprinkler,no_rain)\": \"0.48\"}}\\n + <P1b>: We all recognise the value of, for example, legislating against incitement to racial hatred. #pro\\n  - <C1b>: Censorship such as legislation against incitement to racial hatred drives racists and others underground and thus entrenches and ghettoises that section of the community rather than drawing its members into open and rational debate. #con\\n + <P2>: Certain types of literature or visual image have been conclusively linked to crime. Excessive sex and violence in film and television has been shown (especially in studies in the US) to contribute to a tendency towards similar behaviour in spectators. There is no excuse for this and such images must be sacrificed, no matter what their artistic merit. #pro\\n  - <C2>: In fact, the link between sex and violence on screen and in real life is far from conclusive. To look at it from another angle, those individuals who _already have tendencies_ to violence are likely to watch violent `video nasties\\', just as those with a predilection for rape are likely to use pornography. The two are therefore connected but the individual\\'s personality is formed first. #con\\n   - <C3>: Trying whether a third generation will also work. /* plus adding a comment to ignore <hallo> */\\n   - [Thesis]\\n - <C1a>: Censorship is wrong in principle. However violently we may disagree with a person\\'s point of view or mode of expression, they must be free to express themselves in a free and civilized society.\\n\\n\\n\\n'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# read basic ArgDown example With BayesDown syntax added and corss generational added -- Ella\n","file_path_easy_ex_B_CG = \"/Users/ellaalle/code-ws/AMTAIR_Prototype/Example_file_combined_withBayesDown_Crossgenerational.md\"\n","with open(file_path_easy_ex_B_CG, 'r') as f:\n","  md_content_easy_ex_B_CG = f.read()\n","\n","md_content_easy_ex_B_CG"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3S5fqk7BHFVm"},"outputs":[],"source":["def parse_markdown_hierarchy(markdown_text):\n","    \"\"\"Main function to parse markdown hierarchy into a DataFrame\"\"\"\n","\n","    # Remove comments\n","    clean_text = remove_comments(markdown_text)\n","\n","    # Extract all titles with their descriptions and indentation levels\n","    titles_info = extract_titles_info(clean_text)\n","\n","    # Establish parent-child relationships\n","    titles_with_relations = establish_relationships(titles_info, clean_text)\n","\n","    # Convert to DataFrame\n","    df = convert_to_dataframe(titles_with_relations)\n","\n","    # Add No_Parent and No_Children columns\n","    df = add_no_parent_no_child_columns_to_df(df)\n","\n","    return df\n","\n","def remove_comments(markdown_text):\n","    \"\"\"Remove comment blocks from markdown text\"\"\"\n","    return re.sub(r'/\\*.*?\\*/', '', markdown_text, flags=re.DOTALL)\n","\n","def extract_titles_info(text):\n","    \"\"\"Extract titles with their descriptions and indentation levels\"\"\"\n","    lines = text.split('\\n')\n","    titles_info = {}\n","\n","    for line in lines:\n","        if not line.strip():\n","            continue\n","\n","        title_match = re.search(r'[<\\[](.+?)[>\\]]', line)\n","        if not title_match:\n","            continue\n","\n","        title = title_match.group(1)\n","\n","        # Extract description and metadata\n","        title_pattern_in_line = r'[<\\[]' + re.escape(title) + r'[>\\]]:'\n","        description_match = re.search(title_pattern_in_line + r'\\s*(.*)', line)\n","\n","        if description_match:\n","            full_text = description_match.group(1).strip()\n","\n","            # Check if description contains a \"{\" to not include metadata in description\n","            if \"{\" in full_text:\n","                # Split at the first \"{\"\n","                split_index = full_text.find(\"{\")\n","                description = full_text[:split_index].strip()\n","                metadata = full_text[split_index:].strip()\n","            else:\n","                # Keep the entire description and no metadata\n","                description = full_text\n","                metadata = ''\n","        else:\n","            description = ''\n","            metadata = ''  # Ensure metadata is initialized as empty string\n","\n","        indentation = 0\n","        if '+' in line:\n","            symbol_index = line.find('+')\n","            # Count spaces before the '+' symbol\n","            i = symbol_index - 1\n","            while i >= 0 and line[i] == ' ':\n","                indentation += 1\n","                i -= 1\n","        elif '-' in line:\n","            symbol_index = line.find('-')\n","            # Count spaces before the '-' symbol\n","            i = symbol_index - 1\n","            while i >= 0 and line[i] == ' ':\n","                indentation += 1\n","                i -= 1\n","\n","        # If neither symbol exists, indentation remains 0\n","\n","        if title in titles_info:\n","            # Only update description if it's currently empty and we found a new one\n","            if not titles_info[title]['description'] and description:\n","                titles_info[title]['description'] = description\n","\n","            # Store all indentation levels for this title\n","            titles_info[title]['indentation_levels'].append(indentation)\n","\n","            # Keep max indentation for backward compatibility\n","            if indentation > titles_info[title]['indentation']:\n","                titles_info[title]['indentation'] = indentation\n","\n","            # Do NOT update metadata here - keep the original metadata\n","        else:\n","            # First time seeing this title, create a new entry\n","            titles_info[title] = {\n","                'description': description,\n","                'indentation': indentation,\n","                'indentation_levels': [indentation],  # Initialize with first indentation level\n","                'parents': [],\n","                'children': [],\n","                'line': None,\n","                'line_numbers': [],  # Initialize an empty list for all occurrences\n","                'metadata': metadata  # Set metadata explicitly from what we found\n","            }\n","\n","    return titles_info\n","\n","def establish_relationships(titles_info, text):\n","    \"\"\"Establish parent-child relationships between titles using the BayesDown indentation rules\"\"\"\n","    lines = text.split('\\n')\n","\n","    # Dictionary to store line numbers for each title occurrence\n","    title_occurrences = {}\n","\n","    # Record line number for each title (including multiple occurrences)\n","    line_number = 0\n","    for line in lines:\n","        if not line.strip():\n","            line_number += 1\n","            continue\n","\n","        title_match = re.search(r'[<\\[](.+?)[>\\]]', line)\n","        if not title_match:\n","            line_number += 1\n","            continue\n","\n","        title = title_match.group(1)\n","\n","        # Store all occurrences of each title with their line numbers\n","        if title not in title_occurrences:\n","            title_occurrences[title] = []\n","        title_occurrences[title].append(line_number)\n","\n","        # Store all line numbers where this title appears\n","        if 'line_numbers' not in titles_info[title]:\n","            titles_info[title]['line_numbers'] = []\n","        titles_info[title]['line_numbers'].append(line_number)\n","\n","        # For backward compatibility, keep the first occurrence in 'line'\n","        if titles_info[title]['line'] is None:\n","            titles_info[title]['line'] = line_number\n","\n","        line_number += 1\n","\n","    # Create an ordered list of all title occurrences with their line numbers\n","    all_occurrences = []\n","    for title, occurrences in title_occurrences.items():\n","        for line_num in occurrences:\n","            all_occurrences.append((title, line_num))\n","\n","    # Sort occurrences by line number\n","    all_occurrences.sort(key=lambda x: x[1])\n","\n","    # Get indentation for each occurrence\n","    occurrence_indents = {}\n","    for title, line_num in all_occurrences:\n","        for line in lines[line_num:line_num+1]:  # Only check the current line\n","            indent = 0\n","            if '+' in line:\n","                symbol_index = line.find('+')\n","                # Count spaces before the '+' symbol\n","                j = symbol_index - 1\n","                while j >= 0 and line[j] == ' ':\n","                    indent += 1\n","                    j -= 1\n","            elif '-' in line:\n","                symbol_index = line.find('-')\n","                # Count spaces before the '-' symbol\n","                j = symbol_index - 1\n","                while j >= 0 and line[j] == ' ':\n","                    indent += 1\n","                    j -= 1\n","            occurrence_indents[(title, line_num)] = indent\n","\n","    # Process for finding parents (looking forward)\n","    for i, (title, line_num) in enumerate(all_occurrences):\n","        current_indent = occurrence_indents[(title, line_num)]\n","\n","        # Look ahead for potential parents that are exactly one indentation level higher\n","        j = i + 1\n","        while j < len(all_occurrences):\n","            next_title, next_line = all_occurrences[j]\n","            next_indent = occurrence_indents[(next_title, next_line)]\n","\n","            # If we find a title with same or less indentation, stop looking in this section\n","            if next_indent <= current_indent:\n","                break\n","\n","            # If this is a direct parent (exactly one more indentation) and not the same title\n","            if next_indent == current_indent + 1 and next_title != title:\n","                # More indented node is parent of less indented node\n","                if next_title not in titles_info[title]['parents']:\n","                    titles_info[title]['parents'].append(next_title)\n","                if title not in titles_info[next_title]['children']:\n","                    titles_info[next_title]['children'].append(title)\n","\n","            j += 1\n","\n","    # Process for finding children (looking backward)\n","    for i, (title, line_num) in enumerate(all_occurrences):\n","        current_indent = occurrence_indents[(title, line_num)]\n","\n","        # Skip titles with indentation 0 (they don't have children by looking backward)\n","        if current_indent == 0:\n","            continue\n","\n","        # Look for the immediately preceding title with one less indentation (immediate child)\n","        j = i - 1\n","        found_child = False\n","\n","        while j >= 0 and not found_child:\n","            prev_title, prev_line = all_occurrences[j]\n","            prev_indent = occurrence_indents[(prev_title, prev_line)]\n","\n","            # If the previous title has exactly one less indentation and is not the same title\n","            if prev_indent == current_indent - 1 and prev_title != title:\n","                # Current title is parent of previous title\n","                if title not in titles_info[prev_title]['parents']:\n","                    titles_info[prev_title]['parents'].append(title)\n","                if prev_title not in titles_info[title]['children']:\n","                    titles_info[title]['children'].append(prev_title)\n","                found_child = True  # Only find one immediate child\n","\n","            # If we encounter a title with even less indentation, stop looking\n","            if prev_indent < current_indent - 1:\n","                break\n","\n","            j -= 1\n","\n","    return titles_info\n","\n","    return titles_info\n","\n","def convert_to_dataframe(titles_info):\n","    \"\"\"Convert the titles information dictionary to a pandas DataFrame\"\"\"\n","    df = pd.DataFrame(columns=['Title', 'Description', 'line', 'line_numbers', 'indentation',\n","                               'indentation_levels', 'Parents', 'Children', 'instantiations',\n","                               'priors', 'posteriors'])\n","\n","    for title, info in titles_info.items():\n","        # Parse the metadata JSON string into a Python dictionary\n","        if 'metadata' in info and info['metadata']:\n","            try:\n","                # Only try to parse if metadata is not empty\n","                if info['metadata'].strip():\n","                    jsonMetadata = json.loads(info['metadata'])\n","\n","                    # Create the row dictionary with basic fields\n","                    row = {\n","                        'Title': title,\n","                        'Description': info.get('description', ''),\n","                        'line': info.get('line',''),\n","                        'line_numbers': info.get('line_numbers', []),\n","                        'indentation': info.get('indentation',''),\n","                        'indentation_levels': info.get('indentation_levels', []),\n","                        'Parents': info.get('parents', []),\n","                        'Children': info.get('children', []),\n","                        # Extract specific metadata fields, defaulting to empty if not present\n","                        'instantiations': jsonMetadata.get('instantiations', []),\n","                        'priors': jsonMetadata.get('priors', {}),\n","                        'posteriors': jsonMetadata.get('posteriors', {})\n","                    }\n","                else:\n","                    # Empty metadata case\n","                    row = {\n","                        'Title': title,\n","                        'Description': info.get('description', ''),\n","                        'line': info.get('line',''),\n","                        'line_numbers': info.get('line_numbers', []),\n","                        'indentation': info.get('indentation',''),\n","                        'indentation_levels': info.get('indentation_levels', []),\n","                        'Parents': info.get('parents', []),\n","                        'Children': info.get('children', []),\n","                        'instantiations': [],\n","                        'priors': {},\n","                        'posteriors': {}\n","                    }\n","            except json.JSONDecodeError:\n","                # Handle case where metadata isn't valid JSON\n","                row = {\n","                    'Title': title,\n","                    'Description': info.get('description', ''),\n","                    'line': info.get('line',''),\n","                    'line_numbers': info.get('line_numbers', []),\n","                    'indentation': info.get('indentation',''),\n","                    'indentation_levels': info.get('indentation_levels', []),\n","                    'Parents': info.get('parents', []),\n","                    'Children': info.get('children', []),\n","                    'instantiations': [],\n","                    'priors': {},\n","                    'posteriors': {}\n","                }\n","        else:\n","            # Handle case where metadata field doesn't exist or is empty\n","            row = {\n","                'Title': title,\n","                'Description': info.get('description', ''),\n","                'line': info.get('line',''),\n","                'line_numbers': info.get('line_numbers', []),\n","                'indentation': info.get('indentation',''),\n","                'indentation_levels': info.get('indentation_levels', []),\n","                'Parents': info.get('parents', []),\n","                'Children': info.get('children', []),\n","                'instantiations': [],\n","                'priors': {},\n","                'posteriors': {}\n","            }\n","\n","        # Add the row to the DataFrame\n","        df.loc[len(df)] = row\n","\n","    return df\n","\n","def add_no_parent_no_child_columns_to_df(dataframe):\n","    \"\"\"Add No_Parent and No_Children boolean columns to the DataFrame\"\"\"\n","    no_parent = []\n","    no_children = []\n","\n","    for _, row in dataframe.iterrows():\n","        no_parent.append(not row['Parents'])\n","        no_children.append(not row['Children'])\n","\n","    dataframe['No_Parent'] = no_parent\n","    dataframe['No_Children'] = no_children\n","\n","    return dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F9gS3DUncWFV","outputId":"139d2597-d3a3-431d-ce21-6669c8a05559"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Title</th>\n","      <th>Description</th>\n","      <th>line</th>\n","      <th>line_numbers</th>\n","      <th>indentation</th>\n","      <th>indentation_levels</th>\n","      <th>Parents</th>\n","      <th>Children</th>\n","      <th>instantiations</th>\n","      <th>priors</th>\n","      <th>posteriors</th>\n","      <th>No_Parent</th>\n","      <th>No_Children</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Grass_Wet</td>\n","      <td>Concentrated moisture on, between and around t...</td>\n","      <td>3</td>\n","      <td>[3]</td>\n","      <td>0</td>\n","      <td>[0]</td>\n","      <td>[Rain, Sprinkler]</td>\n","      <td>[]</td>\n","      <td>[TRUE, FALSE]</td>\n","      <td>{'p(TRUE)': '0.322', 'p(FALSE)': '0.678'}</td>\n","      <td>{'p(grass_wet|sprinkler,rain)': '0.00198', 'p(...</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rain</td>\n","      <td>Tears of angles crying high up in the skies hi...</td>\n","      <td>4</td>\n","      <td>[4, 6]</td>\n","      <td>2</td>\n","      <td>[1, 2]</td>\n","      <td>[]</td>\n","      <td>[Grass_Wet, Sprinkler]</td>\n","      <td>[TRUE, FALSE]</td>\n","      <td>{'p(TRUE)': '0.2', 'p(FALSE)': '0.8'}</td>\n","      <td>{}</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sprinkler</td>\n","      <td>Activation of a centrifugal force based CO2 dr...</td>\n","      <td>5</td>\n","      <td>[5]</td>\n","      <td>1</td>\n","      <td>[1]</td>\n","      <td>[Rain]</td>\n","      <td>[Grass_Wet]</td>\n","      <td>[TRUE, FALSE]</td>\n","      <td>{'p(TRUE)': '0.44838', 'p(FALSE)': '0.55162'}</td>\n","      <td>{'p(sprinkler|rain)': '0.01', 'p(sprinkler|no_...</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Title                                        Description  line  \\\n","0  Grass_Wet  Concentrated moisture on, between and around t...     3   \n","1       Rain  Tears of angles crying high up in the skies hi...     4   \n","2  Sprinkler  Activation of a centrifugal force based CO2 dr...     5   \n","\n","  line_numbers  indentation indentation_levels            Parents  \\\n","0          [3]            0                [0]  [Rain, Sprinkler]   \n","1       [4, 6]            2             [1, 2]                 []   \n","2          [5]            1                [1]             [Rain]   \n","\n","                 Children instantiations  \\\n","0                      []  [TRUE, FALSE]   \n","1  [Grass_Wet, Sprinkler]  [TRUE, FALSE]   \n","2             [Grass_Wet]  [TRUE, FALSE]   \n","\n","                                          priors  \\\n","0      {'p(TRUE)': '0.322', 'p(FALSE)': '0.678'}   \n","1          {'p(TRUE)': '0.2', 'p(FALSE)': '0.8'}   \n","2  {'p(TRUE)': '0.44838', 'p(FALSE)': '0.55162'}   \n","\n","                                          posteriors  No_Parent  No_Children  \n","0  {'p(grass_wet|sprinkler,rain)': '0.00198', 'p(...      False         True  \n","1                                                 {}       True        False  \n","2  {'p(sprinkler|rain)': '0.01', 'p(sprinkler|no_...      False        False  "]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["result_df = parse_markdown_hierarchy(md_content_ex_rain_easy)\n","result_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hmoEC7JaHFVn","outputId":"9cb5c244-e772-4b9a-80b6-6d4c5e9cb0cc"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Title</th>\n","      <th>Description</th>\n","      <th>line</th>\n","      <th>line_numbers</th>\n","      <th>indentation</th>\n","      <th>indentation_levels</th>\n","      <th>Parents</th>\n","      <th>Children</th>\n","      <th>instantiations</th>\n","      <th>priors</th>\n","      <th>posteriors</th>\n","      <th>No_Parent</th>\n","      <th>No_Children</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Grass_Wet</td>\n","      <td>Concentrated moisture on, between and around t...</td>\n","      <td>3</td>\n","      <td>[3]</td>\n","      <td>0</td>\n","      <td>[0]</td>\n","      <td>[Rain, Sprinkler, NewArgument]</td>\n","      <td>[]</td>\n","      <td>[TRUE, FALSE]</td>\n","      <td>{'p(TRUE)': '0.322', 'p(FALSE)': '0.678'}</td>\n","      <td>{'p(grass_wet|sprinkler,rain)': '0.00198', 'p(...</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rain</td>\n","      <td>Tears of angles crying high up in the skies hi...</td>\n","      <td>4</td>\n","      <td>[4, 6]</td>\n","      <td>2</td>\n","      <td>[1, 2]</td>\n","      <td>[]</td>\n","      <td>[Grass_Wet, Sprinkler]</td>\n","      <td>[TRUE, FALSE]</td>\n","      <td>{'p(TRUE)': '0.2', 'p(FALSE)': '0.8'}</td>\n","      <td>{}</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sprinkler</td>\n","      <td>Activation of a centrifugal force based CO2 dr...</td>\n","      <td>5</td>\n","      <td>[5]</td>\n","      <td>1</td>\n","      <td>[1]</td>\n","      <td>[Rain]</td>\n","      <td>[Grass_Wet]</td>\n","      <td>[TRUE, FALSE]</td>\n","      <td>{'p(TRUE)': '0.44838', 'p(FALSE)': '0.55162'}</td>\n","      <td>{'p(sprinkler|rain)': '0.01', 'p(sprinkler|no_...</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NewArgument</td>\n","      <td>Blabla of a centrifugal force based CO2 drople...</td>\n","      <td>7</td>\n","      <td>[7]</td>\n","      <td>1</td>\n","      <td>[1]</td>\n","      <td>[EvenMoreNew, EvenMoreNewNewNew]</td>\n","      <td>[Grass_Wet]</td>\n","      <td>[TRUE, FALSE]</td>\n","      <td>{'p(TRUE)': '0.44838', 'p(FALSE)': '0.55162'}</td>\n","      <td>{'p(sprinkler|rain)': '0.01', 'p(sprinkler|no_...</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>EvenMoreNew</td>\n","      <td></td>\n","      <td>8</td>\n","      <td>[8]</td>\n","      <td>2</td>\n","      <td>[2]</td>\n","      <td>[]</td>\n","      <td>[NewArgument]</td>\n","      <td>[]</td>\n","      <td>{}</td>\n","      <td>{}</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>EvenMoreNewNewNew</td>\n","      <td></td>\n","      <td>9</td>\n","      <td>[9]</td>\n","      <td>2</td>\n","      <td>[2]</td>\n","      <td>[]</td>\n","      <td>[NewArgument]</td>\n","      <td>[]</td>\n","      <td>{}</td>\n","      <td>{}</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Title                                        Description  line  \\\n","0          Grass_Wet  Concentrated moisture on, between and around t...     3   \n","1               Rain  Tears of angles crying high up in the skies hi...     4   \n","2          Sprinkler  Activation of a centrifugal force based CO2 dr...     5   \n","3        NewArgument  Blabla of a centrifugal force based CO2 drople...     7   \n","4        EvenMoreNew                                                        8   \n","5  EvenMoreNewNewNew                                                        9   \n","\n","  line_numbers  indentation indentation_levels  \\\n","0          [3]            0                [0]   \n","1       [4, 6]            2             [1, 2]   \n","2          [5]            1                [1]   \n","3          [7]            1                [1]   \n","4          [8]            2                [2]   \n","5          [9]            2                [2]   \n","\n","                            Parents                Children instantiations  \\\n","0    [Rain, Sprinkler, NewArgument]                      []  [TRUE, FALSE]   \n","1                                []  [Grass_Wet, Sprinkler]  [TRUE, FALSE]   \n","2                            [Rain]             [Grass_Wet]  [TRUE, FALSE]   \n","3  [EvenMoreNew, EvenMoreNewNewNew]             [Grass_Wet]  [TRUE, FALSE]   \n","4                                []           [NewArgument]             []   \n","5                                []           [NewArgument]             []   \n","\n","                                          priors  \\\n","0      {'p(TRUE)': '0.322', 'p(FALSE)': '0.678'}   \n","1          {'p(TRUE)': '0.2', 'p(FALSE)': '0.8'}   \n","2  {'p(TRUE)': '0.44838', 'p(FALSE)': '0.55162'}   \n","3  {'p(TRUE)': '0.44838', 'p(FALSE)': '0.55162'}   \n","4                                             {}   \n","5                                             {}   \n","\n","                                          posteriors  No_Parent  No_Children  \n","0  {'p(grass_wet|sprinkler,rain)': '0.00198', 'p(...      False         True  \n","1                                                 {}       True        False  \n","2  {'p(sprinkler|rain)': '0.01', 'p(sprinkler|no_...      False        False  \n","3  {'p(sprinkler|rain)': '0.01', 'p(sprinkler|no_...      False        False  \n","4                                                 {}       True        False  \n","5                                                 {}       True        False  "]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["result_df = parse_markdown_hierarchy(md_content_ex_rain)\n","result_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pwMzzPxfHFVn","outputId":"b45f6d03-a1db-4c5f-bf35-f4c6ba816cc5"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Title</th>\n","      <th>Description</th>\n","      <th>line</th>\n","      <th>line_numbers</th>\n","      <th>indentation</th>\n","      <th>indentation_levels</th>\n","      <th>Parents</th>\n","      <th>Children</th>\n","      <th>instantiations</th>\n","      <th>priors</th>\n","      <th>posteriors</th>\n","      <th>No_Parent</th>\n","      <th>No_Children</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>a</td>\n","      <td>I am currently in no relation.</td>\n","      <td>2</td>\n","      <td>[2]</td>\n","      <td>0</td>\n","      <td>[0]</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>{}</td>\n","      <td>{}</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>b</td>\n","      <td>It's complicated.</td>\n","      <td>4</td>\n","      <td>[4]</td>\n","      <td>0</td>\n","      <td>[0]</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>{}</td>\n","      <td>{}</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>c</td>\n","      <td>I feel disconnected.</td>\n","      <td>6</td>\n","      <td>[6]</td>\n","      <td>0</td>\n","      <td>[0]</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>{}</td>\n","      <td>{}</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Thesis</td>\n","      <td>Censorship is not wrong in principle.</td>\n","      <td>10</td>\n","      <td>[10, 17]</td>\n","      <td>3</td>\n","      <td>[0, 3]</td>\n","      <td>[P1a, P1b, P2, C1a]</td>\n","      <td>[C2]</td>\n","      <td>[]</td>\n","      <td>{}</td>\n","      <td>{}</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>P1a</td>\n","      <td>Freedom of speech is never an absolute right b...</td>\n","      <td>11</td>\n","      <td>[11]</td>\n","      <td>1</td>\n","      <td>[1]</td>\n","      <td>[]</td>\n","      <td>[Thesis]</td>\n","      <td>[TRUE, FALSE]</td>\n","      <td>{'p(TRUE)': '0.322', 'p(FALSE)': '0.678'}</td>\n","      <td>{'p(grass_wet|sprinkler,rain)': '0.00198', 'p(...</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>P1b</td>\n","      <td>We all recognise the value of, for example, le...</td>\n","      <td>12</td>\n","      <td>[12]</td>\n","      <td>1</td>\n","      <td>[1]</td>\n","      <td>[C1b]</td>\n","      <td>[Thesis]</td>\n","      <td>[]</td>\n","      <td>{}</td>\n","      <td>{}</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>C1b</td>\n","      <td>Censorship such as legislation against incitem...</td>\n","      <td>13</td>\n","      <td>[13]</td>\n","      <td>2</td>\n","      <td>[2]</td>\n","      <td>[]</td>\n","      <td>[P1b]</td>\n","      <td>[]</td>\n","      <td>{}</td>\n","      <td>{}</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>P2</td>\n","      <td>Certain types of literature or visual image ha...</td>\n","      <td>14</td>\n","      <td>[14]</td>\n","      <td>1</td>\n","      <td>[1]</td>\n","      <td>[C2]</td>\n","      <td>[Thesis]</td>\n","      <td>[]</td>\n","      <td>{}</td>\n","      <td>{}</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>C2</td>\n","      <td>In fact, the link between sex and violence on ...</td>\n","      <td>15</td>\n","      <td>[15]</td>\n","      <td>2</td>\n","      <td>[2]</td>\n","      <td>[C3, Thesis]</td>\n","      <td>[P2]</td>\n","      <td>[]</td>\n","      <td>{}</td>\n","      <td>{}</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>C3</td>\n","      <td>Trying whether a third generation will also work.</td>\n","      <td>16</td>\n","      <td>[16]</td>\n","      <td>3</td>\n","      <td>[3]</td>\n","      <td>[]</td>\n","      <td>[C2]</td>\n","      <td>[]</td>\n","      <td>{}</td>\n","      <td>{}</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>C1a</td>\n","      <td>Censorship is wrong in principle. However viol...</td>\n","      <td>18</td>\n","      <td>[18]</td>\n","      <td>1</td>\n","      <td>[1]</td>\n","      <td>[]</td>\n","      <td>[Thesis]</td>\n","      <td>[]</td>\n","      <td>{}</td>\n","      <td>{}</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Title                                        Description  line  \\\n","0        a                     I am currently in no relation.     2   \n","1        b                                  It's complicated.     4   \n","2        c                               I feel disconnected.     6   \n","3   Thesis              Censorship is not wrong in principle.    10   \n","4      P1a  Freedom of speech is never an absolute right b...    11   \n","5      P1b  We all recognise the value of, for example, le...    12   \n","6      C1b  Censorship such as legislation against incitem...    13   \n","7       P2  Certain types of literature or visual image ha...    14   \n","8       C2  In fact, the link between sex and violence on ...    15   \n","9       C3  Trying whether a third generation will also work.    16   \n","10     C1a  Censorship is wrong in principle. However viol...    18   \n","\n","   line_numbers  indentation indentation_levels              Parents  \\\n","0           [2]            0                [0]                   []   \n","1           [4]            0                [0]                   []   \n","2           [6]            0                [0]                   []   \n","3      [10, 17]            3             [0, 3]  [P1a, P1b, P2, C1a]   \n","4          [11]            1                [1]                   []   \n","5          [12]            1                [1]                [C1b]   \n","6          [13]            2                [2]                   []   \n","7          [14]            1                [1]                 [C2]   \n","8          [15]            2                [2]         [C3, Thesis]   \n","9          [16]            3                [3]                   []   \n","10         [18]            1                [1]                   []   \n","\n","    Children instantiations                                     priors  \\\n","0         []             []                                         {}   \n","1         []             []                                         {}   \n","2         []             []                                         {}   \n","3       [C2]             []                                         {}   \n","4   [Thesis]  [TRUE, FALSE]  {'p(TRUE)': '0.322', 'p(FALSE)': '0.678'}   \n","5   [Thesis]             []                                         {}   \n","6      [P1b]             []                                         {}   \n","7   [Thesis]             []                                         {}   \n","8       [P2]             []                                         {}   \n","9       [C2]             []                                         {}   \n","10  [Thesis]             []                                         {}   \n","\n","                                           posteriors  No_Parent  No_Children  \n","0                                                  {}       True         True  \n","1                                                  {}       True         True  \n","2                                                  {}       True         True  \n","3                                                  {}      False        False  \n","4   {'p(grass_wet|sprinkler,rain)': '0.00198', 'p(...       True        False  \n","5                                                  {}      False        False  \n","6                                                  {}       True        False  \n","7                                                  {}      False        False  \n","8                                                  {}      False        False  \n","9                                                  {}       True        False  \n","10                                                 {}       True        False  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["result_df_CG = parse_markdown_hierarchy(md_content_easy_ex_B_CG)\n","result_df_CG"]},{"cell_type":"markdown","metadata":{"id":"UcXf3fZ8dahj"},"source":["### 3.3 Data-Post-Processing\n","Add rows to data frame that can be calculated from the extracted rows"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-0BjD1J1dahj"},"outputs":[],"source":["# here we add all the rows that we have to calculate (joint probability..., maybe in several rounds (e.g. first add conditional proability, then use this column to calc joint probability...)"]},{"cell_type":"markdown","metadata":{"id":"xTwPO_J-dahj"},"source":["### 3.4 Download and save finished data frame as .csv file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5rJEacladahj"},"outputs":[],"source":["result_df.to_csv('extracted_data.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"KGoZ9gH55271"},"source":["# 4.0 Analysis & Inference: Practical Software Tools ()"]},{"cell_type":"markdown","metadata":{"id":"mbRSd0SK5_sA"},"source":["## 4.1 Network Visualizer: Data (.csv) to DAGs of Dynamic Bayes Nets (.html)"]},{"cell_type":"markdown","metadata":{"id":"GJonCk9roi82"},"source":["### 4.1.1 Visualize the Network\n","Visualize the network (PDF) using matplotlib and networkx."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":169,"status":"error","timestamp":1743096338734,"user":{"displayName":"Singularity Smith","userId":"08757842931667367012"},"user_tz":360},"id":"Ax_1QJ6aobs1","outputId":"24ed6d48-23c9-4f35-df3d-36689a8d9522"},"outputs":[{"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-a7746b04165e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert pgmpy DAG to a NetworkX graph for visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnx_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnx_pydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraphviz_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx_dag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["# Convert pgmpy DAG to a NetworkX graph for visualization\n","nx_graph = nx.DiGraph(model.edges())\n","\n","pos = nx.nx_pydot.graphviz_layout(nx_dag, prog='dot')\n","\n","\n","\n","# Plot the graph\n","plt.figure(figsize=(10, 7))\n","nx.draw(nx_graph, with_labels=True, node_size=2000, node_color='lightblue', font_size=10, font_weight='bold')\n","plt.title(\"DAG Visualization of Bayesian Network\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"1pZtEqt5n2BE"},"source":["### 4.1.2 Display Graph in Colab as dynamic HTML"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"executionInfo":{"elapsed":20,"status":"error","timestamp":1743096127864,"user":{"displayName":"Singularity Smith","userId":"08757842931667367012"},"user_tz":360},"id":"TEwqOjGrn8f5","outputId":"465123e7-7b0b-480e-f293-9da8bab86dbd"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'pyvis'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-9c8fba1d10d0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create and configure the graph with Pyvis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyvis'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["from pyvis.network import Network\n","import networkx as nx\n","from IPython.display import HTML\n","\n","# Create and configure the graph with Pyvis\n","nx_graph = nx.DiGraph(filtered_edges)\n","net = Network(notebook=True, directed=True, cdn_resources=\"in_line\")\n","net.from_nx(nx_graph)\n","net.force_atlas_2based(gravity=-50)\n","net.show_buttons(filter_=['physics'])\n","\n","# Save the HTML to a file\n","net.save_graph(\"interactive_dag.html\")\n","\n","# Read the HTML file contents and embed it directly\n","with open(\"interactive_dag.html\", \"r\") as f:\n","    html_content = f.read()\n","\n","# Display the graph as HTML\n","HTML(html_content)"]},{"cell_type":"markdown","metadata":{"id":"LHQm7ydMmPhN"},"source":["# 5.0 Archive_version_histories New section"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ipmcopCbHFVt"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1mm2zLqnndeG"},"outputs":[],"source":["# function divided into several sub functions, to better handle, added functionality to add metadata\n","# in progress!\n","\n","def parse_markdown_hierarchy(markdown_text):\n","    \"\"\"Main function to parse markdown hierarchy into a DataFrame\"\"\"\n","\n","    # Remove comments\n","    clean_text = remove_comments(markdown_text)\n","\n","    # Extract all titles with their descriptions and indentation levels\n","    titles_info = extract_titles_info(clean_text)\n","\n","    # Establish parent-child relationships\n","    titles_with_relations = establish_relationships(titles_info, clean_text)\n","\n","    # Convert to DataFrame\n","    df = convert_to_dataframe(titles_with_relations)\n","\n","    # Add No_Parent and No_Children columns\n","    df = add_no_parent_no_child_columns_to_df(df)\n","\n","    return df\n","\n","def remove_comments(markdown_text):\n","    \"\"\"Remove comment blocks from markdown text\"\"\"\n","    return re.sub(r'/\\*.*?\\*/', '', markdown_text, flags=re.DOTALL)\n","\n","def extract_titles_info(text):\n","    \"\"\"Extract titles with their descriptions and indentation levels\"\"\"\n","    lines = text.split('\\n')\n","    print(lines)\n","    titles_info = {}\n","\n","    for line in lines:\n","        print(line)\n","        if not line.strip():\n","            continue\n","\n","        title_match = re.search(r'[<\\[](.+?)[>\\]]', line)\n","        if not title_match:\n","            continue\n","\n","        title = title_match.group(1)\n","\n","        # Extract description and metadata\n","        title_pattern_in_line = r'[<\\[]' + re.escape(title) + r'[>\\]]:'\n","        description_match = re.search(title_pattern_in_line + r'\\s*(.*)', line)\n","\n","        if description_match:\n","            full_text = description_match.group(1).strip()\n","\n","            # Check if description contains a \"{\" to not include metadata in description\n","            if \"{\" in full_text:\n","                # Split at the first \"{\"\n","                split_index = full_text.find(\"{\")\n","                description = full_text[:split_index].strip()\n","                metadata = full_text[split_index:].strip()\n","            else:\n","                # Keep the entire description and no metadata\n","                description = full_text\n","                metadata = ''\n","        else:\n","            description = ''\n","\n","        indentation = 0\n","        if '+' in line:\n","            symbol_index = line.find('+')\n","            # Count spaces before the '+' symbol\n","            i = symbol_index - 1\n","            while i >= 0 and line[i] == ' ':\n","                indentation += 1\n","                i -= 1\n","        elif '-' in line:\n","            symbol_index = line.find('-')\n","            # Count spaces before the '-' symbol\n","            i = symbol_index - 1\n","            while i >= 0 and line[i] == ' ':\n","                indentation += 1\n","                i -= 1\n","        if indentation != 0:\n","            indentation = indentation-1\n","        # If neither symbol exists, indentation remains 0\n","\n","        if title in titles_info:\n","            # Only update description if it's currently empty and we found a new one\n","            if not titles_info[title]['description'] and description:\n","                titles_info[title]['description'] = description\n","            # We might also need to update indentation if this is another occurrence\n","            if '+' in line and indentation > titles_info[title]['indentation']:\n","                titles_info[title]['indentation'] = indentation\n","        else:\n","            # First time seeing this title, create a new entry\n","            titles_info[title] = {\n","                'description': description,\n","                'indentation': indentation,\n","                'parents': [],\n","                'children': [],\n","                'metadata': metadata\n","            }\n","\n","    print(titles_info)\n","    return titles_info\n","\n","def establish_relationships(titles_info, text):\n","    \"\"\"Establish parent-child relationships between titles\"\"\"\n","    lines = text.split('\\n')\n","\n","    # Dictionary to store line numbers for each title\n","    title_lines = {}\n","\n","    # Record line number for each title\n","    line_number = 0\n","    for line in lines:\n","        if not line.strip():\n","            line_number += 1\n","            continue\n","\n","        title_match = re.search(r'[<\\[](.+?)[>\\]]', line)\n","        if not title_match:\n","            line_number += 1\n","            continue\n","\n","        title = title_match.group(1)\n","        title_lines[title] = line_number\n","        line_number += 1\n","\n","    # Sort titles by line number for sequential processing\n","    sorted_titles = sorted(titles_info.keys(), key=lambda t: title_lines.get(t, float('inf')))\n","\n","    print(\"Sorted titles:\")\n","    for title in sorted_titles:\n","        print(f\"{title} - Line: {title_lines.get(title, 'Unknown')} - Indent: {titles_info[title]['indentation']}\")\n","\n","    # Process titles in the order they appear\n","    for i, title in enumerate(sorted_titles):\n","        current_indent = titles_info[title]['indentation']\n","\n","        print(f\"\\nProcessing: {title} (indent: {current_indent})\")\n","\n","        # For non-indented titles (main titles)\n","        if current_indent == 0:\n","            print(\"  This is a main title, looking for parents...\")\n","            # Look ahead for potential parents\n","            for j in range(i+1, len(sorted_titles)):\n","                next_title = sorted_titles[j]\n","                next_indent = titles_info[next_title]['indentation']\n","\n","                print(f\"    Checking {next_title} (indent: {next_indent})\")\n","\n","                # If we find another main title, stop looking\n","                if next_indent == 0:\n","                    print(f\"    Found another main title, stopping parent search\")\n","                    break\n","\n","                # If this is a direct parent (first level of indentation)\n","                if next_indent == 1:\n","                    print(f\"    Found parent: {next_title}\")\n","                    if next_title not in titles_info[title]['parents']:\n","                        titles_info[title]['parents'].append(next_title)\n","                    if title not in titles_info[next_title]['children']:\n","                        titles_info[next_title]['children'].append(title)\n","\n","        # For indented titles\n","        else:\n","            print(\"  This is an indented title, looking for children...\")\n","            # Look for the most recent title with one less indentation\n","            for j in range(i-1, -1, -1):\n","                prev_title = sorted_titles[j]\n","                prev_indent = titles_info[prev_title]['indentation']\n","\n","                print(f\"    Checking {prev_title} (indent: {prev_indent})\")\n","\n","                # If we find a title with exactly one less indentation\n","                if prev_indent == current_indent - 1:\n","                    print(f\"    Found child: {prev_title}\")\n","                    if title not in titles_info[prev_title]['parents']:\n","                        titles_info[prev_title]['parents'].append(title)\n","                    if prev_title not in titles_info[title]['children']:\n","                        titles_info[title]['children'].append(prev_title)\n","                    break\n","\n","    print(\"\\nFinal relationships:\")\n","    for title, info in titles_info.items():\n","        print(f\"{title} - Parents: {info['parents']} - Children: {info['children']}\")\n","\n","    return titles_info\n","\n","def convert_to_dataframe(titles_info):\n","    \"\"\"Convert the titles information dictionary to a pandas DataFrame\"\"\"\n","    df = pd.DataFrame(columns=['Title', 'Description', 'Parents', 'Children', 'instantiations', 'priors', 'posteriors'])\n","\n","    for title, info in titles_info.items():\n","        # Parse the metadata JSON string into a Python dictionary\n","        if 'metadata' in info and info['metadata']:\n","            try:\n","                jsonMetadata = json.loads(info['metadata'])\n","\n","                # Create the row dictionary with basic fields\n","                row = {\n","                    'Title': title,\n","                    'Description': info.get('description', ''),\n","                    'Parents': info.get('parents', []),\n","                    'Children': info.get('children', []),\n","                    # Extract specific metadata fields, defaulting to empty if not present\n","                    'instantiations': jsonMetadata.get('instantiations', []),\n","                    'priors': jsonMetadata.get('priors', {}),\n","                    'posteriors': jsonMetadata.get('posteriors', {})\n","                }\n","            except json.JSONDecodeError:\n","                # Handle case where metadata isn't valid JSON\n","                row = {\n","                    'Title': title,\n","                    'Description': info.get('description', ''),\n","                    'Parents': info.get('parents', []),\n","                    'Children': info.get('children', []),\n","                    'instantiations': [],\n","                    'priors': {},\n","                    'posteriors': {}\n","                }\n","        else:\n","            # Handle case where metadata field doesn't exist\n","            row = {\n","                'Title': title,\n","                'Description': info.get('description', ''),\n","                'Parents': info.get('parents', []),\n","                'Children': info.get('children', []),\n","                'instantiations': [],\n","                'priors': {},\n","                'posteriors': {}\n","            }\n","\n","        # Add the row to the DataFrame\n","        df.loc[len(df)] = row\n","\n","    return df\n","\n","def add_no_parent_no_child_columns_to_df(dataframe):\n","    \"\"\"Add No_Parent and No_Children boolean columns to the DataFrame\"\"\"\n","    no_parent = []\n","    no_children = []\n","\n","    for _, row in dataframe.iterrows():\n","        no_parent.append(not row['Parents'])\n","        no_children.append(not row['Children'])\n","\n","    dataframe['No_Parent'] = no_parent\n","    dataframe['No_Children'] = no_children\n","\n","    return dataframe"]},{"cell_type":"markdown","metadata":{"id":"kjbIj19epbrF"},"source":["# 6.0 Save Outputs\n"]},{"cell_type":"markdown","metadata":{"id":"0QqlN6dYpm4s"},"source":["## Convert ipynb to HTML in Colab\n","\n","Instruction:\n","\n","Download the ipynb, which you want to convert, on your local computer.\n","Run the code below to upload the ipynb.\n","\n","The html version will be downloaded automatically on your local machine.\n","Enjoy it!"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"dWiHUcgWpuvx","outputId":"eab45923-f47f-4831-8e6f-594405065728","executionInfo":{"status":"ok","timestamp":1743457336615,"user_tz":360,"elapsed":30015,"user":{"displayName":"Singularity Smith","userId":"08757842931667367012"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-b6a1e23d-de39-45f4-8f7a-d0cefb02a746\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-b6a1e23d-de39-45f4-8f7a-d0cefb02a746\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving AMTAIR_Prototype_0_1.2.ipynb to AMTAIR_Prototype_0_1.2.ipynb\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_39ee8571-3d4d-4ec8-864d-85d41b19389f\", \"AMTAIR_Prototype_0_1.2.html\", 458977)"]},"metadata":{}}],"source":["#@title Convert ipynb to HTML in Colab\n","# Upload ipynb\n","from google.colab import files\n","f = files.upload()\n","\n","# Convert ipynb to html\n","import subprocess\n","file0 = list(f.keys())[0]\n","_ = subprocess.run([\"pip\", \"install\", \"nbconvert\"])\n","_ = subprocess.run([\"jupyter\", \"nbconvert\", file0, \"--to\", \"html\"])\n","\n","# download the html\n","files.download(file0[:-5]+\"html\")\n"]}],"metadata":{"colab":{"collapsed_sections":["57YvCx9dom5J","ZWx7CRfHn8Va","mbRSd0SK5_sA"],"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}