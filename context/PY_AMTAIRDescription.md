# AMTAIR Project Description

# Tl;dr

The AMTAIR project addresses the critical coordination failure in AI governance by developing computational tools that automate the extraction of probabilistic world models from AI safety literature using frontier language models. Starting with a World Model Extraction and Analysis Tool and building toward a comprehensive framework for a grand strategy for AI safety, we're creating an end-to-end pipeline that integrates dynamic Bayesian networks with live forecasting data to quantify risks, evaluate policy impacts across diverse scenarios, and generate adaptive strategic recommendations. The system makes implicit models explicit, facilitates cross-domain coordination, and provides policymakers with actionable insights based on formalized causal reasoning. Our team combines expertise in Bayesian modeling and AI governance—precisely the interdisciplinary skills needed to develop this strategic "operating system" for aligning disparate efforts before the window for establishing effective governance closes as AI capabilities continue to accelerate.

## Previous Description:

We are working on scaling up the research work done by the team of the MTAIR (Modeling Transformative AI Risks) Project.   
Our goal is to use frontier LLM's to automate the extraction of "world models" from writing in the AI Safety & Governance research community (e.g. papers, articles or other media used to convey more complex arguments).  
We are using modeling software such as Analytics or Squiggle / Guesstimate to represent world models formally which enables us to automate the required steps with today's frontier LLMs. We are working on the scaffolding and prompting required for the necessary steps, e.g. argument mapping, quantification, formatting, testing etc. but expect diminishing reliance on the scaffolding as more capable models are released.   
We also intend to connect the model representations directly with the APIs of the buoying prediction platforms in order to benefit from the rapidly increasing quality and quantity of forecasts.  
This research proposes the development of a World Model Extraction and Analysis Tool and a scalable AI Grand Strategy framework to address existential risks from AI. The project combines Bayesian networks, DAGs, and live forecasting data to create dynamic, adaptive models for strategic decision-making. Building on the MTAIR framework, the research aims to integrate expert input, automate updates using LLMs, and formalize world models within the AI safety community. The resulting tools will help policymakers and researchers develop robust strategies to mitigate AI risks and ensure long-term human survival.

---

## **(Half-Page) Executive Summary**

# **AMTAIR: Automating Transformative AI Risk Modeling**

The Automating Transformative AI Risk Modeling (AMTAIR) project addresses a critical coordination failure in AI governance: despite unprecedented investment in AI safety, we lack the strategic "operating system" needed to align disparate efforts across technical, governance, and policy domains. We are working on scaling up the research work done by the team of the original MTAIR Project. 

We're developing computational tools—starting with a World Model Extraction and Analysis Tool—that automate the extraction of probabilistic world models from AI safety literature using frontier language models. These tools will form the foundation for a comprehensive, adaptive AI Grand Strategy framework.

Our system architecture implements an end-to-end pipeline from unstructured text to actionable insights through five components:

1. Text ingestion and preprocessing using ArgDown derived syntax  
2. LLM-powered extraction of world models, argument structures and probability distributions  
3. Bayesian network construction with directed acyclic graphs  
4. Live forecasting integration from prediction markets  
5. Interactive visualization and analysis interface

Key deliverables include a World Model Extraction and Analysis Tool for quantifying existential risks, an AI Grand Strategy framework for coordinating responses across domains, an AGI Doomsday Clock for public communication, and cross-model comparison tools for identifying agreements and cruxes of disagreement.

The project creates impact by improving research directions, enhancing decision-making for policymakers, and facilitating coordination across domains:

**Enhancing Decision-Making for Policymakers**: Our tools provide structured frameworks for assessing policy impacts across multiple scenarios, explicit quantification of uncertainties, comparison of expert perspectives, and identification of robust interventions.

**Facilitating Cross-Domain Coordination**: Our tools create a shared epistemic infrastructure that facilitates communication between technical and governance researchers, alignment of strategies across organizations, and representation of diverse philosophical perspectives within a unified system.

Our 12-month implementation plan follows a phased approach with clear milestones, risk mitigation strategies, and early stopping points that would still yield valuable outputs. The core team combines expertise in Bayesian modeling, AI governance, strategic planning and community engagement—precisely the interdisciplinary skills needed for this challenge.

The window for establishing effective governance is narrowing as AI capabilities accelerate. AMTAIR creates the epistemic infrastructure necessary for coordinating humanity's response to what may be its most consequential technological development.

## 

## ---

## **2-Page Overview**

# **AMTAIR: Automating Transformative AI Risk Modeling**

## **The Coordination Crisis in AI Governance**

We face an urgent paradox in AI governance: unprecedented investment in safety research coexists alongside a fundamental coordination failure. Despite millions in funding and growing awareness, we lack the strategic "operating system" needed to align disparate efforts as AI capabilities advance at an accelerating pace.

This coordination failure creates exponential risk. When organizations function as independent processors without shared protocols, we generate duplicative work, leave critical gaps unaddressed, and create inconsistent approaches to interdependent problems. Technical alignment researchers develop solutions without implementation pathways; policy specialists craft frameworks without technical grounding; ethicists articulate principles without operational specificity.

## **The AMTAIR Solution**

The Automating Transformative AI Risk Modeling (AMTAIR) project addresses this critical coordination failure by developing a suite of computational tools that automate the extraction of probabilistic world models from AI safety literature using frontier language models. These tools will form the foundation for a comprehensive, adaptive AI Grand Strategy that remains robust across various futures.

Our system architecture implements an end-to-end pipeline:

1. **Text Ingestion and Preprocessing**: Source documents enter the system, undergo preprocessing, and are stored with citation information preserved.  
2. **LLM-Powered Extraction**: Documents are analyzed using a two-stage process that identifies key variables and relationships, represented in an intermediate ArgDown format.  
3. **Bayesian Network Construction**: ArgDown representations are transformed into formal Bayesian networks with nodes, edges, and conditional probability tables.  
4. **Forecasting Integration**: External forecasting data is ingested through APIs and mapped to corresponding variables in the Bayesian network.  
5. **Interactive Analysis Interface**: Users interact through a web-based interface featuring visualization components and analysis tools.

This approach enables automated extraction of world models from research papers, integration with live forecasting data, and robust evaluation of policy impacts across different scenarios.

## **Key Deliverables**

1. **World Model Extraction and Analysis Tool**: A tool that quantifies existential risk from AI systems, with customizable inputs, visual representation of causal networks, and sensitivity analysis capabilities.  
2. **AGI Doomsday Clock**: A visual representation of AI risk levels for broader audiences, with transparent update mechanisms and educational components.  
3. **Cross-Model Comparison Tools**: Specialized tools for identifying agreement and disagreement between different world models, supporting consensus-building while preserving important differences.  
4. **AI Grand Strategy Framework**: A comprehensive framework that formalizes diverse worldviews, identifies robust strategies across multiple scenarios, and includes explicit adaptation mechanisms.

## **Impact Pathways**

AMTAIR creates impact through several complementary pathways:

**Improving Research Directions**: By making implicit models explicit and identifying key uncertainties, our tools help researchers prioritize efforts more effectively.

**Enhancing Decision-Making for Policymakers**: Our tools provide structured frameworks for assessing policy impacts across multiple scenarios, explicit quantification of uncertainties, comparison of expert perspectives, and identification of robust interventions.

**Facilitating Cross-Domain Coordination**: Our tools create a shared epistemic infrastructure that facilitates communication between technical and governance researchers, alignment of strategies across organizations, and representation of diverse philosophical perspectives within a unified system.

## **Implementation Timeline**

Our 12-month implementation plan follows a phased approach:

**Phase 1 (Months 1-4)**: Foundation Development

* Literature review and stakeholder interviews  
* Technical infrastructure setup  
* **World Model Extraction and Analysis Tool** prototype development  
* Initial extraction experiments

**Phase 2 (Months 5-8)**: Core Tool Development

* Expert feedback incorporation  
* Worldview extraction system development  
* Prediction market integration  
* Policy impact evaluation module

**Phase 3 (Months 9-12)**: Scaling and Strategy Development

* Public beta release and community testing  
* Automated extraction at scale  
* Strategic pattern identification  
* AI Grand Strategy framework development

## **The Team**

Our core team brings together precisely the interdisciplinary expertise needed:

**Valentin Jakob Meyer**: Expertise in Bayesian networks, probabilistic modeling, epistemology, and forecasting theory, with extensive experience implementing and analyzing Bayesian networks for complex decision problems.

**Coleman Snell**: Expertise in AI governance, ethics, strategic planning, and community building, with research experience at AI:FAR, University of Chicago's X Risk Lab, and Cambridge's Center for the Study of Existential Risk.

Our complementary backgrounds create a uniquely qualified team that bridges technical modeling and governance domains—a rare combination essential for this project. We're supported by an advisory network of technical, domain, and implementation experts, and have established collaborations with the MTAIR team, forecasting platforms, AI safety research organizations, and academic institutions.

## **Why Now?**

This project represents a response to a unique confluence of developments:

1. **Accelerating AI capabilities** create urgent necessity as the window for establishing effective governance narrows  
2. **Technical breakthrough**s in LLMs, prompt engineering, and Bayesian network tools make our approach feasible for the first time  
3. **Evolving governance landscape** presents a critical opportunity to inform developing frameworks  
4. **Growing recognition** of the coordination gap creates receptiveness for strategic infrastructure

## **Conclusion**

The coordination gap in AI governance is real, growing, and dangerous—but not insurmountable. AMTAIR addresses this gap by creating the epistemic infrastructure necessary for global coordination on what may be humanity's most consequential technical challenge. By developing the tools proposed in this project, we significantly improve our prospects of navigating the transition to advanced AI systems safely and beneficially.

## 

## ---