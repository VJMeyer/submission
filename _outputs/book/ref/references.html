<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.29">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>1&nbsp; References (.md) – Automating the Modelling of Transformative Artificial Intelligence Risks</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/Outlines/Outline_13.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-0815c480559380816a4d1ea211a47e91.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-485d01fc63b59abcd3ee1bf1e8e2748d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../ref/references.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">References (.md)</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Automating the Modelling of Transformative Artificial Intelligence Risks</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/VJMeyer/submission" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="../Automating-the-Modelling-of-Transformative-Artificial-Intelligence-Risks.pdf">
              <i class="bi bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="../Automating-the-Modelling-of-Transformative-Artificial-Intelligence-Risks.epub">
              <i class="bi bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-1" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-1">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/Outlines/Outline_13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Automating the Modeling of Transformative Artificial Intelligence Risks (AMTAIR)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ref/references.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">References (.md)</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#error-watch" id="toc-error-watch" class="nav-link active" data-scroll-target="#error-watch"><span class="header-section-number">1.1</span> Error Watch</a>
  <ul>
  <li><a href="#catch-all-potential-hallucinations" id="toc-catch-all-potential-hallucinations" class="nav-link" data-scroll-target="#catch-all-potential-hallucinations"><span class="header-section-number">1.1.1</span> Catch ALL Potential Hallucinations</a></li>
  </ul></li>
  <li><a href="#figure-inventory-and-tracking" id="toc-figure-inventory-and-tracking" class="nav-link" data-scroll-target="#figure-inventory-and-tracking"><span class="header-section-number">1.2</span> Figure Inventory and Tracking</a>
  <ul>
  <li><a href="#chapter-1" id="toc-chapter-1" class="nav-link" data-scroll-target="#chapter-1"><span class="header-section-number">1.2.1</span> Chapter 1</a></li>
  <li><a href="#chapter-2" id="toc-chapter-2" class="nav-link" data-scroll-target="#chapter-2"><span class="header-section-number">1.2.2</span> Chapter 2</a></li>
  </ul></li>
  <li><a href="#pending-figures" id="toc-pending-figures" class="nav-link" data-scroll-target="#pending-figures"><span class="header-section-number">1.3</span> Pending Figures</a>
  <ul>
  <li><a href="#master-citation-registry" id="toc-master-citation-registry" class="nav-link" data-scroll-target="#master-citation-registry"><span class="header-section-number">1.3.1</span> Master Citation Registry</a></li>
  <li><a href="#figure-tracking" id="toc-figure-tracking" class="nav-link" data-scroll-target="#figure-tracking"><span class="header-section-number">1.3.2</span> Figure tracking</a></li>
  </ul></li>
  <li><a href="#bibliography" id="toc-bibliography" class="nav-link" data-scroll-target="#bibliography">Bibliography</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/VJMeyer/submission/edit/main/ref/references.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div><div class="quarto-code-links"><h2>Code Links</h2><ul><li><a href="https://colab.research.google.com/github/VJMeyer/submission/blob/main/AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb"><i class="bi bi-file-code"></i>Colab Notebook (Manual Link in .yml)</a></li><li><a href="https://github.com/VJMeyer/submission"><i class="bi bi-github"></i>GitHub Repository</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">References (.md)</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="error-watch" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="error-watch"><span class="header-section-number">1.1</span> Error Watch</h2>
<section id="catch-all-potential-hallucinations" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1" class="anchored" data-anchor-id="catch-all-potential-hallucinations"><span class="header-section-number">1.1.1</span> Catch ALL Potential Hallucinations</h3>
<p><code>&lt;!-- [ ] Collect all errors and hallucinations here to be able to reference against them later and ensure none remain throught text --&gt;</code></p>
<p><code>&lt;!-- [ ] Keep track of all hallucinations that have been found here: --&gt;</code></p>
<ol type="1">
<li><p><strong>Validation Metrics</strong>: Claims of “85%+ accuracy for structural extraction” and “73% for probability capture” appear precise for what seems to be a prototype system. These need careful verification or qualification.</p></li>
<li><p><strong>Pilot Study Results</strong>: “40% reduction in time to identify disagreements” and “60% improvement in agreement about disagreement” lack citations and seem surprisingly specific.</p></li>
<li><p><strong>Red-teaming Quantification</strong>: “34% anchoring bias effect” and other precise percentages from adversarial testing need support or qualification as estimates.</p></li>
<li><p><strong>Prediction Market Integration</strong>: Some passages imply deeper integration than the “future work” status indicated elsewhere.</p></li>
</ol>
<p><code>&lt;!-- [ ] Make sure all hallucinations have been removed --&gt;</code></p>
</section>
</section>
<section id="figure-inventory-and-tracking" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="figure-inventory-and-tracking"><span class="header-section-number">1.2</span> Figure Inventory and Tracking</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">## Master Figure Registry {.unnumbered .unlisted}</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- FIGURE INVENTORY --&gt;</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Last updated: 2024-02-15 --&gt;</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">## Implemented Figures</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">## Section to keep track of all Figures</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="in">`&lt;!-- [ ] ALWAYS include the "inclusions" of all figures/graphics below --&gt;`</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="in">`&lt;!-- [ ] ALWAYS keep the #fig-KEYS up-to-date --&gt;`</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="in">```markdown</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>{{</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">![Example Caption/Title 4</span><span class="co">](/images/cover.png)</span>{</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    #fig-Unique_identifier_for_crossreferencing</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    fig-scap="Short caption 4 list of figures as seen in LoF"</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    fig-alt="Detailed alt text that describes the image content, type, purpose, and meaning.</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>            <span class="ot">[CHART TYPE]: </span><span class="co">[</span><span class="ot">Short description</span><span class="co">]</span>.</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>                DATA: <span class="co">[</span><span class="ot">What data is shown, x/y axes</span><span class="co">]</span>.</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>                PURPOSE: <span class="co">[</span><span class="ot">Why it's included, what to look for</span><span class="co">]</span>.</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>                DETAILS: <span class="co">[</span><span class="ot">Longer description of patterns, anomalies, or key insights</span><span class="co">]</span>.</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>                SOURCE: Data from <span class="co">[</span><span class="ot">source name/year and url/link</span><span class="co">]</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>            "</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    fig-align="left"</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    width="30%"</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    }](https://github.com/VJMeyer/submission)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>}}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="chapter-1" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="chapter-1"><span class="header-section-number">1.2.1</span> Chapter 1</h3>
<ul class="task-list">
<li><label><input type="checkbox" checked="">{#fig-overview}: System overview diagram</label>
<ul>
<li>File: images/system-overview.png</li>
<li>Source: Created by author using Draw.io</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb2"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>{{</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">![Example Caption/Title 4</span><span class="co">](/images/cover.png)</span>{</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    #fig-Unique_identifier_for_crossreferencing</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    fig-scap="Short caption 4 list of figures as seen in LoF"</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    fig-alt="Detailed alt text that describes the image content, type, purpose, and meaning.</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>            <span class="ot">[CHART TYPE]: </span><span class="co">[</span><span class="ot">Short description</span><span class="co">]</span>.</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>                DATA: <span class="co">[</span><span class="ot">What data is shown, x/y axes</span><span class="co">]</span>.</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>                PURPOSE: <span class="co">[</span><span class="ot">Why it's included, what to look for</span><span class="co">]</span>.</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>                DETAILS: <span class="co">[</span><span class="ot">Longer description of patterns, anomalies, or key insights</span><span class="co">]</span>.</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>                SOURCE: Data from <span class="co">[</span><span class="ot">source name/year and url/link</span><span class="co">]</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>            "</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    fig-align="left"</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    width="30%"</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    }](https://github.com/VJMeyer/submission)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>}}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="chapter-2" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="chapter-2"><span class="header-section-number">1.2.2</span> Chapter 2</h3>
<ul class="task-list">
<li><label><input type="checkbox" checked="">{#fig-methodology}: Research methodology flowchart</label>
<ul>
<li>File: images/methodology-flow.svg</li>
<li>Source: Author original</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb3"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>{{</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">![Example Caption/Title 4</span><span class="co">](/images/cover.png)</span>{</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    #fig-Unique_identifier_for_crossreferencing</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    fig-scap="Short caption 4 list of figures as seen in LoF"</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    fig-alt="Detailed alt text that describes the image content, type, purpose, and meaning.</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>            <span class="ot">[CHART TYPE]: </span><span class="co">[</span><span class="ot">Short description</span><span class="co">]</span>.</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>                DATA: <span class="co">[</span><span class="ot">What data is shown, x/y axes</span><span class="co">]</span>.</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>                PURPOSE: <span class="co">[</span><span class="ot">Why it's included, what to look for</span><span class="co">]</span>.</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>                DETAILS: <span class="co">[</span><span class="ot">Longer description of patterns, anomalies, or key insights</span><span class="co">]</span>.</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>                SOURCE: Data from <span class="co">[</span><span class="ot">source name/year and url/link</span><span class="co">]</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>            "</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    fig-align="left"</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    width="30%"</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    }](https://github.com/VJMeyer/submission)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>}}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="pending-figures" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="pending-figures"><span class="header-section-number">1.3</span> Pending Figures</h2>
<div class="sourceCode" id="cb4"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">### High Priority</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> {#fig-results-chart}: Main results visualization</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Status: Data ready, needs visualization</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>{{</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">![Example Caption/Title 4</span><span class="co">](/images/cover.png)</span>{</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    #fig-Unique_identifier_for_crossreferencing</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    fig-scap="Short caption 4 list of figures as seen in LoF"</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    fig-alt="Detailed alt text that describes the image content, type, purpose, and meaning.</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>            <span class="ot">[CHART TYPE]: </span><span class="co">[</span><span class="ot">Short description</span><span class="co">]</span>.</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>                DATA: <span class="co">[</span><span class="ot">What data is shown, x/y axes</span><span class="co">]</span>.</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>                PURPOSE: <span class="co">[</span><span class="ot">Why it's included, what to look for</span><span class="co">]</span>.</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>                DETAILS: <span class="co">[</span><span class="ot">Longer description of patterns, anomalies, or key insights</span><span class="co">]</span>.</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>                SOURCE: Data from <span class="co">[</span><span class="ot">source name/year and url/link</span><span class="co">]</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>            "</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    fig-align="left"</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    width="30%"</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    }](https://github.com/VJMeyer/submission)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>}}</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="fu">### Medium Priority</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> {#fig-architecture}: System architecture diagram</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Status: Sketch complete, needs professional rendering</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>{{</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">![Example Caption/Title 4</span><span class="co">](/images/cover.png)</span>{</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    #fig-Unique_identifier_for_crossreferencing</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>    fig-scap="Short caption 4 list of figures as seen in LoF"</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>    fig-alt="Detailed alt text that describes the image content, type, purpose, and meaning.</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>            <span class="ot">[CHART TYPE]: </span><span class="co">[</span><span class="ot">Short description</span><span class="co">]</span>.</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>                DATA: <span class="co">[</span><span class="ot">What data is shown, x/y axes</span><span class="co">]</span>.</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>                PURPOSE: <span class="co">[</span><span class="ot">Why it's included, what to look for</span><span class="co">]</span>.</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>                DETAILS: <span class="co">[</span><span class="ot">Longer description of patterns, anomalies, or key insights</span><span class="co">]</span>.</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>                SOURCE: Data from <span class="co">[</span><span class="ot">source name/year and url/link</span><span class="co">]</span></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>            "</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>    fig-align="left"</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>    width="30%"</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>    }](https://github.com/VJMeyer/submission)</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>}}</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="master-citation-registry" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="master-citation-registry"><span class="header-section-number">1.3.1</span> Master Citation Registry</h3>
<div class="sourceCode" id="cb5"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">## BibTeX of Main Citations Included</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- [ ] Add all the main literature / citations / references here (makes it easy to verify correct key etc. while writing) --&gt;</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- [ ] Keep 'References.md' updated with/from ref/MAref.bib --&gt;</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- [ ] Remove/hide 'References.md' before final publication --&gt;</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="fu">## Update in ref/MAref.bib</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="fu">## Core Citations (Must Have)</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="fu">### Foundational Works</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[x]</span> @carlsmith2021 - Power-seeking AI framework</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Chapter usage: 1, 2, 4</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Key concepts: Six premises, existential risk</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Notes: Central to thesis argument</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[x]</span> @bostrom2014 - Superintelligence paths</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Chapter usage: 1, 2, 3, 5</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Key concepts: Orthogonality, convergence</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Notes: Historical foundation</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>@article{bostrom2012,</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>  title = {The {{Superintelligent Will}}: {{Motivation}} and {{Instrumental Rationality}} in {{Advanced Artificial Agents}}},</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>  author = {Bostrom, Nick},</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>  date = {2012},</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>  journaltitle = {Minds and Machines},</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>  volume = {22},</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>  number = {2},</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>  pages = {71--85},</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>  publisher = {Kluwer Academic Publishers Norwell, MA, USA},</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>  doi = {10.1007/s11023-012-9281-3},</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>  url = {https://philpapers.org/rec/BOSTSW}</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>@book{bostrom2014,</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>  title = {Superintelligence: {{Paths}}, Strategies, Dangers},</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>  author = {Bostrom, Nick},</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>  date = {2014},</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>  publisher = {Oxford University Press},</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>  location = {Oxford},</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>  url = {https://scholar.dominican.edu/cynthia-stokes-brown-books-big-history/47},</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>  abstract = {The human brain has some capabilities that the brains of other animals lack. It is to these distinctive capabilities that our species owes its dominant position. Other animals have stronger muscles or sharper claws, but we have cleverer brains. If machine brains one day come to surpass human brains in general intelligence, then this new superintelligence could become very powerful. As the fate of the gorillas now depends more on us humans than on the gorillas themselves, so the fate of our species then would come to depend on the actions of the machine superintelligence. But we have one advantage: we get to make the first move. Will it be possible to construct a seed AI or otherwise to engineer initial conditions so as to make an intelligence explosion survivable? How could one achieve a controlled detonation? To get closer to an answer to this question, we must make our way through a fascinating landscape of topics and considerations. Read the book and learn about oracles, genies, singletons; about boxing methods, tripwires, and mind crime; about humanity's cosmic endowment and differential technological development; indirect normativity, instrumental convergence, whole brain emulation and technology couplings; Malthusian economics and dystopian evolution; artificial intelligence, and biological cognitive enhancement, and collective intelligence.},</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>  isbn = {978-0-19-967811-2}</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>@article{bostrom2016,</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>  title = {The {{Unilateralist}}’s {{Curse}} and the {{Case}} for a {{Principle}} of {{Conformity}}},</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>  author = {Bostrom, Nick and Douglas, Thomas and Sandberg, Anders},</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>  date = {2016},</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>  journaltitle = {Social Epistemology},</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>  volume = {30},</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>  number = {4},</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>  pages = {350--371},</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>  publisher = {Routledge, part of the Taylor <span class="sc">\&amp;</span> Francis Group},</span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>  doi = {10.1080/02691728.2015.1108373},</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>  url = {https://www.tandfonline.com/doi/full/10.1080/02691728.2015.1108373}</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>@article{bostrom2019,</span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>  title = {The Vulnerable World Hypothesis},</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>  author = {Bostrom, Nick},</span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>  date = {2019},</span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a>  journaltitle = {Global Policy},</span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a>  volume = {10},</span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a>  number = {4},</span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a>  pages = {455--476},</span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>  publisher = {Wiley Online Library},</span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a>  doi = {10.1111/1758-5899.12718}</span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a><span class="fu">## Pending Citations</span></span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a><span class="fu">### Need to Find</span></span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> FIND: @ai-governance-2024: "Recent survey on international AI governance frameworks"</span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>For: Chapter 3, Section 3.2</span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Search terms: AI governance, international coordination, 2024</span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Priority: High</span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a><span class="fu">### Need to Verify</span></span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> VERIFY: @prediction-markets-ai: "Tetlock et al on prediction markets for AI timelines"</span>
<span id="cb5-90"><a href="#cb5-90" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Current info: Possibly in Metaculus report 2023</span>
<span id="cb5-91"><a href="#cb5-91" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>For: Chapter 4, Section 4.3</span>
<span id="cb5-92"><a href="#cb5-92" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Priority: Medium</span>
<span id="cb5-93"><a href="#cb5-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-94"><a href="#cb5-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-95"><a href="#cb5-95" aria-hidden="true" tabindex="-1"></a><span class="fu">## Citation Health Check</span></span>
<span id="cb5-96"><a href="#cb5-96" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> All citations in .bib file</span>
<span id="cb5-97"><a href="#cb5-97" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> All .bib entries have DOIs/URLs</span>
<span id="cb5-98"><a href="#cb5-98" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> No duplicate entries</span>
<span id="cb5-99"><a href="#cb5-99" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> Consistent naming scheme</span>
<span id="cb5-100"><a href="#cb5-100" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> Recent sources included (2023-2024)</span>
<span id="cb5-101"><a href="#cb5-101" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<!-- If you want to include items in the bibliography without actually citing them in the body text, you can define a dummy nocite metadata field and put the citations there:
---
nocite: |
  @item1, @item2
---

@item3
 -->
<p><!-- ## Sidebars for comments {.sidebar}
Create Sidebars by applying the .sidebar attribute to a level 1 heading (for global sidebars) or level 2 heading (for page level sidebars). --></p>
</section>
<section id="figure-tracking" class="level3" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="figure-tracking"><span class="header-section-number">1.3.2</span> Figure tracking</h3>
<p><figure_syntax></figure_syntax></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">[</span><span class="ot">![Figure Caption for Display</span><span class="co">](/path/to/image.png)</span>{</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    #fig-unique-identifier</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    fig-scap="Short caption for list of figures"</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    fig-alt="Detailed description for accessibility.</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>            TYPE: <span class="co">[</span><span class="ot">Chart/Diagram/Photo/etc.</span><span class="co">]</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>            DATA: <span class="co">[</span><span class="ot">What data is shown, axes, units</span><span class="co">]</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>            PURPOSE: <span class="co">[</span><span class="ot">Why included, what to observe</span><span class="co">]</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>            DETAILS: <span class="co">[</span><span class="ot">Key patterns, insights, anomalies</span><span class="co">]</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>            SOURCE: <span class="co">[</span><span class="ot">Citation or data source</span><span class="co">]</span>"</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    fig-align="center"</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    width="80%"</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>  }](https://optional-link-url.com)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p></p>
<div class="sourceCode" id="cb7"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>from @metropolitansky2025</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">![Claimify claim-extraction stages</span><span class="co">](/images/claimify-stages.jpg)</span>{</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    #fig-claimify-stages</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    fig-scap="Claimify claim-extraction stages"</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    fig-alt="COMPOSITE FIGURE: table and process flow. TABLE: four-row, two-column table enumerates stages 1–4 of Claimify’s pipeline—Sentence splitting and context creation, Selection, Disambiguation, Decomposition—each with a plain-language description. FLOW-CHART: sequence of rectangles and diamond decision nodes shows per-sentence logic. Start node ‘Input question &amp; answer’ feeds into ‘Split into sentences &amp; create context’. Decision 1 asks if the sentence contains verifiable content; ‘No’ exits with red X ‘No verifiable claims’, ‘Yes’ advances. Decision 2 checks for irresolvable ambiguity; ‘Yes’ exits with red X ‘Cannot be disambiguated’, ‘No’ advances. Decision 3 asks if at least one claim is produced; ‘No’ exits with red X ‘No verifiable claims’, ‘Yes’ ends with green check ‘Extracted claims’. A dashed bracket labelled ‘Per sentence’ spans the decision chain. PURPOSE: illustrates Claimify’s staged filtering that aligns with AMTAIR’s need for clean, disambiguated claims before formal modelling. DATA: categorical process flow—no numeric axes. SOURCE: Adapted from Claimify documentation (2024, https://www.microsoft.com/en-us/research/blog/claimify-extracting-high-quality-claims-from-language-model-outputs/)."</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    fig-align="center"</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    width="100%"</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>}](https://www.microsoft.com/en-us/research/blog/claimify-extracting-high-quality-claims-from-language-model-outputs/)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>from @tetlock2022</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">![Conditional-tree AI-risk forecasts</span><span class="co">](/images/conditional_metaculus.jpg)</span>{</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    #fig-conditional_metaculus</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    fig-scap="Conditional-tree AI-risk forecasts"</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    fig-alt="SCREENSHOT of a forecasting-platform interface titled ‘Series Contents’. A search bar and filter chips sit above five forecast cards: 1) ‘If, before 2050, AI kills more than 1 million people, will the policy response be insufficient?’ with a 75 percent gauge (green, arrow up 8 percent). 2) ‘Before 2050, will an AI system be shut down due to exhibiting power-seeking behavior?’ at 95 percent (arrow down 2 percent). 3) ‘Before 2100, will AI cause the human population to fall below 5000 individuals?’ at 4 percent. 4) ‘Before 2030, will there be an AI-caused administrative disempowerment?’ at 20 percent. 5) ‘Between 2023 and 2030, will revenue from deep learning double every two years?’ at 80 percent. Beneath several cards, grey CONDITION boxes branch to green bars labelled ‘CTs AI Extinction Before 2100’ with different probabilities for IF YES and IF NO scenarios (e.g. 26 % vs 37 %). Each question lists forecaster counts, closing dates (2030 or 2050), and the tag ‘Conditional Trees: AI Risk’. A footer card introduces the series report. CHART TYPE: mixed UI elements—gauge dials and horizontal bars—displaying probabilities and conditional probabilities. DATA: probabilities (% chances) for base and conditional events; no axes. PURPOSE: demonstrates how crowd-forecasting encodes marginal and counterfactual probabilities suitable as inputs for AMTAIR Bayesian-network nodes. DETAILS: notable high probability for power-seeking AI shutdown, low probability for population collapse, and large shifts in extinction risk under certain conditions. SOURCE: Forecasting Research Institute conditional-tree series, @tetlock2022."</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    fig-align="center"</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>    width="100%"</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>}](https://www.metaculus.com/tournament/3508/)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>from @gruetzemacher2022</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">![Bayes-net pruning → crux extraction → re-expansion</span><span class="co">](/images/bns_and_conditional_trees.jpg)</span>{</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>    #fig-bayesnet-crux-flow</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>    fig-scap="Bayes-net pruning → crux extraction → re-expansion"</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>    fig-alt="THREE-PANEL DIAGRAM. Panel A (upper left) titled ‘Initial Bayes Net—Pruning Least Relevant Nodes’ shows eleven circular nodes connected by arrows inside a rounded rectangle. Solid circles remain; dashed or dotted ones are pruned. Arrows converge on a solid node labelled ‘AI causes human extinction’. Panel B (upper right) titled ‘Two Sets of Crux Events from Bayes Nets Isolated as Conditional Trees’ shows two short vertical chains of dotted or dashed circles. Chain 1: ‘AI alignment problem is solved’ → ‘China and the US cooperate on AI alignment’ → ‘Discontinuous progress in computational costs’. Chain 2: ‘Intergovernmental treaty on AI alignment’ ← ‘Robust AI-driven economic growth’ ← ‘Continual learning integrated with foundation models’. Panel C (bottom) titled ‘Top Set of Crux Events as Conditional Tree Decomposed to Bayes Net’ depicts a new Bayes net where context nodes such as ‘Photonic computing is used for CPU’, ‘US/China trade increases’, and ‘US grows increasingly authoritarian’ feed into ‘China and the US cooperate on AI alignment’, then into ‘AI alignment problem is solved’, and finally ‘AI causes human extinction’. Arrows between panels illustrate the workflow sequence. CHART TYPE: conceptual flow diagram with two Bayes nets and intermediate conditional trees. DATA: relationships among qualitative variables—no numeric axes. PURPOSE: illustrates AMTAIR’s iterative refinement pipeline from full Bayes net to crux-tree extraction and back. DETAILS: emphasises node styles (solid, dashed, dotted) for relevance; shows convergence toward the extinction outcome. SOURCE: @gruetzemacher2022, May 2025."</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>    fig-align="center"                        </span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>    width="100%"</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>}](https://bnma.co/uai2022-apps-workshop/papers/S5.pdf)</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>from @mccaslin2024</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">![Conditional-tree Guide</span><span class="co">](/images/conditional_tree.jpg)</span>{</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>  #fig-conditional_tree</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>  fig-scap="Conditional-tree Guide"</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>  fig-alt="CHART TYPE: annotated schematic of a three-level conditional tree. DATA: placeholders XX %, AA %, BB %, VV %, WW %, etc. PURPOSE: illustrates colour and label conventions—green for ultimate question, blue/purple for indicator questions, grey/red for branch probabilities, red for updated extinction probabilities and relative-risk factors. DETAILS: shows how each indicator’s TRUE or FALSE branch feeds probabilistically into the ultimate extinction outcome. SOURCE: McCaslin et al. 2024 @mccaslin2024, FRI Working Paper #3."</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>  fig-align="center"</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>    width="100%"</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>}](https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/66ba37a144f1d6095de467df/1723479995772/AIConditionalTrees.pdf#page=5.78)</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a>from @mccaslin2024</span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">![Experts’ conditional-tree updates (2030-2070)</span><span class="co">](/images/concerned_experts.jpg)</span>{</span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>    #fig-concerned_experts</span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a>    fig-scap="Experts’ conditional-tree updates (2030-2070)"</span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a>    fig-alt="CHART TYPE: conditional-probability tree with three sequential indicator nodes. DATA: baseline AI-extinction probability 17 % in 2023; indicator 1 (2030 administrative disempowerment warning shot) TRUE=37 %, FALSE=63 %; two conditional probabilities for extinction in 2100: 31.6 % (relative-risk 1.9×) if TRUE, 14.3 % (0.9×) if FALSE. Indicator 2 (2050 power-seeking warning shot) TRUE=54 %, FALSE=46 %; corresponding extinction probabilities 23.4 % (1.4×) and 10.5 % (0.6×). Indicator 3 (2070 no aligned AGI) TRUE=46 %, FALSE=54 %; extinction probabilities 25.0 % (1.5×) and 13.7 % (0.8×). PURPOSE: quantifies how confirmation or disconfirmation of warning-shot events would shift expert-assessed AI-extinction risk. DETAILS: experts are most alarmed by earlier administrative disempowerment (1.9× increase) and least by absence of power-seeking shot (0.6×). SOURCE: McCaslin et al. 2024 @mccaslin2024, FRI Working Paper #3."</span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>    fig-align="center"</span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>    width="100%"</span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>}](https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/66ba37a144f1d6095de467df/1723479995772/AIConditionalTrees.pdf#page=5.78)</span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a>from @manheim2021</span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">![Overlay of inside/outside/assimilation views</span><span class="co">](/images/mtair-insideoutside-overlay.jpg)</span>{</span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a>    #fig-mtair-insideoutside-overlay</span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a>    fig-scap="Overlay of inside/outside/assimilation views"</span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a>    fig-alt="CONCEPT MAP overlaid by three translucent circles captioned Inside view, Outside views, and Assimilation logic. Left bullet list of six APS assumptions feeds a central causal chain of probabilities (timeline, incentive, alignment, failure, disempowerment, catastrophe) leading to a node titled ‘Cr existential catastrophe | world model’. Lower-left cluster of rectangles represents outside-view priors (Second Species Argument, transformative-tech base rate, AGI timeline forecasts, etc.). Right-hand cluster shows weighting and integration logic combining world-model estimate with outside-view priors into a final existential-catastrophe credence. No numerical axes—pure structural relationships. PURPOSE: illustrate how MTAIR reconciles inside-view technical reasoning with outside-view priors using an assimilation weighting scheme. SOURCE: David Manheim @manheim2021, MTAIR sequence post #3, Jul 2021."</span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a>    fig-align="center"</span>
<span id="cb7-76"><a href="#cb7-76" aria-hidden="true" tabindex="-1"></a>    width="100%"</span>
<span id="cb7-77"><a href="#cb7-77" aria-hidden="true" tabindex="-1"></a>}](https://www.lesswrong.com/posts/sGkRDrpphsu6Jhega/a-model-based-approach-to-ai-existential-risk)</span>
<span id="cb7-78"><a href="#cb7-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-79"><a href="#cb7-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-80"><a href="#cb7-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-81"><a href="#cb7-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-82"><a href="#cb7-82" aria-hidden="true" tabindex="-1"></a>from @manheim2021</span>
<span id="cb7-83"><a href="#cb7-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-84"><a href="#cb7-84" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">![Base APS causal map</span><span class="co">](/images/mtair-insideoutside-base.jpg)</span>{</span>
<span id="cb7-85"><a href="#cb7-85" aria-hidden="true" tabindex="-1"></a>    #fig-mtair-insideoutside-base</span>
<span id="cb7-86"><a href="#cb7-86" aria-hidden="true" tabindex="-1"></a>    fig-scap="Base APS causal map (clean)"</span>
<span id="cb7-87"><a href="#cb7-87" aria-hidden="true" tabindex="-1"></a>    fig-alt="Same node-and-arrow causal graph as the overlay figure but without the purple, violet, and red guiding circles. Blue bullet premises feed ‘Collection of inputs’ rectangle, cascading turquoise probability ovals lead to ‘Cr existential catastrophe | world model’. Lower left shows outside-view priors, right shows weighting logic, centre red oval ‘Cr existential catastrophe’. Provides uncluttered view of the structural model prior to explanatory overlay. SOURCE: David Manheim @manheim2021, MTAIR sequence, 2021."</span>
<span id="cb7-88"><a href="#cb7-88" aria-hidden="true" tabindex="-1"></a>    fig-align="center"</span>
<span id="cb7-89"><a href="#cb7-89" aria-hidden="true" tabindex="-1"></a>    width="100%"</span>
<span id="cb7-90"><a href="#cb7-90" aria-hidden="true" tabindex="-1"></a>}](https://www.lesswrong.com/posts/sGkRDrpphsu6Jhega/a-model-based-approach-to-ai-existential-risk)</span>
<span id="cb7-91"><a href="#cb7-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-92"><a href="#cb7-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-93"><a href="#cb7-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-94"><a href="#cb7-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-95"><a href="#cb7-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-96"><a href="#cb7-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-97"><a href="#cb7-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-98"><a href="#cb7-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-99"><a href="#cb7-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-100"><a href="#cb7-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-101"><a href="#cb7-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-102"><a href="#cb7-102" aria-hidden="true" tabindex="-1"></a>from @clarke2022</span>
<span id="cb7-103"><a href="#cb7-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-104"><a href="#cb7-104" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">![MTAIR Quantitative map structure</span><span class="co">](/images/mtair-quant-map.jpg)</span>{</span>
<span id="cb7-105"><a href="#cb7-105" aria-hidden="true" tabindex="-1"></a>    #fig-mtair-quant-map</span>
<span id="cb7-106"><a href="#cb7-106" aria-hidden="true" tabindex="-1"></a>    fig-scap="MTAIR Quantitative map structure"</span>
<span id="cb7-107"><a href="#cb7-107" aria-hidden="true" tabindex="-1"></a>    fig-alt="FLOW DIAGRAM titled ‘Quantitative Model’. Blue and cyan rectangles (Hypotheses and Debated propositions) feed green ‘Proposed agenda’ boxes and a rose ‘Meta-uncertainty’ box, which all point to red ‘Catastrophe scenario’ boxes. Tiny mini-PDF icons depict probability distributions beside each variable. Right-hand analysis panel lists Effects of investment, Sensitivity analysis, What-if questions, Decision approaches, Analysis tools. PURPOSE: show how MTAIR converts a qualitative causal map into a quantified Bayesian network that supports downstream scenario and decision analysis. OURCE: David Manheim et. al, Modeling Transformative AI Risks (MTAIR) Project -- Summary Report, 2021."</span>
<span id="cb7-108"><a href="#cb7-108" aria-hidden="true" tabindex="-1"></a>    fig-align="center"</span>
<span id="cb7-109"><a href="#cb7-109" aria-hidden="true" tabindex="-1"></a>    width="100%"</span>
<span id="cb7-110"><a href="#cb7-110" aria-hidden="true" tabindex="-1"></a>}](https://arxiv.org/pdf/2206.09360#page=10.75)</span>
<span id="cb7-111"><a href="#cb7-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-112"><a href="#cb7-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-113"><a href="#cb7-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-114"><a href="#cb7-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-115"><a href="#cb7-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-116"><a href="#cb7-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-117"><a href="#cb7-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-118"><a href="#cb7-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-119"><a href="#cb7-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-120"><a href="#cb7-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-121"><a href="#cb7-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-122"><a href="#cb7-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-123"><a href="#cb7-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-124"><a href="#cb7-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-125"><a href="#cb7-125" aria-hidden="true" tabindex="-1"></a>from @clarke2022</span>
<span id="cb7-126"><a href="#cb7-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-127"><a href="#cb7-127" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">![MTAIR Qualitative map structure</span><span class="co">](/images/mtair-qual-map.jpg)</span>{</span>
<span id="cb7-128"><a href="#cb7-128" aria-hidden="true" tabindex="-1"></a>    #fig-mtair-qual-map</span>
<span id="cb7-129"><a href="#cb7-129" aria-hidden="true" tabindex="-1"></a>    fig-scap="MTAIR Qualitative map structure"</span>
<span id="cb7-130"><a href="#cb7-130" aria-hidden="true" tabindex="-1"></a>    fig-alt="NODE-LINK DIAGRAM titled ‘Qualitative Map’. Blue rectangles ‘Hypothesis 1’ and ‘Hypothesis 2’, cyan rectangles ‘Debated propositions 1 &amp; 2’, green rectangles ‘Proposed agendas 1 &amp; 2’, red rectangles ‘Catastrophe scenarios 1 &amp; 2’. Arrows show causal influence path from hypotheses through debated propositions and agendas to catastrophes. No probability icons, no analysis panel. PURPOSE: foundational structure before numerical parametrisation, illustrating argumentative flow in MTAIR. SOURCE: David Manheim et. al, Modeling Transformative AI Risks (MTAIR) Project -- Summary Report, 2021."</span>
<span id="cb7-131"><a href="#cb7-131" aria-hidden="true" tabindex="-1"></a>    fig-align="center"</span>
<span id="cb7-132"><a href="#cb7-132" aria-hidden="true" tabindex="-1"></a>    width="100%"</span>
<span id="cb7-133"><a href="#cb7-133" aria-hidden="true" tabindex="-1"></a>}](https://arxiv.org/pdf/2206.09360#page=10.75)</span>
<span id="cb7-134"><a href="#cb7-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-135"><a href="#cb7-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-136"><a href="#cb7-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-137"><a href="#cb7-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-138"><a href="#cb7-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-139"><a href="#cb7-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-140"><a href="#cb7-140" aria-hidden="true" tabindex="-1"></a>from @cottier2019</span>
<span id="cb7-141"><a href="#cb7-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-142"><a href="#cb7-142" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">![Key hypotheses in AI alignment</span><span class="co">](/images/hypotheses_diagram.pdf)</span>{</span>
<span id="cb7-143"><a href="#cb7-143" aria-hidden="true" tabindex="-1"></a>    #fig-ai-hypotheses-map</span>
<span id="cb7-144"><a href="#cb7-144" aria-hidden="true" tabindex="-1"></a>    fig-scap="Key hypotheses in AI alignment"</span>
<span id="cb7-145"><a href="#cb7-145" aria-hidden="true" tabindex="-1"></a>    fig-alt="LARGE CONCEPT MAP. Nodes are colour-coded: red for problems that could lead to catastrophe, green for solutions or agendas, blue for scenarios or conceptual models. Bold-border nodes denote primary hypotheses such as ‘Discontinuity to AGI’, ‘Agentive AGI’, ‘Broad basin for corrigibility’, and ‘Mesa-optimisation’. Directed arrows link questions to hypotheses, questions to questions, and scenarios to hypotheses. Arrow labels (Yes, No, Defer, brief rationales) indicate how answering the tail node influences credence in the head node. A legend at the bottom explains colour categories and arrow semantics. Source: Ben Cottier &amp; Rohin Shah (2019) @cottier2019 “Clarifying Some Key Hypotheses in AI Alignment”, AI Alignment Forum."</span>
<span id="cb7-146"><a href="#cb7-146" aria-hidden="true" tabindex="-1"></a>    fig-align="center"</span>
<span id="cb7-147"><a href="#cb7-147" aria-hidden="true" tabindex="-1"></a>    width="100%"</span>
<span id="cb7-148"><a href="#cb7-148" aria-hidden="true" tabindex="-1"></a>}](https://www.lesswrong.com/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment#Agentive_AGI_)</span>
<span id="cb7-149"><a href="#cb7-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-150"><a href="#cb7-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-151"><a href="#cb7-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-152"><a href="#cb7-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-153"><a href="#cb7-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-154"><a href="#cb7-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-155"><a href="#cb7-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-156"><a href="#cb7-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-157"><a href="#cb7-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-158"><a href="#cb7-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-159"><a href="#cb7-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-160"><a href="#cb7-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-161"><a href="#cb7-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-162"><a href="#cb7-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-163"><a href="#cb7-163" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>from <span class="citation" data-cites="metropolitansky2025">Metropolitansky and Larson (<a href="references.html#ref-metropolitansky2025" role="doc-biblioref">2025</a>)</span></p>
<div id="fig-claimify-stages" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" width="100%" alt="COMPOSITE FIGURE: table and process flow. TABLE: four-row, two-column table enumerates stages 1–4 of Claimify’s pipeline—Sentence splitting and context creation, Selection, Disambiguation, Decomposition—each with a plain-language description. FLOW-CHART: sequence of rectangles and diamond decision nodes shows per-sentence logic. Start node ‘Input question &amp; answer’ feeds into ‘Split into sentences &amp; create context’. Decision 1 asks if the sentence contains verifiable content; ‘No’ exits with red X ‘No verifiable claims’, ‘Yes’ advances. Decision 2 checks for irresolvable ambiguity; ‘Yes’ exits with red X ‘Cannot be disambiguated’, ‘No’ advances. Decision 3 asks if at least one claim is produced; ‘No’ exits with red X ‘No verifiable claims’, ‘Yes’ ends with green check ‘Extracted claims’. A dashed bracket labelled ‘Per sentence’ spans the decision chain. PURPOSE: illustrates Claimify’s staged filtering that aligns with AMTAIR’s need for clean, disambiguated claims before formal modelling. DATA: categorical process flow—no numeric axes. SOURCE: Adapted from Claimify documentation (2024, https://www.microsoft.com/en-us/research/blog/claimify-extracting-high-quality-claims-from-language-model-outputs/)." data-fig-scap="Claimify claim-extraction stages">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-claimify-stages-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://www.microsoft.com/en-us/research/blog/claimify-extracting-high-quality-claims-from-language-model-outputs/"><img src="../images/claimify-stages.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-scap="Claimify claim-extraction stages" alt="COMPOSITE FIGURE: table and process flow. TABLE: four-row, two-column table enumerates stages 1–4 of Claimify’s pipeline—Sentence splitting and context creation, Selection, Disambiguation, Decomposition—each with a plain-language description. FLOW-CHART: sequence of rectangles and diamond decision nodes shows per-sentence logic. Start node ‘Input question &amp; answer’ feeds into ‘Split into sentences &amp; create context’. Decision 1 asks if the sentence contains verifiable content; ‘No’ exits with red X ‘No verifiable claims’, ‘Yes’ advances. Decision 2 checks for irresolvable ambiguity; ‘Yes’ exits with red X ‘Cannot be disambiguated’, ‘No’ advances. Decision 3 asks if at least one claim is produced; ‘No’ exits with red X ‘No verifiable claims’, ‘Yes’ ends with green check ‘Extracted claims’. A dashed bracket labelled ‘Per sentence’ spans the decision chain. PURPOSE: illustrates Claimify’s staged filtering that aligns with AMTAIR’s need for clean, disambiguated claims before formal modelling. DATA: categorical process flow—no numeric axes. SOURCE: Adapted from Claimify documentation (2024, https://www.microsoft.com/en-us/research/blog/claimify-extracting-high-quality-claims-from-language-model-outputs/)."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-claimify-stages-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.1: Claimify claim-extraction stages
</figcaption>
</figure>
</div>
<p>from <span class="citation" data-cites="tetlock2022">Tetlock (<a href="references.html#ref-tetlock2022" role="doc-biblioref">2022</a>)</span></p>
<div id="fig-conditional_metaculus" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" width="100%" alt="SCREENSHOT of a forecasting-platform interface titled ‘Series Contents’. A search bar and filter chips sit above five forecast cards: 1) ‘If, before 2050, AI kills more than 1 million people, will the policy response be insufficient?’ with a 75 percent gauge (green, arrow up 8 percent). 2) ‘Before 2050, will an AI system be shut down due to exhibiting power-seeking behavior?’ at 95 percent (arrow down 2 percent). 3) ‘Before 2100, will AI cause the human population to fall below 5000 individuals?’ at 4 percent. 4) ‘Before 2030, will there be an AI-caused administrative disempowerment?’ at 20 percent. 5) ‘Between 2023 and 2030, will revenue from deep learning double every two years?’ at 80 percent. Beneath several cards, grey CONDITION boxes branch to green bars labelled ‘CTs AI Extinction Before 2100’ with different probabilities for IF YES and IF NO scenarios (e.g. 26 % vs 37 %). Each question lists forecaster counts, closing dates (2030 or 2050), and the tag ‘Conditional Trees: AI Risk’. A footer card introduces the series report. CHART TYPE: mixed UI elements—gauge dials and horizontal bars—displaying probabilities and conditional probabilities. DATA: probabilities (% chances) for base and conditional events; no axes. PURPOSE: demonstrates how crowd-forecasting encodes marginal and counterfactual probabilities suitable as inputs for AMTAIR Bayesian-network nodes. DETAILS: notable high probability for power-seeking AI shutdown, low probability for population collapse, and large shifts in extinction risk under certain conditions. SOURCE: Forecasting Research Institute conditional-tree series, @tetlock2022." data-fig-scap="Conditional-tree AI-risk forecasts">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-conditional_metaculus-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://www.metaculus.com/tournament/3508/"><img src="../images/conditional_metaculus.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-scap="Conditional-tree AI-risk forecasts" alt="SCREENSHOT of a forecasting-platform interface titled ‘Series Contents’. A search bar and filter chips sit above five forecast cards: 1) ‘If, before 2050, AI kills more than 1 million people, will the policy response be insufficient?’ with a 75 percent gauge (green, arrow up 8 percent). 2) ‘Before 2050, will an AI system be shut down due to exhibiting power-seeking behavior?’ at 95 percent (arrow down 2 percent). 3) ‘Before 2100, will AI cause the human population to fall below 5000 individuals?’ at 4 percent. 4) ‘Before 2030, will there be an AI-caused administrative disempowerment?’ at 20 percent. 5) ‘Between 2023 and 2030, will revenue from deep learning double every two years?’ at 80 percent. Beneath several cards, grey CONDITION boxes branch to green bars labelled ‘CTs AI Extinction Before 2100’ with different probabilities for IF YES and IF NO scenarios (e.g. 26 % vs 37 %). Each question lists forecaster counts, closing dates (2030 or 2050), and the tag ‘Conditional Trees: AI Risk’. A footer card introduces the series report. CHART TYPE: mixed UI elements—gauge dials and horizontal bars—displaying probabilities and conditional probabilities. DATA: probabilities (% chances) for base and conditional events; no axes. PURPOSE: demonstrates how crowd-forecasting encodes marginal and counterfactual probabilities suitable as inputs for AMTAIR Bayesian-network nodes. DETAILS: notable high probability for power-seeking AI shutdown, low probability for population collapse, and large shifts in extinction risk under certain conditions. SOURCE: Forecasting Research Institute conditional-tree series, @tetlock2022."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-conditional_metaculus-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.2: Conditional-tree AI-risk forecasts
</figcaption>
</figure>
</div>
<p>from <span class="citation" data-cites="gruetzemacher2022">Gruetzemacher (<a href="references.html#ref-gruetzemacher2022" role="doc-biblioref">2022</a>)</span></p>
<div id="fig-bayesnet-crux-flow" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" width="100%" alt="THREE-PANEL DIAGRAM. Panel A (upper left) titled ‘Initial Bayes Net—Pruning Least Relevant Nodes’ shows eleven circular nodes connected by arrows inside a rounded rectangle. Solid circles remain; dashed or dotted ones are pruned. Arrows converge on a solid node labelled ‘AI causes human extinction’. Panel B (upper right) titled ‘Two Sets of Crux Events from Bayes Nets Isolated as Conditional Trees’ shows two short vertical chains of dotted or dashed circles. Chain 1: ‘AI alignment problem is solved’ → ‘China and the US cooperate on AI alignment’ → ‘Discontinuous progress in computational costs’. Chain 2: ‘Intergovernmental treaty on AI alignment’ ← ‘Robust AI-driven economic growth’ ← ‘Continual learning integrated with foundation models’. Panel C (bottom) titled ‘Top Set of Crux Events as Conditional Tree Decomposed to Bayes Net’ depicts a new Bayes net where context nodes such as ‘Photonic computing is used for CPU’, ‘US/China trade increases’, and ‘US grows increasingly authoritarian’ feed into ‘China and the US cooperate on AI alignment’, then into ‘AI alignment problem is solved’, and finally ‘AI causes human extinction’. Arrows between panels illustrate the workflow sequence. CHART TYPE: conceptual flow diagram with two Bayes nets and intermediate conditional trees. DATA: relationships among qualitative variables—no numeric axes. PURPOSE: illustrates AMTAIR’s iterative refinement pipeline from full Bayes net to crux-tree extraction and back. DETAILS: emphasises node styles (solid, dashed, dotted) for relevance; shows convergence toward the extinction outcome. SOURCE: @gruetzemacher2022, May 2025." data-fig-scap="Bayes-net pruning → crux extraction → re-expansion">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bayesnet-crux-flow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://bnma.co/uai2022-apps-workshop/papers/S5.pdf"><img src="../images/bns_and_conditional_trees.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-scap="Bayes-net pruning → crux extraction → re-expansion" alt="THREE-PANEL DIAGRAM. Panel A (upper left) titled ‘Initial Bayes Net—Pruning Least Relevant Nodes’ shows eleven circular nodes connected by arrows inside a rounded rectangle. Solid circles remain; dashed or dotted ones are pruned. Arrows converge on a solid node labelled ‘AI causes human extinction’. Panel B (upper right) titled ‘Two Sets of Crux Events from Bayes Nets Isolated as Conditional Trees’ shows two short vertical chains of dotted or dashed circles. Chain 1: ‘AI alignment problem is solved’ → ‘China and the US cooperate on AI alignment’ → ‘Discontinuous progress in computational costs’. Chain 2: ‘Intergovernmental treaty on AI alignment’ ← ‘Robust AI-driven economic growth’ ← ‘Continual learning integrated with foundation models’. Panel C (bottom) titled ‘Top Set of Crux Events as Conditional Tree Decomposed to Bayes Net’ depicts a new Bayes net where context nodes such as ‘Photonic computing is used for CPU’, ‘US/China trade increases’, and ‘US grows increasingly authoritarian’ feed into ‘China and the US cooperate on AI alignment’, then into ‘AI alignment problem is solved’, and finally ‘AI causes human extinction’. Arrows between panels illustrate the workflow sequence. CHART TYPE: conceptual flow diagram with two Bayes nets and intermediate conditional trees. DATA: relationships among qualitative variables—no numeric axes. PURPOSE: illustrates AMTAIR’s iterative refinement pipeline from full Bayes net to crux-tree extraction and back. DETAILS: emphasises node styles (solid, dashed, dotted) for relevance; shows convergence toward the extinction outcome. SOURCE: @gruetzemacher2022, May 2025."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bayesnet-crux-flow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.3: Bayes-net pruning → crux extraction → re-expansion
</figcaption>
</figure>
</div>
<p>from <span class="citation" data-cites="mccaslin2024">McCaslin et al. (<a href="references.html#ref-mccaslin2024" role="doc-biblioref">2024</a>)</span></p>
<div id="fig-conditional_tree" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" width="100%" alt="CHART TYPE: annotated schematic of a three-level conditional tree. DATA: placeholders XX %, AA %, BB %, VV %, WW %, etc. PURPOSE: illustrates colour and label conventions—green for ultimate question, blue/purple for indicator questions, grey/red for branch probabilities, red for updated extinction probabilities and relative-risk factors. DETAILS: shows how each indicator’s TRUE or FALSE branch feeds probabilistically into the ultimate extinction outcome. SOURCE: McCaslin et al. 2024 @mccaslin2024, FRI Working Paper #3." data-fig-scap="Conditional-tree Guide">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-conditional_tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/66ba37a144f1d6095de467df/1723479995772/AIConditionalTrees.pdf#page=5.78"><img src="../images/conditional_tree.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-scap="Conditional-tree Guide" alt="CHART TYPE: annotated schematic of a three-level conditional tree. DATA: placeholders XX %, AA %, BB %, VV %, WW %, etc. PURPOSE: illustrates colour and label conventions—green for ultimate question, blue/purple for indicator questions, grey/red for branch probabilities, red for updated extinction probabilities and relative-risk factors. DETAILS: shows how each indicator’s TRUE or FALSE branch feeds probabilistically into the ultimate extinction outcome. SOURCE: McCaslin et al. 2024 @mccaslin2024, FRI Working Paper #3."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-conditional_tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.4: Conditional-tree Guide
</figcaption>
</figure>
</div>
<p>from <span class="citation" data-cites="mccaslin2024">McCaslin et al. (<a href="references.html#ref-mccaslin2024" role="doc-biblioref">2024</a>)</span></p>
<div id="fig-concerned_experts" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" width="100%" alt="CHART TYPE: conditional-probability tree with three sequential indicator nodes. DATA: baseline AI-extinction probability 17 % in 2023; indicator 1 (2030 administrative disempowerment warning shot) TRUE=37 %, FALSE=63 %; two conditional probabilities for extinction in 2100: 31.6 % (relative-risk 1.9×) if TRUE, 14.3 % (0.9×) if FALSE. Indicator 2 (2050 power-seeking warning shot) TRUE=54 %, FALSE=46 %; corresponding extinction probabilities 23.4 % (1.4×) and 10.5 % (0.6×). Indicator 3 (2070 no aligned AGI) TRUE=46 %, FALSE=54 %; extinction probabilities 25.0 % (1.5×) and 13.7 % (0.8×). PURPOSE: quantifies how confirmation or disconfirmation of warning-shot events would shift expert-assessed AI-extinction risk. DETAILS: experts are most alarmed by earlier administrative disempowerment (1.9× increase) and least by absence of power-seeking shot (0.6×). SOURCE: McCaslin et al. 2024 @mccaslin2024, FRI Working Paper #3." data-fig-scap="Experts’ conditional-tree updates (2030-2070)">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-concerned_experts-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/66ba37a144f1d6095de467df/1723479995772/AIConditionalTrees.pdf#page=5.78"><img src="../images/concerned_experts.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-scap="Experts’ conditional-tree updates (2030-2070)" alt="CHART TYPE: conditional-probability tree with three sequential indicator nodes. DATA: baseline AI-extinction probability 17 % in 2023; indicator 1 (2030 administrative disempowerment warning shot) TRUE=37 %, FALSE=63 %; two conditional probabilities for extinction in 2100: 31.6 % (relative-risk 1.9×) if TRUE, 14.3 % (0.9×) if FALSE. Indicator 2 (2050 power-seeking warning shot) TRUE=54 %, FALSE=46 %; corresponding extinction probabilities 23.4 % (1.4×) and 10.5 % (0.6×). Indicator 3 (2070 no aligned AGI) TRUE=46 %, FALSE=54 %; extinction probabilities 25.0 % (1.5×) and 13.7 % (0.8×). PURPOSE: quantifies how confirmation or disconfirmation of warning-shot events would shift expert-assessed AI-extinction risk. DETAILS: experts are most alarmed by earlier administrative disempowerment (1.9× increase) and least by absence of power-seeking shot (0.6×). SOURCE: McCaslin et al. 2024 @mccaslin2024, FRI Working Paper #3."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-concerned_experts-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.5: Experts’ conditional-tree updates (2030-2070)
</figcaption>
</figure>
</div>
<p>from <span class="citation" data-cites="manheim2021">Manheim (<a href="references.html#ref-manheim2021" role="doc-biblioref">2021</a>)</span></p>
<div id="fig-mtair-insideoutside-overlay" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" width="100%" alt="CONCEPT MAP overlaid by three translucent circles captioned Inside view, Outside views, and Assimilation logic. Left bullet list of six APS assumptions feeds a central causal chain of probabilities (timeline, incentive, alignment, failure, disempowerment, catastrophe) leading to a node titled ‘Cr existential catastrophe | world model’. Lower-left cluster of rectangles represents outside-view priors (Second Species Argument, transformative-tech base rate, AGI timeline forecasts, etc.). Right-hand cluster shows weighting and integration logic combining world-model estimate with outside-view priors into a final existential-catastrophe credence. No numerical axes—pure structural relationships. PURPOSE: illustrate how MTAIR reconciles inside-view technical reasoning with outside-view priors using an assimilation weighting scheme. SOURCE: David Manheim @manheim2021, MTAIR sequence post #3, Jul 2021." data-fig-scap="Overlay of inside/outside/assimilation views">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mtair-insideoutside-overlay-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://www.lesswrong.com/posts/sGkRDrpphsu6Jhega/a-model-based-approach-to-ai-existential-risk"><img src="../images/mtair-insideoutside-overlay.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-scap="Overlay of inside/outside/assimilation views" alt="CONCEPT MAP overlaid by three translucent circles captioned Inside view, Outside views, and Assimilation logic. Left bullet list of six APS assumptions feeds a central causal chain of probabilities (timeline, incentive, alignment, failure, disempowerment, catastrophe) leading to a node titled ‘Cr existential catastrophe | world model’. Lower-left cluster of rectangles represents outside-view priors (Second Species Argument, transformative-tech base rate, AGI timeline forecasts, etc.). Right-hand cluster shows weighting and integration logic combining world-model estimate with outside-view priors into a final existential-catastrophe credence. No numerical axes—pure structural relationships. PURPOSE: illustrate how MTAIR reconciles inside-view technical reasoning with outside-view priors using an assimilation weighting scheme. SOURCE: David Manheim @manheim2021, MTAIR sequence post #3, Jul 2021."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mtair-insideoutside-overlay-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.6: Overlay of inside/outside/assimilation views
</figcaption>
</figure>
</div>
<p>from <span class="citation" data-cites="manheim2021">Manheim (<a href="references.html#ref-manheim2021" role="doc-biblioref">2021</a>)</span></p>
<div id="fig-mtair-insideoutside-base" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" width="100%" alt="Same node-and-arrow causal graph as the overlay figure but without the purple, violet, and red guiding circles. Blue bullet premises feed ‘Collection of inputs’ rectangle, cascading turquoise probability ovals lead to ‘Cr existential catastrophe | world model’. Lower left shows outside-view priors, right shows weighting logic, centre red oval ‘Cr existential catastrophe’. Provides uncluttered view of the structural model prior to explanatory overlay. SOURCE: David Manheim @manheim2021, MTAIR sequence, 2021." data-fig-scap="Base APS causal map (clean)">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mtair-insideoutside-base-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://www.lesswrong.com/posts/sGkRDrpphsu6Jhega/a-model-based-approach-to-ai-existential-risk"><img src="../images/mtair-insideoutside-base.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-scap="Base APS causal map (clean)" alt="Same node-and-arrow causal graph as the overlay figure but without the purple, violet, and red guiding circles. Blue bullet premises feed ‘Collection of inputs’ rectangle, cascading turquoise probability ovals lead to ‘Cr existential catastrophe | world model’. Lower left shows outside-view priors, right shows weighting logic, centre red oval ‘Cr existential catastrophe’. Provides uncluttered view of the structural model prior to explanatory overlay. SOURCE: David Manheim @manheim2021, MTAIR sequence, 2021."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mtair-insideoutside-base-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.7: Base APS causal map
</figcaption>
</figure>
</div>
<p>from <span class="citation" data-cites="clarke2022">Clarke et al. (<a href="references.html#ref-clarke2022" role="doc-biblioref">2022</a>)</span></p>
<div id="fig-mtair-quant-map" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" width="100%" alt="FLOW DIAGRAM titled ‘Quantitative Model’. Blue and cyan rectangles (Hypotheses and Debated propositions) feed green ‘Proposed agenda’ boxes and a rose ‘Meta-uncertainty’ box, which all point to red ‘Catastrophe scenario’ boxes. Tiny mini-PDF icons depict probability distributions beside each variable. Right-hand analysis panel lists Effects of investment, Sensitivity analysis, What-if questions, Decision approaches, Analysis tools. PURPOSE: show how MTAIR converts a qualitative causal map into a quantified Bayesian network that supports downstream scenario and decision analysis. OURCE: David Manheim et. al, Modeling Transformative AI Risks (MTAIR) Project -- Summary Report, 2021." data-fig-scap="MTAIR Quantitative map structure">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mtair-quant-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://arxiv.org/pdf/2206.09360#page=10.75"><img src="../images/mtair-quant-map.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-scap="MTAIR Quantitative map structure" alt="FLOW DIAGRAM titled ‘Quantitative Model’. Blue and cyan rectangles (Hypotheses and Debated propositions) feed green ‘Proposed agenda’ boxes and a rose ‘Meta-uncertainty’ box, which all point to red ‘Catastrophe scenario’ boxes. Tiny mini-PDF icons depict probability distributions beside each variable. Right-hand analysis panel lists Effects of investment, Sensitivity analysis, What-if questions, Decision approaches, Analysis tools. PURPOSE: show how MTAIR converts a qualitative causal map into a quantified Bayesian network that supports downstream scenario and decision analysis. OURCE: David Manheim et. al, Modeling Transformative AI Risks (MTAIR) Project -- Summary Report, 2021."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mtair-quant-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.8: MTAIR Quantitative map structure
</figcaption>
</figure>
</div>
<p>from <span class="citation" data-cites="clarke2022">Clarke et al. (<a href="references.html#ref-clarke2022" role="doc-biblioref">2022</a>)</span></p>
<div id="fig-mtair-qual-map" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" width="100%" alt="NODE-LINK DIAGRAM titled ‘Qualitative Map’. Blue rectangles ‘Hypothesis 1’ and ‘Hypothesis 2’, cyan rectangles ‘Debated propositions 1 &amp; 2’, green rectangles ‘Proposed agendas 1 &amp; 2’, red rectangles ‘Catastrophe scenarios 1 &amp; 2’. Arrows show causal influence path from hypotheses through debated propositions and agendas to catastrophes. No probability icons, no analysis panel. PURPOSE: foundational structure before numerical parametrisation, illustrating argumentative flow in MTAIR. SOURCE: David Manheim et. al, Modeling Transformative AI Risks (MTAIR) Project -- Summary Report, 2021." data-fig-scap="MTAIR Qualitative map structure">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mtair-qual-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://arxiv.org/pdf/2206.09360#page=10.75"><img src="../images/mtair-qual-map.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-scap="MTAIR Qualitative map structure" alt="NODE-LINK DIAGRAM titled ‘Qualitative Map’. Blue rectangles ‘Hypothesis 1’ and ‘Hypothesis 2’, cyan rectangles ‘Debated propositions 1 &amp; 2’, green rectangles ‘Proposed agendas 1 &amp; 2’, red rectangles ‘Catastrophe scenarios 1 &amp; 2’. Arrows show causal influence path from hypotheses through debated propositions and agendas to catastrophes. No probability icons, no analysis panel. PURPOSE: foundational structure before numerical parametrisation, illustrating argumentative flow in MTAIR. SOURCE: David Manheim et. al, Modeling Transformative AI Risks (MTAIR) Project -- Summary Report, 2021."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mtair-qual-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.9: MTAIR Qualitative map structure
</figcaption>
</figure>
</div>
<p>from <span class="citation" data-cites="cottier2019">Cottier and Shah (<a href="references.html#ref-cottier2019" role="doc-biblioref">2019</a>)</span></p>
<div id="fig-ai-hypotheses-map" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" width="100%" alt="LARGE CONCEPT MAP. Nodes are colour-coded: red for problems that could lead to catastrophe, green for solutions or agendas, blue for scenarios or conceptual models. Bold-border nodes denote primary hypotheses such as ‘Discontinuity to AGI’, ‘Agentive AGI’, ‘Broad basin for corrigibility’, and ‘Mesa-optimisation’. Directed arrows link questions to hypotheses, questions to questions, and scenarios to hypotheses. Arrow labels (Yes, No, Defer, brief rationales) indicate how answering the tail node influences credence in the head node. A legend at the bottom explains colour categories and arrow semantics. Source: Ben Cottier &amp; Rohin Shah (2019) @cottier2019 “Clarifying Some Key Hypotheses in AI Alignment”, AI Alignment Forum." data-fig-scap="Key hypotheses in AI alignment">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ai-hypotheses-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://www.lesswrong.com/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment#Agentive_AGI_"><embed src="../images/hypotheses_diagram.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:100.0%" data-fig-scap="Key hypotheses in AI alignment" alt="LARGE CONCEPT MAP. Nodes are colour-coded: red for problems that could lead to catastrophe, green for solutions or agendas, blue for scenarios or conceptual models. Bold-border nodes denote primary hypotheses such as ‘Discontinuity to AGI’, ‘Agentive AGI’, ‘Broad basin for corrigibility’, and ‘Mesa-optimisation’. Directed arrows link questions to hypotheses, questions to questions, and scenarios to hypotheses. Arrow labels (Yes, No, Defer, brief rationales) indicate how answering the tail node influences credence in the head node. A legend at the bottom explains colour categories and arrow semantics. Source: Ben Cottier &amp; Rohin Shah (2019) @cottier2019 “Clarifying Some Key Hypotheses in AI Alignment”, AI Alignment Forum."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ai-hypotheses-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.10: Key hypotheses in AI alignment
</figcaption>
</figure>
</div>
</section>
</section>
<section id="bibliography" class="level1 unnumbered">
<h1 class="unnumbered">Bibliography</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-amodei2016" class="csl-entry" role="listitem">
Amodei, Dario, Chris Olah, Jacob Steinhardt, Paul Christiano, John
Schulman, and Dan Mané. 2016. <span>“Concrete <span>Problems</span> in
<span>AI Safety</span>.”</span> July 25, 2016. <a href="https://doi.org/10.48550/arXiv.1606.06565">https://doi.org/10.48550/arXiv.1606.06565</a>.
</div>
<div id="ref-anderson2007" class="csl-entry" role="listitem">
Anderson, Terence J. 2007. <span>“Visualization Tools and Argument
Schemes: A Question of Standpoint.”</span> <em>Law, Prob. &amp;
Risk</em> 6: 97. <a href="https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/lawprisk6&amp;section=9">https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/lawprisk6&amp;section=9</a>.
</div>
<div id="ref-armstrong2016" class="csl-entry" role="listitem">
Armstrong, Stuart, Nick Bostrom, and Carl Shulman. 2016. <span>“Racing
to the Precipice: A Model of Artificial Intelligence
Development.”</span> <em>AI &amp; SOCIETY</em> 31 (2): 201–6. <a href="https://doi.org/10.1007/s00146-015-0590-y">https://doi.org/10.1007/s00146-015-0590-y</a>.
</div>
<div id="ref-askell2021" class="csl-entry" role="listitem">
Askell, Amanda, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom
Henighan, Andy Jones, et al. 2021. <span>“A <span>General Language
Assistant</span> as a <span>Laboratory</span> for
<span>Alignment</span>.”</span> December 9, 2021. <a href="https://doi.org/10.48550/arXiv.2112.00861">https://doi.org/10.48550/arXiv.2112.00861</a>.
</div>
<div id="ref-babakov2025" class="csl-entry" role="listitem">
Babakov, Nikolay, Adarsa Sivaprasad, Ehud Reiter, and Alberto
Bugarín-Diz. 2025. <span>“Reusability of <span>Bayesian Networks</span>
Case Studies: A Survey.”</span> <em>Applied Intelligence</em> 55 (6):
417. <a href="https://doi.org/10.1007/s10489-025-06289-5">https://doi.org/10.1007/s10489-025-06289-5</a>.
</div>
<div id="ref-ban2023" class="csl-entry" role="listitem">
Ban, Taiyu, Lyuzhou Chen, Derui Lyu, Xiangyu Wang, and Huanhuan Chen.
2023. <span>“Causal <span>Structure Learning Supervised</span> by
<span>Large Language Model</span>.”</span> November 20, 2023. <a href="https://doi.org/10.48550/arXiv.2311.11689">https://doi.org/10.48550/arXiv.2311.11689</a>.
</div>
<div id="ref-bayes2025" class="csl-entry" role="listitem">
Bayes, Server. 2025. <span>“Risk Modeling with <span>Bayesian</span>
Networks | <span>Bayes Server</span>.”</span>
https://online.bayesserver.com/. <a href="https://bayesserver.com/docs/modeling/risk/">https://bayesserver.com/docs/modeling/risk/</a>.
</div>
<div id="ref-benn2011" class="csl-entry" role="listitem">
Benn, Neil, and Ann Macintosh. 2011. <span>“Argument
<span>Visualization</span> for <span class="nocase">eParticipation</span>: <span>Towards</span> a
<span>Research Agenda</span> and <span>Prototype Tool</span>.”</span> In
<em>Electronic <span>Participation</span></em>, edited by Efthimios
Tambouris, Ann Macintosh, and Hans De Bruijn, 6847:60–73. Berlin,
Heidelberg: Springer Berlin Heidelberg. <a href="https://doi.org/10.1007/978-3-642-23333-3_6">https://doi.org/10.1007/978-3-642-23333-3_6</a>.
</div>
<div id="ref-bethard2007" class="csl-entry" role="listitem">
Bethard, Steven John. 2007. <span>“Finding Event, Temporal and Causal
Structure in Text: <span>A</span> Machine Learning Approach.”</span> PhD
thesis, University of Colorado at Boulder. <a href="https://search.proquest.com/openview/405fe32503123d9b5f4836dc3be4c011/1?pq-origsite=gscholar&amp;cbl=18750">https://search.proquest.com/openview/405fe32503123d9b5f4836dc3be4c011/1?pq-origsite=gscholar&amp;cbl=18750</a>.
</div>
<div id="ref-bostrom2014" class="csl-entry" role="listitem">
Bostrom, Nick. 2014. <em>Superintelligence: <span>Paths</span>,
Strategies, Dangers</em>. Oxford: Oxford University Press. <a href="https://scholar.dominican.edu/cynthia-stokes-brown-books-big-history/47">https://scholar.dominican.edu/cynthia-stokes-brown-books-big-history/47</a>.
</div>
<div id="ref-box1976" class="csl-entry" role="listitem">
Box, George E. P. 1976. <span>“Science and
<span>Statistics</span>.”</span> <em>Journal of the American Statistical
Association</em> 71 (356): 791–99. <a href="https://doi.org/10.1080/01621459.1976.10480949">https://doi.org/10.1080/01621459.1976.10480949</a>.
</div>
<div id="ref-brundage2018" class="csl-entry" role="listitem">
Brundage, Miles, Shahar Avin, Jack Clark, Helen Toner, Peter Eckersley,
Ben Garfinkel, Allan Dafoe, Paul Scharre, Thomas Zeitzoff, Bobby Filar,
Hyrum Anderson, et al. 2018. <span>“The <span>Malicious Use</span> of
<span>Artificial Intelligence</span>: <span>Forecasting</span>,
<span>Prevention</span>, and <span>Mitigation</span>.”</span> 2018. <a href="https://doi.org/10.48550/ARXIV.1802.07228">https://doi.org/10.48550/ARXIV.1802.07228</a>.
</div>
<div id="ref-brundage2018a" class="csl-entry" role="listitem">
Brundage, Miles, Shahar Avin, Jack Clark, Helen Toner, Peter Eckersley,
Ben Garfinkel, Allan Dafoe, Paul Scharre, Thomas Zeitzoff, and Bobby
Filar. 2018. <span>“The Malicious Use of Artificial Intelligence:
<span>Forecasting</span>, Prevention, and Mitigation.”</span> <a href="https://arxiv.org/abs/1802.07228">https://arxiv.org/abs/1802.07228</a>.
</div>
<div id="ref-carlsmith2021" class="csl-entry" role="listitem">
Carlsmith, Joseph. 2021. <span>“Is <span>Power-Seeking AI</span> an
<span>Existential Risk</span>?”</span> 2021. <a href="https://doi.org/10.48550/arXiv.2206.13353">https://doi.org/10.48550/arXiv.2206.13353</a>.
</div>
<div id="ref-carlsmith2022" class="csl-entry" role="listitem">
———. 2022. <span>“Is Power-Seeking <span>AI</span> an Existential
Risk?”</span> <a href="https://arxiv.org/abs/2206.13353">https://arxiv.org/abs/2206.13353</a>.
</div>
<div id="ref-carlsmith2024" class="csl-entry" role="listitem">
———. 2024. <span>“Is <span>Power-Seeking AI</span> an <span>Existential
Risk</span>?”</span> August 13, 2024. <a href="https://doi.org/10.48550/arXiv.2206.13353">https://doi.org/10.48550/arXiv.2206.13353</a>.
</div>
<div id="ref-chen2023" class="csl-entry" role="listitem">
Chen, Lu, Ruqing Zhang, Wei Huang, Wei Chen, Jiafeng Guo, and Xueqi
Cheng. 2023. <span>“Inducing <span>Causal Structure</span> for
<span>Abstractive Text Summarization</span>.”</span> In <em>Proceedings
of the 32nd <span>ACM International Conference</span> on
<span>Information</span> and <span>Knowledge Management</span></em>,
213–23. Birmingham United Kingdom: ACM. <a href="https://doi.org/10.1145/3583780.3614934">https://doi.org/10.1145/3583780.3614934</a>.
</div>
<div id="ref-christiano2019" class="csl-entry" role="listitem">
Christiano, Paul F. 2019. <span>“What Failure Looks Like,”</span> March.
<a href="https://www.alignmentforum.org/posts/HBxe6wdjxK239zajf/what-failure-looks-like">https://www.alignmentforum.org/posts/HBxe6wdjxK239zajf/what-failure-looks-like</a>.
</div>
<div id="ref-clarke2022" class="csl-entry" role="listitem">
Clarke, Sam, Ben Cottier, Aryeh Englander, Daniel Eth, David Manheim,
Samuel Dylan Martin, and Issa Rice. 2022. <span>“Modeling
<span>Transformative AI Risks</span> (<span>MTAIR</span>)
<span>Project</span> – <span>Summary Report</span>.”</span> 2022. <a href="https://doi.org/10.48550/ARXIV.2206.09360">https://doi.org/10.48550/ARXIV.2206.09360</a>.
</div>
<div id="ref-cottier2021" class="csl-entry" role="listitem">
Cottier, Ben. 2021. <span>“Modeling <span>Risks From Learned
Optimization</span>,”</span> October. <a href="https://www.lesswrong.com/posts/T9oFjteStcE2ijCJi/modeling-risks-from-learned-optimization">https://www.lesswrong.com/posts/T9oFjteStcE2ijCJi/modeling-risks-from-learned-optimization</a>.
</div>
<div id="ref-cottier2021b" class="csl-entry" role="listitem">
Cottier, Ben, Daniel Eth, and Sammy Martin. 2021. <span>“Modeling
<span>Failure Modes</span> of <span>High-Level Machine
Intelligence</span>,”</span> December. <a href="https://www.lesswrong.com/posts/3Eq5Rq5uQ97kt8B8f/modeling-failure-modes-of-high-level-machine-intelligence">https://www.lesswrong.com/posts/3Eq5Rq5uQ97kt8B8f/modeling-failure-modes-of-high-level-machine-intelligence</a>.
</div>
<div id="ref-cottier2019" class="csl-entry" role="listitem">
Cottier, Ben, and Rohin Shah. 2019. <span>“Clarifying Some Key
Hypotheses in <span>AI</span> Alignment,”</span> August. <a href="https://www.lesswrong.com/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment">https://www.lesswrong.com/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment</a>.
</div>
<div id="ref-critch2020" class="csl-entry" role="listitem">
Critch, Andrew, and David Krueger. 2020. <span>“<span>AI Research
Considerations</span> for <span>Human Existential Safety</span>
(<span>ARCHES</span>).”</span> May 30, 2020. <a href="https://doi.org/10.48550/arXiv.2006.04948">https://doi.org/10.48550/arXiv.2006.04948</a>.
</div>
<div id="ref-cuomo2016" class="csl-entry" role="listitem">
Cuomo, Francesca, Christine Mallin, and Alessandro Zattoni. 2016.
<span>“Corporate Governance Codes: <span>A</span> Review and Research
Agenda.”</span> <em>Corporate Governance: An International Review</em>
24 (3): 222–41. <a href="https://ueaeprints.uea.ac.uk/id/eprint/57664/">https://ueaeprints.uea.ac.uk/id/eprint/57664/</a>.
</div>
<div id="ref-dafoe2018" class="csl-entry" role="listitem">
Dafoe, Allan. 2018. <span>“<span>AI</span> Governance: A Research
Agenda.”</span> <em>Governance of AI Program, Future of Humanity
Institute, University of Oxford: Oxford, UK</em> 1442: 1443. <a href="https://www.fhi.ox.ac.uk/wp-content/uploads/GovAI-Agenda.pdf">https://www.fhi.ox.ac.uk/wp-content/uploads/GovAI-Agenda.pdf</a>.
</div>
<div id="ref-dafoe2021" class="csl-entry" role="listitem">
———. 2021. <span>“<span>AI</span> Governance: A Research Agenda.”</span>
2021. <a href="https://www.fhi.ox.ac.uk/wp-content/uploads/GovAI-Agenda.pdf">https://www.fhi.ox.ac.uk/wp-content/uploads/GovAI-Agenda.pdf</a>.
</div>
<div id="ref-davidmanheim2021a" class="csl-entry" role="listitem">
Davidmanheim, David. 2021. <span>“Elicitation for <span>Modeling
Transformative AI Risks</span>,”</span> December. <a href="https://www.lesswrong.com/posts/Kz9NHBMeJxzSwb7R9/elicitation-for-modeling-transformative-ai-risks">https://www.lesswrong.com/posts/Kz9NHBMeJxzSwb7R9/elicitation-for-modeling-transformative-ai-risks</a>.
</div>
<div id="ref-devilliers2021" class="csl-entry" role="listitem">
De Villiers, Charl, and Ruth Dimes. 2021. <span>“Determinants,
Mechanisms and Consequences of Corporate Governance Reporting: A
Research Framework.”</span> <em>Journal of Management and
Governance</em> 25 (1): 7–26. <a href="https://doi.org/10.1007/s10997-020-09530-0">https://doi.org/10.1007/s10997-020-09530-0</a>.
</div>
<div id="ref-demirag2000" class="csl-entry" role="listitem">
Demirag, Istemi, Sudi Sudarsanam, and MIKE WRIGHT. 2000.
<span>“Corporate Governance: Overview and Research Agenda.”</span>
<em>The British Accounting Review</em> 32 (4): 341–54. <a href="https://www.academia.edu/download/49469624/bare.2000.014620161009-3955-1dt4aq5.pdf">https://www.academia.edu/download/49469624/bare.2000.014620161009-3955-1dt4aq5.pdf</a>.
</div>
<div id="ref-divito2022" class="csl-entry" role="listitem">
Di Vito, Jackie, and Kim Trottier. 2022. <span>“A <span>Literature
Review</span> on <span>Corporate Governance Mechanisms</span>:
<span>Past</span>, <span>Present</span>, and
<span>Future</span>*.”</span> <em>Accounting Perspectives</em> 21 (2):
207–35. <a href="https://doi.org/10.1111/1911-3838.12279">https://doi.org/10.1111/1911-3838.12279</a>.
</div>
<div id="ref-drexler2019a" class="csl-entry" role="listitem">
Drexler, K. Eric. 2019. <span>“Reframing Superintelligence:
<span>Comprehensive AI</span> Services as General Intelligence.”</span>
</div>
<div id="ref-drexler2019" class="csl-entry" role="listitem">
Drexler, KE. 2019. <span>“Reframing Superintelligence: Comprehensive
<span>AI</span> Services as General Intelligence.”</span> Technical
Report. Future of Humanity Institute. <a href="https://owainevans.github.io/pdfs/Reframing_Superintelligence_FHI-TR-2019.pdf">https://owainevans.github.io/pdfs/Reframing_Superintelligence_FHI-TR-2019.pdf</a>.
</div>
<div id="ref-duhem1954" class="csl-entry" role="listitem">
Duhem, Pierre Maurice Marie. 1954. <em>The <span>Aim</span> and
<span>Structure</span> of <span>Physical Theory</span></em>. 1.
Princeton University Press.
</div>
<div id="ref-eth2021" class="csl-entry" role="listitem">
Eth, Daniel. 2021. <span>“Paths <span>To High-Level Machine
Intelligence</span>,”</span> September. <a href="https://www.lesswrong.com/posts/amK9EqxALJXyd9Rb2/paths-to-high-level-machine-intelligence">https://www.lesswrong.com/posts/amK9EqxALJXyd9Rb2/paths-to-high-level-machine-intelligence</a>.
</div>
<div id="ref-european2024" class="csl-entry" role="listitem">
European, Union. 2024. <span>“The <span>Act Texts</span> | <span>EU
Artificial Intelligence Act</span>.”</span> 2024. <a href="https://artificialintelligenceact.eu/the-act/">https://artificialintelligenceact.eu/the-act/</a>.
</div>
<div id="ref-good1966" class="csl-entry" role="listitem">
Good, Irving John. 1966. <span>“Speculations <span>Concerning</span> the
<span>First Ultraintelligent Machine</span>.”</span> <em>Advances in
Computers</em>, 31. <a href="https://doi.org/10.1016/S0065-2458(08)60418-0">https://doi.org/10.1016/S0065-2458(08)60418-0</a>.
</div>
<div id="ref-growiec2024" class="csl-entry" role="listitem">
Growiec, Jakub. 2024. <span>“Existential Risk from Transformative
<span>AI</span>: An Economic Perspective.”</span> <em>Technological and
Economic Development of Economy</em> 30 (6): 1682–1708.
</div>
<div id="ref-gruetzemacher2022" class="csl-entry" role="listitem">
Gruetzemacher, Ross. 2022. <span>“Bayesian <span>Networks</span> Vs.
<span>Conditional Trees</span> for <span>Creating Questions</span> for
<span>Forecasting Tournaments</span>.”</span>
</div>
<div id="ref-hadshar2023" class="csl-entry" role="listitem">
Hadshar, Rose. 2023. <span>“A <span>Review</span> of the
<span>Evidence</span> for <span>Existential Risk</span> from
<span>AI</span> via <span>Misaligned Power-Seeking</span>.”</span> 2023.
<a href="https://doi.org/10.48550/ARXIV.2310.18244">https://doi.org/10.48550/ARXIV.2310.18244</a>.
</div>
<div id="ref-hallegatte2012" class="csl-entry" role="listitem">
Hallegatte, Stéphane, Ankur Shah, Robert Lempert, Casey Brown, and
Stuart Gill. 2012. <span>“Investment Decision-Making Under Deep
Uncertainty-Application to Climate Change.”</span> <em>Policy Research
Working Paper</em> 6193. <a href="https://enpc.hal.science/hal-00802049/document">https://enpc.hal.science/hal-00802049/document</a>.
</div>
<div id="ref-heinze-deml2018" class="csl-entry" role="listitem">
Heinze-Deml, Christina, Marloes H. Maathuis, and Nicolai Meinshausen.
2018. <span>“Causal <span>Structure Learning</span>.”</span> <em>Annual
Review of Statistics and Its Application</em> 5 (1): 371–91. <a href="https://doi.org/10.1146/annurev-statistics-031017-100630">https://doi.org/10.1146/annurev-statistics-031017-100630</a>.
</div>
<div id="ref-hendrycks2021" class="csl-entry" role="listitem">
Hendrycks, Dan, Nicholas Carlini, John Schulman, and Jacob Steinhardt.
2021a. <span>“Unsolved <span>Problems</span> in <span>ML
Safety</span>.”</span> 2021. <a href="https://doi.org/10.48550/ARXIV.2109.13916">https://doi.org/10.48550/ARXIV.2109.13916</a>.
</div>
<div id="ref-hendrycks2021a" class="csl-entry" role="listitem">
———. 2021b. <span>“Unsolved Problems in Ml Safety.”</span> <a href="https://arxiv.org/abs/2109.13916">https://arxiv.org/abs/2109.13916</a>.
</div>
<div id="ref-hunt2025" class="csl-entry" role="listitem">
Hunt, Tam. 2025. <span>“The Insane <span>‘Logic’</span> of the
<span>AI</span> Arms Race.”</span> Medium. March 3, 2025. <a href="https://tamhunt.medium.com/the-insane-logic-of-the-ai-arms-race-45a5f79f4c0e">https://tamhunt.medium.com/the-insane-logic-of-the-ai-arms-race-45a5f79f4c0e</a>.
</div>
<div id="ref-jaynes2003" class="csl-entry" role="listitem">
Jaynes, Edwin T. 2003. <em>Probability Theory: <span>The</span> Logic of
Science</em>. Cambridge university press.
</div>
<div id="ref-kasirzadeh2024" class="csl-entry" role="listitem">
Kasirzadeh, Atoosa. 2024. <span>“Two <span>Types</span> of <span>AI
Existential Risk</span>: <span>Decisive</span> and
<span>Accumulative</span>.”</span> 2024. <a href="https://doi.org/10.48550/ARXIV.2401.07836">https://doi.org/10.48550/ARXIV.2401.07836</a>.
</div>
<div id="ref-kaur2024" class="csl-entry" role="listitem">
Kaur, Kawaljit. 2024. <span>“Corporate <span>Governance</span> and
<span>Legal Accountability</span>: <span>A Critical Review</span> of
<span>Global Practices</span>.”</span> <em>Journal of Law</em> 2 (6):
1–7. <a href="https://joi.shodhsagar.org/index.php/SSJOI/article/view/16">https://joi.shodhsagar.org/index.php/SSJOI/article/view/16</a>.
</div>
<div id="ref-khartabil2020" class="csl-entry" role="listitem">
Khartabil, Dana. 2020. <span>“Visualisation Techniques to Facilitate
Argument Exploration.”</span> PhD thesis. <a href="https://napier-repository.worktribe.com/output/2694675">https://napier-repository.worktribe.com/output/2694675</a>.
</div>
<div id="ref-khartabil2021" class="csl-entry" role="listitem">
Khartabil, D., C. Collins, S. Wells, B. Bach, and J. Kennedy. 2021.
<span>“Design and <span>Evaluation</span> of <span>Visualization
Techniques</span> to <span>Facilitate Argument
Exploration</span>.”</span> <em>Computer Graphics Forum</em> 40 (6):
447–65. <a href="https://doi.org/10.1111/cgf.14389">https://doi.org/10.1111/cgf.14389</a>.
</div>
<div id="ref-kilian2023" class="csl-entry" role="listitem">
Kilian, Kyle A., Christopher J. Ventura, and Mark M. Bailey. 2023.
<span>“Examining the <span>Differential Risk</span> from <span class="nocase">High-level Artificial Intelligence</span> and the
<span>Question</span> of <span>Control</span>.”</span> <em>Futures</em>
151 (August): 103182. <a href="https://doi.org/10.1016/j.futures.2023.103182">https://doi.org/10.1016/j.futures.2023.103182</a>.
</div>
<div id="ref-koller2009" class="csl-entry" role="listitem">
Koller, Daphne, and Nir Friedman. 2009. <em>Probabilistic Graphical
Models: Principles and Techniques</em>. MIT press. <a href="https://books.google.ca/books?hl=en&amp;lr=&amp;id=7dzpHCHzNQ4C&amp;oi=fnd&amp;pg=PR9&amp;dq=Koller,+D.,+%26+Friedman,+N.+(2009).+Probabilistic+Graphical+Models&amp;ots=py2HAh0VAL&amp;sig=gpaID3x6-TY8x5SOopuXpZDXfzs">https://books.google.ca/books?hl=en&amp;lr=&amp;id=7dzpHCHzNQ4C&amp;oi=fnd&amp;pg=PR9&amp;dq=Koller,+D.,+%26+Friedman,+N.+(2009).+Probabilistic+Graphical+Models&amp;ots=py2HAh0VAL&amp;sig=gpaID3x6-TY8x5SOopuXpZDXfzs</a>.
</div>
<div id="ref-kuhn1962" class="csl-entry" role="listitem">
Kuhn, Thomas. 1962. <span>“The Structure of Scientific
Revolutions.”</span> <em>International Encyclopedia of Unified
Science</em> 2 (2).
</div>
<div id="ref-kulveit2025" class="csl-entry" role="listitem">
Kulveit, Jan, Raymond Douglas, Nora Ammann, Deger Turan, David Krueger,
and David Duvenaud. 2025. <span>“Gradual <span>Disempowerment</span>:
<span>Systemic Existential Risks</span> from <span>Incremental AI
Development</span>.”</span> January 29, 2025. <a href="https://doi.org/10.48550/arXiv.2501.16946">https://doi.org/10.48550/arXiv.2501.16946</a>.
</div>
<div id="ref-kumar2019a" class="csl-entry" role="listitem">
Kumar, Ram Shankar Siva, David O. Brien, Kendra Albert, Salomé Viljöen,
and Jeffrey Snover. 2019a. <span>“Failure Modes in Machine Learning
Systems.”</span> <a href="https://arxiv.org/abs/1911.11034">https://arxiv.org/abs/1911.11034</a>.
</div>
<div id="ref-kumar2019" class="csl-entry" role="listitem">
Kumar, Ram Shankar Siva, David O Brien, Kendra Albert, Salomé Viljöen,
and Jeffrey Snover. 2019b. <span>“Failure <span>Modes</span> in
<span>Machine Learning Systems</span>.”</span> 2019. <a href="https://doi.org/10.48550/ARXIV.1911.11034">https://doi.org/10.48550/ARXIV.1911.11034</a>.
</div>
<div id="ref-lempert2003" class="csl-entry" role="listitem">
Lempert, Robert J, Steven W Popper, and Steven C Bankes. 2003.
<em>Shaping the Next One Hundred Years: <span>New</span> Methods for
Quantitative, Long-Term Policy Analysis</em>. RAND Corporation.
</div>
<div id="ref-lindley2013" class="csl-entry" role="listitem">
Lindley, Dennis V. 2013. <em>Understanding Uncertainty</em>. John Wiley
&amp; Sons. <a href="https://books.google.ca/books?hl=en&amp;lr=&amp;id=Tfk8AgAAQBAJ&amp;oi=fnd&amp;pg=PR11&amp;dq=Lindley,+D.+(2006).+Understanding+Uncertainty&amp;ots=55HS6lTOVP&amp;sig=0gKCDvRu5rUKhuPyJqhOzW23upU">https://books.google.ca/books?hl=en&amp;lr=&amp;id=Tfk8AgAAQBAJ&amp;oi=fnd&amp;pg=PR11&amp;dq=Lindley,+D.+(2006).+Understanding+Uncertainty&amp;ots=55HS6lTOVP&amp;sig=0gKCDvRu5rUKhuPyJqhOzW23upU</a>.
</div>
<div id="ref-list2011" class="csl-entry" role="listitem">
List, Christian, and Philip Pettit. 2011. <em>Group <span>Agency</span>:
<span>The Possibility</span>, <span>Design</span>, and
<span>Status</span> of <span>Corporate Agents</span></em>. Oxford
University Press.
</div>
<div id="ref-lumina2025" class="csl-entry" role="listitem">
Lumina, Decision Systems. 2025. <span>“Analytica
<span>Online</span>.”</span> 2025. <a href="https://acp.analytica.com/view0?invite=4560&amp;code=3000289064591444815">https://acp.analytica.com/view0?invite=4560&amp;code=3000289064591444815</a>.
</div>
<div id="ref-manheim2021" class="csl-entry" role="listitem">
Manheim, David. 2021. <span>“Modeling <span>Transformative AI
Risk</span> (<span>MTAIR</span>) - <span>LessWrong</span>.”</span> July
28, 2021. <a href="https://www.lesswrong.com/s/aERZoriyHfCqvWkzg">https://www.lesswrong.com/s/aERZoriyHfCqvWkzg</a>.
</div>
<div id="ref-martin2023" class="csl-entry" role="listitem">
Martin, Sammy, Lonnie Chrisman, and Aryeh Englander. 2023. <span>“A
<span class="nocase">Model-based Approach</span> to <span>AI Existential
Risk</span>,”</span> August. <a href="https://www.lesswrong.com/posts/sGkRDrpphsu6Jhega/a-model-based-approach-to-ai-existential-risk">https://www.lesswrong.com/posts/sGkRDrpphsu6Jhega/a-model-based-approach-to-ai-existential-risk</a>.
</div>
<div id="ref-martin2021" class="csl-entry" role="listitem">
Martin, Sammy, and Daniel Eth. 2021. <span>“Takeoff <span>Speeds</span>
and <span>Discontinuities</span>,”</span> September. <a href="https://www.lesswrong.com/posts/pGXR2ynhe5bBCCNqn/takeoff-speeds-and-discontinuities">https://www.lesswrong.com/posts/pGXR2ynhe5bBCCNqn/takeoff-speeds-and-discontinuities</a>.
</div>
<div id="ref-maslej2025" class="csl-entry" role="listitem">
Maslej, Nestor. 2025. <span>“Artificial <span>Intelligence Index
Report</span> 2025.”</span> <em>Artificial Intelligence</em>.
</div>
<div id="ref-mccaslin2024" class="csl-entry" role="listitem">
McCaslin, Tegan, Josh Rosenberg, Ezra Karger, Avital Morris, Molly
Hickman, Sam Glover, Zach Jacobs, and Phil Tetlock. 2024.
<span>“Conditional <span>Trees</span>: <span>A Method</span> for
<span>Generating Informative Questions</span> about <span>Complex
Topics</span>.”</span> <em>Forecasting Research Institute</em>. <a href="https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/66ba37a144f1d6095de467df/1723479995772/AIConditionalTrees.pdf">https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/66ba37a144f1d6095de467df/1723479995772/AIConditionalTrees.pdf</a>.
</div>
<div id="ref-metropolitansky2025" class="csl-entry" role="listitem">
Metropolitansky, Dasha, and Jonathan Larson. 2025. <span>“Towards
<span>Effective Extraction</span> and <span>Evaluation</span> of
<span>Factual Claims</span>.”</span> February 15, 2025. <a href="https://doi.org/10.48550/arXiv.2502.10855">https://doi.org/10.48550/arXiv.2502.10855</a>.
</div>
<div id="ref-meyer2022b" class="csl-entry" role="listitem">
Meyer, Valentin Jakob. 2022. <span>“A <span>Structure</span> of
<span>Knowledge</span> &amp; the <span>Process</span> of
<span>Science</span>.”</span> <em>Philosophy of the Social Sciences</em>
First Course Paper. https://doi.org/<a href="https://www.vjmeyer.com/papers/essays">https://www.vjmeyer.com/papers/essays</a>.
</div>
<div id="ref-miotti2024" class="csl-entry" role="listitem">
Miotti, Andrea, Tolga Bilge, Dave Kasten, and James Newport. 2024.
<span>“A <span>Narrow Path</span>.”</span> <a href="https://www.narrowpath.co/">https://www.narrowpath.co/</a>.
</div>
<div id="ref-nelson2006" class="csl-entry" role="listitem">
Nelson, Roger B. 2006. <em>An <span>Introduction</span> to
<span>Copulas</span></em>. Springer <span>Series</span> in
<span>Statistics</span>. New York, NY: Springer New York. <a href="https://doi.org/10.1007/0-387-28678-0">https://doi.org/10.1007/0-387-28678-0</a>.
</div>
<div id="ref-ngajie2020" class="csl-entry" role="listitem">
Ngajie, Berty Nsolly, Yan Li, Dawit Tibebu Tiruneh, and Mengmeng Cheng.
2020. <span>“Investigating the Effects of a Systematic and Model-Based
Design of Computer-Supported Argument Visualization on Critical
Thinking.”</span> <em>Thinking Skills and Creativity</em> 38: 100742. <a href="https://www.sciencedirect.com/science/article/pii/S1871187120302169">https://www.sciencedirect.com/science/article/pii/S1871187120302169</a>.
</div>
<div id="ref-paul2023" class="csl-entry" role="listitem">
Paul. 2023. <span>“The <span class="nocase">elephAInt</span> –
<span>Are</span> We All Like the Six Blind Men When It Comes to
<span>AI</span>? | <span>PRISMAGuard LLC</span>.”</span> 2023. <a href="https://www.prismaguard.com/the-elephaint-are-we-all-like-the-six-blind-men-when-it-comes-to-ai/">https://www.prismaguard.com/the-elephaint-are-we-all-like-the-six-blind-men-when-it-comes-to-ai/</a>.
</div>
<div id="ref-pearl2000" class="csl-entry" role="listitem">
Pearl, Judea. 2000. <em>Causality: Models, Reasoning, and
Inference</em>. Cambridge, U.K. ; New York: Cambridge University Press.
</div>
<div id="ref-pearl2009" class="csl-entry" role="listitem">
———. 2009. <em>Causality: <span>Models</span>, Reasoning and
Inference</em>. 2nd ed. Cambridge University Press.
</div>
<div id="ref-pearl2014" class="csl-entry" role="listitem">
———. 2014. <em>Probabilistic Reasoning in Intelligent Systems: Networks
of Plausible Inference</em>. Elsevier. <a href="https://books.google.ca/books?hl=en&amp;lr=&amp;id=mn2jBQAAQBAJ&amp;oi=fnd&amp;pg=PP1&amp;dq=Pearl,+J.+(1988).+Probabilistic+Reasoning+in+Intelligent+Systems&amp;ots=4tEX2A4Ha8&amp;sig=lgUs_RCoeXEEuGwM5xMEoyJy4HI">https://books.google.ca/books?hl=en&amp;lr=&amp;id=mn2jBQAAQBAJ&amp;oi=fnd&amp;pg=PP1&amp;dq=Pearl,+J.+(1988).+Probabilistic+Reasoning+in+Intelligent+Systems&amp;ots=4tEX2A4Ha8&amp;sig=lgUs_RCoeXEEuGwM5xMEoyJy4HI</a>.
</div>
<div id="ref-pollock1995" class="csl-entry" role="listitem">
Pollock, John L. 1995. <em>Cognitive Carpentry: <span>A</span> Blueprint
for How to Build a Person</em>. Mit Press. <a href="https://books.google.ca/books?hl=en&amp;lr=&amp;id=JAfHrHTqswAC&amp;oi=fnd&amp;pg=PA1&amp;dq=Pollock,+J.+(1995).+Cognitive+Carpentry&amp;ots=rq-qSCBcxV&amp;sig=aAfHGsGUosxl_1-JuxIEA7C2QO4">https://books.google.ca/books?hl=en&amp;lr=&amp;id=JAfHrHTqswAC&amp;oi=fnd&amp;pg=PA1&amp;dq=Pollock,+J.+(1995).+Cognitive+Carpentry&amp;ots=rq-qSCBcxV&amp;sig=aAfHGsGUosxl_1-JuxIEA7C2QO4</a>.
</div>
<div id="ref-prokudin2024" class="csl-entry" role="listitem">
Prokudin, D. E., E. N. Lisanyuk, and I. R. Baymuratov. 2024.
<span>“Visualization <span>Functions</span> in <span>Argumentation
Representation Software</span>.”</span> <em>Scientific
Visualization</em> 16 (3). <a href="https://sv-journal.org/2024-3/11/en.pdf">https://sv-journal.org/2024-3/11/en.pdf</a>.
</div>
<div id="ref-rehman2025" class="csl-entry" role="listitem">
Rehman, Iskander. 2025. <span>“The <span>Battle</span> for
<span>Brilliant Minds</span>: <span>From</span> the <span>Nuclear
Age</span> to <span>AI</span>.”</span> War on the Rocks. January 13,
2025. <a href="https://warontherocks.com/2025/01/the-battle-for-brilliant-minds-from-the-nuclear-age-to-ai/">https://warontherocks.com/2025/01/the-battle-for-brilliant-minds-from-the-nuclear-age-to-ai/</a>.
</div>
<div id="ref-rice2021" class="csl-entry" role="listitem">
Rice, Issa, and Sammy Martin. 2021. <span>“Analogies and <span>General
Priors</span> on <span>Intelligence</span>,”</span> August. <a href="https://www.lesswrong.com/posts/yFQkFNCszoJPZTnK6/analogies-and-general-priors-on-intelligence">https://www.lesswrong.com/posts/yFQkFNCszoJPZTnK6/analogies-and-general-priors-on-intelligence</a>.
</div>
<div id="ref-russell2015" class="csl-entry" role="listitem">
Russell, Stuart, Tom Dietterich, Eric Horvitz, Bart Selman, Francesca
Rossi, Demis Hassabis, Shane Legg, et al. 2015. <span>“Research
Priorities for Robust and Beneficial Artificial Intelligence:
<span>An</span> Open Letter.”</span> <em>AI Magazine</em> 36 (4): 3–4.
<a href="https://doi.org/10.1609/aimag.v36i4.2621">https://doi.org/10.1609/aimag.v36i4.2621</a>.
</div>
<div id="ref-samborska2025" class="csl-entry" role="listitem">
Samborska, Veronika. 2025. <span>“Scaling up: How Increasing Inputs Has
Made Artificial Intelligence More Capable.”</span> <em>Our World in
Data</em>, January. <a href="https://ourworldindata.org/scaling-up-ai">https://ourworldindata.org/scaling-up-ai</a>.
</div>
<div id="ref-samuel2023" class="csl-entry" role="listitem">
Samuel, Sigal. 2023. <span>“<span>AI</span> Is a <span>‘Tragedy of the
Commons.’</span> <span>We</span>’ve Got Solutions for That.”</span> Vox.
July 7, 2023. <a href="https://www.vox.com/future-perfect/2023/7/7/23787011/ai-arms-race-tragedy-commons-risk-safety">https://www.vox.com/future-perfect/2023/7/7/23787011/ai-arms-race-tragedy-commons-risk-safety</a>.
</div>
<div id="ref-schelling1960" class="csl-entry" role="listitem">
Schelling, Thomas C. 1960. <span>“I960. <span>The</span> Strategy of
Conflict.”</span> <em>Cambridge, Mass</em>.
</div>
<div id="ref-scheuer2010" class="csl-entry" role="listitem">
Scheuer, Oliver, Frank Loll, Niels Pinkwart, and Bruce M. McLaren. 2010.
<span>“Computer-Supported Argumentation: <span>A</span> Review of the
State of the Art.”</span> <em>International Journal of
Computer-Supported Collaborative Learning</em> 5 (1): 43–102. <a href="https://doi.org/10.1007/s11412-009-9080-x">https://doi.org/10.1007/s11412-009-9080-x</a>.
</div>
<div id="ref-solomon2020" class="csl-entry" role="listitem">
Solomon, Jill. 2020. <em>Corporate Governance and Accountability</em>.
John Wiley &amp; Sons. <a href="https://books.google.ca/books?hl=en&amp;lr=&amp;id=JAX9DwAAQBAJ&amp;oi=fnd&amp;pg=PR1&amp;dq=review+of+the+effects+of+liability+frameworks+on+corporate+governance+&amp;ots=ny23_vd-U0&amp;sig=3LuNNhvSWXriEeg-ipAdDIQGAgo">https://books.google.ca/books?hl=en&amp;lr=&amp;id=JAX9DwAAQBAJ&amp;oi=fnd&amp;pg=PR1&amp;dq=review+of+the+effects+of+liability+frameworks+on+corporate+governance+&amp;ots=ny23_vd-U0&amp;sig=3LuNNhvSWXriEeg-ipAdDIQGAgo</a>.
</div>
<div id="ref-sotala2018" class="csl-entry" role="listitem">
Sotala, Kaj. 2018. <span>“Disjunctive <span>Scenarios</span> of
<span>Catastrophic AI Risk</span>.”</span> In <em>Artificial
<span>Intelligence Safety</span> and <span>Security</span></em>, edited
by Roman V. Yampolskiy, 1st ed., 315–37. First edition. | Boca Raton, FL
: CRC Press/Taylor &amp; Francis Group, 2018.: <span>Chapman and
Hall/CRC</span>. <a href="https://doi.org/10.1201/9781351251389-22">https://doi.org/10.1201/9781351251389-22</a>.
</div>
<div id="ref-squires2023" class="csl-entry" role="listitem">
Squires, Chandler, and Caroline Uhler. 2023. <span>“Causal
<span>Structure Learning</span>: <span>A Combinatorial
Perspective</span>.”</span> <em>Foundations of Computational
Mathematics</em> 23 (5): 1781–1815. <a href="https://doi.org/10.1007/s10208-022-09581-9">https://doi.org/10.1007/s10208-022-09581-9</a>.
</div>
<div id="ref-tegmark2024" class="csl-entry" role="listitem">
Tegmark, Max. 2024. <span>“Asilomar <span>AI Principles</span>.”</span>
Future of Life Institute. 2024. <a href="https://futureoflife.org/open-letter/ai-principles/">https://futureoflife.org/open-letter/ai-principles/</a>.
</div>
<div id="ref-tetlock2022" class="csl-entry" role="listitem">
Tetlock, Phil. 2022. <span>“Conditional <span>Trees</span>: <span>AI
Risk</span>.”</span> 2022. <a href="https://www.metaculus.com/tournament/3508/">https://www.metaculus.com/tournament/3508/</a>.
</div>
<div id="ref-tetlock2015" class="csl-entry" role="listitem">
Tetlock, Philip E., and Dan Gardner. 2015. <em>Superforecasting: The Art
and Science of Prediction</em>. First paperback edition. New York:
Broadway Books.
</div>
<div id="ref-todd2024" class="csl-entry" role="listitem">
Todd, Benjamin. 2024. <span>“It Looks Like There Are Some Good Funding
Opportunities in <span>AI</span> Safety Right Now.”</span> Substack
newsletter. Benjamin Todd. December 21, 2024. <a href="https://benjamintodd.substack.com/p/looks-like-there-are-some-good-funding">https://benjamintodd.substack.com/p/looks-like-there-are-some-good-funding</a>.
</div>
<div id="ref-voigt2025" class="csl-entry" role="listitem">
Voigt, Christian. (2014) 2025. <span>“Christianvoigt/Argdown.”</span> <a href="https://github.com/christianvoigt/argdown">https://github.com/christianvoigt/argdown</a>.
</div>
<div id="ref-walton2009" class="csl-entry" role="listitem">
Walton, Douglas. 2009. <span>“Argument Visualization Tools for
Corroborative Evidence.”</span> In <em>Proc. Of the 2nd
<span>International Conference</span> on <span>Evidence Law</span> and
<span>Forensic Science</span></em>, 32–49. <a href="https://www.academia.edu/download/37718171/09ArguVis.pdf">https://www.academia.edu/download/37718171/09ArguVis.pdf</a>.
</div>
<div id="ref-wilson2023" class="csl-entry" role="listitem">
Wilson, Nick, Matt Boyd, John Kerr, Amanda Kvalsvig, and Michael Baker.
2023. <span>“The Need for Long-Term Thinking–<span>Especially</span> for
Preventing Catastrophic Risks.”</span> <em>Public Health Expert
Briefing</em>.
</div>
<div id="ref-yang2022" class="csl-entry" role="listitem">
Yang, Jie, Soyeon Caren Han, and Josiah Poon. 2022. <span>“A Survey on
Extraction of Causal Relations from Natural Language Text.”</span>
<em>Knowledge and Information Systems</em> 64 (5): 1161–86. <a href="https://doi.org/10.1007/s10115-022-01665-w">https://doi.org/10.1007/s10115-022-01665-w</a>.
</div>
<div id="ref-yudkowsky2008" class="csl-entry" role="listitem">
Yudkowsky, Eliezer. 2008. <span>“Artificial <span>Intelligence</span> as
a Positive and Negative Factor in Global Risk.”</span> In <em>Global
<span>Catastrophic Risks</span></em>, by Eliezer Yudkowsky. Oxford
University Press. <a href="https://doi.org/10.1093/oso/9780198570509.003.0021">https://doi.org/10.1093/oso/9780198570509.003.0021</a>.
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/Outlines/Outline_13.html" class="pagination-link" aria-label="Automating the Modeling of Transformative Artificial Intelligence Risks (AMTAIR)">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Automating the Modeling of Transformative Artificial Intelligence Risks (AMTAIR)</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/VJMeyer/submission/edit/main/ref/references.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></div></div></footer></body></html>