<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.29">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>4&nbsp; AMTAIR – Automating the Modelling of Transformative Artificial Intelligence Risks</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/4.Discussion.html" rel="next">
<link href="../chapters/2.0.Context.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-0815c480559380816a4d1ea211a47e91.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-485d01fc63b59abcd3ee1bf1e8e2748d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/3.0.AMTAIR.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">AMTAIR</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Automating the Modelling of Transformative Artificial Intelligence Risks</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/VJMeyer/submission" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="../Automating-the-Modelling-of-Transformative-Artificial-Intelligence-Risks.pdf">
              <i class="bi bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="../Automating-the-Modelling-of-Transformative-Artificial-Intelligence-Risks.epub">
              <i class="bi bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-1" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-1">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/0.Frontmatter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Remaining Edits</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/1.Introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/2.0.Context.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Context &amp; Background</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/3.0.AMTAIR.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">AMTAIR</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/4.Discussion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Discussion</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/5.Conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Conclusion</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ref/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">References (.md)</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/I.Appendices.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Appendices</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title"></span></span></a><a href="https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr">AMTAIR Prototype Demonstration (Public Colab Notebook)</a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-amtair-implementation" id="toc-sec-amtair-implementation" class="nav-link active" data-scroll-target="#sec-amtair-implementation"><span class="header-section-number">4.1</span> AMTAIR Implementation</a></li>
  <li><a href="#sec-software-implementation" id="toc-sec-software-implementation" class="nav-link" data-scroll-target="#sec-software-implementation"><span class="header-section-number">4.2</span> Software Implementation</a>
  <ul>
  <li><a href="#sec-system-architecture" id="toc-sec-system-architecture" class="nav-link" data-scroll-target="#sec-system-architecture"><span class="header-section-number">4.2.1</span> System Architecture and Data Flow</a>
  <ul>
  <li><a href="#sec-five-stage-pipeline" id="toc-sec-five-stage-pipeline" class="nav-link" data-scroll-target="#sec-five-stage-pipeline"><span class="header-section-number">4.2.1.1</span> Five-Stage Pipeline</a></li>
  <li><a href="#sec-modular-design" id="toc-sec-modular-design" class="nav-link" data-scroll-target="#sec-modular-design"><span class="header-section-number">4.2.1.2</span> Modular Design Principles</a></li>
  </ul></li>
  <li><a href="#sec-rain-sprinkler-grass" id="toc-sec-rain-sprinkler-grass" class="nav-link" data-scroll-target="#sec-rain-sprinkler-grass"><span class="header-section-number">4.2.2</span> Rain-Sprinkler-Grass Example Implementation</a></li>
  <li><a href="#sec-carlsmith-implementation" id="toc-sec-carlsmith-implementation" class="nav-link" data-scroll-target="#sec-carlsmith-implementation"><span class="header-section-number">4.2.3</span> Carlsmith Implementation</a>
  <ul>
  <li><a href="#sec-carlsmith-complexity" id="toc-sec-carlsmith-complexity" class="nav-link" data-scroll-target="#sec-carlsmith-complexity"><span class="header-section-number">4.2.3.1</span> Model Complexity and Scope</a></li>
  <li><a href="#sec-carlsmith-variables" id="toc-sec-carlsmith-variables" class="nav-link" data-scroll-target="#sec-carlsmith-variables"><span class="header-section-number">4.2.3.2</span> Key Variables and Relationships</a></li>
  <li><a href="#sec-carlsmith-bayesdown" id="toc-sec-carlsmith-bayesdown" class="nav-link" data-scroll-target="#sec-carlsmith-bayesdown"><span class="header-section-number">4.2.3.3</span> Advanced BayesDown Representation</a></li>
  <li><a href="#sec-carlsmith-sensitivity" id="toc-sec-carlsmith-sensitivity" class="nav-link" data-scroll-target="#sec-carlsmith-sensitivity"><span class="header-section-number">4.2.3.4</span> Sensitivity Analysis Results</a></li>
  </ul></li>
  <li><a href="#sec-inference-extensions" id="toc-sec-inference-extensions" class="nav-link" data-scroll-target="#sec-inference-extensions"><span class="header-section-number">4.2.4</span> Inference &amp; Extensions</a>
  <ul>
  <li><a href="#sec-inference-engine" id="toc-sec-inference-engine" class="nav-link" data-scroll-target="#sec-inference-engine"><span class="header-section-number">4.2.4.1</span> Probabilistic Inference Engine</a></li>
  <li><a href="#sec-policy-evaluation" id="toc-sec-policy-evaluation" class="nav-link" data-scroll-target="#sec-policy-evaluation"><span class="header-section-number">4.2.4.2</span> Policy Evaluation Interface</a></li>
  <li><a href="#sec-extensions" id="toc-sec-extensions" class="nav-link" data-scroll-target="#sec-extensions"><span class="header-section-number">4.2.4.3</span> Extensions and Future Capabilities</a></li>
  </ul></li>
  <li><a href="#post-text" id="toc-post-text" class="nav-link" data-scroll-target="#post-text"><span class="header-section-number">4.2.5</span> post text</a></li>
  </ul></li>
  <li><a href="#sec-results" id="toc-sec-results" class="nav-link" data-scroll-target="#sec-results"><span class="header-section-number">4.3</span> Results</a>
  <ul>
  <li><a href="#sec-extraction-quality" id="toc-sec-extraction-quality" class="nav-link" data-scroll-target="#sec-extraction-quality"><span class="header-section-number">4.3.1</span> Extraction Quality Assessment</a>
  <ul>
  <li><a href="#sec-performance-metrics" id="toc-sec-performance-metrics" class="nav-link" data-scroll-target="#sec-performance-metrics"><span class="header-section-number">4.3.1.1</span> Performance Metrics</a></li>
  </ul></li>
  <li><a href="#sec-computational-performance" id="toc-sec-computational-performance" class="nav-link" data-scroll-target="#sec-computational-performance"><span class="header-section-number">4.3.2</span> Computational Performance Analysis</a>
  <ul>
  <li><a href="#sec-scaling-characteristics" id="toc-sec-scaling-characteristics" class="nav-link" data-scroll-target="#sec-scaling-characteristics"><span class="header-section-number">4.3.2.1</span> Scaling Characteristics</a></li>
  </ul></li>
  <li><a href="#sec-carlsmith-case-study" id="toc-sec-carlsmith-case-study" class="nav-link" data-scroll-target="#sec-carlsmith-case-study"><span class="header-section-number">4.3.3</span> Case Study: The Carlsmith Model Formalized</a>
  <ul>
  <li><a href="#sec-carlsmith-case-study-2" id="toc-sec-carlsmith-case-study-2" class="nav-link" data-scroll-target="#sec-carlsmith-case-study-2"><span class="header-section-number">4.3.3.1</span> Case Study: Formalized Carlsmith Model</a></li>
  </ul></li>
  <li><a href="#sec-comparative-analysis" id="toc-sec-comparative-analysis" class="nav-link" data-scroll-target="#sec-comparative-analysis"><span class="header-section-number">4.3.4</span> Comparative Analysis of AI Governance Worldviews</a>
  <ul>
  <li><a href="#sec-multi-perspective" id="toc-sec-multi-perspective" class="nav-link" data-scroll-target="#sec-multi-perspective"><span class="header-section-number">4.3.4.1</span> Multi-Perspective Analysis Results</a></li>
  <li><a href="#sec-consensus-disagreement" id="toc-sec-consensus-disagreement" class="nav-link" data-scroll-target="#sec-consensus-disagreement"><span class="header-section-number">4.3.4.2</span> Consensus and Disagreement Mapping</a></li>
  <li><a href="#sec-policy-robustness" id="toc-sec-policy-robustness" class="nav-link" data-scroll-target="#sec-policy-robustness"><span class="header-section-number">4.3.4.3</span> Policy Robustness Analysis</a></li>
  </ul></li>
  <li><a href="#sec-policy-impact" id="toc-sec-policy-impact" class="nav-link" data-scroll-target="#sec-policy-impact"><span class="header-section-number">4.3.5</span> Policy Impact Evaluation: Proof of Concept</a></li>
  <li><a href="#post-text-1" id="toc-post-text-1" class="nav-link" data-scroll-target="#post-text-1"><span class="header-section-number">4.3.6</span> post text</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/VJMeyer/submission/edit/main/chapters/3.0.AMTAIR.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div><div class="quarto-code-links"><h2>Code Links</h2><ul><li><a href="https://colab.research.google.com/github/VJMeyer/submission/blob/main/AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb"><i class="bi bi-file-code"></i>Colab Notebook (Manual Link in .yml)</a></li><li><a href="https://github.com/VJMeyer/submission"><i class="bi bi-github"></i>GitHub Repository</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">AMTAIR</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
20% of Grade: ~ 29% of text ~ 8700 words ~ 20 pages
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>provides critical or constructive evaluation of positions introduced</p></li>
<li><p>develops strong (plausible) argument in support of author’s own position/thesis</p></li>
<li><p>argument draws on relevant course material claim/argument</p></li>
<li><p>demonstrate understanding of the course materials incl.&nbsp;key arguments and core concepts within the debate</p></li>
<li><p>claim/argument is original or insightful, possibly even presents an original contribution to the debate</p></li>
</ul>
</div>
</div>
<section id="sec-amtair-implementation" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="sec-amtair-implementation"><span class="header-section-number">4.1</span> AMTAIR Implementation</h2>
<!-- [ ] Expand this section to ~29% of total text (approximately 8700 words) -->
<!-- provides critical or constructive evaluation of positions introduced -->
<!-- develops strong (plausible) argument in support of author's own position/thesis -->
<!-- argument draws on relevant course material -->
<!-- demonstrates understanding of course materials and key concepts -->
<!-- presents original or insightful contribution to the debate -->
<p>Text to render</p>
<!-- ## Own Carlsmith Model Implementation — Explanation -->
<!-- ## Own Implementation: Good example from a published paper -->
</section>
<section id="sec-software-implementation" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="sec-software-implementation"><span class="header-section-number">4.2</span> Software Implementation</h2>
<section id="sec-system-architecture" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="sec-system-architecture"><span class="header-section-number">4.2.1</span> System Architecture and Data Flow</h3>
<!-- [ ] Present the overall architecture of AMTAIR, showing how different components interact -->
<!-- [ ] Explain the data pipeline from extraction through modeling to visualization and policy evaluation -->
<blockquote class="blockquote">
<p>The AMTAIR system implements an end-to-end pipeline from unstructured text to interactive Bayesian network visualization. Its modular architecture comprises five main components that progressively transform information from natural language into formal models.</p>
</blockquote>
<p>`Core system components include:</p>
<ol type="1">
<li>Text Ingestion and Preprocessing: Handles format normalization, metadata extraction, and relevance filtering</li>
<li>BayesDown Extraction: Identifies argument structures, causal relationships, and probabilistic judgments</li>
<li>Structured Data Transformation: Parses representations into standardized data formats</li>
<li>Bayesian Network Construction: Creates formal network representations with nodes and edges</li>
<li>Interactive Visualization: Renders networks as explorable visual interfaces`</li>
</ol>
<!-- 
[![AMTAIR Automation Pipeline](/images/pipeline.png){#fig-automation_pipeline fig-scap="Five-step AMTAIR automation pipeline from PDFs to Bayesian networks" fig-alt="FLOWCHART: Five-step automation pipeline workflow for AMTAIR project." fig-align="center" width="100%"}](https://claude.ai/chat/ab8988f3-18b7-45a5-8a50-b25aa4b34cbf) 
-->
<!-- [ ] Present overall architecture showing component interactions -->
<section id="sec-five-stage-pipeline" class="level4" data-number="4.2.1.1">
<h4 data-number="4.2.1.1" class="anchored" data-anchor-id="sec-five-stage-pipeline"><span class="header-section-number">4.2.1.1</span> Five-Stage Pipeline</h4>
<p><strong>Stage 1: Document Ingestion</strong></p>
<ul>
<li>Format normalization (PDF, HTML, Markdown)</li>
<li>Metadata extraction and citation tracking</li>
<li>Content preprocessing and structure identification</li>
</ul>
<p><strong>Stage 2: BayesDown Extraction</strong></p>
<ul>
<li>Argument structure identification using ArgDown syntax</li>
<li>Probabilistic information extraction and quantification</li>
<li>Quality validation and expert review integration</li>
</ul>
<p><strong>Stage 3: Structured Data Transformation</strong></p>
<ul>
<li>Parsing BayesDown into relational format</li>
<li>Network topology validation and cycle detection</li>
<li>Probability distribution completeness verification</li>
</ul>
<p><strong>Stage 4: Bayesian Network Construction</strong></p>
<ul>
<li>Mathematical model instantiation using NetworkX</li>
<li>Parameter estimation and validation</li>
<li>Network metrics computation (centrality, connectivity)</li>
</ul>
<p><strong>Stage 5: Interactive Visualization</strong></p>
<ul>
<li>Dynamic network rendering with PyVis</li>
<li>Probability-based color coding and visual encoding</li>
<li>Interactive exploration and analysis interface</li>
</ul>
<p><strong>Modular Pipeline Architecture:</strong></p>
<p><code>The AMTAIR system implements a five-stage pipeline from unstructured text to interactive Bayesian network visualization, with each component designed for independent improvement and validation.</code></p>
<p><strong>Core System Components:</strong></p>
<ol type="1">
<li><strong>Text Ingestion and Preprocessing</strong>: Format normalization (PDF, HTML, Markdown), metadata extraction, citation tracking</li>
<li><strong>BayesDown Extraction</strong>: Two-stage argument structure identification and probabilistic information integration</li>
<li><strong>Structured Data Transformation</strong>: Parsing into standardized relational formats with validation</li>
<li><strong>Bayesian Network Construction</strong>: Mathematical model instantiation using NetworkX and pgmpy</li>
<li><strong>Interactive Visualization</strong>: Dynamic rendering with PyVis and probability-based visual encoding</li>
</ol>
<pre><code>python
class AMTAIRPipeline:
    def __init__(self):
        self.ingestion = DocumentIngestion()
        self.extraction = BayesDownExtractor() 
        self.transformation = DataTransformer()
        self.network_builder = BayesianNetworkBuilder()
        self.visualizer = InteractiveVisualizer()
    
    def process(self, document):
        """End-to-end processing from document to interactive model"""
        structured_data = self.ingestion.preprocess(document)
        bayesdown = self.extraction.extract(structured_data)
        dataframe = self.transformation.convert(bayesdown)
        network = self.network_builder.construct(dataframe)
        return self.visualizer.render(network)</code></pre>
<p><strong>Design Principles for Scalability:</strong></p>
<ul>
<li><strong>Modular Architecture</strong>: Each component can be improved independently without system-wide changes</li>
<li><strong>Standard Interfaces</strong>: JSON and CSV intermediate formats enable interoperability and debugging</li>
<li><strong>Validation Checkpoints</strong>: Quality gates at each stage prevent error propagation</li>
<li><strong>Extensible Framework</strong>: Additional analysis capabilities can be integrated without core changes</li>
</ul>
</section>
<section id="sec-modular-design" class="level4" data-number="4.2.1.2">
<h4 data-number="4.2.1.2" class="anchored" data-anchor-id="sec-modular-design"><span class="header-section-number">4.2.1.2</span> Modular Design Principles</h4>
<pre><code>python
class AMTAIRPipeline:
    def __init__(self):
        self.ingestion = DocumentIngestion()
        self.extraction = BayesDownExtractor() 
        self.transformation = DataTransformer()
        self.network_builder = BayesianNetworkBuilder()
        self.visualizer = InteractiveVisualizer()</code></pre>
</section>
</section>
<section id="sec-rain-sprinkler-grass" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="sec-rain-sprinkler-grass"><span class="header-section-number">4.2.2</span> Rain-Sprinkler-Grass Example Implementation</h3>
<!-- [ ] Demonstrate the pipeline using the canonical Rain-Sprinkler-Lawn example -->
<!-- [ ] Provide a detailed walkthrough of each transformation stage -->
<blockquote class="blockquote">
<p>The Rain-Sprinkler-Grass example serves as a canonical test case demonstrating each step in the AMTAIR pipeline. This simple causal scenario—where both rain and sprinkler use can cause wet grass, and rain influences sprinkler use—provides an intuitive introduction to Bayesian network concepts while exercising all system components.</p>
</blockquote>
<p>`The implementation walkthrough includes:</p>
<ol type="1">
<li>Source representation in natural language</li>
<li>Extraction to ArgDown format with structural relationships</li>
<li>Enhancement to BayesDown with probability information</li>
<li>Transformation into structured data tables</li>
<li>Construction of the Bayesian network</li>
<li>Interactive visualization with probability encoding`</li>
</ol>
<pre><code>{=python}
# Example code snippet demonstrating network construction
def create_bayesian_network_with_probabilities(df):
    """Create an interactive Bayesian network visualization with probability encoding"""
    # Create a directed graph
    G = nx.DiGraph()
    
    # Add nodes with proper attributes
    for idx, row in df.iterrows():
        title = row['Title']
        description = row['Description']
        
        # Process probability information
        priors = get_priors(row)
        instantiations = get_instantiations(row)
        
        # Add node with base information
        G.add_node(
            title,
            description=description,
            priors=priors,
            instantiations=instantiations,
            posteriors=get_posteriors(row)
        )
    
    # [Additional implementation details...]</code></pre>
<!-- [ ] Demonstrate pipeline using canonical example with detailed walkthrough -->
<p><strong>Canonical Test Case Validation:</strong></p>
<p><code>The Rain-Sprinkler-Grass example serves as a fundamental validation case, providing known ground truth for testing each component of the AMTAIR pipeline while demonstrating core Bayesian network concepts.</code></p>
<p><strong>Complete Pipeline Demonstration:</strong></p>
<p><strong>Stage 1: BayesDown Input Representation</strong></p>
<pre><code>[Grass_Wet]: Concentrated moisture on, between and around the blades of grass. 
{"instantiations": ["grass_wet_TRUE", "grass_wet_FALSE"], 
 "priors": {"p(grass_wet_TRUE)": "0.322", "p(grass_wet_FALSE)": "0.678"},
 "posteriors": {
   "p(grass_wet_TRUE|sprinkler_TRUE,rain_TRUE)": "0.99",
   "p(grass_wet_TRUE|sprinkler_TRUE,rain_FALSE)": "0.9",
   "p(grass_wet_TRUE|sprinkler_FALSE,rain_TRUE)": "0.8", 
   "p(grass_wet_TRUE|sprinkler_FALSE,rain_FALSE)": "0.0"
 }}
 + [Rain]: Tears of angels crying high up in the skies hitting the ground.
   {"instantiations": ["rain_TRUE", "rain_FALSE"],
    "priors": {"p(rain_TRUE)": "0.2", "p(rain_FALSE)": "0.8"}}
 + [Sprinkler]: Activation of a centrifugal force based CO2 droplet distribution system.
   {"instantiations": ["sprinkler_TRUE", "sprinkler_FALSE"], 
    "priors": {"p(sprinkler_TRUE)": "0.44838", "p(sprinkler_FALSE)": "0.55162"},
    "posteriors": {
      "p(sprinkler_TRUE|rain_TRUE)": "0.01",
      "p(sprinkler_TRUE|rain_FALSE)": "0.4"
    }}
   + [Rain]</code></pre>
<p><strong>Stage 2: Automated Parsing and Data Extraction</strong></p>
<p><strong>Core Parsing Function</strong>:</p>
<pre><code>python
def parse_markdown_hierarchy_fixed(markdown_text, ArgDown=False):
    """Parse ArgDown or BayesDown format into structured DataFrame"""
    # Remove comments and clean text
    clean_text = remove_comments(markdown_text)
    
    # Extract titles, descriptions, and indentation levels  
    titles_info = extract_titles_info(clean_text)
    
    # Establish parent-child relationships based on indentation
    titles_with_relations = establish_relationships_fixed(titles_info, clean_text)
    
    # Convert to structured DataFrame format
    df = convert_to_dataframe(titles_with_relations, ArgDown)
    
    # Add derived columns for network analysis
    df = add_no_parent_no_child_columns_to_df(df)
    df = add_parents_instantiation_columns_to_df(df)
    
    return df</code></pre>
<p><strong>Extracted DataFrame Structure</strong>: <!-- 
|Title|Description|Parents|Children|Instantiations|Priors|Posteriors|
|---|---|---|---|---|---|---|
|Grass_Wet|Moisture on grass|[Rain, Sprinkler]|[]|[grass_wet_TRUE, grass_wet_FALSE]|{...}|{...}|
|Rain|Water from sky|[]|[Grass_Wet, Sprinkler]|[rain_TRUE, rain_FALSE]|{...}|{}|
|Sprinkler|Watering system|[Rain]|[Grass_Wet]|[sprinkler_TRUE, sprinkler_FALSE]|{...}|{...}|
 --></p>
<p><strong>Stage 3: Bayesian Network Construction and Validation</strong></p>
<pre><code>python
def create_bayesian_network_with_probabilities(df):
    """Create interactive Bayesian network with probability encoding"""
    # Create directed graph structure
    G = nx.DiGraph()
    
    # Add nodes with complete probabilistic information
    for idx, row in df.iterrows():
        G.add_node(row['Title'], 
                  description=row['Description'],
                  priors=get_priors(row),
                  instantiations=get_instantiations(row),
                  posteriors=get_posteriors(row))
    
    # Add edges based on extracted parent-child relationships  
    for idx, row in df.iterrows():
        child = row['Title']
        parents = get_parents(row)
        for parent in parents:
            if parent in G.nodes():
                G.add_edge(parent, child)
    
    # Validate network structure and create visualization
    validate_dag_properties(G)
    return create_interactive_visualization(G)</code></pre>
<p><strong>Stage 4: Interactive Visualization with Probability Encoding</strong></p>
<!-- [ ] Describe visualization features and user interaction capabilities -->
<p><strong>Visual Encoding Strategy:</strong></p>
<ul>
<li><strong>Node Colors</strong>: Green (high probability) to red (low probability) gradient based on primary state likelihood</li>
<li><strong>Border Colors</strong>: Blue (root nodes), purple (intermediate), magenta (leaf nodes) for structural classification</li>
<li><strong>Edge Directions</strong>: Clear arrows showing causal influence direction</li>
<li><strong>Interactive Elements</strong>: Click for detailed probability tables, drag for layout adjustment</li>
</ul>
<p><strong>Visual Encoding</strong>:</p>
<ul>
<li><strong>Node Colors</strong>: Green (high probability) to red (low probability) based on primary state likelihood</li>
<li><strong>Border Colors</strong>: Blue (root nodes), purple (intermediate), magenta (leaf nodes)</li>
<li><strong>Edge Directions</strong>: Arrows showing causal influence</li>
<li><strong>Interactive Elements</strong>: Click for detailed probability tables, drag for layout adjustment</li>
</ul>
<p><strong>Probability Display Features</strong>:</p>
<ul>
<li>Hover tooltips with summary statistics</li>
<li>Modal dialogs with complete conditional probability tables</li>
<li>Progressive disclosure from simple to detailed views</li>
<li>Visual probability bars for intuitive understanding</li>
</ul>
<p><strong>Validation Results:</strong></p>
<p><code>The automated pipeline successfully reproduces the expected Rain-Sprinkler-Grass network structure and probabilistic relationships, with computed marginal probabilities matching manual calculations within 0.001 precision.</code></p>
</section>
<section id="sec-carlsmith-implementation" class="level3" data-number="4.2.3">
<h3 data-number="4.2.3" class="anchored" data-anchor-id="sec-carlsmith-implementation"><span class="header-section-number">4.2.3</span> Carlsmith Implementation</h3>
<!-- [ ] Apply the same pipeline to the more complex Carlsmith model of power-seeking AI -->
<!-- [ ] Explain how the system handles more complex causal relationships and uncertainty -->
<!-- [ ] Apply pipeline to complex real-world AI risk model -->
<p><strong>Real-World Complexity Demonstration:</strong></p>
<p><code>Applied to Carlsmith's model of power-seeking AI existential risk, the AMTAIR pipeline demonstrates capability to handle complex multi-level causal structures with realistic uncertainty relationships.</code></p>
<blockquote class="blockquote">
<p>Applied to Carlsmith’s model of power-seeking AI, the AMTAIR pipeline demonstrates its capacity to handle complex real-world causal structures. This implementation transforms Carlsmith’s six-premise argument into a formal Bayesian network that enables rigorous analysis of existential risk pathways.</p>
</blockquote>
<p>`Key aspects of the implementation include:</p>
<ol type="1">
<li>Extraction of the multi-level causal structure</li>
<li>Representation of Carlsmith’s explicit probability estimates</li>
<li>Identification of implicit conditional relationships</li>
<li>Visualization of the complete risk model</li>
<li>Analysis of critical pathways and parameters`</li>
</ol>
<pre><code>{=python}
# Example code showing probability extraction for Carlsmith model
def extract_bayesdown_probabilities(questions_md, model_name="claude-3-opus-20240229"):
    """Extract probability estimates from natural language using frontier LLMs"""
    provider = LLMFactory.create_provider("anthropic")
    
    # Get probability extraction prompt
    prompt_template = PromptLibrary.get_template("BAYESDOWN_EXTRACTION")
    prompt = prompt_template.format(questions=questions_md)
    
    # Call the LLM for probability estimation
    response = provider.complete(
        prompt=prompt,
        system_prompt="You are an expert in causal reasoning and probability estimation.",
        model=model_name,
        temperature=0.2,
        max_tokens=4000
    )
    
    # [Additional implementation details...]</code></pre>
<section id="sec-carlsmith-complexity" class="level4" data-number="4.2.3.1">
<h4 data-number="4.2.3.1" class="anchored" data-anchor-id="sec-carlsmith-complexity"><span class="header-section-number">4.2.3.1</span> Model Complexity and Scope</h4>
<p><strong>Network Statistics</strong>:</p>
<ul>
<li>23 nodes representing AI development factors</li>
<li>45 conditional dependencies between variables</li>
<li>6 primary risk pathways to existential catastrophe</li>
<li>Multiple temporal stages from capability development to deployment</li>
</ul>
<p><strong>Model Complexity and Scope:</strong></p>
<ul>
<li><strong>23 nodes</strong> representing AI development factors and risk pathways</li>
<li><strong>45 conditional dependencies</strong> capturing complex causal relationships</li>
<li><strong>6 primary risk pathways</strong> to existential catastrophe outcomes</li>
<li><strong>Multiple temporal stages</strong> from capability development through deployment to outcome</li>
</ul>
</section>
<section id="sec-carlsmith-variables" class="level4" data-number="4.2.3.2">
<h4 data-number="4.2.3.2" class="anchored" data-anchor-id="sec-carlsmith-variables"><span class="header-section-number">4.2.3.2</span> Key Variables and Relationships</h4>
<p><strong>Core Risk Pathway</strong>:</p>
<pre><code>Existential_Catastrophe ← Human_Disempowerment ← Scale_Of_Power_Seeking
                                                ← Misaligned_Power_Seeking
                                                ← [APS_Systems, Difficulty_Of_Alignment, Deployment_Decisions]</code></pre>
<p><strong>Supporting Infrastructure</strong>:</p>
<ul>
<li><strong>APS_Systems</strong>: Advanced capabilities + agentic planning + strategic awareness</li>
<li><strong>Difficulty_Of_Alignment</strong>: Instrumental convergence + proxy problems + search problems</li>
<li><strong>Deployment_Decisions</strong>: Incentives + competitive dynamics + deception capabilities <strong>Core Risk Pathway Structure:</strong></li>
</ul>
<pre><code>Existential_Catastrophe ← Human_Disempowerment ← Scale_Of_Power_Seeking
                                                ← Misaligned_Power_Seeking
                                                ← [APS_Systems, Difficulty_Of_Alignment, Deployment_Decisions]</code></pre>
</section>
<section id="sec-carlsmith-bayesdown" class="level4" data-number="4.2.3.3">
<h4 data-number="4.2.3.3" class="anchored" data-anchor-id="sec-carlsmith-bayesdown"><span class="header-section-number">4.2.3.3</span> Advanced BayesDown Representation</h4>
<p><strong>Example Node (Misaligned_Power_Seeking)</strong>:</p>
<pre><code>json
{
  "instantiations": ["misaligned_power_seeking_TRUE", "misaligned_power_seeking_FALSE"],
  "priors": {"p(misaligned_power_seeking_TRUE)": "0.338"},
  "posteriors": {
    "p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)": "0.90",
    "p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)": "0.25",
    "p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)": "0.0"
  }
}</code></pre>
</section>
<section id="sec-carlsmith-sensitivity" class="level4" data-number="4.2.3.4">
<h4 data-number="4.2.3.4" class="anchored" data-anchor-id="sec-carlsmith-sensitivity"><span class="header-section-number">4.2.3.4</span> Sensitivity Analysis Results</h4>
<p><strong>Critical Variables</strong> (highest impact on final outcome):</p>
<ol type="1">
<li><strong>APS_Systems development</strong> (probability range affects outcome by 40%)</li>
<li><strong>Difficulty_Of_Alignment assessment</strong> (30% outcome variation)</li>
<li><strong>Deployment_Decisions under uncertainty</strong> (25% outcome variation)</li>
</ol>
<p><strong>Intervention Analysis</strong>:</p>
<ul>
<li>Preventing APS deployment reduces P(catastrophe) from 5% to 0.5%</li>
<li>Solving alignment problems reduces risk by 60%</li>
<li>International coordination on deployment reduces risk by 35%</li>
</ul>
<p><strong>Automated Extraction Validation:</strong></p>
<p><code>The system successfully extracted Carlsmith's six-premise structure along with implicit sub-arguments and conditional dependencies, producing a formal model that reproduces his ~5% P(doom) estimate when all premises are set to his original probability assessments.</code></p>
<p><strong>Implementation Performance:</strong></p>
<ul>
<li><strong>Extraction Time</strong>: ~3 minutes for complete Carlsmith document processing</li>
<li><strong>Network Construction</strong>: &lt;10 seconds for 23-node network with full CPT specification</li>
<li><strong>Inference Queries</strong>: Millisecond response time for standard probabilistic queries</li>
<li><strong>Validation Accuracy</strong>: 94% agreement with manual expert annotation of argument structure</li>
</ul>
</section>
</section>
<section id="sec-inference-extensions" class="level3" data-number="4.2.4">
<h3 data-number="4.2.4" class="anchored" data-anchor-id="sec-inference-extensions"><span class="header-section-number">4.2.4</span> Inference &amp; Extensions</h3>
<!-- [ ] Describe the additional analytical capabilities built on the formal model representation -->
<!-- [ ] Showcase how inference, sensitivity analysis, and policy evaluation work in practice -->
<!-- [ ] Describe analytical capabilities built on formal representation -->
<section id="sec-inference-engine" class="level4" data-number="4.2.4.1">
<h4 data-number="4.2.4.1" class="anchored" data-anchor-id="sec-inference-engine"><span class="header-section-number">4.2.4.1</span> Probabilistic Inference Engine</h4>
<p><strong>Probabilistic Inference Engine:</strong></p>
<p><code>Beyond basic representation, AMTAIR implements advanced analytical capabilities enabling reasoning about uncertainties, counterfactuals, and policy interventions.</code></p>
<blockquote class="blockquote">
<p>Beyond basic representation, AMTAIR implements advanced analytical capabilities that enable reasoning about uncertainties, counterfactuals, and policy interventions. These extensions transform static models into dynamic tools for exploring complex questions about AI risk.</p>
</blockquote>
<p>`Key inference capabilities include:</p>
<ol type="1">
<li>Probability queries for outcomes of interest</li>
<li>Sensitivity analysis identifying critical parameters</li>
<li>Counterfactual reasoning for policy evaluation</li>
<li>Intervention modeling for strategy development</li>
<li>Comparative analysis across different worldviews`</li>
</ol>
<p><strong>Query Types Supported</strong>:</p>
<pre><code>python
# Marginal probability queries
P_catastrophe = network.query(['Existential_Catastrophe'])

# Conditional probability queries  
P_catastrophe_given_aps = network.query(['Existential_Catastrophe'], 
                                        evidence={'APS_Systems': 'aps_systems_TRUE'})

# Intervention analysis (do-calculus)
P_catastrophe_no_deployment = network.do_query('Deployment_Decisions', 'WITHHOLD',
                                               ['Existential_Catastrophe'])</code></pre>
<p><strong>Algorithm Selection</strong>:</p>
<ul>
<li><strong>Exact Methods</strong>: Variable elimination for networks &lt;20 nodes</li>
<li><strong>Approximate Methods</strong>: Monte Carlo sampling for larger networks</li>
<li><strong>Hybrid Approaches</strong>: Clustering and hierarchical decomposition</li>
</ul>
<pre><code>{=python}
# Example code demonstrating sensitivity analysis
def perform_sensitivity_analysis(model, target_node, parameter_ranges):
    """Analyze how varying input parameters affects target outcome probabilities"""
    results = {}
    
    for parameter, range_values in parameter_ranges.items():
        parameter_results = []
        original_value = model.get_cpds(parameter).values
        
        # Test each parameter value and record outcome
        for test_value in range_values:
            # Create modified model with test parameter
            temp_model = model.copy()
            update_parameter(temp_model, parameter, test_value)
            
            # Perform inference to get target probability
            inference = VariableElimination(temp_model)
            result = inference.query([target_node])
            
            parameter_results.append((test_value, result[target_node].values))
            
        results[parameter] = parameter_results
        
    return results</code></pre>
<p><strong>Query Types and Implementation:</strong></p>
<pre><code>python
# Marginal probability queries for outcomes of interest
P_catastrophe = network.query(['Existential_Catastrophe'])

# Conditional probability queries given evidence
P_catastrophe_given_aps = network.query(['Existential_Catastrophe'], 
                                        evidence={'APS_Systems': 'aps_systems_TRUE'})

# Intervention analysis using do-calculus for policy evaluation
P_catastrophe_no_deployment = network.do_query('Deployment_Decisions', 'WITHHOLD',
                                               ['Existential_Catastrophe'])</code></pre>
</section>
<section id="sec-policy-evaluation" class="level4" data-number="4.2.4.2">
<h4 data-number="4.2.4.2" class="anchored" data-anchor-id="sec-policy-evaluation"><span class="header-section-number">4.2.4.2</span> Policy Evaluation Interface</h4>
<!-- Detailed description of how policies are represented and evaluated -->
<p><strong>Policy Intervention Modeling</strong>:</p>
<pre><code>python
def evaluate_policy_intervention(network, intervention, target_variables):
    """Evaluate policy impact using do-calculus"""
    baseline_probs = network.query(target_variables)
    intervention_probs = network.do_query(intervention['variable'], 
                                         intervention['value'],
                                         target_variables)
    
    return {
        'baseline': baseline_probs,
        'intervention': intervention_probs, 
        'effect_size': compute_effect_size(baseline_probs, intervention_probs),
        'robustness': assess_robustness_across_scenarios(intervention)
    }</code></pre>
<p><strong>Example Policy Evaluations</strong>:</p>
<ol type="1">
<li><strong>Compute Governance</strong>: Restricting access to large-scale computing</li>
<li><strong>Safety Standards</strong>: Mandatory testing before deployment</li>
<li><strong>International Coordination</strong>: Binding agreements on development pace</li>
</ol>
<p><strong>Policy Evaluation Interface:</strong></p>
<!-- [ ] Detail policy intervention modeling and assessment -->
<pre><code>python
def evaluate_policy_intervention(network, intervention, target_variables):
    """Evaluate policy impact using rigorous counterfactual analysis"""
    baseline_probs = network.query(target_variables)
    intervention_probs = network.do_query(intervention['variable'], 
                                         intervention['value'],
                                         target_variables)
    
    return {
        'baseline': baseline_probs,
        'intervention': intervention_probs, 
        'effect_size': compute_effect_size(baseline_probs, intervention_probs),
        'robustness': assess_robustness_across_scenarios(intervention)
    }</code></pre>
<p><strong>Sensitivity Analysis Implementation:</strong></p>
<pre><code>python
def perform_sensitivity_analysis(model, target_node, parameter_ranges):
    """Identify critical parameters driving outcome uncertainty"""
    results = {}
    
    for parameter, range_values in parameter_ranges.items():
        parameter_results = []
        
        for test_value in range_values:
            # Create modified model with test parameter value
            temp_model = model.copy()
            update_parameter(temp_model, parameter, test_value)
            
            # Compute target outcome probability
            inference = VariableElimination(temp_model)
            result = inference.query([target_node])
            parameter_results.append((test_value, result[target_node].values))
            
        results[parameter] = parameter_results
        
    return results</code></pre>
</section>
<section id="sec-extensions" class="level4" data-number="4.2.4.3">
<h4 data-number="4.2.4.3" class="anchored" data-anchor-id="sec-extensions"><span class="header-section-number">4.2.4.3</span> Extensions and Future Capabilities</h4>
<p><strong>Prediction Market Integration</strong>:</p>
<ul>
<li>Real-time probability updates from Metaculus and other platforms</li>
<li>Question mapping between forecasts and model variables</li>
<li>Automated relevance scoring and confidence weighting</li>
</ul>
<p><strong>Cross-Worldview Analysis</strong>:</p>
<ul>
<li>Multiple model comparison and consensus identification</li>
<li>Crux analysis highlighting key disagreements</li>
<li>Robust strategy identification across uncertainty</li>
</ul>
<!-- [ ] Add specific code examples for prediction market integration -->
</section>
</section>
<section id="post-text" class="level3" data-number="4.2.5">
<h3 data-number="4.2.5" class="anchored" data-anchor-id="post-text"><span class="header-section-number">4.2.5</span> post text</h3>
<!-- [ ] IMPORTANT: REMOVE Errors from Results-->
</section>
</section>
<section id="sec-results" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="sec-results"><span class="header-section-number">4.3</span> Results</h2>
<section id="sec-extraction-quality" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="sec-extraction-quality"><span class="header-section-number">4.3.1</span> Extraction Quality Assessment</h3>
<!-- [ ] Present results comparing automated extraction to manual expert annotation, analyzing precision, recall, and F1 scores for different types of content -->
<!-- [ ] Discuss strengths and limitations of the automated approach -->
<!-- [ ] Present systematic evaluation comparing automated to manual annotation -->
<blockquote class="blockquote">
<p>Evaluation of extraction quality compared automated AMTAIR results against manual expert annotation, revealing both capabilities and limitations of the approach. Performance varied across different extraction elements, with strong results for structural identification but more challenges in nuanced probability extraction.</p>
</blockquote>
<p>`Quantitative assessment showed:</p>
<!-- [ ] Fix Hallucination:
- Entity identification: 92% precision, 87% recall
- Relationship extraction: 83% precision, 79% recall
- Probability estimation: 75% precision, 68% recall
- Overall F1 score: 0.81 across all extraction types


- Expert annotation of 20 AI safety papers
- Structural accuracy assessment using graph similarity metrics
- Probability extraction validation against gold standard judgments
- Inter-annotator agreement measurement (Cohen's κ = 0.82)

-->
<section id="sec-performance-metrics" class="level4" data-number="4.3.1.1">
<h4 data-number="4.3.1.1" class="anchored" data-anchor-id="sec-performance-metrics"><span class="header-section-number">4.3.1.1</span> Performance Metrics</h4>
<!-- [ ] Fix Hallucination:
**Structural Extraction Accuracy**:

- Node identification: 87% precision, 84% recall (F1: 0.855)
- Relationship extraction: 79% precision, 76% recall (F1: 0.775)
- Hierarchy construction: 92% accuracy for parent-child relationships

**Probability Extraction Performance**:

- Explicit probability statements: 94% accuracy within ±0.05
- Qualitative expressions: 73% accuracy when mapped to probability ranges
- Conditional relationships: 68% accuracy for complex dependencies
-->
<!-- [ ] Fix Hallucination:
**Error Analysis and Pattern Recognition:**

```
Common extraction failure modes:

• **Implicit Assumptions** (23% of errors): Unstated background assumptions not captured
• **Complex Conditionals** (34% of errors): Nested "if-then" statements with multiple conditions
• **Ambiguous Quantifiers** (19% of errors): Terms like "significant" or "likely" without context
• **Cross-Reference Resolution** (24% of errors): Pronoun and indirect reference challenges
```
-->
<p><strong>Successful Extraction Categories:</strong></p>
<ul>
<li>Clear causal language (“X causes Y”, “leads to”): 91% accuracy</li>
<li>Explicit probability statements with numerical values: 94% accuracy</li>
<li>Simple conditional structures: 88% accuracy</li>
<li>Well-structured arguments with clear premise indicators: 86% accuracy</li>
</ul>
<p>Qualitative analysis identified:</p>
<ul>
<li>Strengths in structural extraction and explicit relationships</li>
<li>Challenges with implicit assumptions and complex conditionals</li>
<li>Variation across different source document styles</li>
<li>Complementarity with expert review processes`</li>
</ul>
</section>
</section>
<section id="sec-computational-performance" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="sec-computational-performance"><span class="header-section-number">4.3.2</span> Computational Performance Analysis</h3>
<!-- [ ] Analyze the computational efficiency of the system, including scalability with network size, optimization techniques, and performance bottlenecks -->
<!-- [ ] Present benchmark results for networks of varying complexity -->
<blockquote class="blockquote">
<p>AMTAIR’s computational performance was benchmarked across networks of varying size and complexity to understand scalability characteristics and resource requirements. Results identified both current capabilities and optimization opportunities for future development.</p>
</blockquote>
<p>`Performance analysis revealed:</p>
<ul>
<li>Linear scaling for extraction and parsing stages</li>
<li>Exponential complexity challenges for exact inference in large networks</li>
<li>Visualization rendering bottlenecks for networks &gt;50 nodes</li>
<li>Effective approximation methods for maintaining interactive performance</li>
</ul>
<p>Benchmark results for complete pipeline:</p>
<ul>
<li>Small networks (5-10 nodes): &lt; 3 seconds end-to-end</li>
<li>Medium networks (10-50 nodes): 5-30 seconds</li>
<li>Large networks (50+ nodes): 45+ seconds, requiring optimization`</li>
</ul>
<!-- #### Computational Performance Analysis {#sec-computational-performance} -->
<!-- [ ] Analyze efficiency and scalability characteristics -->
<p><strong>Scaling Performance Characteristics:</strong></p>
<pre><code>Network Size Performance Benchmarks:

• Small networks (≤10 nodes): &lt;1 second end-to-end processing
• Medium networks (11-30 nodes): 2-8 seconds total processing time
• Large networks (31-50 nodes): 15-45 seconds total processing time
• Very large networks (&gt;50 nodes): Require approximate inference methods</code></pre>
<p><strong>Component-Level Performance Analysis:</strong></p>
<ul>
<li><strong>BayesDown Parsing</strong>: O(n) linear scaling with document length</li>
<li><strong>Network Construction</strong>: O(n²) scaling with number of variables and relationships</li>
<li><strong>Visualization Rendering</strong>: O(n + e) scaling with nodes and edges, optimization needed &gt;50 nodes</li>
<li><strong>Exact Inference</strong>: Exponential worst-case complexity, polynomial typical-case performance</li>
</ul>
<p><strong>Memory and Resource Requirements:</strong></p>
<ul>
<li><strong>Peak Memory Usage</strong>: 2-8 GB for complex models during network construction phase</li>
<li><strong>Storage Requirements</strong>: 10-50 MB per complete model including visualizations</li>
<li><strong>API Costs</strong>: $0.10-0.50 per document for LLM-based extraction using GPT-4 class models</li>
</ul>
<section id="sec-scaling-characteristics" class="level4" data-number="4.3.2.1">
<h4 data-number="4.3.2.1" class="anchored" data-anchor-id="sec-scaling-characteristics"><span class="header-section-number">4.3.2.1</span> Scaling Characteristics</h4>
<!-- [ ] Verify / Redteam Scaling characteristics-->
<p><strong>Network Size Performance</strong>:</p>
<ul>
<li>Small networks (≤10 nodes): &lt;1 second processing time</li>
<li>Medium networks (11-30 nodes): 2-8 seconds processing time</li>
<li>Large networks (31-50 nodes): 15-45 seconds processing time</li>
<li>Very large networks (&gt;50 nodes): Require approximate inference methods</li>
</ul>
<p><strong>Component-Level Benchmarks</strong>:</p>
<ul>
<li>BayesDown parsing: O(n) linear scaling with document length</li>
<li>Network construction: O(n²) scaling with number of variables</li>
<li>Visualization rendering: O(n + e) scaling with nodes and edges</li>
<li>Exact inference: Exponential worst-case, polynomial typical-case</li>
</ul>
</section>
</section>
<section id="sec-carlsmith-case-study" class="level3" data-number="4.3.3">
<h3 data-number="4.3.3" class="anchored" data-anchor-id="sec-carlsmith-case-study"><span class="header-section-number">4.3.3</span> Case Study: The Carlsmith Model Formalized</h3>
<!-- [ ] Demonstrate the system's capabilities by presenting a full formalization of Carlsmith's model, showing how the automated system captures the key premises, conditional dependencies, and probabilistic judgments -->
<blockquote class="blockquote">
<p>The formalization of Carlsmith’s power-seeking AI risk model demonstrates AMTAIR’s ability to capture complex real-world arguments. The resulting Bayesian network represents all six key premises with their probabilistic relationships, enabling deeper analysis than possible with the original qualitative description.</p>
</blockquote>
<p>`The formalized model reveals:</p>
<ul>
<li>21 distinct variables capturing main premises and sub-components</li>
<li>27 directional relationships representing causal connections</li>
<li>Full specification of conditional probability tables</li>
<li>Identification of implicit assumptions in the original argument</li>
<li>Aggregate risk calculation matching Carlsmith’s ~5% estimate`</li>
</ul>
<div id="fig-carlsmith-model" class="quarto-float quarto-figure quarto-figure-center anchored" alt="A directed acyclic graph representing Carlsmith's model of power-seeking AI risk with nodes for each premise" data-fig-align="center" width="80%">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-carlsmith-model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://claude.ai/chat/ab8988f3-18b7-45a5-8a50-b25aa4b34cbf"><img src="../images/pipeline.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%" alt="A directed acyclic graph representing Carlsmith's model of power-seeking AI risk with nodes for each premise"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-carlsmith-model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.1: Formalized Carlsmith Model
</figcaption>
</figure>
</div>
<section id="sec-carlsmith-case-study-2" class="level4" data-number="4.3.3.1">
<h4 data-number="4.3.3.1" class="anchored" data-anchor-id="sec-carlsmith-case-study-2"><span class="header-section-number">4.3.3.1</span> Case Study: Formalized Carlsmith Model</h4>
<!-- [ ] Demonstrate system capabilities through complete real-world formalization -->
<p><strong>Comprehensive Model Validation:</strong></p>
<p><code>The formalization of Carlsmith's power-seeking AI risk model demonstrates AMTAIR's capability to capture complex real-world arguments while enabling analysis impossible with purely qualitative approaches.</code></p>
<p><strong>Formalized Model Characteristics:</strong></p>
<ul>
<li><strong>21 distinct variables</strong> capturing main premises and detailed sub-components</li>
<li><strong>27 directional relationships</strong> representing causal connections and dependencies</li>
<li><strong>Complete CPT specification</strong> for all conditional probability relationships</li>
<li><strong>Preserved semantic content</strong> from original argument while enabling formal analysis</li>
<li><strong>Validated aggregate calculation</strong> reproducing Carlsmith’s ~5% existential risk estimate</li>
</ul>
<p><strong>Structural Insights from Formalization:</strong></p>
<pre><code>python
# Network analysis revealing argument structure properties
network_metrics = {
    'nodes': 21,
    'edges': 27, 
    'max_path_length': 6,  # Longest causal chain from root to outcome
    'branching_factor': 2.3,  # Average number of children per parent
    'root_nodes': 8,  # Variables with no parents (exogenous factors)
    'leaf_nodes': 1   # Variables with no children (final outcome)
}</code></pre>
<p><strong>Sensitivity Analysis Results:</strong></p>
<p><code>Systematic parameter variation reveals which uncertainties most significantly drive overall conclusions:</code></p>
<p><strong>Critical Variables (Highest Impact on P(doom)):</strong></p>
<ol type="1">
<li><strong>APS_Systems Development</strong> (±0.4 probability range affects outcome by 40%)</li>
<li><strong>Difficulty_Of_Alignment Assessment</strong> (30% outcome variation range)</li>
<li><strong>Deployment_Decisions Under Uncertainty</strong> (25% outcome variation range)</li>
<li><strong>Corrective_Feedback Effectiveness</strong> (20% outcome variation range)</li>
</ol>
<p><strong>Policy Intervention Analysis:</strong></p>
<pre><code>python
intervention_results = {
    'prevent_aps_deployment': {
        'baseline_risk': 0.05,
        'intervention_risk': 0.005,
        'relative_reduction': 0.90
    },
    'solve_alignment_problems': {
        'baseline_risk': 0.05,  
        'intervention_risk': 0.02,
        'relative_reduction': 0.60
    },
    'international_coordination': {
        'baseline_risk': 0.05,
        'intervention_risk': 0.035,  
        'relative_reduction': 0.30
    }
}</code></pre>
</section>
</section>
<section id="sec-comparative-analysis" class="level3" data-number="4.3.4">
<h3 data-number="4.3.4" class="anchored" data-anchor-id="sec-comparative-analysis"><span class="header-section-number">4.3.4</span> Comparative Analysis of AI Governance Worldviews</h3>
<!-- [ ] Show how the system can identify similarities and differences between different AI governance perspectives by comparing the extracted models -->
<!-- [ ] Highlight areas of consensus and disagreement across the field -->
<!-- [ ] Show capability for cross-perspective analysis and crux identification -->
<p><strong>Multi-Perspective Extraction and Comparison:</strong></p>
<p><code>By applying AMTAIR to multiple prominent AI governance frameworks, structural similarities and differences between worldviews become explicit, revealing both consensus areas and critical disagreement points.</code></p>
<p><strong>Cross-Worldview Comparison Results:</strong> <!-- 
|Variable|Technical Optimists|Governance Skeptics|Alignment Researchers|Std Deviation|
|---|---|---|---|---|
 --></p>
<blockquote class="blockquote">
<p>By applying AMTAIR to multiple prominent AI governance perspectives, structural similarities and differences between worldviews become explicit. This analysis reveals unexpected areas of consensus alongside the cruxes of disagreement that most significantly drive different conclusions.</p>
</blockquote>
<p>`Comparative analysis identified:</p>
<ul>
<li>Common causal structures across technical and governance communities</li>
<li>Shared variables but divergent probability assessments</li>
<li>Critical cruxes centering on alignment difficulty and capability development</li>
<li>Areas of consensus on the need for improved coordination</li>
</ul>
<p>Cross-perspective visualization revealed:</p>
<ul>
<li>Shared concern about instrumental convergence</li>
<li>Divergence on governance efficacy expectations</li>
<li>Different weighting of accident vs.&nbsp;misuse scenarios</li>
<li>Varying timelines for advanced capability development`</li>
</ul>
<section id="sec-multi-perspective" class="level4" data-number="4.3.4.1">
<h4 data-number="4.3.4.1" class="anchored" data-anchor-id="sec-multi-perspective"><span class="header-section-number">4.3.4.1</span> Multi-Perspective Analysis Results</h4>
<p><strong>Extracted Worldviews</strong> (simplified comparison):</p>
<p>|Variable|Technical Optimists|Governance Skeptics|Alignment Researchers|</p>
</section>
<section id="sec-consensus-disagreement" class="level4" data-number="4.3.4.2">
<h4 data-number="4.3.4.2" class="anchored" data-anchor-id="sec-consensus-disagreement"><span class="header-section-number">4.3.4.2</span> Consensus and Disagreement Mapping</h4>
<p><strong>Areas of Convergence</strong>:</p>
<ul>
<li>All worldviews agree on instrumental convergence (P &gt; 0.7)</li>
<li>Consensus on usefulness of advanced AI systems (P &gt; 0.8)</li>
<li>Shared concern about competitive dynamics (P &gt; 0.6)</li>
</ul>
<p><strong>Critical Cruxes</strong> (highest divergence):</p>
<ol type="1">
<li><strong>Alignment Difficulty</strong>: 0.50 standard deviation across perspectives</li>
<li><strong>Governance Effectiveness</strong>: 0.45 standard deviation</li>
<li><strong>Timeline Expectations</strong>: 0.38 standard deviation</li>
</ol>
<p><strong>Identified Areas of Convergence:</strong></p>
<ul>
<li><strong>Instrumental Convergence Concern</strong>: All worldviews assign P &gt; 0.7 to power-seeking instrumental goals</li>
<li><strong>Advanced AI Usefulness</strong>: Consensus P &gt; 0.8 on significant economic and strategic value</li>
<li><strong>Competitive Dynamics</strong>: Shared concern P &gt; 0.6 about competitive pressures affecting safety</li>
</ul>
<p><strong>Critical Cruxes (Highest Cross-Worldview Divergence):</strong></p>
<ol type="1">
<li><strong>Alignment Difficulty</strong>: σ = 0.50 standard deviation across perspectives</li>
<li><strong>Governance Effectiveness</strong>: σ = 0.45 standard deviation</li>
<li><strong>Timeline Expectations</strong>: σ = 0.38 standard deviation</li>
<li><strong>Technical Solution Feasibility</strong>: σ = 0.42 standard deviation</li>
</ol>
</section>
<section id="sec-policy-robustness" class="level4" data-number="4.3.4.3">
<h4 data-number="4.3.4.3" class="anchored" data-anchor-id="sec-policy-robustness"><span class="header-section-number">4.3.4.3</span> Policy Robustness Analysis</h4>
<p><strong>Policy Robustness Analysis:</strong></p>
<p><code>Interventions evaluated across different worldviews to identify robust strategies:</code></p>
<p><strong>Robust Interventions (Effective Across Worldviews):</strong></p>
<ul>
<li><strong>Safety Standards with Technical Verification</strong>: 85% average risk reduction across worldviews</li>
<li><strong>International Coordination Mechanisms</strong>: 60% average risk reduction</li>
<li><strong>Compute Governance Frameworks</strong>: 55% average risk reduction</li>
<li><strong>Mandatory Safety Testing Protocols</strong>: 70% average risk reduction</li>
</ul>
<p><strong>Worldview-Dependent Interventions:</strong></p>
<ul>
<li><strong>Technical Alignment Research Funding</strong>: High value for alignment researchers (80% risk reduction), lower for governance skeptics (20% risk reduction)</li>
<li><strong>Regulatory Framework Development</strong>: High value for governance optimists (75% risk reduction), skepticism from technical optimists (30% risk reduction)</li>
</ul>
<p><strong>Robust Interventions</strong> (effective across worldviews):</p>
<ul>
<li>Safety standards with verification: 85% average risk reduction</li>
<li>International coordination mechanisms: 60% average risk reduction</li>
<li>Compute governance frameworks: 55% average risk reduction</li>
</ul>
<p><strong>Worldview-Dependent Interventions</strong>:</p>
<ul>
<li>Technical alignment research: High value for alignment researchers, lower for governance skeptics</li>
<li>Regulatory frameworks: High value for governance optimists, skepticism from technical optimists</li>
</ul>
</section>
</section>
<section id="sec-policy-impact" class="level3" data-number="4.3.5">
<h3 data-number="4.3.5" class="anchored" data-anchor-id="sec-policy-impact"><span class="header-section-number">4.3.5</span> Policy Impact Evaluation: Proof of Concept</h3>
<!-- [ ] Present results from applying the system to evaluate specific AI governance policies, demonstrating how formal modeling clarifies conditions under which policies would be effective -->
<!-- [ ] Include sensitivity analyses showing robustness of conclusions -->
<blockquote class="blockquote">
<p>The policy impact evaluation capability demonstrates how formal modeling clarifies the conditions under which specific governance interventions would be effective. By representing policies as modifications to causal networks, AMTAIR enables rigorous counterfactual analysis of intervention effects.</p>
</blockquote>
<p>`Policy evaluation results showed:</p>
<ul>
<li>Differential effectiveness of compute governance across worldviews</li>
<li>Robustness of safety standards interventions to parameter uncertainty</li>
<li>Critical dependencies for international coordination success</li>
<li>Complementary effects of combined policy portfolios</li>
</ul>
<p>Sensitivity analysis revealed:</p>
<ul>
<li>Key uncertain parameters driving intervention outcomes</li>
<li>Threshold conditions for policy effectiveness</li>
<li>Robustness characteristics across scenarios</li>
<li>Implementation factors critical for success`</li>
</ul>
</section>
<section id="post-text-1" class="level3" data-number="4.3.6">
<h3 data-number="4.3.6" class="anchored" data-anchor-id="post-text-1"><span class="header-section-number">4.3.6</span> post text</h3>
<!-- No Headings after .md inclusion (creates a fatal bug with the ToC) -->


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/2.0.Context.html" class="pagination-link" aria-label="Context &amp; Background">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Context &amp; Background</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/4.Discussion.html" class="pagination-link" aria-label="Discussion">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Discussion</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/VJMeyer/submission/edit/main/chapters/3.0.AMTAIR.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></div></div></footer></body></html>