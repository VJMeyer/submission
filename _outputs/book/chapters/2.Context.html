<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.29">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3&nbsp; Context – Automating the Modelling of Transformative Artificial Intelligence Risks</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/3.AMTAIR.html" rel="next">
<link href="../chapters/1.Introduction.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-0815c480559380816a4d1ea211a47e91.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-485d01fc63b59abcd3ee1bf1e8e2748d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/2.Context.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Context</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Automating the Modelling of Transformative Artificial Intelligence Risks</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/VJMeyer/submission" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="../Automating-the-Modelling-of-Transformative-Artificial-Intelligence-Risks.pdf">
              <i class="bi bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="../Automating-the-Modelling-of-Transformative-Artificial-Intelligence-Risks.epub">
              <i class="bi bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-1" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-1">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/0.Frontmatter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Quarto Syntax</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/1.Introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/2.Context.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Context</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/3.AMTAIR.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">AMTAIR</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/4.Discussion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Discussion</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/5.Conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Conclusion</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ref/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliography (References)</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/I.Appendices.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Appendices</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title"></span></span></a><a href="https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr">AMTAIR Prototype Demonstration (Public Colab Notebook)</a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-context" id="toc-sec-context" class="nav-link active" data-scroll-target="#sec-context"><span class="header-section-number">4</span> Context &amp; Background</a>
  <ul>
  <li><a href="#sec-theoretical-foundations" id="toc-sec-theoretical-foundations" class="nav-link" data-scroll-target="#sec-theoretical-foundations"><span class="header-section-number">4.1</span> Theoretical Foundations</a>
  <ul>
  <li><a href="#sec-carlsmith-model" id="toc-sec-carlsmith-model" class="nav-link" data-scroll-target="#sec-carlsmith-model"><span class="header-section-number">4.1.1</span> AI Existential Risk: The Carlsmith Model</a>
  <ul class="collapse">
  <li><a href="#sec-carlsmith-ideal" id="toc-sec-carlsmith-ideal" class="nav-link" data-scroll-target="#sec-carlsmith-ideal"><span class="header-section-number">4.1.1.1</span> Why Carlsmith as Ideal Formalization Target</a></li>
  </ul></li>
  <li><a href="#sec-epistemic-challenge" id="toc-sec-epistemic-challenge" class="nav-link" data-scroll-target="#sec-epistemic-challenge"><span class="header-section-number">4.1.2</span> The Epistemic Challenge of Policy Evaluation</a>
  <ul class="collapse">
  <li><a href="#sec-unique-difficulties" id="toc-sec-unique-difficulties" class="nav-link" data-scroll-target="#sec-unique-difficulties"><span class="header-section-number">4.1.2.1</span> Unique Difficulties in AI Governance</a></li>
  <li><a href="#sec-traditional-limitations" id="toc-sec-traditional-limitations" class="nav-link" data-scroll-target="#sec-traditional-limitations"><span class="header-section-number">4.1.2.2</span> Limitations of Traditional Policy Analysis</a></li>
  </ul></li>
  <li><a href="#sec-argument-mapping" id="toc-sec-argument-mapping" class="nav-link" data-scroll-target="#sec-argument-mapping"><span class="header-section-number">4.1.3</span> Argument Mapping and Formal Representations</a></li>
  <li><a href="#sec-bayesian-networks" id="toc-sec-bayesian-networks" class="nav-link" data-scroll-target="#sec-bayesian-networks"><span class="header-section-number">4.1.4</span> Bayesian Networks as Knowledge Representation</a>
  <ul class="collapse">
  <li><a href="#sec-mathematical-foundations" id="toc-sec-mathematical-foundations" class="nav-link" data-scroll-target="#sec-mathematical-foundations"><span class="header-section-number">4.1.4.1</span> Mathematical Foundations</a></li>
  <li><a href="#sec-rain-sprinkler-example" id="toc-sec-rain-sprinkler-example" class="nav-link" data-scroll-target="#sec-rain-sprinkler-example"><span class="header-section-number">4.1.4.2</span> The Rain-Sprinkler-Grass Example</a></li>
  <li><a href="#sec-modeling-advantages" id="toc-sec-modeling-advantages" class="nav-link" data-scroll-target="#sec-modeling-advantages"><span class="header-section-number">4.1.4.3</span> Advantages for AI Risk Modeling</a></li>
  <li><a href="#sec-natural-to-formal" id="toc-sec-natural-to-formal" class="nav-link" data-scroll-target="#sec-natural-to-formal"><span class="header-section-number">4.1.4.4</span> From Natural Language to Formal Models</a></li>
  <li><a href="#sec-bayesdown-innovation" id="toc-sec-bayesdown-innovation" class="nav-link" data-scroll-target="#sec-bayesdown-innovation"><span class="header-section-number">4.1.4.5</span> BayesDown: The Critical Innovation</a></li>
  </ul></li>
  <li><a href="#sec-mtair-framework" id="toc-sec-mtair-framework" class="nav-link" data-scroll-target="#sec-mtair-framework"><span class="header-section-number">4.1.5</span> The MTAIR Framework: Achievements and Limitations</a>
  <ul class="collapse">
  <li><a href="#sec-mtair-innovations" id="toc-sec-mtair-innovations" class="nav-link" data-scroll-target="#sec-mtair-innovations"><span class="header-section-number">4.1.5.1</span> MTAIR’s Innovations</a></li>
  <li><a href="#sec-mtair-limitations" id="toc-sec-mtair-limitations" class="nav-link" data-scroll-target="#sec-mtair-limitations"><span class="header-section-number">4.1.5.2</span> Fundamental Limitations Motivating AMTAIR</a></li>
  </ul></li>
  <li><a href="#sec-narrow-path" id="toc-sec-narrow-path" class="nav-link" data-scroll-target="#sec-narrow-path"><span class="header-section-number">4.1.6</span> “A Narrow Path”: Conditional Policy Proposals in Practice</a></li>
  </ul></li>
  <li><a href="#sec-methodology" id="toc-sec-methodology" class="nav-link" data-scroll-target="#sec-methodology"><span class="header-section-number">4.2</span> Methodology</a>
  <ul>
  <li><a href="#sec-research-design" id="toc-sec-research-design" class="nav-link" data-scroll-target="#sec-research-design"><span class="header-section-number">4.2.1</span> Research Design Overview</a>
  <ul class="collapse">
  <li><a href="#sec-hybrid-approach" id="toc-sec-hybrid-approach" class="nav-link" data-scroll-target="#sec-hybrid-approach"><span class="header-section-number">4.2.1.1</span> Hybrid Theoretical-Empirical Approach</a></li>
  <li><a href="#sec-iterative-process" id="toc-sec-iterative-process" class="nav-link" data-scroll-target="#sec-iterative-process"><span class="header-section-number">4.2.1.2</span> Iterative Development Process</a></li>
  </ul></li>
  <li><a href="#sec-formalizing-world-models" id="toc-sec-formalizing-world-models" class="nav-link" data-scroll-target="#sec-formalizing-world-models"><span class="header-section-number">4.2.2</span> Formalizing World Models from AI Safety Literature</a></li>
  <li><a href="#sec-natural-to-computational" id="toc-sec-natural-to-computational" class="nav-link" data-scroll-target="#sec-natural-to-computational"><span class="header-section-number">4.2.3</span> From Natural Language to Computational Models</a>
  <ul class="collapse">
  <li><a href="#sec-two-stage-extraction" id="toc-sec-two-stage-extraction" class="nav-link" data-scroll-target="#sec-two-stage-extraction"><span class="header-section-number">4.2.3.1</span> The Two-Stage Extraction Process</a></li>
  <li><a href="#sec-llm-integration" id="toc-sec-llm-integration" class="nav-link" data-scroll-target="#sec-llm-integration"><span class="header-section-number">4.2.3.2</span> LLM Integration Strategy</a></li>
  </ul></li>
  <li><a href="#sec-dag-structure" id="toc-sec-dag-structure" class="nav-link" data-scroll-target="#sec-dag-structure"><span class="header-section-number">4.2.4</span> Directed Acyclic Graphs: Structure and Semantics</a>
  <ul class="collapse">
  <li><a href="#sec-formal-properties" id="toc-sec-formal-properties" class="nav-link" data-scroll-target="#sec-formal-properties"><span class="header-section-number">4.2.4.1</span> Formal Properties</a></li>
  <li><a href="#sec-causal-interpretation" id="toc-sec-causal-interpretation" class="nav-link" data-scroll-target="#sec-causal-interpretation"><span class="header-section-number">4.2.4.2</span> Causal Interpretation</a></li>
  </ul></li>
  <li><a href="#sec-quantification" id="toc-sec-quantification" class="nav-link" data-scroll-target="#sec-quantification"><span class="header-section-number">4.2.5</span> Quantification of Probabilistic Judgments</a>
  <ul class="collapse">
  <li><a href="#sec-qualitative-to-quantitative" id="toc-sec-qualitative-to-quantitative" class="nav-link" data-scroll-target="#sec-qualitative-to-quantitative"><span class="header-section-number">4.2.5.1</span> From Qualitative to Quantitative</a></li>
  <li><a href="#sec-expert-elicitation" id="toc-sec-expert-elicitation" class="nav-link" data-scroll-target="#sec-expert-elicitation"><span class="header-section-number">4.2.5.2</span> Expert Elicitation Methods</a></li>
  </ul></li>
  <li><a href="#sec-inference-techniques" id="toc-sec-inference-techniques" class="nav-link" data-scroll-target="#sec-inference-techniques"><span class="header-section-number">4.2.6</span> Inference Techniques for Complex Networks</a></li>
  <li><a href="#sec-prediction-markets" id="toc-sec-prediction-markets" class="nav-link" data-scroll-target="#sec-prediction-markets"><span class="header-section-number">4.2.7</span> Integration with Prediction Markets and Forecasting Platforms</a>
  <ul class="collapse">
  <li><a href="#sec-live-data" id="toc-sec-live-data" class="nav-link" data-scroll-target="#sec-live-data"><span class="header-section-number">4.2.7.1</span> Live Data Sources</a></li>
  <li><a href="#sec-data-processing" id="toc-sec-data-processing" class="nav-link" data-scroll-target="#sec-data-processing"><span class="header-section-number">4.2.7.2</span> Data Processing Pipeline</a></li>
  </ul></li>
  </ul></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/VJMeyer/submission/edit/main/chapters/2.Context.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div><div class="quarto-code-links"><h2>Code Links</h2><ul><li><a href="https://colab.research.google.com/github/VJMeyer/submission/blob/main/AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb"><i class="bi bi-file-code"></i>Colab Notebook (Manual Link in .yml)</a></li><li><a href="https://github.com/VJMeyer/submission"><i class="bi bi-github"></i>GitHub Repository</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Context</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<pre><code>### 20% of Grade: ~ 29% of text ~ 8700 words ~ 20 pages

- demonstrates understanding of all relevant core concepts

- explains why the question/thesis/problem is relevant in student’s own words (supported by quotations)

- situates it within the debate/course material

- reconstructs selected arguments and identifies relevant assumptions

- describes additional relevant material that has been consulted and integrates it with the course material as well as the research question/thesis/problem
</code></pre>
<!-- 1. successively (chunk my chunk) introduce concepts/ideas ---
and 2. ground each with existing literature -->
<section id="sec-context" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Context &amp; Background</h1>
<!-- [ ] Expand this section to ~29% of total text (approximately 8700 words) -->
<!-- ---
title: "Background"
# Control if this file starts numbering
numbering:
  start-at: 2      # Start at Section 1
  level: 2         # Chapter level
--- -->
<section id="sec-theoretical-foundations" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="sec-theoretical-foundations"><span class="header-section-number">4.1</span> Theoretical Foundations</h2>
<!-- demonstrates understanding of all relevant core concepts -->
<!-- explains why the question/thesis/problem is relevant in student's own words (supported by quotations) -->
<!-- situates it within the debate/course material -->
<!-- reconstructs selected arguments and identifies relevant assumptions -->
<section id="sec-carlsmith-model" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="sec-carlsmith-model"><span class="header-section-number">4.1.1</span> AI Existential Risk: The Carlsmith Model</h3>
<!-- [ ] Examine Joe Carlsmith's probabilistic model of power-seeking AI causing existential catastrophe -->
<!-- [ ] Unpack the six key premises and explain why this structured approach serves as an ideal candidate for formal modeling -->
<blockquote class="blockquote">
<p>Carlsmith’s “Is power-seeking AI an existential risk?” (2021) represents one of the most structured approaches to assessing the probability of existential catastrophe from advanced AI. The analysis decomposes the overall risk into six key premises, each with an explicit probability estimate.</p>
</blockquote>
<blockquote class="blockquote">
<p><span class="citation" data-cites="carlsmith2021">Carlsmith (<a href="../ref/references.html#ref-carlsmith2021" role="doc-biblioref">2021</a>)</span> provides the canonical structured approach to AI existential risk assessment</p>
</blockquote>
<p><strong>Six-Premise Decomposition:</strong></p>
<p><code>Carlsmith decomposes existential risk into a probabilistic chain with explicit estimates:</code></p>
<ol type="1">
<li><strong>Premise 1</strong>: Transformative AI development this century (P ≈ 0.80)</li>
<li><strong>Premise 2</strong>: AI systems pursuing objectives in the world (P ≈ 0.95)</li>
<li><strong>Premise 3</strong>: Systems with power-seeking instrumental incentives (P ≈ 0.40)</li>
<li><strong>Premise 4</strong>: Sufficient capability for existential threat (P ≈ 0.65)</li>
<li><strong>Premise 5</strong>: Misaligned systems despite safety efforts (P ≈ 0.50)</li>
<li><strong>Premise 6</strong>: Catastrophic outcomes from misaligned power-seeking (P ≈ 0.65)</li>
</ol>
<p><strong>Composite Risk Calculation</strong>: P(doom) ≈ 0.05 (5%) ~5% probability of existential catastrophe</p>
<blockquote class="blockquote">
<p>This structured approach exemplifies the type of reasoning that AMTAIR aims to formalize and automate, providing both transparency in assumptions and modularity for critique and refinement.</p>
</blockquote>
<p><code>Carlsmith's model exemplifies the type of structured reasoning that AMTAIR aims to formalize and automate</code></p>
<section id="sec-carlsmith-ideal" class="level4" data-number="4.1.1.1">
<h4 data-number="4.1.1.1" class="anchored" data-anchor-id="sec-carlsmith-ideal"><span class="header-section-number">4.1.1.1</span> Why Carlsmith as Ideal Formalization Target</h4>
<pre><code>- Explicitly probabilistic reasoning with quantified estimates
- Clear conditional dependencies between premises  
- Transparent decomposition of complex causal pathways
- Well-documented argumentation available for extraction validation
- Policy-relevant implications requiring formal evaluation</code></pre>
<p><strong>Formalization Potential:</strong></p>
<p><code>Carlsmith's model represents "low-hanging fruit" for automated formalization because it already exhibits explicit probabilistic reasoning with clear conditional dependencies. Success with this structured argument validates the approach for less explicit arguments throughout AI safety literature.</code></p>
</section>
</section>
<section id="sec-epistemic-challenge" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="sec-epistemic-challenge"><span class="header-section-number">4.1.2</span> The Epistemic Challenge of Policy Evaluation</h3>
<!-- [ ] Explore why evaluating AI governance policies is particularly difficult: complex causal chains, deep uncertainty, divergent worldviews, and limited empirical data -->
<!-- [ ] Establish why traditional policy analysis methods are insufficient -->
<blockquote class="blockquote">
<p>AI governance policy evaluation faces unique epistemic challenges that render traditional policy analysis methods insufficient. The domain combines complex causal chains with limited empirical grounding, deep uncertainty about future capabilities, divergent stakeholder worldviews, and few opportunities for experimental testing before deployment.</p>
</blockquote>
<p>`Traditional methods fall short in several ways:</p>
<ul>
<li>Cost-benefit analysis struggles with existential outcomes and deep uncertainty</li>
<li>Scenario planning often lacks probabilistic reasoning necessary for rigorous evaluation</li>
<li>Expert elicitation alone fails to formalize interdependencies between variables</li>
<li>Qualitative approaches obscure crucial assumptions that drive conclusions`</li>
</ul>
<p><strong>Unprecedented Epistemic Environment:</strong></p>
<blockquote class="blockquote">
<p>AI governance policy evaluation faces challenges that render traditional policy analysis methods insufficient: complex causal chains, deep uncertainty about unprecedented capabilities, divergent stakeholder worldviews, and limited opportunities for empirical validation.</p>
</blockquote>
<pre><code>Specific challenges include:

• **Deep Uncertainty**: Many decisions involve unprecedented scenarios without historical frequency data
• **Complex Causality**: Policy effects propagate through multi-level dependencies (technical → institutional → strategic)
• **Multidisciplinary Integration**: Combining technical facts, ethical principles, and strategic considerations
• **Value-Laden Assessment**: Risk evaluation inherently involves normative judgments about acceptable outcomes</code></pre>
<section id="sec-unique-difficulties" class="level4" data-number="4.1.2.1">
<h4 data-number="4.1.2.1" class="anchored" data-anchor-id="sec-unique-difficulties"><span class="header-section-number">4.1.2.1</span> Unique Difficulties in AI Governance</h4>
<p><strong>Complex Causal Chains</strong>: Multi-level dependencies between technical capabilities, institutional responses, and strategic outcomes</p>
<p><strong>Deep Uncertainty</strong>: Unprecedented AI capabilities make historical analogies insufficient</p>
<blockquote class="blockquote">
<p><span class="citation" data-cites="lempert2003">Lempert, Popper, and Bankes (<a href="../ref/references.html#ref-lempert2003" role="doc-biblioref">2003</a>)</span> on robust decision-making under deep uncertainty</p>
</blockquote>
<p><strong>Divergent Worldviews</strong>: Fundamental disagreements about:</p>
<ul>
<li>Timeline expectations for transformative AI</li>
<li>Difficulty of alignment problems</li>
<li>Effectiveness of governance interventions</li>
<li>International coordination possibilities</li>
</ul>
</section>
<section id="sec-traditional-limitations" class="level4" data-number="4.1.2.2">
<h4 data-number="4.1.2.2" class="anchored" data-anchor-id="sec-traditional-limitations"><span class="header-section-number">4.1.2.2</span> Limitations of Traditional Policy Analysis</h4>
<!-- Critical assessment of existing approaches -->
<ul>
<li><strong>Cost-Benefit Analysis</strong>: Struggles with existential outcomes and infinite expected values</li>
<li><strong>Scenario Planning</strong>: Lacks probabilistic reasoning and uncertainty quantification</li>
<li><strong>Expert Elicitation</strong>: Fails to formalize complex interdependencies between variables</li>
<li><strong>Qualitative Frameworks</strong>: Obscure crucial assumptions and parameter sensitivities</li>
</ul>
<p><strong>Limitations of Traditional Approaches:</strong></p>
<ul>
<li><strong>Cost-Benefit Analysis</strong>: Struggles with existential outcomes and infinite expected values</li>
<li><strong>Scenario Planning</strong>: Often lacks probabilistic reasoning necessary for rigorous uncertainty quantification</li>
<li><strong>Expert Elicitation</strong>: Fails to formalize complex interdependencies between variables and assumptions</li>
<li><strong>Qualitative Frameworks</strong>: Obscure crucial assumptions and parameter sensitivities driving conclusions</li>
</ul>
<blockquote class="blockquote">
<p><span class="citation" data-cites="lempert2003">Lempert, Popper, and Bankes (<a href="../ref/references.html#ref-lempert2003" role="doc-biblioref">2003</a>)</span> on robust decision-making under deep uncertainty provides methodological foundations, but application to AI governance requires novel integration of argument mapping with probabilistic modeling.</p>
</blockquote>
</section>
</section>
<section id="sec-argument-mapping" class="level3" data-number="4.1.3">
<h3 data-number="4.1.3" class="anchored" data-anchor-id="sec-argument-mapping"><span class="header-section-number">4.1.3</span> Argument Mapping and Formal Representations</h3>
<!-- [ ] Bridge informal reasoning to formal models by showing how argument maps capture causal relationships and conditional dependencies that can be translated into Bayesian networks -->
<blockquote class="blockquote">
<p>Argument mapping offers a bridge between informal reasoning in natural language and the formal representations needed for rigorous analysis. By explicitly identifying claims, premises, inferential relationships, and support/attack patterns, argument maps make implicit reasoning structures visible for examination and critique.</p>
</blockquote>
<p><code>The progression from natural language arguments to formal Bayesian networks requires an intermediate representation that preserves narrative structure while adding mathematical precision. The ArgDown format serves this purpose by encoding hierarchical relationships between statements, while its extension, BayesDown, adds probabilistic metadata to enable full Bayesian network construction.</code></p>
<pre><code>[Effect_Node]: Description of effect. {"instantiations": ["effect_TRUE", "effect_FALSE"]}
 + [Cause_Node]: Description of direct cause. {"instantiations": ["cause_TRUE", "cause_FALSE"]}
   + [Root_Cause]: Description of indirect cause. {"instantiations": ["root_TRUE", "root_FALSE"]}</code></pre>
</section>
<section id="sec-bayesian-networks" class="level3" data-number="4.1.4">
<h3 data-number="4.1.4" class="anchored" data-anchor-id="sec-bayesian-networks"><span class="header-section-number">4.1.4</span> Bayesian Networks as Knowledge Representation</h3>
<!-- [ ] Introduce Bayesian networks as formal tools for representing uncertainty, causal relationships, and conditional dependencies -->
<!-- [ ] Explain key concepts: nodes, edges, conditional probability tables, and inference -->
<blockquote class="blockquote">
<p>Bayesian networks provide a formal mathematical framework for representing causal relationships and reasoning under uncertainty. These directed acyclic graphs (DAGs) combine qualitative structure—nodes representing variables and edges representing dependencies—with quantitative parameters in the form of conditional probability tables.</p>
</blockquote>
<p>`Key properties that make Bayesian networks particularly suited to AI risk modeling include:</p>
<ul>
<li>Natural representation of causal relationships between variables</li>
<li>Explicit handling of uncertainty through probability distributions</li>
<li>Support for evidence updating through Bayesian inference</li>
<li>Capability for interventional reasoning through do-calculus</li>
<li>Balance between mathematical rigor and intuitive visual representation`</li>
</ul>
<div id="fig-bayesian-network" class="quarto-float quarto-figure quarto-figure-center anchored" width="70%" data-fig-align="center" alt="A directed acyclic graph showing a simple Bayesian network with nodes and edges">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bayesian-network-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://claude.ai/chat/ab8988f3-18b7-45a5-8a50-b25aa4b34cbf"><img src="../images/pipeline.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%" alt="A directed acyclic graph showing a simple Bayesian network with nodes and edges"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bayesian-network-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.1: Example Bayesian Network
</figcaption>
</figure>
</div>
<section id="sec-mathematical-foundations" class="level4" data-number="4.1.4.1">
<h4 data-number="4.1.4.1" class="anchored" data-anchor-id="sec-mathematical-foundations"><span class="header-section-number">4.1.4.1</span> Mathematical Foundations</h4>
<p><code>Bayesian networks provide a formal mathematical framework for representing causal relationships and reasoning under uncertainty through Directed Acyclic Graphs (DAGs) combining qualitative structure with quantitative parameters.</code></p>
<p><strong>Directed Acyclic Graphs (DAGs)</strong>:</p>
<p><strong>Core Components:</strong></p>
<ul>
<li><strong>Nodes</strong>: Variables with discrete states representing propositions or factors</li>
<li><strong>Edges</strong>: Directed relationships representing conditional dependencies</li>
<li><strong>Acyclicity</strong>: Ensuring coherent probabilistic interpretation without circular dependencies</li>
</ul>
<p>BNs:<!-- [ ] Explain BNs vs DAGs --></p>
<ul>
<li><strong>Conditional Probability Tables</strong>: Quantifying P(Node|Parents) for all parent state combinations</li>
</ul>
<p><strong>Probability Factorization</strong>: <span class="math inline">\(P(X_1, X_2, ..., X_n) = \prod_{i=1}^{n} P(X_i | Parents(X_i))\)</span></p>
</section>
<section id="sec-rain-sprinkler-example" class="level4" data-number="4.1.4.2">
<h4 data-number="4.1.4.2" class="anchored" data-anchor-id="sec-rain-sprinkler-example"><span class="header-section-number">4.1.4.2</span> The Rain-Sprinkler-Grass Example</h4>
<!-- Introduce canonical example used throughout thesis -->
<p><strong>The Rain-Sprinkler-Grass Canonical Example:</strong></p>
<p><code>This simple example demonstrates all key concepts while remaining intuitive</code></p>
<p><strong>Network Structure</strong>:</p>
<ul>
<li><strong>Rain</strong> (root cause): P(rain) = 0.2</li>
<li><strong>Sprinkler</strong> (intermediate): P(sprinkler|rain) varies by rain state</li>
<li><strong>Grass_Wet</strong> (effect): P(wet|rain, sprinkler) depends on both causes</li>
</ul>
<p><strong>Inference Capabilities</strong>:</p>
<ul>
<li><p>Marginal probabilities: P(grass_wet) = ?</p></li>
<li><p>Conditional queries: P(rain|grass_wet) = ?</p></li>
<li><p>Counterfactual analysis: P(grass_wet|do(sprinkler=false)) = ?</p></li>
<li><p>Marginal probabilities: P(grass_wet) computed from joint distribution</p></li>
<li><p>Conditional queries: P(rain|grass_wet) for diagnostic reasoning</p></li>
<li><p>Counterfactual analysis: P(grass_wet|do(sprinkler=false)) for intervention effects</p></li>
</ul>
<pre><code>python
# Basic network representation
nodes = ['Rain', 'Sprinkler', 'Grass_Wet']
edges = [('Rain', 'Sprinkler'), ('Rain', 'Grass_Wet'), ('Sprinkler', 'Grass_Wet')]

# Conditional probability specification
P_wet_given_causes = {
    (True, True): 0.99,    # Rain=T, Sprinkler=T
    (True, False): 0.80,   # Rain=T, Sprinkler=F  
    (False, True): 0.90,   # Rain=F, Sprinkler=T
    (False, False): 0.01   # Rain=F, Sprinkler=F
}</code></pre>
</section>
<section id="sec-modeling-advantages" class="level4" data-number="4.1.4.3">
<h4 data-number="4.1.4.3" class="anchored" data-anchor-id="sec-modeling-advantages"><span class="header-section-number">4.1.4.3</span> Advantages for AI Risk Modeling</h4>
<ul>
<li><strong>Explicit Uncertainty</strong>: All beliefs represented with probability distributions rather than point estimates</li>
<li><strong>Causal Reasoning</strong>: Native support for intervention analysis and counterfactual reasoning through do-calculus</li>
<li><strong>Evidence Integration</strong>: Bayesian updating enables principled incorporation of new information</li>
<li><strong>Modular Structure</strong>: Complex arguments decomposed into manageable, verifiable components</li>
<li><strong>Visual Communication</strong>: Graphical representation facilitates understanding across expertise levels</li>
</ul>
<!-- ### Argument Mapping and Formal Representations {#sec-argument-mapping} -->
</section>
<section id="sec-natural-to-formal" class="level4" data-number="4.1.4.4">
<h4 data-number="4.1.4.4" class="anchored" data-anchor-id="sec-natural-to-formal"><span class="header-section-number">4.1.4.4</span> From Natural Language to Formal Models</h4>
<p><strong>The Representation Challenge</strong>: How to preserve narrative richness while enabling mathematical analysis</p>
<p><code>The core methodological challenge involves preserving narrative richness of natural language arguments while enabling mathematical analysis—bridging interpretive reasoning favored in philosophy with quantitative prediction favored in technical fields.</code></p>
<p><strong>ArgDown Syntax</strong>:</p>
<pre><code>[Conclusion]: Description of the conclusion.
 + [Premise1]: Supporting evidence or reasoning.
   + [Sub-premise]: More detailed supporting factor.
 + [Premise2]: Additional independent support.</code></pre>
<p><code>ArgDown uses hierarchical indentation to capture support/attack relationships between statements, making argument structure explicit while remaining human-readable.</code></p>
</section>
<section id="sec-bayesdown-innovation" class="level4" data-number="4.1.4.5">
<h4 data-number="4.1.4.5" class="anchored" data-anchor-id="sec-bayesdown-innovation"><span class="header-section-number">4.1.4.5</span> BayesDown: The Critical Innovation</h4>
<!-- [ ] Introduce AMTAIR's key technical contribution -->
<p><code>BayesDown extends ArgDown with probabilistic metadata, creating a hybrid format that bridges natural language and mathematical modeling:</code></p>
<pre><code>json
{
  "instantiations": ["conclusion_TRUE", "conclusion_FALSE"],
  "priors": {"p(conclusion_TRUE)": "0.7", "p(conclusion_FALSE)": "0.3"},
  "posteriors": {
    "p(conclusion_TRUE|premise1_TRUE,premise2_TRUE)": "0.9",
    "p(conclusion_TRUE|premise1_TRUE,premise2_FALSE)": "0.6",
    "p(conclusion_TRUE|premise1_FALSE,premise2_TRUE)": "0.4",
    "p(conclusion_TRUE|premise1_FALSE,premise2_FALSE)": "0.1"
  }
}</code></pre>
<p><strong>Design Principles</strong>:</p>
<ul>
<li><strong>Human Readable</strong>: Preserves natural language explanations</li>
<li><strong>Machine Processable</strong>: Structured for automated analysis</li>
<li><strong>Probabilistically Complete</strong>: Contains all information for Bayesian network construction</li>
<li><strong>Extensible</strong>: Supports additional metadata as needed</li>
</ul>
</section>
</section>
<section id="sec-mtair-framework" class="level3" data-number="4.1.5">
<h3 data-number="4.1.5" class="anchored" data-anchor-id="sec-mtair-framework"><span class="header-section-number">4.1.5</span> The MTAIR Framework: Achievements and Limitations</h3>
<!-- [ ] Review the MTAIR project's approach to modeling AI risks using Analytica, highlighting both its innovations and limitations, particularly the manual labor intensity that limits scalability -->
<blockquote class="blockquote">
<p><span class="citation" data-cites="bucknall2022">Bucknall and Dori-Hacohen (<a href="../ref/references.html#ref-bucknall2022" role="doc-biblioref">2022</a>)</span> on the original Modeling Transformative AI Risks project demonstrates both the value and limitations of manual formal modeling approaches.</p>
</blockquote>
<blockquote class="blockquote">
<p>The Modeling Transformative AI Risks (MTAIR) project demonstrated the value of formal probabilistic modeling for AI safety, but also revealed significant limitations in the manual approach. While MTAIR successfully translated complex arguments into Bayesian networks and enabled sensitivity analysis, the intensive human labor required for model creation limited both scalability and timeliness.</p>
</blockquote>
<section id="sec-mtair-innovations" class="level4" data-number="4.1.5.1">
<h4 data-number="4.1.5.1" class="anchored" data-anchor-id="sec-mtair-innovations"><span class="header-section-number">4.1.5.1</span> MTAIR’s Innovations</h4>
<blockquote class="blockquote">
<p><span class="citation" data-cites="bucknall2022">Bucknall and Dori-Hacohen (<a href="../ref/references.html#ref-bucknall2022" role="doc-biblioref">2022</a>)</span> on the original Modeling Transformative AI Risks project</p>
</blockquote>
<ul>
<li><strong>Structured Uncertainty Representation</strong>: Explicit probability distributions over key variables</li>
<li><strong>Expert Judgment Integration</strong>: Systematic methods for aggregating diverse opinions</li>
<li><strong>Sensitivity Analysis</strong>: Identification of critical uncertainties driving outcomes</li>
<li><strong>Policy Application</strong>: Connection between technical models and governance implications</li>
</ul>
<p><strong>MTAIR’s Key Innovations:</strong></p>
<ul>
<li><strong>Structured Uncertainty Representation</strong>: Explicit probability distributions over key variables rather than point estimates</li>
<li><strong>Expert Judgment Integration</strong>: Systematic methods for aggregating diverse expert opinions and beliefs</li>
<li><strong>Sensitivity Analysis</strong>: Identification of critical uncertainties that most significantly drive overall conclusions</li>
<li><strong>Policy Application</strong>: Direct connection between technical risk models and governance implications</li>
</ul>
<p>`MTAIR’s key innovations included:</p>
<ul>
<li>Explicit representation of uncertainty through probability distributions</li>
<li>Structured decomposition of complex risk scenarios</li>
<li>Integration of diverse expert judgments</li>
<li>Sensitivity analysis to identify critical parameters</li>
</ul>
</section>
<section id="sec-mtair-limitations" class="level4" data-number="4.1.5.2">
<h4 data-number="4.1.5.2" class="anchored" data-anchor-id="sec-mtair-limitations"><span class="header-section-number">4.1.5.2</span> Fundamental Limitations Motivating AMTAIR</h4>
<p><strong>Scalability Bottleneck</strong>: Manual model construction requires weeks of expert effort per model</p>
<p><strong>Static Models</strong>: No mechanisms for updating as new research emerges</p>
<p><strong>Limited Accessibility</strong>: Technical complexity restricts usage to specialists</p>
<p><strong>Single Worldview Focus</strong>: Difficulty representing multiple perspectives simultaneously</p>
<p><code>These limitations create the opportunity for automated approaches that can scale formal modeling to match the pace of AI governance discourse</code></p>
<p><strong>Fundamental Limitations Motivating AMTAIR:</strong></p>
<pre><code>Critical constraints of manual approaches:

• **Scalability Bottleneck**: Manual model construction requires weeks of expert effort per argument
• **Static Nature**: No mechanisms for updating models as new research and evidence emerges  
• **Limited Accessibility**: Technical complexity restricts usage to specialists with formal modeling expertise
• **Single Worldview Focus**: Difficulty representing multiple conflicting perspectives simultaneously</code></pre>
<p><code>These limitations create a clear opportunity for automated approaches that can scale formal modeling to match the pace and diversity of AI governance discourse.</code></p>
<p>Its limitations motivated the current automated approach:</p>
<ul>
<li>Manual labor intensity limiting scalability</li>
<li>Static nature of models once constructed</li>
<li>Limited accessibility for non-technical stakeholders</li>
<li>Challenges in representing multiple worldviews simultaneously`</li>
</ul>
</section>
</section>
<section id="sec-narrow-path" class="level3" data-number="4.1.6">
<h3 data-number="4.1.6" class="anchored" data-anchor-id="sec-narrow-path"><span class="header-section-number">4.1.6</span> “A Narrow Path”: Conditional Policy Proposals in Practice</h3>
<!-- [ ] Examine "A Narrow Path" as a case study of conditional policy proposals, highlighting how formal modeling could clarify the conditions under which specific policy interventions would be effective -->
<!-- [ ] Examine conditional policy proposals highlighting formal modeling potential -->
<blockquote class="blockquote">
<p>“A Narrow Path” represents influential example of conditional policy proposals in AI governance—identifying interventions that could succeed under specific conditions rather than universal prescriptions.</p>
</blockquote>
<p><code>However, these conditions remain implicitly defined and qualitatively described, limiting rigorous evaluation and comparison across alternative approaches.</code></p>
<blockquote class="blockquote">
<p>“A Narrow Path” represents an influential example of conditional policy proposals in AI governance—identifying interventions that could succeed under specific conditions rather than absolute prescriptions. However, these conditions remain implicitly defined and qualitatively described, limiting rigorous evaluation.</p>
</blockquote>
<p>`Formal modeling could enhance such proposals by:</p>
<ul>
<li>Making conditions explicit and quantifiable</li>
<li>Clarifying when interventions would be effective</li>
<li>Identifying which uncertainties most significantly affect outcomes</li>
<li>Enabling systematic comparison of alternative approaches</li>
<li>Supporting robust policy development across possible futures`</li>
</ul>
<p><strong>Formal Modeling Enhancement Potential:</strong></p>
<ul>
<li>Making conditions explicit and quantifiable rather than implicit assumptions</li>
<li>Clarifying specific circumstances when interventions would be effective versus ineffective</li>
<li>Identifying which uncertainties most significantly affect intervention outcomes</li>
<li>Enabling systematic comparison of alternative policy approaches under uncertainty</li>
<li>Supporting robust policy development that performs well across multiple possible futures</li>
</ul>
<!-- ---
title: "Methodology"
# Control if this file starts numbering
numbering:
  start-at: 2      # Start at Section 1
  level: 2         # Chapter level
--- -->
</section>
</section>
<section id="sec-methodology" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="sec-methodology"><span class="header-section-number">4.2</span> Methodology</h2>
<section id="sec-research-design" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="sec-research-design"><span class="header-section-number">4.2.1</span> Research Design Overview</h3>
<!-- [ ] Present the overall research approach, combining theoretical development, software implementation, validation testing, and policy application -->
<!-- [ ] Clarify the iterative nature of the process -->
<blockquote class="blockquote">
<p>This research combines theoretical development with practical implementation, following an iterative approach that moves between conceptual refinement and technical validation. The methodology encompasses formal framework development, computational implementation, extraction quality assessment, and application to real-world AI governance questions.</p>
</blockquote>
<p>`The research process follows four main phases:</p>
<ol type="1">
<li>Framework development: Creating the theoretical foundations and formal representations</li>
<li>System implementation: Building the computational tools for extraction and analysis</li>
<li>Validation testing: Assessing extraction quality and system performance</li>
<li>Application evaluation: Applying the framework to concrete AI governance questions`</li>
</ol>
<section id="sec-hybrid-approach" class="level4" data-number="4.2.1.1">
<h4 data-number="4.2.1.1" class="anchored" data-anchor-id="sec-hybrid-approach"><span class="header-section-number">4.2.1.1</span> Hybrid Theoretical-Empirical Approach</h4>
<!-- [ ] Present hybrid theoretical-empirical approach with iterative development -->
<p><strong>Four Integrated Components</strong>:</p>
<ol type="1">
<li><strong>Theoretical Development</strong>: Formal framework for automated worldview extraction</li>
<li><strong>Technical Implementation</strong>: Working prototype demonstrating feasibility</li>
<li><strong>Empirical Validation</strong>: Quality assessment against expert benchmarks</li>
<li><strong>Policy Application</strong>: Case studies with real governance questions</li>
</ol>
<p><strong>Four Primary Components:</strong></p>
<ol type="1">
<li><strong>Theoretical Development</strong>: Formal framework for automated worldview extraction and representation</li>
<li><strong>Technical Implementation</strong>: Working prototype demonstrating feasibility and validation</li>
<li><strong>Empirical Validation</strong>: Quality assessment against expert benchmarks and known ground truth</li>
<li><strong>Policy Application</strong>: Case studies demonstrating practical utility for real governance questions</li>
</ol>
<p><strong>Iterative Development Process:</strong></p>
<pre><code>Phase 1: Conceptual Framework Development
↓
Phase 2: Prototype Implementation with Simple Validation Examples  
↓
Phase 3: Complex Real-World Case Application and Evaluation
↓
Phase 4: Policy Impact Assessment and Governance Integration</code></pre>
</section>
<section id="sec-iterative-process" class="level4" data-number="4.2.1.2">
<h4 data-number="4.2.1.2" class="anchored" data-anchor-id="sec-iterative-process"><span class="header-section-number">4.2.1.2</span> Iterative Development Process</h4>
<pre><code>Phase 1: Conceptual Framework Development
Phase 2: Prototype Implementation with Simple Examples  
Phase 3: Validation with Complex Real-World Cases
Phase 4: Policy Application and Evaluation</code></pre>
</section>
</section>
<section id="sec-formalizing-world-models" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="sec-formalizing-world-models"><span class="header-section-number">4.2.2</span> Formalizing World Models from AI Safety Literature</h3>
<!-- [ ] Detail the process of extracting causal relationships, key variables, and probabilistic judgments from AI safety literature -->
<!-- [ ] Explain the role of LLMs in this process and the development of prompt engineering techniques to improve extraction quality -->
<blockquote class="blockquote">
<p>The core methodological challenge involves transforming natural language arguments in AI safety literature into formal causal models with explicit probability judgments. This extraction process identifies key variables, causal relationships, and both explicit and implicit probability estimates through a systematic pipeline.</p>
</blockquote>
<p>`The extraction approach combines:</p>
<ul>
<li>Identification of key variables and entities in text</li>
<li>Recognition of causal claims and relationships</li>
<li>Detection of explicit and implicit probability judgments</li>
<li>Transformation into structured intermediate representations</li>
<li>Conversion to formal Bayesian networks</li>
</ul>
<p>Large language models facilitate this process through:</p>
<ul>
<li>Two-stage prompting that separates structure from probability extraction</li>
<li>Specialized templates for different types of source documents</li>
<li>Techniques for identifying implicit assumptions and relationships</li>
<li>Mechanisms for handling ambiguity and uncertainty`</li>
</ul>
</section>
<section id="sec-natural-to-computational" class="level3" data-number="4.2.3">
<h3 data-number="4.2.3" class="anchored" data-anchor-id="sec-natural-to-computational"><span class="header-section-number">4.2.3</span> From Natural Language to Computational Models</h3>
<!-- [ ] Detail the two-stage extraction process that is core to AMTAIR -->
<p><strong>The Two-Stage Extraction Architecture:</strong></p>
<p><code>AMTAIR employs a novel two-stage process that separates structural argument extraction from probability quantification, enabling modular improvement and human oversight at critical decision points.</code></p>
<section id="sec-two-stage-extraction" class="level4" data-number="4.2.3.1">
<h4 data-number="4.2.3.1" class="anchored" data-anchor-id="sec-two-stage-extraction"><span class="header-section-number">4.2.3.1</span> The Two-Stage Extraction Process</h4>
<p><strong>Stage 1: Structural Extraction (ArgDown)</strong></p>
<ul>
<li>Identify key variables and causal claims</li>
<li>Extract hierarchical argument structure</li>
<li>Map logical relationships between elements</li>
<li>Generate intermediate representation preserving narrative</li>
</ul>
<p><strong>Stage 1: Structural Extraction (ArgDown Generation)</strong></p>
<!-- [ ] Describe argument structure identification process -->
<ul>
<li><strong>Variable and Claim Identification</strong>: Extract key propositions and entities from natural language text</li>
<li><strong>Causal Relationship Mapping</strong>: Identify support/attack relationships and conditional dependencies</li>
<li><strong>Hierarchical Structure Construction</strong>: Generate properly nested argument representations preserving logical flow</li>
<li><strong>Intermediate Representation</strong>: Create ArgDown format suitable for human review and machine processing</li>
</ul>
<pre><code>python
def extract_argument_structure(text):
    """Extract hierarchical argument structure from natural language"""
    # LLM-based extraction with specialized prompts
    prompt = ArgumentExtractionPrompt(
        text=text,
        output_format="ArgDown",
        focus_areas=["causal_claims", "probability_statements", "conditional_reasoning"]
    )
    
    structure = llm.complete(prompt)
    return validate_argdown_syntax(structure)</code></pre>
<p><strong>Stage 2: Probability Integration (BayesDown)</strong></p>
<ul>
<li>Extract explicit probability statements</li>
<li>Generate questions for implicit judgments</li>
<li>Quantify uncertainty and conditional dependencies</li>
<li>Create complete probabilistic specification</li>
</ul>
<p><strong>Stage 2: Probability Integration (BayesDown Enhancement)</strong></p>
<!-- [ ] Explain quantification and validation processes -->
<ul>
<li><strong>Explicit Probability Extraction</strong>: Identify and parse numerical probability statements in source text</li>
<li><strong>Question Generation</strong>: Create systematic elicitation questions for implicit probability judgments</li>
<li><strong>Expert Input Integration</strong>: Incorporate domain expertise for ambiguous or missing quantifications</li>
<li><strong>Consistency Validation</strong>: Ensure probability assignments satisfy basic coherence requirements</li>
</ul>
<pre><code>python
def integrate_probabilities(argdown_structure, probability_sources):
    """Convert ArgDown to BayesDown with probabilistic information"""
    questions = generate_probability_questions(argdown_structure)
    probabilities = extract_probabilities(probability_sources, questions)
    
    bayesdown = enhance_with_probabilities(argdown_structure, probabilities)
    return validate_probability_coherence(bayesdown)</code></pre>
</section>
<section id="sec-llm-integration" class="level4" data-number="4.2.3.2">
<h4 data-number="4.2.3.2" class="anchored" data-anchor-id="sec-llm-integration"><span class="header-section-number">4.2.3.2</span> LLM Integration Strategy</h4>
<!-- Explain how frontier AI enables automated extraction -->
<p><strong>Prompt Engineering Approach</strong>:</p>
<ul>
<li>Specialized prompts for argument structure identification</li>
<li>Two-stage prompting to separate structure from quantification</li>
<li>Validation mechanisms to ensure extraction quality</li>
<li>Iterative refinement based on expert feedback</li>
</ul>
<p><strong>Current Capabilities and Limitations</strong>:</p>
<blockquote class="blockquote">
<p>Frontier LLMs show promising extraction quality but require careful validation</p>
</blockquote>
<p><strong>LLM Integration Strategy:</strong></p>
<blockquote class="blockquote">
<p>Frontier language models enable automated extraction but require careful prompt engineering and validation mechanisms to ensure extraction quality and consistency.</p>
</blockquote>
<ul>
<li><strong>Specialized Prompting</strong>: Domain-specific templates for argument structure identification</li>
<li><strong>Two-Stage Separation</strong>: Structural and probabilistic extraction handled independently for quality control</li>
<li><strong>Validation Mechanisms</strong>: Automated and human review processes for extraction accuracy</li>
<li><strong>Iterative Refinement</strong>: Feedback loops enabling continuous improvement based on expert assessment</li>
</ul>
</section>
</section>
<section id="sec-dag-structure" class="level3" data-number="4.2.4">
<h3 data-number="4.2.4" class="anchored" data-anchor-id="sec-dag-structure"><span class="header-section-number">4.2.4</span> Directed Acyclic Graphs: Structure and Semantics</h3>
<!-- [ ] Explain the mathematical properties of DAGs and their semantic interpretation in the context of AI risk modeling -->
<!-- [ ] Cover both structural and parametric aspects of the models -->
<blockquote class="blockquote">
<p>Directed Acyclic Graphs (DAGs) form the mathematical foundation of Bayesian networks, encoding both the qualitative structure of causal relationships and the quantitative parameters that define conditional dependencies. In AI risk modeling, these structures represent causal pathways to potential outcomes of interest.</p>
</blockquote>
<p>`Key mathematical properties include:</p>
<ul>
<li>Acyclicity, ensuring no feedback loops</li>
<li>Path properties defining information flow</li>
<li>D-separation criteria determining conditional independence</li>
<li>Markov blanket defining minimal contextual information</li>
</ul>
<section id="sec-formal-properties" class="level4" data-number="4.2.4.1">
<h4 data-number="4.2.4.1" class="anchored" data-anchor-id="sec-formal-properties"><span class="header-section-number">4.2.4.1</span> Formal Properties</h4>
<p><strong>Acyclicity Requirement</strong>: Ensures coherent probabilistic interpretation</p>
<p><strong>D-Separation</strong>: Conditional independence relationships between variables</p>
<p><strong>Markov Condition</strong>: Each variable independent of non-descendants given parents</p>
<!-- [ ] Explain mathematical properties and semantic interpretation -->
<p><strong>Formal Properties Essential for AI Risk Modeling:</strong></p>
<ul>
<li><strong>Acyclicity Requirement</strong>: Ensures coherent probabilistic interpretation without logical contradictions</li>
<li><strong>D-Separation</strong>: Defines conditional independence relationships between variables based on graph structure</li>
<li><strong>Markov Condition</strong>: Each variable conditionally independent of non-descendants given parents</li>
<li><strong>Path Analysis</strong>: Causal pathways and information flow through the network structure</li>
</ul>
<p><strong>Causal Interpretation in AI Governance Context:</strong></p>
<blockquote class="blockquote">
<p><span class="citation" data-cites="pearl2009">Pearl (<a href="../ref/references.html#ref-pearl2009" role="doc-biblioref">2009</a>)</span> on causal inference and intervention analysis provides mathematical foundations for policy evaluation through do-calculus.</p>
</blockquote>
<ul>
<li><strong>Edges as Causal Relations</strong>: Directed arrows represent direct causal influence between factors</li>
<li><strong>Intervention Analysis</strong>: Do-calculus enables rigorous evaluation of policy intervention effects</li>
<li><strong>Counterfactual Reasoning</strong>: “What if” scenarios essential for governance planning under uncertainty</li>
<li><strong>Evidence Integration</strong>: Bayesian updating for incorporating new information and expert judgment</li>
</ul>
</section>
<section id="sec-causal-interpretation" class="level4" data-number="4.2.4.2">
<h4 data-number="4.2.4.2" class="anchored" data-anchor-id="sec-causal-interpretation"><span class="header-section-number">4.2.4.2</span> Causal Interpretation</h4>
<!-- Connection to Pearl's causal framework -->
<blockquote class="blockquote">
<p><span class="citation" data-cites="pearl2009">Pearl (<a href="../ref/references.html#ref-pearl2009" role="doc-biblioref">2009</a>)</span> on causal inference and intervention analysis</p>
</blockquote>
<ul>
<li><strong>Edges as Causal Relations</strong>: Directed arrows represent direct causal influence</li>
<li><strong>Intervention Analysis</strong>: Do-calculus for policy evaluation</li>
<li><strong>Counterfactual Reasoning</strong>: “What if” scenarios for governance planning</li>
</ul>
<p>Semantic interpretation in AI risk contexts:</p>
<ul>
<li>Nodes represent key variables in risk pathways</li>
<li>Edges represent causal or inferential relationships</li>
<li>Path blocking corresponds to intervention points</li>
<li>Probability flows represent risk propagation through systems`</li>
</ul>
</section>
</section>
<section id="sec-quantification" class="level3" data-number="4.2.5">
<h3 data-number="4.2.5" class="anchored" data-anchor-id="sec-quantification"><span class="header-section-number">4.2.5</span> Quantification of Probabilistic Judgments</h3>
<!-- [ ] Examine methods for converting qualitative judgments into quantitative probabilities, including expert elicitation, calibration techniques, and sensitivity analysis -->
<!-- [ ] Discuss challenges of aggregating diverse probabilistic judgments -->
<!-- [ ] Examine methods for converting qualitative to quantitative assessments -->
<p><strong>Linguistic Probability Mapping:</strong></p>
<p><code>Transforming qualitative uncertainty expressions into quantitative probabilities requires systematic interpretation frameworks that account for individual and cultural variation.</code></p>
<pre><code>Standard linguistic mappings (with significant individual variation):
• "Very likely" → 0.8-0.9
• "Probable" → 0.6-0.8  
• "Uncertain" → 0.4-0.6
• "Unlikely" → 0.2-0.4
• "Highly improbable" → 0.05-0.15</code></pre>
<blockquote class="blockquote">
<p>Transforming qualitative judgments in AI safety literature into quantitative probabilities requires a systematic approach to interpretation, extraction, and validation. This process combines direct extraction of explicit numerical statements with inference of implicit probability judgments from qualitative language.</p>
</blockquote>
<p>`Quantification methods include:</p>
<ul>
<li>Direct extraction of explicit numerical statements</li>
<li>Linguistic mapping of qualitative expressions</li>
<li>Expert elicitation techniques for ambiguous cases</li>
<li>Bayesian updating from multiple sources</li>
</ul>
<p>Special challenges in AI risk quantification:</p>
<ul>
<li>Deep uncertainty about unprecedented events</li>
<li>Diverse disciplinary languages and conventions</li>
<li>Limited empirical basis for calibration</li>
<li>Value-laden aspects of risk assessment`</li>
</ul>
<section id="sec-qualitative-to-quantitative" class="level4" data-number="4.2.5.1">
<h4 data-number="4.2.5.1" class="anchored" data-anchor-id="sec-qualitative-to-quantitative"><span class="header-section-number">4.2.5.1</span> From Qualitative to Quantitative</h4>
<p><strong>Linguistic Probability Expressions</strong>:</p>
<ul>
<li>“Very likely” → 0.8-0.9</li>
<li>“Uncertain” → 0.4-0.6</li>
<li>“Highly improbable” → 0.05-0.15</li>
</ul>
<p><strong>Calibration Challenges</strong>:</p>
<ul>
<li>Individual variation in linguistic interpretation</li>
<li>Domain-specific probability anchoring</li>
<li>Cultural and contextual influences on uncertainty expression</li>
</ul>
<p><strong>Calibration and Validation Challenges:</strong></p>
<ul>
<li>Individual variation in linguistic interpretation and probability anchoring</li>
<li>Domain-specific probability anchoring and reference class selection</li>
<li>Cultural and contextual influences on uncertainty expression and tolerance</li>
<li>Limited empirical basis for calibration in unprecedented scenarios like transformative AI</li>
</ul>
</section>
<section id="sec-expert-elicitation" class="level4" data-number="4.2.5.2">
<h4 data-number="4.2.5.2" class="anchored" data-anchor-id="sec-expert-elicitation"><span class="header-section-number">4.2.5.2</span> Expert Elicitation Methods</h4>
<pre><code>Direct Probability Assessment: "What is P(outcome)?"
Comparative Assessment: "Is A more likely than B?"  
Frequency Format: "In 100 similar cases, how many would result in outcome?"
Betting Odds: "What odds would you accept for this bet?"</code></pre>
<p><strong>Expert Elicitation Methodologies:</strong></p>
<ul>
<li><strong>Direct Probability Assessment</strong>: “What is P(outcome)?” with calibration training</li>
<li><strong>Comparative Assessment</strong>: “Is A more likely than B?” for relative judgment validation</li>
<li><strong>Frequency Format</strong>: “In 100 similar cases, how many would result in outcome?” for clearer mental models</li>
<li><strong>Betting Odds</strong>: “What odds would you accept for this bet?” for revealed preference elicitation</li>
</ul>
</section>
</section>
<section id="sec-inference-techniques" class="level3" data-number="4.2.6">
<h3 data-number="4.2.6" class="anchored" data-anchor-id="sec-inference-techniques"><span class="header-section-number">4.2.6</span> Inference Techniques for Complex Networks</h3>
<!-- [ ] Review Monte Carlo sampling and other inference techniques for complex Bayesian networks, explaining their application to policy evaluation -->
<!-- [ ] Discuss computational complexity considerations and approximation methods -->
<blockquote class="blockquote">
<p>Once Bayesian networks are constructed, probabilistic inference enables reasoning about uncertainties, counterfactuals, and policy interventions. For the complex networks representing AI risks, computational approaches must balance accuracy with tractability.</p>
</blockquote>
<p>`Inference methods implemented include:</p>
<ul>
<li>Exact methods for smaller networks (variable elimination, junction trees)</li>
<li>Approximate methods for larger networks (Monte Carlo sampling)</li>
<li>Specialized approaches for rare events</li>
<li>Intervention modeling for policy evaluation</li>
</ul>
<p>Implementation considerations include:</p>
<ul>
<li>Computational complexity management</li>
<li>Sampling efficiency optimization</li>
<li>Approximation quality monitoring</li>
<li>Uncertainty representation in outputs`</li>
</ul>
</section>
<section id="sec-prediction-markets" class="level3" data-number="4.2.7">
<h3 data-number="4.2.7" class="anchored" data-anchor-id="sec-prediction-markets"><span class="header-section-number">4.2.7</span> Integration with Prediction Markets and Forecasting Platforms</h3>
<!-- [ ] Detail methods for connecting the formal models with live data sources from prediction markets and forecasting platforms -->
<!-- [ ] Explain data standardization, weighting mechanisms, and update procedures -->
<blockquote class="blockquote">
<p>To maintain relevance in a rapidly evolving field, formal models must integrate with live data sources such as prediction markets and forecasting platforms. This integration enables continuous updating of model parameters as new information emerges.</p>
</blockquote>
<p>`Integration approaches include:</p>
<ul>
<li>API connections to platforms like Metaculus</li>
<li>Semantic mapping between forecast questions and model variables</li>
<li>Weighting mechanisms based on forecaster track records</li>
<li>Update procedures for incorporating new predictions</li>
<li>Feedback loops identifying valuable forecast questions</li>
</ul>
<p>Technical implementation involves:</p>
<ul>
<li>Standardized data formats across platforms</li>
<li>Conflict resolution for contradictory sources</li>
<li>Temporal alignment of forecasts</li>
<li>Confidence-weighted aggregation methods`</li>
</ul>
<!-- [ ] Detail methods for connecting models with live data sources -->
<p><strong>Live Data Sources for Dynamic Model Updating:</strong></p>
<ul>
<li><strong>Metaculus</strong>: Long-term AI predictions and technological forecasting</li>
<li><strong>Good Judgment Open</strong>: Geopolitical events and policy outcomes</li>
<li><strong>Manifold Markets</strong>: Diverse question types with rapid market response</li>
<li><strong>Internal Expert Forecasting</strong>: Organization-specific predictions and assessments</li>
</ul>
<p><strong>Data Processing and Integration Pipeline:</strong></p>
<pre><code>python
def integrate_forecast_data(model_variables, forecast_platforms):
    """Connect Bayesian network variables to live forecasting data"""
    mappings = create_semantic_mappings(model_variables, forecast_platforms)
    
    for variable, forecasts in mappings.items():
        weighted_forecast = aggregate_forecasts(
            forecasts, 
            weights=calculate_track_record_weights(forecasts)
        )
        model.update_prior(variable, weighted_forecast)
    
    return model.recompute_posteriors()</code></pre>
<p><strong>Technical Implementation Challenges:</strong></p>
<ul>
<li><strong>Question Mapping</strong>: Connecting forecast questions to specific model variables with semantic accuracy</li>
<li><strong>Temporal Alignment</strong>: Handling different forecast horizons and update frequencies across platforms</li>
<li><strong>Conflict Resolution</strong>: Principled aggregation when sources provide contradictory information</li>
<li><strong>Track Record Weighting</strong>: Incorporating forecaster calibration and expertise into aggregation weights</li>
</ul>
<section id="sec-live-data" class="level4" data-number="4.2.7.1">
<h4 data-number="4.2.7.1" class="anchored" data-anchor-id="sec-live-data"><span class="header-section-number">4.2.7.1</span> Live Data Sources</h4>
<p><strong>Forecasting Platforms</strong>:</p>
<ul>
<li>Metaculus for long-term AI predictions</li>
<li>Good Judgment Open for geopolitical events</li>
<li>Manifold Markets for diverse question types</li>
<li>Internal expert forecasting within organizations</li>
</ul>
</section>
<section id="sec-data-processing" class="level4" data-number="4.2.7.2">
<h4 data-number="4.2.7.2" class="anchored" data-anchor-id="sec-data-processing"><span class="header-section-number">4.2.7.2</span> Data Processing Pipeline</h4>
<p><strong>Question Mapping</strong>: Connecting forecast questions to model variables</p>
<p><strong>Temporal Alignment</strong>: Handling different forecast horizons and update frequencies</p>
<p><strong>Aggregation Methods</strong>: Weighting sources by track record and relevance</p>
<!-- [ ] Add specific examples of forecast integration -->
<div id="fig-automation_pipeline" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" width="100%" alt="FLOWCHART: Five-step automation pipeline workflow for AMTAIR project.           DATA: The pipeline transforms PDFs through ArgDown, BayesDown, CSV, and HTML into Bayesian network visualizations.           PURPOSE: Illustrates the core technical process that enables automated extraction of probabilistic models from AI safety literature.           DETAILS: Five numbered green steps show: (1) LLM-based extraction from PDFs to ArgDown, (2) ArgDown to BayesDown completion with probabilities, (3) Extracting world-models as CSV data, (4) Software tools for data inference, and (5) Visualization of the resulting Bayesian network.           Each step includes example outputs, with the final visualization showing a Rain-Sprinkler-Grass Wet Bayesian network with probability tables.           SOURCE: Created by the author to explain the AMTAIR methodology           " data-fig-scap="Five-step AMTAIR automation pipeline from PDFs to Bayesian networks">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-automation_pipeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://github.com/VJMeyer/submission"><img src="../images/pipeline.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-scap="Five-step AMTAIR automation pipeline from PDFs to Bayesian networks" alt="FLOWCHART: Five-step automation pipeline workflow for AMTAIR project.           DATA: The pipeline transforms PDFs through ArgDown, BayesDown, CSV, and HTML into Bayesian network visualizations.           PURPOSE: Illustrates the core technical process that enables automated extraction of probabilistic models from AI safety literature.           DETAILS: Five numbered green steps show: (1) LLM-based extraction from PDFs to ArgDown, (2) ArgDown to BayesDown completion with probabilities, (3) Extracting world-models as CSV data, (4) Software tools for data inference, and (5) Visualization of the resulting Bayesian network.           Each step includes example outputs, with the final visualization showing a Rain-Sprinkler-Grass Wet Bayesian network with probability tables.           SOURCE: Created by the author to explain the AMTAIR methodology           "></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-automation_pipeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.2: AMTAIR Automation Pipeline from CITATION
</figcaption>
</figure>
</div>
<p>Testing crossreferencing grapics <a href="#fig-automation_pipeline" class="quarto-xref">Figure&nbsp;<span>4.2</span></a>.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-bucknall2022" class="csl-entry" role="listitem">
Bucknall, Benjamin S., and Shiri Dori-Hacohen. 2022. <span>“Current and <span>Near-Term AI</span> as a <span>Potential Existential Risk Factor</span>.”</span> In <em>Proceedings of the 2022 <span>AAAI</span>/<span>ACM Conference</span> on <span>AI</span>, <span>Ethics</span>, and <span>Society</span></em>, 119–29. Oxford United Kingdom: ACM. <a href="https://doi.org/10.1145/3514094.3534146">https://doi.org/10.1145/3514094.3534146</a>.
</div>
<div id="ref-carlsmith2021" class="csl-entry" role="listitem">
Carlsmith, Joseph. 2021. <span>“Is <span>Power-Seeking AI</span> an <span>Existential Risk</span>?”</span> 2021. <a href="https://doi.org/10.48550/arXiv.2206.13353">https://doi.org/10.48550/arXiv.2206.13353</a>.
</div>
<div id="ref-lempert2003" class="csl-entry" role="listitem">
Lempert, Robert J, Steven W Popper, and Steven C Bankes. 2003. <em>Shaping the Next One Hundred Years: <span>New</span> Methods for Quantitative, Long-Term Policy Analysis</em>. RAND Corporation.
</div>
<div id="ref-pearl2009" class="csl-entry" role="listitem">
Pearl, Judea. 2009. <em>Causality: <span>Models</span>, Reasoning and Inference</em>. 2nd ed. Cambridge University Press.
</div>
</div>
</section>
</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/1.Introduction.html" class="pagination-link" aria-label="Introduction">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/3.AMTAIR.html" class="pagination-link" aria-label="AMTAIR">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">AMTAIR</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/VJMeyer/submission/edit/main/chapters/2.Context.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></div></div></footer></body></html>