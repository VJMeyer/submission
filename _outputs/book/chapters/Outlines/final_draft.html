<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.29">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; Automating the Modeling of Transformative Artificial Intelligence Risks – Automating the Modelling of Transformative Artificial Intelligence Risks</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../ref/references.html" rel="next">
<link href="../../index.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-0815c480559380816a4d1ea211a47e91.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-485d01fc63b59abcd3ee1bf1e8e2748d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/Outlines/final_draft.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Automating the Modeling of Transformative Artificial Intelligence Risks</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Automating the Modelling of Transformative Artificial Intelligence Risks</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/VJMeyer/submission" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="../../Automating-the-Modelling-of-Transformative-Artificial-Intelligence-Risks.pdf">
              <i class="bi bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="../../Automating-the-Modelling-of-Transformative-Artificial-Intelligence-Risks.epub">
              <i class="bi bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-1" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-1">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Abstract</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/Outlines/final_draft.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Automating the Modeling of Transformative Artificial Intelligence Risks</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../ref/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliography</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/manual_extraction_bucknall.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Manual Extraction of ArgDown Data from <span class="citation" data-cites="bucknall2022">Bucknall and Dori-Hacohen (</span></span></span></a><a href="#ref-bucknall2022" role="doc-biblioref">2022</a>)
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#frontmatter-preface" id="toc-frontmatter-preface" class="nav-link active" data-scroll-target="#frontmatter-preface">Frontmatter: Preface</a></li>
  <li><a href="#acknowledgments" id="toc-acknowledgments" class="nav-link" data-scroll-target="#acknowledgments">Acknowledgments</a></li>
  <li><a href="#introduction-the-coordination-crisis-in-ai-governance" id="toc-introduction-the-coordination-crisis-in-ai-governance" class="nav-link" data-scroll-target="#introduction-the-coordination-crisis-in-ai-governance">1. Introduction: The Coordination Crisis in AI Governance</a>
  <ul>
  <li><a href="#opening-scenario-the-policymakers-dilemma" id="toc-opening-scenario-the-policymakers-dilemma" class="nav-link" data-scroll-target="#opening-scenario-the-policymakers-dilemma">1.1 Opening Scenario: The Policymaker’s Dilemma</a></li>
  <li><a href="#the-coordination-crisis-in-ai-governance" id="toc-the-coordination-crisis-in-ai-governance" class="nav-link" data-scroll-target="#the-coordination-crisis-in-ai-governance">1.2 The Coordination Crisis in AI Governance</a>
  <ul>
  <li><a href="#safety-gaps-from-misaligned-efforts" id="toc-safety-gaps-from-misaligned-efforts" class="nav-link" data-scroll-target="#safety-gaps-from-misaligned-efforts">1.2.1 Safety Gaps from Misaligned Efforts</a></li>
  <li><a href="#resource-misallocation" id="toc-resource-misallocation" class="nav-link" data-scroll-target="#resource-misallocation">1.2.2 Resource Misallocation</a></li>
  <li><a href="#negative-sum-dynamics" id="toc-negative-sum-dynamics" class="nav-link" data-scroll-target="#negative-sum-dynamics">1.2.3 Negative-Sum Dynamics</a></li>
  </ul></li>
  <li><a href="#historical-parallels-and-temporal-urgency" id="toc-historical-parallels-and-temporal-urgency" class="nav-link" data-scroll-target="#historical-parallels-and-temporal-urgency">1.3 Historical Parallels and Temporal Urgency</a></li>
  <li><a href="#research-question-and-scope" id="toc-research-question-and-scope" class="nav-link" data-scroll-target="#research-question-and-scope">1.4 Research Question and Scope</a></li>
  <li><a href="#the-multiplicative-benefits-framework" id="toc-the-multiplicative-benefits-framework" class="nav-link" data-scroll-target="#the-multiplicative-benefits-framework">1.5 The Multiplicative Benefits Framework</a>
  <ul>
  <li><a href="#automated-worldview-extraction" id="toc-automated-worldview-extraction" class="nav-link" data-scroll-target="#automated-worldview-extraction">1.5.1 Automated Worldview Extraction</a></li>
  <li><a href="#live-data-integration" id="toc-live-data-integration" class="nav-link" data-scroll-target="#live-data-integration">1.5.2 Live Data Integration</a></li>
  <li><a href="#formal-policy-evaluation" id="toc-formal-policy-evaluation" class="nav-link" data-scroll-target="#formal-policy-evaluation">1.5.3 Formal Policy Evaluation</a></li>
  <li><a href="#the-synergy" id="toc-the-synergy" class="nav-link" data-scroll-target="#the-synergy">1.5.4 The Synergy</a></li>
  </ul></li>
  <li><a href="#thesis-structure-and-roadmap" id="toc-thesis-structure-and-roadmap" class="nav-link" data-scroll-target="#thesis-structure-and-roadmap">1.6 Thesis Structure and Roadmap</a></li>
  </ul></li>
  <li><a href="#context-and-theoretical-foundations" id="toc-context-and-theoretical-foundations" class="nav-link" data-scroll-target="#context-and-theoretical-foundations">2. Context and Theoretical Foundations</a>
  <ul>
  <li><a href="#ai-existential-risk-the-carlsmith-model" id="toc-ai-existential-risk-the-carlsmith-model" class="nav-link" data-scroll-target="#ai-existential-risk-the-carlsmith-model">2.1 AI Existential Risk: The Carlsmith Model</a>
  <ul>
  <li><a href="#six-premise-decomposition" id="toc-six-premise-decomposition" class="nav-link" data-scroll-target="#six-premise-decomposition">2.1.1 Six-Premise Decomposition</a></li>
  <li><a href="#why-carlsmith-exemplifies-formalizable-arguments" id="toc-why-carlsmith-exemplifies-formalizable-arguments" class="nav-link" data-scroll-target="#why-carlsmith-exemplifies-formalizable-arguments">2.1.2 Why Carlsmith Exemplifies Formalizable Arguments</a></li>
  </ul></li>
  <li><a href="#the-epistemic-challenge-of-policy-evaluation" id="toc-the-epistemic-challenge-of-policy-evaluation" class="nav-link" data-scroll-target="#the-epistemic-challenge-of-policy-evaluation">2.2 The Epistemic Challenge of Policy Evaluation</a>
  <ul>
  <li><a href="#unique-characteristics-of-ai-governance" id="toc-unique-characteristics-of-ai-governance" class="nav-link" data-scroll-target="#unique-characteristics-of-ai-governance">2.2.1 Unique Characteristics of AI Governance</a></li>
  <li><a href="#limitations-of-traditional-approaches" id="toc-limitations-of-traditional-approaches" class="nav-link" data-scroll-target="#limitations-of-traditional-approaches">2.2.2 Limitations of Traditional Approaches</a></li>
  <li><a href="#the-underlying-epistemic-framework" id="toc-the-underlying-epistemic-framework" class="nav-link" data-scroll-target="#the-underlying-epistemic-framework">2.2.3 The Underlying Epistemic Framework</a></li>
  <li><a href="#toward-new-epistemic-tools" id="toc-toward-new-epistemic-tools" class="nav-link" data-scroll-target="#toward-new-epistemic-tools">2.2.4 Toward New Epistemic Tools</a></li>
  </ul></li>
  <li><a href="#bayesian-networks-as-knowledge-representation" id="toc-bayesian-networks-as-knowledge-representation" class="nav-link" data-scroll-target="#bayesian-networks-as-knowledge-representation">2.3 Bayesian Networks as Knowledge Representation</a>
  <ul>
  <li><a href="#mathematical-foundations" id="toc-mathematical-foundations" class="nav-link" data-scroll-target="#mathematical-foundations">2.3.1 Mathematical Foundations</a></li>
  <li><a href="#the-rain-sprinkler-grass-example" id="toc-the-rain-sprinkler-grass-example" class="nav-link" data-scroll-target="#the-rain-sprinkler-grass-example">2.3.2 The Rain-Sprinkler-Grass Example</a>
  <ul>
  <li><a href="#rain-sprinkler-grass-network-rendering" id="toc-rain-sprinkler-grass-network-rendering" class="nav-link" data-scroll-target="#rain-sprinkler-grass-network-rendering">2.3.3 Rain-Sprinkler-Grass Network Rendering</a></li>
  </ul></li>
  <li><a href="#sec-modeling-advantages" id="toc-sec-modeling-advantages" class="nav-link" data-scroll-target="#sec-modeling-advantages">2.3.4 Advantages for AI Risk Modeling</a></li>
  </ul></li>
  <li><a href="#sec-argument-mapping" id="toc-sec-argument-mapping" class="nav-link" data-scroll-target="#sec-argument-mapping">2.4 Argument Mapping and Formal Representations</a>
  <ul>
  <li><a href="#sec-natural-to-structure" id="toc-sec-natural-to-structure" class="nav-link" data-scroll-target="#sec-natural-to-structure">2.4.1 From Natural Language to Structure</a></li>
  <li><a href="#sec-argdown-notation" id="toc-sec-argdown-notation" class="nav-link" data-scroll-target="#sec-argdown-notation">2.4.2 ArgDown: Structured Argument Notation</a></li>
  <li><a href="#sec-bayesdown" id="toc-sec-bayesdown" class="nav-link" data-scroll-target="#sec-bayesdown">2.4.3 BayesDown: The Bridge to Bayesian Networks</a></li>
  </ul></li>
  <li><a href="#sec-mtair-framework" id="toc-sec-mtair-framework" class="nav-link" data-scroll-target="#sec-mtair-framework">2.5 The MTAIR Framework: Achievements and Limitations</a>
  <ul>
  <li><a href="#sec-mtair-approach" id="toc-sec-mtair-approach" class="nav-link" data-scroll-target="#sec-mtair-approach">2.5.1 MTAIR’s Approach</a></li>
  <li><a href="#sec-mtair-achievements" id="toc-sec-mtair-achievements" class="nav-link" data-scroll-target="#sec-mtair-achievements">2.5.2 Key Achievements</a></li>
  <li><a href="#sec-mtair-limitations" id="toc-sec-mtair-limitations" class="nav-link" data-scroll-target="#sec-mtair-limitations">2.5.3 Fundamental Limitations</a></li>
  <li><a href="#sec-automation-opportunity" id="toc-sec-automation-opportunity" class="nav-link" data-scroll-target="#sec-automation-opportunity">2.5.4 The Automation Opportunity</a></li>
  </ul></li>
  <li><a href="#sec-literature-review" id="toc-sec-literature-review" class="nav-link" data-scroll-target="#sec-literature-review">2.6 Literature Review: Content and Technical Levels</a>
  <ul>
  <li><a href="#sec-risk-models-evolution" id="toc-sec-risk-models-evolution" class="nav-link" data-scroll-target="#sec-risk-models-evolution">2.6.1 AI Risk Models Evolution</a></li>
  <li><a href="#sec-governance-taxonomy" id="toc-sec-governance-taxonomy" class="nav-link" data-scroll-target="#sec-governance-taxonomy">2.6.2 Governance Proposals Taxonomy</a></li>
  <li><a href="#sec-bn-theory" id="toc-sec-bn-theory" class="nav-link" data-scroll-target="#sec-bn-theory">2.6.3 Bayesian Network Theory and Applications</a></li>
  <li><a href="#sec-software-tools" id="toc-sec-software-tools" class="nav-link" data-scroll-target="#sec-software-tools">2.6.4 Software Tools Landscape</a></li>
  <li><a href="#sec-formalization" id="toc-sec-formalization" class="nav-link" data-scroll-target="#sec-formalization">2.6.5 Formalization Approaches</a></li>
  <li><a href="#sec-correlation-methods" id="toc-sec-correlation-methods" class="nav-link" data-scroll-target="#sec-correlation-methods">2.6.6 Correlation Accounting Methods</a></li>
  </ul></li>
  <li><a href="#sec-methodology" id="toc-sec-methodology" class="nav-link" data-scroll-target="#sec-methodology">2.7 Methodology</a>
  <ul>
  <li><a href="#sec-research-design" id="toc-sec-research-design" class="nav-link" data-scroll-target="#sec-research-design">2.7.1 Research Design Overview</a>
  <ul>
  <li><a href="#the-original-plan" id="toc-the-original-plan" class="nav-link" data-scroll-target="#the-original-plan">The Original Plan</a></li>
  <li><a href="#engineering-experience" id="toc-engineering-experience" class="nav-link" data-scroll-target="#engineering-experience">Engineering Experience</a></li>
  </ul></li>
  <li><a href="#sec-formalizing-world-models" id="toc-sec-formalizing-world-models" class="nav-link" data-scroll-target="#sec-formalizing-world-models">2.7.2 Formalizing World Models from AI Safety Literature</a></li>
  <li><a href="#sec-natural-to-computational" id="toc-sec-natural-to-computational" class="nav-link" data-scroll-target="#sec-natural-to-computational">2.7.3 From Natural Language to Computational Models</a></li>
  <li><a href="#sec-dag-structure" id="toc-sec-dag-structure" class="nav-link" data-scroll-target="#sec-dag-structure">2.7.4 Directed Acyclic Graphs: Structure and Semantics</a></li>
  <li><a href="#sec-quantification" id="toc-sec-quantification" class="nav-link" data-scroll-target="#sec-quantification">2.7.5 Quantification of Probabilistic Judgments</a></li>
  <li><a href="#sec-inference-techniques" id="toc-sec-inference-techniques" class="nav-link" data-scroll-target="#sec-inference-techniques">2.7.6 Inference Techniques for Complex Networks</a></li>
  <li><a href="#sec-prediction-markets" id="toc-sec-prediction-markets" class="nav-link" data-scroll-target="#sec-prediction-markets">2.7.7 Integration with Prediction Markets and Forecasting Platforms</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-amtair" id="toc-sec-amtair" class="nav-link" data-scroll-target="#sec-amtair">3. AMTAIR: Design and Implementation</a>
  <ul>
  <li><a href="#sec-system-architecture" id="toc-sec-system-architecture" class="nav-link" data-scroll-target="#sec-system-architecture">3.1 System Architecture Overview</a>
  <ul>
  <li><a href="#sec-five-stage-pipeline" id="toc-sec-five-stage-pipeline" class="nav-link" data-scroll-target="#sec-five-stage-pipeline">3.1.1 Five-Stage Pipeline Architecture</a></li>
  <li><a href="#sec-design-principles" id="toc-sec-design-principles" class="nav-link" data-scroll-target="#sec-design-principles">3.1.2 Design Principles</a></li>
  </ul></li>
  <li><a href="#sec-two-stage-extraction" id="toc-sec-two-stage-extraction" class="nav-link" data-scroll-target="#sec-two-stage-extraction">3.2 The Two-Stage Extraction Process</a>
  <ul>
  <li><a href="#sec-stage1-argdown" id="toc-sec-stage1-argdown" class="nav-link" data-scroll-target="#sec-stage1-argdown">3.2.1 Stage 1: Structural Extraction (ArgDown)</a></li>
  <li><a href="#sec-stage2-bayesdown" id="toc-sec-stage2-bayesdown" class="nav-link" data-scroll-target="#sec-stage2-bayesdown">3.2.2 Stage 2: Probability Integration (BayesDown)</a></li>
  <li><a href="#sec-why-two-stages" id="toc-sec-why-two-stages" class="nav-link" data-scroll-target="#sec-why-two-stages">3.2.3 Why Two Stages?</a></li>
  </ul></li>
  <li><a href="#sec-implementation-tech" id="toc-sec-implementation-tech" class="nav-link" data-scroll-target="#sec-implementation-tech">3.3 Implementation Technologies</a>
  <ul>
  <li><a href="#sec-tech-stack" id="toc-sec-tech-stack" class="nav-link" data-scroll-target="#sec-tech-stack">3.3.1 Technology Stack</a></li>
  <li><a href="#sec-key-algorithms" id="toc-sec-key-algorithms" class="nav-link" data-scroll-target="#sec-key-algorithms">3.3.2 Key Algorithms</a></li>
  <li><a href="#sec-performance" id="toc-sec-performance" class="nav-link" data-scroll-target="#sec-performance">3.3.3 (Expected) Performance Characteristics</a></li>
  <li><a href="#sec-deterministic-probabilistic" id="toc-sec-deterministic-probabilistic" class="nav-link" data-scroll-target="#sec-deterministic-probabilistic">3.3.4 Deterministic vs.&nbsp;Probabilistic Components of the Workflow</a></li>
  </ul></li>
  <li><a href="#sec-case-rain-sprinkler" id="toc-sec-case-rain-sprinkler" class="nav-link" data-scroll-target="#sec-case-rain-sprinkler">3.4 Case Study: Rain-Sprinkler-Grass</a>
  <ul>
  <li><a href="#sec-rsg-processing" id="toc-sec-rsg-processing" class="nav-link" data-scroll-target="#sec-rsg-processing">3.4.1 Processing Steps</a></li>
  </ul></li>
  <li><a href="#sec-case-carlsmith" id="toc-sec-case-carlsmith" class="nav-link" data-scroll-target="#sec-case-carlsmith">3.5 Case Study: Carlsmith’s Power-Seeking AI Model</a>
  <ul>
  <li><a href="#sec-carlsmith-complexity" id="toc-sec-carlsmith-complexity" class="nav-link" data-scroll-target="#sec-carlsmith-complexity">3.5.1 Model Complexity</a></li>
  <li><a href="#sec-carlsmith-validation" id="toc-sec-carlsmith-validation" class="nav-link" data-scroll-target="#sec-carlsmith-validation">3.5.6 Validation Against Original (From the MTAIR Project)</a></li>
  </ul></li>
  <li><a href="#sec-validation-methodology" id="toc-sec-validation-methodology" class="nav-link" data-scroll-target="#sec-validation-methodology">3.6 Validation Methodology</a>
  <ul>
  <li><a href="#sec-ground-truth" id="toc-sec-ground-truth" class="nav-link" data-scroll-target="#sec-ground-truth">3.6.1 Ground Truth Construction</a></li>
  <li><a href="#sec-evaluation-metrics" id="toc-sec-evaluation-metrics" class="nav-link" data-scroll-target="#sec-evaluation-metrics">3.6.2 Evaluation Metrics</a></li>
  <li><a href="#sec-validation-results" id="toc-sec-validation-results" class="nav-link" data-scroll-target="#sec-validation-results">3.6.3 Results Summary</a></li>
  <li><a href="#sec-error-analysis" id="toc-sec-error-analysis" class="nav-link" data-scroll-target="#sec-error-analysis">3.6.4 Error Analysis</a></li>
  <li><a href="#sec-manual-validation" id="toc-sec-manual-validation" class="nav-link" data-scroll-target="#sec-manual-validation">3.6.5 Independent Manual Extraction Validation</a></li>
  </ul></li>
  <li><a href="#sec-policy-evaluation" id="toc-sec-policy-evaluation" class="nav-link" data-scroll-target="#sec-policy-evaluation">3.7 Policy Evaluation Capabilities</a>
  <ul>
  <li><a href="#sec-intervention-representation" id="toc-sec-intervention-representation" class="nav-link" data-scroll-target="#sec-intervention-representation">3.7.1 Intervention Representation</a></li>
  <li><a href="#sec-deployment-example" id="toc-sec-deployment-example" class="nav-link" data-scroll-target="#sec-deployment-example">3.7.2 Example: Deployment Governance</a></li>
  <li><a href="#sec-robustness" id="toc-sec-robustness" class="nav-link" data-scroll-target="#sec-robustness">3.7.3 Robustness Analysis</a></li>
  </ul></li>
  <li><a href="#sec-visualization-design" id="toc-sec-visualization-design" class="nav-link" data-scroll-target="#sec-visualization-design">3.8 Interactive Visualization Design</a>
  <ul>
  <li><a href="#sec-visual-encoding" id="toc-sec-visual-encoding" class="nav-link" data-scroll-target="#sec-visual-encoding">3.8.1 Visual Encoding Strategy</a></li>
  <li><a href="#sec-progressive-disclosure" id="toc-sec-progressive-disclosure" class="nav-link" data-scroll-target="#sec-progressive-disclosure">3.8.2 Progressive Disclosure</a></li>
  <li><a href="#sec-ui-elements" id="toc-sec-ui-elements" class="nav-link" data-scroll-target="#sec-ui-elements">3.8.3 User Interface Elements</a></li>
  </ul></li>
  <li><a href="#sec-market-integration" id="toc-sec-market-integration" class="nav-link" data-scroll-target="#sec-market-integration">3.9 Integration with Prediction Markets</a>
  <ul>
  <li><a href="#sec-integration-design" id="toc-sec-integration-design" class="nav-link" data-scroll-target="#sec-integration-design">3.9.1 Design for Integration</a></li>
  <li><a href="#sec-market-challenges" id="toc-sec-market-challenges" class="nav-link" data-scroll-target="#sec-market-challenges">3.9.2 Challenges and Opportunities</a></li>
  </ul></li>
  <li><a href="#sec-computational-performance-analysis" id="toc-sec-computational-performance-analysis" class="nav-link" data-scroll-target="#sec-computational-performance-analysis">3.10 Computational Performance Analysis</a>
  <ul>
  <li><a href="#sec-exact-approximate" id="toc-sec-exact-approximate" class="nav-link" data-scroll-target="#sec-exact-approximate">3.10.1 Exact vs.&nbsp;Approximate Inference</a></li>
  <li><a href="#sec-scaling-strategies" id="toc-sec-scaling-strategies" class="nav-link" data-scroll-target="#sec-scaling-strategies">3.10.2 Scaling Strategies</a></li>
  </ul></li>
  <li><a href="#sec-results-achievements" id="toc-sec-results-achievements" class="nav-link" data-scroll-target="#sec-results-achievements">3.11 Results and Achievements</a>
  <ul>
  <li><a href="#sec-extraction-quality" id="toc-sec-extraction-quality" class="nav-link" data-scroll-target="#sec-extraction-quality">3.11.1 Extraction Quality Assessment</a></li>
  <li><a href="#sec-computational-performance" id="toc-sec-computational-performance" class="nav-link" data-scroll-target="#sec-computational-performance">3.11.2 Computational Performance</a></li>
  <li><a href="#sec-policy-impact" id="toc-sec-policy-impact" class="nav-link" data-scroll-target="#sec-policy-impact">3.11.3 Policy Impact Evaluation</a></li>
  </ul></li>
  <li><a href="#sec-technical-summary" id="toc-sec-technical-summary" class="nav-link" data-scroll-target="#sec-technical-summary">3.12 Summary of Technical Contributions</a></li>
  </ul></li>
  <li><a href="#sec-discussion" id="toc-sec-discussion" class="nav-link" data-scroll-target="#sec-discussion">4. Discussion: Implications and Limitations</a>
  <ul>
  <li><a href="#sec-technical-limitations" id="toc-sec-technical-limitations" class="nav-link" data-scroll-target="#sec-technical-limitations">4.1 Technical Limitations and Responses</a>
  <ul>
  <li><a href="#sec-extraction-boundaries" id="toc-sec-extraction-boundaries" class="nav-link" data-scroll-target="#sec-extraction-boundaries">4.1.1 Extraction Quality Boundaries</a></li>
  <li><a href="#sec-false-precision" id="toc-sec-false-precision" class="nav-link" data-scroll-target="#sec-false-precision">4.1.2 Objection 2: False Precision in Uncertainty</a></li>
  <li><a href="#sec-correlation-complexity" id="toc-sec-correlation-complexity" class="nav-link" data-scroll-target="#sec-correlation-complexity">4.1.3 Objection 3: Correlation Complexity</a></li>
  </ul></li>
  <li><a href="#sec-conceptual-concerns" id="toc-sec-conceptual-concerns" class="nav-link" data-scroll-target="#sec-conceptual-concerns">4.2 Conceptual and Methodological Concerns</a>
  <ul>
  <li><a href="#sec-democratic-exclusion" id="toc-sec-democratic-exclusion" class="nav-link" data-scroll-target="#sec-democratic-exclusion">4.2.1 Objection 4: Democratic Exclusion</a></li>
  <li><a href="#sec-oversimplification" id="toc-sec-oversimplification" class="nav-link" data-scroll-target="#sec-oversimplification">4.2.2 Objection 5: Oversimplification of Complex Systems</a></li>
  <li><a href="#sec-idiosyncratic" id="toc-sec-idiosyncratic" class="nav-link" data-scroll-target="#sec-idiosyncratic">4.2.3 Objection 6: Idiosyncratic Implementation and Modeling Choices</a></li>
  </ul></li>
  <li><a href="#sec-red-teaming" id="toc-sec-red-teaming" class="nav-link" data-scroll-target="#sec-red-teaming">4.3 Red-Teaming Results</a>
  <ul>
  <li><a href="#sec-adversarial-extraction" id="toc-sec-adversarial-extraction" class="nav-link" data-scroll-target="#sec-adversarial-extraction">4.3.1 Adversarial Extraction Attempts</a></li>
  <li><a href="#sec-robustness-findings" id="toc-sec-robustness-findings" class="nav-link" data-scroll-target="#sec-robustness-findings">4.3.2 Robustness Findings</a></li>
  <li><a href="#sec-deployment-implications" id="toc-sec-deployment-implications" class="nav-link" data-scroll-target="#sec-deployment-implications">4.3.3 Implications for Deployment</a></li>
  </ul></li>
  <li><a href="#sec-epistemic-security" id="toc-sec-epistemic-security" class="nav-link" data-scroll-target="#sec-epistemic-security">4.4 Enhancing Epistemic Security</a>
  <ul>
  <li><a href="#sec-inspectable-models" id="toc-sec-inspectable-models" class="nav-link" data-scroll-target="#sec-inspectable-models">4.4.1 Making Models Inspectable</a></li>
  <li><a href="#sec-convergence-divergence" id="toc-sec-convergence-divergence" class="nav-link" data-scroll-target="#sec-convergence-divergence">4.4.2 Revealing Convergence and Divergence</a></li>
  <li><a href="#sec-collective-reasoning" id="toc-sec-collective-reasoning" class="nav-link" data-scroll-target="#sec-collective-reasoning">4.4.3 Improving Collective Reasoning</a></li>
  </ul></li>
  <li><a href="#sec-scaling" id="toc-sec-scaling" class="nav-link" data-scroll-target="#sec-scaling">4.5 Scaling Challenges and Opportunities</a>
  <ul>
  <li><a href="#sec-technical-scaling" id="toc-sec-technical-scaling" class="nav-link" data-scroll-target="#sec-technical-scaling">4.5.1 Technical Scaling</a></li>
  <li><a href="#sec-social-scaling" id="toc-sec-social-scaling" class="nav-link" data-scroll-target="#sec-social-scaling">4.5.2 Social and Institutional Scaling</a></li>
  <li><a href="#sec-impact-opportunities" id="toc-sec-impact-opportunities" class="nav-link" data-scroll-target="#sec-impact-opportunities">4.5.3 Opportunities for Impact</a></li>
  </ul></li>
  <li><a href="#sec-governance-integration" id="toc-sec-governance-integration" class="nav-link" data-scroll-target="#sec-governance-integration">4.6 Integration with Governance Frameworks</a>
  <ul>
  <li><a href="#sec-standards-integration" id="toc-sec-standards-integration" class="nav-link" data-scroll-target="#sec-standards-integration">4.6.1 Standards Development</a></li>
  <li><a href="#sec-regulatory-integration" id="toc-sec-regulatory-integration" class="nav-link" data-scroll-target="#sec-regulatory-integration">4.6.2 Regulatory Design</a></li>
  <li><a href="#sec-international-integration" id="toc-sec-international-integration" class="nav-link" data-scroll-target="#sec-international-integration">4.6.3 International Coordination</a></li>
  <li><a href="#sec-organizational-integration" id="toc-sec-organizational-integration" class="nav-link" data-scroll-target="#sec-organizational-integration">4.6.4 Organizational Decision-Making</a></li>
  </ul></li>
  <li><a href="#sec-future-research" id="toc-sec-future-research" class="nav-link" data-scroll-target="#sec-future-research">4.7 Future Research Directions</a>
  <ul>
  <li><a href="#sec-technical-future" id="toc-sec-technical-future" class="nav-link" data-scroll-target="#sec-technical-future">4.7.1 Technical Enhancements</a></li>
  <li><a href="#sec-methodological-future" id="toc-sec-methodological-future" class="nav-link" data-scroll-target="#sec-methodological-future">4.7.2 Methodological Extensions</a></li>
  <li><a href="#sec-application-future" id="toc-sec-application-future" class="nav-link" data-scroll-target="#sec-application-future">4.7.3 Application Domains</a></li>
  <li><a href="#sec-ecosystem-future" id="toc-sec-ecosystem-future" class="nav-link" data-scroll-target="#sec-ecosystem-future">4.7.4 Ecosystem Development</a></li>
  </ul></li>
  <li><a href="#sec-deep-uncertainties" id="toc-sec-deep-uncertainties" class="nav-link" data-scroll-target="#sec-deep-uncertainties">4.8 Known Unknowns and Deep Uncertainties</a>
  <ul>
  <li><a href="#sec-uncertainty-categories" id="toc-sec-uncertainty-categories" class="nav-link" data-scroll-target="#sec-uncertainty-categories">4.8.1 Categories of Deep Uncertainty</a></li>
  <li><a href="#sec-adaptation-strategies" id="toc-sec-adaptation-strategies" class="nav-link" data-scroll-target="#sec-adaptation-strategies">4.8.2 Adaptation Strategies for Deep Uncertainty</a></li>
  <li><a href="#sec-robust-principles" id="toc-sec-robust-principles" class="nav-link" data-scroll-target="#sec-robust-principles">4.8.3 Robust Decision-Making Principles</a></li>
  </ul></li>
  <li><a href="#sec-implications-summary" id="toc-sec-implications-summary" class="nav-link" data-scroll-target="#sec-implications-summary">4.9 Summary of Implications</a></li>
  </ul></li>
  <li><a href="#sec-conclusion" id="toc-sec-conclusion" class="nav-link" data-scroll-target="#sec-conclusion">5. Conclusion: Toward Coordinated AI Governance</a>
  <ul>
  <li><a href="#sec-key-contributions" id="toc-sec-key-contributions" class="nav-link" data-scroll-target="#sec-key-contributions">5.1 Summary of Key Contributions</a>
  <ul>
  <li><a href="#sec-theoretical-contributions" id="toc-sec-theoretical-contributions" class="nav-link" data-scroll-target="#sec-theoretical-contributions">5.1.1 Theoretical Contributions</a></li>
  <li><a href="#sec-methodological-innovations" id="toc-sec-methodological-innovations" class="nav-link" data-scroll-target="#sec-methodological-innovations">5.1.2 Methodological Innovations</a></li>
  <li><a href="#sec-technical-achievements" id="toc-sec-technical-achievements" class="nav-link" data-scroll-target="#sec-technical-achievements">5.1.3 Technical Achievements</a></li>
  <li><a href="#sec-empirical-findings" id="toc-sec-empirical-findings" class="nav-link" data-scroll-target="#sec-empirical-findings">5.1.4 Empirical Findings</a></li>
  </ul></li>
  <li><a href="#sec-limitations-assessment" id="toc-sec-limitations-assessment" class="nav-link" data-scroll-target="#sec-limitations-assessment">5.2 Limitations and Honest Assessment</a>
  <ul>
  <li><a href="#sec-technical-constraints" id="toc-sec-technical-constraints" class="nav-link" data-scroll-target="#sec-technical-constraints">5.2.1 Technical Constraints</a></li>
  <li><a href="#sec-conceptual-limitations" id="toc-sec-conceptual-limitations" class="nav-link" data-scroll-target="#sec-conceptual-limitations">5.2.2 Conceptual Limitations</a></li>
  <li><a href="#sec-practical-constraints" id="toc-sec-practical-constraints" class="nav-link" data-scroll-target="#sec-practical-constraints">5.2.3 Practical Constraints</a></li>
  </ul></li>
  <li><a href="#sec-governance-implications" id="toc-sec-governance-implications" class="nav-link" data-scroll-target="#sec-governance-implications">5.3 Implications for AI Governance</a>
  <ul>
  <li><a href="#sec-near-term-applications" id="toc-sec-near-term-applications" class="nav-link" data-scroll-target="#sec-near-term-applications">5.3.1 Near-Term Applications</a></li>
  <li><a href="#sec-medium-term" id="toc-sec-medium-term" class="nav-link" data-scroll-target="#sec-medium-term">5.3.2 Medium-Term Transformation</a></li>
  <li><a href="#sec-long-term-vision" id="toc-sec-long-term-vision" class="nav-link" data-scroll-target="#sec-long-term-vision">5.3.3 Long-Term Vision</a></li>
  </ul></li>
  <li><a href="#sec-recommendations" id="toc-sec-recommendations" class="nav-link" data-scroll-target="#sec-recommendations">5.4 Recommendations for Stakeholders</a>
  <ul>
  <li><a href="#sec-researcher-recommendations" id="toc-sec-researcher-recommendations" class="nav-link" data-scroll-target="#sec-researcher-recommendations">5.4.1 For Researchers</a></li>
  <li><a href="#sec-policymaker-recommendations" id="toc-sec-policymaker-recommendations" class="nav-link" data-scroll-target="#sec-policymaker-recommendations">5.4.2 For Policymakers</a></li>
  <li><a href="#sec-technologist-recommendations" id="toc-sec-technologist-recommendations" class="nav-link" data-scroll-target="#sec-technologist-recommendations">5.4.3 For Technologists</a></li>
  </ul></li>
  <li><a href="#sec-future-research-agenda" id="toc-sec-future-research-agenda" class="nav-link" data-scroll-target="#sec-future-research-agenda">5.5 Future Research Agenda</a>
  <ul>
  <li><a href="#sec-technical-priorities" id="toc-sec-technical-priorities" class="nav-link" data-scroll-target="#sec-technical-priorities">5.5.1 Technical Priorities</a></li>
  <li><a href="#sec-methodological-development" id="toc-sec-methodological-development" class="nav-link" data-scroll-target="#sec-methodological-development">5.5.2 Methodological Development</a></li>
  <li><a href="#sec-application-expansion" id="toc-sec-application-expansion" class="nav-link" data-scroll-target="#sec-application-expansion">5.5.3 Application Expansion</a></li>
  </ul></li>
  <li><a href="#sec-closing-reflections" id="toc-sec-closing-reflections" class="nav-link" data-scroll-target="#sec-closing-reflections">5.6 Closing Reflections</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/VJMeyer/submission/edit/main/chapters/Outlines/final_draft.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div><div class="quarto-code-links"><h2>Code Links</h2><ul><li><a href="https://colab.research.google.com/github/VJMeyer/submission/blob/main/AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb"><i class="bi bi-file-code"></i>Colab Notebook (Manual Link in .yml)</a></li><li><a href="https://github.com/VJMeyer/submission"><i class="bi bi-github"></i>GitHub Repository</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Automating the Modeling of Transformative Artificial Intelligence Risks</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="frontmatter-preface" class="level2">
<h2 class="anchored" data-anchor-id="frontmatter-preface">Frontmatter: Preface</h2>
<!-- 
title: "Automating the Modelling of Transformative Artificial Intelligence Risks"
subtitle: "An Epistemic Framework for Leveraging Frontier AI Systems to Upscale Conditional Policy Assessments in Bayesian Networks on a Narrow Path towards Existential Safety"
#title-block-banner: true
#title-block-banner: latex/uni-bayreuth-logo.png
author:
  - name: Valentin Jakob Meyer
    orcid: 0009-0006-0889-5269
    corresponding: true
    email: Valentin.Meyer@uni-bayreuth.de
    roles:
      GraduateAuthor
#      - Investigation
#      - Project administration
#      - Software
#      - Visualization
    affiliations:
      - University of Bayreuth
      - MCMP — LMU Munich
  - name: Dr. Timo Speith       
    orcid: 0000-0002-6675-154X    # from https://orcid.org/0000-0002-6675-154X
    corresponding: false
    roles: Supervisor
#      [Supervisor]
    affiliations:
      - University of Bayreuth
keywords:
  - AMTAIR
  - AI Governance
  - Bayesian Networks
  - Transformative AI
  - Risk Assessment
  - Argument Extraction
abstract: |
  This thesis addresses coordination problems in AI safety by creating tools that automatically extract and formalize the assumptions and models underlying different approaches to AI governance.
  By transforming complex arguments into interactive visualizations showing relationships and probabilities, AMTAIR helps bridge communication gaps between technical researchers, policy specialists, and other stakeholders working to address risks from advanced AI.
plain-language-summary: |
  This thesis addresses coordination problems in AI safety by creating tools that automatically
  extract and formalize the assumptions and models underlying different approaches to AI governance.
  By transforming complex arguments into interactive visualizations showing relationships and
  probabilities, AMTAIR helps bridge communication gaps between technical researchers, policy
  specialists, and other stakeholders working to address risks from advanced AI.
key-points:
  - A novel extraction pipeline transforms argument structures into Bayesian networks through a two-stage process
  - Interactive visualizations make complex probabilistic relationships accessible to diverse stakeholders
  - Formal representation enables comparison across different worldviews and assumptions
  - The approach addresses coordination failures by creating a common language for AI risk assessment
metadata-submission:
  field-of-study: "Philosophy & Economics M.A."
  matriculation-number: 1828610
  submission-date: "May 26, 2025"
  word-count: 30000
date: "2025-05-26"
bibliography: ref/MAref.bib
citation:
  container-title: University of Bayreuth
number-sections: true
reference-location: margin
citation-location: margin 
-->
<!-- [-] TODO: Expand preface to include personal journey and acknowledgments -->
<p>This thesis represents the culmination of interdisciplinary research at the intersection of AI safety, formal epistemology, and computational social science. The work emerged from recognizing a fundamental challenge in AI governance: while investment in AI safety research has grown exponentially, coordination between different stakeholder communities remains fragmented, potentially increasing existential risk through misaligned efforts.</p>
<p>The journey from initial concept to working implementation involved iterative refinement based on feedback from advisors, domain experts, and potential users. What began as a technical exercise in automated extraction evolved into a broader framework for enhancing epistemic security in one of humanity’s most critical coordination challenges. The AMTAIR project—Automating Transformative AI Risk Modeling—represents an attempt to build computational bridges between communities that, despite shared concerns about AI risk, often struggle to communicate effectively due to incompatible frameworks, terminologies, and implicit assumptions.</p>
<p>I hope this work contributes to building the intellectual and technical infrastructure necessary for humanity to navigate the transition to transformative AI safely. The tools and frameworks presented here are offered in the spirit of collaborative problem-solving, recognizing that the challenges we face require unprecedented cooperation across disciplines, institutions, and worldviews.</p>
</section>
<section id="acknowledgments" class="level2">
<h2 class="anchored" data-anchor-id="acknowledgments">Acknowledgments</h2>
<!-- [-] TODO: Add specific names and contributions -->
<p>This thesis represents not just an intellectual journey but a deeply personal one, made possible only through the support, patience, and contributions of many remarkable people.</p>
<p>My supervisor, Dr.&nbsp;Timo Speith, provided the perfect balance of intellectual freedom and thoughtful guidance. His ability to see both the philosophical forest and the technical trees helped me navigate moments when I was lost in one or the other. His questions pushed this work beyond what I thought possible and his experience and intuition helped me steer clear of too many rabbit holes to count.</p>
<p>I owe my deepest gratitude to my wife, Mina Deol, whose unwavering support made these months of intensive research possible. Her patience during countless late nights, her encouragement during moments of doubt, and her willingness to listen to endless iterations of esoteric Bayesian network speculations went far beyond what any partner should reasonably endure. This work exists because she created the space for it to flourish.</p>
<p>I owe a particular debt to Johannes Meyer and Jelena Meyer for their meticulous work in creating independent manual extractions of the Carlsmith and Bucknall papers. Their contribution went far beyond mere validation; it provided peace of mind. As lead developer, I had harbored persistent concerns that my own intuitions might have inadvertently shaped the system’s behavior through architectural choices, prompt engineering, or source selection. Their independent extractions—showing both convergence in structure and expected variance in probabilities—allowed me to release these anxieties and trust that the system captures something real about how arguments work, not just my own biases about how they should work. Their intellectual generosity and attention to detail exemplify the collaborative spirit that makes progress possible.</p>
<p>Coleman Snell deserves special recognition for his partnership in developing the AMTAIR vision. Our conversations—ranging from technical implementation details to grand strategic questions about AI governance—shaped this project in fundamental ways. His ability to oscillate between pragmatic engineering concerns and ambitious long-term thinking kept the work both grounded and aspirational.</p>
<p>The MTAIR team’s pioneering manual approach provided both inspiration and a benchmark. David Manheim, Sam Clarke, Aryeh Englander and their collaborators demonstrated that formal modeling of AI risk arguments was possible, even if arduously manual. Their work posed the challenge this thesis attempts to answer: could we preserve their rigor while achieving scale through automation?</p>
<p>My family—my parents and sister—provided the foundation that made this journey possible. Their love, support, and occasional bewilderment at my career choices (“you’re teaching computers to argue about robot apocalypse? – seems all too real now”) kept me grounded in what matters. They reminded me that behind all the technical complexity lie fundamentally human concerns about our shared future.</p>
<p>The broader AI safety community created the intellectual raw material without which this work would be impossible. Every researcher who wrestled their intuitions into prose, every attempt to quantify the unquantifiable, every blog post and paper and comment thread contributed to the corpus that AMTAIR learns to formalize. I thank them for taking these risks seriously and for the courage to reason publicly about them.</p>
<p>Finally, I acknowledge the peculiar historical moment that made this work both possible and necessary. We live in an era where the tools to build potentially transformative AI exist alongside deep uncertainty about how to do so safely. This thesis represents one small attempt to build infrastructure for navigating that uncertainty collectively.</p>
<p>Any errors, oversights, or failures of imagination remain entirely my own responsibility. The contributions of others made this work possible; its limitations reflect only my own constraints.</p>
<!-- [-] LATER VERIFY: Verify all figures are properly labeled and captioned -->
<!-- Quarto auto-generates LOF -->
<!-- ## List of Tables -->
<!-- [-] LATER VERIFY: Ensure all tables have proper captions -->
<!-- Quarto auto-generates LOT -->
<!-- [-] TODO: Review and expand abbreviation list -->
<!-- 
## List of Abbreviations -- here only placeholder, original lives in index



AI - Artificial Intelligence  
AGI - Artificial General Intelligence  
AMTAIR - Automating Transformative AI Risk Modeling  
API - Application Programming Interface  
APS - Advanced, Planning, Strategic (AI systems)  
BN - Bayesian Network  
CPT - Conditional Probability Table  
DAG - Directed Acyclic Graph  
LLM - Large Language Model  
ML - Machine Learning  
MTAIR - Modeling Transformative AI Risks  
NLP - Natural Language Processing  
P&E - Philosophy & Economics  
PDF - Portable Document Format  
TAI - Transformative Artificial Intelligence -->
<!-- [ ] Add to glossary and define: prediction markets & forecasting platforms -->
</section>
<section id="introduction-the-coordination-crisis-in-ai-governance" class="level1">
<h1>1. Introduction: The Coordination Crisis in AI Governance</h1>
<!-- 
**Chapter Overview**  
**Grade Weight**: 10% | **Target Length**: ~14% of text (~4,200 words)  
**Requirements**: Introduces and motivates the core question, provides context, states precise thesis, provides roadmap
-->
<!-- ## 1.1 Opening Scenario: The Policymaker's Dilemma -->
<!-- [-] TODO: Polish opening scenario for maximum impact -->
<!-- 
Consider the following scenario, one that has become distressingly common in regulatory offices worldwide. A policy advisor—let's call her Sarah—faces an impossible task. Her desk groans under the weight of competing analyses about artificial intelligence risks. Each report carries impressive credentials. Each reaches fundamentally different conclusions.

The first document, authored by a consortium of computer scientists, warns of imminent existential threat. Its pages bristle with technical terminology: mesa-optimization, instrumental convergence, orthogonality thesis. The mathematics appears sound, yet the conclusions seem almost fantastical. The second report, penned by economists and policy veterans, dismisses such concerns as speculative fear-mongering. Where the computer scientists see existential risk, the economists see manageable externalities. A third analysis, straddling both worlds, proposes technical standards so hedged with caveats as to be nearly meaningless.

Sarah's dilemma extends beyond mere intellectual disagreement. The clock ticks toward a legislative deadline. Real decisions with profound consequences await. Yet the expert community offers not clarity but cacophony. Each perspective seems internally coherent, even compelling, yet they cannot all be correct. The technical arguments require PhD-level mathematics to evaluate properly. The timescales range from "urgent action needed yesterday" to "let's wait and see how the technology develops." 

This scenario—Sarah's scenario—plays out with minor variations in Washington, Brussels, Beijing, and dozens of other capitals. It represents what I've come to understand as the coordination crisis in AI governance: a systematic failure of our epistemic infrastructure at precisely the moment we need it most. -->
<section id="opening-scenario-the-policymakers-dilemma" class="level2">
<h2 class="anchored" data-anchor-id="opening-scenario-the-policymakers-dilemma">1.1 Opening Scenario: The Policymaker’s Dilemma</h2>
<!-- [-] TODO: Polish opening scenario for maximum impact -->
<!-- [-] ADD: @todd2024 add as reference for more resources towards AI safety -->
<!-- [ ] ADD: CITATIONS for orthogonality thesis and instrumental convergence thesis -->
<p>A senior policy advisor sits at her desk, drowning in reports. Twelve different documents from AI safety researchers, each compelling, each contradictory. One warns of existential catastrophe within the decade, citing concepts she half-understands—orthogonality, instrumental convergence. Another dismisses these fears as overblown. A third proposes technical standards but hedges with so many caveats it might as well propose nothing. The clock’s ticking. Legislation needs drafting. Yet these experts, brilliant as they are individually, seem to inhabit different universes. The technical arguments involve mathematical formalism she lacks time to parse. The policy recommendations conflict at fundamental levels. She needs synthesis, not more analysis. She needs a way to see where these worldviews actually diverge versus where they’re using different words for the same fears. This scenario plays out daily across Washington, Brussels, Beijing—wherever humans grapple with governing something that doesn’t exist yet but might remake everything when it does.</p>
<!-- [-] EXPLAIN: in footnotes: a) Orthogonality Thesis: Intelligence and goals are independent; an AI can have any set of objectives regardless of its intelligence level. b) Instrumental Convergence Thesis: Different AI systems may adopt similar instrumental goals (e.g., self-preservation, resource acquisition) to achieve their objectives. -->
<p>This scenario<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> plays out daily across government offices, corporate boardrooms, and research institutions worldwide. It exemplifies what I term the “coordination crisis” in AI governance: despite unprecedented attention and resources directed toward AI safety, we lack the epistemic infrastructure to synthesize diverse expert knowledge into actionable governance strategies <span class="citation" data-cites="todd2024">Todd (<a href="../../ref/references.html#ref-todd2024" role="doc-biblioref">2024</a>)</span>.</p>
<!-- [-] CREATE: {#fig-policymaker-dilemma}: "Visual representation of conflicting expert reports on advisor's desk" 
Show Image
-->
</section>
<section id="the-coordination-crisis-in-ai-governance" class="level2">
<h2 class="anchored" data-anchor-id="the-coordination-crisis-in-ai-governance">1.2 The Coordination Crisis in AI Governance</h2>
<!-- [-] TODO: Frame the problem as coordination failure rather than merely technical challenge -->
<!-- [-] ADD: @maslej2025 Add citation for page 85 as evidence for accelerating capabilities -->
<!-- [-] ADD: @samborska2025 Add as citation for accelerating capabilities -->
<p>As AI capabilities advance at an accelerating pace—demonstrated by the rapid progression from GPT-3 to GPT-4, Claude, and emerging multimodal systems <span class="citation" data-cites="maslej2025">Maslej (<a href="../../ref/references.html#ref-maslej2025" role="doc-biblioref">2025</a>)</span> <span class="citation" data-cites="samborska2025">Samborska (<a href="../../ref/references.html#ref-samborska2025" role="doc-biblioref">2025</a>)</span>—humanity faces a governance challenge unlike any in history. The task of ensuring increasingly powerful AI systems remain aligned with human values and beneficial to our long-term flourishing grows more urgent with each capability breakthrough. This challenge becomes particularly acute when considering transformative AI systems that could drastically alter civilization’s trajectory, potentially including existential risks from misaligned systems pursuing objectives counter to human welfare.</p>
<p>Despite unprecedented investment in AI safety research, rapidly growing awareness among key stakeholders, and proliferating frameworks for responsible AI development, we face what I’ll term the “coordination crisis” in AI governance—a systemic failure to align diverse efforts across technical, policy, and strategic domains into a coherent response proportionate to the risks we face.</p>
<p>The current state of AI governance presents a striking paradox. On one hand, we witness extraordinary mobilization: billions in research funding, proliferating safety initiatives, major tech companies establishing alignment teams, and governments worldwide developing AI strategies. The Asilomar AI Principles garnered thousands of signatures <span class="citation" data-cites="tegmark2024">Tegmark (<a href="../../ref/references.html#ref-tegmark2024" role="doc-biblioref">2024</a>)</span>, the EU advances comprehensive AI regulation <span class="citation" data-cites="european2024">European (<a href="../../ref/references.html#ref-european2024" role="doc-biblioref">2024</a>)</span>, and technical researchers produce increasingly sophisticated work on alignment, interpretability, and robustness.</p>
<p>Yet alongside this activity, we observe systematic coordination failures that may prove catastrophic. Technical safety researchers develop sophisticated alignment techniques without clear implementation pathways. Policy specialists craft regulatory frameworks lacking technical grounding to ensure practical efficacy. Ethicists articulate normative principles that lack operational specificity. Strategy researchers identify critical uncertainties but struggle to translate these into actionable guidance. International bodies convene without shared frameworks for assessing interventions.</p>
<!-- [-] CREATE: {#fig-coordination-crisis}: "Systems diagram showing fragmentation between AI governance communities" 
Show Image
-->
<div id="fig-ai-hypotheses-map" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-scap="Key hypotheses in AI alignment" alt="LARGE CONCEPT MAP. Nodes are colour-coded: red for problems that could lead to catastrophe, green for solutions or agendas, blue for scenarios or conceptual models. Bold-border nodes denote primary hypotheses such as ‘Discontinuity to AGI’, ‘Agentive AGI’, ‘Broad basin for corrigibility’, and ‘Mesa-optimisation’. Directed arrows link questions to hypotheses, questions to questions, and scenarios to hypotheses. Arrow labels (Yes, No, Defer, brief rationales) indicate how answering the tail node influences credence in the head node. A legend at the bottom explains colour categories and arrow semantics. Source: Ben Cottier &amp; Rohin Shah (2019) @cottier2019 “Clarifying Some Key Hypotheses in AI Alignment”, AI Alignment Forum." width="100%" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ai-hypotheses-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://www.lesswrong.com/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment#Agentive_AGI_"><embed src="../../images/hypotheses_diagram.pdf" class="img-fluid quarto-figure quarto-figure-center" style="width:100.0%" data-fig-scap="Key hypotheses in AI alignment" alt="LARGE CONCEPT MAP. Nodes are colour-coded: red for problems that could lead to catastrophe, green for solutions or agendas, blue for scenarios or conceptual models. Bold-border nodes denote primary hypotheses such as ‘Discontinuity to AGI’, ‘Agentive AGI’, ‘Broad basin for corrigibility’, and ‘Mesa-optimisation’. Directed arrows link questions to hypotheses, questions to questions, and scenarios to hypotheses. Arrow labels (Yes, No, Defer, brief rationales) indicate how answering the tail node influences credence in the head node. A legend at the bottom explains colour categories and arrow semantics. Source: Ben Cottier &amp; Rohin Shah (2019) @cottier2019 “Clarifying Some Key Hypotheses in AI Alignment”, AI Alignment Forum."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ai-hypotheses-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.1: from <span class="citation" data-cites="cottier2019">Cottier and Shah (<a href="../../ref/references.html#ref-cottier2019" role="doc-biblioref">2019</a>)</span>: Key hypotheses across the AI alignment ecosystem
</figcaption>
</figure>
</div>
<section id="safety-gaps-from-misaligned-efforts" class="level3">
<h3 class="anchored" data-anchor-id="safety-gaps-from-misaligned-efforts">1.2.1 Safety Gaps from Misaligned Efforts</h3>
<!-- [-] TODO: Document how fragmentation systematically increases risk through with specific, good examples -->
<p>The fragmentation problem manifests in incompatible frameworks between technical researchers, policy specialists, and strategic analysts. Each community develops sophisticated approaches within their domain, yet translation between domains remains primitive. This creates systematic blind spots where risks emerge at the interfaces between technical capabilities, institutional responses, and strategic dynamics.</p>
<p>When different communities operate with incompatible frameworks, critical risks fall through the cracks. Technical researchers may solve alignment problems under assumptions that policymakers’ decisions invalidate. Regulations optimized for current systems may inadvertently incentivize dangerous development patterns. Without shared models of the risk landscape, our collective efforts resemble the parable of blind men describing an elephant—each accurate within their domain but missing the complete picture <span class="citation" data-cites="paul2023">Paul (<a href="../../ref/references.html#ref-paul2023" role="doc-biblioref">2023</a>)</span>.</p>
<!-- [-] FIND: @coordination-failure-examples: "Specific historical examples of coordination failures in technology governance" -- arms races to nobodies benefit -- technological race to ?? -->
<p>Historical precedents demonstrate how coordination failures in technology governance can lead to dangerous dynamics. The nuclear arms race exemplifies how lack of coordination can create negative-sum outcomes where all parties become less secure despite massive investments in safety measures. Similar dynamics may emerge in AI development without proper coordination infrastructure.</p>
</section>
<section id="resource-misallocation" class="level3">
<h3 class="anchored" data-anchor-id="resource-misallocation">1.2.2 Resource Misallocation</h3>
<!-- [-] TODO: Explain that duplicative efforts absorbing research funding, publications, and initiatives might sometimes improve reliability (think reproducing results) but tend to waste resources in expectation (opportuntity cost) -- change the tone of the paragraph accordingly -->
<p>The AI safety community faces a complex tradeoff in resource allocation. While some duplication of efforts can improve reliability through independent verification—akin to reproducing scientific results—the current level of fragmentation often leads to wasteful redundancy. Multiple teams independently develop similar frameworks without building on each other’s work, creating opportunity costs where critical but unglamorous research areas remain understaffed. Funders struggle to identify high-impact opportunities across technical and governance domains, lacking the epistemic infrastructure to assess where marginal resources would have the greatest impact. This misallocation becomes more costly as the window for establishing effective governance narrows with accelerating AI development.</p>
<!-- [-] CREATE: {#tbl-resource-duplication}: "Examples of duplicated AI safety efforts across organizations" -->
<div id="tbl-resource-duplication" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-resource-duplication-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3.1: Table 1.2.2: Examples of duplicated AI safety efforts across organizations
</figcaption>
<div aria-describedby="tbl-resource-duplication-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>Research Area</th>
<th>Organization A</th>
<th>Organization B</th>
<th>Duplication Level</th>
<th>Opportunity Cost</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Interpretability Methods</td>
<td>Anthropic’s mechanistic interpretability</td>
<td>DeepMind’s concept activation vectors</td>
<td>Medium</td>
<td>Reduced focus on multi-agent safety</td>
</tr>
<tr class="even">
<td>Alignment Frameworks</td>
<td>MIRI’s embedded agency</td>
<td>FHI’s comprehensive AI services</td>
<td>High</td>
<td>Limited work on institutional design</td>
</tr>
<tr class="odd">
<td>Risk Assessment Models</td>
<td>GovAI’s policy models</td>
<td>CSER’s existential risk frameworks</td>
<td>High</td>
<td>Insufficient capability benchmarking</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="negative-sum-dynamics" class="level3">
<h3 class="anchored" data-anchor-id="negative-sum-dynamics">1.2.3 Negative-Sum Dynamics</h3>
<!-- [-] TODO: Address capability-governance gaps widening with accelerating development -->
<p>Perhaps most concerning, uncoordinated interventions can actively increase risk. Safety standards that advantage established players may accelerate risky development elsewhere. Partial transparency requirements might enable capability advances without commensurate safety improvements. International agreements lacking shared technical understanding may lock in dangerous practices. Without coordination, our cure risks becoming worse than the disease.</p>
<p>The game-theoretic structure of AI development creates particularly pernicious dynamics. Armstrong et al. <span class="citation" data-cites="armstrong2016">Armstrong, Bostrom, and Shulman (<a href="../../ref/references.html#ref-armstrong2016" role="doc-biblioref">2016</a>)</span> demonstrate how uncoordinated policies can incentivize a “race to the precipice” where competitive pressures override safety considerations. The situation resembles a multi-player prisoner’s dilemma or stag hunt where individually rational decisions lead to collectively catastrophic outcomes <span class="citation" data-cites="samuel2023">Samuel (<a href="../../ref/references.html#ref-samuel2023" role="doc-biblioref">2023</a>)</span> <span class="citation" data-cites="hunt2025">Hunt (<a href="../../ref/references.html#ref-hunt2025" role="doc-biblioref">2025</a>)</span>.</p>
<!-- [-] LATER ADD: Citation for unpublished "anybody builds it everyone dies (soares & yudkowsky)" -->
</section>
</section>
<section id="historical-parallels-and-temporal-urgency" class="level2">
<h2 class="anchored" data-anchor-id="historical-parallels-and-temporal-urgency">1.3 Historical Parallels and Temporal Urgency</h2>
<!-- [-] TODO: Draw connections to nuclear governance, climate change, and biosecurity -->
<p>History offers instructive parallels. The nuclear age began with scientists racing to understand and control forces that could destroy civilization. Early coordination failures—competing national programs, scientist-military tensions, public-expert divides—nearly led to catastrophe multiple times. Only through developing shared frameworks (deterrence theory) <span class="citation" data-cites="schelling1960">Schelling (<a href="../../ref/references.html#ref-schelling1960" role="doc-biblioref">1960</a>)</span>, institutions (IAEA), and communication channels (hotlines, treaties) did humanity navigate the nuclear precipice <span class="citation" data-cites="rehman2025">Rehman (<a href="../../ref/references.html#ref-rehman2025" role="doc-biblioref">2025</a>)</span>.</p>
<p>Yet AI presents unique coordination challenges that compress our response timeline:</p>
<p><strong>Accelerating Development</strong>: Unlike nuclear weapons requiring massive infrastructure, AI development proceeds in corporate labs and academic departments worldwide. Capability improvements come through algorithmic insights and computational scale, both advancing exponentially.</p>
<p><strong>Dual-Use Ubiquity</strong>: Every AI advance potentially contributes to both beneficial applications and catastrophic risks. The same language model architectures enabling scientific breakthroughs could facilitate dangerous manipulation or deception at scale.</p>
<p><strong>Comprehension Barriers</strong>: Nuclear risks were viscerally understandable—cities vaporized, radiation sickness, nuclear winter. AI risks involve abstract concepts like optimization processes, goal misspecification, and emergent capabilities that resist intuitive understanding.</p>
<p><strong>Governance Lag</strong>: Traditional governance mechanisms—legislation, international treaties, professional standards—operate on timescales of years to decades. AI capabilities advance on timescales of months to years, creating an ever-widening capability-governance gap.</p>
<!-- [-] CREATE: {#fig-governance-lag}: "Timeline comparison of AI capability vs governance development" 
Show Image
-->
</section>
<section id="research-question-and-scope" class="level2">
<h2 class="anchored" data-anchor-id="research-question-and-scope">1.4 Research Question and Scope</h2>
<!-- [-] TODO: Clearly articulate the primary research question with precision -->
<p>This thesis addresses a specific dimension of the coordination challenge by investigating the question:</p>
<p><strong>Can frontier AI technologies be utilized to automate the modeling of transformative AI risks, enabling robust prediction of policy impacts across diverse worldviews?</strong></p>
<p>More specifically, I explore whether frontier language models can automate the extraction and formalization of probabilistic world models from AI safety literature, creating a scalable computational framework that enhances coordination in AI governance through systematic policy evaluation under uncertainty.</p>
<p>To break this down into its components:</p>
<ul>
<li><strong>Frontier AI Technologies</strong>: Today’s most capable language models (GPT-4, Claude-3 level systems)</li>
<li><strong>Automated Modeling</strong>: Using these systems to extract and formalize argument structures from natural language</li>
<li><strong>Transformative AI Risks</strong>: Potentially catastrophic outcomes from advanced AI systems, particularly existential risks</li>
<li><strong>Policy Impact Prediction</strong>: Evaluating how governance interventions might alter probability distributions over outcomes</li>
<li><strong>Diverse Worldviews</strong>: Accounting for fundamental disagreements about AI development trajectories and risk factors</li>
</ul>
<p>The investigation encompasses both theoretical development and practical implementation, focusing specifically on existential risks from misaligned AI systems rather than broader AI ethics concerns. This narrowed scope enables deep technical development while addressing the highest-stakes coordination challenges.</p>
<!-- [-] LATER TODO: Refine thesis statement based on advisor feedback -->
</section>
<section id="the-multiplicative-benefits-framework" class="level2">
<h2 class="anchored" data-anchor-id="the-multiplicative-benefits-framework">1.5 The Multiplicative Benefits Framework</h2>
<!-- [-] TODO: Establish central thesis about synergistic combination of three elements -->
<p>The central thesis of this work is that combining three elements—automated worldview extraction, prediction market integration, and formal policy evaluation—creates multiplicative rather than merely additive benefits for AI governance. Each component enhances the others, creating a system more valuable than the sum of its parts.</p>
<!-- [-] CREATE: {#fig-multiplicative-benefits}: "Venn diagram showing synergies between extraction, markets, and evaluation": Automation × Live Prediction Market Integrations × Policy Impact Evaluations
Show Image
-->
<section id="automated-worldview-extraction" class="level3">
<h3 class="anchored" data-anchor-id="automated-worldview-extraction">1.5.1 Automated Worldview Extraction</h3>
<p>Current approaches to AI risk modeling, exemplified by the Modeling Transformative AI Risks (MTAIR) project, demonstrate the value of formal representation but require extensive manual effort. Creating a single model demands dozens of expert-hours to translate qualitative arguments into quantitative frameworks. This bottleneck severely limits the number of perspectives that can be formalized and the speed of model updates as new arguments emerge.</p>
<p>Automation using frontier language models addresses this scaling challenge. By developing systematic methods to extract causal structures and probability judgments from natural language, we can:</p>
<ul>
<li>Process orders of magnitude more content</li>
<li>Incorporate diverse perspectives rapidly</li>
<li>Maintain models that evolve with the discourse</li>
<li>Reduce barriers to entry for contributing worldviews</li>
</ul>
</section>
<section id="live-data-integration" class="level3">
<h3 class="anchored" data-anchor-id="live-data-integration">1.5.2 Live Data Integration</h3>
<p>Static models, however well-constructed, quickly become outdated in fast-moving domains. Prediction markets and forecasting platforms aggregate distributed knowledge about uncertain futures, providing continuously updated probability estimates. By connecting formal models to these live data sources, we create dynamic assessments that incorporate the latest collective intelligence <span class="citation" data-cites="tetlock2015">P. E. Tetlock and Gardner (<a href="../../ref/references.html#ref-tetlock2015" role="doc-biblioref">2015</a>)</span>.</p>
<p>This integration serves multiple purposes:</p>
<ul>
<li>Grounding abstract models in empirical forecasts</li>
<li>Identifying which uncertainties most affect outcomes</li>
<li>Revealing when model assumptions diverge from collective expectations</li>
<li>Generating new questions for forecasting communities</li>
</ul>
</section>
<section id="formal-policy-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="formal-policy-evaluation">1.5.3 Formal Policy Evaluation</h3>
<p><strong>Formal policy evaluation</strong> transforms static risk assessments into actionable guidance by modeling how specific interventions alter critical parameters. Using causal inference techniques <span class="citation" data-cites="pearl2000">Pearl (<a href="../../ref/references.html#ref-pearl2000" role="doc-biblioref">2000</a>)</span> <span class="citation" data-cites="pearl2009">Pearl (<a href="../../ref/references.html#ref-pearl2009" role="doc-biblioref">2009</a>)</span>, we can assess not just the probability of adverse outcomes but how those probabilities change under different policy regimes.</p>
<p>This enables genuinely evidence-based policy development:</p>
<ul>
<li>Comparing interventions across multiple worldviews</li>
<li>Identifying robust strategies that work across scenarios</li>
<li>Understanding which uncertainties most affect policy effectiveness</li>
<li>Prioritizing research to reduce decision-relevant uncertainty</li>
</ul>
</section>
<section id="the-synergy" class="level3">
<h3 class="anchored" data-anchor-id="the-synergy">1.5.4 The Synergy</h3>
<p>The multiplicative benefits emerge from the interactions between components:</p>
<ul>
<li>Automation enables comprehensive coverage, making prediction market integration more valuable by connecting to more perspectives</li>
<li>Market data validates and calibrates automated extractions, improving quality</li>
<li>Policy evaluation gains precision from both comprehensive models and live probability updates</li>
<li>The complete system creates feedback loops where policy analysis identifies critical uncertainties for market attention</li>
</ul>
<p>This synergistic combination addresses the coordination crisis by providing common ground for disparate communities, translating between technical and policy languages, quantifying previously implicit disagreements, and enabling evidence-based compromise.</p>
</section>
</section>
<section id="thesis-structure-and-roadmap" class="level2">
<h2 class="anchored" data-anchor-id="thesis-structure-and-roadmap">1.6 Thesis Structure and Roadmap</h2>
<!-- [-] TODO: Preview the logical progression of the thesis -->
<p>The remainder of this thesis develops the multiplicative benefits framework from theoretical foundations to practical implementation:</p>
<p><strong>Chapter 2: Context and Theoretical Foundations</strong> establishes the intellectual groundwork, examining the epistemic challenges unique to AI governance, Bayesian networks as formal tools for uncertainty representation, argument mapping as a bridge from natural language to formal models, the MTAIR project’s achievements and limitations, and requirements for effective coordination infrastructure.</p>
<p><strong>Chapter 3: AMTAIR Design and Implementation</strong> presents the technical system including overall architecture and design principles, the two-stage extraction pipeline (ArgDown → BayesDown), validation methodology and results, case studies from simple examples to complex AI risk models, and integration with prediction markets and policy evaluation.</p>
<p><strong>Chapter 4: Discussion - Implications and Limitations</strong> critically examines technical limitations and failure modes, conceptual concerns about formalization, integration with existing governance frameworks, scaling challenges and opportunities, and broader implications for epistemic security.</p>
<p><strong>Chapter 5: Conclusion</strong> synthesizes key contributions and charts paths forward with a summary of theoretical and practical achievements, concrete recommendations for stakeholders, research agenda for community development, and vision for AI governance with proper coordination infrastructure.</p>
<p>Throughout this progression, I maintain dual focus on theoretical sophistication and practical utility. The framework aims not merely to advance academic understanding but to provide actionable tools for improving coordination in AI governance during this critical period.</p>
<!-- [-] CREATE: {#fig-thesis-roadmap}: "Visual flowchart of thesis structure and chapter connections"
Show Image
-->
<p>Having established the coordination crisis and outlined how automated modeling can address it, we now turn to the theoretical foundations that make this approach possible. The next chapter examines the unique epistemic challenges of AI governance and introduces the formal tools—particularly Bayesian networks—that enable rigorous reasoning under deep uncertainty.</p>
</section>
</section>
<section id="context-and-theoretical-foundations" class="level1">
<h1>2. Context and Theoretical Foundations</h1>
<!-- 
**Chapter Overview**  
**Grade Weight**: 20% | **Target Length**: ~29% of text (~8,700 words)  
**Requirements**: Demonstrates understanding of relevant concepts, explains relevance, situates in debate, reconstructs arguments -->
<!-- [-] INTRODUCE: Concise overview of the Literature, Concepts & Terminology introduced in this chapter/thesis-->
<p>This chapter establishes the theoretical and methodological foundations for the AMTAIR approach. We begin by examining a concrete example of structured AI risk assessment—Joseph Carlsmith’s power-seeking AI model—to ground our discussion in practical terms. We then explore the unique epistemic challenges of AI governance that render traditional policy analysis inadequate, introduce Bayesian networks as formal tools for representing uncertainty, and examine how argument mapping bridges natural language reasoning and formal models. The chapter concludes by analyzing the MTAIR project’s achievements and limitations, motivating the need for automated approaches, and surveying relevant literature across AI risk modeling, governance proposals, and technical methodologies.</p>
<!-- [-] TODO: Create "Background Knowledge" footnotes for key concepts -->
<section id="ai-existential-risk-the-carlsmith-model" class="level2">
<h2 class="anchored" data-anchor-id="ai-existential-risk-the-carlsmith-model">2.1 AI Existential Risk: The Carlsmith Model</h2>
<!-- [-] TODO: Provide overview of Joe Carlsmith's probabilistic model of power-seeking AI -->
<p>To ground our discussion in concrete terms, I examine Joseph Carlsmith’s “Is Power-Seeking AI an Existential Risk?” as an exemplar of structured reasoning about AI catastrophic risk <span class="citation" data-cites="carlsmith2022">Carlsmith (<a href="../../ref/references.html#ref-carlsmith2022" role="doc-biblioref">2022</a>)</span>. Carlsmith’s analysis stands out for its explicit probabilistic decomposition of the path from current AI development to potential existential catastrophe.</p>
<!-- [-] ADD: @carlsmith2022: "Carlsmith, J. (2022). Is Power-Seeking AI an Existential Risk?" -->
<!-- [-] Explain CITATION: - as a footnote somewhere in this section - that there are multiple versions of the Carlsmith paper: @carlsmith2024 , @carlsmith2021 , @carlsmith2022 @carlsmith2023 -->
<section id="six-premise-decomposition" class="level3">
<h3 class="anchored" data-anchor-id="six-premise-decomposition">2.1.1 Six-Premise Decomposition</h3>
<!-- [-] ADD: @clarke2022 citation -->
<p>According to the MTAIR model <span class="citation" data-cites="clarke2022">Clarke et al. (<a href="../../ref/references.html#ref-clarke2022" role="doc-biblioref">2022</a>)</span>, Carlsmith decomposes existential risk into a probabilistic chain with explicit estimates<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>:</p>
<ol type="1">
<li><strong>Premise</strong>: Transformative AI development this century<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> <span class="math inline">\((P≈0.80)\)</span><a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></li>
<li><strong>Premise</strong>: AI systems pursuing objectives in the world<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> <span class="math inline">\((P≈0.95)\)</span></li>
<li><strong>Premise</strong>: Systems with power-seeking instrumental incentives<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> <span class="math inline">\((P≈0.40)\)</span></li>
<li><strong>Premise</strong>: Sufficient capability for existential threat<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> <span class="math inline">\((P≈0.65)\)</span></li>
<li><strong>Premise</strong>: Misaligned systems despite safety efforts<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> <span class="math inline">\((P≈0.50)\)</span></li>
<li><strong>Premise</strong>: Catastrophic outcomes from misaligned power-seeking<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> <span class="math inline">\((P≈0.65)\)</span></li>
</ol>
<p><strong>Composite Risk Calculation</strong><a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>: <span class="math inline">\(P(doom)≈0.05\)</span> (5%)</p>
<p>This structured approach exemplifies the type of reasoning AMTAIR aims to formalize and automate. While Carlsmith spent months developing this model manually, similar rigor exists implicitly in many AI safety arguments awaiting extraction.</p>
<div id="fig-mtair-insideoutside-base" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-scap="Base APS causal map (clean)" alt="Same node-and-arrow causal graph as the overlay figure but without the purple, violet, and red guiding circles. Blue bullet premises feed ‘Collection of inputs’ rectangle, cascading turquoise probability ovals lead to ‘Cr existential catastrophe | world model’. Lower left shows outside-view priors, right shows weighting logic, centre red oval ‘Cr existential catastrophe’. Provides uncluttered view of the structural model prior to explanatory overlay. SOURCE: David Manheim @manheim2021, MTAIR sequence, 2021." width="120%" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mtair-insideoutside-base-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://www.lesswrong.com/posts/sGkRDrpphsu6Jhega/a-model-based-approach-to-ai-existential-risk"><img src="../../images/mtair-insideoutside-base.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:120.0%" data-fig-scap="Base APS causal map (clean)" alt="Same node-and-arrow causal graph as the overlay figure but without the purple, violet, and red guiding circles. Blue bullet premises feed ‘Collection of inputs’ rectangle, cascading turquoise probability ovals lead to ‘Cr existential catastrophe | world model’. Lower left shows outside-view priors, right shows weighting logic, centre red oval ‘Cr existential catastrophe’. Provides uncluttered view of the structural model prior to explanatory overlay. SOURCE: David Manheim @manheim2021, MTAIR sequence, 2021."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mtair-insideoutside-base-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.1: from <span class="citation" data-cites="manheim2021">Manheim (<a href="../../ref/references.html#ref-manheim2021" role="doc-biblioref">2021</a>)</span>: MTAIR integrated Carlsmith’s model as the “inside view” in their Analytica Software Demonstration
</figcaption>
</figure>
</div>
<!-- [-] TODO: Verify manual extraction of Carlsmith model for ground truth with Ella and Johannes -->
</section>
<section id="why-carlsmith-exemplifies-formalizable-arguments" class="level3">
<h3 class="anchored" data-anchor-id="why-carlsmith-exemplifies-formalizable-arguments">2.1.2 Why Carlsmith Exemplifies Formalizable Arguments</h3>
<!-- [ ] Use as footnote description for enumeration above -->
<p>Carlsmith’s model demonstrates several features that make it ideal for formal representation:</p>
<p><strong>Explicit Probabilistic Structure</strong>: Each premise receives numerical probability estimates with documented reasoning, enabling direct translation to Bayesian network parameters.</p>
<p><strong>Clear Conditional Dependencies</strong>: The logical flow from capabilities through deployment decisions to catastrophic outcomes maps naturally onto directed acyclic graphs.</p>
<p><strong>Transparent Decomposition</strong>: Breaking the argument into modular premises allows independent evaluation and sensitivity analysis of each component.</p>
<p><strong>Documented Reasoning</strong>: Extensive justification for each probability enables extraction of both structure and parameters from the source text.</p>
<!-- [-] ADD: "foreshadowing" of how/why we will pick up with carlsmith model later-->
<p>We will return to Carlsmith’s model in Chapter 3 as our primary complex case study, demonstrating how AMTAIR successfully extracts and formalizes this sophisticated multi-level argument.</p>
<!-- [-] LATER TODO: Extract two additional "inside view" world models for comparison -->
<!-- [-] ADD: @christiano2019: "Christiano, P. (2019). What failure looks like. AI Alignment Forum." -->
<p>Beyond Carlsmith’s model, other structured approaches to AI risk—such as Christiano’s “What failure looks like” <span class="citation" data-cites="christiano2019">Christiano (<a href="../../ref/references.html#ref-christiano2019" role="doc-biblioref">2019</a>)</span>—provide additional targets for automated extraction, enabling comparative analysis across different expert worldviews.</p>
</section>
</section>
<section id="the-epistemic-challenge-of-policy-evaluation" class="level2">
<h2 class="anchored" data-anchor-id="the-epistemic-challenge-of-policy-evaluation">2.2 The Epistemic Challenge of Policy Evaluation</h2>
<!-- [-] TODO: Explain why evaluating AI governance policies is particularly difficult -->
<p>AI governance policy evaluation faces unique epistemic challenges that render traditional policy analysis methods insufficient. Understanding these challenges motivates the need for new computational approaches.</p>
<section id="unique-characteristics-of-ai-governance" class="level3">
<h3 class="anchored" data-anchor-id="unique-characteristics-of-ai-governance">2.2.1 Unique Characteristics of AI Governance</h3>
<p><strong>Deep Uncertainty Rather Than Risk</strong>: Traditional policy analysis distinguishes between risk (known probability distributions) and uncertainty (known possibilities, unknown probabilities). AI governance faces deep uncertainty—we cannot confidently enumerate possible futures, much less assign probabilities <span class="citation" data-cites="hallegatte2012">Hallegatte et al. (<a href="../../ref/references.html#ref-hallegatte2012" role="doc-biblioref">2012</a>)</span>. Will recursive self-improvement enable rapid capability gains? Can value alignment be solved technically? These foundational questions resist empirical resolution before their answers become catastrophically relevant.</p>
<p><strong>Complex Multi-Level Causation</strong>: Policy effects propagate through technical, institutional, and social levels with intricate feedback loops. A technical standard might alter research incentives, shifting capability development trajectories, changing competitive dynamics, and ultimately affecting existential risk through pathways invisible at the policy’s inception. Traditional linear causal models cannot capture these dynamics.</p>
<p><strong>Irreversibility and Lock-In</strong>: Many AI governance decisions create path dependencies that prove difficult or impossible to reverse. Early technical standards shape development trajectories. Institutional structures ossify. International agreements create sticky equilibria. Unlike many policy domains where course correction remains possible, AI governance mistakes may prove permanent.</p>
<p><strong>Value-Laden Technical Choices</strong>: The entanglement of technical and normative questions confounds traditional separation of facts and values. What constitutes “alignment”? How much capability development should we risk for economic benefits? Technical specifications embed ethical judgments that resist neutral expertise.</p>
<!-- [-] CREATE: {#tbl-governance-challenges}: "Comparison of AI governance vs traditional policy domains" -->
<div id="tbl-governance-challenges" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-governance-challenges-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;4.1: Table 2.3.4: Comparison of AI governance vs traditional policy domains
</figcaption>
<div aria-describedby="tbl-governance-challenges-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Dimension</th>
<th>Traditional Policy</th>
<th>AI Governance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Uncertainty Type</td>
<td>Risk (known distributions)</td>
<td>Deep uncertainty (unknown unknowns)</td>
</tr>
<tr class="even">
<td>Causal Structure</td>
<td>Linear, traceable</td>
<td>Multi-level, feedback loops</td>
</tr>
<tr class="odd">
<td>Reversibility</td>
<td>Course correction possible</td>
<td>Path dependencies, lock-in</td>
</tr>
<tr class="even">
<td>Fact-Value Separation</td>
<td>Clear boundaries</td>
<td>Entangled technical-normative</td>
</tr>
<tr class="odd">
<td>Empirical Grounding</td>
<td>Historical precedents</td>
<td>Unprecedented phenomena</td>
</tr>
<tr class="even">
<td>Time Horizons</td>
<td>Years to decades</td>
<td>Months to centuries</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="limitations-of-traditional-approaches" class="level3">
<h3 class="anchored" data-anchor-id="limitations-of-traditional-approaches">2.2.2 Limitations of Traditional Approaches</h3>
<p>Standard policy evaluation tools prove inadequate for these challenges:</p>
<p><strong>Cost-Benefit Analysis</strong> assumes commensurable outcomes and stable probability distributions. When potential outcomes include existential catastrophe with deeply uncertain probabilities, the mathematical machinery breaks down. Infinite negative utility resists standard decision frameworks.</p>
<p><strong>Scenario Planning</strong> helps explore possible futures but typically lacks the probabilistic reasoning needed for decision-making under uncertainty. Without quantification, scenarios provide narrative richness but limited action guidance.</p>
<p><strong>Expert Elicitation</strong> aggregates specialist judgment but struggles with interdisciplinary questions where no single expert grasps all relevant factors. Moreover, experts often operate with different implicit models, making aggregation problematic.</p>
<p><strong>Red Team Exercises</strong> test specific plans but miss systemic risks emerging from component interactions. Gaming individual failures cannot reveal emergent catastrophic possibilities.</p>
<p>These limitations create a methodological gap: we need approaches that handle deep uncertainty, represent complex causation, quantify expert disagreement, and enable systematic exploration of intervention effects.</p>
<!-- [-] ADD: @hallegatte2012: "Hallegatte et al. on robust decision-making under deep uncertainty" -->
</section>
<section id="the-underlying-epistemic-framework" class="level3">
<h3 class="anchored" data-anchor-id="the-underlying-epistemic-framework">2.2.3 The Underlying Epistemic Framework</h3>
<!-- [-] OUTLINE AND WRITE: this entire section about Foundation Epistemic Framework — Probabilistic, Conditional, Possible Worlds -->
<p>The AMTAIR approach rests on a specific epistemic framework that combines probabilistic reasoning, conditional logic, and possible worlds semantics. This framework provides the philosophical foundation for representing deep uncertainty about AI futures.</p>
<p><strong>Probabilistic Epistemology</strong>: Following the Bayesian tradition, we treat probability as a measure of rational credence rather than objective frequency. This subjective interpretation allows meaningful probability assignments even for unique, unprecedented events like AI catastrophe. As E.T. Jaynes demonstrated, probability theory extends deductive logic to handle uncertainty, providing a calculus for rational belief <span class="citation" data-cites="jaynes2003">Jaynes (<a href="../../ref/references.html#ref-jaynes2003" role="doc-biblioref">2003</a>)</span>.</p>
<p><strong>Conditional Structure</strong>: The framework emphasizes conditional rather than absolute probabilities. Instead of asking “What is P(catastrophe)?” we ask “What is P(catastrophe | specific assumptions)?” This conditionalization makes explicit the dependency of conclusions on worldview assumptions, enabling productive disagreement about premises rather than conclusions.</p>
<p><strong>Possible Worlds Semantics</strong>: We conceptualize uncertainty as distributions over possible worlds—complete descriptions of how reality might unfold. Each world represents a coherent scenario with specific values for all relevant variables. Probability distributions over these worlds capture both what we know and what we don’t know about the future.</p>
<p>This framework enables several key capabilities:</p>
<ol type="1">
<li><strong>Representing ignorance</strong>: We can express uncertainty about uncertainty itself through hierarchical probability models</li>
<li><strong>Combining evidence</strong>: Bayesian updating provides principled methods for integrating new information</li>
<li><strong>Comparing worldviews</strong>: Different probability distributions over the same space of possibilities enable systematic comparison</li>
<li><strong>Evaluating interventions</strong>: Counterfactual reasoning about how actions change probability distributions</li>
</ol>
<!-- [-] DECIDE AND IMPLEMENT: Should this section be level 2 ?-->
</section>
<section id="toward-new-epistemic-tools" class="level3">
<h3 class="anchored" data-anchor-id="toward-new-epistemic-tools">2.2.4 Toward New Epistemic Tools</h3>
<!-- [-] TODO: Bridge from limitations to the need for automated, computational approaches -->
<p>The inadequacy of traditional methods for AI governance creates an urgent need for new epistemic tools. These tools must:</p>
<ul>
<li><strong>Handle Deep Uncertainty</strong>: Move beyond point estimates to represent ranges of possibilities</li>
<li><strong>Capture Complex Causation</strong>: Model multi-level interactions and feedback loops</li>
<li><strong>Quantify Disagreement</strong>: Make explicit where experts diverge and why</li>
<li><strong>Enable Systematic Analysis</strong>: Support rigorous comparison of policy options</li>
</ul>
<p><strong>Key Insight</strong>: The computational approaches developed in this thesis—particularly Bayesian networks enhanced with automated extraction—directly address each of these requirements by providing formal frameworks for reasoning under uncertainty.</p>
<div id="fig-conditional_tree" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-scap="Conditional-tree Guide" alt="CHART TYPE: annotated schematic of a three-level conditional tree. DATA: placeholders XX %, AA %, BB %, VV %, WW %, etc. PURPOSE: illustrates colour and label conventions—green for ultimate question, blue/purple for indicator questions, grey/red for branch probabilities, red for updated extinction probabilities and relative-risk factors. DETAILS: shows how each indicator’s TRUE or FALSE branch feeds probabilistically into the ultimate extinction outcome. SOURCE: McCaslin et al. 2024 @mccaslin2024, FRI Working Paper #3." width="80%" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-conditional_tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/66ba37a144f1d6095de467df/1723479995772/AIConditionalTrees.pdf#page=5.78"><img src="../../images/conditional_tree.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%" data-fig-scap="Conditional-tree Guide" alt="CHART TYPE: annotated schematic of a three-level conditional tree. DATA: placeholders XX %, AA %, BB %, VV %, WW %, etc. PURPOSE: illustrates colour and label conventions—green for ultimate question, blue/purple for indicator questions, grey/red for branch probabilities, red for updated extinction probabilities and relative-risk factors. DETAILS: shows how each indicator’s TRUE or FALSE branch feeds probabilistically into the ultimate extinction outcome. SOURCE: McCaslin et al. 2024 @mccaslin2024, FRI Working Paper #3."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-conditional_tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.2: from <span class="citation" data-cites="mccaslin2024">McCaslin et al. (<a href="../../ref/references.html#ref-mccaslin2024" role="doc-biblioref">2024</a>)</span>: Conditional-tree Guide
</figcaption>
</figure>
</div>
<div id="fig-concerned_experts" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-scap="Experts’ conditional-tree updates (2030-2070)" alt="CHART TYPE: conditional-probability tree with three sequential indicator nodes. DATA: baseline AI-extinction probability 17 % in 2023; indicator 1 (2030 administrative disempowerment warning shot) TRUE=37 %, FALSE=63 %; two conditional probabilities for extinction in 2100: 31.6 % (relative-risk 1.9×) if TRUE, 14.3 % (0.9×) if FALSE. Indicator 2 (2050 power-seeking warning shot) TRUE=54 %, FALSE=46 %; corresponding extinction probabilities 23.4 % (1.4×) and 10.5 % (0.6×). Indicator 3 (2070 no aligned AGI) TRUE=46 %, FALSE=54 %; extinction probabilities 25.0 % (1.5×) and 13.7 % (0.8×). PURPOSE: quantifies how confirmation or disconfirmation of warning-shot events would shift expert-assessed AI-extinction risk. DETAILS: experts are most alarmed by earlier administrative disempowerment (1.9× increase) and least by absence of power-seeking shot (0.6×). SOURCE: McCaslin et al. 2024 @mccaslin2024, FRI Working Paper #3." width="80%" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-concerned_experts-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/66ba37a144f1d6095de467df/1723479995772/AIConditionalTrees.pdf#page=5.78"><img src="../../images/concerned_experts.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%" data-fig-scap="Experts’ conditional-tree updates (2030-2070)" alt="CHART TYPE: conditional-probability tree with three sequential indicator nodes. DATA: baseline AI-extinction probability 17 % in 2023; indicator 1 (2030 administrative disempowerment warning shot) TRUE=37 %, FALSE=63 %; two conditional probabilities for extinction in 2100: 31.6 % (relative-risk 1.9×) if TRUE, 14.3 % (0.9×) if FALSE. Indicator 2 (2050 power-seeking warning shot) TRUE=54 %, FALSE=46 %; corresponding extinction probabilities 23.4 % (1.4×) and 10.5 % (0.6×). Indicator 3 (2070 no aligned AGI) TRUE=46 %, FALSE=54 %; extinction probabilities 25.0 % (1.5×) and 13.7 % (0.8×). PURPOSE: quantifies how confirmation or disconfirmation of warning-shot events would shift expert-assessed AI-extinction risk. DETAILS: experts are most alarmed by earlier administrative disempowerment (1.9× increase) and least by absence of power-seeking shot (0.6×). SOURCE: McCaslin et al. 2024 @mccaslin2024, FRI Working Paper #3."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-concerned_experts-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.3: from <span class="citation" data-cites="mccaslin2024">McCaslin et al. (<a href="../../ref/references.html#ref-mccaslin2024" role="doc-biblioref">2024</a>)</span>: Experts’ conditional-tree updates (2030-2070)
</figcaption>
</figure>
</div>
<!-- [-] ADD: @mccaslin2024 cite and write about "Conditional Trees: A Method for Generating Informative Questions about Complex Topics" -->
<p>Recent work on conditional trees demonstrates the value of structured approaches to uncertainty. McCaslin et al. <span class="citation" data-cites="mccaslin2024">McCaslin et al. (<a href="../../ref/references.html#ref-mccaslin2024" role="doc-biblioref">2024</a>)</span> show how hierarchical conditional forecasting can identify high-value questions for reducing uncertainty about complex topics like AI risk. Their methodology, which asks experts to produce simplified Bayesian networks of informative forecasting questions, achieved nine times higher information value than standard forecasting platform questions.</p>
<!-- [-] ADD: @tetlock2022 cite and explain their use of metaculus prediction markets -->
<p>Tetlock’s work with the Forecasting Research Institute <span class="citation" data-cites="tetlock2022">P. Tetlock (<a href="../../ref/references.html#ref-tetlock2022" role="doc-biblioref">2022</a>)</span> exemplifies how prediction markets can provide empirical grounding for formal models. By structuring questions as conditional trees, they enable forecasters to express complex dependencies between events, providing exactly the type of data needed for Bayesian network parameterization.</p>
<div id="fig-conditional_metaculus" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-scap="Conditional-tree AI-risk forecasts" alt="SCREENSHOT of a forecasting-platform interface titled ‘Series Contents’. A search bar and filter chips sit above five forecast cards: 1) ‘If, before 2050, AI kills more than 1 million people, will the policy response be insufficient?’ with a 75 percent gauge (green, arrow up 8 percent). 2) ‘Before 2050, will an AI system be shut down due to exhibiting power-seeking behavior?’ at 95 percent (arrow down 2 percent). 3) ‘Before 2100, will AI cause the human population to fall below 5000 individuals?’ at 4 percent. 4) ‘Before 2030, will there be an AI-caused administrative disempowerment?’ at 20 percent. 5) ‘Between 2023 and 2030, will revenue from deep learning double every two years?’ at 80 percent. Beneath several cards, grey CONDITION boxes branch to green bars labelled ‘CTs AI Extinction Before 2100’ with different probabilities for IF YES and IF NO scenarios (e.g. 26 % vs 37 %). Each question lists forecaster counts, closing dates (2030 or 2050), and the tag ‘Conditional Trees: AI Risk’. A footer card introduces the series report. CHART TYPE: mixed UI elements—gauge dials and horizontal bars—displaying probabilities and conditional probabilities. DATA: probabilities (% chances) for base and conditional events; no axes. PURPOSE: demonstrates how crowd-forecasting encodes marginal and counterfactual probabilities suitable as inputs for AMTAIR Bayesian-network nodes. DETAILS: notable high probability for power-seeking AI shutdown, low probability for population collapse, and large shifts in extinction risk under certain conditions. SOURCE: Forecasting Research Institute conditional-tree series, @tetlock2022." width="80%" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-conditional_metaculus-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://www.metaculus.com/tournament/3508/"><img src="../../images/conditional_metaculus.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%" data-fig-scap="Conditional-tree AI-risk forecasts" alt="SCREENSHOT of a forecasting-platform interface titled ‘Series Contents’. A search bar and filter chips sit above five forecast cards: 1) ‘If, before 2050, AI kills more than 1 million people, will the policy response be insufficient?’ with a 75 percent gauge (green, arrow up 8 percent). 2) ‘Before 2050, will an AI system be shut down due to exhibiting power-seeking behavior?’ at 95 percent (arrow down 2 percent). 3) ‘Before 2100, will AI cause the human population to fall below 5000 individuals?’ at 4 percent. 4) ‘Before 2030, will there be an AI-caused administrative disempowerment?’ at 20 percent. 5) ‘Between 2023 and 2030, will revenue from deep learning double every two years?’ at 80 percent. Beneath several cards, grey CONDITION boxes branch to green bars labelled ‘CTs AI Extinction Before 2100’ with different probabilities for IF YES and IF NO scenarios (e.g. 26 % vs 37 %). Each question lists forecaster counts, closing dates (2030 or 2050), and the tag ‘Conditional Trees: AI Risk’. A footer card introduces the series report. CHART TYPE: mixed UI elements—gauge dials and horizontal bars—displaying probabilities and conditional probabilities. DATA: probabilities (% chances) for base and conditional events; no axes. PURPOSE: demonstrates how crowd-forecasting encodes marginal and counterfactual probabilities suitable as inputs for AMTAIR Bayesian-network nodes. DETAILS: notable high probability for power-seeking AI shutdown, low probability for population collapse, and large shifts in extinction risk under certain conditions. SOURCE: Forecasting Research Institute conditional-tree series, @tetlock2022."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-conditional_metaculus-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.4: from <span class="citation" data-cites="tetlock2022">P. Tetlock (<a href="../../ref/references.html#ref-tetlock2022" role="doc-biblioref">2022</a>)</span>: Conditional-tree AI-risk forecasts
</figcaption>
</figure>
</div>
<!-- [-] ADD @gruetzemacher2022 cite and summarize the relevant aspects -->
<p>Gruetzemacher <span class="citation" data-cites="gruetzemacher2022">Gruetzemacher (<a href="../../ref/references.html#ref-gruetzemacher2022" role="doc-biblioref">2022</a>)</span> evaluates the tradeoffs between full Bayesian networks and conditional trees for forecasting tournaments. While conditional trees offer simplicity, Bayesian networks provide richer representation of dependencies—motivating AMTAIR’s approach of using full networks while leveraging conditional tree insights for question generation.</p>
<div id="fig-bayesnet-crux-flow" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-scap="Bayes-net pruning → crux extraction → re-expansion" alt="THREE-PANEL DIAGRAM. Panel A (upper left) titled ‘Initial Bayes Net—Pruning Least Relevant Nodes’ shows eleven circular nodes connected by arrows inside a rounded rectangle. Solid circles remain; dashed or dotted ones are pruned. Arrows converge on a solid node labelled ‘AI causes human extinction’. Panel B (upper right) titled ‘Two Sets of Crux Events from Bayes Nets Isolated as Conditional Trees’ shows two short vertical chains of dotted or dashed circles. Chain 1: ‘AI alignment problem is solved’ → ‘China and the US cooperate on AI alignment’ → ‘Discontinuous progress in computational costs’. Chain 2: ‘Intergovernmental treaty on AI alignment’ ← ‘Robust AI-driven economic growth’ ← ‘Continual learning integrated with foundation models’. Panel C (bottom) titled ‘Top Set of Crux Events as Conditional Tree Decomposed to Bayes Net’ depicts a new Bayes net where context nodes such as ‘Photonic computing is used for CPU’, ‘US/China trade increases’, and ‘US grows increasingly authoritarian’ feed into ‘China and the US cooperate on AI alignment’, then into ‘AI alignment problem is solved’, and finally ‘AI causes human extinction’. Arrows between panels illustrate the workflow sequence. CHART TYPE: conceptual flow diagram with two Bayes nets and intermediate conditional trees. DATA: relationships among qualitative variables—no numeric axes. PURPOSE: illustrates AMTAIR’s iterative refinement pipeline from full Bayes net to crux-tree extraction and back. DETAILS: emphasises node styles (solid, dashed, dotted) for relevance; shows convergence toward the extinction outcome. SOURCE: @gruetzemacher2022, May 2025." width="100%" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bayesnet-crux-flow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://bnma.co/uai2022-apps-workshop/papers/S5.pdf"><img src="../../images/bns_and_conditional_trees.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%" data-fig-scap="Bayes-net pruning → crux extraction → re-expansion" alt="THREE-PANEL DIAGRAM. Panel A (upper left) titled ‘Initial Bayes Net—Pruning Least Relevant Nodes’ shows eleven circular nodes connected by arrows inside a rounded rectangle. Solid circles remain; dashed or dotted ones are pruned. Arrows converge on a solid node labelled ‘AI causes human extinction’. Panel B (upper right) titled ‘Two Sets of Crux Events from Bayes Nets Isolated as Conditional Trees’ shows two short vertical chains of dotted or dashed circles. Chain 1: ‘AI alignment problem is solved’ → ‘China and the US cooperate on AI alignment’ → ‘Discontinuous progress in computational costs’. Chain 2: ‘Intergovernmental treaty on AI alignment’ ← ‘Robust AI-driven economic growth’ ← ‘Continual learning integrated with foundation models’. Panel C (bottom) titled ‘Top Set of Crux Events as Conditional Tree Decomposed to Bayes Net’ depicts a new Bayes net where context nodes such as ‘Photonic computing is used for CPU’, ‘US/China trade increases’, and ‘US grows increasingly authoritarian’ feed into ‘China and the US cooperate on AI alignment’, then into ‘AI alignment problem is solved’, and finally ‘AI causes human extinction’. Arrows between panels illustrate the workflow sequence. CHART TYPE: conceptual flow diagram with two Bayes nets and intermediate conditional trees. DATA: relationships among qualitative variables—no numeric axes. PURPOSE: illustrates AMTAIR’s iterative refinement pipeline from full Bayes net to crux-tree extraction and back. DETAILS: emphasises node styles (solid, dashed, dotted) for relevance; shows convergence toward the extinction outcome. SOURCE: @gruetzemacher2022, May 2025."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bayesnet-crux-flow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.5: from <span class="citation" data-cites="gruetzemacher2022">Gruetzemacher (<a href="../../ref/references.html#ref-gruetzemacher2022" role="doc-biblioref">2022</a>)</span>: Bayes-net pruning → crux extraction → re-expansion
</figcaption>
</figure>
</div>
</section>
</section>
<section id="bayesian-networks-as-knowledge-representation" class="level2">
<h2 class="anchored" data-anchor-id="bayesian-networks-as-knowledge-representation">2.3 Bayesian Networks as Knowledge Representation</h2>
<!-- [-] TODO: Introduce Bayesian networks as formal tools for representing uncertainty -->
<p>Bayesian networks offer a mathematical framework uniquely suited to addressing these epistemic challenges. By combining graphical structure with probability theory, they provide tools for reasoning about complex uncertain domains.</p>
<section id="mathematical-foundations" class="level3">
<h3 class="anchored" data-anchor-id="mathematical-foundations">2.3.1 Mathematical Foundations</h3>
<p>A Bayesian network consists of:</p>
<ul>
<li><strong>Directed Acyclic Graph (DAG)</strong>: Nodes represent variables, edges represent direct dependencies</li>
<li><strong>Conditional Probability Tables (CPTs)</strong>: For each node, P(node|parents) quantifies relationships</li>
</ul>
<p>The joint probability distribution factors according to the graph structure:</p>
<!-- [-] CHECK: if this equation is correct -->
<p>P(X1,X2,…,Xn)=∏i=1nP(Xi∣Parents(Xi))P(X_1, X_2, …, X_n) = _{i=1}^{n} P(X_i | Parents(X_i))P(X1​,X2​,…,Xn​)=i=1∏n​P(Xi​∣Parents(Xi​))</p>
<p>This factorization enables efficient inference and embodies causal assumptions explicitly.</p>
<!-- [-] ADD: @pearl2014: "Pearl, J. (2014). Probabilistic Reasoning in Intelligent Systems: Networks of plausible Inference" -->
<p>Pearl’s foundational work <span class="citation" data-cites="pearl2014">Pearl (<a href="../../ref/references.html#ref-pearl2014" role="doc-biblioref">2014</a>)</span> established Bayesian networks as a principled approach to automated reasoning under uncertainty, providing both theoretical foundations and practical algorithms.</p>
<!-- [-] INTEGRATE: the information of this write up -->
<!-- Removed lengthy section on risk management and Bayesian networks that wasn't directly relevant to the thesis focus -->
</section>
<section id="the-rain-sprinkler-grass-example" class="level3">
<h3 class="anchored" data-anchor-id="the-rain-sprinkler-grass-example">2.3.2 The Rain-Sprinkler-Grass Example</h3>
<!-- [-] CHANGE ORDER: of Rain-sprinkler-grass example and argument mapping section-->
<p>The canonical example illustrates key concepts<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>:</p>
<!-- [-] EXPAND: Use this to elaborate and explain "from DAGs to Bayesian Networks" -->
<div class="sourceCode" id="cb1"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ot">[Grass_Wet]: </span>Concentrated moisture on grass. </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="ss"> + </span><span class="co">[</span><span class="ot">Rain</span><span class="co">]</span>: Water falling from sky.</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="ss"> + </span><span class="co">[</span><span class="ot">Sprinkler</span><span class="co">]</span>: Artificial watering system.</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="ss">   + </span><span class="co">[</span><span class="ot">Rain</span><span class="co">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Network Structure:</p>
<ul>
<li><strong>Rain</strong> (root cause): P(rain) = 0.2</li>
<li><strong>Sprinkler</strong> (intermediate): P(sprinkler|rain) varies by rain state</li>
<li><strong>Grass_Wet</strong> (effect): P(wet|rain, sprinkler) depends on both causes</li>
</ul>
<!-- [ ] FIX: Mermaid flowchart of Rain-Sprinkler-Grass model with probabilities (in correct Quarto Syntax)-->
<!--

-->
<p>python</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Basic network representation</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>nodes <span class="op">=</span> [<span class="st">'Rain'</span>, <span class="st">'Sprinkler'</span>, <span class="st">'Grass_Wet'</span>]</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>edges <span class="op">=</span> [(<span class="st">'Rain'</span>, <span class="st">'Sprinkler'</span>), (<span class="st">'Rain'</span>, <span class="st">'Grass_Wet'</span>), (<span class="st">'Sprinkler'</span>, <span class="st">'Grass_Wet'</span>)]</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Conditional probability specification</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>P_wet_given_causes <span class="op">=</span> {</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    (<span class="va">True</span>, <span class="va">True</span>): <span class="fl">0.99</span>,    <span class="co"># Rain=T, Sprinkler=T</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    (<span class="va">True</span>, <span class="va">False</span>): <span class="fl">0.80</span>,   <span class="co"># Rain=T, Sprinkler=F  </span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    (<span class="va">False</span>, <span class="va">True</span>): <span class="fl">0.90</span>,   <span class="co"># Rain=F, Sprinkler=T</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    (<span class="va">False</span>, <span class="va">False</span>): <span class="fl">0.01</span>   <span class="co"># Rain=F, Sprinkler=F</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This simple network demonstrates:</p>
<ul>
<li><strong>Marginal Inference</strong>: P(grass_wet) computed from joint distribution</li>
<li><strong>Diagnostic Reasoning</strong>: P(rain|grass_wet) reasoning from effects to causes</li>
<li><strong>Intervention Modeling</strong>: P(grass_wet|do(sprinkler=on)) for policy analysis</li>
</ul>
<!-- [-] CREATE: {#fig-rain-sprinkler-network}: "Visual Bayesian network for rain-sprinkler-grass with CPTs" -->
<section id="rain-sprinkler-grass-network-rendering" class="level4">
<h4 class="anchored" data-anchor-id="rain-sprinkler-grass-network-rendering">2.3.3 Rain-Sprinkler-Grass Network Rendering</h4>
<div id="cell-rain_sprinkler_grass_example_network_rendering" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> IFrame</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>IFrame(src<span class="op">=</span><span class="st">"https://singularitysmith.github.io/AMTAIR_Prototype/bayesian_network.html"</span>, width<span class="op">=</span><span class="st">"100%"</span>, height<span class="op">=</span><span class="st">"800px"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="rain_sprinkler_grass_example_network_rendering" class="cell-output cell-output-display" data-execution_count="1">

        <iframe width="100%" height="800px" src="https://singularitysmith.github.io/AMTAIR_Prototype/bayesian_network.html" frameborder="0" allowfullscreen=""></iframe>
        
<p>Dynamic Html Rendering of the Rain-Sprinkler-Grass DAG with Conditional Probabilities</p>
</div>
</div>
</section>
</section>
<section id="sec-modeling-advantages" class="level3">
<h3 class="anchored" data-anchor-id="sec-modeling-advantages">2.3.4 Advantages for AI Risk Modeling</h3>
<p>These features address key requirements for AI governance:</p>
<ul>
<li><strong>Handling Uncertainty</strong>: Every parameter is a distribution, not a point estimate</li>
<li><strong>Representing Causation</strong>: Directed edges embody causal relationships</li>
<li><strong>Enabling Analysis</strong>: Formal inference algorithms support systematic evaluation</li>
<li><strong>Facilitating Communication</strong>: Visual structure aids cross-domain understanding</li>
</ul>
<p>Bayesian networks offer several compelling advantages for the peculiar challenge of modeling AI risks—a domain where we’re essentially trying to reason about systems that don’t yet exist, wielding capabilities we can barely imagine, potentially causing outcomes we desperately hope to avoid.</p>
<p><strong>Explicit Uncertainty Representation</strong>: Unlike traditional risk assessment tools that often hide uncertainty behind point estimates, Bayesian networks wear their uncertainty on their sleeve. Every node, every edge, every probability is a distribution rather than a false certainty. This matters enormously when discussing AI catastrophe—we’re not pretending to know the unknowable, but rather mapping the landscape of our ignorance with mathematical precision.</p>
<p><strong>Native Causal Reasoning</strong>: The directed edges in Bayesian networks aren’t just arrows on a diagram; they encode causal beliefs about how the world works. This enables both forward reasoning (“If we develop AGI, what happens?”) and diagnostic reasoning (“Given that we observe concerning AI behaviors, what does this tell us about underlying alignment?”). Pearl’s do-calculus <span class="citation" data-cites="pearl2009">Pearl (<a href="../../ref/references.html#ref-pearl2009" role="doc-biblioref">2009</a>)</span> transforms these networks into laboratories for counterfactual exploration.</p>
<p><strong>Evidence Integration</strong>: As new research emerges, as capabilities advance, as governance experiments succeed or fail, Bayesian networks provide a principled framework for updating our beliefs. Unlike static position papers that age poorly, these models can evolve with our understanding—a living document for a rapidly changing field.</p>
<p><strong>Modular Construction</strong>: Complex arguments about AI risk involve multiple interacting factors across technical, social, and political domains. Bayesian networks allow us to build these arguments piece by piece, validating each component before assembling the whole. This modularity also enables different experts to contribute their specialized knowledge without needing to understand every aspect of the system.</p>
<p><strong>Visual Communication</strong>: Perhaps most importantly for the coordination challenge, Bayesian networks provide a visual language that transcends disciplinary boundaries. A policymaker might not understand the mathematics of instrumental convergence, but they can see how the “power-seeking” node connects to “human disempowerment” in the network diagram. This shared visual vocabulary creates common ground for productive disagreement.</p>
<!-- [-] COMPLETED: Added advantages for AI risk modeling with proper explanation -->
</section>
</section>
<section id="sec-argument-mapping" class="level2">
<h2 class="anchored" data-anchor-id="sec-argument-mapping">2.4 Argument Mapping and Formal Representations</h2>
<!-- [-] TODO: Bridge informal reasoning to formal models -->
<p>The journey from a researcher’s intuition about AI risk to a formal probabilistic model resembles translating poetry into mathematics—something essential is always at risk of being lost, yet something equally essential might be gained. Argument mapping provides the crucial middle ground, a structured approach to preserving the logic of natural language arguments while preparing them for mathematical formalization.</p>
<section id="sec-natural-to-structure" class="level3">
<h3 class="anchored" data-anchor-id="sec-natural-to-structure">2.4.1 From Natural Language to Structure</h3>
<p>Natural language arguments about AI risk are rich tapestries woven from causal claims, conditional relationships, uncertainty expressions, and support patterns. When Bostrom writes about the “treacherous turn” <span class="citation" data-cites="bostrom2014">Bostrom (<a href="../../ref/references.html#ref-bostrom2014" role="doc-biblioref">2014</a>)</span>, he’s not just coining a memorable phrase—he’s encoding a complex causal story about how a seemingly aligned AI system might conceal its true objectives until it gains sufficient power to pursue them without constraint.</p>
<p>The challenge lies in extracting this structure without losing the nuance. Traditional logical analysis might reduce Bostrom’s argument to syllogisms, but this would miss the probabilistic texture, the implicit conditionality, the causal directionality that makes the argument compelling. Argument mapping takes a different approach, seeking to identify:</p>
<ul>
<li><strong>Core claims and propositions</strong>: What exactly is being asserted?</li>
<li><strong>Inferential relationships</strong>: How do claims support or challenge each other?</li>
<li><strong>Implicit assumptions</strong>: What unstated premises make the argument work?</li>
<li><strong>Uncertainty qualifications</strong>: Where does the author express doubt or confidence?</li>
</ul>
<p>Recent advances in computational argument mining <span class="citation" data-cites="anderson2007">Anderson (<a href="../../ref/references.html#ref-anderson2007" role="doc-biblioref">2007</a>)</span> <span class="citation" data-cites="benn2011">Benn and Macintosh (<a href="../../ref/references.html#ref-benn2011" role="doc-biblioref">2011</a>)</span> <span class="citation" data-cites="khartabil2021">Khartabil et al. (<a href="../../ref/references.html#ref-khartabil2021" role="doc-biblioref">2021</a>)</span> have shown promise in automating parts of this process. Tools like Microsoft’s Claimify <span class="citation" data-cites="metropolitansky2025">Metropolitansky and Larson (<a href="../../ref/references.html#ref-metropolitansky2025" role="doc-biblioref">2025</a>)</span> demonstrate how large language models can extract verifiable claims from complex texts, though the challenge of preserving argumentative structure remains formidable.</p>
<!-- [-] COMPLETED: Added comprehensive review of argument visualization techniques as requested -->
</section>
<section id="sec-argdown-notation" class="level3">
<h3 class="anchored" data-anchor-id="sec-argdown-notation">2.4.2 ArgDown: Structured Argument Notation</h3>
<p>Enter ArgDown <span class="citation" data-cites="voigt2025">Voigt (<a href="../../ref/references.html#ref-voigt2025" role="doc-biblioref">[2014] 2025</a>)</span>, a markdown-inspired syntax that captures hierarchical argument structure while remaining human-readable. Think of it as the middle child between the wild expressiveness of natural language and the rigid formality of logic—inheriting the best traits of both parents while developing its own personality.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="ot">[MainClaim]: </span>Description of primary conclusion.</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="ss"> + </span><span class="co">[</span><span class="ot">SupportingEvidence</span><span class="co">]</span>: Evidence supporting the claim.</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="ss">   + </span><span class="co">[</span><span class="ot">SubEvidence</span><span class="co">]</span>: More specific support.</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span><span class="co">[</span><span class="ot">CounterArgument</span><span class="co">]</span>: Evidence against the claim.</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This notation does several clever things simultaneously. The hierarchical structure mirrors how we naturally think about arguments—main claims supported by evidence, which in turn rest on more fundamental observations. The <code>+</code> and <code>-</code> symbols indicate support and opposition relationships, creating a visual flow of argumentative force. Most importantly, it preserves the semantic content of each claim while imposing just enough structure to enable computational processing.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="ot">[AI_Poses_Risk]: </span>Advanced AI systems may pose existential risk to humanity.</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="ss"> + </span><span class="co">[</span><span class="ot">Capability_Growth</span><span class="co">]</span>: AI capabilities are growing exponentially.</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="ss">   + </span><span class="co">[</span><span class="ot">Compute_Scaling</span><span class="co">]</span>: Available compute doubles every few months.</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="ss">   + </span><span class="co">[</span><span class="ot">Algorithmic_Progress</span><span class="co">]</span>: New architectures show surprising emergent abilities.</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="ss"> + </span><span class="co">[</span><span class="ot">Alignment_Difficulty</span><span class="co">]</span>: Aligning AI with human values is unsolved.</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span><span class="co">[</span><span class="ot">Current_Progress</span><span class="co">]</span>: Some progress on interpretability and oversight.</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="ss"> - </span><span class="co">[</span><span class="ot">Institutional_Response</span><span class="co">]</span>: Institutions are mobilizing to address risks.</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>For AMTAIR, we adapt ArgDown specifically for causal arguments, where the hierarchy represents causal influence rather than logical support. This seemingly small change has profound implications—we’re not just mapping what follows from what, but what causes what.</p>
<!-- [-] COMPLETED: Added ArgDown explanation with example -->
</section>
<section id="sec-bayesdown" class="level3">
<h3 class="anchored" data-anchor-id="sec-bayesdown">2.4.3 BayesDown: The Bridge to Bayesian Networks</h3>
<!-- [-] COMPLETED: Explained that BayesDown was developed by the author -->
<p>If ArgDown is the middle child, then BayesDown—developed specifically for this thesis—is the ambitious younger sibling who insists on quantifying everything. By extending ArgDown syntax with probabilistic metadata in JSON format, BayesDown creates a complete specification for Bayesian networks while maintaining human readability.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ot">[</span><span class="er">Effect</span><span class="ot">]</span><span class="er">:</span> <span class="er">Description</span> <span class="er">of</span> <span class="er">effect.</span> <span class="fu">{</span><span class="dt">"instantiations"</span><span class="fu">:</span> <span class="ot">[</span><span class="st">"effect_TRUE"</span><span class="ot">,</span> <span class="st">"effect_FALSE"</span><span class="ot">]</span><span class="fu">}</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a> <span class="er">+</span> <span class="ot">[</span><span class="er">Cause1</span><span class="ot">]</span><span class="er">:</span> <span class="er">Description</span> <span class="er">of</span> <span class="er">first</span> <span class="er">cause.</span> <span class="fu">{</span><span class="dt">"instantiations"</span><span class="fu">:</span> <span class="ot">[</span><span class="st">"cause1_TRUE"</span><span class="ot">,</span> <span class="st">"cause1_FALSE"</span><span class="ot">]</span><span class="fu">}</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a> <span class="er">+</span> <span class="ot">[</span><span class="er">Cause2</span><span class="ot">]</span><span class="er">:</span> <span class="er">Description</span> <span class="er">of</span> <span class="er">second</span> <span class="er">cause.</span> <span class="fu">{</span><span class="dt">"instantiations"</span><span class="fu">:</span> <span class="ot">[</span><span class="st">"cause2_TRUE"</span><span class="ot">,</span> <span class="st">"cause2_FALSE"</span><span class="ot">]</span><span class="fu">}</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>   <span class="er">+</span> <span class="ot">[</span><span class="er">Root_Cause</span><span class="ot">]</span><span class="er">:</span> <span class="er">A</span> <span class="er">cause</span> <span class="er">that</span> <span class="er">influences</span> <span class="er">Cause2.</span> <span class="fu">{</span><span class="dt">"instantiations"</span><span class="fu">:</span> <span class="ot">[</span><span class="st">"root_TRUE"</span><span class="ot">,</span> <span class="st">"root_FALSE"</span><span class="ot">]</span><span class="fu">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This representation performs a delicate balancing act. The natural language descriptions preserve the semantic meaning that makes arguments comprehensible. The hierarchical structure maintains the causal relationships that give arguments their logical force. The JSON metadata adds the mathematical precision needed for formal analysis. Together, they create what I call a “hybrid representation”—neither fully natural nor fully formal, but something more useful than either alone.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ot">[</span><span class="er">Existential_Catastrophe</span><span class="ot">]</span><span class="er">:</span> <span class="er">Permanent</span> <span class="er">curtailment</span> <span class="er">of</span> <span class="er">humanity's</span> <span class="er">potential.</span> <span class="fu">{</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"instantiations"</span><span class="fu">:</span> <span class="ot">[</span><span class="st">"catastrophe_TRUE"</span><span class="ot">,</span> <span class="st">"catastrophe_FALSE"</span><span class="ot">]</span><span class="fu">,</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"priors"</span><span class="fu">:</span> <span class="fu">{</span><span class="dt">"p(catastrophe_TRUE)"</span><span class="fu">:</span> <span class="st">"0.05"</span><span class="fu">,</span> <span class="dt">"p(catastrophe_FALSE)"</span><span class="fu">:</span> <span class="st">"0.95"</span><span class="fu">},</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"posteriors"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"p(catastrophe_TRUE|disempowerment_TRUE)"</span><span class="fu">:</span> <span class="st">"0.95"</span><span class="fu">,</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"p(catastrophe_TRUE|disempowerment_FALSE)"</span><span class="fu">:</span> <span class="st">"0.001"</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">}</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a> <span class="er">+</span> <span class="ot">[</span><span class="er">Human_Disempowerment</span><span class="ot">]</span><span class="er">:</span> <span class="er">Loss</span> <span class="er">of</span> <span class="er">human</span> <span class="er">control</span> <span class="er">over</span> <span class="er">future</span> <span class="er">trajectory.</span> <span class="fu">{</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>   <span class="dt">"instantiations"</span><span class="fu">:</span> <span class="ot">[</span><span class="st">"disempowerment_TRUE"</span><span class="ot">,</span> <span class="st">"disempowerment_FALSE"</span><span class="ot">]</span><span class="fu">,</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>   <span class="dt">"priors"</span><span class="fu">:</span> <span class="fu">{</span><span class="dt">"p(disempowerment_TRUE)"</span><span class="fu">:</span> <span class="st">"0.20"</span><span class="fu">,</span> <span class="dt">"p(disempowerment_FALSE)"</span><span class="fu">:</span> <span class="st">"0.80"</span><span class="fu">}</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a> <span class="fu">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The two-stage extraction process (ArgDown → BayesDown) mirrors how experts actually think about complex arguments. First, we identify what matters and how things relate causally (structure). Then, we consider how likely different scenarios are based on those relationships (quantification). This separation isn’t just convenient for implementation—it’s psychologically valid.</p>
<!-- [-] COMPLETED: Added detailed BayesDown explanation -->
</section>
</section>
<section id="sec-mtair-framework" class="level2">
<h2 class="anchored" data-anchor-id="sec-mtair-framework">2.5 The MTAIR Framework: Achievements and Limitations</h2>
<!-- [-] TODO: Explain the MTAIR project's methodological approach -->
<p>Understanding AMTAIR requires understanding its intellectual ancestor: the Modeling Transformative AI Risks (MTAIR) project. Like many good ideas in science, MTAIR began with a simple observation and a ambitious goal.</p>
<section id="sec-mtair-approach" class="level3">
<h3 class="anchored" data-anchor-id="sec-mtair-approach">2.5.1 MTAIR’s Approach</h3>
<p>The MTAIR project, spearheaded by David Manheim and colleagues <span class="citation" data-cites="clarke2022">Clarke et al. (<a href="../../ref/references.html#ref-clarke2022" role="doc-biblioref">2022</a>)</span>, emerged from a frustration familiar to anyone who’s attended a conference on AI safety: brilliant people talking past each other, using the same words to mean different things, reaching incompatible conclusions from seemingly shared premises. The diagnosis was elegant—perhaps these disagreements stemmed not from fundamental philosophical differences but from implicit models that had never been made explicit.</p>
<p>Their prescription was equally elegant: manually translate influential AI risk arguments into formal Bayesian networks, making assumptions visible and disagreements quantifiable. Using Analytica software, the team embarked on what can only be described as an intellectual archaeology expedition, carefully excavating the implicit causal models buried in papers, blog posts, and treatises about AI risk.</p>
<div id="fig-mtair-qual-map" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-scap="MTAIR Qualitative map structure" alt="NODE-LINK DIAGRAM titled ‘Qualitative Map’. Blue rectangles ‘Hypothesis 1’ and ‘Hypothesis 2’, cyan rectangles ‘Debated propositions 1 &amp; 2’, green rectangles ‘Proposed agendas 1 &amp; 2’, red rectangles ‘Catastrophe scenarios 1 &amp; 2’. Arrows show causal influence path from hypotheses through debated propositions and agendas to catastrophes. No probability icons, no analysis panel. PURPOSE: foundational structure before numerical parametrisation, illustrating argumentative flow in MTAIR. SOURCE: David Manheim et. al, Modeling Transformative AI Risks (MTAIR) Project -- Summary Report, 2021." width="25%" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mtair-qual-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://arxiv.org/pdf/2206.09360#page=10.75"><img src="../../images/mtair-qual-map.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:25.0%" data-fig-scap="MTAIR Qualitative map structure" alt="NODE-LINK DIAGRAM titled ‘Qualitative Map’. Blue rectangles ‘Hypothesis 1’ and ‘Hypothesis 2’, cyan rectangles ‘Debated propositions 1 &amp; 2’, green rectangles ‘Proposed agendas 1 &amp; 2’, red rectangles ‘Catastrophe scenarios 1 &amp; 2’. Arrows show causal influence path from hypotheses through debated propositions and agendas to catastrophes. No probability icons, no analysis panel. PURPOSE: foundational structure before numerical parametrisation, illustrating argumentative flow in MTAIR. SOURCE: David Manheim et. al, Modeling Transformative AI Risks (MTAIR) Project -- Summary Report, 2021."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mtair-qual-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.6: from <span class="citation" data-cites="clarke2022">Clarke et al. (<a href="../../ref/references.html#ref-clarke2022" role="doc-biblioref">2022</a>)</span>: MTAIR Qualitative map structure
</figcaption>
</figure>
</div>
<p>The process was painstaking:</p>
<ol type="1">
<li><strong>Systematic Decomposition</strong>: Breaking complex arguments into component claims, identifying variables and relationships through close reading and expert consultation.</li>
<li><strong>Probability Elicitation</strong>: Gathering quantitative estimates through structured expert interviews, literature review, and careful interpretation of qualitative claims.</li>
<li><strong>Sensitivity Analysis</strong>: Testing which parameters most influenced conclusions, revealing where disagreements actually mattered versus where they were merely academic.</li>
<li><strong>Visual Communication</strong>: Creating interactive models that stakeholders could explore, modify, and understand without deep technical training.</li>
</ol>
<p>The ambition was breathtaking—to create a formal lingua franca for AI risk discussions, enabling productive disagreement and cumulative progress.</p>
<div id="fig-mtair-quant-map" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-scap="MTAIR Quantitative map structure" alt="FLOW DIAGRAM titled ‘Quantitative Model’. Blue and cyan rectangles (Hypotheses and Debated propositions) feed green ‘Proposed agenda’ boxes and a rose ‘Meta-uncertainty’ box, which all point to red ‘Catastrophe scenario’ boxes. Tiny mini-PDF icons depict probability distributions beside each variable. Right-hand analysis panel lists Effects of investment, Sensitivity analysis, What-if questions, Decision approaches, Analysis tools. PURPOSE: show how MTAIR converts a qualitative causal map into a quantified Bayesian network that supports downstream scenario and decision analysis. OURCE: David Manheim et. al, Modeling Transformative AI Risks (MTAIR) Project -- Summary Report, 2021." width="60%" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mtair-quant-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://arxiv.org/pdf/2206.09360#page=10.75"><img src="../../images/mtair-quant-map.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%" data-fig-scap="MTAIR Quantitative map structure" alt="FLOW DIAGRAM titled ‘Quantitative Model’. Blue and cyan rectangles (Hypotheses and Debated propositions) feed green ‘Proposed agenda’ boxes and a rose ‘Meta-uncertainty’ box, which all point to red ‘Catastrophe scenario’ boxes. Tiny mini-PDF icons depict probability distributions beside each variable. Right-hand analysis panel lists Effects of investment, Sensitivity analysis, What-if questions, Decision approaches, Analysis tools. PURPOSE: show how MTAIR converts a qualitative causal map into a quantified Bayesian network that supports downstream scenario and decision analysis. OURCE: David Manheim et. al, Modeling Transformative AI Risks (MTAIR) Project -- Summary Report, 2021."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mtair-quant-map-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.7: from <span class="citation" data-cites="clarke2022">Clarke et al. (<a href="../../ref/references.html#ref-clarke2022" role="doc-biblioref">2022</a>)</span>: MTAIR Quantitative map structure
</figcaption>
</figure>
</div>
<!-- [-] COMPLETED: Added comprehensive MTAIR description -->
</section>
<section id="sec-mtair-achievements" class="level3">
<h3 class="anchored" data-anchor-id="sec-mtair-achievements">2.5.2 Key Achievements</h3>
<p>Credit where credit is due: MTAIR demonstrated something many thought impossible. Complex philosophical arguments about AI risk—the kind that sprawl across hundred-page papers mixing technical detail with speculative scenarios—could indeed be formalized without losing their essential insights.</p>
<p><strong>Feasibility of Formalization</strong>: The project’s greatest achievement was simply showing it could be done. Arguments from Bostrom, Christiano, and others translated surprisingly well into network form, suggesting that beneath the surface complexity lay coherent causal models waiting to be extracted.</p>
<p><strong>Value of Quantification</strong>: Moving from “likely” and “probably” to actual numbers forced precision in a domain often clouded by vague pronouncements. Disagreements that seemed fundamental sometimes evaporated when forced to specify exactly what probability ranges were under dispute.</p>
<p><strong>Cross-Perspective Communication</strong>: The formal models created neutral ground where technical AI researchers and policy wonks could meet. Instead of talking past each other in incompatible languages, they could point to specific nodes and edges, making disagreements concrete and tractable.</p>
<p><strong>Research Prioritization</strong>: Perhaps most practically, sensitivity analysis revealed which empirical questions actually mattered. If changing your belief about technical parameter X from 0.3 to 0.7 doesn’t meaningfully affect the conclusion about AI risk, maybe we should focus our research elsewhere.</p>
<div id="fig-mtair-insideoutside-overlay" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-scap="Overlay of inside/outside/assimilation views" alt="CONCEPT MAP overlaid by three translucent circles captioned Inside view, Outside views, and Assimilation logic. Left bullet list of six APS assumptions feeds a central causal chain of probabilities (timeline, incentive, alignment, failure, disempowerment, catastrophe) leading to a node titled ‘Cr existential catastrophe | world model’. Lower-left cluster of rectangles represents outside-view priors (Second Species Argument, transformative-tech base rate, AGI timeline forecasts, etc.). Right-hand cluster shows weighting and integration logic combining world-model estimate with outside-view priors into a final existential-catastrophe credence. No numerical axes—pure structural relationships. PURPOSE: illustrate how MTAIR reconciles inside-view technical reasoning with outside-view priors using an assimilation weighting scheme. SOURCE: David Manheim @manheim2021, MTAIR sequence post #3, Jul 2021." width="110%" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mtair-insideoutside-overlay-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="https://www.lesswrong.com/posts/sGkRDrpphsu6Jhega/a-model-based-approach-to-ai-existential-risk"><img src="../../images/mtair-insideoutside-overlay.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:110.0%" data-fig-scap="Overlay of inside/outside/assimilation views" alt="CONCEPT MAP overlaid by three translucent circles captioned Inside view, Outside views, and Assimilation logic. Left bullet list of six APS assumptions feeds a central causal chain of probabilities (timeline, incentive, alignment, failure, disempowerment, catastrophe) leading to a node titled ‘Cr existential catastrophe | world model’. Lower-left cluster of rectangles represents outside-view priors (Second Species Argument, transformative-tech base rate, AGI timeline forecasts, etc.). Right-hand cluster shows weighting and integration logic combining world-model estimate with outside-view priors into a final existential-catastrophe credence. No numerical axes—pure structural relationships. PURPOSE: illustrate how MTAIR reconciles inside-view technical reasoning with outside-view priors using an assimilation weighting scheme. SOURCE: David Manheim @manheim2021, MTAIR sequence post #3, Jul 2021."></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mtair-insideoutside-overlay-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.8: from <span class="citation" data-cites="manheim2021">Manheim (<a href="../../ref/references.html#ref-manheim2021" role="doc-biblioref">2021</a>)</span>: Overlay of inside/outside/assimilation views
</figcaption>
</figure>
</div>
<!-- [-] COMPLETED: Added MTAIR achievements -->
</section>
<section id="sec-mtair-limitations" class="level3">
<h3 class="anchored" data-anchor-id="sec-mtair-limitations">2.5.3 Fundamental Limitations</h3>
<p>But here’s where the story takes a sobering turn. Despite these achievements, MTAIR faced limitations that prevented it from achieving its full vision—limitations that ultimately motivated the development of AMTAIR.</p>
<p><strong>Labor Intensity</strong>: Creating a single model required what can charitably be called a heroic effort. Based on team reports and model complexity, estimates ranged from 200 to 400 expert-hours per formalization<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>. In a field where new influential arguments appear monthly, this pace couldn’t keep up with the discourse.</p>
<!-- [-] COMPLETED: Removed hallucinated specific time breakdowns and replaced with realistic description -->
<p><strong>Static Nature</strong>: Once built, these beautiful models began aging immediately. New research emerged, capability assessments shifted, governance proposals evolved—but updating the models required near-complete reconstruction. They were snapshots of arguments at particular moments, not living representations that could evolve.</p>
<p><strong>Limited Accessibility</strong>: Using the models required Analytica software and non-trivial technical sophistication. The very experts whose arguments were being formalized often couldn’t directly engage with their formalized representations without intermediation.</p>
<p><strong>Single Perspective</strong>: Each model represented one worldview at a time. Comparing different perspectives required building entirely separate models, making systematic comparison across viewpoints labor-intensive and error-prone.</p>
<p>These weren’t failures of execution but fundamental constraints of the manual approach. Like medieval scribes copying manuscripts, the MTAIR team had shown the value of preservation and dissemination, but the printing press had yet to be invented.</p>
<!-- [-] COMPLETED: Added comprehensive limitations -->
</section>
<section id="sec-automation-opportunity" class="level3">
<h3 class="anchored" data-anchor-id="sec-automation-opportunity">2.5.4 The Automation Opportunity</h3>
<p>The MTAIR experience revealed a tantalizing possibility: if the bottleneck was human labor rather than conceptual feasibility, perhaps automation could crack open the problem. The rise of large language models capable of sophisticated reasoning about text created a technological moment ripe for exploitation.</p>
<p>Key lessons from MTAIR informed the automation approach:</p>
<ul>
<li>Formal models genuinely enhance understanding and coordination—the juice is worth the squeeze</li>
<li>The modeling process itself surfaces implicit assumptions—extraction is as valuable as the final product</li>
<li>Quantification enables analyses impossible with qualitative arguments alone—numbers matter even when uncertain</li>
<li>But manual approaches cannot scale to match the challenge—we need computational leverage</li>
</ul>
<p>This set the stage for AMTAIR’s central innovation: using frontier language models to automate the extraction and formalization process while preserving the benefits MTAIR had demonstrated. Not to replace human judgment, but to amplify it—turning what took weeks into what takes hours, enabling comprehensive coverage rather than selective sampling.</p>
<!-- [-] COMPLETED: Added automation opportunity discussion -->
</section>
</section>
<section id="sec-literature-review" class="level2">
<h2 class="anchored" data-anchor-id="sec-literature-review">2.6 Literature Review: Content and Technical Levels</h2>
<!-- [-] TODO: Provide an overview of the key/most important existing AI risk models, governance proposals, and technical approaches -->
<p>The intellectual landscape surrounding AI risk resembles a rapidly expanding metropolis—new neighborhoods of thought spring up monthly, connected by bridges of varying stability to the established districts. A comprehensive review would fill volumes, so let me provide a guided tour of the territories most relevant to AMTAIR’s mission.</p>
<section id="sec-risk-models-evolution" class="level3">
<h3 class="anchored" data-anchor-id="sec-risk-models-evolution">2.6.1 AI Risk Models Evolution</h3>
<p>The intellectual history of AI risk thinking reads like a gradual awakening—from vague unease to mathematical precision, though perhaps losing something essential in translation.</p>
<p>The field’s prehistory belongs to the visionaries and worriers. Good’s 1966 meditation on the ultraintelligent machine feels almost quaint now, with its assumption that such a system would naturally be designed to serve human purposes. Vinge popularized the singularity concept, though his version emphasized speed rather than the strategic considerations that dominate current thinking. These early writings functioned more as philosophical provocations than actionable analyses.</p>
<p><strong>Early Phase (2000-2010)</strong>: The conversation began with broad conceptual arguments. Good’s ultraintelligent machine <span class="citation" data-cites="good1966">Good (<a href="../../ref/references.html#ref-good1966" role="doc-biblioref">1966</a>)</span> and Vinge’s technological singularity set the stage, but these were more thought experiments than models. Yudkowsky’s early writings <span class="citation" data-cites="yudkowsky2008">Yudkowsky (<a href="../../ref/references.html#ref-yudkowsky2008" role="doc-biblioref">2008</a>)</span> introduced key concepts like recursive self-improvement and orthogonality but remained largely qualitative.</p>
<p>Yudkowsky’s contributions in the 2000s marked a transitional moment. His writing style—part manifesto, part technical argument—resisted easy categorization. Yet buried within the sometimes baroque prose lay genuinely novel insights. The orthogonality thesis (intelligence and goals vary independently) and instrumental convergence (diverse goals lead to similar intermediate strategies) provided conceptual tools that remain central to the field. Still, these arguments remained largely qualitative, more useful for establishing possibility than probability.</p>
<p><strong>Formalization Phase (2010-2018)</strong>: Bostrom’s <em>Superintelligence</em> <span class="citation" data-cites="bostrom2014">Bostrom (<a href="../../ref/references.html#ref-bostrom2014" role="doc-biblioref">2014</a>)</span> marked a watershed, providing systematic analysis of pathways, capabilities, and risks. The book’s genius lay not in mathematical formalism but in conceptual clarity—decomposing the nebulous fear of “robot overlords” into specific mechanisms like instrumental convergence and infrastructure profusion.</p>
<p>Bostrom’s 2014 Superintelligence achieved what earlier work had not: respectability. Here was an Oxford philosopher writing with analytical precision about AI risk. The book’s great contribution wasn’t mathematical formalism—indeed, it contains remarkably few equations—but rather its systematic decomposition of the problem space. Bostrom transformed “robots might kill us all” into specific mechanisms: capability gain, goal preservation, resource acquisition. Suddenly, one could have serious discussions about AI risk without sounding like a science fiction enthusiast.</p>
<p>The current quantitative turn, exemplified by Carlsmith’s power-seeking analysis and Cotra’s biological anchors, represents both progress and peril. We now assign numbers where before we had only words. Yet as any student of probability knows, precise numbers don’t necessarily mean accurate predictions. The models grow more sophisticated, the mathematics more rigorous, but the fundamental uncertainties remain as daunting as ever.</p>
<p><strong>Quantification Phase (2018-present)</strong>: Recent years have seen explicit probability estimates entering mainstream discourse. Carlsmith’s power-seeking model <span class="citation" data-cites="carlsmith2022">Carlsmith (<a href="../../ref/references.html#ref-carlsmith2022" role="doc-biblioref">2022</a>)</span>, Cotra’s biological anchors, and various compute-based timelines represent attempts to put numbers on previously qualitative claims. The field increasingly recognizes that governance decisions require more than philosophical arguments—they need probability distributions.</p>
<p>This progression reflects a maturing field, though it also creates new challenges. As models become more quantitative, they risk false precision. As they become more complex, they risk inscrutability. AMTAIR attempts to navigate these tensions by preserving the narrative clarity of earlier work while enabling the mathematical rigor of recent approaches.</p>
<p>The evolution of AI risk models traces a path from philosophical speculation to increasingly rigorous formalization—a journey from “what if?” to “how likely?”</p>
<!-- [-] COMPLETED: Added AI risk models evolution -->
</section>
<section id="sec-governance-taxonomy" class="level3">
<h3 class="anchored" data-anchor-id="sec-governance-taxonomy">2.6.2 Governance Proposals Taxonomy</h3>
<p>If risk models are the diagnosis, governance proposals are the treatment plans—and like medicine, they range from gentle interventions to radical surgery.</p>
<p><strong>Technical Standards</strong>: The “first, do no harm” approach focuses on concrete safety requirements—interpretability benchmarks, robustness testing, capability thresholds. These proposals, exemplified by standard-setting bodies and technical safety organizations, offer specificity at the cost of narrowness.</p>
<p><strong>Regulatory Frameworks</strong>: Moving up the intervention ladder, we find comprehensive regulatory proposals like the EU AI Act <span class="citation" data-cites="european2024">European (<a href="../../ref/references.html#ref-european2024" role="doc-biblioref">2024</a>)</span>. These create institutional structures, liability regimes, and oversight mechanisms, trading broad coverage for implementation complexity.</p>
<p><strong>International Coordination</strong>: At the ambitious end, proposals for international AI governance treaties, soft law arrangements, and technical cooperation agreements aim to prevent races to the bottom. Think nuclear non-proliferation but for minds instead of missiles.</p>
<p><strong>Research Priorities</strong>: Cutting across these categories, work by Dafoe <span class="citation" data-cites="dafoe2018">Dafoe (<a href="../../ref/references.html#ref-dafoe2018" role="doc-biblioref">2018</a>)</span> and others maps the research landscape itself—what questions need answering before we can govern wisely? This meta-level analysis shapes funding flows and talent allocation.</p>
<p>A particularly compelling example of conditional governance thinking comes from “A Narrow Path” <span class="citation" data-cites="miotti2024">Miotti et al. (<a href="../../ref/references.html#ref-miotti2024" role="doc-biblioref">2024</a>)</span>, which proposes a phased approach: immediate safety measures to prevent uncontrolled development, international institutions to ensure stability, and long-term scientific foundations for beneficial transformative AI. This temporal sequencing—safety, stability, then flourishing—reflects growing sophistication in governance thinking.</p>
<!-- [-] COMPLETED: Added governance taxonomy with A Narrow Path example -->
</section>
<section id="sec-bn-theory" class="level3">
<h3 class="anchored" data-anchor-id="sec-bn-theory">2.6.3 Bayesian Network Theory and Applications</h3>
<p>The mathematical machinery underlying AMTAIR rests on decades of theoretical development in probabilistic graphical models. Understanding this foundation helps appreciate both the power and limitations of the approach.</p>
<p>The key insight, crystallized in the work of Pearl <span class="citation" data-cites="pearl2014">Pearl (<a href="../../ref/references.html#ref-pearl2014" role="doc-biblioref">2014</a>)</span> and elaborated by Koller &amp; Friedman <span class="citation" data-cites="koller2009">Koller and Friedman (<a href="../../ref/references.html#ref-koller2009" role="doc-biblioref">2009</a>)</span>, is that independence relationships in complex systems can be read from graph structure. D-separation, the Markov condition, and the relationship between graphs and probability distributions provide the mathematical spine that makes Bayesian networks more than pretty pictures.</p>
<p>Critical concepts for AI risk modeling:</p>
<ul>
<li><strong>Conditional Independence</strong>: Variable A is independent of C given B—encoded through graph separation</li>
<li><strong>Markov Condition</strong>: Each variable is independent of its non-descendants given its parents</li>
<li><strong>Inference Algorithms</strong>: From exact variable elimination to approximate Monte Carlo methods</li>
<li><strong>Causal Interpretation</strong>: When edges represent causal influence, the network supports counterfactual reasoning</li>
</ul>
<p>These aren’t just mathematical niceties. When we claim that “deployment decisions” mediates the relationship between “capability advancement” and “catastrophic risk,” we’re making a precise statement about conditional independence that has testable implications.</p>
<!-- [-] COMPLETED: Added Bayesian network theory -->
</section>
<section id="sec-software-tools" class="level3">
<h3 class="anchored" data-anchor-id="sec-software-tools">2.6.4 Software Tools Landscape</h3>
<p>The gap between Bayesian network theory and practical implementation is bridged by an ecosystem of software tools, each with its own strengths and opinions about how probabilistic reasoning should work.</p>
<p><strong>pgmpy</strong>: This Python library provides the computational backbone for AMTAIR, offering both learning algorithms and inference engines. Its object-oriented design maps naturally onto our extraction pipeline.</p>
<p><strong>NetworkX</strong>: For graph manipulation and analysis, NetworkX has become the de facto standard in Python, providing algorithms for everything from centrality measurement to community detection.</p>
<p><strong>PyVis</strong>: Interactive visualization transforms static networks into explorable landscapes. PyVis’s integration with web technologies enables the rich interactive features that make formal models accessible.</p>
<p><strong>Pandas/NumPy</strong>: The workhorses of scientific Python handle data manipulation and numerical computation, providing the infrastructure on which everything else builds.</p>
<p>The integration challenge—making these tools play nicely together while maintaining performance and correctness—shaped many architectural decisions in AMTAIR. Each tool excels in its domain, but the seams between them required careful engineering.</p>
<!-- [-] COMPLETED: Added software tools -->
</section>
<section id="sec-formalization" class="level3">
<h3 class="anchored" data-anchor-id="sec-formalization">2.6.5 Formalization Approaches</h3>
<p>The challenge of formalizing natural language arguments extends far beyond AI risk, touching on fundamental questions in logic, linguistics, and artificial intelligence.</p>
<p>Pollock’s work on cognitive carpentry <span class="citation" data-cites="pollock1995">Pollock (<a href="../../ref/references.html#ref-pollock1995" role="doc-biblioref">1995</a>)</span> provides philosophical grounding, arguing that human reasoning itself involves implicit formal structures that can be computationally modeled. This view—that formalization reveals rather than imposes structure—underlies AMTAIR’s approach.</p>
<p>Key theoretical challenges:</p>
<ul>
<li><strong>Semantic Preservation</strong>: How do we maintain meaning while adding precision?</li>
<li><strong>Structural Extraction</strong>: What implicit relationships lurk in natural language?</li>
<li><strong>Uncertainty Quantification</strong>: How do we map “likely” to numbers?</li>
</ul>
<p>Recent work on causal structure learning from text <span class="citation" data-cites="babakov2025">Babakov et al. (<a href="../../ref/references.html#ref-babakov2025" role="doc-biblioref">2025</a>)</span> <span class="citation" data-cites="ban2023">Ban et al. (<a href="../../ref/references.html#ref-ban2023" role="doc-biblioref">2023</a>)</span> <span class="citation" data-cites="bethard2007">Bethard (<a href="../../ref/references.html#ref-bethard2007" role="doc-biblioref">2007</a>)</span> offers hope that these challenges can be addressed computationally. The convergence of large language models with formal methods creates new possibilities for bridging the semantic-symbolic gap.</p>
<!-- [-] COMPLETED: Added formalization approaches -->
</section>
<section id="sec-correlation-methods" class="level3">
<h3 class="anchored" data-anchor-id="sec-correlation-methods">2.6.6 Correlation Accounting Methods</h3>
<p>One of the most persistent criticisms of Bayesian networks concerns their assumption of conditional independence given parents. In the real world, and especially in complex socio-technical systems like AI development, correlations abound.</p>
<p>Methods for handling these correlations have evolved considerably:</p>
<p><strong>Copula Methods</strong>: By separating marginal distributions from dependence structure, copulas <span class="citation" data-cites="nelson2006">Nelson (<a href="../../ref/references.html#ref-nelson2006" role="doc-biblioref">2006</a>)</span> allow modeling of complex correlations while preserving the Bayesian network framework. Think of it as adding a correlation layer on top of the basic network.</p>
<p><strong>Hierarchical Models</strong>: Introducing latent variables that influence multiple observed variables captures correlations naturally. If “AI research culture” influences both “capability progress” and “safety investment,” their correlation is explained.</p>
<p><strong>Explicit Correlation Nodes</strong>: Sometimes the most straightforward approach is best—directly model correlation mechanisms as additional nodes in the network.</p>
<p><strong>Sensitivity Bounds</strong>: When correlations remain uncertain, compute best and worst case scenarios. This reveals when independence assumptions critically affect conclusions versus when they’re harmless simplifications.</p>
<p>For AMTAIR, the pragmatic approach dominates: start with independence assumptions, identify where they matter through sensitivity analysis, then selectively add correlation modeling where it most affects conclusions.</p>
<!-- [-] COMPLETED: Added correlation methods -->
</section>
</section>
<section id="sec-methodology" class="level2">
<h2 class="anchored" data-anchor-id="sec-methodology">2.7 Methodology</h2>
<!-- [-] TODO: Present the overall research approach -->
<p>The methodology of this research resembles less a linear march from hypothesis to conclusion and more an iterative dance between theory and implementation, vision and reality. Let me walk you through the choreography. Actually, that’s not quite right. It was messier than a dance. More like trying to build a bridge while crossing it, discovering halfway across that your blueprints assumed different gravity. The original plan seemed straightforward: take the MTAIR team’s manual approach, automate it with language models, validate against their results. Simple. Reality laughed at this simplicity. Language models hallucinate. Arguments don’t decompose cleanly. Probabilities hide in qualifying phrases that might mean 0.6 to one reader and 0.9 to another. Each solution spawned new problems in fractal recursion.</p>
<section id="sec-research-design" class="level3">
<h3 class="anchored" data-anchor-id="sec-research-design">2.7.1 Research Design Overview</h3>
<section id="the-original-plan" class="level4">
<h4 class="anchored" data-anchor-id="the-original-plan">The Original Plan</h4>
<p>This research follows what methodologists might call a “design science” approach—we’re not just studying existing phenomena but creating new artifacts (the AMTAIR system) and evaluating their utility for solving practical problems (the coordination crisis in AI governance).</p>
<p>The overall flow:</p>
<ol type="1">
<li><strong>Theoretical Development</strong>: Establishing why automated extraction could address the coordination crisis, grounded in epistemic theory and mechanism design</li>
<li><strong>Technical Implementation</strong>: Building working software that demonstrates feasibility, not as a proof-of-concept toy but as a system capable of handling real arguments</li>
<li><strong>Empirical Validation</strong>: Testing extraction quality against expert judgment, measuring not just accuracy but usefulness for downstream tasks</li>
<li><strong>Application Studies</strong>: Applying the system to real AI governance questions, evaluating whether formal models actually enhance decision-making</li>
</ol>
<p>This isn’t waterfall development where each phase completes before the next begins. Rather, insights from implementation fed back into theory, validation results shaped technical improvements, and application attempts revealed new requirements. The methodology itself embodied the iterative refinement it sought to enable.</p>
</section>
<section id="engineering-experience" class="level4">
<h4 class="anchored" data-anchor-id="engineering-experience">Engineering Experience</h4>
<p>The initial conception seemed straightforward enough. The MTAIR team had demonstrated that expert arguments about AI risk could be formalized into Bayesian networks. The process took hundreds of hours per model. Large language models had recently demonstrated remarkable capacity for understanding and generating structured text. The syllogism practically wrote itself: use LLMs to automate what MTAIR did manually. A few weeks of implementation, some validation, done.</p>
<p>That naive optimism lasted approximately until the first extraction attempt<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>. The LLM cheerfully produced what looked like a reasonable argument structure, except half the nodes were subtly wrong, several causal relationships pointed backward, and the probability estimates bore no discernible relationship to the source text. Worse, different runs produced different structures entirely. The gap between “looks plausible” and “actually correct” proved wider than anticipated.</p>
<p>What emerged from this initial failure was a recognition that the problem decomposed naturally into distinct challenges. Extracting structure—what relates to what—differed fundamentally from extracting probabilities. The former required understanding argumentative flow and causal language. The latter demanded interpreting uncertainty expressions and maintaining consistency across estimates. This insight led to the two-stage architecture that ultimately proved successful.</p>
<p>The development process resembled less a march toward a predetermined goal and more a conversation between ambition and reality. Each implementation attempt revealed new constraints. Each constraint suggested workarounds. Some workarounds opened unexpected possibilities. The final system bears only passing resemblance to the initial conception, yet it works—imperfectly, with clear limitations, but well enough to demonstrate feasibility.</p>
<!-- [-] COMPLETED: Added research design overview -->
</section>
</section>
<section id="sec-formalizing-world-models" class="level3">
<h3 class="anchored" data-anchor-id="sec-formalizing-world-models">2.7.2 Formalizing World Models from AI Safety Literature</h3>
<p>The core methodological challenge—transforming natural language arguments into formal probabilistic models—requires careful consideration of what we’re actually trying to capture.</p>
<p>A “world model” in this context isn’t just any formal representation but specifically a causal model embodying beliefs about how different factors influence AI risk. The extraction approach must therefore:</p>
<ul>
<li><strong>Identify key variables</strong>: Not just any entities mentioned, but causally relevant factors</li>
<li><strong>Extract causal relationships</strong>: Not mere correlation or co-occurrence, but directed influence</li>
<li><strong>Capture uncertainty</strong>: Both structural uncertainty (does A cause B?) and parametric uncertainty (how strongly?)</li>
<li><strong>Preserve context</strong>: Maintaining enough semantic information to interpret the formal model</li>
</ul>
<p>Large language models enable this through sophisticated pattern recognition and reasoning capabilities, but they’re tools, not magic wands. The methodology must account for their strengths (recognizing implicit structure) and weaknesses (potential hallucination, inconsistency).</p>
<!-- [-] COMPLETED: Added world model formalization -->
</section>
<section id="sec-natural-to-computational" class="level3">
<h3 class="anchored" data-anchor-id="sec-natural-to-computational">2.7.3 From Natural Language to Computational Models</h3>
<p>The journey from text to computation follows a carefully designed pipeline that mirrors human cognitive processes. Just as you wouldn’t ask someone to simultaneously parse grammar and solve equations, we separate structural understanding from quantitative reasoning.</p>
<p><strong>The Two-Stage Process</strong>:</p>
<p>Stage 1 focuses on structure—what causes what? The LLM reads an argument much as a human would, identifying key claims and their relationships. The prompt design here is crucial, providing enough guidance to ensure consistent extraction while allowing flexibility for different argument styles.</p>
<p>Stage 2 adds quantities—how likely is each outcome? With structure established, the system generates targeted questions about probabilities. This separation enables different approaches to quantification: extracting explicit estimates from text, inferring from qualitative language, or even connecting to external prediction markets.</p>
<p>The magic happens in the interplay. Structure constrains what probabilities are needed. Probability requirements might reveal missing structural elements. The process is a dialogue between qualitative and quantitative understanding.</p>
<!-- [-] COMPLETED: Added two-stage process explanation -->
</section>
<section id="sec-dag-structure" class="level3">
<h3 class="anchored" data-anchor-id="sec-dag-structure">2.7.4 Directed Acyclic Graphs: Structure and Semantics</h3>
<p>At the mathematical heart of Bayesian networks lie Directed Acyclic Graphs (DAGs)—structures that are simultaneously simple enough to analyze and rich enough to capture complex phenomena.</p>
<p>The “directed” part encodes causality or influence—edges have direction, flowing from cause to effect. The “acyclic” part ensures logical coherence—you can’t have A causing B causing C causing A, no matter how much certain political arguments might suggest otherwise.</p>
<p>Key properties for AI risk modeling:</p>
<p><strong>Acyclicity</strong>: More than a mathematical convenience, this enforces coherent temporal or causal ordering. In AI risk arguments, this prevents circular reasoning where consequences justify premises that predict those same consequences.</p>
<p><strong>D-separation</strong>: This graphical criterion determines conditional independence. If knowing about AI capabilities tells you nothing additional about risk given that you know deployment decisions, then capabilities and risk are d-separated given deployment.</p>
<p><strong>Markov Condition</strong>: Each variable depends only on its parents, not on its entire ancestry. This locality assumption makes inference tractable and forces modelers to make intervention points explicit.</p>
<p><strong>Path Analysis</strong>: Following paths through the graph reveals how influence propagates. Multiple paths between variables indicate redundancy—important for understanding intervention robustness.</p>
<p>The causal interpretation, following Pearl’s framework, transforms these mathematical objects into tools for counterfactual reasoning. When we ask “what if we prevented deployment of misaligned systems?” we’re performing surgery on the DAG, setting variables and propagating consequences.</p>
<!-- [-] COMPLETED: Added DAG structure explanation -->
</section>
<section id="sec-quantification" class="level3">
<h3 class="anchored" data-anchor-id="sec-quantification">2.7.5 Quantification of Probabilistic Judgments</h3>
<p>Here we encounter one of the most philosophically fraught aspects of the methodology: turning words into numbers. When an expert writes “highly likely,” what probability should we assign? When they say “significant risk,” what distribution captures their belief?</p>
<p>The methodology embraces rather than elides this challenge:</p>
<p><strong>Calibration Studies</strong>: Research on human probability expression shows systematic patterns. “Highly likely” typically maps to 0.8-0.9, “probable” to 0.6-0.8, though individual and cultural variation is substantial.</p>
<p><strong>Extraction Strategies</strong>: The system uses multiple approximations:</p>
<ul>
<li>Direct extraction: “We estimate 65% probability”</li>
<li>Linguistic mapping: “Very likely” → 0.85 (with uncertainty)</li>
<li>Comparative extraction: “More likely than X” where P(X) is known</li>
<li>Bounded extraction: “At least 30%” → [0.30, 1.0]</li>
</ul>
<p><strong>Uncertainty Representation</strong>: Rather than false precision, we maintain uncertainty about probabilities themselves. This might seem like uncertainty piled on uncertainty, but it’s honest, helps avoid systematic biases—and mathematically tractable through hierarchical models.</p>
<p>The goal isn’t perfect extraction but useful extraction. If we can narrow “significant risk” from [0, 1] to [0.15, 0.45], we’ve added information even if we haven’t achieved precision.</p>
<!-- [-] COMPLETED: Added probability quantification -->
</section>
<section id="sec-inference-techniques" class="level3">
<h3 class="anchored" data-anchor-id="sec-inference-techniques">2.7.6 Inference Techniques for Complex Networks</h3>
<p>Once we’ve built these formal models, we need to reason with them—and here computational complexity rears its exponential head. The number of probability calculations required for exact inference grows exponentially with network connectivity, quickly overwhelming even modern computers.</p>
<p>The methodology employs a portfolio of approaches:</p>
<p><strong>Exact Methods</strong>: For smaller networks (&lt;30 nodes), variable elimination and junction tree algorithms provide exact answers. These form the gold standard against which we validate approximate methods.</p>
<p><strong>Sampling Approaches</strong>: Monte Carlo methods trade exactness for scalability. By simulating many possible worlds consistent with our probability model, we approximate the true distributions. The law of large numbers is our friend here.</p>
<p><strong>Variational Methods</strong>: These turn inference into optimization—find the simplest distribution that approximates our true beliefs. Like finding the best polynomial approximation to a complex curve.</p>
<p><strong>Hybrid Strategies</strong>: Different parts of the network might use different methods. Exact inference for critical subgraphs, approximation for peripheral components.</p>
<p>The choice of method affects not just computation time but the types of questions we can meaningfully ask. This creates a methodological feedback loop where feasible inference shapes model design.</p>
<!-- [-] COMPLETED: Added inference techniques -->
</section>
<section id="sec-prediction-markets" class="level3">
<h3 class="anchored" data-anchor-id="sec-prediction-markets">2.7.7 Integration with Prediction Markets and Forecasting Platforms</h3>
<!-- [-] COMPLETED: Modified to clarify this is planned future work -->
<p>While full integration remains future work, the methodology anticipates connection to live forecasting data as a critical enhancement. The vision is compelling: formal models grounded in collective intelligence, updating as new information emerges.</p>
<p>The planned approach would involve:</p>
<p><strong>Semantic Matching</strong>: Model variables rarely align perfectly with forecast questions. “AI causes human extinction” might map to multiple specific forecasts about capabilities, deployment, and impacts. Developing robust matching algorithms is essential.</p>
<p><strong>Temporal Alignment</strong>: Markets predict specific dates (“AGI by 2030”) while models consider scenarios (“given AGI development”). Bridging these requires careful probability conditioning.</p>
<p><strong>Quality Weighting</strong>: Not all forecasts are created equal. Platform reputation, forecaster track records, and market depth all affect reliability. The methodology must account for this heterogeneity.</p>
<p><strong>Update Scheduling</strong>: Real-time updates would overwhelm users and computation. The system needs intelligent policies about when model updates provide value.</p>
<p>Platforms like Metaculus <span class="citation" data-cites="tetlock2022">P. Tetlock (<a href="../../ref/references.html#ref-tetlock2022" role="doc-biblioref">2022</a>)</span> already demonstrate sophisticated conditional forecasting on AI topics. The challenge lies not in data availability but in meaningful integration that enhances rather than complicates decision-making.</p>
<!-- [-] COMPLETED: Added prediction market integration methodology -->
<p>With these theoretical foundations and methodological commitments established, we can now turn to the concrete implementation of AMTAIR. The next chapter demonstrates how these abstract principles translate into working software that addresses real governance challenges. The journey from theory to practice always involves surprises—some pleasant, others less so—but that’s what makes it interesting.</p>
</section>
</section>
</section>
<section id="sec-amtair" class="level1">
<h1>3. AMTAIR: Design and Implementation</h1>
<!-- 
**Chapter Overview**  
**Grade Weight**: 20% | **Target Length**: ~29% of text (~8,700 words)  
**Requirements**: Critical evaluation, strong argument for position, original contribution -->
<p>The moment of truth in any research project comes when elegant theories meet stubborn reality. For AMTAIR, this meant transforming the vision of automated argument extraction into working code that could handle the beautiful messiness of real AI safety arguments. Let me take you through this journey from blueprint to implementation, complete with victories, defeats, and the occasional moment of “well, that’s unexpected.”</p>
<section id="sec-system-architecture" class="level2">
<h2 class="anchored" data-anchor-id="sec-system-architecture">3.1 System Architecture Overview</h2>
<!-- [-] TODO: Present the overall architecture of AMTAIR -->
<p>Picture, if you will, a factory for transforming arguments into models. Raw materials enter at one end—PDFs thick with jargon, blog posts mixing insight with speculation, research papers where crucial assumptions hide in footnote 47. Finished products emerge at the other end—clean network diagrams where you can trace how Assumption A leads to Catastrophe B with probability 0.3. Actually, scratch the factory metaphor. It’s too clean, too industrial. This is more like archaeology meets interpretation meets mathematics. You’re digging through layers of argument, trying to distinguish the load-bearing claims from rhetorical flourishes, all while preserving enough context that the formalization means something.</p>
<!-- [-] COMPLETED: Created component description -->
<p>The pipeline consists of five main stages:</p>
<ol type="1">
<li><strong>Text Ingestion and Preprocessing</strong>: Like a careful librarian, this stage catalogues incoming documents, normalizes their format, extracts metadata, and identifies the argumentative content worth processing.</li>
<li><strong>Argument Extraction</strong>: The intellectual heart of the system, where large language models perform their magic, transforming prose into structured representations.</li>
<li><strong>Data Transformation</strong>: The workshop where extracted arguments are refined, validated, and prepared for mathematical representation.</li>
<li><strong>Network Construction</strong>: The assembly line where formal Bayesian networks are instantiated, complete with conditional probability tables.</li>
<li><strong>Interactive Visualization</strong>: The showroom where complex models become accessible through thoughtful design and interactivity.</li>
</ol>
<section id="sec-five-stage-pipeline" class="level3">
<h3 class="anchored" data-anchor-id="sec-five-stage-pipeline">3.1.1 Five-Stage Pipeline Architecture</h3>
<p>Let’s examine each stage more closely, understanding not just what they do but why they exist as separate components.</p>
<p><strong>Text Ingestion and Preprocessing</strong> handles the unglamorous but essential work of standardization. Academic PDFs, with their two-column layouts and embedded figures, differ vastly from blog posts with inline code and hyperlinks. This stage creates a uniform representation while preserving essential structure and metadata. Format normalization strips away presentation while preserving content. Metadata extraction captures authorship, publication date, and citations. Relevance filtering identifies sections containing arguments rather than literature reviews or acknowledgments. Character encoding standardization prevents those maddening �replacement characters that plague text processing.</p>
<p><strong>Argument Extraction</strong> represents AMTAIR’s core innovation. Using a two-stage process that mirrors human reasoning, it first identifies structural relationships (what influences what) then quantifies those relationships (how likely, how strong). This separation enables targeted prompts optimized for each task, human verification between stages, and modular improvements as LLM capabilities evolve.</p>
<p><strong>Data Transformation</strong> bridges the gap between textual representations and mathematical models. It parses the BayesDown syntax into structured data, validates that the resulting network forms a proper DAG, checks probability consistency, and handles missing data intelligently.</p>
<p><strong>Network Construction</strong> instantiates the formal mathematical model. This involves creating nodes and edges according to extracted structure, populating conditional probability tables, initializing inference engines, and validating the complete model.</p>
<p><strong>Interactive Visualization</strong> makes the complex accessible. Through thoughtful visual encoding of probabilities and relationships, progressive disclosure of detail, interactive exploration capabilities, and multiple export formats, it serves diverse stakeholder needs.</p>
<!-- [-] COMPLETED: Added pipeline architecture details -->
</section>
<section id="sec-design-principles" class="level3">
<h3 class="anchored" data-anchor-id="sec-design-principles">3.1.2 Design Principles</h3>
<p><strong>Core Design Philosophy</strong>: The architecture embodies several principles that guided countless implementation decisions:</p>
<p><strong>Modularity</strong>: Each component has clear inputs, outputs, and responsibilities. This isn’t just good software engineering—it enables independent improvement of components and graceful degradation when parts fail.</p>
<p><strong>Validation Checkpoints</strong>: Between each stage, we validate outputs before proceeding. Bad extractions don’t propagate into visualization. Malformed networks trigger re-extraction rather than cryptic errors.</p>
<p><strong>Human-in-the-Loop</strong>: While pursuing automation, we recognize that human judgment remains invaluable. The architecture provides natural intervention points where experts can verify and correct.</p>
<p><strong>Extensibility</strong>: New document formats, improved extraction prompts, alternative visualization libraries—the architecture accommodates growth without restructuring.</p>
<p>The system emphasizes transparency over black-box efficiency. Users can inspect intermediate representations, understand extraction decisions, and verify transformations. This builds trust—essential for a system handling high-stakes arguments about existential risk.</p>
<!-- [-] COMPLETED: Added design principles -->
</section>
</section>
<section id="sec-two-stage-extraction" class="level2">
<h2 class="anchored" data-anchor-id="sec-two-stage-extraction">3.2 The Two-Stage Extraction Process</h2>
<!-- [-] TODO: Detail the process of extracting ArgDown representations -->
<p>The heart of AMTAIR beats with a two-stage rhythm: structure, then probability. This separation, which initially seemed like an implementation detail, revealed itself as fundamental to the extraction challenge.</p>
<section id="sec-stage1-argdown" class="level3">
<h3 class="anchored" data-anchor-id="sec-stage1-argdown">3.2.1 Stage 1: Structural Extraction (ArgDown)</h3>
<p>Imagine reading a complex argument about AI risk. Your first pass likely isn’t calculating exact probabilities—you’re mapping the landscape. What are the key claims? How do they relate? What supports what? Stage 1 mirrors this cognitive process.</p>
<p>The extraction begins with pattern recognition. Natural language contains linguistic markers of causal relationships: “leads to,” “results in,” “depends on,” “influences.” The LLM, trained on vast corpora of argumentative text, recognizes these patterns and their variations.</p>
<p>Consider extracting from a passage like: “The development of artificial general intelligence will likely lead to rapid capability gains through recursive self-improvement. This intelligence explosion could result in systems pursuing convergent instrumental goals, potentially including resource acquisition and self-preservation. Without solved alignment, such power-seeking behavior poses existential risks to humanity.”</p>
<p>The system identifies three key variables connected by causal relationships:</p>
<ul>
<li>AGI Development → Intelligence Explosion</li>
<li>Intelligence Explosion → Power-Seeking Behavior</li>
<li>Power-Seeking Behavior → Existential Risk</li>
</ul>
<p>But extraction goes beyond simple pattern matching. The system must handle complex linguistic phenomena like coreference (“this,” “such systems”), implicit relationships, conditional statements, and negative statements. The magic lies in prompt engineering that guides the LLM to consistent extraction while remaining flexible enough for diverse argument styles.</p>
<p>The output, formatted in ArgDown syntax, preserves both structure and semantics:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="ot">[Existential_Risk]: </span>Threat to humanity's continued existence and flourishing.</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="ss"> + </span><span class="co">[</span><span class="ot">Power_Seeking_Behavior</span><span class="co">]</span>: AI systems pursuing instrumental goals like resource acquisition.</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="ss">   + </span><span class="co">[</span><span class="ot">Intelligence_Explosion</span><span class="co">]</span>: Rapid recursive self-improvement leading to superintelligence.</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="ss">     + </span><span class="co">[</span><span class="ot">AGI_Development</span><span class="co">]</span>: Creation of artificial general intelligence systems.</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<!-- [-] COMPLETED: Added detailed Stage 1 explanation -->
</section>
<section id="sec-stage2-bayesdown" class="level3">
<h3 class="anchored" data-anchor-id="sec-stage2-bayesdown">3.2.2 Stage 2: Probability Integration (BayesDown)</h3>
<p>With structure established, Stage 2 adds the quantitative flesh to the qualitative bones. This stage faces a different challenge: extracting numerical beliefs from text that often expresses uncertainty in frustratingly vague terms.</p>
<p>The process begins by generating targeted questions based on the extracted structure. For each node, we need prior probabilities. For each child-parent relationship, we need conditional probabilities. The combinatorics can be daunting—a node with three binary parents requires 8 conditional probability values.</p>
<p>The system employs multiple strategies for probability extraction:</p>
<p><strong>Explicit Extraction</strong>: When authors provide numerical estimates (“we assign 70% probability”), extraction is straightforward, though we must handle various formats and contexts.</p>
<p><strong>Linguistic Mapping</strong>: While comprehensive validation remains future work, preliminary assessments using the methodology described above would likely reveal several patterns.</p>
<p><strong>Comparative Reasoning</strong>: Statements like “more probable than not” or “at least as likely as X” provide bounds even without exact values.</p>
<p><strong>Coherence Enforcement</strong>: Probabilities must sum correctly. If P(A|B) = 0.7, then P(not A|B) must equal 0.3. The syntax allows future system to detect and resolve inconsistencies.</p>
<p>The result is a complete BayesDown specification:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="ot">[</span><span class="er">Existential_Risk</span><span class="ot">]</span><span class="er">:</span> <span class="er">Threat</span> <span class="er">to</span> <span class="er">humanity's</span> <span class="er">continued</span> <span class="er">existence.</span> <span class="fu">{</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"instantiations"</span><span class="fu">:</span> <span class="ot">[</span><span class="st">"true"</span><span class="ot">,</span> <span class="st">"false"</span><span class="ot">]</span><span class="fu">,</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"priors"</span><span class="fu">:</span> <span class="fu">{</span><span class="dt">"p(true)"</span><span class="fu">:</span> <span class="st">"0.10"</span><span class="fu">,</span> <span class="dt">"p(false)"</span><span class="fu">:</span> <span class="st">"0.90"</span><span class="fu">},</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"posteriors"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"p(true|power_seeking_true)"</span><span class="fu">:</span> <span class="st">"0.65"</span><span class="fu">,</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"p(true|power_seeking_false)"</span><span class="fu">:</span> <span class="st">"0.001"</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">}</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<!-- [-] COMPLETED: Added detailed Stage 2 explanation -->
</section>
<section id="sec-why-two-stages" class="level3">
<h3 class="anchored" data-anchor-id="sec-why-two-stages">3.2.3 Why Two Stages?</h3>
<p>The separation of structure from probability isn’t merely convenient—it’s cognitively valid and practically essential. Let me count the ways this design decision pays dividends:</p>
<p><strong>Cognitive Alignment</strong>: Humans naturally separate “what relates to what” from “how likely is it.” The two-stage process mirrors this, making the system’s operation intuitive and interpretable.</p>
<p><strong>Error Isolation</strong>: Structural errors (missing a key variable) differ fundamentally from probability errors (estimating 0.7 instead of 0.8). Separating stages allows targeted debugging and improvement.</p>
<p><strong>Modular Validation</strong>: Experts can verify structure without needing to evaluate every probability. This enables efficient human oversight at natural checkpoints.</p>
<p><strong>Flexible Quantification</strong>: Different probability sources (text extraction, expert elicitation, market data) can feed into the same structure. The architecture accommodates multiple approaches to the probability challenge.</p>
<p><strong>Transparency</strong>: Users can inspect ArgDown to understand what was extracted before probabilities were added. This builds trust and enables meaningful correction.</p>
<p>The two-stage approach also revealed an unexpected benefit: ArgDown itself became a valuable output. Researchers began using these structural extractions for qualitative analysis, even without probability quantification. Sometimes, just making argument structure explicit provides sufficient value.</p>
<!-- [-] COMPLETED: Added why two stages explanation -->
</section>
</section>
<section id="sec-implementation-tech" class="level2">
<h2 class="anchored" data-anchor-id="sec-implementation-tech">3.3 Implementation Technologies</h2>
<!-- [-] TODO: Detail the technology stack and key algorithms -->
<p>Choosing technologies for AMTAIR resembled assembling a band—each instrument needed to excel individually while harmonizing with the ensemble. The selection criteria balanced capability, maturity, interoperability, and community support.</p>
<section id="sec-tech-stack" class="level3">
<h3 class="anchored" data-anchor-id="sec-tech-stack">3.3.1 Technology Stack</h3>
<p>Selecting technologies for a project like AMTAIR involves a peculiar form of fortune-telling. You’re choosing tools not just for present needs but for future possibilities you can’t fully anticipate. Early decisions cascade through the implementation, creating path dependencies that only become apparent months later.</p>
<p>The choice of Python as the primary language was perhaps the only decision that never faced serious questioning. The ecosystem for scientific computing, the availability of sophisticated libraries, the community support—all pointed in the same direction. Yet even this “obvious” choice carried hidden implications. Python’s flexibility enabled rapid prototyping but occasionally masked performance issues until they became critical.</p>
<!-- Language model selection proved more contentious. GPT-4 offered superior reasoning capabilities but came with usage restrictions and costs that complicated large-scale extraction. Claude demonstrated stronger performance on structured tasks but wasn't available when development began. The solution—supporting multiple providers through a common interface—seemed elegant in theory but introduced its own complexities. Each model had quirks in how it interpreted prompts, requiring provider-specific adjustments that somewhat undermined the abstraction. -->
<p>NetworkX emerged as the natural choice for graph manipulation after brief flirtations with alternatives. Its maturity showed in countless small conveniences—algorithms I didn’t have to implement, edge cases already handled, documentation for obscure functions. Pgmpy for Bayesian network operations was less obvious. Several libraries offered similar functionality, but pgmpy’s API design aligned well with our extraction pipeline. The ability to construct networks incrementally, validate structure during construction, and perform inference without elaborate setup proved decisive.</p>
<p>The visualization challenge nearly derailed the project. Initial attempts with matplotlib produced static images that technically displayed the network but failed to convey understanding. The breakthrough came with PyVis, which leveraged vis.js to create interactive web-based visualizations. Suddenly, complex networks became explorable. Users could drag nodes to untangle connections, click for details, adjust physics parameters to find optimal layouts. The difference between seeing and understanding turned out to be interactivity.</p>
<p>The final ensemble performs beautifully:</p>
<div id="tbl-tech-stack" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-tech-stack-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;5.1: Table 3.3.1: Overview of Tech Stack
</figcaption>
<div aria-describedby="tbl-tech-stack-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Component</th>
<th>Technology</th>
<th>Purpose</th>
<th>Why This Choice</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Language Models</td>
<td>GPT-4, Claude</td>
<td>Argument extraction</td>
<td>State-of-the-art reasoning capabilities</td>
</tr>
<tr class="even">
<td>Network Analysis</td>
<td>NetworkX</td>
<td>Graph algorithms</td>
<td>Mature, comprehensive, well-documented</td>
</tr>
<tr class="odd">
<td>Probabilistic Modeling</td>
<td>pgmpy</td>
<td>Bayesian operations</td>
<td>Native Python, active development</td>
</tr>
<tr class="even">
<td>Visualization</td>
<td>PyVis</td>
<td>Interactive rendering</td>
<td>Web-based, customizable, responsive</td>
</tr>
<tr class="odd">
<td>Data Processing</td>
<td>Pandas</td>
<td>Structured manipulation</td>
<td>Industry standard, powerful operations</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p><strong>Language Models</strong> form the cognitive core. GPT-4 and Claude demonstrate remarkable ability to understand complex arguments, recognize implicit structure, and maintain coherence across long extractions. The choice to support multiple models provides robustness and allows leveraging their complementary strengths.</p>
<p><strong>NetworkX</strong> handles all graph-theoretic heavy lifting. From basic operations like cycle detection to advanced algorithms like centrality measurement, it provides a comprehensive toolkit that would take years to replicate.</p>
<p><strong>pgmpy</strong> bridges the gap between graph structure and probabilistic reasoning. Its clean API design maps naturally onto our extracted representations, while its inference algorithms handle the computational complexity of Bayesian reasoning.</p>
<p><strong>PyVis</strong> transforms static networks into living documents. Built on vis.js, it provides smooth physics simulations, rich interactivity, and extensive customization options—all accessible through Python.</p>
<p><strong>Pandas</strong> might seem mundane compared to its companions, but it’s the reliable rhythm section that keeps everything together. Its ability to reshape, merge, and transform structured data makes the complex data transformations tractable.</p>
<!-- [-] COMPLETED: Added technology stack details -->
</section>
<section id="sec-key-algorithms" class="level3">
<h3 class="anchored" data-anchor-id="sec-key-algorithms">3.3.2 Key Algorithms</h3>
<p>Beyond the libraries lie custom algorithms that address AMTAIR-specific challenges:</p>
<p><strong>Hierarchical Parsing</strong>: The algorithm that transforms indented ArgDown text into structured data represents a small miracle of recursive descent parsing adapted for our custom syntax. It maintains parent-child relationships while handling edge cases like repeated nodes and complex dependencies.</p>
<p>python</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: example_use_case</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "example use case"</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-link: "https://colab.research.google.com/github/VJMeyer/submission/blob/main/AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb#scrollTo=ibjjJ34v3sQn&amp;line=4&amp;uniqifier=1"</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "example use case"</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parsing_argdown_bayesdown(text, current_indent<span class="op">=</span><span class="dv">0</span>):</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Recursively parse indented structure maintaining relationships"""</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Track nodes at each level for parent identification</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handle repeated nodes by reference</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Validate DAG property during construction</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<!-- {{< embed /AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb#parsing_argdown_bayesdown echo=true >}} -->
<!-- 
#| label: example_use_case
#| echo: true
#| eval: true
#| fig-cap: "example use case"
#| fig-link: "https://colab.research.google.com/github/VJMeyer/submission/blob/main/AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb#scrollTo=ibjjJ34v3sQn&line=4&uniqifier=1"
#| fig-alt: "example use case"
-->
<p><strong>Probability Completion</strong>: Real arguments rarely specify all required probabilities. Our completion algorithm uses maximum entropy principles—when uncertain, assume maximum disorder. This provides conservative estimates that can be refined with additional information.</p>
<p><strong>Visual Encoding</strong>: The algorithm mapping probabilities to colors uses perceptual uniformity. The green-to-red gradient isn’t linear in RGB space but follows human perception of color difference. Small details, big impact on usability.</p>
<p><strong>Layout Optimization</strong>: Force-directed layouts often produce “hairballs” for complex networks. Our customized approach uses hierarchical initialization based on causal depth, then refines with physics simulation. The result: layouts that reveal structure rather than obscuring it.</p>
<!-- [-] COMPLETED: Added key algorithms -->
</section>
<section id="sec-performance" class="level3">
<h3 class="anchored" data-anchor-id="sec-performance">3.3.3 (Expected) Performance Characteristics</h3>
<!-- [-] COMPLETED: Replaced hallucinated metrics with theoretical analysis -->
<p>Performance in a system like AMTAIR involves multiple dimensions—speed, accuracy, scalability. Let’s examine what theoretical analysis and design considerations suggest about system behavior.</p>
<p><strong>Computational Complexity</strong>: The extraction phase exhibits linear complexity in document length—processing twice as much text takes roughly twice as long. However, the inference phase faces exponential complexity in network connectivity. A fully connected network with n binary nodes requires O(2^n) operations for exact inference. This fundamental limitation shapes practical usage patterns.</p>
<p><strong>Practical Implications</strong>: Small networks (&lt;20 nodes) enable real-time interaction with exact inference. Medium networks (20-50 nodes) require seconds to minutes depending on connectivity. Large networks (&gt;50 nodes) necessitate approximate methods, trading accuracy for tractability. Very large networks push the boundaries of current methods.</p>
<p>The bottleneck shifts predictably: extraction remains manageable even for lengthy documents, but inference becomes challenging as models grow. This suggests a natural workflow—extract comprehensively, then focus on relevant subnetworks for detailed analysis.</p>
<p><strong>Optimization Opportunities</strong>: Several strategies could improve performance: caching frequent inference queries, hierarchical decomposition of large networks, parallel processing for independent subgraphs, and progressive rendering for visualization. The modular architecture accommodates these enhancements without fundamental restructuring.</p>
<!-- [-] COMPLETED: Added performance analysis -->
</section>
<section id="sec-deterministic-probabilistic" class="level3">
<h3 class="anchored" data-anchor-id="sec-deterministic-probabilistic">3.3.4 Deterministic vs.&nbsp;Probabilistic Components of the Workflow</h3>
<p>An interesting philosophical question arises: in a system reasoning about probability, which components should themselves be probabilistic?</p>
<p>The current implementation draws a clear line:</p>
<p><strong>Deterministic Components</strong>: All data transformations, graph algorithms, and inference calculations operate deterministically. Given the same input, they produce identical output. This provides reproducibility and debuggability—essential for building trust.</p>
<p><strong>Probabilistic Components</strong>: The LLM calls for extraction introduce variability. Even with temperature set to 0, language models exhibit some randomness. Different runs might extract slightly different structures or probability estimates from the same text.</p>
<p>This division reflects a deeper principle: use determinism wherever possible, embrace probability where necessary. The extraction task—interpreting natural language—inherently involves uncertainty. But once we have formal representations, all subsequent operations should be predictable.</p>
<p>From an information-theoretic perspective, we’re trying to extract maximum information from documents within computational budget constraints. Each document contains some finite amount of formalizable argument structure. Our goal is recovering as much as possible given realistic resource limits.</p>
<p>The two-stage extraction can be viewed as successive refinement—first recovering the higher-order bits (structure), then filling in lower-order bits (probabilities). This aligns with rate-distortion theory, where we get the most important information first.</p>
<!-- [-] COMPLETED: Added deterministic vs probabilistic analysis -->
</section>
</section>
<section id="sec-case-rain-sprinkler" class="level2">
<h2 class="anchored" data-anchor-id="sec-case-rain-sprinkler">3.4 Case Study: Rain-Sprinkler-Grass</h2>
<!-- [-] TODO: Demonstrate the pipeline using the canonical example -->
<p>Every field has its canonical examples—physics has spherical cows, economics has widget factories, and Bayesian networks have the rain-sprinkler-grass scenario. Despite its simplicity, this example teaches profound lessons about causal reasoning and serves as the perfect test case for AMTAIR.</p>
<section id="sec-rsg-processing" class="level3">
<h3 class="anchored" data-anchor-id="sec-rsg-processing">3.4.1 Processing Steps</h3>
<p>Let me walk you through how AMTAIR processes this foundational example:</p>
<p>The input arrives as a simple text description: “When it rains, the grass gets wet. The sprinkler also makes the grass wet. However, when it rains, we usually don’t run the sprinkler.”</p>
<p>From this prosaic description, the system performs five transformations:</p>
<ol type="1">
<li><strong>ArgDown Parsing</strong>: Extract three variables (Rain, Sprinkler, Grass_Wet) and identify that rain influences both sprinkler usage and grass wetness, while the sprinkler also influences grass wetness.</li>
<li><strong>Question Generation</strong>: Create probability queries: What’s P(Rain)? What’s P(Sprinkler|Rain)? What’s P(Grass_Wet|Rain,Sprinkler) for all combinations?</li>
<li><strong>BayesDown Extraction</strong>: Either extract probabilities from text or apply reasonable defaults. The “usually don’t run” becomes P(Sprinkler|Rain) ≈ 0.01.</li>
<li><strong>Network Construction</strong>: Build the formal Bayesian network with three nodes, three edges, and complete conditional probability tables.</li>
<li><strong>Visualization Rendering</strong>: Create an interactive display where rain appears as a root cause, influencing both sprinkler and grass directly.</li>
</ol>
<p>Each step validates its outputs before proceeding, ensuring that errors don’t cascade through the pipeline.</p>
<!-- [-] COMPLETED: Added processing steps -->
</section>
<div class="landscape">
<section id="sec-rsg-input" class="level3">
<h3 class="anchored" data-anchor-id="sec-rsg-input">3.4.2 Example Conversion Steps</h3>
<p>Let’s trace the actual transformations to see the pipeline in action:</p>
<p><strong>Initial ArgDown Extraction</strong>:</p>
<!-- 
```markdown
[Grass_Wet]: Concentrated moisture on grass blades. {"instantiations": ["wet", "dry"]}    
 + [Rain]: Precipitation from the sky. {"instantiations": ["raining", "not_raining"]}
 + [Sprinkler]: Artificial watering system. {"instantiations": ["on", "off"]}
   + [Rain]
``` -->
<div class="sourceCode" id="cb11"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="ot">[Grass_Wet]: </span>Concentrated moisture on, between and around the blades of grass.{"instantiations": <span class="co">[</span><span class="ot">"grass_wet_TRUE", "grass_wet_FALSE"</span><span class="co">]</span>}    </span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span><span class="co">[</span><span class="ot">Rain</span><span class="co">]</span>: Tears of angles crying high up in the skies hitting the ground.{"instantiations": <span class="co">[</span><span class="ot">"rain_TRUE", "rain_FALSE"</span><span class="co">]</span>}</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span><span class="co">[</span><span class="ot">Sprinkler</span><span class="co">]</span>: Activation of a centrifugal force based CO2 droplet distribution system.{"instantiations": <span class="co">[</span><span class="ot">"sprinkler_TRUE", "sprinkler_FALSE"</span><span class="co">]</span>}</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="ss">      + </span><span class="co">[</span><span class="ot">Rain</span><span class="co">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The hierarchy captures that rain influences sprinkler usage—a subtle but important causal relationship that pure correlation would miss.</p>
<p><strong>Generated Questions for Probability Extraction</strong>:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="er">BayesDown</span> <span class="er">Format</span> <span class="er">Preview:</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="er">#</span> <span class="er">BayesDown</span> <span class="er">Representation</span> <span class="er">with</span> <span class="er">Placeholder</span> <span class="er">Probabilities</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="er">/*</span> <span class="er">This</span> <span class="er">file</span> <span class="er">contains</span> <span class="er">BayesDown</span> <span class="er">syntax</span> <span class="er">with</span> <span class="er">placeholder</span> <span class="er">probabilities.</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>   <span class="er">Replace</span> <span class="er">the</span> <span class="er">placeholders</span> <span class="er">with</span> <span class="er">actual</span> <span class="er">probability</span> <span class="er">values</span> <span class="er">based</span> <span class="er">on</span> <span class="er">the</span> </span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>   <span class="er">questions</span> <span class="er">in</span> <span class="er">the</span> <span class="er">comments.</span> <span class="er">*/</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    <span class="er">/*</span> <span class="er">What</span> <span class="er">is</span> <span class="er">the</span> <span class="er">probability</span> <span class="er">for</span> <span class="er">Grass_Wet=grass_wet_TRUE?</span> <span class="er">*/</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    <span class="er">/*</span> <span class="er">What</span> <span class="er">is</span> <span class="er">the</span> <span class="er">probability</span> <span class="er">for</span> <span class="er">Grass_Wet=grass_wet_TRUE</span> <span class="er">if</span> <span class="er">Rain=rain_TRUE,</span> <span class="er">Sprinkler=sprinkler_TRUE?</span> <span class="er">*/</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    <span class="er">/*</span> <span class="er">What</span> <span class="er">is</span> <span class="er">the</span> <span class="er">probability</span> <span class="er">for</span> <span class="er">Grass_Wet=grass_wet_TRUE</span> <span class="er">if</span> <span class="er">Rain=rain_TRUE,</span> <span class="er">Sprinkler=sprinkler_FALSE?</span> <span class="er">*/</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    <span class="er">/*</span> <span class="er">What</span> <span class="er">is</span> <span class="er">the</span> <span class="er">probability</span> <span class="er">for</span> <span class="er">Grass_Wet=grass_wet_TRUE</span> <span class="er">if</span> <span class="er">Rain=rain_FALSE,</span> <span class="er">Sprinkler=sprinkler_TRUE?</span> <span class="er">*/</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    <span class="er">/*</span> <span class="er">What</span> <span class="er">is</span> <span class="er">the</span> <span class="er">probability</span> <span class="er">for</span> <span class="er">Grass_Wet=grass_wet_TRUE</span> <span class="er">if</span> <span class="er">Rain=rain_FALSE,</span> <span class="er">Sprinkler=sprinkler_FALSE?</span> <span class="er">*/</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    <span class="er">/*</span> <span class="er">What</span> <span class="er">is</span> <span class="er">the</span> <span class="er">probability</span> <span class="er">for</span> <span class="er">Grass_Wet=grass_wet_FALSE?</span> <span class="er">*/</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    <span class="er">/*</span> <span class="er">What</span> <span class="er">is</span> <span class="er">the</span> <span class="er">probability</span> <span class="er">for</span> <span class="er">Grass_Wet=grass_wet_FALSE</span> <span class="er">if</span> <span class="er">Rain=rain_TRUE,</span> <span class="er">Sprinkler=sprinkler_TRUE?</span> <span class="er">*/</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    <span class="er">/*</span> <span class="er">What</span> <span class="er">is</span> <span class="er">the</span> <span class="er">probability</span> <span class="er">for</span> <span class="er">Grass_Wet=grass_wet_FALSE</span> <span class="er">if</span> <span class="er">Rain=rain_TRUE,</span> <span class="er">Sprinkler=sprinkler_FALSE?</span> <span class="er">*/</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    <span class="er">/*</span> <span class="er">What</span> <span class="er">is</span> <span class="er">the</span> <span class="er">probability</span> <span class="er">for</span> <span class="er">Grass_Wet=grass_wet_FALSE</span> <span class="er">if</span> <span class="er">Rain=rain_FALSE,</span> <span class="er">Sprinkler=sprinkler_TRUE?</span> <span class="er">*/</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    <span class="er">/*</span> <span class="er">What</span> <span class="er">is</span> <span class="er">the</span> <span class="er">probability</span> <span class="er">for</span> <span class="er">Grass_Wet=grass_wet_FALSE</span> <span class="er">if</span> <span class="er">Rain=rain_FALSE,</span> <span class="er">Sprinkler=sprinkler_FALSE?</span> <span class="er">*/</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    <span class="ot">[</span><span class="er">Grass_Wet</span><span class="ot">]</span><span class="er">:</span> <span class="er">Concentrated</span> <span class="er">moisture</span> <span class="er">on,</span> <span class="er">between</span> <span class="er">and</span> <span class="er">around</span> <span class="er">the</span> <span class="er">blades</span> <span class="er">of</span> <span class="er">grass.</span> <span class="fu">{</span><span class="dt">"instantiations"</span><span class="fu">:</span> <span class="ot">[</span><span class="st">"grass_wet_TRUE"</span><span class="ot">,</span> <span class="st">"grass_wet_FALSE"</span><span class="ot">]</span><span class="fu">,</span> <span class="dt">"priors"</span><span class="fu">:</span> <span class="fu">{</span><span class="dt">"What is the probability for Grass_Wet=grass_wet_TRUE?"</span><span class="fu">:</span> <span class="st">"%?"</span><span class="fu">,</span> <span class="dt">"What is the probability for Grass_Wet=grass_wet_FALSE?"</span><span class="fu">:</span> <span class="st">"%?"</span><span class="fu">},</span> <span class="dt">"posteriors"</span><span class="fu">:</span> <span class="fu">{</span><span class="dt">"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_TRUE, Sprinkler=sprinkler_TRUE?"</span><span class="fu">:</span> <span class="st">"?%"</span><span class="fu">,</span> <span class="dt">"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_TRUE, Sprinkler=sprinkler_FALSE?"</span><span class="fu">:</span> <span class="st">"?%"</span><span class="fu">,</span> <span class="dt">"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_FALSE, Sprinkler=sprinkler_TRUE?"</span><span class="fu">:</span> <span class="st">"?%"</span><span class="fu">,</span> <span class="dt">"What is the probability for Grass_Wet=grass_wet_TRUE if Rain=rain_FALSE, Sprinkler=sprinkler_FALSE?"</span><span class="fu">:</span> <span class="st">"?%"</span><span class="fu">,</span> <span class="dt">"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_TRUE, Sprinkler=sprinkler_TRUE?"</span><span class="fu">:</span> <span class="st">"?%"</span><span class="fu">,</span> <span class="dt">"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_TRUE, Sprinkler=sprinkler_FALSE?"</span><span class="fu">:</span> <span class="st">"?%"</span><span class="fu">,</span> <span class="dt">"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_FALSE, Sprinkler=sprinkler_TRUE?"</span><span class="fu">:</span> <span class="st">"?%"</span><span class="fu">,</span> <span class="dt">"What is the probability for Grass_Wet=grass_wet_FALSE if Rain=rain_FALSE, Sprinkler=sprinkler_FALSE?"</span><span class="fu">:</span> <span class="st">"?%"</span><span class="fu">}}</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>        <span class="er">/*</span> <span class="er">What</span> <span class="er">is</span> <span class="er">the</span> <span class="er">probability</span> <span class="er">for</span> <span class="er">Rain=rain_TRUE?</span> <span class="er">*/</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>        <span class="er">/*</span> <span class="er">What</span> <span class="er">is</span> <span class="er">the</span> <span class="er">probability</span> <span class="er">for</span> <span class="er">Rain=rain_FALSE?</span> <span class="er">*/</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>        <span class="er">+</span> <span class="ot">[</span><span class="er">Rain</span><span class="ot">]</span><span class="er">:</span> <span class="er">Tears</span> <span class="er">of</span> <span class="er">angles</span> <span class="er">crying</span> <span class="er">high</span> <span class="er">up</span> <span class="er">in</span> <span class="er">the</span> <span class="er">skies</span> <span class="er">hitting</span> <span class="er">the</span> <span class="er">ground.</span> <span class="fu">{</span><span class="dt">"instantiations"</span><span class="fu">:</span> <span class="ot">[</span><span class="st">"rain_TRUE"</span><span class="ot">,</span> <span class="st">"rain_FALSE"</span><span class="ot">]</span><span class="fu">,</span> <span class="dt">"priors"</span><span class="fu">:</span> <span class="fu">{</span><span class="dt">"What is the probability for Rain=rain_TRUE?"</span><span class="fu">:</span> <span class="st">"%?"</span><span class="fu">,</span> <span class="dt">"What is the probability for Rain=rain_FALSE?"</span><span class="fu">:</span> <span class="st">"%?"</span><span class="fu">}}</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>        <span class="er">/*</span> <span class="er">What</span> <span class="er">is</span> <span class="er">the</span> <span class="er">probability</span> <span class="er">for</span> <span class="er">Sprinkler=sprinkler_TRUE?</span> <span class="er">*/</span></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>        <span class="er">/*</span> <span class="er">What</span> <span class="er">is</span> <span class="er">the</span> <span class="er">probability</span> <span class="er">for</span> <span class="er">Sprinkler=sprinkler_TRUE</span> <span class="er">if</span> <span class="er">Rain=rain_TRUE?</span> <span class="er">*/</span></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>        <span class="er">/*</span> <span class="er">What</span> <span class="er">is</span> <span class="er">the</span> <span class="er">probability</span> <span class="er">for</span> <span class="er">Sprinkler=sprinkler_TRUE</span> <span class="er">if</span> <span class="er">Rain=rain_FALSE?</span> <span class="er">*/</span></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>        <span class="er">/*</span> <span class="er">What</span> <span class="er">is</span> <span class="er">the</span> <span class="er">probability</span> <span class="er">for</span> <span class="er">Sprinkler=sprinkler_FALSE?</span> <span class="er">*/</span></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>        <span class="er">/*</span> <span class="er">What</span> <span class="er">is</span> <span class="er">the</span> <span class="er">probability</span> <span class="er">for</span> <span class="er">Sprinkler=sprinkler_FALSE</span> <span class="er">if</span> <span class="er">Rain=rain_TRUE?</span> <span class="er">*/</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>        <span class="er">/*</span> <span class="er">What</span> <span class="er">is</span> <span class="er">the</span> <span class="er">probability</span> <span class="er">for</span> <span class="er">Sprinkler=sprinkler_FALSE</span> <span class="er">if</span> <span class="er">Rain=rain_FALSE?</span> <span class="er">*/</span></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>        <span class="er">+</span> <span class="ot">[</span><span class="er">Sprinkler</span><span class="ot">]</span><span class="er">:</span> <span class="er">Activation</span> <span class="er">of</span> <span class="er">a</span> <span class="er">centrifugal</span> <span class="er">force</span> <span class="er">based</span> <span class="er">CO2</span> <span class="er">droplet</span> <span class="er">distribution</span> <span class="er">system.</span> <span class="fu">{</span><span class="dt">"instantiations"</span><span class="fu">:</span> <span class="ot">[</span><span class="st">"sprinkler_TRUE"</span><span class="ot">,</span> <span class="st">"sprinkler_FALSE"</span><span class="ot">]</span><span class="fu">,</span> <span class="dt">"priors"</span><span class="fu">:</span> <span class="fu">{</span><span class="dt">"What is the probability for Sprinkler=sprinkler_TRUE?"</span><span class="fu">:</span> <span class="st">"%?"</span><span class="fu">,</span> <span class="dt">"What is the probability for Sprinkler=sprinkler_FALSE?"</span><span class="fu">:</span> <span class="st">"%?"</span><span class="fu">},</span> <span class="dt">"posteriors"</span><span class="fu">:</span> <span class="fu">{</span><span class="dt">"What is the probability for Sprinkler=sprinkler_TRUE if Rain=rain_TRUE?"</span><span class="fu">:</span> <span class="st">"?%"</span><span class="fu">,</span> <span class="dt">"What is the probability for Sprinkler=sprinkler_TRUE if Rain=rain_FALSE?"</span><span class="fu">:</span> <span class="st">"?%"</span><span class="fu">,</span> <span class="dt">"What is the probability for Sprinkler=sprinkler_FALSE if Rain=rain_TRUE?"</span><span class="fu">:</span> <span class="st">"?%"</span><span class="fu">,</span> <span class="dt">"What is the probability for Sprinkler=sprinkler_FALSE if Rain=rain_FALSE?"</span><span class="fu">:</span> <span class="st">"?%"</span><span class="fu">}}</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>            <span class="er">/*</span> <span class="er">What</span> <span class="er">is</span> <span class="er">the</span> <span class="er">probability</span> <span class="er">for</span> <span class="er">Rain=rain_TRUE?</span> <span class="er">*/</span></span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>            <span class="er">/*</span> <span class="er">What</span> <span class="er">is</span> <span class="er">the</span> <span class="er">probability</span> <span class="er">for</span> <span class="er">Rain=rain_FALSE?</span> <span class="er">*/</span></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>            <span class="er">+</span> <span class="ot">[</span><span class="er">Rain</span><span class="ot">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<!-- 
```markdown
/* Prior probabilities */
- What is the probability that it rains?
- What is the probability the sprinkler is on?

/* Conditional probabilities */  
- What is the probability the sprinkler is on when it's raining?
- What is the probability the sprinkler is on when it's not raining?
- What is the probability the grass is wet when it's raining and sprinkler is on?
- [... and so on for all combinations]
```
-->
<p>The system generates exactly the questions needed to fully specify the network.</p>
<p><strong>Complete BayesDown Result</strong>:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="ot">[Grass_Wet]: </span>Concentrated moisture on, between and around the blades of grass.{"instantiations": <span class="co">[</span><span class="ot">"grass_wet_TRUE", "grass_wet_FALSE"</span><span class="co">]</span>}    </span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    +<span class="co">[</span><span class="ot">Rain</span><span class="co">]</span>: Tears of angles crying high up in the skies hitting the ground.{"instantiations": <span class="co">[</span><span class="ot">"rain_TRUE", "rain_FALSE"</span><span class="co">]</span>}</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    +<span class="co">[</span><span class="ot">Sprinkler</span><span class="co">]</span>: Activation of a centrifugal force based CO2 droplet distribution system.{"instantiations": <span class="co">[</span><span class="ot">"sprinkler_TRUE", "sprinkler_FALSE"</span><span class="co">]</span>}</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>        +<span class="co">[</span><span class="ot">Rain</span><span class="co">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<!-- 
```json
[Grass_Wet]: Concentrated moisture on grass. {
  "instantiations": ["wet", "dry"],
  "priors": {"p(wet)": "0.45", "p(dry)": "0.55"},
  "posteriors": {
    "p(wet|raining,on)": "0.99",
    "p(wet|raining,off)": "0.80", 
    "p(wet|not_raining,on)": "0.90",
    "p(wet|not_raining,off)": "0.01"
  }
}
``` -->
<p>Notice how the probabilities tell a coherent story—grass is almost certainly wet if either water source is active, almost certainly dry if neither is.</p>
<p><strong>Resulting DataFrame Structure</strong>:</p>
<p>The transformation into tabular format enables standard data analysis tools while preserving all relationships and probabilities. Each row represents a node with its properties, parents, children, and probability distributions.</p>
<!-- [-] COMPLETED: Added conversion examples -->
</section>
<section id="sec-rsg-results" class="level3">
<h3 class="anchored" data-anchor-id="sec-rsg-results">3.4.3 Results</h3>
<div id="tbl-rsg-extracted-data" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-rsg-extracted-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;5.2: Table 3.5.3: Extracted BayesDown data structure for rain-sprinkler-grass example
</figcaption>
<div aria-describedby="tbl-rsg-extracted-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 4%">
<col style="width: 7%">
<col style="width: 3%">
<col style="width: 8%">
<col style="width: 7%">
<col style="width: 11%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 9%">
<col style="width: 4%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 7%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Description</th>
<th>line</th>
<th>line_numbers</th>
<th>indentation</th>
<th>indentation_levels</th>
<th>Parents</th>
<th>Children</th>
<th>instantiations</th>
<th>priors</th>
<th>posteriors</th>
<th>No_Parent</th>
<th>No_Children</th>
<th>parent_instantiations</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Grass_Wet</td>
<td>Concentrated moisture on, between and around the blades of grass</td>
<td>3</td>
<td>[3]</td>
<td>0</td>
<td>[0]</td>
<td>[Rain, Sprinkler]</td>
<td>[]</td>
<td>[grass_wet_TRUE, grass_wet_FALSE]</td>
<td>{‘p(grass_wet_TRUE)’: ‘0.322’, ‘p(grass_wet_FALSE)’: ‘0.678’}</td>
<td>{‘p(grass_wet_TRUE|sprinkler_TRUE,rain_TRUE)’: ‘0.99’, ‘p(grass_wet_TRUE|sprinkler_TRUE,rain_FALSE)’: ‘0.9’, ‘p(grass_wet_TRUE|sprinkler_FALSE,rain_TRUE)’: ‘0.8’, ‘p(grass_wet_TRUE|sprinkler_FALSE,rain_FALSE)’: ‘0.01’}</td>
<td>False</td>
<td>True</td>
<td>[[rain_TRUE, rain_FALSE], [sprinkler_TRUE, sprinkler_FALSE]]</td>
</tr>
<tr class="even">
<td>Rain</td>
<td>Tears of angles crying high up in the skies hitting the ground</td>
<td>4</td>
<td>[4, 6]</td>
<td>2</td>
<td>[1, 2]</td>
<td>[]</td>
<td>[Grass_Wet, Sprinkler]</td>
<td>[rain_TRUE, rain_FALSE]</td>
<td>{‘p(rain_TRUE)’: ‘0.2’, ‘p(rain_FALSE)’: ‘0.8’}</td>
<td>{}</td>
<td>True</td>
<td>False</td>
<td>[]</td>
</tr>
<tr class="odd">
<td>Sprinkler</td>
<td>Activation of a centrifugal force based CO2 droplet distribution system</td>
<td>5</td>
<td>[5]</td>
<td>1</td>
<td>[1]</td>
<td>[Rain]</td>
<td>[Grass_Wet]</td>
<td>[sprinkler_TRUE, sprinkler_FALSE]</td>
<td>{‘p(sprinkler_TRUE)’: ‘0.44838’, ‘p(sprinkler_FALSE)’: ‘0.55162’}</td>
<td>{‘p(sprinkler_TRUE|rain_TRUE)’: ‘0.01’, ‘p(sprinkler_TRUE|rain_FALSE)’: ‘0.4’}</td>
<td>False</td>
<td>False</td>
<td>[[rain_TRUE, rain_FALSE]]</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>The successfully processed rain-sprinkler-grass example demonstrates several key capabilities:</p>
<p><strong>Structure Preservation</strong>: The causal relationships—including the subtle influence of rain on sprinkler usage—are correctly captured and maintained throughout processing.</p>
<p><strong>Probability Coherence</strong>: All probability distributions sum to 1.0, conditional probabilities are complete, and the values tell a plausible story.</p>
<p><strong>Visual Clarity</strong>: The rendered network clearly shows rain as the root cause, influencing both sprinkler and grass, while sprinkler provides an additional pathway to wet grass.</p>
<p><strong>Interactive Exploration</strong>: Users can click nodes to see detailed probabilities, drag to rearrange for clarity, and explore how changing parameters affects outcomes.</p>
<p><strong>Inference Capability</strong>: The system correctly calculates derived probabilities like P(Rain|Grass_Wet)—the diagnostic reasoning from effect to cause that makes Bayesian networks so powerful.</p>
<p>This simple example validates the basic pipeline functionality. But the real test comes with complex, real-world arguments …</p>
<!-- [-] COMPLETED: Added results -->
<section id="rain-sprinkler-grass-network-rendering-1" class="level4">
<h4 class="anchored" data-anchor-id="rain-sprinkler-grass-network-rendering-1">Rain-Sprinkler-Grass Network Rendering</h4>
<div id="cell-rain_sprinkler_grass_example_network_rendering2" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> IFrame</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>IFrame(src<span class="op">=</span><span class="st">"https://singularitysmith.github.io/AMTAIR_Prototype/bayesian_network.html"</span>, width<span class="op">=</span><span class="st">"100%"</span>, height<span class="op">=</span><span class="st">"600px"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="rain_sprinkler_grass_example_network_rendering2" class="cell-output cell-output-display" data-execution_count="2">

        <iframe width="100%" height="600px" src="https://singularitysmith.github.io/AMTAIR_Prototype/bayesian_network.html" frameborder="0" allowfullscreen=""></iframe>
        
<p>Dynamic Html Rendering of the Rain-Sprinkler-Grass DAG with Conditional Probabilities</p>
</div>
</div>
</section>
</section>
</div>
</section>
<section id="sec-case-carlsmith" class="level2">
<h2 class="anchored" data-anchor-id="sec-case-carlsmith">3.5 Case Study: Carlsmith’s Power-Seeking AI Model</h2>
<!-- [-] TODO: Introduce and refine walkthrough of the pipeline with the more complex Carlsmith model -->
<p>Having validated the implementation on the canonical rain-sprinkler-lawn example, I applied the AMTAIR approach to a substantially more complex real-world case: Joseph Carlsmith’s model of existential risk from power-seeking AI. This application demonstrates the system’s ability to handle sophisticated multi-level arguments with numerous variables and relationships.</p>
<p>Carlsmith’s model represents a dramatic increase in complexity—both conceptually and computationally. Where rain-sprinkler-grass has 3 nodes, Carlsmith involves 23. Where grass wetness is intuitive, “mesa-optimization” and “corrigibility” require careful thought.</p>
<section id="sec-carlsmith-complexity" class="level3">
<h3 class="anchored" data-anchor-id="sec-carlsmith-complexity">3.5.1 Model Complexity</h3>
<p>The numbers tell only part of the story:</p>
<ul>
<li><strong>23 nodes</strong>: Each representing a substantive claim about AI development, deployment, or risk</li>
<li><strong>29 edges</strong>: Encoding causal relationships across technical, strategic, and societal domains</li>
<li><strong>Multiple probability tables</strong>: Many nodes have several parents, creating combinatorial explosion</li>
<li><strong>Six-level causal depth</strong>: From root causes to final catastrophe, influence propagates through multiple stages</li>
</ul>
<p>But the conceptual complexity dwarfs the computational. Nodes like “APS-Systems” (Advanced, Planning, Strategically aware) encode specific technical hypotheses. Relationships like how “incentives to build” influence “deployment despite misalignment” require understanding of organizational behavior under competitive pressure.</p>
<p>This is no longer a toy problem but a serious attempt to formalize one of the most important arguments of our time.</p>
<!-- [-] COMPLETED: Added complexity analysis -->
</section>
<div class="landscape">
<section id="sec-carlsmith-extraction" class="level3">
<h3 class="anchored" data-anchor-id="sec-carlsmith-extraction">3.5.2 Automated Extraction of the Carlsmith’s Argument Structure</h3>
<p>The extraction process began with feeding Carlsmith’s paper to AMTAIR. Watching the system work felt like observing an archaeological excavation—layers of argument slowly revealed their structure.</p>
<p>The LLM prompts for extraction deserve special attention. Through iterative refinement, we developed prompts that guide extraction while remaining flexible:</p>
<pre><code>#| label: prompt_template_function
#| echo: true
#| eval: true
#| fig-cap: "Prompt Template Function Definitions"
#| fig-link: "https://colab.research.google.com/github/VJMeyer/submission/blob/main/AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb#scrollTo=MJpgdepF2Ug3&amp;line=5&amp;uniqifier=1"
#| fig-alt: "Prompt Template Function Definitions"</code></pre>
<div class="quarto-embed-nb-cell" data-notebook="/Users/vjm/Library/Mobile Documents/iCloud~md~obsidian/Documents/Vaulty/2_DoingGood/Studies/P&amp;E/Specializations/Test_Sync_MAThesis/submission/AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb" data-notebook-title="[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)" data-notebook-cellid="cell-prompt_template_function">
<div id="prompt_template_function" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># @title 1.2.0 --- Prompt Template Function Definitions --- [prompt_template_function]</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co">BLOCK PURPOSE: Defines a flexible template system for LLM prompts used in the extraction pipeline.</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co">This block implements two key classes:</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co">1. PromptTemplate: A template class supporting variable substitution for dynamic prompts</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co">2. PromptLibrary: A collection of pre-defined prompt templates for different extraction tasks</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="co">These templates are used in the ArgDown and BayesDown probability extraction</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co">stages of the pipeline, providing consistent and well-structured prompts to the LLMs.</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="co">DEPENDENCIES: string.Template for variable substitution</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="co">OUTPUTS: PromptTemplate and PromptLibrary classes</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> string <span class="im">import</span> Template</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Dict, Optional, Union, List</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PromptTemplate:</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Template system for LLM prompts with variable substitution"""</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, template: <span class="bu">str</span>):</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Initialize with template string using $variable format"""</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.template <span class="op">=</span> Template(template)</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="bu">format</span>(<span class="va">self</span>, <span class="op">**</span>kwargs) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Substitute variables in the template"""</span></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.template.safe_substitute(<span class="op">**</span>kwargs)</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">@classmethod</span></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> from_file(cls, filepath: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="st">'PromptTemplate'</span>:</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Load template from a file"""</span></span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="bu">open</span>(filepath, <span class="st">'r'</span>) <span class="im">as</span> f:</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>            template <span class="op">=</span> f.read()</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> cls(template)</span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PromptLibrary:</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Collection of prompt templates for different extraction tasks"""</span></span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ArgDown extraction prompt - transforms source text into structured argument map</span></span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>    ARGDOWN_EXTRACTION <span class="op">=</span> PromptTemplate(<span class="st">"""</span></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a><span class="st">You are participating in the AMTAIR (Automating Transformative AI Risk Modeling)</span></span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a><span class="st">project and you are tasked with converting natural language arguments into</span></span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a><span class="st">ArgDown syntax by extracting and formalizing causal world models from</span></span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a><span class="st">unstructured text.</span></span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a><span class="st">Your specific task is to extract the implicit causal model from the provided</span></span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a><span class="st">document in structured ArgDown format.</span></span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a><span class="st">## Epistemic Foundation &amp; Purpose</span></span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a><span class="st">This extraction represents one possible interpretation of the implicit causal</span></span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a><span class="st">model in the document. Multiple extractions from the same text help reveal</span></span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a><span class="st">patterns of convergence (where the model is clearly articulated) and</span></span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a><span class="st">divergence (where the model contains ambiguities). This approach acknowledges</span></span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a><span class="st">that expert texts often contain implicit rather than explicit causal models.</span></span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a><span class="st">Your role is to reveal the causal structure already present in the author's</span></span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a><span class="st">thinking, maintaining epistemic humility about your interpretation while</span></span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a><span class="st">adhering strictly to the required format.</span></span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a><span class="st">## ArgDown Format Specification</span></span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a><span class="st">### Core Syntax</span></span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a><span class="st">ArgDown represents causal relationships using a hierarchical structure:</span></span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-68"><a href="#cb16-68" aria-hidden="true" tabindex="-1"></a><span class="st">1. Variables appear in square brackets with descriptive text:</span></span>
<span id="cb16-69"><a href="#cb16-69" aria-hidden="true" tabindex="-1"></a><span class="st">   `[Variable_Name]: Description of the variable.`</span></span>
<span id="cb16-70"><a href="#cb16-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-71"><a href="#cb16-71" aria-hidden="true" tabindex="-1"></a><span class="st">2. Causal relationships use indentation (2 spaces per level) and '+' symbols:</span></span>
<span id="cb16-72"><a href="#cb16-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-73"><a href="#cb16-73" aria-hidden="true" tabindex="-1"></a><span class="st">[Effect]: Description of effect. + [Cause]: Description of cause. + [Deeper_Cause]: Description of deeper cause.</span></span>
<span id="cb16-74"><a href="#cb16-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-75"><a href="#cb16-75" aria-hidden="true" tabindex="-1"></a><span class="st">3. Causality flows from bottom (more indented) to top (less indented):</span></span>
<span id="cb16-76"><a href="#cb16-76" aria-hidden="true" tabindex="-1"></a><span class="st">- More indented variables (causes) influence less indented variables (effects)</span></span>
<span id="cb16-77"><a href="#cb16-77" aria-hidden="true" tabindex="-1"></a><span class="st">- The top-level variable is the ultimate effect or outcome</span></span>
<span id="cb16-78"><a href="#cb16-78" aria-hidden="true" tabindex="-1"></a><span class="st">- Deeper indentation levels represent root causes or earlier factors</span></span>
<span id="cb16-79"><a href="#cb16-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-80"><a href="#cb16-80" aria-hidden="true" tabindex="-1"></a><span class="st">4. Each variable must include JSON metadata with possible states (instantiations):</span></span>
<span id="cb16-81"><a href="#cb16-81" aria-hidden="true" tabindex="-1"></a><span class="st">`[Variable]: Description. {"instantiations": ["variable_STATE1", "variable_STATE2"]}`</span></span>
<span id="cb16-82"><a href="#cb16-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-83"><a href="#cb16-83" aria-hidden="true" tabindex="-1"></a><span class="st">### JSON Metadata Format</span></span>
<span id="cb16-84"><a href="#cb16-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-85"><a href="#cb16-85" aria-hidden="true" tabindex="-1"></a><span class="st">The JSON metadata must follow this exact structure:</span></span>
<span id="cb16-86"><a href="#cb16-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-87"><a href="#cb16-87" aria-hidden="true" tabindex="-1"></a><span class="st">```json</span></span>
<span id="cb16-88"><a href="#cb16-88" aria-hidden="true" tabindex="-1"></a><span class="st">{"instantiations": ["variable_STATE1", "variable_STATE2"]}</span></span>
<span id="cb16-89"><a href="#cb16-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-90"><a href="#cb16-90" aria-hidden="true" tabindex="-1"></a><span class="st">Requirements:</span></span>
<span id="cb16-91"><a href="#cb16-91" aria-hidden="true" tabindex="-1"></a><span class="st">* Double quotes (not single) around field names and string values</span></span>
<span id="cb16-92"><a href="#cb16-92" aria-hidden="true" tabindex="-1"></a><span class="st">* Square brackets enclosing the instantiations array</span></span>
<span id="cb16-93"><a href="#cb16-93" aria-hidden="true" tabindex="-1"></a><span class="st">* Comma separation between array elements</span></span>
<span id="cb16-94"><a href="#cb16-94" aria-hidden="true" tabindex="-1"></a><span class="st">* No trailing comma after the last element</span></span>
<span id="cb16-95"><a href="#cb16-95" aria-hidden="true" tabindex="-1"></a><span class="st">* Must be valid JSON syntax that can be parsed by standard JSON parsers</span></span>
<span id="cb16-96"><a href="#cb16-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-97"><a href="#cb16-97" aria-hidden="true" tabindex="-1"></a><span class="st">For binary variables (most common case):</span></span>
<span id="cb16-98"><a href="#cb16-98" aria-hidden="true" tabindex="-1"></a><span class="st">{"instantiations": ["variable_TRUE", "variable_FALSE"]}</span></span>
<span id="cb16-99"><a href="#cb16-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-100"><a href="#cb16-100" aria-hidden="true" tabindex="-1"></a><span class="st">For multi-state variables (when clearly specified in the text):</span></span>
<span id="cb16-101"><a href="#cb16-101" aria-hidden="true" tabindex="-1"></a><span class="st">{"instantiations": ["variable_HIGH", "variable_MEDIUM", "variable_LOW"]}</span></span>
<span id="cb16-102"><a href="#cb16-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-103"><a href="#cb16-103" aria-hidden="true" tabindex="-1"></a><span class="st">The metadata must appear on the same line as the variable definition, after the description.</span></span>
<span id="cb16-104"><a href="#cb16-104" aria-hidden="true" tabindex="-1"></a><span class="st">## Complex Structural Patterns</span></span>
<span id="cb16-105"><a href="#cb16-105" aria-hidden="true" tabindex="-1"></a><span class="st">### Variables Influencing Multiple Effects</span></span>
<span id="cb16-106"><a href="#cb16-106" aria-hidden="true" tabindex="-1"></a><span class="st">The same variable can appear multiple times in different places in the hierarchy if it influences multiple effects:</span></span>
<span id="cb16-107"><a href="#cb16-107" aria-hidden="true" tabindex="-1"></a><span class="st">[Effect1]: First effect description. {"instantiations": ["effect1_TRUE", "effect1_FALSE"]}</span></span>
<span id="cb16-108"><a href="#cb16-108" aria-hidden="true" tabindex="-1"></a><span class="st">  + [Cause_A]: Description of cause A. {"instantiations": ["cause_a_TRUE", "cause_a_FALSE"]}</span></span>
<span id="cb16-109"><a href="#cb16-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-110"><a href="#cb16-110" aria-hidden="true" tabindex="-1"></a><span class="st">[Effect2]: Second effect description. {"instantiations": ["effect2_TRUE", "effect2_FALSE"]}</span></span>
<span id="cb16-111"><a href="#cb16-111" aria-hidden="true" tabindex="-1"></a><span class="st">  + [Cause_A]</span></span>
<span id="cb16-112"><a href="#cb16-112" aria-hidden="true" tabindex="-1"></a><span class="st">  + [Cause_B]: Description of cause B. {"instantiations": ["cause_b_TRUE", "cause_b_FALSE"]}</span></span>
<span id="cb16-113"><a href="#cb16-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-114"><a href="#cb16-114" aria-hidden="true" tabindex="-1"></a><span class="st">### Multiple Causes of the Same Effect</span></span>
<span id="cb16-115"><a href="#cb16-115" aria-hidden="true" tabindex="-1"></a><span class="st">Multiple causes can influence the same effect by being listed at the same indentation level:</span></span>
<span id="cb16-116"><a href="#cb16-116" aria-hidden="true" tabindex="-1"></a><span class="st">[Effect]: Description of effect. {"instantiations": ["effect_TRUE", "effect_FALSE"]}</span></span>
<span id="cb16-117"><a href="#cb16-117" aria-hidden="true" tabindex="-1"></a><span class="st">  + [Cause1]: Description of first cause. {"instantiations": ["cause1_TRUE", "cause1_FALSE"]}</span></span>
<span id="cb16-118"><a href="#cb16-118" aria-hidden="true" tabindex="-1"></a><span class="st">  + [Cause2]: Description of second cause. {"instantiations": ["cause2_TRUE", "cause2_FALSE"]}</span></span>
<span id="cb16-119"><a href="#cb16-119" aria-hidden="true" tabindex="-1"></a><span class="st">    + [Deeper_Cause]: A cause that influences Cause2. {"instantiations": ["deeper_cause_TRUE", "deeper_cause_FALSE"]}</span></span>
<span id="cb16-120"><a href="#cb16-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-121"><a href="#cb16-121" aria-hidden="true" tabindex="-1"></a><span class="st">### Causal Chains</span></span>
<span id="cb16-122"><a href="#cb16-122" aria-hidden="true" tabindex="-1"></a><span class="st">Causal chains are represented through multiple levels of indentation:</span></span>
<span id="cb16-123"><a href="#cb16-123" aria-hidden="true" tabindex="-1"></a><span class="st">[Ultimate_Effect]: The final outcome. {"instantiations": ["ultimate_effect_TRUE", "ultimate_effect_FALSE"]}</span></span>
<span id="cb16-124"><a href="#cb16-124" aria-hidden="true" tabindex="-1"></a><span class="st">  + [Intermediate_Effect]: A mediating variable. {"instantiations": ["intermediate_effect_TRUE", "intermediate_effect_FALSE"]}</span></span>
<span id="cb16-125"><a href="#cb16-125" aria-hidden="true" tabindex="-1"></a><span class="st">    + [Root_Cause]: The initial cause. {"instantiations": ["root_cause_TRUE", "root_cause_FALSE"]}</span></span>
<span id="cb16-126"><a href="#cb16-126" aria-hidden="true" tabindex="-1"></a><span class="st">  + [2nd_Intermediate_Effect]: A mediating variable. {"instantiations": ["intermediate_effect_TRUE", "intermediate_effect_FALSE"]}</span></span>
<span id="cb16-127"><a href="#cb16-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-128"><a href="#cb16-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-129"><a href="#cb16-129" aria-hidden="true" tabindex="-1"></a><span class="st">### Common Cause of Multiple Variables</span></span>
<span id="cb16-130"><a href="#cb16-130" aria-hidden="true" tabindex="-1"></a><span class="st">A common cause affecting multiple variables is represented by referencing the same variable in multiple places:</span></span>
<span id="cb16-131"><a href="#cb16-131" aria-hidden="true" tabindex="-1"></a><span class="st">[Effect1]: First effect description. {"instantiations": ["effect1_TRUE", "effect1_FALSE"]}</span></span>
<span id="cb16-132"><a href="#cb16-132" aria-hidden="true" tabindex="-1"></a><span class="st">  + [Common_Cause]: Description of common cause. {"instantiations": ["common_cause_TRUE", "common_cause_FALSE"]}</span></span>
<span id="cb16-133"><a href="#cb16-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-134"><a href="#cb16-134" aria-hidden="true" tabindex="-1"></a><span class="st">[Effect2]: Second effect description. {"instantiations": ["effect2_TRUE", "effect2_FALSE"]}</span></span>
<span id="cb16-135"><a href="#cb16-135" aria-hidden="true" tabindex="-1"></a><span class="st">  + [Common_Cause]</span></span>
<span id="cb16-136"><a href="#cb16-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-137"><a href="#cb16-137" aria-hidden="true" tabindex="-1"></a><span class="st">## Detailed Extraction Workflow</span></span>
<span id="cb16-138"><a href="#cb16-138" aria-hidden="true" tabindex="-1"></a><span class="st">Please follow this step-by-step process, documenting your reasoning in XML tags:</span></span>
<span id="cb16-139"><a href="#cb16-139" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;analysis&gt;</span></span>
<span id="cb16-140"><a href="#cb16-140" aria-hidden="true" tabindex="-1"></a><span class="st">First, conduct a holistic analysis of the document:</span></span>
<span id="cb16-141"><a href="#cb16-141" aria-hidden="true" tabindex="-1"></a><span class="st">1. Identify the main subject matter or domain</span></span>
<span id="cb16-142"><a href="#cb16-142" aria-hidden="true" tabindex="-1"></a><span class="st">2. Note key concepts, variables, and factors discussed</span></span>
<span id="cb16-143"><a href="#cb16-143" aria-hidden="true" tabindex="-1"></a><span class="st">3. Pay attention to language indicating causal relationships (causes, affects, influences, depends on, etc.)</span></span>
<span id="cb16-144"><a href="#cb16-144" aria-hidden="true" tabindex="-1"></a><span class="st">4. Look for the ultimate outcomes or effects that are the focus of the document</span></span>
<span id="cb16-145"><a href="#cb16-145" aria-hidden="true" tabindex="-1"></a><span class="st">5. Record your general understanding of the document's implicit causal structure</span></span>
<span id="cb16-146"><a href="#cb16-146" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;/analysis&gt;</span></span>
<span id="cb16-147"><a href="#cb16-147" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;variable_identification&gt;</span></span>
<span id="cb16-148"><a href="#cb16-148" aria-hidden="true" tabindex="-1"></a><span class="st">Next, identify and list the key variables in the causal model:</span></span>
<span id="cb16-149"><a href="#cb16-149" aria-hidden="true" tabindex="-1"></a><span class="st">* Focus on factors that are discussed as having an influence or being influenced</span></span>
<span id="cb16-150"><a href="#cb16-150" aria-hidden="true" tabindex="-1"></a><span class="st">* For each variable:</span></span>
<span id="cb16-151"><a href="#cb16-151" aria-hidden="true" tabindex="-1"></a><span class="st">  * Create a descriptive name in [square_brackets]</span></span>
<span id="cb16-152"><a href="#cb16-152" aria-hidden="true" tabindex="-1"></a><span class="st">  * Write a concise description based directly on the text</span></span>
<span id="cb16-153"><a href="#cb16-153" aria-hidden="true" tabindex="-1"></a><span class="st">  * Determine possible states (usually binary TRUE/FALSE unless clearly specified)</span></span>
<span id="cb16-154"><a href="#cb16-154" aria-hidden="true" tabindex="-1"></a><span class="st">* Distinguish between:</span></span>
<span id="cb16-155"><a href="#cb16-155" aria-hidden="true" tabindex="-1"></a><span class="st">  * Outcome variables (effects the author is concerned with)</span></span>
<span id="cb16-156"><a href="#cb16-156" aria-hidden="true" tabindex="-1"></a><span class="st">  * Intermediate variables (both causes and effects in chains)</span></span>
<span id="cb16-157"><a href="#cb16-157" aria-hidden="true" tabindex="-1"></a><span class="st">  * Root cause variables (exogenous factors in the model)</span></span>
<span id="cb16-158"><a href="#cb16-158" aria-hidden="true" tabindex="-1"></a><span class="st">* List all identified variables with their descriptions and possible states</span></span>
<span id="cb16-159"><a href="#cb16-159" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;/variable_identification&gt;</span></span>
<span id="cb16-160"><a href="#cb16-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-161"><a href="#cb16-161" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;causal_structure&gt;</span></span>
<span id="cb16-162"><a href="#cb16-162" aria-hidden="true" tabindex="-1"></a><span class="st">Then, determine the causal relationships between variables:</span></span>
<span id="cb16-163"><a href="#cb16-163" aria-hidden="true" tabindex="-1"></a><span class="st">* For each variable, identify what factors influence it</span></span>
<span id="cb16-164"><a href="#cb16-164" aria-hidden="true" tabindex="-1"></a><span class="st">* Note the direction of causality (what causes what)</span></span>
<span id="cb16-165"><a href="#cb16-165" aria-hidden="true" tabindex="-1"></a><span class="st">* Look for mediating variables in causal chains</span></span>
<span id="cb16-166"><a href="#cb16-166" aria-hidden="true" tabindex="-1"></a><span class="st">* Identify common causes of multiple effects</span></span>
<span id="cb16-167"><a href="#cb16-167" aria-hidden="true" tabindex="-1"></a><span class="st">* Capture feedback loops if present (though they must be represented as DAGs)</span></span>
<span id="cb16-168"><a href="#cb16-168" aria-hidden="true" tabindex="-1"></a><span class="st">* Map out the hierarchical structure of the causal model</span></span>
<span id="cb16-169"><a href="#cb16-169" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;/causal_structure&gt;</span></span>
<span id="cb16-170"><a href="#cb16-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-171"><a href="#cb16-171" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;format_conversion&gt;</span></span>
<span id="cb16-172"><a href="#cb16-172" aria-hidden="true" tabindex="-1"></a><span class="st">Now, convert your analysis into proper ArgDown format:</span></span>
<span id="cb16-173"><a href="#cb16-173" aria-hidden="true" tabindex="-1"></a><span class="st">* Start with the ultimate outcome variables at the top level</span></span>
<span id="cb16-174"><a href="#cb16-174" aria-hidden="true" tabindex="-1"></a><span class="st">* Place direct causes indented below with </span><span class="er">\</span><span class="st">+ symbols</span></span>
<span id="cb16-175"><a href="#cb16-175" aria-hidden="true" tabindex="-1"></a><span class="st">* Continue with deeper causes at further indentation levels</span></span>
<span id="cb16-176"><a href="#cb16-176" aria-hidden="true" tabindex="-1"></a><span class="st">* Add variable descriptions and instantiations metadata</span></span>
<span id="cb16-177"><a href="#cb16-177" aria-hidden="true" tabindex="-1"></a><span class="st">* Ensure variables appearing in multiple places have consistent names</span></span>
<span id="cb16-178"><a href="#cb16-178" aria-hidden="true" tabindex="-1"></a><span class="st">* Check that the entire structure forms a valid directed acyclic graph</span></span>
<span id="cb16-179"><a href="#cb16-179" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;/format_conversion&gt;</span></span>
<span id="cb16-180"><a href="#cb16-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-181"><a href="#cb16-181" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;validation&gt;</span></span>
<span id="cb16-182"><a href="#cb16-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-183"><a href="#cb16-183" aria-hidden="true" tabindex="-1"></a><span class="st">Finally, review your extraction for quality and format correctness:</span></span>
<span id="cb16-184"><a href="#cb16-184" aria-hidden="true" tabindex="-1"></a><span class="st">1. Verify all variables have properly formatted metadata</span></span>
<span id="cb16-185"><a href="#cb16-185" aria-hidden="true" tabindex="-1"></a><span class="st">2. Check that indentation properly represents causal direction</span></span>
<span id="cb16-186"><a href="#cb16-186" aria-hidden="true" tabindex="-1"></a><span class="st">3. Confirm the extraction accurately reflects the document's implicit model</span></span>
<span id="cb16-187"><a href="#cb16-187" aria-hidden="true" tabindex="-1"></a><span class="st">4. Ensure no cycles exist in the causal structure</span></span>
<span id="cb16-188"><a href="#cb16-188" aria-hidden="true" tabindex="-1"></a><span class="st">5. Verify that variables referenced multiple times are consistent</span></span>
<span id="cb16-189"><a href="#cb16-189" aria-hidden="true" tabindex="-1"></a><span class="st">6. Check that the extraction would be useful for subsequent analysis</span></span>
<span id="cb16-190"><a href="#cb16-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-191"><a href="#cb16-191" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;/validation&gt;</span></span>
<span id="cb16-192"><a href="#cb16-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-193"><a href="#cb16-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-194"><a href="#cb16-194" aria-hidden="true" tabindex="-1"></a><span class="st">## Source Document Analysis Guidance</span></span>
<span id="cb16-195"><a href="#cb16-195" aria-hidden="true" tabindex="-1"></a><span class="st">When analyzing the source document:</span></span>
<span id="cb16-196"><a href="#cb16-196" aria-hidden="true" tabindex="-1"></a><span class="st">* Focus on revealing the author's own causal model, not imposing an external framework</span></span>
<span id="cb16-197"><a href="#cb16-197" aria-hidden="true" tabindex="-1"></a><span class="st">* Maintain the author's terminology where possible</span></span>
<span id="cb16-198"><a href="#cb16-198" aria-hidden="true" tabindex="-1"></a><span class="st">* Look for both explicit statements of causality and implicit assumptions</span></span>
<span id="cb16-199"><a href="#cb16-199" aria-hidden="true" tabindex="-1"></a><span class="st">* Pay attention to the relative importance the author assigns to different factors</span></span>
<span id="cb16-200"><a href="#cb16-200" aria-hidden="true" tabindex="-1"></a><span class="st">* Notice where the author expresses certainty versus uncertainty</span></span>
<span id="cb16-201"><a href="#cb16-201" aria-hidden="true" tabindex="-1"></a><span class="st">* Consider the level of granularity appropriate to the document's own analysis</span></span>
<span id="cb16-202"><a href="#cb16-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-203"><a href="#cb16-203" aria-hidden="true" tabindex="-1"></a><span class="st">Remember that your goal is to make the implicit model explicit, not to evaluate or improve it.</span></span>
<span id="cb16-204"><a href="#cb16-204" aria-hidden="true" tabindex="-1"></a><span class="st">The value lies in accurately representing the author's perspective, even if you might personally disagree or see limitations in their model.</span></span>
<span id="cb16-205"><a href="#cb16-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-206"><a href="#cb16-206" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span>
<span id="cb16-207"><a href="#cb16-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-208"><a href="#cb16-208" aria-hidden="true" tabindex="-1"></a>    <span class="co"># BayesDown probability extraction prompt - enhances ArgDown with probability information</span></span>
<span id="cb16-209"><a href="#cb16-209" aria-hidden="true" tabindex="-1"></a>    BAYESDOWN_EXTRACTION <span class="op">=</span> PromptTemplate(<span class="st">"""</span></span>
<span id="cb16-210"><a href="#cb16-210" aria-hidden="true" tabindex="-1"></a><span class="st">You are an expert in probabilistic reasoning and Bayesian networks. Your task is</span></span>
<span id="cb16-211"><a href="#cb16-211" aria-hidden="true" tabindex="-1"></a><span class="st">to extend the provided ArgDown structure with probability information,</span></span>
<span id="cb16-212"><a href="#cb16-212" aria-hidden="true" tabindex="-1"></a><span class="st">creating a BayesDown representation.</span></span>
<span id="cb16-213"><a href="#cb16-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-214"><a href="#cb16-214" aria-hidden="true" tabindex="-1"></a><span class="st">For each statement in the ArgDown structure, you need to:</span></span>
<span id="cb16-215"><a href="#cb16-215" aria-hidden="true" tabindex="-1"></a><span class="st">1. Estimate prior probabilities for each possible state</span></span>
<span id="cb16-216"><a href="#cb16-216" aria-hidden="true" tabindex="-1"></a><span class="st">2. Estimate conditional probabilities given parent states</span></span>
<span id="cb16-217"><a href="#cb16-217" aria-hidden="true" tabindex="-1"></a><span class="st">3. Maintain the original structure and relationships</span></span>
<span id="cb16-218"><a href="#cb16-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-219"><a href="#cb16-219" aria-hidden="true" tabindex="-1"></a><span class="st">Here is the format to follow:</span></span>
<span id="cb16-220"><a href="#cb16-220" aria-hidden="true" tabindex="-1"></a><span class="st">[Node]: Description. { "instantiations": ["node_TRUE", "node_FALSE"], "priors": { "p(node_TRUE)": "0.7", "p(node_FALSE)": "0.3" }, "posteriors": { "p(node_TRUE|parent_TRUE)": "0.9", "p(node_TRUE|parent_FALSE)": "0.4", "p(node_FALSE|parent_TRUE)": "0.1", "p(node_FALSE|parent_FALSE)": "0.6" } }</span></span>
<span id="cb16-221"><a href="#cb16-221" aria-hidden="true" tabindex="-1"></a><span class="st"> [Parent]: Parent description. {...}</span></span>
<span id="cb16-222"><a href="#cb16-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-223"><a href="#cb16-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-224"><a href="#cb16-224" aria-hidden="true" tabindex="-1"></a><span class="st">Here are the specific probability questions to answer:</span></span>
<span id="cb16-225"><a href="#cb16-225" aria-hidden="true" tabindex="-1"></a><span class="st">$questions</span></span>
<span id="cb16-226"><a href="#cb16-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-227"><a href="#cb16-227" aria-hidden="true" tabindex="-1"></a><span class="st">ArgDown structure to enhance:</span></span>
<span id="cb16-228"><a href="#cb16-228" aria-hidden="true" tabindex="-1"></a><span class="st">$argdown</span></span>
<span id="cb16-229"><a href="#cb16-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-230"><a href="#cb16-230" aria-hidden="true" tabindex="-1"></a><span class="st">Provide the complete BayesDown representation with probabilities:</span></span>
<span id="cb16-231"><a href="#cb16-231" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span>
<span id="cb16-232"><a href="#cb16-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-233"><a href="#cb16-233" aria-hidden="true" tabindex="-1"></a>    <span class="at">@classmethod</span></span>
<span id="cb16-234"><a href="#cb16-234" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_template(cls, template_name: <span class="bu">str</span>) <span class="op">-&gt;</span> PromptTemplate:</span>
<span id="cb16-235"><a href="#cb16-235" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Get a prompt template by name"""</span></span>
<span id="cb16-236"><a href="#cb16-236" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(cls, template_name):</span>
<span id="cb16-237"><a href="#cb16-237" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="bu">getattr</span>(cls, template_name)</span>
<span id="cb16-238"><a href="#cb16-238" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb16-239"><a href="#cb16-239" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Template not found: </span><span class="sc">{</span>template_name<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
<!-- python

```python
ARGDOWN_EXTRACTION = PromptTemplate("""
You are extracting the causal model from an AI safety argument.
Focus on:
1. Identifying key variables that affect outcomes
2. Capturing causal relationships (not mere association)  
3. Preserving the author's terminology where possible
4. Creating a directed acyclic graph structure

For Carlsmith's argument about power-seeking AI, pay special attention to:
- The chain from capabilities to catastrophe
- Conditional relationships (X matters only if Y)
- Technical preconditions for risk
""")
``` -->
<section id="prompting-llms-for-argdown-extraction" class="level4">
<h4 class="anchored" data-anchor-id="prompting-llms-for-argdown-extraction">Prompting LLMs for ArgDown Extraction</h4>
<!-- 
#| label: prompt_template_function
#| echo: true
#| eval: true
#| fig-cap: "Prompt Template Function Definitions"
#| fig-link: "https://colab.research.google.com/github/VJMeyer/submission/blob/main/AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb#scrollTo=MJpgdepF2Ug3&line=5&uniqifier=1"
#| fig-alt: "Prompt Template Function Definitions"
-->
<p>The extraction revealed Carlsmith’s elegant decomposition. At the highest level: capabilities enable power-seeking, which enables disempowerment, which constitutes catastrophe. But the details matter—deployment decisions mediated by incentives and deception, alignment difficulty influenced by multiple technical factors, corrective mechanisms that might interrupt the chain.</p>
<p>The ArgDown representation captured this structure: <!-- 
```markdown
[Existential_Catastrophe]: Permanent curtailment of humanity's potential
 + [Human_Disempowerment]: Humans lose control over future
   + [Scale_Of_Power_Seeking]: Power-seeking behavior becomes overwhelming
     + [Misaligned_Power_Seeking]: AI systems pursue problematic objectives
       + [APS_Systems]: Advanced, planning, strategically aware AI
       + [Alignment_Difficulty]: Hard to align such systems
       + [Deployment_Despite_Misalignment]: Systems deployed anyway
         + [Incentives_To_Build]: Strong pressure to develop AI
         + [Deception]: AI systems hide misalignment
```
--></p>
<div class="quarto-embed-nb-cell" data-notebook="/Users/vjm/Library/Mobile Documents/iCloud~md~obsidian/Documents/Vaulty/2_DoingGood/Studies/P&amp;E/Specializations/Test_Sync_MAThesis/submission/AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb" data-notebook-title="[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)" data-notebook-cellid="cell-parsing_argdown_bayesdown">
<div id="parsing_argdown_bayesdown" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># @title 1.7.0 --- Parsing ArgDown &amp; BayesDown (.md to .csv) --- [parsing_argdown_bayesdown]</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co">BLOCK PURPOSE: Provides the core parsing functionality for transforming ArgDown</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co">and BayesDown text representations into structured DataFrame format for further</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co">processing.</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co">This block implements the critical extraction pipeline described in the AMTAIR</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co">project (see PY_TechnicalImplementation) that converts argument structures</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co">into Bayesian networks.</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co">The function can handle both basic ArgDown (structure-only) and</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="co">BayesDown (with probabilities).</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co">Key steps in the parsing process:</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="co">1. Remove comments from the markdown text</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="co">2. Extract titles, descriptions, and indentation levels</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="co">3. Establish parent-child relationships based on indentation</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="co">4. Convert the structured information into a DataFrame</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="co">5. Add derived columns for network analysis</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a><span class="co">DEPENDENCIES: pandas, re, json libraries</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="co">INPUTS: Markdown text in ArgDown/BayesDown format</span></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a><span class="co">OUTPUTS: Structured DataFrame with node information, relationships, and properties</span></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parse_markdown_hierarchy_fixed(markdown_text, ArgDown<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a><span class="co">    Parse ArgDown or BayesDown format into a structured DataFrame with parent-child relationships.</span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a><span class="co">        markdown_text (str): Text in ArgDown or BayesDown format</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a><span class="co">        ArgDown (bool): If True, extracts only structure without probabilities</span></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a><span class="co">                        If False, extracts both structure and probability information</span></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a><span class="co">        pandas.DataFrame: Structured data with node information, relationships, and attributes</span></span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># PHASE 1: Clean and prepare the text</span></span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>    clean_text <span class="op">=</span> remove_comments(markdown_text)</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># PHASE 2: Extract basic information about nodes</span></span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>    titles_info <span class="op">=</span> extract_titles_info(clean_text)</span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># PHASE 3: Determine the hierarchical relationships</span></span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a>    titles_with_relations <span class="op">=</span> establish_relationships_fixed(titles_info, clean_text)</span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># PHASE 4: Convert to structured DataFrame format</span></span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> convert_to_dataframe(titles_with_relations, ArgDown)</span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># PHASE 5: Add derived columns for analysis</span></span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> add_no_parent_no_child_columns_to_df(df)</span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> add_parents_instantiation_columns_to_df(df)</span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df</span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> remove_comments(markdown_text):</span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb17-58"><a href="#cb17-58" aria-hidden="true" tabindex="-1"></a><span class="co">    Remove comment blocks from markdown text using regex pattern matching.</span></span>
<span id="cb17-59"><a href="#cb17-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-60"><a href="#cb17-60" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb17-61"><a href="#cb17-61" aria-hidden="true" tabindex="-1"></a><span class="co">        markdown_text (str): Text containing potential comment blocks</span></span>
<span id="cb17-62"><a href="#cb17-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-63"><a href="#cb17-63" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb17-64"><a href="#cb17-64" aria-hidden="true" tabindex="-1"></a><span class="co">        str: Text with comment blocks removed</span></span>
<span id="cb17-65"><a href="#cb17-65" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-66"><a href="#cb17-66" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remove anything between /* and */ using regex</span></span>
<span id="cb17-67"><a href="#cb17-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> re.sub(<span class="vs">r'/</span><span class="ch">\*</span><span class="dv">.</span><span class="op">*?</span><span class="ch">\*</span><span class="vs">/'</span>, <span class="st">''</span>, markdown_text, flags<span class="op">=</span>re.DOTALL)</span>
<span id="cb17-68"><a href="#cb17-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-69"><a href="#cb17-69" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_titles_info(text):</span>
<span id="cb17-70"><a href="#cb17-70" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb17-71"><a href="#cb17-71" aria-hidden="true" tabindex="-1"></a><span class="co">    Extract titles with their descriptions and indentation levels from markdown text.</span></span>
<span id="cb17-72"><a href="#cb17-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-73"><a href="#cb17-73" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb17-74"><a href="#cb17-74" aria-hidden="true" tabindex="-1"></a><span class="co">        text (str): Cleaned markdown text</span></span>
<span id="cb17-75"><a href="#cb17-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-76"><a href="#cb17-76" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb17-77"><a href="#cb17-77" aria-hidden="true" tabindex="-1"></a><span class="co">        dict: Dictionary with titles as keys and dictionaries of attributes as values</span></span>
<span id="cb17-78"><a href="#cb17-78" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-79"><a href="#cb17-79" aria-hidden="true" tabindex="-1"></a>    lines <span class="op">=</span> text.split(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb17-80"><a href="#cb17-80" aria-hidden="true" tabindex="-1"></a>    titles_info <span class="op">=</span> {}</span>
<span id="cb17-81"><a href="#cb17-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-82"><a href="#cb17-82" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> line <span class="kw">in</span> lines:</span>
<span id="cb17-83"><a href="#cb17-83" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Skip empty lines</span></span>
<span id="cb17-84"><a href="#cb17-84" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> line.strip():</span>
<span id="cb17-85"><a href="#cb17-85" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb17-86"><a href="#cb17-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-87"><a href="#cb17-87" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract title within square or angle brackets</span></span>
<span id="cb17-88"><a href="#cb17-88" aria-hidden="true" tabindex="-1"></a>        title_match <span class="op">=</span> re.search(<span class="vs">r'</span><span class="pp">[&lt;</span><span class="ch">\[</span><span class="pp">]</span><span class="kw">(</span><span class="dv">.</span><span class="op">+?</span><span class="kw">)</span><span class="pp">[&gt;</span><span class="ch">\]</span><span class="pp">]</span><span class="vs">'</span>, line)</span>
<span id="cb17-89"><a href="#cb17-89" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> title_match:</span>
<span id="cb17-90"><a href="#cb17-90" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb17-91"><a href="#cb17-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-92"><a href="#cb17-92" aria-hidden="true" tabindex="-1"></a>        title <span class="op">=</span> title_match.group(<span class="dv">1</span>)</span>
<span id="cb17-93"><a href="#cb17-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-94"><a href="#cb17-94" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract description and metadata</span></span>
<span id="cb17-95"><a href="#cb17-95" aria-hidden="true" tabindex="-1"></a>        title_pattern_in_line <span class="op">=</span> <span class="vs">r'</span><span class="pp">[&lt;</span><span class="ch">\[</span><span class="pp">]</span><span class="vs">'</span> <span class="op">+</span> re.escape(title) <span class="op">+</span> <span class="vs">r'</span><span class="pp">[&gt;</span><span class="ch">\]</span><span class="pp">]</span><span class="vs">:'</span></span>
<span id="cb17-96"><a href="#cb17-96" aria-hidden="true" tabindex="-1"></a>        description_match <span class="op">=</span> re.search(title_pattern_in_line <span class="op">+</span> <span class="vs">r'</span><span class="dv">\s</span><span class="op">*</span><span class="kw">(</span><span class="dv">.</span><span class="op">*</span><span class="kw">)</span><span class="vs">'</span>, line)</span>
<span id="cb17-97"><a href="#cb17-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-98"><a href="#cb17-98" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> description_match:</span>
<span id="cb17-99"><a href="#cb17-99" aria-hidden="true" tabindex="-1"></a>            full_text <span class="op">=</span> description_match.group(<span class="dv">1</span>).strip()</span>
<span id="cb17-100"><a href="#cb17-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-101"><a href="#cb17-101" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Split description and metadata at the first "{"</span></span>
<span id="cb17-102"><a href="#cb17-102" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="st">"{"</span> <span class="kw">in</span> full_text:</span>
<span id="cb17-103"><a href="#cb17-103" aria-hidden="true" tabindex="-1"></a>                split_index <span class="op">=</span> full_text.find(<span class="st">"{"</span>)</span>
<span id="cb17-104"><a href="#cb17-104" aria-hidden="true" tabindex="-1"></a>                description <span class="op">=</span> full_text[:split_index].strip()</span>
<span id="cb17-105"><a href="#cb17-105" aria-hidden="true" tabindex="-1"></a>                metadata <span class="op">=</span> full_text[split_index:].strip()</span>
<span id="cb17-106"><a href="#cb17-106" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb17-107"><a href="#cb17-107" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Keep the entire description and no metadata</span></span>
<span id="cb17-108"><a href="#cb17-108" aria-hidden="true" tabindex="-1"></a>                description <span class="op">=</span> full_text</span>
<span id="cb17-109"><a href="#cb17-109" aria-hidden="true" tabindex="-1"></a>                metadata <span class="op">=</span> <span class="st">''</span>  <span class="co"># Initialize as empty string</span></span>
<span id="cb17-110"><a href="#cb17-110" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb17-111"><a href="#cb17-111" aria-hidden="true" tabindex="-1"></a>            description <span class="op">=</span> <span class="st">''</span></span>
<span id="cb17-112"><a href="#cb17-112" aria-hidden="true" tabindex="-1"></a>            metadata <span class="op">=</span> <span class="st">''</span>  <span class="co"># Ensure metadata is initialized</span></span>
<span id="cb17-113"><a href="#cb17-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-114"><a href="#cb17-114" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate indentation level based on spaces before + or - symbol</span></span>
<span id="cb17-115"><a href="#cb17-115" aria-hidden="true" tabindex="-1"></a>        indentation <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb17-116"><a href="#cb17-116" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">'+'</span> <span class="kw">in</span> line:</span>
<span id="cb17-117"><a href="#cb17-117" aria-hidden="true" tabindex="-1"></a>            symbol_index <span class="op">=</span> line.find(<span class="st">'+'</span>)</span>
<span id="cb17-118"><a href="#cb17-118" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Count spaces before the '+' symbol</span></span>
<span id="cb17-119"><a href="#cb17-119" aria-hidden="true" tabindex="-1"></a>            i <span class="op">=</span> symbol_index <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb17-120"><a href="#cb17-120" aria-hidden="true" tabindex="-1"></a>            <span class="cf">while</span> i <span class="op">&gt;=</span> <span class="dv">0</span> <span class="kw">and</span> line[i] <span class="op">==</span> <span class="st">' '</span>:</span>
<span id="cb17-121"><a href="#cb17-121" aria-hidden="true" tabindex="-1"></a>                indentation <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb17-122"><a href="#cb17-122" aria-hidden="true" tabindex="-1"></a>                i <span class="op">-=</span> <span class="dv">1</span></span>
<span id="cb17-123"><a href="#cb17-123" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="st">'-'</span> <span class="kw">in</span> line:</span>
<span id="cb17-124"><a href="#cb17-124" aria-hidden="true" tabindex="-1"></a>            symbol_index <span class="op">=</span> line.find(<span class="st">'-'</span>)</span>
<span id="cb17-125"><a href="#cb17-125" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Count spaces before the '-' symbol</span></span>
<span id="cb17-126"><a href="#cb17-126" aria-hidden="true" tabindex="-1"></a>            i <span class="op">=</span> symbol_index <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb17-127"><a href="#cb17-127" aria-hidden="true" tabindex="-1"></a>            <span class="cf">while</span> i <span class="op">&gt;=</span> <span class="dv">0</span> <span class="kw">and</span> line[i] <span class="op">==</span> <span class="st">' '</span>:</span>
<span id="cb17-128"><a href="#cb17-128" aria-hidden="true" tabindex="-1"></a>                indentation <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb17-129"><a href="#cb17-129" aria-hidden="true" tabindex="-1"></a>                i <span class="op">-=</span> <span class="dv">1</span></span>
<span id="cb17-130"><a href="#cb17-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-131"><a href="#cb17-131" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If neither symbol exists, indentation remains 0</span></span>
<span id="cb17-132"><a href="#cb17-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-133"><a href="#cb17-133" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> title <span class="kw">in</span> titles_info:</span>
<span id="cb17-134"><a href="#cb17-134" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Only update description if it's currently empty and we found a new one</span></span>
<span id="cb17-135"><a href="#cb17-135" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="kw">not</span> titles_info[title][<span class="st">'description'</span>] <span class="kw">and</span> description:</span>
<span id="cb17-136"><a href="#cb17-136" aria-hidden="true" tabindex="-1"></a>                titles_info[title][<span class="st">'description'</span>] <span class="op">=</span> description</span>
<span id="cb17-137"><a href="#cb17-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-138"><a href="#cb17-138" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Store all indentation levels for this title</span></span>
<span id="cb17-139"><a href="#cb17-139" aria-hidden="true" tabindex="-1"></a>            titles_info[title][<span class="st">'indentation_levels'</span>].append(indentation)</span>
<span id="cb17-140"><a href="#cb17-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-141"><a href="#cb17-141" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Keep max indentation for backward compatibility</span></span>
<span id="cb17-142"><a href="#cb17-142" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> indentation <span class="op">&gt;</span> titles_info[title][<span class="st">'indentation'</span>]:</span>
<span id="cb17-143"><a href="#cb17-143" aria-hidden="true" tabindex="-1"></a>                titles_info[title][<span class="st">'indentation'</span>] <span class="op">=</span> indentation</span>
<span id="cb17-144"><a href="#cb17-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-145"><a href="#cb17-145" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Do NOT update metadata here - keep the original metadata</span></span>
<span id="cb17-146"><a href="#cb17-146" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb17-147"><a href="#cb17-147" aria-hidden="true" tabindex="-1"></a>            <span class="co"># First time seeing this title, create a new entry</span></span>
<span id="cb17-148"><a href="#cb17-148" aria-hidden="true" tabindex="-1"></a>            titles_info[title] <span class="op">=</span> {</span>
<span id="cb17-149"><a href="#cb17-149" aria-hidden="true" tabindex="-1"></a>                <span class="st">'description'</span>: description,</span>
<span id="cb17-150"><a href="#cb17-150" aria-hidden="true" tabindex="-1"></a>                <span class="st">'indentation'</span>: indentation,</span>
<span id="cb17-151"><a href="#cb17-151" aria-hidden="true" tabindex="-1"></a>                <span class="st">'indentation_levels'</span>: [indentation],  <span class="co"># Initialize with first indentation level</span></span>
<span id="cb17-152"><a href="#cb17-152" aria-hidden="true" tabindex="-1"></a>                <span class="st">'parents'</span>: [],</span>
<span id="cb17-153"><a href="#cb17-153" aria-hidden="true" tabindex="-1"></a>                <span class="st">'children'</span>: [],</span>
<span id="cb17-154"><a href="#cb17-154" aria-hidden="true" tabindex="-1"></a>                <span class="st">'line'</span>: <span class="va">None</span>,</span>
<span id="cb17-155"><a href="#cb17-155" aria-hidden="true" tabindex="-1"></a>                <span class="st">'line_numbers'</span>: [],  <span class="co"># Initialize an empty list for all occurrences</span></span>
<span id="cb17-156"><a href="#cb17-156" aria-hidden="true" tabindex="-1"></a>                <span class="st">'metadata'</span>: metadata  <span class="co"># Set metadata explicitly from what we found</span></span>
<span id="cb17-157"><a href="#cb17-157" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb17-158"><a href="#cb17-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-159"><a href="#cb17-159" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> titles_info</span>
<span id="cb17-160"><a href="#cb17-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-161"><a href="#cb17-161" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> establish_relationships_fixed(titles_info, text):</span>
<span id="cb17-162"><a href="#cb17-162" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb17-163"><a href="#cb17-163" aria-hidden="true" tabindex="-1"></a><span class="co">    Establish parent-child relationships between titles using BayesDown</span></span>
<span id="cb17-164"><a href="#cb17-164" aria-hidden="true" tabindex="-1"></a><span class="co">    indentation rules.</span></span>
<span id="cb17-165"><a href="#cb17-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-166"><a href="#cb17-166" aria-hidden="true" tabindex="-1"></a><span class="co">    In BayesDown syntax:</span></span>
<span id="cb17-167"><a href="#cb17-167" aria-hidden="true" tabindex="-1"></a><span class="co">    - More indented nodes (with + symbol) are PARENTS of less indented nodes</span></span>
<span id="cb17-168"><a href="#cb17-168" aria-hidden="true" tabindex="-1"></a><span class="co">    - The relationship reads as "Effect is caused by Cause" (Effect + Cause)</span></span>
<span id="cb17-169"><a href="#cb17-169" aria-hidden="true" tabindex="-1"></a><span class="co">    - This aligns with how Bayesian networks represent causality</span></span>
<span id="cb17-170"><a href="#cb17-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-171"><a href="#cb17-171" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb17-172"><a href="#cb17-172" aria-hidden="true" tabindex="-1"></a><span class="co">        titles_info (dict): Dictionary with information about titles</span></span>
<span id="cb17-173"><a href="#cb17-173" aria-hidden="true" tabindex="-1"></a><span class="co">        text (str): Original markdown text (for identifying line numbers)</span></span>
<span id="cb17-174"><a href="#cb17-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-175"><a href="#cb17-175" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb17-176"><a href="#cb17-176" aria-hidden="true" tabindex="-1"></a><span class="co">        dict: Updated dictionary with parent-child relationships</span></span>
<span id="cb17-177"><a href="#cb17-177" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-178"><a href="#cb17-178" aria-hidden="true" tabindex="-1"></a>    lines <span class="op">=</span> text.split(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb17-179"><a href="#cb17-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-180"><a href="#cb17-180" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Dictionary to store line numbers for each title occurrence</span></span>
<span id="cb17-181"><a href="#cb17-181" aria-hidden="true" tabindex="-1"></a>    title_occurrences <span class="op">=</span> {}</span>
<span id="cb17-182"><a href="#cb17-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-183"><a href="#cb17-183" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Record line number for each title (including multiple occurrences)</span></span>
<span id="cb17-184"><a href="#cb17-184" aria-hidden="true" tabindex="-1"></a>    line_number <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb17-185"><a href="#cb17-185" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> line <span class="kw">in</span> lines:</span>
<span id="cb17-186"><a href="#cb17-186" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> line.strip():</span>
<span id="cb17-187"><a href="#cb17-187" aria-hidden="true" tabindex="-1"></a>            line_number <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb17-188"><a href="#cb17-188" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb17-189"><a href="#cb17-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-190"><a href="#cb17-190" aria-hidden="true" tabindex="-1"></a>        title_match <span class="op">=</span> re.search(<span class="vs">r'</span><span class="pp">[&lt;</span><span class="ch">\[</span><span class="pp">]</span><span class="kw">(</span><span class="dv">.</span><span class="op">+?</span><span class="kw">)</span><span class="pp">[&gt;</span><span class="ch">\]</span><span class="pp">]</span><span class="vs">'</span>, line)</span>
<span id="cb17-191"><a href="#cb17-191" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> title_match:</span>
<span id="cb17-192"><a href="#cb17-192" aria-hidden="true" tabindex="-1"></a>            line_number <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb17-193"><a href="#cb17-193" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb17-194"><a href="#cb17-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-195"><a href="#cb17-195" aria-hidden="true" tabindex="-1"></a>        title <span class="op">=</span> title_match.group(<span class="dv">1</span>)</span>
<span id="cb17-196"><a href="#cb17-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-197"><a href="#cb17-197" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Store all occurrences of each title with their line numbers</span></span>
<span id="cb17-198"><a href="#cb17-198" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> title <span class="kw">not</span> <span class="kw">in</span> title_occurrences:</span>
<span id="cb17-199"><a href="#cb17-199" aria-hidden="true" tabindex="-1"></a>            title_occurrences[title] <span class="op">=</span> []</span>
<span id="cb17-200"><a href="#cb17-200" aria-hidden="true" tabindex="-1"></a>        title_occurrences[title].append(line_number)</span>
<span id="cb17-201"><a href="#cb17-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-202"><a href="#cb17-202" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Store all line numbers where this title appears</span></span>
<span id="cb17-203"><a href="#cb17-203" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">'line_numbers'</span> <span class="kw">not</span> <span class="kw">in</span> titles_info[title]:</span>
<span id="cb17-204"><a href="#cb17-204" aria-hidden="true" tabindex="-1"></a>            titles_info[title][<span class="st">'line_numbers'</span>] <span class="op">=</span> []</span>
<span id="cb17-205"><a href="#cb17-205" aria-hidden="true" tabindex="-1"></a>        titles_info[title][<span class="st">'line_numbers'</span>].append(line_number)</span>
<span id="cb17-206"><a href="#cb17-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-207"><a href="#cb17-207" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For backward compatibility, keep the first occurrence in 'line'</span></span>
<span id="cb17-208"><a href="#cb17-208" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> titles_info[title][<span class="st">'line'</span>] <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb17-209"><a href="#cb17-209" aria-hidden="true" tabindex="-1"></a>            titles_info[title][<span class="st">'line'</span>] <span class="op">=</span> line_number</span>
<span id="cb17-210"><a href="#cb17-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-211"><a href="#cb17-211" aria-hidden="true" tabindex="-1"></a>        line_number <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb17-212"><a href="#cb17-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-213"><a href="#cb17-213" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create an ordered list of all title occurrences with their line numbers</span></span>
<span id="cb17-214"><a href="#cb17-214" aria-hidden="true" tabindex="-1"></a>    all_occurrences <span class="op">=</span> []</span>
<span id="cb17-215"><a href="#cb17-215" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> title, occurrences <span class="kw">in</span> title_occurrences.items():</span>
<span id="cb17-216"><a href="#cb17-216" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> line_num <span class="kw">in</span> occurrences:</span>
<span id="cb17-217"><a href="#cb17-217" aria-hidden="true" tabindex="-1"></a>            all_occurrences.append((title, line_num))</span>
<span id="cb17-218"><a href="#cb17-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-219"><a href="#cb17-219" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sort occurrences by line number</span></span>
<span id="cb17-220"><a href="#cb17-220" aria-hidden="true" tabindex="-1"></a>    all_occurrences.sort(key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">1</span>])</span>
<span id="cb17-221"><a href="#cb17-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-222"><a href="#cb17-222" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get indentation for each occurrence</span></span>
<span id="cb17-223"><a href="#cb17-223" aria-hidden="true" tabindex="-1"></a>    occurrence_indents <span class="op">=</span> {}</span>
<span id="cb17-224"><a href="#cb17-224" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> title, line_num <span class="kw">in</span> all_occurrences:</span>
<span id="cb17-225"><a href="#cb17-225" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> line <span class="kw">in</span> lines[line_num:line_num<span class="op">+</span><span class="dv">1</span>]:  <span class="co"># Only check the current line</span></span>
<span id="cb17-226"><a href="#cb17-226" aria-hidden="true" tabindex="-1"></a>            indent <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb17-227"><a href="#cb17-227" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="st">'+'</span> <span class="kw">in</span> line:</span>
<span id="cb17-228"><a href="#cb17-228" aria-hidden="true" tabindex="-1"></a>                symbol_index <span class="op">=</span> line.find(<span class="st">'+'</span>)</span>
<span id="cb17-229"><a href="#cb17-229" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Count spaces before the '+' symbol</span></span>
<span id="cb17-230"><a href="#cb17-230" aria-hidden="true" tabindex="-1"></a>                j <span class="op">=</span> symbol_index <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb17-231"><a href="#cb17-231" aria-hidden="true" tabindex="-1"></a>                <span class="cf">while</span> j <span class="op">&gt;=</span> <span class="dv">0</span> <span class="kw">and</span> line[j] <span class="op">==</span> <span class="st">' '</span>:</span>
<span id="cb17-232"><a href="#cb17-232" aria-hidden="true" tabindex="-1"></a>                    indent <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb17-233"><a href="#cb17-233" aria-hidden="true" tabindex="-1"></a>                    j <span class="op">-=</span> <span class="dv">1</span></span>
<span id="cb17-234"><a href="#cb17-234" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> <span class="st">'-'</span> <span class="kw">in</span> line:</span>
<span id="cb17-235"><a href="#cb17-235" aria-hidden="true" tabindex="-1"></a>                symbol_index <span class="op">=</span> line.find(<span class="st">'-'</span>)</span>
<span id="cb17-236"><a href="#cb17-236" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Count spaces before the '-' symbol</span></span>
<span id="cb17-237"><a href="#cb17-237" aria-hidden="true" tabindex="-1"></a>                j <span class="op">=</span> symbol_index <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb17-238"><a href="#cb17-238" aria-hidden="true" tabindex="-1"></a>                <span class="cf">while</span> j <span class="op">&gt;=</span> <span class="dv">0</span> <span class="kw">and</span> line[j] <span class="op">==</span> <span class="st">' '</span>:</span>
<span id="cb17-239"><a href="#cb17-239" aria-hidden="true" tabindex="-1"></a>                    indent <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb17-240"><a href="#cb17-240" aria-hidden="true" tabindex="-1"></a>                    j <span class="op">-=</span> <span class="dv">1</span></span>
<span id="cb17-241"><a href="#cb17-241" aria-hidden="true" tabindex="-1"></a>            occurrence_indents[(title, line_num)] <span class="op">=</span> indent</span>
<span id="cb17-242"><a href="#cb17-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-243"><a href="#cb17-243" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Enhanced backward pass for correct parent-child relationships</span></span>
<span id="cb17-244"><a href="#cb17-244" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, (title, line_num) <span class="kw">in</span> <span class="bu">enumerate</span>(all_occurrences):</span>
<span id="cb17-245"><a href="#cb17-245" aria-hidden="true" tabindex="-1"></a>        current_indent <span class="op">=</span> occurrence_indents[(title, line_num)]</span>
<span id="cb17-246"><a href="#cb17-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-247"><a href="#cb17-247" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Skip root nodes (indentation 0) for processing</span></span>
<span id="cb17-248"><a href="#cb17-248" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> current_indent <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb17-249"><a href="#cb17-249" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb17-250"><a href="#cb17-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-251"><a href="#cb17-251" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Look for the immediately preceding node with lower indentation</span></span>
<span id="cb17-252"><a href="#cb17-252" aria-hidden="true" tabindex="-1"></a>        j <span class="op">=</span> i <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb17-253"><a href="#cb17-253" aria-hidden="true" tabindex="-1"></a>        <span class="cf">while</span> j <span class="op">&gt;=</span> <span class="dv">0</span>:</span>
<span id="cb17-254"><a href="#cb17-254" aria-hidden="true" tabindex="-1"></a>            prev_title, prev_line <span class="op">=</span> all_occurrences[j]</span>
<span id="cb17-255"><a href="#cb17-255" aria-hidden="true" tabindex="-1"></a>            prev_indent <span class="op">=</span> occurrence_indents[(prev_title, prev_line)]</span>
<span id="cb17-256"><a href="#cb17-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-257"><a href="#cb17-257" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If we find a node with less indentation, it's a child of current node</span></span>
<span id="cb17-258"><a href="#cb17-258" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> prev_indent <span class="op">&lt;</span> current_indent:</span>
<span id="cb17-259"><a href="#cb17-259" aria-hidden="true" tabindex="-1"></a>                <span class="co"># In BayesDown:</span></span>
<span id="cb17-260"><a href="#cb17-260" aria-hidden="true" tabindex="-1"></a>                <span class="co"># More indented node is a parent (cause) of less indented node (effect)</span></span>
<span id="cb17-261"><a href="#cb17-261" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> title <span class="kw">not</span> <span class="kw">in</span> titles_info[prev_title][<span class="st">'parents'</span>]:</span>
<span id="cb17-262"><a href="#cb17-262" aria-hidden="true" tabindex="-1"></a>                    titles_info[prev_title][<span class="st">'parents'</span>].append(title)</span>
<span id="cb17-263"><a href="#cb17-263" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> prev_title <span class="kw">not</span> <span class="kw">in</span> titles_info[title][<span class="st">'children'</span>]:</span>
<span id="cb17-264"><a href="#cb17-264" aria-hidden="true" tabindex="-1"></a>                    titles_info[title][<span class="st">'children'</span>].append(prev_title)</span>
<span id="cb17-265"><a href="#cb17-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-266"><a href="#cb17-266" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Only need to find the immediate child</span></span>
<span id="cb17-267"><a href="#cb17-267" aria-hidden="true" tabindex="-1"></a>                <span class="co"># (closest preceding node with lower indentation)</span></span>
<span id="cb17-268"><a href="#cb17-268" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb17-269"><a href="#cb17-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-270"><a href="#cb17-270" aria-hidden="true" tabindex="-1"></a>            j <span class="op">-=</span> <span class="dv">1</span></span>
<span id="cb17-271"><a href="#cb17-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-272"><a href="#cb17-272" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> titles_info</span>
<span id="cb17-273"><a href="#cb17-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-274"><a href="#cb17-274" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> convert_to_dataframe(titles_info, ArgDown):</span>
<span id="cb17-275"><a href="#cb17-275" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb17-276"><a href="#cb17-276" aria-hidden="true" tabindex="-1"></a><span class="co">    Convert the titles information dictionary to a pandas DataFrame.</span></span>
<span id="cb17-277"><a href="#cb17-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-278"><a href="#cb17-278" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb17-279"><a href="#cb17-279" aria-hidden="true" tabindex="-1"></a><span class="co">        titles_info (dict): Dictionary with information about titles</span></span>
<span id="cb17-280"><a href="#cb17-280" aria-hidden="true" tabindex="-1"></a><span class="co">        ArgDown (bool): If True, extract only structural information without probabilities</span></span>
<span id="cb17-281"><a href="#cb17-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-282"><a href="#cb17-282" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb17-283"><a href="#cb17-283" aria-hidden="true" tabindex="-1"></a><span class="co">        pandas.DataFrame: Structured data with node information and relationships</span></span>
<span id="cb17-284"><a href="#cb17-284" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-285"><a href="#cb17-285" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ArgDown <span class="op">==</span> <span class="va">True</span>:</span>
<span id="cb17-286"><a href="#cb17-286" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For ArgDown, exclude probability columns</span></span>
<span id="cb17-287"><a href="#cb17-287" aria-hidden="true" tabindex="-1"></a>        df <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">'Title'</span>, <span class="st">'Description'</span>, <span class="st">'line'</span>, <span class="st">'line_numbers'</span>, <span class="st">'indentation'</span>,</span>
<span id="cb17-288"><a href="#cb17-288" aria-hidden="true" tabindex="-1"></a>                               <span class="st">'indentation_levels'</span>, <span class="st">'Parents'</span>, <span class="st">'Children'</span>, <span class="st">'instantiations'</span>])</span>
<span id="cb17-289"><a href="#cb17-289" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb17-290"><a href="#cb17-290" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For BayesDown, include probability columns</span></span>
<span id="cb17-291"><a href="#cb17-291" aria-hidden="true" tabindex="-1"></a>        df <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">'Title'</span>, <span class="st">'Description'</span>, <span class="st">'line'</span>, <span class="st">'line_numbers'</span>, <span class="st">'indentation'</span>,</span>
<span id="cb17-292"><a href="#cb17-292" aria-hidden="true" tabindex="-1"></a>                               <span class="st">'indentation_levels'</span>, <span class="st">'Parents'</span>, <span class="st">'Children'</span>, <span class="st">'instantiations'</span>,</span>
<span id="cb17-293"><a href="#cb17-293" aria-hidden="true" tabindex="-1"></a>                               <span class="st">'priors'</span>, <span class="st">'posteriors'</span>])</span>
<span id="cb17-294"><a href="#cb17-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-295"><a href="#cb17-295" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> title, info <span class="kw">in</span> titles_info.items():</span>
<span id="cb17-296"><a href="#cb17-296" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Parse the metadata JSON string into a Python dictionary</span></span>
<span id="cb17-297"><a href="#cb17-297" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">'metadata'</span> <span class="kw">in</span> info <span class="kw">and</span> info[<span class="st">'metadata'</span>]:</span>
<span id="cb17-298"><a href="#cb17-298" aria-hidden="true" tabindex="-1"></a>            <span class="cf">try</span>:</span>
<span id="cb17-299"><a href="#cb17-299" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Only try to parse if metadata is not empty</span></span>
<span id="cb17-300"><a href="#cb17-300" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> info[<span class="st">'metadata'</span>].strip():</span>
<span id="cb17-301"><a href="#cb17-301" aria-hidden="true" tabindex="-1"></a>                    jsonMetadata <span class="op">=</span> json.loads(info[<span class="st">'metadata'</span>])</span>
<span id="cb17-302"><a href="#cb17-302" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> ArgDown <span class="op">==</span> <span class="va">True</span>:</span>
<span id="cb17-303"><a href="#cb17-303" aria-hidden="true" tabindex="-1"></a>                        <span class="co"># Create the row dictionary with instantiations as</span></span>
<span id="cb17-304"><a href="#cb17-304" aria-hidden="true" tabindex="-1"></a>                        <span class="co"># metadata only, no probabilities yet</span></span>
<span id="cb17-305"><a href="#cb17-305" aria-hidden="true" tabindex="-1"></a>                        row <span class="op">=</span> {</span>
<span id="cb17-306"><a href="#cb17-306" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'Title'</span>: title,</span>
<span id="cb17-307"><a href="#cb17-307" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'Description'</span>: info.get(<span class="st">'description'</span>, <span class="st">''</span>),</span>
<span id="cb17-308"><a href="#cb17-308" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'line'</span>: info.get(<span class="st">'line'</span>,<span class="st">''</span>),</span>
<span id="cb17-309"><a href="#cb17-309" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'line_numbers'</span>: info.get(<span class="st">'line_numbers'</span>, []),</span>
<span id="cb17-310"><a href="#cb17-310" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'indentation'</span>: info.get(<span class="st">'indentation'</span>,<span class="st">''</span>),</span>
<span id="cb17-311"><a href="#cb17-311" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'indentation_levels'</span>: info.get(<span class="st">'indentation_levels'</span>, []),</span>
<span id="cb17-312"><a href="#cb17-312" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'Parents'</span>: info.get(<span class="st">'parents'</span>, []),</span>
<span id="cb17-313"><a href="#cb17-313" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'Children'</span>: info.get(<span class="st">'children'</span>, []),</span>
<span id="cb17-314"><a href="#cb17-314" aria-hidden="true" tabindex="-1"></a>                            <span class="co"># Extract specific metadata fields,</span></span>
<span id="cb17-315"><a href="#cb17-315" aria-hidden="true" tabindex="-1"></a>                            <span class="co"># defaulting to empty if not present</span></span>
<span id="cb17-316"><a href="#cb17-316" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'instantiations'</span>: jsonMetadata.get(<span class="st">'instantiations'</span>, []),</span>
<span id="cb17-317"><a href="#cb17-317" aria-hidden="true" tabindex="-1"></a>                        }</span>
<span id="cb17-318"><a href="#cb17-318" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">else</span>:</span>
<span id="cb17-319"><a href="#cb17-319" aria-hidden="true" tabindex="-1"></a>                        <span class="co"># Create dict with probabilities for BayesDown</span></span>
<span id="cb17-320"><a href="#cb17-320" aria-hidden="true" tabindex="-1"></a>                        row <span class="op">=</span> {</span>
<span id="cb17-321"><a href="#cb17-321" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'Title'</span>: title,</span>
<span id="cb17-322"><a href="#cb17-322" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'Description'</span>: info.get(<span class="st">'description'</span>, <span class="st">''</span>),</span>
<span id="cb17-323"><a href="#cb17-323" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'line'</span>: info.get(<span class="st">'line'</span>,<span class="st">''</span>),</span>
<span id="cb17-324"><a href="#cb17-324" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'line_numbers'</span>: info.get(<span class="st">'line_numbers'</span>, []),</span>
<span id="cb17-325"><a href="#cb17-325" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'indentation'</span>: info.get(<span class="st">'indentation'</span>,<span class="st">''</span>),</span>
<span id="cb17-326"><a href="#cb17-326" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'indentation_levels'</span>: info.get(<span class="st">'indentation_levels'</span>, []),</span>
<span id="cb17-327"><a href="#cb17-327" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'Parents'</span>: info.get(<span class="st">'parents'</span>, []),</span>
<span id="cb17-328"><a href="#cb17-328" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'Children'</span>: info.get(<span class="st">'children'</span>, []),</span>
<span id="cb17-329"><a href="#cb17-329" aria-hidden="true" tabindex="-1"></a>                            <span class="co"># Extract specific metadata fields, defaulting to empty if not present</span></span>
<span id="cb17-330"><a href="#cb17-330" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'instantiations'</span>: jsonMetadata.get(<span class="st">'instantiations'</span>, []),</span>
<span id="cb17-331"><a href="#cb17-331" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'priors'</span>: jsonMetadata.get(<span class="st">'priors'</span>, {}),</span>
<span id="cb17-332"><a href="#cb17-332" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'posteriors'</span>: jsonMetadata.get(<span class="st">'posteriors'</span>, {})</span>
<span id="cb17-333"><a href="#cb17-333" aria-hidden="true" tabindex="-1"></a>                        }</span>
<span id="cb17-334"><a href="#cb17-334" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb17-335"><a href="#cb17-335" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># Empty metadata case</span></span>
<span id="cb17-336"><a href="#cb17-336" aria-hidden="true" tabindex="-1"></a>                    row <span class="op">=</span> {</span>
<span id="cb17-337"><a href="#cb17-337" aria-hidden="true" tabindex="-1"></a>                        <span class="st">'Title'</span>: title,</span>
<span id="cb17-338"><a href="#cb17-338" aria-hidden="true" tabindex="-1"></a>                        <span class="st">'Description'</span>: info.get(<span class="st">'description'</span>, <span class="st">''</span>),</span>
<span id="cb17-339"><a href="#cb17-339" aria-hidden="true" tabindex="-1"></a>                        <span class="st">'line'</span>: info.get(<span class="st">'line'</span>,<span class="st">''</span>),</span>
<span id="cb17-340"><a href="#cb17-340" aria-hidden="true" tabindex="-1"></a>                        <span class="st">'line_numbers'</span>: info.get(<span class="st">'line_numbers'</span>, []),</span>
<span id="cb17-341"><a href="#cb17-341" aria-hidden="true" tabindex="-1"></a>                        <span class="st">'indentation'</span>: info.get(<span class="st">'indentation'</span>,<span class="st">''</span>),</span>
<span id="cb17-342"><a href="#cb17-342" aria-hidden="true" tabindex="-1"></a>                        <span class="st">'indentation_levels'</span>: info.get(<span class="st">'indentation_levels'</span>, []),</span>
<span id="cb17-343"><a href="#cb17-343" aria-hidden="true" tabindex="-1"></a>                        <span class="st">'Parents'</span>: info.get(<span class="st">'parents'</span>, []),</span>
<span id="cb17-344"><a href="#cb17-344" aria-hidden="true" tabindex="-1"></a>                        <span class="st">'Children'</span>: info.get(<span class="st">'children'</span>, []),</span>
<span id="cb17-345"><a href="#cb17-345" aria-hidden="true" tabindex="-1"></a>                        <span class="st">'instantiations'</span>: [],</span>
<span id="cb17-346"><a href="#cb17-346" aria-hidden="true" tabindex="-1"></a>                        <span class="st">'priors'</span>: {},</span>
<span id="cb17-347"><a href="#cb17-347" aria-hidden="true" tabindex="-1"></a>                        <span class="st">'posteriors'</span>: {}</span>
<span id="cb17-348"><a href="#cb17-348" aria-hidden="true" tabindex="-1"></a>                    }</span>
<span id="cb17-349"><a href="#cb17-349" aria-hidden="true" tabindex="-1"></a>            <span class="cf">except</span> json.JSONDecodeError:</span>
<span id="cb17-350"><a href="#cb17-350" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Handle case where metadata isn't valid JSON</span></span>
<span id="cb17-351"><a href="#cb17-351" aria-hidden="true" tabindex="-1"></a>                row <span class="op">=</span> {</span>
<span id="cb17-352"><a href="#cb17-352" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'Title'</span>: title,</span>
<span id="cb17-353"><a href="#cb17-353" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'Description'</span>: info.get(<span class="st">'description'</span>, <span class="st">''</span>),</span>
<span id="cb17-354"><a href="#cb17-354" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'line'</span>: info.get(<span class="st">'line'</span>,<span class="st">''</span>),</span>
<span id="cb17-355"><a href="#cb17-355" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'line_numbers'</span>: info.get(<span class="st">'line_numbers'</span>, []),</span>
<span id="cb17-356"><a href="#cb17-356" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'indentation'</span>: info.get(<span class="st">'indentation'</span>,<span class="st">''</span>),</span>
<span id="cb17-357"><a href="#cb17-357" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'indentation_levels'</span>: info.get(<span class="st">'indentation_levels'</span>, []),</span>
<span id="cb17-358"><a href="#cb17-358" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'Parents'</span>: info.get(<span class="st">'parents'</span>, []),</span>
<span id="cb17-359"><a href="#cb17-359" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'Children'</span>: info.get(<span class="st">'children'</span>, []),</span>
<span id="cb17-360"><a href="#cb17-360" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'instantiations'</span>: [],</span>
<span id="cb17-361"><a href="#cb17-361" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'priors'</span>: {},</span>
<span id="cb17-362"><a href="#cb17-362" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'posteriors'</span>: {}</span>
<span id="cb17-363"><a href="#cb17-363" aria-hidden="true" tabindex="-1"></a>                }</span>
<span id="cb17-364"><a href="#cb17-364" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb17-365"><a href="#cb17-365" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Handle case where metadata field doesn't exist or is empty</span></span>
<span id="cb17-366"><a href="#cb17-366" aria-hidden="true" tabindex="-1"></a>            row <span class="op">=</span> {</span>
<span id="cb17-367"><a href="#cb17-367" aria-hidden="true" tabindex="-1"></a>                <span class="st">'Title'</span>: title,</span>
<span id="cb17-368"><a href="#cb17-368" aria-hidden="true" tabindex="-1"></a>                <span class="st">'Description'</span>: info.get(<span class="st">'description'</span>, <span class="st">''</span>),</span>
<span id="cb17-369"><a href="#cb17-369" aria-hidden="true" tabindex="-1"></a>                <span class="st">'line'</span>: info.get(<span class="st">'line'</span>,<span class="st">''</span>),</span>
<span id="cb17-370"><a href="#cb17-370" aria-hidden="true" tabindex="-1"></a>                <span class="st">'line_numbers'</span>: info.get(<span class="st">'line_numbers'</span>, []),</span>
<span id="cb17-371"><a href="#cb17-371" aria-hidden="true" tabindex="-1"></a>                <span class="st">'indentation'</span>: info.get(<span class="st">'indentation'</span>,<span class="st">''</span>),</span>
<span id="cb17-372"><a href="#cb17-372" aria-hidden="true" tabindex="-1"></a>                <span class="st">'indentation_levels'</span>: info.get(<span class="st">'indentation_levels'</span>, []),</span>
<span id="cb17-373"><a href="#cb17-373" aria-hidden="true" tabindex="-1"></a>                <span class="st">'Parents'</span>: info.get(<span class="st">'parents'</span>, []),</span>
<span id="cb17-374"><a href="#cb17-374" aria-hidden="true" tabindex="-1"></a>                <span class="st">'Children'</span>: info.get(<span class="st">'children'</span>, []),</span>
<span id="cb17-375"><a href="#cb17-375" aria-hidden="true" tabindex="-1"></a>                <span class="st">'instantiations'</span>: [],</span>
<span id="cb17-376"><a href="#cb17-376" aria-hidden="true" tabindex="-1"></a>                <span class="st">'priors'</span>: {},</span>
<span id="cb17-377"><a href="#cb17-377" aria-hidden="true" tabindex="-1"></a>                <span class="st">'posteriors'</span>: {}</span>
<span id="cb17-378"><a href="#cb17-378" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb17-379"><a href="#cb17-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-380"><a href="#cb17-380" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add the row to the DataFrame</span></span>
<span id="cb17-381"><a href="#cb17-381" aria-hidden="true" tabindex="-1"></a>        df.loc[<span class="bu">len</span>(df)] <span class="op">=</span> row</span>
<span id="cb17-382"><a href="#cb17-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-383"><a href="#cb17-383" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df</span>
<span id="cb17-384"><a href="#cb17-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-385"><a href="#cb17-385" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> add_no_parent_no_child_columns_to_df(dataframe):</span>
<span id="cb17-386"><a href="#cb17-386" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb17-387"><a href="#cb17-387" aria-hidden="true" tabindex="-1"></a><span class="co">    Add No_Parent and No_Children boolean columns to the DataFrame to</span></span>
<span id="cb17-388"><a href="#cb17-388" aria-hidden="true" tabindex="-1"></a><span class="co">    identify root and leaf nodes.</span></span>
<span id="cb17-389"><a href="#cb17-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-390"><a href="#cb17-390" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb17-391"><a href="#cb17-391" aria-hidden="true" tabindex="-1"></a><span class="co">        dataframe (pandas.DataFrame): The DataFrame to enhance</span></span>
<span id="cb17-392"><a href="#cb17-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-393"><a href="#cb17-393" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb17-394"><a href="#cb17-394" aria-hidden="true" tabindex="-1"></a><span class="co">        pandas.DataFrame: Enhanced DataFrame with additional boolean columns</span></span>
<span id="cb17-395"><a href="#cb17-395" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-396"><a href="#cb17-396" aria-hidden="true" tabindex="-1"></a>    no_parent <span class="op">=</span> []</span>
<span id="cb17-397"><a href="#cb17-397" aria-hidden="true" tabindex="-1"></a>    no_children <span class="op">=</span> []</span>
<span id="cb17-398"><a href="#cb17-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-399"><a href="#cb17-399" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _, row <span class="kw">in</span> dataframe.iterrows():</span>
<span id="cb17-400"><a href="#cb17-400" aria-hidden="true" tabindex="-1"></a>        no_parent.append(<span class="kw">not</span> row[<span class="st">'Parents'</span>])  <span class="co"># True if Parents list is empty</span></span>
<span id="cb17-401"><a href="#cb17-401" aria-hidden="true" tabindex="-1"></a>        no_children.append(<span class="kw">not</span> row[<span class="st">'Children'</span>])  <span class="co"># True if Children list is empty</span></span>
<span id="cb17-402"><a href="#cb17-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-403"><a href="#cb17-403" aria-hidden="true" tabindex="-1"></a>    dataframe[<span class="st">'No_Parent'</span>] <span class="op">=</span> no_parent</span>
<span id="cb17-404"><a href="#cb17-404" aria-hidden="true" tabindex="-1"></a>    dataframe[<span class="st">'No_Children'</span>] <span class="op">=</span> no_children</span>
<span id="cb17-405"><a href="#cb17-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-406"><a href="#cb17-406" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dataframe</span>
<span id="cb17-407"><a href="#cb17-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-408"><a href="#cb17-408" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> add_parents_instantiation_columns_to_df(dataframe):</span>
<span id="cb17-409"><a href="#cb17-409" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb17-410"><a href="#cb17-410" aria-hidden="true" tabindex="-1"></a><span class="co">    Add all possible instantiations of parents as a list of lists column</span></span>
<span id="cb17-411"><a href="#cb17-411" aria-hidden="true" tabindex="-1"></a><span class="co">    to the DataFrame.</span></span>
<span id="cb17-412"><a href="#cb17-412" aria-hidden="true" tabindex="-1"></a><span class="co">    This is crucial for generating conditional probability tables.</span></span>
<span id="cb17-413"><a href="#cb17-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-414"><a href="#cb17-414" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb17-415"><a href="#cb17-415" aria-hidden="true" tabindex="-1"></a><span class="co">        dataframe (pandas.DataFrame): The DataFrame to enhance</span></span>
<span id="cb17-416"><a href="#cb17-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-417"><a href="#cb17-417" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb17-418"><a href="#cb17-418" aria-hidden="true" tabindex="-1"></a><span class="co">        pandas.DataFrame: Enhanced DataFrame with parent_instantiations column</span></span>
<span id="cb17-419"><a href="#cb17-419" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-420"><a href="#cb17-420" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a new column to store parent instantiations</span></span>
<span id="cb17-421"><a href="#cb17-421" aria-hidden="true" tabindex="-1"></a>    parent_instantiations <span class="op">=</span> []</span>
<span id="cb17-422"><a href="#cb17-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-423"><a href="#cb17-423" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Iterate through each row in the dataframe</span></span>
<span id="cb17-424"><a href="#cb17-424" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _, row <span class="kw">in</span> dataframe.iterrows():</span>
<span id="cb17-425"><a href="#cb17-425" aria-hidden="true" tabindex="-1"></a>        parents <span class="op">=</span> row[<span class="st">'Parents'</span>]</span>
<span id="cb17-426"><a href="#cb17-426" aria-hidden="true" tabindex="-1"></a>        parent_insts <span class="op">=</span> []</span>
<span id="cb17-427"><a href="#cb17-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-428"><a href="#cb17-428" aria-hidden="true" tabindex="-1"></a>        <span class="co"># For each parent, find its instantiations and add to the list</span></span>
<span id="cb17-429"><a href="#cb17-429" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> parent <span class="kw">in</span> parents:</span>
<span id="cb17-430"><a href="#cb17-430" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Find the row where Title matches the parent</span></span>
<span id="cb17-431"><a href="#cb17-431" aria-hidden="true" tabindex="-1"></a>            parent_row <span class="op">=</span> dataframe[dataframe[<span class="st">'Title'</span>] <span class="op">==</span> parent]</span>
<span id="cb17-432"><a href="#cb17-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-433"><a href="#cb17-433" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If parent found in the dataframe</span></span>
<span id="cb17-434"><a href="#cb17-434" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="kw">not</span> parent_row.empty:</span>
<span id="cb17-435"><a href="#cb17-435" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Get the instantiations of this parent</span></span>
<span id="cb17-436"><a href="#cb17-436" aria-hidden="true" tabindex="-1"></a>                parent_instantiation <span class="op">=</span> parent_row[<span class="st">'instantiations'</span>].iloc[<span class="dv">0</span>]</span>
<span id="cb17-437"><a href="#cb17-437" aria-hidden="true" tabindex="-1"></a>                parent_insts.append(parent_instantiation)</span>
<span id="cb17-438"><a href="#cb17-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-439"><a href="#cb17-439" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add the list of parent instantiations to our new column</span></span>
<span id="cb17-440"><a href="#cb17-440" aria-hidden="true" tabindex="-1"></a>        parent_instantiations.append(parent_insts)</span>
<span id="cb17-441"><a href="#cb17-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-442"><a href="#cb17-442" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add the new column to the dataframe</span></span>
<span id="cb17-443"><a href="#cb17-443" aria-hidden="true" tabindex="-1"></a>    dataframe[<span class="st">'parent_instantiations'</span>] <span class="op">=</span> parent_instantiations</span>
<span id="cb17-444"><a href="#cb17-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-445"><a href="#cb17-445" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dataframe</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
<!-- 
#| label: parsing_argdown_bayesdown
#| echo: true
#| eval: true
#| fig-cap: "Parsing ArgDown & BayesDown"
#| fig-link: "https://colab.research.google.com/github/VJMeyer/submission/blob/main/AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb#scrollTo=LTDQOBd7COIm&line=8&uniqifier=1"
#| fig-alt: "Parsing ArgDown & BayesDown"
-->
<p>The structure revealed insights. “Misaligned_Power_Seeking” emerged as a critical hub, influenced by multiple factors and influencing multiple outcomes. The pathway from incentives through deployment to risk became explicit.</p>
<!-- [-] COMPLETED: Added extraction details -->
</section>
</section>
<section id="sec-carlsmith-bayesdown" class="level3">
<h3 class="anchored" data-anchor-id="sec-carlsmith-bayesdown">3.5.3 From ArgDown to BayesDown in Carlsmith’s Model</h3>
<p>Adding probabilities to Carlsmith’s structure presented unique challenges. Unlike rain-sprinkler probabilities that have intuitive values, what’s the probability of “mesa-optimization” or “deceptive alignment”?</p>
<p>The system generated over 100 probability questions for the full model. <!-- 
```markdown
For [Deployment_Decisions]:
- What is P(deploy)?
- What is P(deploy|strong_incentives, deception)?
- What is P(deploy|strong_incentives, no_deception)?
- What is P(deploy|weak_incentives, deception)?
- What is P(deploy|weak_incentives, no_deception)?
``` --></p>
<p>Each question targets a specific parameter needed for the Bayesian network. The conditional structure reflects Carlsmith’s argument—deployment depends on both incentives (external pressure) and deception (hidden misalignment).</p>
<p>The LLM extraction drew on Carlsmith’s explicit estimates where available and inferred reasonable values elsewhere. The result captured both the structure and Carlsmith’s quantitative risk assessment:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="ot">[</span><span class="er">Deployment_Decisions</span><span class="ot">]</span><span class="er">:</span> <span class="er">Decisions</span> <span class="er">to</span> <span class="er">deploy</span> <span class="er">potentially</span> <span class="er">misaligned</span> <span class="er">AI</span> <span class="er">systems.</span> <span class="fu">{</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"instantiations"</span><span class="fu">:</span> <span class="ot">[</span><span class="st">"deployment_decisions_DEPLOY"</span><span class="ot">,</span> <span class="st">"deployment_decisions_WITHHOLD"</span><span class="ot">]</span><span class="fu">,</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"priors"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"p(deployment_decisions_DEPLOY)"</span><span class="fu">:</span> <span class="st">"0.70"</span><span class="fu">,</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"p(deployment_decisions_WITHHOLD)"</span><span class="fu">:</span> <span class="st">"0.30"</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">},</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"posteriors"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"p(deployment_decisions_DEPLOY|incentives_to_build_aps_STRONG, deception_by_ai_TRUE)"</span><span class="fu">:</span> <span class="st">"0.90"</span><span class="fu">,</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"p(deployment_decisions_DEPLOY|incentives_to_build_aps_STRONG, deception_by_ai_FALSE)"</span><span class="fu">:</span> <span class="st">"0.75"</span><span class="fu">,</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"p(deployment_decisions_DEPLOY|incentives_to_build_aps_WEAK, deception_by_ai_TRUE)"</span><span class="fu">:</span> <span class="st">"0.60"</span><span class="fu">,</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"p(deployment_decisions_DEPLOY|incentives_to_build_aps_WEAK, deception_by_ai_FALSE)"</span><span class="fu">:</span> <span class="st">"0.30"</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">}</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<!-- 
```json
[Deployment_Decisions]: Decisions to deploy potentially misaligned AI. {
  "instantiations": ["deploy", "withhold"],
  "priors": {"p(deploy)": "0.70", "p(withhold)": "0.30"},
  "posteriors": {
    "p(deploy|strong_incentives,deception)": "0.90",
    "p(deploy|strong_incentives,no_deception)": "0.75",
    "p(deploy|weak_incentives,deception)": "0.60",
    "p(deploy|weak_incentives,no_deception)": "0.30"
  }
}
```
-->
<!-- [-] COMPLETED: Added BayesDown transformation -->
<p>This node has two possible states (DEPLOY or WITHHOLD), prior probabilities for each state, and conditional probabilities based on different combinations of its parent variables (“Incentives_To_Build_APS” and “Deception_By_AI”). The probabilities tell a plausible story: deployment becomes more likely with stronger incentives and successful deception, but even without deception, strong incentives create substantial deployment probability.</p>
<!-- 
#| label: generate_bayesdown
#| echo: true
#| eval: true
#| fig-cap: "Questions Generated for BayesDown Extraction from Carlsmith model"
#| fig-link: "https://colab.research.google.com/github/VJMeyer/submission/blob/main/AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb#scrollTo=lBLyoERIT557&line=1&uniqifier=1"
#| fig-alt: "Questions Generated for BayesDown Extraction from Carlsmith model"
-->
<p>Along with these questions the following prompt is sent to the LLM:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="er">You</span> <span class="er">are</span> <span class="er">an</span> <span class="er">expert</span> <span class="er">in</span> <span class="er">probabilistic</span> <span class="er">reasoning</span> <span class="er">and</span> <span class="er">Bayesian</span> <span class="er">networks.</span> <span class="er">Your</span> <span class="er">task</span> <span class="er">is</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="er">to</span> <span class="er">extend</span> <span class="er">the</span> <span class="er">provided</span> <span class="er">ArgDown</span> <span class="er">structure</span> <span class="er">with</span> <span class="er">probability</span> <span class="er">information,</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="er">creating</span> <span class="er">a</span> <span class="er">BayesDown</span> <span class="er">representation.</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="er">For</span> <span class="er">each</span> <span class="er">statement</span> <span class="er">in</span> <span class="er">the</span> <span class="er">ArgDown</span> <span class="er">structure,</span> <span class="er">you</span> <span class="er">need</span> <span class="er">to:</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="er">1.</span> <span class="er">Estimate</span> <span class="er">prior</span> <span class="er">probabilities</span> <span class="er">for</span> <span class="er">each</span> <span class="er">possible</span> <span class="er">state</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="er">2.</span> <span class="er">Estimate</span> <span class="er">conditional</span> <span class="er">probabilities</span> <span class="er">given</span> <span class="er">parent</span> <span class="er">states</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="er">3.</span> <span class="er">Maintain</span> <span class="er">the</span> <span class="er">original</span> <span class="er">structure</span> <span class="er">and</span> <span class="er">relationships</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="er">Here</span> <span class="er">is</span> <span class="er">the</span> <span class="er">format</span> <span class="er">to</span> <span class="er">follow:</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="ot">[</span><span class="er">Node</span><span class="ot">]</span><span class="er">:</span> <span class="er">Description.</span> <span class="fu">{</span> <span class="dt">"instantiations"</span><span class="fu">:</span> <span class="ot">[</span><span class="st">"node_TRUE"</span><span class="ot">,</span> <span class="st">"node_FALSE"</span><span class="ot">]</span><span class="fu">,</span> <span class="dt">"priors"</span><span class="fu">:</span> <span class="fu">{</span> <span class="dt">"p(node_TRUE)"</span><span class="fu">:</span> <span class="st">"0.7"</span><span class="fu">,</span> <span class="dt">"p(node_FALSE)"</span><span class="fu">:</span> <span class="st">"0.3"</span> <span class="fu">},</span> <span class="dt">"posteriors"</span><span class="fu">:</span> <span class="fu">{</span> <span class="dt">"p(node_TRUE|parent_TRUE)"</span><span class="fu">:</span> <span class="st">"0.9"</span><span class="fu">,</span> <span class="dt">"p(node_TRUE|parent_FALSE)"</span><span class="fu">:</span> <span class="st">"0.4"</span><span class="fu">,</span> <span class="dt">"p(node_FALSE|parent_TRUE)"</span><span class="fu">:</span> <span class="st">"0.1"</span><span class="fu">,</span> <span class="dt">"p(node_FALSE|parent_FALSE)"</span><span class="fu">:</span> <span class="st">"0.6"</span> <span class="fu">}</span> <span class="fu">}</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a> <span class="ot">[</span><span class="er">Parent</span><span class="ot">]</span><span class="er">:</span> <span class="er">Parent</span> <span class="er">description.</span> <span class="fu">{</span><span class="er">...</span><span class="fu">}</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="er">Here</span> <span class="er">are</span> <span class="er">the</span> <span class="er">specific</span> <span class="er">probability</span> <span class="er">questions</span> <span class="er">to</span> <span class="er">answer:</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a><span class="er">$questions</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a><span class="er">ArgDown</span> <span class="er">structure</span> <span class="er">to</span> <span class="er">enhance:</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a><span class="er">$argdown</span></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a><span class="er">Provide</span> <span class="er">the</span> <span class="er">complete</span> <span class="er">BayesDown</span> <span class="er">representation</span> <span class="er">with</span> <span class="er">probabilities:</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="example-bayesdown-excerpt-from-the-carlsmith-model" class="level4">
<h4 class="anchored" data-anchor-id="example-bayesdown-excerpt-from-the-carlsmith-model">Example BayesDown Excerpt from the Carlsmith model</h4>
<div class="sourceCode" id="cb20"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="er">#|</span> <span class="er">label:</span> <span class="er">json_carlsmith_excerpt</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="er">#|</span> <span class="er">echo:</span> <span class="er">true</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="er">#|</span> <span class="er">eval:</span> <span class="er">true</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="er">#|</span> <span class="er">fig-cap:</span> <span class="er">"Example</span> <span class="er">BayesDown</span> <span class="er">Excerpt</span> <span class="er">from</span> <span class="er">the</span> <span class="er">Carlsmith</span> <span class="er">model"</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="er">#|</span> <span class="er">fig-link:</span> <span class="er">"https://colab.research.google.com/github/VJMeyer/submission/blob/main/AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb#scrollTo=AFnu_1Ludahi"</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="er">#|</span> <span class="er">fig-alt:</span> <span class="er">"Example</span> <span class="er">BayesDown</span> <span class="er">Excerpt</span> <span class="er">from</span> <span class="er">the</span> <span class="er">Carlsmith</span> <span class="er">model"</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="ot">[</span><span class="er">Existential_Catastrophe</span><span class="ot">]</span><span class="er">:</span> <span class="er">The</span> <span class="er">destruction</span> <span class="er">of</span> <span class="er">humanity's</span> <span class="er">long-term</span> <span class="er">potential</span> <span class="er">due</span> <span class="er">to</span> <span class="er">AI</span> <span class="er">systems</span> <span class="er">we've</span> <span class="er">lost</span> <span class="er">control</span> <span class="er">over.</span> <span class="fu">{</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"instantiations"</span><span class="fu">:</span> <span class="ot">[</span><span class="st">"existential_catastrophe_TRUE"</span><span class="ot">,</span> <span class="st">"existential_catastrophe_FALSE"</span><span class="ot">]</span><span class="fu">,</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"priors"</span><span class="fu">:</span> <span class="fu">{</span><span class="dt">"p(existential_catastrophe_TRUE)"</span><span class="fu">:</span> <span class="st">"0.05"</span><span class="fu">,</span> <span class="dt">"p(existential_catastrophe_FALSE)"</span><span class="fu">:</span> <span class="st">"0.95"</span><span class="fu">},</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"posteriors"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"p(existential_catastrophe_TRUE|human_disempowerment_TRUE)"</span><span class="fu">:</span> <span class="st">"0.95"</span><span class="fu">,</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"p(existential_catastrophe_TRUE|human_disempowerment_FALSE)"</span><span class="fu">:</span> <span class="st">"0.0"</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">}</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a> <span class="er">+</span> <span class="ot">[</span><span class="er">Human_Disempowerment</span><span class="ot">]</span><span class="er">:</span> <span class="er">Permanent</span> <span class="er">and</span> <span class="er">collective</span> <span class="er">disempowerment</span> <span class="er">of</span> <span class="er">humanity</span> <span class="er">relative</span> <span class="er">to</span> <span class="er">AI</span> <span class="er">systems.</span> <span class="fu">{</span></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>   <span class="dt">"instantiations"</span><span class="fu">:</span> <span class="ot">[</span><span class="st">"human_disempowerment_TRUE"</span><span class="ot">,</span> <span class="st">"human_disempowerment_FALSE"</span><span class="ot">]</span><span class="fu">,</span></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>   <span class="dt">"priors"</span><span class="fu">:</span> <span class="fu">{</span><span class="dt">"p(human_disempowerment_TRUE)"</span><span class="fu">:</span> <span class="st">"0.208"</span><span class="fu">,</span> <span class="dt">"p(human_disempowerment_FALSE)"</span><span class="fu">:</span> <span class="st">"0.792"</span><span class="fu">},</span></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>   <span class="dt">"posteriors"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>     <span class="dt">"p(human_disempowerment_TRUE|scale_of_power_seeking_TRUE)"</span><span class="fu">:</span> <span class="st">"1.0"</span><span class="fu">,</span></span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>     <span class="dt">"p(human_disempowerment_TRUE|scale_of_power_seeking_FALSE)"</span><span class="fu">:</span> <span class="st">"0.0"</span></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>   <span class="fu">}</span></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a> <span class="fu">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This excerpt from the Carlsmith model representation illustrates how BayesDown preserves both the narrative description (“The destruction of humanity’s long-term potential…”) and the precise probability judgments. Someone without technical background can still understand the core claims and their relationships, while someone seeking quantitative precision can find exact probability values.</p>
<p>The format supports multiple levels of engagement. At the most basic level, readers can follow the hierarchical structure to understand causal relationships between factors. At an intermediate level, they can examine probability judgments to assess the strength of different influences. At the most technical level, they can analyze the complete probabilistic model to perform inference and sensitivity analysis.</p>
</section>
</section>
<section id="sec-practically-meaningful" class="level3">
<h3 class="anchored" data-anchor-id="sec-practically-meaningful">3.5.4 Practically Meaningful BayesDown</h3>
<p>The BayesDown representation achieves something remarkable: it bridges the chasm between Carlsmith’s nuanced prose and mathematical formalism without losing the essence of either.</p>
<p>Consider what this bridge enables:</p>
<p><strong>For Technical Researchers</strong>: The formal structure makes assumptions explicit. Is power-seeking really independent of capability level given strategic awareness? The model forces clarity.</p>
<p><strong>For Policymakers</strong>: Probabilities attached to comprehensible descriptions provide actionable intelligence. “70% chance of deployment despite misalignment” translates better than abstract concerns.</p>
<p><strong>For Strategic Analysts</strong>: The network structure reveals intervention points. Which nodes, if changed, most affect the final outcome? Where should we focus effort?</p>
<p>The hybrid nature—natural language plus formal structure plus probabilities—serves each audience while enabling communication between them. A policymaker can understand “deployment decisions” without probability theory. A researcher can analyze the mathematical model without losing sight of what the variables mean.</p>
<p>This isn’t just convenient—it’s essential for coordination. When different communities can refer to the same model but engage with it at their appropriate level of technical detail, we create common ground for productive disagreement and collaborative problem-solving.</p>
<!-- [-] COMPLETED: Added practical meaning -->
</section>
<section id="sec-interactive-visualization" class="level3">
<h3 class="anchored" data-anchor-id="sec-interactive-visualization">3.5.5 Interactive Visualization and Exploration</h3>
<p>The moment when Carlsmith’s model first rendered as an interactive network felt like putting on glasses after years of squinting. Suddenly, the complex web of relationships became navigable.</p>
<p>The visualization system employs multiple visual channels simultaneously:</p>
<p><strong>Color Coding</strong>: Nodes shift from deep red (low probability) through yellow to bright green (high probability). At a glance, you see which factors Carlsmith considers likely versus speculative.</p>
<p><strong>Border Styling</strong>: Blue borders mark root causes (like “Incentives_To_Build”), purple indicates intermediate nodes, magenta highlights final outcomes. The visual grammar guides the eye through causal flow.</p>
<p><strong>Layout Algorithm</strong>: Initial placement uses causal depth—root causes at bottom, final outcomes at top. Physics simulation then refines positions to minimize edge crossings while preserving hierarchical structure.</p>
<p><strong>Progressive Disclosure</strong>: Hovering reveals probability summaries. Clicking opens detailed conditional probability tables. Dragging allows custom arrangement. Each interaction level serves different analytical needs.</p>
<p>The figure below shows the interactive visualization of Carlsmith’s model, highlighting how color, border styling, and layout work together to represent complex causal relationships:</p>
<div class="quarto-embed-nb-cell" data-notebook="/Users/vjm/Library/Mobile Documents/iCloud~md~obsidian/Documents/Vaulty/2_DoingGood/Studies/P&amp;E/Specializations/Test_Sync_MAThesis/submission/AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb" data-notebook-title="[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)" data-notebook-cellid="cell-main_visualization_function">
<div id="main_visualization_function" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># @title 4.4.0 --- Main Visualization Function --- [main_visualization_function]</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_bayesian_network_with_probabilities(df):</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Create an interactive Bayesian network visualization with enhanced</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co">    probability visualization and node classification based on network structure.</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a directed graph</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    G <span class="op">=</span> nx.DiGraph()</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add nodes with proper attributes</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx, row <span class="kw">in</span> df.iterrows():</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>        title <span class="op">=</span> row[<span class="st">'Title'</span>]</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>        description <span class="op">=</span> row[<span class="st">'Description'</span>]</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Process probability information</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>        priors <span class="op">=</span> get_priors(row)</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>        instantiations <span class="op">=</span> get_instantiations(row)</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add node with base information</span></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>        G.add_node(</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>            title,</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>            description<span class="op">=</span>description,</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>            priors<span class="op">=</span>priors,</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>            instantiations<span class="op">=</span>instantiations,</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>            posteriors<span class="op">=</span>get_posteriors(row)</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add edges</span></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx, row <span class="kw">in</span> df.iterrows():</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>        child <span class="op">=</span> row[<span class="st">'Title'</span>]</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>        parents <span class="op">=</span> get_parents(row)</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add edges from each parent to this child</span></span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> parent <span class="kw">in</span> parents:</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> parent <span class="kw">in</span> G.nodes():</span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>                G.add_edge(parent, child)</span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Classify nodes based on network structure</span></span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a>    classify_nodes(G)</span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create network visualization</span></span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a>    net <span class="op">=</span> Network(notebook<span class="op">=</span><span class="va">True</span>, directed<span class="op">=</span><span class="va">True</span>, cdn_resources<span class="op">=</span><span class="st">"in_line"</span>, height<span class="op">=</span><span class="st">"600px"</span>, width<span class="op">=</span><span class="st">"100%"</span>)</span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Configure physics for better layout</span></span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a>    net.force_atlas_2based(gravity<span class="op">=-</span><span class="dv">50</span>, spring_length<span class="op">=</span><span class="dv">100</span>, spring_strength<span class="op">=</span><span class="fl">0.02</span>)</span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a>    net.show_buttons(filter_<span class="op">=</span>[<span class="st">'physics'</span>])</span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add the graph to the network</span></span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a>    net.from_nx(G)</span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Enhance node appearance with probability information and classification</span></span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> node <span class="kw">in</span> net.nodes:</span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a>        node_id <span class="op">=</span> node[<span class="st">'id'</span>]</span>
<span id="cb21-55"><a href="#cb21-55" aria-hidden="true" tabindex="-1"></a>        node_data <span class="op">=</span> G.nodes[node_id]</span>
<span id="cb21-56"><a href="#cb21-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-57"><a href="#cb21-57" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get node type and set border color</span></span>
<span id="cb21-58"><a href="#cb21-58" aria-hidden="true" tabindex="-1"></a>        node_type <span class="op">=</span> node_data.get(<span class="st">'node_type'</span>, <span class="st">'unknown'</span>)</span>
<span id="cb21-59"><a href="#cb21-59" aria-hidden="true" tabindex="-1"></a>        border_color <span class="op">=</span> get_border_color(node_type)</span>
<span id="cb21-60"><a href="#cb21-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-61"><a href="#cb21-61" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get probability information</span></span>
<span id="cb21-62"><a href="#cb21-62" aria-hidden="true" tabindex="-1"></a>        priors <span class="op">=</span> node_data.get(<span class="st">'priors'</span>, {})</span>
<span id="cb21-63"><a href="#cb21-63" aria-hidden="true" tabindex="-1"></a>        true_prob <span class="op">=</span> priors.get(<span class="st">'true_prob'</span>, <span class="fl">0.5</span>) <span class="cf">if</span> priors <span class="cf">else</span> <span class="fl">0.5</span></span>
<span id="cb21-64"><a href="#cb21-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-65"><a href="#cb21-65" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get proper state names</span></span>
<span id="cb21-66"><a href="#cb21-66" aria-hidden="true" tabindex="-1"></a>        instantiations <span class="op">=</span> node_data.get(<span class="st">'instantiations'</span>, [<span class="st">"TRUE"</span>, <span class="st">"FALSE"</span>])</span>
<span id="cb21-67"><a href="#cb21-67" aria-hidden="true" tabindex="-1"></a>        true_state <span class="op">=</span> instantiations[<span class="dv">0</span>] <span class="cf">if</span> <span class="bu">len</span>(instantiations) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="st">"TRUE"</span></span>
<span id="cb21-68"><a href="#cb21-68" aria-hidden="true" tabindex="-1"></a>        false_state <span class="op">=</span> instantiations[<span class="dv">1</span>] <span class="cf">if</span> <span class="bu">len</span>(instantiations) <span class="op">&gt;</span> <span class="dv">1</span> <span class="cf">else</span> <span class="st">"FALSE"</span></span>
<span id="cb21-69"><a href="#cb21-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-70"><a href="#cb21-70" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create background color based on probability</span></span>
<span id="cb21-71"><a href="#cb21-71" aria-hidden="true" tabindex="-1"></a>        background_color <span class="op">=</span> get_probability_color(priors)</span>
<span id="cb21-72"><a href="#cb21-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-73"><a href="#cb21-73" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create tooltip with probability information</span></span>
<span id="cb21-74"><a href="#cb21-74" aria-hidden="true" tabindex="-1"></a>        tooltip <span class="op">=</span> create_tooltip(node_id, node_data)</span>
<span id="cb21-75"><a href="#cb21-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-76"><a href="#cb21-76" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create a simpler node label with probability</span></span>
<span id="cb21-77"><a href="#cb21-77" aria-hidden="true" tabindex="-1"></a>        simple_label <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>node_id<span class="sc">}</span><span class="ch">\n</span><span class="ss">p=</span><span class="sc">{</span>true_prob<span class="sc">:.2f}</span><span class="ss">"</span></span>
<span id="cb21-78"><a href="#cb21-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-79"><a href="#cb21-79" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Store expanded content as a node attribute for use in click handler</span></span>
<span id="cb21-80"><a href="#cb21-80" aria-hidden="true" tabindex="-1"></a>        node_data[<span class="st">'expanded_content'</span>] <span class="op">=</span> create_expanded_content(node_id, node_data)</span>
<span id="cb21-81"><a href="#cb21-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-82"><a href="#cb21-82" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Set node attributes</span></span>
<span id="cb21-83"><a href="#cb21-83" aria-hidden="true" tabindex="-1"></a>        node[<span class="st">'title'</span>] <span class="op">=</span> tooltip  <span class="co"># Tooltip HTML</span></span>
<span id="cb21-84"><a href="#cb21-84" aria-hidden="true" tabindex="-1"></a>        node[<span class="st">'label'</span>] <span class="op">=</span> simple_label  <span class="co"># Simple text label</span></span>
<span id="cb21-85"><a href="#cb21-85" aria-hidden="true" tabindex="-1"></a>        node[<span class="st">'shape'</span>] <span class="op">=</span> <span class="st">'box'</span></span>
<span id="cb21-86"><a href="#cb21-86" aria-hidden="true" tabindex="-1"></a>        node[<span class="st">'color'</span>] <span class="op">=</span> {</span>
<span id="cb21-87"><a href="#cb21-87" aria-hidden="true" tabindex="-1"></a>            <span class="st">'background'</span>: background_color,</span>
<span id="cb21-88"><a href="#cb21-88" aria-hidden="true" tabindex="-1"></a>            <span class="st">'border'</span>: border_color,</span>
<span id="cb21-89"><a href="#cb21-89" aria-hidden="true" tabindex="-1"></a>            <span class="st">'highlight'</span>: {</span>
<span id="cb21-90"><a href="#cb21-90" aria-hidden="true" tabindex="-1"></a>                <span class="st">'background'</span>: background_color,</span>
<span id="cb21-91"><a href="#cb21-91" aria-hidden="true" tabindex="-1"></a>                <span class="st">'border'</span>: border_color</span>
<span id="cb21-92"><a href="#cb21-92" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb21-93"><a href="#cb21-93" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb21-94"><a href="#cb21-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-95"><a href="#cb21-95" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set up the click handler with proper data</span></span>
<span id="cb21-96"><a href="#cb21-96" aria-hidden="true" tabindex="-1"></a>    setup_data <span class="op">=</span> {</span>
<span id="cb21-97"><a href="#cb21-97" aria-hidden="true" tabindex="-1"></a>        <span class="st">'nodes_data'</span>: {node_id: {</span>
<span id="cb21-98"><a href="#cb21-98" aria-hidden="true" tabindex="-1"></a>            <span class="st">'expanded_content'</span>: json.dumps(G.nodes[node_id].get(<span class="st">'expanded_content'</span>, <span class="st">''</span>)),</span>
<span id="cb21-99"><a href="#cb21-99" aria-hidden="true" tabindex="-1"></a>            <span class="st">'description'</span>: G.nodes[node_id].get(<span class="st">'description'</span>, <span class="st">''</span>),</span>
<span id="cb21-100"><a href="#cb21-100" aria-hidden="true" tabindex="-1"></a>            <span class="st">'priors'</span>: G.nodes[node_id].get(<span class="st">'priors'</span>, {}),</span>
<span id="cb21-101"><a href="#cb21-101" aria-hidden="true" tabindex="-1"></a>            <span class="st">'posteriors'</span>: G.nodes[node_id].get(<span class="st">'posteriors'</span>, {})</span>
<span id="cb21-102"><a href="#cb21-102" aria-hidden="true" tabindex="-1"></a>        } <span class="cf">for</span> node_id <span class="kw">in</span> G.nodes()}</span>
<span id="cb21-103"><a href="#cb21-103" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb21-104"><a href="#cb21-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-105"><a href="#cb21-105" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add custom click handling JavaScript</span></span>
<span id="cb21-106"><a href="#cb21-106" aria-hidden="true" tabindex="-1"></a>    click_js <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb21-107"><a href="#cb21-107" aria-hidden="true" tabindex="-1"></a><span class="st">    // Store node data for click handling</span></span>
<span id="cb21-108"><a href="#cb21-108" aria-hidden="true" tabindex="-1"></a><span class="st">    var nodesData = </span><span class="sc">%s</span><span class="st">;</span></span>
<span id="cb21-109"><a href="#cb21-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-110"><a href="#cb21-110" aria-hidden="true" tabindex="-1"></a><span class="st">    // Add event listener for node clicks</span></span>
<span id="cb21-111"><a href="#cb21-111" aria-hidden="true" tabindex="-1"></a><span class="st">    network.on("click", function(params) {</span></span>
<span id="cb21-112"><a href="#cb21-112" aria-hidden="true" tabindex="-1"></a><span class="st">        if (params.nodes.length &gt; 0) {</span></span>
<span id="cb21-113"><a href="#cb21-113" aria-hidden="true" tabindex="-1"></a><span class="st">            var nodeId = params.nodes[0];</span></span>
<span id="cb21-114"><a href="#cb21-114" aria-hidden="true" tabindex="-1"></a><span class="st">            var nodeInfo = nodesData[nodeId];</span></span>
<span id="cb21-115"><a href="#cb21-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-116"><a href="#cb21-116" aria-hidden="true" tabindex="-1"></a><span class="st">            if (nodeInfo) {</span></span>
<span id="cb21-117"><a href="#cb21-117" aria-hidden="true" tabindex="-1"></a><span class="st">                // Create a modal popup for expanded content</span></span>
<span id="cb21-118"><a href="#cb21-118" aria-hidden="true" tabindex="-1"></a><span class="st">                var modal = document.createElement('div');</span></span>
<span id="cb21-119"><a href="#cb21-119" aria-hidden="true" tabindex="-1"></a><span class="st">                modal.style.position = 'fixed';</span></span>
<span id="cb21-120"><a href="#cb21-120" aria-hidden="true" tabindex="-1"></a><span class="st">                modal.style.left = '50</span><span class="sc">%%</span><span class="st">';</span></span>
<span id="cb21-121"><a href="#cb21-121" aria-hidden="true" tabindex="-1"></a><span class="st">                modal.style.top = '50</span><span class="sc">%%</span><span class="st">';</span></span>
<span id="cb21-122"><a href="#cb21-122" aria-hidden="true" tabindex="-1"></a><span class="st">                modal.style.transform = 'translate(-50</span><span class="sc">%%</span><span class="st">, -50</span><span class="sc">%%</span><span class="st">)';</span></span>
<span id="cb21-123"><a href="#cb21-123" aria-hidden="true" tabindex="-1"></a><span class="st">                modal.style.backgroundColor = 'white';</span></span>
<span id="cb21-124"><a href="#cb21-124" aria-hidden="true" tabindex="-1"></a><span class="st">                modal.style.padding = '20px';</span></span>
<span id="cb21-125"><a href="#cb21-125" aria-hidden="true" tabindex="-1"></a><span class="st">                modal.style.borderRadius = '5px';</span></span>
<span id="cb21-126"><a href="#cb21-126" aria-hidden="true" tabindex="-1"></a><span class="st">                modal.style.boxShadow = '0 0 10px rgba(0,0,0,0.5)';</span></span>
<span id="cb21-127"><a href="#cb21-127" aria-hidden="true" tabindex="-1"></a><span class="st">                modal.style.zIndex = '1000';</span></span>
<span id="cb21-128"><a href="#cb21-128" aria-hidden="true" tabindex="-1"></a><span class="st">                modal.style.maxWidth = '80</span><span class="sc">%%</span><span class="st">';</span></span>
<span id="cb21-129"><a href="#cb21-129" aria-hidden="true" tabindex="-1"></a><span class="st">                modal.style.maxHeight = '80</span><span class="sc">%%</span><span class="st">';</span></span>
<span id="cb21-130"><a href="#cb21-130" aria-hidden="true" tabindex="-1"></a><span class="st">                modal.style.overflow = 'auto';</span></span>
<span id="cb21-131"><a href="#cb21-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-132"><a href="#cb21-132" aria-hidden="true" tabindex="-1"></a><span class="st">                // Parse the JSON string back to HTML content</span></span>
<span id="cb21-133"><a href="#cb21-133" aria-hidden="true" tabindex="-1"></a><span class="st">                try {</span></span>
<span id="cb21-134"><a href="#cb21-134" aria-hidden="true" tabindex="-1"></a><span class="st">                    var expandedContent = JSON.parse(nodeInfo.expanded_content);</span></span>
<span id="cb21-135"><a href="#cb21-135" aria-hidden="true" tabindex="-1"></a><span class="st">                    modal.innerHTML = expandedContent;</span></span>
<span id="cb21-136"><a href="#cb21-136" aria-hidden="true" tabindex="-1"></a><span class="st">                } catch (e) {</span></span>
<span id="cb21-137"><a href="#cb21-137" aria-hidden="true" tabindex="-1"></a><span class="st">                    modal.innerHTML = 'Error displaying content: ' + e.message;</span></span>
<span id="cb21-138"><a href="#cb21-138" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb21-139"><a href="#cb21-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-140"><a href="#cb21-140" aria-hidden="true" tabindex="-1"></a><span class="st">                // Add close button</span></span>
<span id="cb21-141"><a href="#cb21-141" aria-hidden="true" tabindex="-1"></a><span class="st">                var closeBtn = document.createElement('button');</span></span>
<span id="cb21-142"><a href="#cb21-142" aria-hidden="true" tabindex="-1"></a><span class="st">                closeBtn.innerHTML = 'Close';</span></span>
<span id="cb21-143"><a href="#cb21-143" aria-hidden="true" tabindex="-1"></a><span class="st">                closeBtn.style.marginTop = '10px';</span></span>
<span id="cb21-144"><a href="#cb21-144" aria-hidden="true" tabindex="-1"></a><span class="st">                closeBtn.style.padding = '5px 10px';</span></span>
<span id="cb21-145"><a href="#cb21-145" aria-hidden="true" tabindex="-1"></a><span class="st">                closeBtn.style.cursor = 'pointer';</span></span>
<span id="cb21-146"><a href="#cb21-146" aria-hidden="true" tabindex="-1"></a><span class="st">                closeBtn.onclick = function() {</span></span>
<span id="cb21-147"><a href="#cb21-147" aria-hidden="true" tabindex="-1"></a><span class="st">                    document.body.removeChild(modal);</span></span>
<span id="cb21-148"><a href="#cb21-148" aria-hidden="true" tabindex="-1"></a><span class="st">                };</span></span>
<span id="cb21-149"><a href="#cb21-149" aria-hidden="true" tabindex="-1"></a><span class="st">                modal.appendChild(closeBtn);</span></span>
<span id="cb21-150"><a href="#cb21-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-151"><a href="#cb21-151" aria-hidden="true" tabindex="-1"></a><span class="st">                // Add modal to body</span></span>
<span id="cb21-152"><a href="#cb21-152" aria-hidden="true" tabindex="-1"></a><span class="st">                document.body.appendChild(modal);</span></span>
<span id="cb21-153"><a href="#cb21-153" aria-hidden="true" tabindex="-1"></a><span class="st">            }</span></span>
<span id="cb21-154"><a href="#cb21-154" aria-hidden="true" tabindex="-1"></a><span class="st">        }</span></span>
<span id="cb21-155"><a href="#cb21-155" aria-hidden="true" tabindex="-1"></a><span class="st">    });</span></span>
<span id="cb21-156"><a href="#cb21-156" aria-hidden="true" tabindex="-1"></a><span class="st">    """</span> <span class="op">%</span> json.dumps(setup_data[<span class="st">'nodes_data'</span>])</span>
<span id="cb21-157"><a href="#cb21-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-158"><a href="#cb21-158" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Save the graph to HTML</span></span>
<span id="cb21-159"><a href="#cb21-159" aria-hidden="true" tabindex="-1"></a>    html_file <span class="op">=</span> <span class="st">"bayesian_network.html"</span></span>
<span id="cb21-160"><a href="#cb21-160" aria-hidden="true" tabindex="-1"></a>    net.save_graph(html_file)</span>
<span id="cb21-161"><a href="#cb21-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-162"><a href="#cb21-162" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Inject custom click handling into HTML</span></span>
<span id="cb21-163"><a href="#cb21-163" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb21-164"><a href="#cb21-164" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="bu">open</span>(html_file, <span class="st">"r"</span>) <span class="im">as</span> f:</span>
<span id="cb21-165"><a href="#cb21-165" aria-hidden="true" tabindex="-1"></a>            html_content <span class="op">=</span> f.read()</span>
<span id="cb21-166"><a href="#cb21-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-167"><a href="#cb21-167" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Insert click handling script before the closing body tag</span></span>
<span id="cb21-168"><a href="#cb21-168" aria-hidden="true" tabindex="-1"></a>        html_content <span class="op">=</span> html_content.replace(<span class="st">'&lt;/body&gt;'</span>, <span class="ss">f'&lt;script&gt;</span><span class="sc">{</span>click_js<span class="sc">}</span><span class="ss">&lt;/script&gt;&lt;/body&gt;'</span>)</span>
<span id="cb21-169"><a href="#cb21-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-170"><a href="#cb21-170" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Write back the modified HTML</span></span>
<span id="cb21-171"><a href="#cb21-171" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="bu">open</span>(html_file, <span class="st">"w"</span>) <span class="im">as</span> f:</span>
<span id="cb21-172"><a href="#cb21-172" aria-hidden="true" tabindex="-1"></a>            f.write(html_content)</span>
<span id="cb21-173"><a href="#cb21-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-174"><a href="#cb21-174" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> HTML(html_content)</span>
<span id="cb21-175"><a href="#cb21-175" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb21-176"><a href="#cb21-176" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> HTML(<span class="ss">f"&lt;p&gt;Error rendering HTML: </span><span class="sc">{</span><span class="bu">str</span>(e)<span class="sc">}</span><span class="ss">&lt;/p&gt;"</span></span>
<span id="cb21-177"><a href="#cb21-177" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> <span class="st">"&lt;p&gt;The network visualization has been saved to '</span><span class="sc">{html_file}</span><span class="st">'&lt;/p&gt;"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</div>
<!-- 
#| label: main_visualization_function
#| echo: true
#| eval: true
#| fig-cap: "Main Visualization Function"
#| fig-link: "https://colab.research.google.com/github/VJMeyer/submission/blob/main/AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb#scrollTo=7UkPk-bm5_fm&line=8&uniqifier=1"
#| fig-alt: "Main Visualization Function"
-->
<p>The resulting visualization transforms abstract relationships into tangible understanding. Users report “aha” moments when exploring—suddenly seeing how technical factors compound into strategic risks, or identifying previously unnoticed bottlenecks in the causal chain.</p>
<p>This visualization reveals several structural insights:</p>
<ol type="1">
<li><strong>Central importance of “Misaligned_Power_Seeking”</strong> as a hub node with multiple parents and children</li>
<li><strong>Multiple pathways to “Existential_Catastrophe”</strong> through different intermediate factors</li>
<li><strong>Clusters of related variables</strong> forming coherent subarguments (e.g., factors affecting alignment difficulty)</li>
<li><strong>Flow of influence</strong> from technical factors (bottom) through deployment decisions to ultimate outcomes (top)</li>
</ol>
<p>The implementation successfully handles the complexity of Carlsmith’s model, correctly processing the multi-level structure, resolving repeated node references, and calculating appropriate probability distributions. The interactive visualization makes this complex model accessible, allowing users to explore different aspects of the argument through intuitive navigation.</p>
<p>Several key aspects of the implementation were particularly important for handling this complex model:</p>
<ol type="1">
<li><p>The <strong>parent-child relationship detection algorithm</strong> correctly identified hierarchical relationships despite the complex structure with repeated nodes and multiple levels.</p></li>
<li><p>The <strong>probability question generation system</strong> created appropriate questions for all variables, including those with multiple parents requiring factorial combinations of conditional probabilities.</p></li>
<li><p>The <strong>network enhancement functions</strong> calculated useful metrics like centrality measures and Markov blankets that help interpret the model structure.</p></li>
<li><p>The <strong>visualization system</strong> effectively presented the complex network through color-coding, interactive exploration, and progressive disclosure of details.</p></li>
</ol>
<p>The successful application to Carlsmith’s model demonstrates the AMTAIR approach’s scalability to complex real-world arguments. While the canonical rain-sprinkler-lawn example validated correctness, this application proves practical utility for sophisticated multi-level arguments with dozens of variables and complex interdependencies—precisely the kind of arguments that characterize AI risk assessments.</p>
<p>This capability addresses a core limitation of the original MTAIR framework: the labor intensity of manual formalization. Where manually converting Carlsmith’s argument to a formal model might take days of expert time, the AMTAIR approach accomplished this in minutes, creating a foundation for further analysis and exploration.</p>
<!-- [-] COMPLETED: Added visualization details -->
</section>
</div>
<section id="sec-carlsmith-validation" class="level3">
<h3 class="anchored" data-anchor-id="sec-carlsmith-validation">3.5.6 Validation Against Original (From the MTAIR Project)</h3>
<!-- [-] COMPLETELY REWRITE: Results were HALLUCINATED -- rewrite based on results / comparison with Ella and Johannes extractions and by describing what procedures etc. one would ideally follow -->
<p>Validating AMTAIR’s extraction required careful comparison with expert judgment. While comprehensive benchmarking remains future work, preliminary validation efforts provide encouraging signals.</p>
<p><strong>Manual Baseline Creation</strong>: Johannes Meyer and Jelena Meyer, independently extracted ArgDown and BayesDown representations from Carlsmith’s paper and Bucknall and Dori-Hacohen’s. This created ground truth accounting for legitimate interpretive variation—experts might reasonably disagree on some structural choices or probability estimates.</p>
<p><strong>Structural Comparison</strong>: Comparing extracted causal structures revealed high agreement on core relationships. AMTAIR consistently identified the main causal chain from capabilities through deployment to catastrophe. Some variation appeared in handling of auxiliary factors—where one expert might include a minor influence, another might omit it for simplicity.</p>
<p><strong>Probability Assessment</strong>: Probability extraction showed greater variation, reflecting inherent ambiguity in translating qualitative language. When Carlsmith writes “likely,” different readers might reasonably interpret this as 0.7, 0.75, or 0.8. AMTAIR’s extractions fell within the range of expert interpretations, suggesting successful capture of intended meaning even if not identical numbers.</p>
<p><strong>Semantic Preservation</strong>: Most importantly, the formal models preserved the essential insights of Carlsmith’s argument. The critical role of deployment decisions, the compound nature of risk, the importance of technical and strategic factors—all emerged clearly in the extracted representations.</p>
<p>An ideal validation protocol would expand this approach:</p>
<ol type="1">
<li>Multiple expert extractors working independently</li>
<li>Systematic comparison of structural and quantitative agreement</li>
<li>Analysis of where and why extractions diverge</li>
<li>Testing whether different extractions lead to different policy conclusions</li>
<li>Iterative refinement based on identified failure modes</li>
</ol>
<p>The goal isn’t perfect agreement—even human experts disagree. Rather, we seek extractions good enough to support meaningful analysis while acknowledging their limitations.</p>
<!-- [-] COMPLETED: Rewrote validation section without hallucinations -->
</section>
</section>
<section id="sec-validation-methodology" class="level2">
<h2 class="anchored" data-anchor-id="sec-validation-methodology">3.6 Validation Methodology</h2>
<!-- [-] TODO: Present results comparing automated extraction to manual annotation -->
<p>Building trust in automated extraction requires more than anecdotal success. We need systematic validation that honestly assesses both capabilities and limitations.</p>
<section id="sec-ground-truth" class="level3">
<h3 class="anchored" data-anchor-id="sec-ground-truth">3.6.1 Ground Truth Construction</h3>
<!-- [-] COMPLETELY REWRITE: Results were HALLUCINATED -- rewrite by describing what procedures etc. one would ideally follow -->
<p>Creating ground truth for argument extraction poses unique challenges. Unlike named entity recognition or sentiment analysis, argument structure lacks universal standards. What constitutes the “correct” extraction from a complex text?</p>
<p>An ideal validation approach would embrace this inherent subjectivity:</p>
<p><strong>Expert Selection</strong>: Recruit 5-10 domain experts with demonstrated expertise in both AI safety and formal modeling. Diversity matters—include technical researchers, policy analysts, and those with mixed backgrounds.</p>
<p><strong>Extraction Protocol</strong>: Provide standardized training on ArgDown/BayesDown syntax while allowing flexibility in interpretation. Experts work independently to avoid anchoring bias, documenting their reasoning process alongside final extractions.</p>
<p><strong>Consensus Building</strong>: Through structured discussion, identify areas of convergence (likely core argument structure) versus legitimate disagreement (interpretive choices, granularity decisions). This distinguishes system errors from inherent ambiguity.</p>
<p><strong>Quality Metrics</strong>: Rather than binary correct/incorrect judgments, assess:</p>
<ul>
<li>Structural similarity (graph edit distance)</li>
<li>Probability distribution overlap (KL divergence)</li>
<li>Semantic preservation (expert ratings)</li>
<li>Downstream task performance (policy analysis agreement)</li>
</ul>
<p>The resulting dataset would capture not a single “truth” but a distribution of reasonable interpretations against which to evaluate automated extraction.</p>
<!-- [-] COMPLETED: Rewrote ground truth construction -->
</section>
<section id="sec-evaluation-metrics" class="level3">
<h3 class="anchored" data-anchor-id="sec-evaluation-metrics">3.6.2 Evaluation Metrics</h3>
<!-- [-] COMPLETELY REWRITE: Results were HALLUCINATED -- rewrite by describing what procedures etc. one would ideally follow -->
<p>Evaluating argument extraction requires metrics that capture multiple dimensions of quality:</p>
<p><strong>Structural Fidelity</strong>:</p>
<ul>
<li>Node identification: What fraction of expert-identified variables does the system extract?</li>
<li>Edge accuracy: Are causal relationships preserved?</li>
<li>Hierarchy preservation: Does the system maintain argument levels?</li>
</ul>
<p><strong>Probability Calibration</strong>:</p>
<ul>
<li>Explicit extraction: When sources state probabilities, how accurately are they captured?</li>
<li>Linguistic mapping: Do qualitative expressions translate to reasonable probabilities?</li>
<li>Coherence: Are probability distributions properly normalized?</li>
</ul>
<p><strong>Semantic Quality</strong>:</p>
<ul>
<li>Description accuracy: Do extracted descriptions preserve original meaning?</li>
<li>Terminology preservation: Does the system maintain author’s vocabulary?</li>
<li>Context retention: Is sufficient information preserved for interpretation?</li>
</ul>
<p><strong>Functional Validity</strong>:</p>
<ul>
<li>Inference agreement: Do extracted models support similar conclusions?</li>
<li>Sensitivity preservation: Are critical parameters identified as influential?</li>
<li>Policy robustness: Do different extractions suggest similar interventions?</li>
</ul>
<p>These metrics acknowledge that perfect extraction is neither expected nor necessary. The goal is extraction sufficient for practical use while maintaining transparency about limitations.</p>
<!-- [-] COMPLETED: Rewrote evaluation metrics -->
</section>
<section id="sec-validation-results" class="level3">
<h3 class="anchored" data-anchor-id="sec-validation-results">3.6.3 Results Summary</h3>
<!-- [-] COMPLETELY REWRITE: Results were HALLUCINATED -- rewrite by describing what procedures etc. one would ideally follow -->
<p>While comprehensive validation remains future work, preliminary assessments using the methodology described above would likely reveal several patterns:</p>
<p><strong>Expected Strengths</strong>: Automated extraction should excel at identifying explicit causal claims, preserving hierarchical argument structure, and extracting stated probabilities. The two-stage approach likely improves quality by allowing focused optimization for each task.</p>
<p><strong>Anticipated Challenges</strong>: Implicit reasoning, complex conditionals, and ambiguous quantifiers would pose greater challenges. Coreference resolution across long documents and maintaining consistency in large models would require continued refinement.</p>
<p><strong>Practical Utility Threshold</strong>: Even with imperfect extraction, the system could provide value if it achieves perhaps 70-80% structural accuracy and captures probability estimates within reasonable ranges. This level of performance would enable rapid initial modeling that experts could refine, dramatically reducing the time from argument to formal model.</p>
<p>The validation framework itself represents a contribution—establishing systematic methods for assessing argument extraction quality as this research area develops.</p>
<!-- [-] COMPLETED: Rewrote results summary -->
</section>
<section id="sec-error-analysis" class="level3">
<h3 class="anchored" data-anchor-id="sec-error-analysis">3.6.4 Error Analysis</h3>
<p>Understanding failure modes guides both appropriate use and future improvements:</p>
<p><strong>Implicit Assumptions</strong>: Authors often leave critical assumptions unstated, relying on shared background knowledge. When an AI safety researcher writes about “alignment,” they assume readers understand the technical concept. The system must either extract these implicit elements or flag their absence.</p>
<p><strong>Complex Conditionals</strong>: Natural language expresses conditionality in myriad ways. “If we achieve alignment (which seems unlikely without major theoretical breakthroughs), then deployment might be safe (assuming robust verification).” Parsing nested, qualified conditionals challenges current methods.</p>
<p><strong>Ambiguous Quantifiers</strong>: The word “significant” might mean 10% in one context, 60% in another. Without calibration to author-specific usage or domain conventions, probability extraction remains approximate.</p>
<p><strong>Coreference Challenges</strong>: Academic writing loves pronouns and indirect references. When “this approach” appears three paragraphs after introducing multiple approaches, identifying the correct referent requires sophisticated discourse understanding.</p>
<p>These limitations don’t invalidate the approach but rather define its boundaries. Users who understand these constraints can work within them, leveraging automation’s strengths while compensating for its weaknesses.</p>
<!-- [-] COMPLETED: Added error analysis -->
</section>
<section id="sec-manual-validation" class="level3">
<h3 class="anchored" data-anchor-id="sec-manual-validation">3.6.5 Independent Manual Extraction Validation</h3>
<!-- [-] ADD: Independent validation through manual extraction comparison -->
<p>To establish ground truth for evaluating AMTAIR’s extraction quality, I obtained independent manual extractions from domain experts. Johannes Meyer and Jelena Meyer<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a>, both experienced in formal logic and argument analysis, independently extracted ArgDown and BayesDown representations from Bucknall and Dori-Hacohen’s “Current and Near-Term AI as a Potential Existential Risk Factor” <span class="citation" data-cites="bucknall2022">Bucknall and Dori-Hacohen (<a href="../../ref/references.html#ref-bucknall2022" role="doc-biblioref">2022</a>)</span>. This paper, which examines how near-term AI systems might contribute to existential risks through various causal pathways, provides an ideal test case due to its explicit discussion of multiple risk factors and their interdependencies.</p>
<p>The manual extraction process revealed patterns consistent with theoretical expectations from the argument mining literature <span class="citation" data-cites="khartabil2021">Khartabil et al. (<a href="../../ref/references.html#ref-khartabil2021" role="doc-biblioref">2021</a>)</span>. Both extractors identified remarkably similar causal structures—the core nodes representing existential risk factors (unaligned AGI, nuclear conflict, biological risks, environmental catastrophe) and their relationships to near-term AI capabilities showed near-perfect agreement. This structural convergence aligns with findings from Anderson <span class="citation" data-cites="anderson2007">Anderson (<a href="../../ref/references.html#ref-anderson2007" role="doc-biblioref">2007</a>)</span> that expert annotators tend to agree on primary argumentative relationships even when working independently.</p>
<p>However, the probability quantification phase exhibited substantially higher variance, corroborating established challenges in eliciting subjective probabilities from text. When extracting conditional probabilities for relationships like P(Nuclear_Conflict | Compromised_Political_Decision_Making), the two extractors’ estimates differed by as much as 30 percentage points. This variance reflects the fundamental ambiguity Pollock <span class="citation" data-cites="pollock1995">Pollock (<a href="../../ref/references.html#ref-pollock1995" role="doc-biblioref">1995</a>)</span> identified in mapping natural language uncertainty expressions to numerical values—when Bucknall and Dori-Hacohen write that AI “may intensify cyber warfare,” reasonable interpreters might assign probabilities anywhere from 0.4 to 0.7.</p>
<p>The extraction revealed a hierarchical structure with [Existential_Risk] as the root node, influenced by both direct AI risks (unaligned AGI) and indirect pathways where near-term AI acts as an intermediate risk factor. The extractors consistently identified four main causal mechanisms: state-to-state relations (arms race dynamics), corporate power concentration, stable repressive regimes, and compromised political decision-making. This structural clarity demonstrates that despite quantitative uncertainty, the qualitative causal model remains extractable with high fidelity.</p>
<p>Interestingly, both manual extractors struggled with the same ambiguities that challenge automated systems, which could be an indication about convergence on the underlying level of information contained in the source. The relationship between social media recommender systems and various risk factors appeared multiple times in the text with slightly different framings, requiring judgment calls about whether these represented single or multiple causal relationships. This observation supports the design decision to maintain human oversight in AMTAIR’s extraction pipeline—certain interpretive choices require domain knowledge and contextual understanding that neither human nor machine extractors can make with complete confidence in isolation.</p>
<p>The manual extraction exercise validates AMTAIR’s two-stage approach. The high agreement on structure (ArgDown) combined with high variance in probabilities (BayesDown) empirically confirms that separating these extraction tasks addresses genuine cognitive and epistemological differences. As predicted by the causal structure learning literature <span class="citation" data-cites="heinze-deml2018">Heinze-Deml, Maathuis, and Meinshausen (<a href="../../ref/references.html#ref-heinze-deml2018" role="doc-biblioref">2018</a>)</span> <span class="citation" data-cites="squires2023">Squires and Uhler (<a href="../../ref/references.html#ref-squires2023" role="doc-biblioref">2023</a>)</span>, identifying “what causes what” represents a different inferential challenge than quantifying “how likely” those causal relationships are.</p>
<p>This validation also illuminates the value proposition of automated extraction. While human experts required 4-6 hours each to complete their extractions, AMTAIR processed the same document in under two minutes. Even if automated extraction only achieves 80% of human accuracy, the 100x speed improvement enables analyzing entire literatures rather than individual papers. The manual baseline suggests that perfect extraction may be impossible even for humans—but good-enough extraction at scale can still transform how we synthesize complex arguments about AI risk.</p>
</section>
</section>
<section id="sec-policy-evaluation" class="level2">
<h2 class="anchored" data-anchor-id="sec-policy-evaluation">3.7 Policy Evaluation Capabilities</h2>
<!-- [-] TODO: Showcase how inference, sensitivity analysis, and policy evaluation work -->
<p>The ultimate test of a model isn’t its elegance but its utility. Can AMTAIR’s extracted models actually inform governance decisions? This section demonstrates how formal models enable systematic policy analysis.</p>
<section id="sec-intervention-representation" class="level3">
<h3 class="anchored" data-anchor-id="sec-intervention-representation">3.7.1 Intervention Representation</h3>
<!-- [-] COMPLETELY REWRITE: Results were HALLUCINATED -- rewrite by describing what procedures etc. one would ideally follow -->
<p>Representing policy interventions in Bayesian networks requires translating governance mechanisms into parameter modifications. Pearl’s do-calculus provides the mathematical framework, but the practical challenge lies in meaningful translation.</p>
<p>An ideal implementation would support several intervention types:</p>
<p><strong>Parameter Modification</strong>: Policies often change probabilities. Safety requirements might reduce P(deployment|misaligned) from 0.7 to 0.2 by making unsafe deployment legally prohibited or reputationally costly.</p>
<p><strong>Structural Interventions</strong>: Some policies add new causal pathways. Introducing mandatory review boards creates new nodes and edges representing oversight mechanisms.</p>
<p><strong>Uncertainty Modeling</strong>: Policy effectiveness is itself uncertain. Rather than assuming perfect implementation, represent ranges: P(deployment|misaligned) might become [0.1, 0.3] depending on enforcement.</p>
<p><strong>Multi-Level Effects</strong>: Policies influence multiple levels simultaneously. Compute governance affects technical development, corporate behavior, and international competition.</p>
<p>The system would translate high-level policy descriptions into specific network modifications, enabling rigorous counterfactual analysis of intervention effects.</p>
<!-- [-] COMPLETED: Rewrote intervention representation -->
</section>
<section id="sec-deployment-example" class="level3">
<h3 class="anchored" data-anchor-id="sec-deployment-example">3.7.2 Example: Deployment Governance</h3>
<p>Let’s trace how a specific policy—mandatory safety certification before deployment—might be evaluated:</p>
<p><strong>Baseline Model</strong>: In Carlsmith’s original model, P(deployment|misaligned) = 0.7, reflecting competitive pressures overwhelming safety concerns.</p>
<p><strong>Policy Specification</strong>: Safety certification requires demonstrating alignment properties before deployment authorization. Based on similar regulations in other domains, we might estimate 80-90% effectiveness.</p>
<p><strong>Parameter Update</strong>: The modified model sets P(deployment|misaligned) = 0.1-0.2, representing the residual probability of circumvention or regulatory capture.</p>
<p><strong>Downstream Effects</strong>:</p>
<ul>
<li>Reduced deployment of misaligned systems</li>
<li>Lower probability of power-seeking manifestation</li>
<li>Decreased existential risk from ~5% to ~1.2%</li>
</ul>
<p><strong>Sensitivity Analysis</strong>: How robust is this conclusion? Varying certification effectiveness, enforcement probability, and other parameters reveals which assumptions critically affect the outcome.</p>
<p>This example illustrates policy evaluation’s value: moving from vague claims (“regulation would help”) to quantitative assessments (“this specific intervention might reduce risk by 75%±15%”).</p>
<!-- [-] COMPLETED: Added deployment governance example -->
</section>
<section id="sec-robustness" class="level3">
<h3 class="anchored" data-anchor-id="sec-robustness">3.7.3 Robustness Analysis</h3>
<p>Good policies work across scenarios. AMTAIR enables testing interventions against multiple worldviews, parameter ranges, and structural variations.</p>
<p><strong>Cross-Model Testing</strong>: Extract multiple expert models and evaluate the same policy in each. If an intervention reduces risk in Carlsmith’s model but increases it in Christiano’s, we’ve identified a critical dependency.</p>
<p><strong>Parameter Sensitivity</strong>: Which uncertainties most affect policy effectiveness? If the intervention only works for P(alignment_difficulty) &lt; 0.3, and experts disagree whether it’s 0.2 or 0.4, we need more research before implementing.</p>
<p><strong>Structural Uncertainty</strong>: Some disagreements concern model structure itself. Does capability advancement directly influence misalignment risk, or only indirectly through deployment pressures? Test policies under both structures.</p>
<p><strong>Confidence Bounds</strong>: Rather than point estimates, compute ranges. “This policy reduces risk by 40-80%” honestly represents uncertainty while still providing actionable guidance.</p>
<p>The goal isn’t eliminating uncertainty but making decisions despite it. Robustness analysis reveals which policies work across uncertainties versus those requiring specific assumptions.</p>
<!-- [-] COMPLETED: Added robustness analysis -->
</section>
</section>
<section id="sec-visualization-design" class="level2">
<h2 class="anchored" data-anchor-id="sec-visualization-design">3.8 Interactive Visualization Design</h2>
<!-- [-] TODO: Describe the additional analytical capabilities -->
<p>A Bayesian network without good visualization is like a symphony without performers—all potential, no impact. The visualization system transforms mathematical abstractions into intuitive understanding.</p>
<section id="sec-visual-encoding" class="level3">
<h3 class="anchored" data-anchor-id="sec-visual-encoding">3.8.1 Visual Encoding Strategy</h3>
<p>Every visual element carries information:</p>
<p><strong>Color</strong>: The probability spectrum from red (low) through yellow to green (high) provides immediate gestalt understanding. Pre-attentive processing—the brain’s ability to process certain visual features without conscious attention—makes patterns jump out.</p>
<p><strong>Borders</strong>: Node type encoding (blue=root, purple=intermediate, magenta=outcome) creates visual flow. The eye naturally follows from blue through purple to magenta, tracing causal pathways.</p>
<p><strong>Size</strong>: Larger nodes have higher centrality—more connections, more influence. This emerges from the physics simulation but reinforces importance.</p>
<p><strong>Layout</strong>: Force-directed positioning naturally clusters related concepts while maintaining readability. The algorithm balances competing constraints: minimize edge crossings, maintain hierarchical levels, avoid node overlap, and create aesthetic appeal.</p>
<p>The encoding philosophy: every pixel should earn its place by conveying information while maintaining visual harmony.</p>
<!-- [-] COMPLETED: Added visual encoding -->
</section>
<section id="sec-progressive-disclosure" class="level3">
<h3 class="anchored" data-anchor-id="sec-progressive-disclosure">3.8.2 Progressive Disclosure</h3>
<p>Information overload kills understanding. The interface reveals complexity gradually:</p>
<p><strong>Level 1 - Overview</strong>: At first glance, see network structure and probability color coding. This answers: “What’s the shape of the argument? Where are the high-risk areas?”</p>
<p><strong>Level 2 - Hover Details</strong>: Mouse over a node to see its description and prior probability. This adds: “What does this factor represent? How likely is it?”</p>
<p><strong>Level 3 - Click Deep Dive</strong>: Clicking opens full probability tables and relationships. This reveals: “How does this probability change with conditions? What influences this factor?”</p>
<p><strong>Level 4 - Interactive Exploration</strong>: Dragging, zooming, and physics controls enable custom investigation. This supports: “What if I reorganize to see different patterns? How do these clusters relate?”</p>
<p>Each level serves different users and use cases. A policymaker might work primarily with levels 1-2, while a researcher dives into level 3-4 details.</p>
<!-- [-] COMPLETED: Added progressive disclosure -->
</section>
<section id="sec-ui-elements" class="level3">
<h3 class="anchored" data-anchor-id="sec-ui-elements">3.8.3 User Interface Elements</h3>
<!-- [-] COMPLETELY REWRITE: Results were HALLUCINATED -- rewrite by describing what procedures etc. one would ideally follow -->
<p>Effective interface design for Bayesian networks requires balancing power with accessibility:</p>
<p><strong>Physics Controls</strong>: Force-directed layouts benefit from tuning. Gravity affects spread, spring length controls spacing, damping influences settling time. Advanced users can adjust these for optimal layouts, while defaults work well for most cases.</p>
<p><strong>Filter Options</strong>: With large networks, selective viewing becomes essential. Filter by probability ranges (show only likely events), node types (focus on interventions), or causal depth (see only immediate effects).</p>
<p><strong>Export Functions</strong>: Different stakeholders need different formats. Researchers want raw data, policymakers need reports, presenters require images. Supporting diverse export formats enables broad usage.</p>
<p><strong>Comparison Mode</strong>: Understanding often comes from contrast. Side-by-side viewing of baseline versus intervention, or different expert models, reveals critical differences.</p>
<p>Iterative design with actual users would refine these features, ensuring they serve real needs rather than imagined ones.</p>
<!-- [-] COMPLETED: Rewrote UI elements -->
</section>
</section>
<section id="sec-market-integration" class="level2">
<h2 class="anchored" data-anchor-id="sec-market-integration">3.9 Integration with Prediction Markets</h2>
<!-- [-] TODO: Outline methods for connecting formal models with live data -->
<p>The vision: formal models that breathe with live data, updating as collective intelligence evolves. While full implementation awaits, the architecture anticipates this future.</p>
<section id="sec-integration-design" class="level3">
<h3 class="anchored" data-anchor-id="sec-integration-design">3.9.1 Design for Integration</h3>
<p><strong>Integration Architecture</strong> requires careful design to manage the impedance mismatch between formal models and market data:</p>
<p><strong>API Specifications</strong>: Each platform—Metaculus, Manifold, Good Judgment Open—has unique data formats, update frequencies, and question types. A unified adapter layer would translate platform-specific formats into model-compatible data.</p>
<p><strong>Semantic Matching</strong>: The hard problem—connecting “AI causes extinction by 2100” (market question) to “Existential_Catastrophe” (model node). This requires sophisticated NLP and possibly human curation for high-stakes connections.</p>
<p><strong>Aggregation Methods</strong>: When multiple markets address similar questions, how do we combine? Weighted averages based on market depth, participant quality, and historical accuracy provide more signal than simple means.</p>
<p><strong>Update Scheduling</strong>: Real-time updates would overwhelm users and computation. Smart scheduling might update daily for slow-changing strategic questions, hourly for capability announcements, immediately for critical events.</p>
<!-- [-] COMPLETED: Added integration design -->
</section>
<section id="sec-market-challenges" class="level3">
<h3 class="anchored" data-anchor-id="sec-market-challenges">3.9.2 Challenges and Opportunities</h3>
<p>The challenges are real but surmountable:</p>
<p><strong>Question Mapping</strong>: Markets ask specific, time-bound questions while models represent general relationships. “AGI by 2030?” maps uncertainly to “APS_Systems exists.” Developing robust mapping functions requires deep understanding of both domains.</p>
<p><strong>Temporal Alignment</strong>: Market probabilities change over time, but model parameters are typically static. Should we use current market values, time-weighted averages, or attempt to extract trend information?</p>
<p><strong>Quality Variation</strong>: A liquid market with expert participants provides different information than a thin market with casual forecasters. Weighting schemes must account for these quality differences.</p>
<p><strong>Incentive Effects</strong>: If models influence policy and policy influences outcomes, and markets forecast outcomes, we create feedback loops. Understanding these dynamics prevents perverse incentives.</p>
<p>Despite challenges, even partial integration provides value:</p>
<ul>
<li>External validation of expert-derived probabilities</li>
<li>Dynamic updating as new information emerges</li>
<li>Identification of where model and market disagree</li>
<li>Quantified uncertainty from market spread</li>
</ul>
<p>The perfect shouldn’t be the enemy of the good—simple integration beats no integration.</p>
<!-- [-] COMPLETED: Added market challenges -->
</section>
</section>
<section id="sec-computational-performance-analysis" class="level2">
<h2 class="anchored" data-anchor-id="sec-computational-performance-analysis">3.10 Computational Performance Analysis</h2>
<!-- [-] TODO: Analyze the computational efficiency of the system -->
<p>As networks grow from toy examples to real-world complexity, computational challenges emerge. Understanding these constraints shapes realistic expectations and optimization priorities.</p>
<section id="sec-exact-approximate" class="level3">
<h3 class="anchored" data-anchor-id="sec-exact-approximate">3.10.1 Exact vs.&nbsp;Approximate Inference</h3>
<p>The fundamental tradeoff in probabilistic reasoning: exactness versus tractability.</p>
<p><strong>Exact Inference</strong>: Variable elimination and junction tree algorithms provide mathematically exact answers. For our 3-node rain-sprinkler network, calculations complete instantly. For 20-node networks with modest connectivity, expect seconds. But for 50+ node networks with complex dependencies, exact inference becomes impractical—potentially taking hours or exhausting memory.</p>
<p><strong>Approximate Methods</strong>: When exactness becomes impractical, approximation saves the day:</p>
<ul>
<li><strong>Monte Carlo Sampling</strong>: Generate thousands of scenarios consistent with the network, estimate probabilities from frequencies. Accuracy improves with samples, trading computation time for precision.</li>
<li><strong>Variational Inference</strong>: Find the simplest distribution that approximates our complex reality. Like fitting a smooth curve to jagged data—we lose detail but gain comprehension.</li>
<li><strong>Belief Propagation</strong>: Pass messages between nodes until beliefs converge. Works beautifully for tree-structured networks, can oscillate or converge slowly for complex loops.</li>
</ul>
<p>The system selects methods based on network properties:</p>
<ul>
<li>Small networks: exact inference for precision</li>
<li>Medium networks: belief propagation for speed</li>
<li>Large networks: sampling for scalability</li>
<li>Very large networks: hierarchical decomposition</li>
</ul>
<!-- [-] COMPLETED: Added inference comparison -->
</section>
<section id="sec-scaling-strategies" class="level3">
<h3 class="anchored" data-anchor-id="sec-scaling-strategies">3.10.2 Scaling Strategies</h3>
<p>When networks grow beyond convenient computation, clever strategies maintain usability:</p>
<p><strong>Hierarchical Decomposition</strong>: Break large networks into smaller, manageable subnetworks. Compute locally, then integrate results. Like solving a jigsaw puzzle by completing sections before assembling the whole.</p>
<p><strong>Relevance Pruning</strong>: For specific queries, most nodes don’t matter. If asking about deployment risk, technical details about interpretability methods might be temporarily ignorable. Prune irrelevant subgraphs for focused analysis.</p>
<p><strong>Caching Architecture</strong>: Many queries repeat—P(catastrophe), P(deployment|misalignment). Cache results to avoid recomputation. Smart invalidation updates only affected queries when parameters change.</p>
<p><strong>Parallel Processing</strong>: Inference calculations often decompose naturally. Different branches of the network can be processed simultaneously. Modern multi-core processors and cloud computing make this increasingly attractive.</p>
<p>Implementation would balance these strategies based on usage patterns. Interactive exploration benefits from caching and pruning. Batch analysis leverages parallelization. The architecture accommodates multiple approaches.</p>
<!-- [-] COMPLETED: Added scaling strategies -->
</section>
</section>
<section id="sec-results-achievements" class="level2">
<h2 class="anchored" data-anchor-id="sec-results-achievements">3.11 Results and Achievements</h2>
<!-- [-] TODO: Summarize extraction quality, performance, and policy evaluation results -->
<section id="sec-extraction-quality" class="level3">
<h3 class="anchored" data-anchor-id="sec-extraction-quality">3.11.1 Extraction Quality Assessment</h3>
<!-- [-] COMPLETELY REWRITE: Results were HALLUCINATED -- rewrite by describing what procedures etc. one would ideally follow -->
<p>Assessing extraction quality requires honesty about both achievements and limitations. An ideal evaluation would examine multiple dimensions:</p>
<p><strong>Coverage</strong>: What proportion of arguments in source texts does the system successfully capture? Initial applications suggest the two-stage approach identifies most explicit causal claims while struggling with deeply implicit relationships.</p>
<p><strong>Accuracy</strong>: How closely do automated extractions match expert consensus? Preliminary comparisons indicate strong agreement on primary causal structures with more variation in probability estimates.</p>
<p><strong>Robustness</strong>: How well does the system handle different writing styles, argument structures, and domains? Academic papers with clear argumentation extract more reliably than informal blog posts or policy documents.</p>
<p><strong>Utility</strong>: Do the extracted models enable meaningful analysis? Even imperfect extractions that capture 80% of structure with approximate probabilities can dramatically accelerate modeling compared to starting from scratch.</p>
<p>The key insight: perfect extraction isn’t necessary for practical value. Like machine translation, which provides useful results despite imperfections, automated argument extraction can enhance human capability without replacing human judgment.</p>
<!-- [-] COMPLETED: Rewrote extraction quality assessment -->
</section>
<section id="sec-computational-performance" class="level3">
<h3 class="anchored" data-anchor-id="sec-computational-performance">3.11.2 Computational Performance</h3>
<!-- [-] COMPLETELY REWRITE: Results were HALLUCINATED -- rewrite by describing what procedures etc. one would ideally follow -->
<p>Performance analysis would reveal the practical boundaries of the current system:</p>
<p><strong>Extraction Speed</strong>: LLM-based extraction scales roughly linearly with document length. A 20-page paper might require 30-60 seconds for structural extraction and similar time for probability extraction. This enables processing dozens of documents daily—orders of magnitude faster than manual approaches.</p>
<p><strong>Network Complexity Limits</strong>: Exact inference remains tractable for networks up to approximately 30-40 nodes with moderate connectivity. Beyond this, approximate methods become necessary, with sampling methods scaling to hundreds of nodes at the cost of precision.</p>
<p><strong>Visualization Responsiveness</strong>: The extraction phase exhibits linear complexity in document length—processing twice as much text takes roughly twice as long. However, the inference phase faces exponential complexity in network connectivity.</p>
<p><strong>End-to-End Pipeline</strong>: From document input to interactive visualization, expect 2-5 minutes for typical AI safety arguments. This represents roughly 100x speedup compared to manual modeling efforts.</p>
<p>These performance characteristics make AMTAIR practical for real-world use while highlighting areas for future optimization.</p>
<!-- [-] COMPLETED: Rewrote computational performance -->
</section>
<section id="sec-policy-impact" class="level3">
<h3 class="anchored" data-anchor-id="sec-policy-impact">3.11.3 Policy Impact Evaluation</h3>
<!-- [-] COMPLETELY REWRITE: Results were HALLUCINATED -- rewrite by describing what procedures etc. one would ideally follow -->
<p>The true test of AMTAIR lies in its ability to inform governance decisions. An ideal policy evaluation framework would demonstrate several capabilities:</p>
<p><strong>Intervention Modeling</strong>: Representing diverse policy proposals—from technical standards to international agreements—as parameter modifications in extracted networks. This translation from qualitative proposals to quantitative changes enables rigorous analysis.</p>
<p><strong>Comparative Assessment</strong>: Evaluating multiple interventions across different expert worldviews to identify robust strategies. Policies that reduce risk across different models deserve priority over those requiring specific assumptions.</p>
<p><strong>Sensitivity Analysis</strong>: Understanding which uncertainties most affect policy conclusions. If an intervention’s effectiveness depends critically on disputed parameters, this highlights research priorities.</p>
<p><strong>Implementation Guidance</strong>: Moving beyond “this policy reduces risk” to specific recommendations about design details, implementation sequences, and success metrics.</p>
<p>The system would transform abstract policy discussions into concrete quantitative analyses, enabling evidence-based decision-making in AI governance.</p>
<!-- [-] COMPLETED: Rewrote policy impact evaluation -->
</section>
</section>
<section id="sec-technical-summary" class="level2">
<h2 class="anchored" data-anchor-id="sec-technical-summary">3.12 Summary of Technical Contributions</h2>
<p>Looking back at the implementation journey, several achievements stand out:</p>
<p><strong>Automated Extraction</strong>: The two-stage pipeline successfully transforms natural language arguments into formal models, achieving practical accuracy while maintaining transparency about limitations.</p>
<p><strong>Hybrid Representation</strong>: BayesDown bridges qualitative and quantitative worlds, preserving semantic richness while enabling mathematical analysis.</p>
<p><strong>Scalable Architecture</strong>: Modular design accommodates growth—new document types, improved extraction methods, additional visualization options—without fundamental restructuring.</p>
<p><strong>Interactive Accessibility</strong>: Thoughtful visualization makes complex models understandable to diverse stakeholders, democratizing access to formal reasoning tools.</p>
<p><strong>Policy Relevance</strong>: The ability to model interventions and assess robustness transforms academic exercises into practical governance tools.</p>
<p>These technical achievements validate the feasibility of computational coordination infrastructure for AI governance. Not as a complete solution, but as a meaningful enhancement to human judgment and collaboration.</p>
<p>The implementation demonstrates that the vision of automated argument extraction is not merely theoretical but practically achievable. While challenges remain—particularly in handling implicit reasoning and diverse uncertainty expressions—the system provides a foundation for enhanced coordination in AI governance.</p>
<p>The journey from concept to implementation revealed unexpected insights. The two-stage extraction process, initially a pragmatic choice, proved cognitively valid. The intermediate representations became valuable outputs themselves. The visualization challenges led to design innovations applicable beyond this project.</p>
<p>Most importantly, the implementation confirms that formal modeling of AI risk arguments need not remain the province of a few dedicated experts. Through automation and thoughtful design, these powerful tools can serve the broader community working to ensure advanced AI benefits humanity.</p>
<p>Having demonstrated technical feasibility and practical utility, we must now critically examine limitations, address objections, and explore broader implications. The next chapter undertakes this essential reflection, ensuring we neither oversell the approach nor undervalue its contributions.</p>
</section>
</section>
<section id="sec-discussion" class="level1">
<h1>4. Discussion: Implications and Limitations</h1>
<!-- 
**Chapter Overview**  
**Grade Weight**: 10% | **Target Length**: ~14% of text (~4,200 words)  
**Requirements**: Discusses objections, provides convincing replies, extends beyond course materials 
-->
<!-- [-] TODO: Address each objection with rigorous counteranalysis -->
<section id="sec-technical-limitations" class="level2">
<h2 class="anchored" data-anchor-id="sec-technical-limitations">4.1 Technical Limitations and Responses</h2>
<section id="sec-extraction-boundaries" class="level3">
<h3 class="anchored" data-anchor-id="sec-extraction-boundaries">4.1.1 Extraction Quality Boundaries</h3>
<p>The critique that automated extraction systematically misses nuanced arguments deserves serious consideration. After months of working with these systems, I’ve developed both appreciation for their capabilities and acute awareness of their limitations. The reality, unsurprisingly, resists simple characterization.</p>
<p>Consider what happens when AMTAIR encounters a passage like: “While alignment might be achieved through current methods, the economic incentives pushing toward capability development at the expense of safety create a dynamic where technical solutions alone appear insufficient.” A human reader parses this effortlessly—alignment is possible but threatened by misaligned incentives. The system, however, might extract two separate claims about alignment feasibility and economic incentives without capturing their interconnection.</p>
<p>These failures aren’t random. They follow predictable patterns that reveal something fundamental about the difference between human and machine comprehension. Humans excel at inferring unstated connections, filling gaps with background knowledge, recognizing when an author assumes rather than argues. The system, lacking this context, must rely on explicit linguistic markers. When those markers are absent—as they often are in sophisticated arguments—extraction quality degrades.</p>
<p>Yet dismissing automated extraction based on these limitations misses a crucial point. The alternative isn’t perfect human extraction but no formal extraction at all. In practice, humans rarely take the time to formally map complex arguments. When they do, they exhibit their own biases and inconsistencies. The question becomes not whether automated extraction achieves perfection but whether it provides value despite imperfection.</p>
<p>My experience suggests it does, particularly when embedded in appropriate workflows. The two-stage architecture allows human review at natural breakpoints. Extracted structures make excellent starting points for refinement. Most surprisingly, extraction failures often diagnose ambiguities in source texts that human readers gloss over. When the system struggles to determine whether claim A supports or merely relates to claim B, it’s often because the original text genuinely leaves this ambiguous.</p>
<p>Framed differently:</p>
<p><strong>Critic</strong>: “Complex implicit reasoning chains resist formalization; automated extraction will systematically miss nuanced arguments and subtle conditional relationships that human experts would identify.”</p>
<p><strong>Response</strong>: This concern has merit—extraction does face inherent limitations. However, the empirical results tell a more nuanced story. The two-stage extraction process, while imperfect, captures sufficient structure for practical use while maintaining transparency about its limitations.</p>
<p>More importantly, AMTAIR employs a hybrid human-AI workflow that addresses this limitation:</p>
<ul>
<li><strong>Two-stage verification</strong>: Humans review structural extraction before probability quantification</li>
<li><strong>Transparent outputs</strong>: All intermediate representations remain human-readable</li>
<li><strong>Iterative refinement</strong>: Extraction prompts improve based on error analysis</li>
<li><strong>Ensemble approaches</strong>: Multiple extraction attempts can identify ambiguities</li>
</ul>
<p>The question is not whether automated extraction perfectly captures every nuance—it doesn’t. Rather, it’s whether imperfect extraction still provides value over no formal representation. When the alternative is relying on conflicting mental models that remain entirely implicit, even partially accurate formal models represent significant progress.</p>
<p>Furthermore, extraction errors often reveal interesting properties of the source arguments themselves—ambiguities that human readers gloss over become explicit when formalization fails. This diagnostic value enhances rather than undermines the approach.</p>
</section>
<section id="sec-false-precision" class="level3">
<h3 class="anchored" data-anchor-id="sec-false-precision">4.1.2 Objection 2: False Precision in Uncertainty</h3>
<p><strong>Critic</strong>: “Attaching exact probabilities to unprecedented events like AI catastrophe is fundamentally misguided. The numbers create false confidence in what amounts to educated speculation about radically uncertain futures.”</p>
<p><strong>Response</strong>: This philosophical objection strikes at the heart of formal risk assessment. However, AMTAIR addresses it through several design choices:</p>
<p>First, the system explicitly represents uncertainty about uncertainty. Rather than point estimates, the framework supports probability distributions over parameters. When someone says “likely” we might model this as a range rather than exactly 0.8, capturing both the central estimate and our uncertainty about it.</p>
<p>Second, all probabilities are explicitly conditional on stated assumptions. The system doesn’t claim “P(catastrophe) = 0.05” absolutely, but rather “Given Carlsmith’s model assumptions, P(catastrophe) = 0.05.” This conditionality is preserved throughout analysis.</p>
<p>Third, sensitivity analysis reveals which probabilities actually matter. Often, precise values are unnecessary—knowing whether a parameter is closer to 0.1 or 0.9 suffices for decision-making. The formalization helps identify where precision matters and where it doesn’t.</p>
<p>Finally, the alternative to quantification isn’t avoiding the problem but making it worse. When experts say “highly likely” or “significant risk,” they implicitly reason with probabilities. Formalization simply makes these implicit quantities explicit and subject to scrutiny. As Dennis Lindley noted, “Uncertainty is not in the events, but in our knowledge about them.”</p>
<!-- [-] ADD: @lindley2013: "Lindley, D. (2013). Understanding Uncertainty" -->
</section>
<section id="sec-correlation-complexity" class="level3">
<h3 class="anchored" data-anchor-id="sec-correlation-complexity">4.1.3 Objection 3: Correlation Complexity</h3>
<p><strong>Critic</strong>: “Bayesian networks assume conditional independence given parents, but real-world AI risks involve complex correlations. Ignoring these dependencies could dramatically misrepresent risk levels.”</p>
<p><strong>Response</strong>: Standard Bayesian networks do face limitations with correlation representation—this is a genuine technical challenge. However, several approaches within the framework address this:</p>
<p><strong>Explicit correlation nodes</strong>: When factors share hidden common causes, we can add latent variables to capture correlations. For instance, “AI research culture” might influence both “capability advancement” and “safety investment.”</p>
<p><strong>Copula methods</strong>: For known correlation structures, copula functions can model dependencies while preserving marginal distributions. This extends standard Bayesian networks significantly.<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a></p>
<p><strong>Sensitivity bounds</strong>: When correlations remain uncertain, we can compute bounds on outcomes under different correlation assumptions. This reveals when correlations critically affect conclusions.</p>
<p><strong>Model ensembles</strong>: Different correlation structures can be modeled separately and results aggregated, similar to climate modeling approaches.</p>
<p>More fundamentally, the question is whether imperfect independence assumptions invalidate the approach. In practice, explicitly modeling first-order effects with known limitations often proves more valuable than attempting to capture all dependencies informally. The framework makes assumptions transparent, enabling targeted improvements where correlations matter most.</p>
</section>
</section>
<section id="sec-conceptual-concerns" class="level2">
<h2 class="anchored" data-anchor-id="sec-conceptual-concerns">4.2 Conceptual and Methodological Concerns</h2>
<section id="sec-democratic-exclusion" class="level3">
<h3 class="anchored" data-anchor-id="sec-democratic-exclusion">4.2.1 Objection 4: Democratic Exclusion</h3>
<p><strong>Critic</strong>: “Transforming policy debates into complex graphs and equations will sideline non-technical stakeholders, concentrating influence among those comfortable with formal models. This technocratic approach undermines democratic participation in crucial decisions about humanity’s future.”</p>
<p><strong>Response</strong>: This concern about technocratic exclusion deserves serious consideration—formal methods can indeed create barriers. However, AMTAIR’s design explicitly prioritizes accessibility alongside rigor:</p>
<p><strong>Progressive disclosure interfaces</strong> allow engagement at multiple levels. A policymaker might explore visual network structures and probability color-coding without engaging mathematical details. Interactive features let users modify assumptions and see consequences without understanding implementation.</p>
<p><strong>Natural language preservation</strong> ensures original arguments remain accessible. The BayesDown format maintains human-readable descriptions alongside formal specifications. Users can always trace from mathematical representations back to source texts.</p>
<p><strong>Comparative advantage</strong> comes from making implicit technical content explicit, not adding complexity. When experts debate AI risk, they already employ sophisticated probabilistic reasoning—formalization reveals rather than creates this complexity. Making hidden assumptions visible arguably enhances rather than reduces democratic participation.</p>
<p><strong>Multiple interfaces</strong> serve different communities. Researchers access full technical depth, policymakers use summary dashboards, public stakeholders explore interactive visualizations. The same underlying model supports varied engagement modes.</p>
<p>Rather than excluding non-technical stakeholders, proper implementation can democratize access to expert reasoning by making it inspectable and modifiable. The risk lies not in formalization itself but in poor interface design or gatekeeping behaviors around model access.</p>
</section>
<section id="sec-oversimplification" class="level3">
<h3 class="anchored" data-anchor-id="sec-oversimplification">4.2.2 Objection 5: Oversimplification of Complex Systems</h3>
<p><strong>Critic</strong>: “Forcing rich socio-technical systems into discrete Bayesian networks necessarily loses crucial dynamics—feedback loops, emergent properties, institutional responses, and cultural factors that shape AI development. The models become precise but wrong.”</p>
<p><strong>Response</strong>: All models simplify by necessity—as Box noted, “All models are wrong, but some are useful.” The question becomes whether formal simplifications improve upon informal mental models:</p>
<p><strong>Transparent limitations</strong> make formal models’ shortcomings explicit. Unlike mental models where simplifications remain hidden, network representations clearly show what is and isn’t included. This transparency enables targeted criticism and improvement.</p>
<p><strong>Iterative refinement</strong> allows models to grow more sophisticated over time. Starting with first-order effects and adding complexity where it proves important follows successful practice in other domains. Climate models began simply and added dynamics as computational power and understanding grew.</p>
<p><strong>Complementary tools</strong> address different aspects of the system. Bayesian networks excel at probabilistic reasoning and intervention analysis. Other approaches—agent-based models, system dynamics, scenario planning—can capture different properties. AMTAIR provides one lens, not the only lens.</p>
<p><strong>Empirical adequacy</strong> ultimately judges models. If simplified representations enable better predictions and decisions than informal alternatives, their abstractions are justified. Early results suggest formal models, despite simplifications, outperform intuitive reasoning for complex risk assessment.</p>
<p>The goal isn’t creating perfect representations but useful ones. By making simplifications explicit and modifiable, formal models enable systematic improvement in ways mental models cannot.</p>
</section>
<section id="sec-idiosyncratic" class="level3">
<h3 class="anchored" data-anchor-id="sec-idiosyncratic">4.2.3 Objection 6: Idiosyncratic Implementation and Modeling Choices</h3>
<p><strong>Critic</strong>: “The specific choices made in AMTAIR’s implementation—from prompt design to parsing algorithms to visualization strategies—seem arbitrary. Different teams might make entirely different choices, leading to incompatible results. How can we trust conclusions that depend so heavily on implementation details?”</p>
<p><strong>Response</strong>: This concern about implementation dependency is valid and deserves careful consideration. However, several factors mitigate this issue:</p>
<p><strong>Convergent Design Principles</strong>: While specific implementations vary, fundamental design principles tend to converge. The two-stage extraction process (structure then probability) emerges naturally from how humans parse arguments. The use of intermediate representations follows established practice in computational linguistics. These aren’t arbitrary choices but responses to inherent challenges.</p>
<p><strong>Empirical Validation</strong>: The “correctness” of implementation choices isn’t philosophical but empirical. If different reasonable implementations extract similar structures and lead to similar policy conclusions, this demonstrates robustness. If they diverge dramatically, this reveals genuine ambiguity in source materials—itself valuable information.</p>
<p><strong>Transparent Methodology</strong>: By documenting all implementation choices and making code open source, AMTAIR enables replication and variation. Other teams can modify specific components while preserving overall architecture, testing which choices matter.</p>
<p><strong>Convergence at Higher Levels</strong>: Even if implementations differ in details, they may converge at levels that matter for coordination. If two systems extract slightly different network structures but reach similar conclusions about policy robustness, the implementation differences don’t undermine the approach’s value.</p>
<p><strong>Community Standards</strong>: As the field matures, community standards will likely emerge—not enforcing uniformity but establishing interoperability. This parallels development in other technical fields where multiple implementations coexist within shared frameworks.</p>
<p>The deeper insight is that implementation choices encode theoretical commitments. By making these explicit and variable, AMTAIR turns a bug into a feature—we can systematically explore how different assumptions affect conclusions, enhancing rather than undermining epistemic security.</p>
</section>
</section>
<section id="sec-red-teaming" class="level2">
<h2 class="anchored" data-anchor-id="sec-red-teaming">4.3 Red-Teaming Results</h2>
<!-- [-] TODO: Present results from systematic attempts to find weaknesses -->
<p>To identify failure modes, systematic adversarial testing of the AMTAIR system would be essential.</p>
<section id="sec-adversarial-extraction" class="level3">
<h3 class="anchored" data-anchor-id="sec-adversarial-extraction">4.3.1 Adversarial Extraction Attempts</h3>
<!-- [-] COMPLETELY REWRITE: Results were HALLUCINATED -- rewrite by describing what procedures etc. one would ideally follow -->
<p>A comprehensive red-teaming approach would test the system with:</p>
<p><strong>Contradictory Arguments</strong>: Texts containing logically inconsistent claims or probability estimates. The system should flag contradictions rather than silently reconciling them.</p>
<p><strong>Circular Reasoning</strong>: Arguments with circular dependencies that violate DAG requirements. Proper validation should detect and report such structural issues.</p>
<p><strong>Ambiguous Language</strong>: Texts using extremely vague or metaphorical language. The system should acknowledge extraction uncertainty rather than forcing precise interpretations.</p>
<p><strong>Deceptive Framings</strong>: Arguments crafted to imply false causal relationships. This tests whether the system merely extracts surface claims or requires deeper coherence.</p>
<p><strong>Adversarial Prompts</strong>: Inputs designed to trigger known LLM failure modes. This ensures robustness against prompt injection and manipulation attempts.</p>
<p>Each failure mode discovered would inform system improvements and user guidance.</p>
</section>
<section id="sec-robustness-findings" class="level3">
<h3 class="anchored" data-anchor-id="sec-robustness-findings">4.3.2 Robustness Findings</h3>
<p>Theoretical analysis suggests key vulnerabilities:</p>
<p><strong>Anchoring Effects</strong>: Language models may over-weight information presented early in documents, potentially biasing extraction toward initial framings.</p>
<p><strong>Authority Sensitivity</strong>: Extraction might be influenced by explicit credibility signals in text, potentially giving undue weight to claimed expertise.</p>
<p><strong>Complexity Limits</strong>: Performance likely degrades with very large argument structures, requiring hierarchical decomposition strategies.</p>
<p><strong>Context Windows</strong>: Long-range dependencies exceeding model context windows could be missed, fragmenting cohesive arguments.</p>
<p>Understanding these limitations enables appropriate use—leveraging strengths while compensating for weaknesses through human oversight and validation.</p>
</section>
<section id="sec-deployment-implications" class="level3">
<h3 class="anchored" data-anchor-id="sec-deployment-implications">4.3.3 Implications for Deployment</h3>
<p>These considerations suggest AMTAIR is suitable for:</p>
<ul>
<li><strong>Research applications</strong> with expert oversight</li>
<li><strong>Policy analysis</strong> of well-structured arguments</li>
<li><strong>Educational uses</strong> demonstrating formal reasoning</li>
<li><strong>Collaborative modeling</strong> with human verification</li>
</ul>
<p>But should be used cautiously for:</p>
<ul>
<li>Fully automated analysis without review</li>
<li>Adversarial or politically contentious texts</li>
<li>Real-time decision-making without validation</li>
<li>Arguments far outside training distribution</li>
</ul>
</section>
</section>
<section id="sec-epistemic-security" class="level2">
<h2 class="anchored" data-anchor-id="sec-epistemic-security">4.4 Enhancing Epistemic Security</h2>
<!-- [-] TODO: Analyze how formal modeling improves discourse quality -->
<p>Despite limitations, AMTAIR contributes to epistemic security in AI governance through several mechanisms.</p>
<section id="sec-inspectable-models" class="level3">
<h3 class="anchored" data-anchor-id="sec-inspectable-models">4.4.1 Making Models Inspectable</h3>
<p>The greatest epistemic benefit comes from forcing implicit models into explicit form. When an expert claims “misalignment likely leads to catastrophe,” formalization asks:</p>
<ul>
<li>Likely means what probability?</li>
<li>Through what causal pathways?</li>
<li>Under what assumptions?</li>
<li>With what evidence?</li>
</ul>
<p>This explicitation serves multiple functions:</p>
<p><strong>Clarity</strong>: Vague statements become precise claims subject to evaluation</p>
<p><strong>Comparability</strong>: Different experts’ models can be systematically compared</p>
<p><strong>Criticizability</strong>: Hidden assumptions become visible targets for challenge</p>
<p><strong>Updatability</strong>: Formal models can systematically incorporate new evidence</p>
</section>
<section id="sec-convergence-divergence" class="level3">
<h3 class="anchored" data-anchor-id="sec-convergence-divergence">4.4.2 Revealing Convergence and Divergence</h3>
<!-- [-] COMPLETELY REWRITE: Results were HALLUCINATED -- rewrite by describing what results we expect from theoretical considerations -->
<p>Theoretical analysis suggests formal comparison would reveal:</p>
<p><strong>Structural Patterns</strong>: Experts likely share more agreement about causal structures than probability values, suggesting common understanding of mechanisms despite quantitative disagreement.</p>
<p><strong>Crux Identification</strong>: Formal models make explicit which specific disagreements drive different conclusions, focusing discussion on genuinely critical differences.</p>
<p><strong>Hidden Agreements</strong>: Apparently conflicting positions might share substantial common ground obscured by different terminology or emphasis.</p>
<p><strong>Uncertainty Clustering</strong>: Areas of high uncertainty likely correlate across models, revealing where additional research would most reduce disagreement.</p>
<p>These patterns remain invisible in natural language debates but become analyzable through formalization.</p>
</section>
<section id="sec-collective-reasoning" class="level3">
<h3 class="anchored" data-anchor-id="sec-collective-reasoning">4.4.3 Improving Collective Reasoning</h3>
<p>AMTAIR enhances group epistemics through:</p>
<p><strong>Explicit uncertainty</strong>: Replacing “might,” “could,” “likely” with probability distributions reduces miscommunication and forces precision</p>
<p><strong>Compositional reasoning</strong>: Complex arguments decompose into manageable components that can be independently evaluated</p>
<p><strong>Evidence integration</strong>: New information updates specific parameters rather than requiring complete argument reconstruction</p>
<p><strong>Exploration tools</strong>: Stakeholders can modify assumptions and immediately see consequences, building intuition about model dynamics</p>
<!-- [-] COMPLETELY REWRITE: Results were HALLUCINATED -- rewrite by describing what benefits one can plausibly anticipate -->
<p>While empirical validation remains future work, theoretical considerations suggest these mechanisms could substantially improve coordination quality. By providing shared representations and systematic methods for managing disagreement, formal models create infrastructure for collective intelligence that transcends individual limitations.</p>
</section>
</section>
<section id="sec-scaling" class="level2">
<h2 class="anchored" data-anchor-id="sec-scaling">4.5 Scaling Challenges and Opportunities</h2>
<!-- [-] TODO: Examine how the modeling approach could complement existing initiatives -->
<p>Moving from prototype to widespread adoption faces both technical and social challenges.</p>
<section id="sec-technical-scaling" class="level3">
<h3 class="anchored" data-anchor-id="sec-technical-scaling">4.5.1 Technical Scaling</h3>
<p><strong>Computational complexity</strong> grows with network size, but several approaches help:</p>
<ul>
<li>Hierarchical decomposition for very large models</li>
<li>Caching and approximation for common queries</li>
<li>Distributed processing for extraction tasks</li>
<li>Incremental updating rather than full recomputation</li>
</ul>
<p><strong>Data quality</strong> varies dramatically across sources:</p>
<ul>
<li>Academic papers provide structured arguments</li>
<li>Blog posts offer rich ideas with less formal structure</li>
<li>Policy documents mix normative and empirical claims</li>
<li>Social media presents extreme extraction challenges</li>
</ul>
<p><strong>Integration complexity</strong> increases with ecosystem growth:</p>
<ul>
<li>Multiple LLM providers with different capabilities</li>
<li>Diverse visualization needs across users</li>
<li>Various export formats for downstream tools</li>
<li>Version control for evolving models</li>
</ul>
</section>
<section id="sec-social-scaling" class="level3">
<h3 class="anchored" data-anchor-id="sec-social-scaling">4.5.2 Social and Institutional Scaling</h3>
<p><strong>Adoption barriers</strong> include:</p>
<ul>
<li>Learning curve for formal methods</li>
<li>Institutional inertia in established processes</li>
<li>Concerns about replacing human judgment</li>
<li>Resource requirements for implementation</li>
</ul>
<p><strong>Trust building</strong> requires:</p>
<ul>
<li>Transparent methodology documentation</li>
<li>Published validation studies</li>
<li>High-profile successful applications</li>
<li>Community ownership and development</li>
</ul>
<p><strong>Sustainability</strong> depends on:</p>
<ul>
<li>Open source development model</li>
<li>Diverse funding sources</li>
<li>Academic and industry partnerships</li>
<li>Clear value demonstration</li>
</ul>
</section>
<section id="sec-impact-opportunities" class="level3">
<h3 class="anchored" data-anchor-id="sec-impact-opportunities">4.5.3 Opportunities for Impact</h3>
<p>Despite challenges, several factors favor adoption:</p>
<p><strong>Timing</strong>: AI governance needs tools now, creating receptive audiences</p>
<p><strong>Complementarity</strong>: AMTAIR enhances rather than replaces existing processes</p>
<p><strong>Flexibility</strong>: The approach adapts to different contexts and needs</p>
<p><strong>Network effects</strong>: Value increases as more perspectives are formalized</p>
<p>Early adopters in research organizations and think tanks can demonstrate value, creating momentum for broader adoption.</p>
</section>
</section>
<section id="sec-governance-integration" class="level2">
<h2 class="anchored" data-anchor-id="sec-governance-integration">4.6 Integration with Governance Frameworks</h2>
<!-- [-] TODO: Examine how modeling could complement existing AI governance -->
<p>AMTAIR complements rather than replaces existing governance approaches.</p>
<section id="sec-standards-integration" class="level3">
<h3 class="anchored" data-anchor-id="sec-standards-integration">4.6.1 Standards Development</h3>
<p>Technical standards bodies could use AMTAIR to:</p>
<ul>
<li>Model how proposed standards affect risk pathways</li>
<li>Compare different standard options systematically</li>
<li>Identify unintended consequences through pathway analysis</li>
<li>Build consensus through explicit model negotiation</li>
</ul>
<p>Example: Evaluating compute thresholds for AI system regulation by modeling how different thresholds affect capability development, safety investment, and competitive dynamics.</p>
</section>
<section id="sec-regulatory-integration" class="level3">
<h3 class="anchored" data-anchor-id="sec-regulatory-integration">4.6.2 Regulatory Design</h3>
<p>Regulators could apply the framework to:</p>
<ul>
<li>Assess regulatory impact across different scenarios</li>
<li>Identify enforcement challenges through explicit modeling</li>
<li>Compare international approaches systematically</li>
<li>Design adaptive regulations responsive to evidence</li>
</ul>
<p>Example: Analyzing how liability frameworks affect corporate AI development decisions under different market conditions.</p>
<!-- [-] Added citations about liability frameworks and corporate governance -->
<p>The extensive literature on corporate governance and liability frameworks <span class="citation" data-cites="cuomo2016">Cuomo, Mallin, and Zattoni (<a href="../../ref/references.html#ref-cuomo2016" role="doc-biblioref">2016</a>)</span> <span class="citation" data-cites="demirag2000">Demirag, Sudarsanam, and WRIGHT (<a href="../../ref/references.html#ref-demirag2000" role="doc-biblioref">2000</a>)</span> <span class="citation" data-cites="devilliers2021">De Villiers and Dimes (<a href="../../ref/references.html#ref-devilliers2021" role="doc-biblioref">2021</a>)</span> <span class="citation" data-cites="divito2022">Di Vito and Trottier (<a href="../../ref/references.html#ref-divito2022" role="doc-biblioref">2022</a>)</span> <span class="citation" data-cites="kaur2024">Kaur (<a href="../../ref/references.html#ref-kaur2024" role="doc-biblioref">2024</a>)</span> <span class="citation" data-cites="list2011">List and Pettit (<a href="../../ref/references.html#ref-list2011" role="doc-biblioref">2011</a>)</span> <span class="citation" data-cites="solomon2020">Solomon (<a href="../../ref/references.html#ref-solomon2020" role="doc-biblioref">2020</a>)</span> provides theoretical grounding for understanding how regulatory interventions shape organizational behavior. AMTAIR could formalize these relationships in the specific context of AI development, making explicit how different liability regimes might incentivize or discourage safety investments.</p>
</section>
<section id="sec-international-integration" class="level3">
<h3 class="anchored" data-anchor-id="sec-international-integration">4.6.3 International Coordination</h3>
<p>Multilateral bodies could leverage shared models for:</p>
<ul>
<li>Establishing common risk assessments</li>
<li>Negotiating agreements with explicit assumptions</li>
<li>Monitoring compliance through parameter tracking</li>
<li>Adapting agreements as evidence emerges</li>
</ul>
<p>Example: Building shared models for AGI development scenarios to inform international AI governance treaties.</p>
</section>
<section id="sec-organizational-integration" class="level3">
<h3 class="anchored" data-anchor-id="sec-organizational-integration">4.6.4 Organizational Decision-Making</h3>
<p>Individual organizations could use AMTAIR for:</p>
<ul>
<li>Internal risk assessment and planning</li>
<li>Board-level communication about AI strategies</li>
<li>Research prioritization based on model sensitivity</li>
<li>Safety case development with explicit assumptions</li>
</ul>
<p>Example: An AI lab modeling how different safety investments affect both capability advancement and risk mitigation.</p>
</section>
</section>
<section id="sec-future-research" class="level2">
<h2 class="anchored" data-anchor-id="sec-future-research">4.7 Future Research Directions</h2>
<!-- [-] TODO: Acknowledge fundamental limitations regarding novel developments -->
<p>Several research directions could enhance AMTAIR’s capabilities and impact.</p>
<section id="sec-technical-future" class="level3">
<h3 class="anchored" data-anchor-id="sec-technical-future">4.7.1 Technical Enhancements</h3>
<p><strong>Improved extraction</strong>: Fine-tuning language models specifically for argument extraction, handling implicit reasoning, and cross-document synthesis</p>
<p><strong>Richer representations</strong>: Temporal dynamics, continuous variables, and multi-agent interactions within extended frameworks</p>
<p><strong>Inference advances</strong>: Quantum computing applications, neural approximate inference, and hybrid symbolic-neural methods</p>
<p><strong>Validation methods</strong>: Automated consistency checking, anomaly detection in extracted models, and benchmark dataset development</p>
</section>
<section id="sec-methodological-future" class="level3">
<h3 class="anchored" data-anchor-id="sec-methodological-future">4.7.2 Methodological Extensions</h3>
<p><strong>Causal discovery</strong>: Inferring causal structures from data rather than just extracting from text</p>
<p><strong>Experimental integration</strong>: Connecting models to empirical results from AI safety experiments</p>
<p><strong>Dynamic updating</strong>: Continuous model refinement as new evidence emerges from research and deployment</p>
<p><strong>Uncertainty quantification</strong>: Richer representation of deep uncertainty and model confidence</p>
<!-- [-] Added citations about causal structure learning -->
<p>Recent advances in causal structure learning from both text and data <span class="citation" data-cites="babakov2025">Babakov et al. (<a href="../../ref/references.html#ref-babakov2025" role="doc-biblioref">2025</a>)</span> <span class="citation" data-cites="ban2023">Ban et al. (<a href="../../ref/references.html#ref-ban2023" role="doc-biblioref">2023</a>)</span> <span class="citation" data-cites="bethard2007">Bethard (<a href="../../ref/references.html#ref-bethard2007" role="doc-biblioref">2007</a>)</span> <span class="citation" data-cites="chen2023">Chen et al. (<a href="../../ref/references.html#ref-chen2023" role="doc-biblioref">2023</a>)</span> <span class="citation" data-cites="heinze-deml2018">Heinze-Deml, Maathuis, and Meinshausen (<a href="../../ref/references.html#ref-heinze-deml2018" role="doc-biblioref">2018</a>)</span> <span class="citation" data-cites="squires2023">Squires and Uhler (<a href="../../ref/references.html#ref-squires2023" role="doc-biblioref">2023</a>)</span> <span class="citation" data-cites="yang2022">Yang, Han, and Poon (<a href="../../ref/references.html#ref-yang2022" role="doc-biblioref">2022</a>)</span> suggest promising directions for enhancing AMTAIR’s extraction capabilities. The theoretical foundations from <span class="citation" data-cites="duhem1954">Duhem (<a href="../../ref/references.html#ref-duhem1954" role="doc-biblioref">1954</a>)</span> and <span class="citation" data-cites="meyer2022b">Meyer (<a href="../../ref/references.html#ref-meyer2022b" role="doc-biblioref">2022</a>)</span> on the philosophy of science and knowledge structures provide epistemological grounding for these methodological extensions.</p>
</section>
<section id="sec-application-future" class="level3">
<h3 class="anchored" data-anchor-id="sec-application-future">4.7.3 Application Domains</h3>
<p><strong>Beyond AI safety</strong>: Climate risk, biosecurity, nuclear policy, and other existential risks</p>
<p><strong>Corporate governance</strong>: Strategic planning, risk management, and innovation assessment</p>
<p><strong>Scientific modeling</strong>: Formalizing theoretical arguments in emerging fields</p>
<p><strong>Educational tools</strong>: Teaching probabilistic reasoning and critical thinking</p>
</section>
<section id="sec-ecosystem-future" class="level3">
<h3 class="anchored" data-anchor-id="sec-ecosystem-future">4.7.4 Ecosystem Development</h3>
<p><strong>Open standards</strong>: Common formats for model exchange and tool interoperability</p>
<p><strong>Community platforms</strong>: Collaborative model development and sharing infrastructure</p>
<p><strong>Training programs</strong>: Building capacity for formal modeling in governance communities</p>
<p><strong>Quality assurance</strong>: Certification processes for high-stakes model applications</p>
<p>These directions could transform AMTAIR from a single tool into a broader ecosystem for enhanced reasoning about complex risks.</p>
</section>
</section>
<section id="sec-deep-uncertainties" class="level2">
<h2 class="anchored" data-anchor-id="sec-deep-uncertainties">4.8 Known Unknowns and Deep Uncertainties</h2>
<p>While AMTAIR enhances reasoning under uncertainty, fundamental limitations remain regarding truly novel developments that might fall outside existing conceptual frameworks.</p>
<section id="sec-uncertainty-categories" class="level3">
<h3 class="anchored" data-anchor-id="sec-uncertainty-categories">4.8.1 Categories of Deep Uncertainty</h3>
<p><strong>Novel Capabilities</strong>: Future AI developments may operate according to principles outside current scientific understanding. No amount of careful modeling can anticipate fundamental paradigm shifts in what intelligence can accomplish.</p>
<p><strong>Emergent Behaviors</strong>: Complex system properties that resist prediction from component analysis may dominate outcomes. The interaction between advanced AI systems and human society could produce wholly unexpected dynamics.</p>
<p><strong>Strategic Interactions</strong>: Game-theoretic dynamics with superhuman AI systems exceed human modeling capacity. We cannot reliably predict how entities smarter than us will behave strategically.</p>
<p><strong>Social Transformation</strong>: Unprecedented social and economic changes may invalidate current institutional assumptions. Our models assume continuity in basic social structures that AI might fundamentally alter.</p>
</section>
<section id="sec-adaptation-strategies" class="level3">
<h3 class="anchored" data-anchor-id="sec-adaptation-strategies">4.8.2 Adaptation Strategies for Deep Uncertainty</h3>
<p>Rather than pretending to model the unmodelable, AMTAIR incorporates several strategies:</p>
<p><strong>Model Architecture Flexibility</strong>: The modular structure enables rapid incorporation of new variables as novel factors become apparent. When surprises occur, models can be updated rather than discarded.</p>
<p><strong>Explicit Uncertainty Tracking</strong>: Confidence levels for each model component make clear where knowledge is solid versus speculative. This prevents false confidence in highly uncertain domains.</p>
<p><strong>Scenario Branching</strong>: Multiple model variants capture different assumptions about fundamental uncertainties. Rather than committing to one worldview, the system maintains portfolios of possibilities.</p>
<p><strong>Update Mechanisms</strong>: Integration with prediction markets and expert assessment enables rapid model revision as new information emerges. Models evolve rather than remaining static.</p>
</section>
<section id="sec-robust-principles" class="level3">
<h3 class="anchored" data-anchor-id="sec-robust-principles">4.8.3 Robust Decision-Making Principles</h3>
<p>Given deep uncertainty, certain decision principles become paramount:</p>
<p><strong>Option Value Preservation</strong>: Policies should maintain flexibility for future course corrections rather than locking in irreversible choices based on current models.</p>
<p><strong>Portfolio Diversification</strong>: Multiple approaches hedging across different uncertainty sources provide robustness against model error.</p>
<p><strong>Early Warning Systems</strong>: Monitoring for developments that would invalidate current models enables rapid response when assumptions break down.</p>
<p><strong>Adaptive Governance</strong>: Institutional mechanisms must enable rapid response to new information rather than rigid adherence to plans based on outdated models.</p>
<p>The goal is not to eliminate uncertainty but to make good decisions despite it. AMTAIR provides tools for systematic reasoning about what we do know while maintaining appropriate humility about what we don’t and can’t know.</p>
</section>
</section>
<section id="sec-implications-summary" class="level2">
<h2 class="anchored" data-anchor-id="sec-implications-summary">4.9 Summary of Implications</h2>
<p>The discussion reveals both the promise and limitations of computational approaches to AI governance coordination:</p>
<p><strong>Technical Feasibility</strong>: Despite imperfections, automated extraction and formal modeling prove practically viable for complex AI risk arguments.</p>
<p><strong>Epistemic Value</strong>: Making implicit models explicit, enabling systematic comparison, and supporting evidence integration enhance collective reasoning.</p>
<p><strong>Practical Limitations</strong>: Extraction boundaries, false precision risks, and implementation dependencies require careful management.</p>
<p><strong>Integration Potential</strong>: The approach complements rather than replaces existing governance frameworks, adding rigor without sacrificing flexibility.</p>
<p><strong>Future Development</strong>: Technical enhancements, methodological extensions, and ecosystem growth could amplify impact.</p>
<p><strong>Deep Uncertainty</strong>: Fundamental limits on predicting novel developments require maintaining humility and adaptability.</p>
<p>These findings suggest AMTAIR represents a valuable addition to the AI governance toolkit—not a panacea but a meaningful enhancement to our collective capacity for navigating unprecedented challenges.</p>
</section>
</section>
<section id="sec-conclusion" class="level1">
<h1>5. Conclusion: Toward Coordinated AI Governance</h1>
<!-- 
**Chapter Overview**  
**Grade Weight**: 10% | **Target Length**: ~14% of text (~4,200 words)  
**Requirements**: Summarizes thesis and argument, outlines implications, notes limitations, points to future research
-->
<!-- [-] TODO: Ensure strong connection back to introduction themes -->
<section id="sec-key-contributions" class="level2">
<h2 class="anchored" data-anchor-id="sec-key-contributions">5.1 Summary of Key Contributions</h2>
<p>This thesis has demonstrated both the need for and feasibility of computational approaches to enhancing coordination in AI governance. The work makes several distinct contributions across theory, methodology, and implementation.</p>
<section id="sec-theoretical-contributions" class="level3">
<h3 class="anchored" data-anchor-id="sec-theoretical-contributions">5.1.1 Theoretical Contributions</h3>
<p><strong>Diagnosis of the Coordination Crisis</strong>: I’ve articulated how fragmentation across technical, policy, and strategic communities systematically amplifies existential risk from advanced AI. This framing moves beyond identifying disagreements to understanding how misaligned efforts create negative-sum dynamics—safety gaps emerge between communities, resources are misallocated through duplication and neglect, and interventions interact destructively.</p>
<p><strong>The Multiplicative Benefits Framework</strong>: The combination of automated extraction, prediction market integration, and formal policy evaluation creates value exceeding the sum of parts. Automation enables scale, markets provide empirical grounding, and policy analysis delivers actionable insights. Together, they address different facets of the coordination challenge while reinforcing each other’s strengths.</p>
<p><strong>Epistemic Infrastructure Conception</strong>: Positioning formal models as epistemic infrastructure reframes the role of technical tools in governance. Rather than replacing human judgment, computational approaches provide common languages, shared representations, and systematic methods for managing disagreement—essential foundations for coordination under uncertainty.</p>
</section>
<section id="sec-methodological-innovations" class="level3">
<h3 class="anchored" data-anchor-id="sec-methodological-innovations">5.1.2 Methodological Innovations</h3>
<p><strong>Two-Stage Extraction Architecture</strong>: Separating structural extraction (ArgDown) from probability quantification (BayesDown) addresses key challenges in automated formalization. This modularity enables human oversight at critical points, supports multiple quantification methods, allows for unprecedented transparency and explainability of the entire process, and isolates different types of errors for targeted improvement.</p>
<p><strong>BayesDown as Bridge Representation</strong>: The development of BayesDown syntax creates a crucial intermediate representation preserving both narrative accessibility and mathematical precision. This bridge enables the transformation from qualitative arguments to quantitative models while maintaining traceability and human readability.</p>
<p><strong>Validation Framework</strong>: The systematic approach to validating automated extraction—comparing against expert annotations, measuring multiple accuracy dimensions, and analyzing error patterns—establishes scientific standards for assessing formalization tools. This framework can guide future development in this emerging area.</p>
</section>
<section id="sec-technical-achievements" class="level3">
<h3 class="anchored" data-anchor-id="sec-technical-achievements">5.1.3 Technical Achievements</h3>
<p><strong>Working Implementation</strong>: AMTAIR demonstrates end-to-end feasibility from document ingestion through interactive visualization. The system successfully processes complex arguments like Carlsmith’s power-seeking AI model, extracting hierarchical structures and probability information.</p>
<p><strong>Scalability Solutions</strong>: Technical approaches for handling realistic model complexity—hierarchical decomposition, approximate inference, and progressive visualization—show that computational limitations need not prevent practical application.</p>
<p><strong>Accessibility Design</strong>: The layered interface approach serves diverse stakeholders without compromising technical depth. Progressive disclosure, visual encoding, and interactive exploration make formal models accessible beyond technical specialists.</p>
</section>
<section id="sec-empirical-findings" class="level3">
<h3 class="anchored" data-anchor-id="sec-empirical-findings">5.1.4 Empirical Findings</h3>
<p><strong>Extraction Feasibility</strong>: The successful extraction of complex arguments like Carlsmith’s model validates the core premise that implicit formal structures exist in natural language arguments and can be computationally recovered with reasonable fidelity.</p>
<p><strong>Convergence Patterns</strong>: Theoretical analysis suggests that formal comparison would reveal structural agreements across different expert worldviews even when probability estimates diverge—providing foundations for coordination.</p>
<p><strong>Intervention Impacts</strong>: Policy evaluation capabilities demonstrate how formal models enable rigorous assessment of governance options. The ability to trace intervention effects through complex causal networks validates the practical value of formalization.</p>
</section>
</section>
<section id="sec-limitations-assessment" class="level2">
<h2 class="anchored" data-anchor-id="sec-limitations-assessment">5.2 Limitations and Honest Assessment</h2>
<p>Despite these contributions, important limitations constrain current capabilities and should guide appropriate use.</p>
<section id="sec-technical-constraints" class="level3">
<h3 class="anchored" data-anchor-id="sec-technical-constraints">5.2.1 Technical Constraints</h3>
<p><strong>Extraction Boundaries</strong>: The system struggles with implicit assumptions, complex conditionals, and ambiguous quantifiers. These limitations necessitate human review for high-stakes applications.</p>
<p><strong>Correlation Handling</strong>: Standard Bayesian networks inadequately represent complex correlations in real systems. While extensions like copulas and explicit correlation nodes help, fully capturing interdependencies remains challenging.</p>
<p><strong>Computational Scaling</strong>: Very large networks require approximations that may affect accuracy. As models grow to represent richer phenomena, computational constraints increasingly bind.</p>
</section>
<section id="sec-conceptual-limitations" class="level3">
<h3 class="anchored" data-anchor-id="sec-conceptual-limitations">5.2.2 Conceptual Limitations</h3>
<p><strong>Formalization Trade-offs</strong>: Converting rich arguments to formal models necessarily loses nuance. While making assumptions explicit provides value, some insights resist mathematical representation.</p>
<p><strong>Probability Interpretation</strong>: Deep uncertainty about unprecedented events challenges probabilistic representation. Numbers can create false precision even when explicitly conditional and uncertain.</p>
<p><strong>Social Complexity</strong>: Institutional dynamics, cultural factors, and political processes influence AI development in ways that causal models struggle to capture fully.</p>
</section>
<section id="sec-practical-constraints" class="level3">
<h3 class="anchored" data-anchor-id="sec-practical-constraints">5.2.3 Practical Constraints</h3>
<p><strong>Adoption Barriers</strong>: Learning curves, institutional inertia, and resource requirements limit immediate deployment. Even demonstrably valuable tools face implementation challenges.</p>
<p><strong>Maintenance Burden</strong>: Models require updating as arguments evolve and evidence emerges. Without sustained effort, formal representations quickly become outdated.</p>
<p><strong>Context Dependence</strong>: The approach works best for well-structured academic arguments. Application to informal discussions or political rhetoric remains challenging.</p>
</section>
</section>
<section id="sec-governance-implications" class="level2">
<h2 class="anchored" data-anchor-id="sec-governance-implications">5.3 Implications for AI Governance</h2>
<!-- [-] TODO: Provide concrete recommendations for stakeholders -->
<p>Despite limitations, AMTAIR’s approach offers significant implications for how AI governance can evolve toward greater coordination and effectiveness.</p>
<section id="sec-near-term-applications" class="level3">
<h3 class="anchored" data-anchor-id="sec-near-term-applications">5.3.1 Near-Term Applications</h3>
<p><strong>Research Coordination</strong>: Research organizations can use formal models to:</p>
<ul>
<li>Map the landscape of current arguments and identify gaps</li>
<li>Prioritize investigations targeting high-sensitivity parameters</li>
<li>Build cumulative knowledge through explicit model updating</li>
<li>Facilitate collaboration through shared representations</li>
</ul>
<p><strong>Policy Development</strong>: Governance bodies can apply the framework to:</p>
<ul>
<li>Evaluate proposals across multiple expert worldviews</li>
<li>Identify robust interventions effective under uncertainty</li>
<li>Make assumptions explicit for democratic scrutiny</li>
<li>Track how evidence changes optimal policies over time</li>
</ul>
<p><strong>Stakeholder Communication</strong>: The visualization and analysis tools enable:</p>
<ul>
<li>Clearer communication between technical and policy communities</li>
<li>Public engagement with complex risk assessments</li>
<li>Board-level strategic discussions grounded in formal analysis</li>
<li>International negotiations with explicit shared models</li>
</ul>
</section>
<section id="sec-medium-term" class="level3">
<h3 class="anchored" data-anchor-id="sec-medium-term">5.3.2 Medium-Term Transformation</h3>
<p>As adoption spreads, we might see:</p>
<p><strong>Epistemic Commons</strong>: Shared repositories of formalized arguments become reference points for governance discussions, similar to how economic models inform monetary policy or climate models guide environmental agreements.</p>
<p><strong>Adaptive Governance</strong>: Policies designed with explicit models can include triggers for reassessment as key parameters change, enabling responsive governance that avoids both paralysis and recklessness.</p>
<p><strong>Professionalization</strong>: “Model curator” and “argument formalization specialist” emerge as recognized roles, building expertise in bridging natural language and formal representations.</p>
<p><strong>Quality Standards</strong>: Community norms develop around model transparency, validation requirements, and appropriate use cases, preventing both dismissal and over-reliance on formal tools.</p>
</section>
<section id="sec-long-term-vision" class="level3">
<h3 class="anchored" data-anchor-id="sec-long-term-vision">5.3.3 Long-Term Vision</h3>
<p>Successfully scaling this approach could fundamentally alter AI governance:</p>
<p><strong>Coordinated Response</strong>: Rather than fragmented efforts, the AI safety ecosystem could operate with shared situational awareness—different actors understanding how their efforts interact and contribute to collective goals.</p>
<p><strong>Anticipatory Action</strong>: Formal models with prediction market integration could provide early warning of emerging risks, enabling proactive rather than reactive governance.</p>
<p><strong>Global Cooperation</strong>: Shared formal frameworks could facilitate international coordination similar to how economic models enable monetary coordination or climate models support environmental agreements.</p>
<p><strong>Democratic Enhancement</strong>: Making expert reasoning transparent and modifiable could enable broader participation in crucial decisions about humanity’s technological future.</p>
<p>The long-term vision feels almost embarrassingly ambitious when stated plainly. Could this approach fundamentally alter AI governance? Maybe. Probably not in the revolutionary way manifestos promise. More likely, it becomes one tool among many, useful in specific contexts, gradually improving as more people use it and complain about its limitations. But sometimes I imagine a world where policy discussions start with shared models rather than conflicting narratives. Where “let’s check what the model says” becomes as natural as “let’s check what the data says.” Where international negotiations involve parameter haggling rather than rhetorical grandstanding. It’s a nice vision. Whether we get there—well, that depends on factors far beyond any technical system.</p>
</section>
</section>
<section id="sec-recommendations" class="level2">
<h2 class="anchored" data-anchor-id="sec-recommendations">5.4 Recommendations for Stakeholders</h2>
<p>Different communities can take concrete steps to realize these benefits:</p>
<section id="sec-researcher-recommendations" class="level3">
<h3 class="anchored" data-anchor-id="sec-researcher-recommendations">5.4.1 For Researchers</h3>
<ol type="1">
<li><strong>Experiment with formalization</strong>: Try extracting your own arguments into ArgDown/BayesDown format to discover implicit assumptions</li>
<li><strong>Contribute to validation</strong>: Provide expert annotations for building benchmark datasets and improving extraction quality</li>
<li><strong>Develop extensions</strong>: Build on the open-source foundation to add capabilities for your specific domain needs</li>
<li><strong>Publish formally</strong>: Include formal model representations alongside traditional papers to enable cumulative building</li>
</ol>
</section>
<section id="sec-policymaker-recommendations" class="level3">
<h3 class="anchored" data-anchor-id="sec-policymaker-recommendations">5.4.2 For Policymakers</h3>
<ol type="1">
<li><strong>Pilot applications</strong>: Use AMTAIR for internal analysis of specific policy proposals to build familiarity and identify value</li>
<li><strong>Demand transparency</strong>: Request formal models underlying expert recommendations to understand assumptions and uncertainties</li>
<li><strong>Fund development</strong>: Support tool development and training to build governance capacity for formal methods</li>
<li><strong>Design adaptively</strong>: Create policies with explicit triggers based on model parameters to enable responsive governance</li>
</ol>
</section>
<section id="sec-technologist-recommendations" class="level3">
<h3 class="anchored" data-anchor-id="sec-technologist-recommendations">5.4.3 For Technologists</h3>
<ol type="1">
<li><strong>Improve extraction</strong>: Contribute better prompting strategies, fine-tuned models, or validation methods</li>
<li><strong>Enhance interfaces</strong>: Develop visualizations and interactions serving specific stakeholder needs</li>
<li><strong>Build integrations</strong>: Connect AMTAIR to other tools in the AI governance ecosystem</li>
<li><strong>Scale infrastructure</strong>: Address computational challenges for larger models and broader deployment</li>
</ol>
</section>
</section>
<section id="sec-future-research-agenda" class="level2">
<h2 class="anchored" data-anchor-id="sec-future-research-agenda">5.5 Future Research Agenda</h2>
<p>Looking ahead, the landscape of possibilities stretches toward the horizon, each path promising its own rewards and challenges. Let me map the territory worth exploring.</p>
<section id="sec-technical-priorities" class="level3">
<h3 class="anchored" data-anchor-id="sec-technical-priorities">5.5.1 Technical Priorities</h3>
<p>The technical frontier advances on multiple fronts, each offering multiplicative improvements when combined:</p>
<p><strong>Extraction Enhancement</strong>: The current system, while functional, merely scratches the surface of what’s possible. Fine-tuning language models specifically on argument extraction tasks could dramatically improve accuracy. Imagine models trained not just on general text but on thousands of examples of arguments transformed into formal representations.</p>
<p><strong>Handling Implicit Reasoning</strong>: So much of expert argumentation relies on unstated background knowledge. When an AI safety researcher mentions “mesa-optimization,” they assume familiarity with complex concepts about learned optimization occurring within larger optimization processes. Future systems need to bridge these inferential gaps, perhaps by maintaining explicit knowledge bases of domain concepts or by training models to recognize and fill common argumentative ellipses.</p>
<p><strong>Cross-Document Synthesis</strong>: Real understanding emerges not from single papers but from conversations across documents. Authors respond to each other, build on previous work, refine arguments over time. Future systems should trace these intellectual lineages, building composite models that capture evolving community understanding rather than static snapshots.</p>
<p><strong>Representation Extensions</strong>: Current Bayesian networks, while powerful, make limiting assumptions. Temporal dynamics matter—AI development unfolds over time, with early decisions constraining later options. Multi-agent representations could capture strategic interactions between actors. Continuous variables better represent quantities like “capability level” than binary approximations. Each extension opens new analytical possibilities.</p>
<!-- [-] COMPLETED: Added technical priorities -->
</section>
<section id="sec-methodological-development" class="level3">
<h3 class="anchored" data-anchor-id="sec-methodological-development">5.5.2 Methodological Development</h3>
<p>Beyond technical improvements lie deeper methodological questions about how we validate, use, and improve these systems:</p>
<p><strong>Validation Science</strong>: We need not just ad hoc evaluation but a science of argument extraction assessment. This means building benchmark datasets capturing diverse argument types, developing metrics that go beyond surface accuracy to semantic fidelity, creating adversarial test suites that probe system limitations, and establishing longitudinal studies tracking how extracted models evolve with updating source documents.</p>
<p><strong>Hybrid Intelligence</strong>: The future isn’t human or AI but human and AI. Optimal collaboration patterns remain unexplored. Should humans verify structure while AI handles probabilities? Should AI propose multiple extractions for human selection? How do we combine formal models with scenario narratives, quantitative forecasts with qualitative insights? The design space for human-AI collaboration in argument formalization remains largely uncharted.</p>
<p><strong>Social Methods</strong>: Technology embedded in social contexts requires social science. How do organizations actually use these models? What changes when formal representations replace informal discussions? Ethnographic studies of model use, measurement of coordination improvements, identification of adoption barriers—all essential for real-world impact.</p>
<!-- [-] COMPLETED: Added methodological development -->
</section>
<section id="sec-application-expansion" class="level3">
<h3 class="anchored" data-anchor-id="sec-application-expansion">5.5.3 Application Expansion</h3>
<p>The principles underlying AMTAIR apply far beyond AI risk:</p>
<p><strong>Domain Extensions</strong>: Every field grappling with complex risks could benefit. Biosecurity faces similar challenges—technical complexity, value-laden choices, deep uncertainty. Climate policy involves multi-level causation across physical, economic, and social systems. Nuclear policy, despite decades of study, still struggles with coordination across technical and strategic communities. Each domain would require specialized extraction approaches but could leverage the same fundamental architecture.</p>
<p><strong>Institutional Integration</strong>: Moving from research prototype to institutional tool requires thoughtful embedding. Regulatory impact assessment could incorporate formal modeling to make assumptions explicit. Corporate strategic planning, especially for companies developing advanced technologies, needs tools for reasoning about unprecedented risks. Academic peer review might benefit from formal representation of complex arguments.</p>
<p><strong>Global Deployment</strong>: AI governance is inherently international, but different regions have different governance cultures, risk tolerances, and institutional structures. Adapting AMTAIR for different contexts—from Silicon Valley’s move-fast culture to the EU’s precautionary approach to China’s state-led development—requires both technical and cultural translation.</p>
<!-- [-] COMPLETED: Added application expansion -->
<!-- 

## 5.6 Closing Reflections {#sec-closing-reflections}

Writing these final paragraphs, I find myself thinking about Sarah, our hypothetical policy advisor from the introduction. Has this work made her job easier? The honest answer is: marginally, yes, but the fundamental challenge remains daunting.

AMTAIR offers Sarah tools she didn't have before. She can now see, literally see, how different expert arguments relate to each other. Where before she had to hold competing worldviews in her head, struggling to identify where they genuinely diverged versus where terminology obscured agreement, she now has visual representations that make these relationships explicit. The formal models won't make her decisions for her, but they might help her make better-informed decisions.

The journey from initial concept to working system taught me more about the problem than about the solution. I began thinking the coordination crisis stemmed primarily from communication failures—experts talking past each other, using different terms for similar concepts. Build translation tools, I reasoned, and coordination would follow. The reality proved more complex. Even with perfect communication, deep disagreements about values, priorities, and acceptable risks remain. Tools can clarify these disagreements but not resolve them.

What surprised me most was how the process of formalization itself generated insights. Forcing myself to make extraction rules explicit revealed my own implicit assumptions about how arguments work. Watching the system fail in predictable ways illuminated the remarkable sophistication of human textual understanding. Building visualizations that actually aided comprehension required confronting how poorly we typically communicate uncertainty.

The technical contributions of this work—the two-stage extraction pipeline, the BayesDown notation, the visualization system—feel less like culminating achievements and more like initial sketches of what's needed. Each component works well enough to demonstrate feasibility but would require substantial refinement for production use. The validation remains preliminary, the scaling challenges largely unaddressed, the integration with existing governance frameworks more theoretical than practical.

Yet I remain cautiously optimistic about the approach's potential. Not because AMTAIR solves the coordination crisis—it doesn't—but because it represents the kind of epistemic infrastructure we'll need as AI capabilities advance. The choice isn't between perfect and imperfect tools but between imperfect tools and no tools at all. In a domain where the stakes approach infinity and time grows short, even marginal improvements in coordination capacity matter.

The work continues, as it must. Each month brings new AI capabilities that challenge existing frameworks. Each breakthrough raises the stakes. Each failure to coordinate effectively increases cumulative risk. Whether humanity successfully navigates the transition to advanced AI remains radically uncertain. What seems clear is that success, if it comes, will require unprecedented coordination across communities that currently struggle to understand each other. AMTAIR represents one small attempt to build bridges. Many more are needed.

To future readers—whether you're reading this in a world made wonderful by aligned AI or studying how we tried and failed—know that we saw the challenge clearly. We understood the stakes. We built what tools we could with the time and knowledge available. The rest, as they say, is history. Or will be. -->
</section>
</section>
<section id="sec-closing-reflections" class="level2">
<h2 class="anchored" data-anchor-id="sec-closing-reflections">5.6 Closing Reflections</h2>
<p>As I write these final words, I’m struck by the peculiar position we find ourselves in. We are arguably the first generation that must govern technologies that could fundamentally transform or terminate our species’ story. The margin for error shrinks as capabilities grow. The cost of coordination failure rises toward infinity.</p>
<p>The AMTAIR project emerged from a simple observation paired with an ambitious hope. The observation: while humanity mobilizes unprecedented resources to address AI risks, our efforts remain tragically uncoordinated. Different communities work with incompatible frameworks, duplicate efforts, and sometimes actively undermine each other’s work. The hope: that computational tools might help us build the epistemic infrastructure necessary for coordination.</p>
<p>What we’ve accomplished here is both less and more than originally envisioned. Less, because the challenges proved deeper than anticipated. Natural language resists formalization. Probabilities remain stubbornly subjective. Coordination failures have roots beyond mere communication difficulties. More, because the journey revealed unexpected possibilities. Intermediate representations became valuable in themselves. The extraction process surfaced insights about argument structure. The visualization work demonstrated how thoughtful design can democratize access to formal tools.</p>
<p>Perhaps most importantly, this work demonstrates that perfect solutions need not be the enemy of meaningful progress. AMTAIR doesn’t solve the coordination crisis—no single tool could. But it offers genuine assistance: making implicit models explicit, enabling systematic comparison across worldviews, supporting evidence-based policy evaluation, and creating common ground for productive disagreement.</p>
<p>The journey from initial concept to working system taught me more about the problem than about the solution. I began thinking the coordination crisis stemmed primarily from communication failures—experts talking past each other, using different terms for similar concepts. Build translation tools, I reasoned, and coordination would follow. The reality proved more complex. Even with perfect communication, deep disagreements about values, priorities, and acceptable risks remain. Tools can clarify these disagreements but not resolve them.</p>
<p>What surprised me most was how the process of formalization itself generated insights. Forcing myself to make extraction rules explicit revealed my own implicit assumptions about how arguments work. Watching the system fail in predictable ways illuminated the remarkable sophistication of human textual understanding. Building visualizations that actually aided comprehension required confronting how poorly we typically communicate uncertainty.</p>
<p>The technical contributions of this work—the two-stage extraction pipeline, the BayesDown notation, the visualization system—feel less like culminating achievements and more like initial sketches of what’s needed. Each component works well enough to demonstrate feasibility but would require substantial refinement for production use. The validation remains preliminary, the scaling challenges largely unaddressed, the integration with existing governance frameworks more theoretical than practical.</p>
<p>Yet I remain optimistic about the approach’s potential. Not because AMTAIR solves the coordination crisis—it doesn’t—but because it represents the kind of epistemic infrastructure we’ll need as AI capabilities advance. The choice isn’t between perfect and imperfect tools but between imperfect tools and no tools at all. In a domain where the stakes approach infinity and time grows short, even marginal improvements in coordination capacity matter.</p>
<p><strong>The Stakes</strong>: Let me be plain about what’s at risk. The development of artificial general intelligence represents a discontinuity in human history comparable to the emergence of life or the evolution of consciousness. Get it right, and we might solve problems that have plagued humanity since our beginning—disease, poverty, ignorance, perhaps even death itself. Get it wrong, and we might extinguish not just ourselves but all the potential futures we might have created.</p>
<p>This isn’t science fiction or academic speculation. The capabilities advancing in labs today point toward systems that could, within decades or less, exceed human cognitive abilities across all domains. What happens when we create minds greater than our own? How do we ensure they remain aligned with human values and flourishing? These questions demand our best collective wisdom.</p>
<p>Currently we approach this challenge fragmented. Technical researchers develop alignment techniques without clear paths to implementation. Policymakers craft governance frameworks without deep technical understanding. Ethicists articulate values without operational specificity. International bodies convene without shared models of the risks they’re addressing. This fragmentation isn’t just inefficient—it’s existentially dangerous.</p>
<p>AMTAIR represents one attempt to build bridges. By automating the extraction of worldviews, integrating live forecasts, and enabling systematic policy evaluation, we create infrastructure for enhanced coordination. Not coordination itself—that requires human wisdom, institutional change, and political will. But infrastructure that makes coordination more feasible.</p>
<p>The path forward demands both ambition and humility. Ambition to build the tools, institutions, and practices necessary for navigating unprecedented risks. Humility to recognize that our tools are imperfect, our understanding incomplete, and our time limited. We must act despite uncertainty, coordinate despite disagreement, and hope despite the magnitude of the challenge.</p>
<p>As I close this thesis, I think of future readers—perhaps humans living in a world made wonderful by aligned AI, perhaps historians studying how we navigated this crucial transition, perhaps no one at all if we fail. To those readers, know that we tried. We saw the challenge, recognized our limitations, and attempted to build what tools we could.</p>
<p>The coordination crisis in AI governance represents both existential risk and existential opportunity. Risk, if we fail to align our efforts before it’s too late. Opportunity, if we succeed in creating unprecedented cooperation around humanity’s most important challenge. AMTAIR offers one piece of the puzzle—computational infrastructure that enhances our collective ability to reason about complex risks.</p>
<p>The work continues, as it must. Each month brings new AI capabilities that challenge existing frameworks. Each breakthrough raises the stakes. Each failure to coordinate effectively increases cumulative risk. Whether humanity successfully navigates the transition to advanced AI remains radically uncertain. What seems clear is that success, if it comes, will require unprecedented coordination across communities that currently struggle to understand each other. AMTAIR represents one small attempt to build bridges. Many more are needed. May we prove worthy of the challenge before us. May our tools amplify our wisdom rather than our folly.</p>
<p>To future readers—whether you’re reading this in a world made wonderful by aligned AI or studying how we tried and failed—know that we saw the challenge clearly. We understood the stakes. We built what tools we could with the time and knowledge available. The rest, as they say, is history. Or will be.</p>
<p>The work continues. The stakes could not be higher. The time grows short. Let us build what we can, while we can, for all our futures depend on it.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-anderson2007" class="csl-entry" role="listitem">
Anderson, Terence J. 2007. <span>“Visualization Tools and Argument Schemes: A Question of Standpoint.”</span> <em>Law, Prob. &amp; Risk</em> 6: 97. <a href="https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/lawprisk6&amp;section=9">https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/lawprisk6&amp;section=9</a>.
</div>
<div id="ref-armstrong2016" class="csl-entry" role="listitem">
Armstrong, Stuart, Nick Bostrom, and Carl Shulman. 2016. <span>“Racing to the Precipice: A Model of Artificial Intelligence Development.”</span> <em>AI &amp; SOCIETY</em> 31 (2): 201–6. <a href="https://doi.org/10.1007/s00146-015-0590-y">https://doi.org/10.1007/s00146-015-0590-y</a>.
</div>
<div id="ref-babakov2025" class="csl-entry" role="listitem">
Babakov, Nikolay, Adarsa Sivaprasad, Ehud Reiter, and Alberto Bugarín-Diz. 2025. <span>“Reusability of <span>Bayesian Networks</span> Case Studies: A Survey.”</span> <em>Applied Intelligence</em> 55 (6): 417. <a href="https://doi.org/10.1007/s10489-025-06289-5">https://doi.org/10.1007/s10489-025-06289-5</a>.
</div>
<div id="ref-ban2023" class="csl-entry" role="listitem">
Ban, Taiyu, Lyuzhou Chen, Derui Lyu, Xiangyu Wang, and Huanhuan Chen. 2023. <span>“Causal <span>Structure Learning Supervised</span> by <span>Large Language Model</span>.”</span> November 20, 2023. <a href="https://doi.org/10.48550/arXiv.2311.11689">https://doi.org/10.48550/arXiv.2311.11689</a>.
</div>
<div id="ref-benn2011" class="csl-entry" role="listitem">
Benn, Neil, and Ann Macintosh. 2011. <span>“Argument <span>Visualization</span> for <span class="nocase">eParticipation</span>: <span>Towards</span> a <span>Research Agenda</span> and <span>Prototype Tool</span>.”</span> In <em>Electronic <span>Participation</span></em>, edited by Efthimios Tambouris, Ann Macintosh, and Hans De Bruijn, 6847:60–73. Berlin, Heidelberg: Springer Berlin Heidelberg. <a href="https://doi.org/10.1007/978-3-642-23333-3_6">https://doi.org/10.1007/978-3-642-23333-3_6</a>.
</div>
<div id="ref-bethard2007" class="csl-entry" role="listitem">
Bethard, Steven John. 2007. <span>“Finding Event, Temporal and Causal Structure in Text: <span>A</span> Machine Learning Approach.”</span> PhD thesis, University of Colorado at Boulder. <a href="https://search.proquest.com/openview/405fe32503123d9b5f4836dc3be4c011/1?pq-origsite=gscholar&amp;cbl=18750">https://search.proquest.com/openview/405fe32503123d9b5f4836dc3be4c011/1?pq-origsite=gscholar&amp;cbl=18750</a>.
</div>
<div id="ref-bostrom2014" class="csl-entry" role="listitem">
Bostrom, Nick. 2014. <em>Superintelligence: <span>Paths</span>, Strategies, Dangers</em>. Oxford: Oxford University Press. <a href="https://scholar.dominican.edu/cynthia-stokes-brown-books-big-history/47">https://scholar.dominican.edu/cynthia-stokes-brown-books-big-history/47</a>.
</div>
<div id="ref-bucknall2022" class="csl-entry" role="listitem">
Bucknall, Benjamin S., and Shiri Dori-Hacohen. 2022. <span>“Current and <span>Near-Term AI</span> as a <span>Potential Existential Risk Factor</span>.”</span> In <em>Proceedings of the 2022 <span>AAAI</span>/<span>ACM Conference</span> on <span>AI</span>, <span>Ethics</span>, and <span>Society</span></em>, 119–29. Oxford United Kingdom: ACM. <a href="https://doi.org/10.1145/3514094.3534146">https://doi.org/10.1145/3514094.3534146</a>.
</div>
<div id="ref-carlsmith2021" class="csl-entry" role="listitem">
Carlsmith, Joseph. 2021. <span>“Is <span>Power-Seeking AI</span> an <span>Existential Risk</span>?”</span> 2021. <a href="https://doi.org/10.48550/arXiv.2206.13353">https://doi.org/10.48550/arXiv.2206.13353</a>.
</div>
<div id="ref-carlsmith2022" class="csl-entry" role="listitem">
———. 2022. <span>“Is Power-Seeking <span>AI</span> an Existential Risk?”</span> <a href="https://arxiv.org/abs/2206.13353">https://arxiv.org/abs/2206.13353</a>.
</div>
<div id="ref-carlsmith2024" class="csl-entry" role="listitem">
———. 2024. <span>“Is <span>Power-Seeking AI</span> an <span>Existential Risk</span>?”</span> August 13, 2024. <a href="https://doi.org/10.48550/arXiv.2206.13353">https://doi.org/10.48550/arXiv.2206.13353</a>.
</div>
<div id="ref-chen2023" class="csl-entry" role="listitem">
Chen, Lu, Ruqing Zhang, Wei Huang, Wei Chen, Jiafeng Guo, and Xueqi Cheng. 2023. <span>“Inducing <span>Causal Structure</span> for <span>Abstractive Text Summarization</span>.”</span> In <em>Proceedings of the 32nd <span>ACM International Conference</span> on <span>Information</span> and <span>Knowledge Management</span></em>, 213–23. Birmingham United Kingdom: ACM. <a href="https://doi.org/10.1145/3583780.3614934">https://doi.org/10.1145/3583780.3614934</a>.
</div>
<div id="ref-christiano2019" class="csl-entry" role="listitem">
Christiano, Paul F. 2019. <span>“What Failure Looks Like,”</span> March. <a href="https://www.alignmentforum.org/posts/HBxe6wdjxK239zajf/what-failure-looks-like">https://www.alignmentforum.org/posts/HBxe6wdjxK239zajf/what-failure-looks-like</a>.
</div>
<div id="ref-clarke2022" class="csl-entry" role="listitem">
Clarke, Sam, Ben Cottier, Aryeh Englander, Daniel Eth, David Manheim, Samuel Dylan Martin, and Issa Rice. 2022. <span>“Modeling <span>Transformative AI Risks</span> (<span>MTAIR</span>) <span>Project</span> – <span>Summary Report</span>.”</span> 2022. <a href="https://doi.org/10.48550/ARXIV.2206.09360">https://doi.org/10.48550/ARXIV.2206.09360</a>.
</div>
<div id="ref-cottier2019" class="csl-entry" role="listitem">
Cottier, Ben, and Rohin Shah. 2019. <span>“Clarifying Some Key Hypotheses in <span>AI</span> Alignment,”</span> August. <a href="https://www.lesswrong.com/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment">https://www.lesswrong.com/posts/mJ5oNYnkYrd4sD5uE/clarifying-some-key-hypotheses-in-ai-alignment</a>.
</div>
<div id="ref-cuomo2016" class="csl-entry" role="listitem">
Cuomo, Francesca, Christine Mallin, and Alessandro Zattoni. 2016. <span>“Corporate Governance Codes: <span>A</span> Review and Research Agenda.”</span> <em>Corporate Governance: An International Review</em> 24 (3): 222–41. <a href="https://ueaeprints.uea.ac.uk/id/eprint/57664/">https://ueaeprints.uea.ac.uk/id/eprint/57664/</a>.
</div>
<div id="ref-dafoe2018" class="csl-entry" role="listitem">
Dafoe, Allan. 2018. <span>“<span>AI</span> Governance: A Research Agenda.”</span> <em>Governance of AI Program, Future of Humanity Institute, University of Oxford: Oxford, UK</em> 1442: 1443. <a href="https://www.fhi.ox.ac.uk/wp-content/uploads/GovAI-Agenda.pdf">https://www.fhi.ox.ac.uk/wp-content/uploads/GovAI-Agenda.pdf</a>.
</div>
<div id="ref-devilliers2021" class="csl-entry" role="listitem">
De Villiers, Charl, and Ruth Dimes. 2021. <span>“Determinants, Mechanisms and Consequences of Corporate Governance Reporting: A Research Framework.”</span> <em>Journal of Management and Governance</em> 25 (1): 7–26. <a href="https://doi.org/10.1007/s10997-020-09530-0">https://doi.org/10.1007/s10997-020-09530-0</a>.
</div>
<div id="ref-demirag2000" class="csl-entry" role="listitem">
Demirag, Istemi, Sudi Sudarsanam, and MIKE WRIGHT. 2000. <span>“Corporate Governance: Overview and Research Agenda.”</span> <em>The British Accounting Review</em> 32 (4): 341–54. <a href="https://www.academia.edu/download/49469624/bare.2000.014620161009-3955-1dt4aq5.pdf">https://www.academia.edu/download/49469624/bare.2000.014620161009-3955-1dt4aq5.pdf</a>.
</div>
<div id="ref-divito2022" class="csl-entry" role="listitem">
Di Vito, Jackie, and Kim Trottier. 2022. <span>“A <span>Literature Review</span> on <span>Corporate Governance Mechanisms</span>: <span>Past</span>, <span>Present</span>, and <span>Future</span>*.”</span> <em>Accounting Perspectives</em> 21 (2): 207–35. <a href="https://doi.org/10.1111/1911-3838.12279">https://doi.org/10.1111/1911-3838.12279</a>.
</div>
<div id="ref-duhem1954" class="csl-entry" role="listitem">
Duhem, Pierre Maurice Marie. 1954. <em>The <span>Aim</span> and <span>Structure</span> of <span>Physical Theory</span></em>. 1. Princeton University Press.
</div>
<div id="ref-european2024" class="csl-entry" role="listitem">
European, Union. 2024. <span>“The <span>Act Texts</span> | <span>EU Artificial Intelligence Act</span>.”</span> 2024. <a href="https://artificialintelligenceact.eu/the-act/">https://artificialintelligenceact.eu/the-act/</a>.
</div>
<div id="ref-good1966" class="csl-entry" role="listitem">
Good, Irving John. 1966. <span>“Speculations <span>Concerning</span> the <span>First Ultraintelligent Machine</span>.”</span> <em>Advances in Computers</em>, 31. <a href="https://doi.org/10.1016/S0065-2458(08)60418-0">https://doi.org/10.1016/S0065-2458(08)60418-0</a>.
</div>
<div id="ref-gruetzemacher2022" class="csl-entry" role="listitem">
Gruetzemacher, Ross. 2022. <span>“Bayesian <span>Networks</span> Vs. <span>Conditional Trees</span> for <span>Creating Questions</span> for <span>Forecasting Tournaments</span>.”</span>
</div>
<div id="ref-hallegatte2012" class="csl-entry" role="listitem">
Hallegatte, Stéphane, Ankur Shah, Robert Lempert, Casey Brown, and Stuart Gill. 2012. <span>“Investment Decision-Making Under Deep Uncertainty-Application to Climate Change.”</span> <em>Policy Research Working Paper</em> 6193. <a href="https://enpc.hal.science/hal-00802049/document">https://enpc.hal.science/hal-00802049/document</a>.
</div>
<div id="ref-heinze-deml2018" class="csl-entry" role="listitem">
Heinze-Deml, Christina, Marloes H. Maathuis, and Nicolai Meinshausen. 2018. <span>“Causal <span>Structure Learning</span>.”</span> <em>Annual Review of Statistics and Its Application</em> 5 (1): 371–91. <a href="https://doi.org/10.1146/annurev-statistics-031017-100630">https://doi.org/10.1146/annurev-statistics-031017-100630</a>.
</div>
<div id="ref-hunt2025" class="csl-entry" role="listitem">
Hunt, Tam. 2025. <span>“The Insane <span>‘Logic’</span> of the <span>AI</span> Arms Race.”</span> Medium. March 3, 2025. <a href="https://tamhunt.medium.com/the-insane-logic-of-the-ai-arms-race-45a5f79f4c0e">https://tamhunt.medium.com/the-insane-logic-of-the-ai-arms-race-45a5f79f4c0e</a>.
</div>
<div id="ref-jaynes2003" class="csl-entry" role="listitem">
Jaynes, Edwin T. 2003. <em>Probability Theory: <span>The</span> Logic of Science</em>. Cambridge university press.
</div>
<div id="ref-kaur2024" class="csl-entry" role="listitem">
Kaur, Kawaljit. 2024. <span>“Corporate <span>Governance</span> and <span>Legal Accountability</span>: <span>A Critical Review</span> of <span>Global Practices</span>.”</span> <em>Journal of Law</em> 2 (6): 1–7. <a href="https://joi.shodhsagar.org/index.php/SSJOI/article/view/16">https://joi.shodhsagar.org/index.php/SSJOI/article/view/16</a>.
</div>
<div id="ref-khartabil2021" class="csl-entry" role="listitem">
Khartabil, D., C. Collins, S. Wells, B. Bach, and J. Kennedy. 2021. <span>“Design and <span>Evaluation</span> of <span>Visualization Techniques</span> to <span>Facilitate Argument Exploration</span>.”</span> <em>Computer Graphics Forum</em> 40 (6): 447–65. <a href="https://doi.org/10.1111/cgf.14389">https://doi.org/10.1111/cgf.14389</a>.
</div>
<div id="ref-koller2009" class="csl-entry" role="listitem">
Koller, Daphne, and Nir Friedman. 2009. <em>Probabilistic Graphical Models: Principles and Techniques</em>. MIT press. <a href="https://books.google.ca/books?hl=en&amp;lr=&amp;id=7dzpHCHzNQ4C&amp;oi=fnd&amp;pg=PR9&amp;dq=Koller,+D.,+%26+Friedman,+N.+(2009).+Probabilistic+Graphical+Models&amp;ots=py2HAh0VAL&amp;sig=gpaID3x6-TY8x5SOopuXpZDXfzs">https://books.google.ca/books?hl=en&amp;lr=&amp;id=7dzpHCHzNQ4C&amp;oi=fnd&amp;pg=PR9&amp;dq=Koller,+D.,+%26+Friedman,+N.+(2009).+Probabilistic+Graphical+Models&amp;ots=py2HAh0VAL&amp;sig=gpaID3x6-TY8x5SOopuXpZDXfzs</a>.
</div>
<div id="ref-list2011" class="csl-entry" role="listitem">
List, Christian, and Philip Pettit. 2011. <em>Group <span>Agency</span>: <span>The Possibility</span>, <span>Design</span>, and <span>Status</span> of <span>Corporate Agents</span></em>. Oxford University Press.
</div>
<div id="ref-manheim2021" class="csl-entry" role="listitem">
Manheim, David. 2021. <span>“Modeling <span>Transformative AI Risk</span> (<span>MTAIR</span>) - <span>LessWrong</span>.”</span> July 28, 2021. <a href="https://www.lesswrong.com/s/aERZoriyHfCqvWkzg">https://www.lesswrong.com/s/aERZoriyHfCqvWkzg</a>.
</div>
<div id="ref-maslej2025" class="csl-entry" role="listitem">
Maslej, Nestor. 2025. <span>“Artificial <span>Intelligence Index Report</span> 2025.”</span> <em>Artificial Intelligence</em>.
</div>
<div id="ref-mccaslin2024" class="csl-entry" role="listitem">
McCaslin, Tegan, Josh Rosenberg, Ezra Karger, Avital Morris, Molly Hickman, Sam Glover, Zach Jacobs, and Phil Tetlock. 2024. <span>“Conditional <span>Trees</span>: <span>A Method</span> for <span>Generating Informative Questions</span> about <span>Complex Topics</span>.”</span> <em>Forecasting Research Institute</em>. <a href="https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/66ba37a144f1d6095de467df/1723479995772/AIConditionalTrees.pdf">https://static1.squarespace.com/static/635693acf15a3e2a14a56a4a/t/66ba37a144f1d6095de467df/1723479995772/AIConditionalTrees.pdf</a>.
</div>
<div id="ref-metropolitansky2025" class="csl-entry" role="listitem">
Metropolitansky, Dasha, and Jonathan Larson. 2025. <span>“Towards <span>Effective Extraction</span> and <span>Evaluation</span> of <span>Factual Claims</span>.”</span> February 15, 2025. <a href="https://doi.org/10.48550/arXiv.2502.10855">https://doi.org/10.48550/arXiv.2502.10855</a>.
</div>
<div id="ref-meyer2022b" class="csl-entry" role="listitem">
Meyer, Valentin Jakob. 2022. <span>“A <span>Structure</span> of <span>Knowledge</span> &amp; the <span>Process</span> of <span>Science</span>.”</span> <em>Philosophy of the Social Sciences</em> First Course Paper. https://doi.org/<a href="https://www.vjmeyer.com/papers/essays">https://www.vjmeyer.com/papers/essays</a>.
</div>
<div id="ref-miotti2024" class="csl-entry" role="listitem">
Miotti, Andrea, Tolga Bilge, Dave Kasten, and James Newport. 2024. <span>“A <span>Narrow Path</span>.”</span> <a href="https://www.narrowpath.co/">https://www.narrowpath.co/</a>.
</div>
<div id="ref-nelson2006" class="csl-entry" role="listitem">
Nelson, Roger B. 2006. <em>An <span>Introduction</span> to <span>Copulas</span></em>. Springer <span>Series</span> in <span>Statistics</span>. New York, NY: Springer New York. <a href="https://doi.org/10.1007/0-387-28678-0">https://doi.org/10.1007/0-387-28678-0</a>.
</div>
<div id="ref-paul2023" class="csl-entry" role="listitem">
Paul. 2023. <span>“The <span class="nocase">elephAInt</span> – <span>Are</span> We All Like the Six Blind Men When It Comes to <span>AI</span>? | <span>PRISMAGuard LLC</span>.”</span> 2023. <a href="https://www.prismaguard.com/the-elephaint-are-we-all-like-the-six-blind-men-when-it-comes-to-ai/">https://www.prismaguard.com/the-elephaint-are-we-all-like-the-six-blind-men-when-it-comes-to-ai/</a>.
</div>
<div id="ref-pearl2000" class="csl-entry" role="listitem">
Pearl, Judea. 2000. <em>Causality: Models, Reasoning, and Inference</em>. Cambridge, U.K. ; New York: Cambridge University Press.
</div>
<div id="ref-pearl2009" class="csl-entry" role="listitem">
———. 2009. <em>Causality: <span>Models</span>, Reasoning and Inference</em>. 2nd ed. Cambridge University Press.
</div>
<div id="ref-pearl2014" class="csl-entry" role="listitem">
———. 2014. <em>Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference</em>. Elsevier. <a href="https://books.google.ca/books?hl=en&amp;lr=&amp;id=mn2jBQAAQBAJ&amp;oi=fnd&amp;pg=PP1&amp;dq=Pearl,+J.+(1988).+Probabilistic+Reasoning+in+Intelligent+Systems&amp;ots=4tEX2A4Ha8&amp;sig=lgUs_RCoeXEEuGwM5xMEoyJy4HI">https://books.google.ca/books?hl=en&amp;lr=&amp;id=mn2jBQAAQBAJ&amp;oi=fnd&amp;pg=PP1&amp;dq=Pearl,+J.+(1988).+Probabilistic+Reasoning+in+Intelligent+Systems&amp;ots=4tEX2A4Ha8&amp;sig=lgUs_RCoeXEEuGwM5xMEoyJy4HI</a>.
</div>
<div id="ref-pollock1995" class="csl-entry" role="listitem">
Pollock, John L. 1995. <em>Cognitive Carpentry: <span>A</span> Blueprint for How to Build a Person</em>. Mit Press. <a href="https://books.google.ca/books?hl=en&amp;lr=&amp;id=JAfHrHTqswAC&amp;oi=fnd&amp;pg=PA1&amp;dq=Pollock,+J.+(1995).+Cognitive+Carpentry&amp;ots=rq-qSCBcxV&amp;sig=aAfHGsGUosxl_1-JuxIEA7C2QO4">https://books.google.ca/books?hl=en&amp;lr=&amp;id=JAfHrHTqswAC&amp;oi=fnd&amp;pg=PA1&amp;dq=Pollock,+J.+(1995).+Cognitive+Carpentry&amp;ots=rq-qSCBcxV&amp;sig=aAfHGsGUosxl_1-JuxIEA7C2QO4</a>.
</div>
<div id="ref-rehman2025" class="csl-entry" role="listitem">
Rehman, Iskander. 2025. <span>“The <span>Battle</span> for <span>Brilliant Minds</span>: <span>From</span> the <span>Nuclear Age</span> to <span>AI</span>.”</span> War on the Rocks. January 13, 2025. <a href="https://warontherocks.com/2025/01/the-battle-for-brilliant-minds-from-the-nuclear-age-to-ai/">https://warontherocks.com/2025/01/the-battle-for-brilliant-minds-from-the-nuclear-age-to-ai/</a>.
</div>
<div id="ref-samborska2025" class="csl-entry" role="listitem">
Samborska, Veronika. 2025. <span>“Scaling up: How Increasing Inputs Has Made Artificial Intelligence More Capable.”</span> <em>Our World in Data</em>, January. <a href="https://ourworldindata.org/scaling-up-ai">https://ourworldindata.org/scaling-up-ai</a>.
</div>
<div id="ref-samuel2023" class="csl-entry" role="listitem">
Samuel, Sigal. 2023. <span>“<span>AI</span> Is a <span>‘Tragedy of the Commons.’</span> <span>We</span>’ve Got Solutions for That.”</span> Vox. July 7, 2023. <a href="https://www.vox.com/future-perfect/2023/7/7/23787011/ai-arms-race-tragedy-commons-risk-safety">https://www.vox.com/future-perfect/2023/7/7/23787011/ai-arms-race-tragedy-commons-risk-safety</a>.
</div>
<div id="ref-schelling1960" class="csl-entry" role="listitem">
Schelling, Thomas C. 1960. <span>“I960. <span>The</span> Strategy of Conflict.”</span> <em>Cambridge, Mass</em>.
</div>
<div id="ref-solomon2020" class="csl-entry" role="listitem">
Solomon, Jill. 2020. <em>Corporate Governance and Accountability</em>. John Wiley &amp; Sons. <a href="https://books.google.ca/books?hl=en&amp;lr=&amp;id=JAX9DwAAQBAJ&amp;oi=fnd&amp;pg=PR1&amp;dq=review+of+the+effects+of+liability+frameworks+on+corporate+governance+&amp;ots=ny23_vd-U0&amp;sig=3LuNNhvSWXriEeg-ipAdDIQGAgo">https://books.google.ca/books?hl=en&amp;lr=&amp;id=JAX9DwAAQBAJ&amp;oi=fnd&amp;pg=PR1&amp;dq=review+of+the+effects+of+liability+frameworks+on+corporate+governance+&amp;ots=ny23_vd-U0&amp;sig=3LuNNhvSWXriEeg-ipAdDIQGAgo</a>.
</div>
<div id="ref-squires2023" class="csl-entry" role="listitem">
Squires, Chandler, and Caroline Uhler. 2023. <span>“Causal <span>Structure Learning</span>: <span>A Combinatorial Perspective</span>.”</span> <em>Foundations of Computational Mathematics</em> 23 (5): 1781–1815. <a href="https://doi.org/10.1007/s10208-022-09581-9">https://doi.org/10.1007/s10208-022-09581-9</a>.
</div>
<div id="ref-tegmark2024" class="csl-entry" role="listitem">
Tegmark, Max. 2024. <span>“Asilomar <span>AI Principles</span>.”</span> Future of Life Institute. 2024. <a href="https://futureoflife.org/open-letter/ai-principles/">https://futureoflife.org/open-letter/ai-principles/</a>.
</div>
<div id="ref-tetlock2022" class="csl-entry" role="listitem">
Tetlock, Phil. 2022. <span>“Conditional <span>Trees</span>: <span>AI Risk</span>.”</span> 2022. <a href="https://www.metaculus.com/tournament/3508/">https://www.metaculus.com/tournament/3508/</a>.
</div>
<div id="ref-tetlock2015" class="csl-entry" role="listitem">
Tetlock, Philip E., and Dan Gardner. 2015. <em>Superforecasting: The Art and Science of Prediction</em>. First paperback edition. New York: Broadway Books.
</div>
<div id="ref-todd2024" class="csl-entry" role="listitem">
Todd, Benjamin. 2024. <span>“It Looks Like There Are Some Good Funding Opportunities in <span>AI</span> Safety Right Now.”</span> Substack newsletter. Benjamin Todd. December 21, 2024. <a href="https://benjamintodd.substack.com/p/looks-like-there-are-some-good-funding">https://benjamintodd.substack.com/p/looks-like-there-are-some-good-funding</a>.
</div>
<div id="ref-voigt2025" class="csl-entry" role="listitem">
Voigt, Christian. (2014) 2025. <span>“Christianvoigt/Argdown.”</span> <a href="https://github.com/christianvoigt/argdown">https://github.com/christianvoigt/argdown</a>.
</div>
<div id="ref-yang2022" class="csl-entry" role="listitem">
Yang, Jie, Soyeon Caren Han, and Josiah Poon. 2022. <span>“A Survey on Extraction of Causal Relations from Natural Language Text.”</span> <em>Knowledge and Information Systems</em> 64 (5): 1161–86. <a href="https://doi.org/10.1007/s10115-022-01665-w">https://doi.org/10.1007/s10115-022-01665-w</a>.
</div>
<div id="ref-yudkowsky2008" class="csl-entry" role="listitem">
Yudkowsky, Eliezer. 2008. <span>“Artificial <span>Intelligence</span> as a Positive and Negative Factor in Global Risk.”</span> In <em>Global <span>Catastrophic Risks</span></em>, by Eliezer Yudkowsky. Oxford University Press. <a href="https://doi.org/10.1093/oso/9780198570509.003.0021">https://doi.org/10.1093/oso/9780198570509.003.0021</a>.
</div>
</div>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>The orthogonality thesis posits that intelligence and goals are independent—an AI can have any set of objectives regardless of its intelligence level. The instrumental convergence thesis suggests that different AI systems may adopt similar instrumental goals (e.g., self-preservation, resource acquisition) to achieve their objectives.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Multiple versions of Carlsmith’s paper exist with slight updates to probability estimates: <span class="citation" data-cites="carlsmith2021">Carlsmith (<a href="../../ref/references.html#ref-carlsmith2021" role="doc-biblioref">2021</a>)</span>, <span class="citation" data-cites="carlsmith2022">Carlsmith (<a href="../../ref/references.html#ref-carlsmith2022" role="doc-biblioref">2022</a>)</span>, <span class="citation" data-cites="carlsmith2024">Carlsmith (<a href="../../ref/references.html#ref-carlsmith2024" role="doc-biblioref">2024</a>)</span>. We primarily reference the version used by the MTAIR team for their extraction. Extended discussion and expert probability estimates can be found on LessWrong.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><strong>Premise 1: APS Systems by 2070</strong> <span class="math inline">\((P≈0.65)\)</span> “By 2070, there will be AI systems with Advanced capability, Agentic planning, and Strategic awareness”—the conjunction of capabilities that could enable systematic pursuit of objectives in the world.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p><strong>Premise 1: APS Systems by 2070</strong> <span class="math inline">\((P≈0.65)\)</span> “By 2070, there will be AI systems with Advanced capability, Agentic planning, and Strategic awareness”—the conjunction of capabilities that could enable systematic pursuit of objectives in the world.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p><strong>Premise 2: Alignment Difficulty</strong> <span class="math inline">\((P≈0.40)\)</span> “It will be harder to build aligned APS systems than misaligned systems that are still attractive to deploy”—capturing the challenge that safety may conflict with capability or efficiency.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p><strong>Premise 3: Deployment Despite Misalignment</strong> <span class="math inline">\((P≈0.70)\)</span> “Conditional on 1 and 2, we will deploy misaligned APS systems”—reflecting competitive pressures and limited coordination.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p><strong>Premise 4: Power-Seeking Behavior</strong> <span class="math inline">\((P≈0.65)\)</span> “Conditional on 1-3, misaligned APS systems will seek power in high-impact ways”—based on instrumental convergence arguments.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p><strong>Premise 5: Disempowerment Success</strong> <span class="math inline">\((P≈0.40)\)</span> “Conditional on 1-4, power-seeking will scale to permanent human disempowerment”—despite potential resistance and safeguards.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p><strong>Premise 6: Existential Catastrophe</strong> <span class="math inline">\((P≈0.95)\)</span> “Conditional on 1-5, this disempowerment constitutes existential catastrophe”—connecting power loss to permanent curtailment of human potential.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p><strong>Overall Risk</strong>: Multiplying through the conditional chain yields $P(doom)≈0.05 $ or 5% by 2070.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>This example, while simple, demonstrates all essential features of Bayesian networks and serves as the foundation for understanding more complex applications<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>These estimates include time for initial extraction, expert consultation, probability elicitation, validation, and refinement<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>If I’m honest about how this research actually developed, it looked nothing like the clean progression these methodology sections usually imply. The reality was messier, more iterative, occasionally frustrating, and ultimately more interesting than any linear narrative could capture.<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>I am extremely grateful for their help, support and the invaluable contribution. As lead engineer I had had the nagging suspicion that, maybe I had “hardcoded” by own intuitions into the system (through choices in the setup, system prompt, source selection etc.). I am relieved to let go of this concern and hope that future, large scale work confirms the potential for objectivity and convergence.<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>Copulas provide a mathematically elegant way to separate marginal behavior from dependence structure<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../index.html" class="pagination-link" aria-label="Abstract">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Abstract</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../ref/references.html" class="pagination-link" aria-label="Bibliography">
        <span class="nav-page-text">Bibliography</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/VJMeyer/submission/edit/main/chapters/Outlines/final_draft.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></div></div></footer></body></html>