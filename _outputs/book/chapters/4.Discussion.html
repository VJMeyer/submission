<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.29">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>6&nbsp; 4. Discussion: Implications and Limitations – Automating the Modelling of Transformative Artificial Intelligence Risks</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/5.Conclusion.html" rel="next">
<link href="../chapters/3.0.AMTAIR.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-0815c480559380816a4d1ea211a47e91.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-485d01fc63b59abcd3ee1bf1e8e2748d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/4.Discussion.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">4. Discussion: Implications and Limitations</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Automating the Modelling of Transformative Artificial Intelligence Risks</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/VJMeyer/submission" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="../Automating-the-Modelling-of-Transformative-Artificial-Intelligence-Risks.pdf">
              <i class="bi bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="../Automating-the-Modelling-of-Transformative-Artificial-Intelligence-Risks.epub">
              <i class="bi bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-1" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-1">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Abstract</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/0.Frontmatter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Preface</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/1.Introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">1. Introduction: The Coordination Crisis in AI Governance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/2.0.Context.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">2. Context and Theoretical Foundations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/3.0.AMTAIR.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">3. AMTAIR: Design and Implementation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/4.Discussion.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">4. Discussion: Implications and Limitations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/5.Conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">5. Conclusion: Toward Coordinated AI Governance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ref/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliography</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/Appendix-K.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Appendix K: From Prototype to Platform: A Research Program Roadmap</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/Appendix-L.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Appendix L: Prompt Engineering - The Hidden Art</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/Appendix-M.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Appendix M: The Validation Frontier - Measuring Truth in Argument Extraction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/Appendix-N.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Appendix N: Bucknall Case Study - Near-Term AI as Existential Risk Factor</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title"></span></span></a><a href="https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr">AMTAIR Prototype Demonstration (Public Colab Notebook)</a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-technical-limitations" id="toc-sec-technical-limitations" class="nav-link active" data-scroll-target="#sec-technical-limitations">4.1 Technical Limitations and Responses</a>
  <ul>
  <li><a href="#sec-extraction-boundaries" id="toc-sec-extraction-boundaries" class="nav-link" data-scroll-target="#sec-extraction-boundaries">4.1.1 Extraction Quality Boundaries</a></li>
  <li><a href="#sec-false-precision" id="toc-sec-false-precision" class="nav-link" data-scroll-target="#sec-false-precision">4.1.2 Objection 2: False Precision in Uncertainty</a></li>
  <li><a href="#sec-correlation-complexity" id="toc-sec-correlation-complexity" class="nav-link" data-scroll-target="#sec-correlation-complexity">4.1.3 Objection 3: Correlation Complexity</a></li>
  </ul></li>
  <li><a href="#sec-conceptual-concerns" id="toc-sec-conceptual-concerns" class="nav-link" data-scroll-target="#sec-conceptual-concerns">4.2 Conceptual and Methodological Concerns</a>
  <ul>
  <li><a href="#sec-democratic-exclusion" id="toc-sec-democratic-exclusion" class="nav-link" data-scroll-target="#sec-democratic-exclusion">4.2.1 Objection 4: Democratic Exclusion</a></li>
  <li><a href="#sec-oversimplification" id="toc-sec-oversimplification" class="nav-link" data-scroll-target="#sec-oversimplification">4.2.2 Objection 5: Oversimplification of Complex Systems</a></li>
  <li><a href="#sec-idiosyncratic" id="toc-sec-idiosyncratic" class="nav-link" data-scroll-target="#sec-idiosyncratic">4.2.3 Objection 6: Idiosyncratic Implementation and Modeling Choices</a></li>
  </ul></li>
  <li><a href="#sec-red-teaming" id="toc-sec-red-teaming" class="nav-link" data-scroll-target="#sec-red-teaming">4.3 Red-Teaming Results</a>
  <ul>
  <li><a href="#sec-adversarial-extraction" id="toc-sec-adversarial-extraction" class="nav-link" data-scroll-target="#sec-adversarial-extraction">4.3.1 Adversarial Extraction Attempts</a></li>
  <li><a href="#sec-robustness-findings" id="toc-sec-robustness-findings" class="nav-link" data-scroll-target="#sec-robustness-findings">4.3.2 Robustness Findings</a></li>
  <li><a href="#sec-deployment-implications" id="toc-sec-deployment-implications" class="nav-link" data-scroll-target="#sec-deployment-implications">4.3.3 Implications for Deployment</a></li>
  </ul></li>
  <li><a href="#sec-epistemic-security" id="toc-sec-epistemic-security" class="nav-link" data-scroll-target="#sec-epistemic-security">4.4 Enhancing Epistemic Security</a>
  <ul>
  <li><a href="#sec-inspectable-models" id="toc-sec-inspectable-models" class="nav-link" data-scroll-target="#sec-inspectable-models">4.4.1 Making Models Inspectable</a></li>
  <li><a href="#sec-convergence-divergence" id="toc-sec-convergence-divergence" class="nav-link" data-scroll-target="#sec-convergence-divergence">4.4.2 Revealing Convergence and Divergence</a></li>
  <li><a href="#sec-collective-reasoning" id="toc-sec-collective-reasoning" class="nav-link" data-scroll-target="#sec-collective-reasoning">4.4.3 Improving Collective Reasoning</a></li>
  </ul></li>
  <li><a href="#sec-scaling" id="toc-sec-scaling" class="nav-link" data-scroll-target="#sec-scaling">4.5 Scaling Challenges and Opportunities</a>
  <ul>
  <li><a href="#sec-technical-scaling" id="toc-sec-technical-scaling" class="nav-link" data-scroll-target="#sec-technical-scaling">4.5.1 Technical Scaling</a></li>
  <li><a href="#sec-social-scaling" id="toc-sec-social-scaling" class="nav-link" data-scroll-target="#sec-social-scaling">4.5.2 Social and Institutional Scaling</a></li>
  <li><a href="#sec-impact-opportunities" id="toc-sec-impact-opportunities" class="nav-link" data-scroll-target="#sec-impact-opportunities">4.5.3 Opportunities for Impact</a></li>
  </ul></li>
  <li><a href="#sec-governance-integration" id="toc-sec-governance-integration" class="nav-link" data-scroll-target="#sec-governance-integration">4.6 Integration with Governance Frameworks</a>
  <ul>
  <li><a href="#sec-standards-integration" id="toc-sec-standards-integration" class="nav-link" data-scroll-target="#sec-standards-integration">4.6.1 Standards Development</a></li>
  <li><a href="#sec-regulatory-integration" id="toc-sec-regulatory-integration" class="nav-link" data-scroll-target="#sec-regulatory-integration">4.6.2 Regulatory Design</a></li>
  <li><a href="#sec-international-integration" id="toc-sec-international-integration" class="nav-link" data-scroll-target="#sec-international-integration">4.6.3 International Coordination</a></li>
  <li><a href="#sec-organizational-integration" id="toc-sec-organizational-integration" class="nav-link" data-scroll-target="#sec-organizational-integration">4.6.4 Organizational Decision-Making</a></li>
  </ul></li>
  <li><a href="#sec-future-research" id="toc-sec-future-research" class="nav-link" data-scroll-target="#sec-future-research">4.7 Future Research Directions</a>
  <ul>
  <li><a href="#sec-technical-future" id="toc-sec-technical-future" class="nav-link" data-scroll-target="#sec-technical-future">4.7.1 Technical Enhancements</a></li>
  <li><a href="#sec-methodological-future" id="toc-sec-methodological-future" class="nav-link" data-scroll-target="#sec-methodological-future">4.7.2 Methodological Extensions</a></li>
  <li><a href="#sec-application-future" id="toc-sec-application-future" class="nav-link" data-scroll-target="#sec-application-future">4.7.3 Application Domains</a></li>
  <li><a href="#sec-ecosystem-future" id="toc-sec-ecosystem-future" class="nav-link" data-scroll-target="#sec-ecosystem-future">4.7.4 Ecosystem Development</a></li>
  </ul></li>
  <li><a href="#sec-deep-uncertainties" id="toc-sec-deep-uncertainties" class="nav-link" data-scroll-target="#sec-deep-uncertainties">4.8 Known Unknowns and Deep Uncertainties</a>
  <ul>
  <li><a href="#sec-uncertainty-categories" id="toc-sec-uncertainty-categories" class="nav-link" data-scroll-target="#sec-uncertainty-categories">4.8.1 Categories of Deep Uncertainty</a></li>
  <li><a href="#sec-adaptation-strategies" id="toc-sec-adaptation-strategies" class="nav-link" data-scroll-target="#sec-adaptation-strategies">4.8.2 Adaptation Strategies for Deep Uncertainty</a></li>
  <li><a href="#sec-robust-principles" id="toc-sec-robust-principles" class="nav-link" data-scroll-target="#sec-robust-principles">4.8.3 Robust Decision-Making Principles</a></li>
  </ul></li>
  <li><a href="#sec-implications-summary" id="toc-sec-implications-summary" class="nav-link" data-scroll-target="#sec-implications-summary">4.9 Summary of Implications</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/VJMeyer/submission/edit/main/chapters/4.Discussion.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div><div class="quarto-code-links"><h2>Code Links</h2><ul><li><a href="https://colab.research.google.com/github/VJMeyer/submission/blob/main/AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb"><i class="bi bi-file-code"></i>Colab Notebook</a></li><li><a href="https://github.com/VJMeyer/submission"><i class="bi bi-github"></i>GitHub Repository</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-discussion" class="quarto-section-identifier"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">4. Discussion: Implications and Limitations</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<!-- 
**Chapter Overview**  
**Grade Weight**: 10% | **Target Length**: ~14% of text (~4,200 words)  
**Requirements**: Discusses objections, provides convincing replies, extends beyond course materials 
-->
<!-- [-] TODO: Address each objection with rigorous counteranalysis -->
<section id="sec-technical-limitations" class="level2">
<h2 class="anchored" data-anchor-id="sec-technical-limitations">4.1 Technical Limitations and Responses</h2>
<section id="sec-extraction-boundaries" class="level3">
<h3 class="anchored" data-anchor-id="sec-extraction-boundaries">4.1.1 Extraction Quality Boundaries</h3>
<p>The critique that automated extraction systematically misses nuanced arguments deserves serious consideration. After months of working with these systems, I’ve developed both appreciation for their capabilities and acute awareness of their limitations. The reality, unsurprisingly, resists simple characterization.</p>
<p>Consider what happens when AMTAIR encounters a passage like: “While alignment might be achieved through current methods, the economic incentives pushing toward capability development at the expense of safety create a dynamic where technical solutions alone appear insufficient.” A human reader parses this effortlessly—alignment is possible but threatened by misaligned incentives. The system, however, might extract two separate claims about alignment feasibility and economic incentives without capturing their interconnection.</p>
<p>These failures aren’t random. They follow predictable patterns that reveal something fundamental about the difference between human and machine comprehension. Humans excel at inferring unstated connections, filling gaps with background knowledge, recognizing when an author assumes rather than argues. The system, lacking this context, must rely on explicit linguistic markers. When those markers are absent—as they often are in sophisticated arguments—extraction quality degrades.</p>
<p>Yet dismissing automated extraction based on these limitations misses a crucial point. The alternative isn’t perfect human extraction but no formal extraction at all. In practice, humans rarely take the time to formally map complex arguments. When they do, they exhibit their own biases and inconsistencies. The question becomes not whether automated extraction achieves perfection but whether it provides value despite imperfection.</p>
<p>My experience suggests it does, particularly when embedded in appropriate workflows. The two-stage architecture allows human review at natural breakpoints. Extracted structures make excellent starting points for refinement. Most surprisingly, extraction failures often diagnose ambiguities in source texts that human readers gloss over. When the system struggles to determine whether claim A supports or merely relates to claim B, it’s often because the original text genuinely leaves this ambiguous.</p>
<p>Framed differently:</p>
<p><strong>Critic</strong>: “Complex implicit reasoning chains resist formalization; automated extraction will systematically miss nuanced arguments and subtle conditional relationships that human experts would identify.”</p>
<p><strong>Response</strong>: This concern has merit—extraction does face inherent limitations. However, the empirical results tell a more nuanced story. The two-stage extraction process, while imperfect, captures sufficient structure for practical use while maintaining transparency about its limitations.</p>
<p>More importantly, AMTAIR employs a hybrid human-AI workflow that addresses this limitation:</p>
<ul>
<li><strong>Two-stage verification</strong>: Humans review structural extraction before probability quantification</li>
<li><strong>Transparent outputs</strong>: All intermediate representations remain human-readable</li>
<li><strong>Iterative refinement</strong>: Extraction prompts improve based on error analysis</li>
<li><strong>Ensemble approaches</strong>: Multiple extraction attempts can identify ambiguities</li>
</ul>
<p>The question is not whether automated extraction perfectly captures every nuance—it doesn’t. Rather, it’s whether imperfect extraction still provides value over no formal representation. When the alternative is relying on conflicting mental models that remain entirely implicit, even partially accurate formal models represent significant progress.</p>
<p>Furthermore, extraction errors often reveal interesting properties of the source arguments themselves—ambiguities that human readers gloss over become explicit when formalization fails. This diagnostic value enhances rather than undermines the approach.</p>
</section>
<section id="sec-false-precision" class="level3">
<h3 class="anchored" data-anchor-id="sec-false-precision">4.1.2 Objection 2: False Precision in Uncertainty</h3>
<p><strong>Critic</strong>: “Attaching exact probabilities to unprecedented events like AI catastrophe is fundamentally misguided. The numbers create false confidence in what amounts to educated speculation about radically uncertain futures.”</p>
<p><strong>Response</strong>: This philosophical objection strikes at the heart of formal risk assessment. However, AMTAIR addresses it through several design choices:</p>
<p>First, the system explicitly represents uncertainty about uncertainty. Rather than point estimates, the framework supports probability distributions over parameters. When someone says “likely” we might model this as a range rather than exactly 0.8, capturing both the central estimate and our uncertainty about it.</p>
<p>Second, all probabilities are explicitly conditional on stated assumptions. The system doesn’t claim “P(catastrophe) = 0.05” absolutely, but rather “Given Carlsmith’s model assumptions, P(catastrophe) = 0.05.” This conditionality is preserved throughout analysis.</p>
<p>Third, sensitivity analysis reveals which probabilities actually matter. Often, precise values are unnecessary—knowing whether a parameter is closer to 0.1 or 0.9 suffices for decision-making. The formalization helps identify where precision matters and where it doesn’t.</p>
<p>Finally, the alternative to quantification isn’t avoiding the problem but making it worse. When experts say “highly likely” or “significant risk,” they implicitly reason with probabilities. Formalization simply makes these implicit quantities explicit and subject to scrutiny. As Dennis Lindley noted, “Uncertainty is not in the events, but in our knowledge about them.”</p>
<!-- [-] ADD: @lindley2013: "Lindley, D. (2013). Understanding Uncertainty" -->
</section>
<section id="sec-correlation-complexity" class="level3">
<h3 class="anchored" data-anchor-id="sec-correlation-complexity">4.1.3 Objection 3: Correlation Complexity</h3>
<p><strong>Critic</strong>: “Bayesian networks assume conditional independence given parents, but real-world AI risks involve complex correlations. Ignoring these dependencies could dramatically misrepresent risk levels.”</p>
<p><strong>Response</strong>: Standard Bayesian networks do face limitations with correlation representation—this is a genuine technical challenge. However, several approaches within the framework address this:</p>
<p><strong>Explicit correlation nodes</strong>: When factors share hidden common causes, we can add latent variables to capture correlations. For instance, “AI research culture” might influence both “capability advancement” and “safety investment.”</p>
<p><strong>Copula methods</strong>: For known correlation structures, copula functions can model dependencies while preserving marginal distributions. This extends standard Bayesian networks significantly.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p><strong>Sensitivity bounds</strong>: When correlations remain uncertain, we can compute bounds on outcomes under different correlation assumptions. This reveals when correlations critically affect conclusions.</p>
<p><strong>Model ensembles</strong>: Different correlation structures can be modeled separately and results aggregated, similar to climate modeling approaches.</p>
<p>More fundamentally, the question is whether imperfect independence assumptions invalidate the approach. In practice, explicitly modeling first-order effects with known limitations often proves more valuable than attempting to capture all dependencies informally. The framework makes assumptions transparent, enabling targeted improvements where correlations matter most.</p>
</section>
</section>
<section id="sec-conceptual-concerns" class="level2">
<h2 class="anchored" data-anchor-id="sec-conceptual-concerns">4.2 Conceptual and Methodological Concerns</h2>
<section id="sec-democratic-exclusion" class="level3">
<h3 class="anchored" data-anchor-id="sec-democratic-exclusion">4.2.1 Objection 4: Democratic Exclusion</h3>
<p><strong>Critic</strong>: “Transforming policy debates into complex graphs and equations will sideline non-technical stakeholders, concentrating influence among those comfortable with formal models. This technocratic approach undermines democratic participation in crucial decisions about humanity’s future.”</p>
<p><strong>Response</strong>: This concern about technocratic exclusion deserves serious consideration—formal methods can indeed create barriers. However, AMTAIR’s design explicitly prioritizes accessibility alongside rigor:</p>
<p><strong>Progressive disclosure interfaces</strong> allow engagement at multiple levels. A policymaker might explore visual network structures and probability color-coding without engaging mathematical details. Interactive features let users modify assumptions and see consequences without understanding implementation.</p>
<p><strong>Natural language preservation</strong> ensures original arguments remain accessible. The BayesDown format maintains human-readable descriptions alongside formal specifications. Users can always trace from mathematical representations back to source texts.</p>
<p><strong>Comparative advantage</strong> comes from making implicit technical content explicit, not adding complexity. When experts debate AI risk, they already employ sophisticated probabilistic reasoning—formalization reveals rather than creates this complexity. Making hidden assumptions visible arguably enhances rather than reduces democratic participation.</p>
<p><strong>Multiple interfaces</strong> serve different communities. Researchers access full technical depth, policymakers use summary dashboards, public stakeholders explore interactive visualizations. The same underlying model supports varied engagement modes.</p>
<p>Rather than excluding non-technical stakeholders, proper implementation can democratize access to expert reasoning by making it inspectable and modifiable. The risk lies not in formalization itself but in poor interface design or gatekeeping behaviors around model access.</p>
</section>
<section id="sec-oversimplification" class="level3">
<h3 class="anchored" data-anchor-id="sec-oversimplification">4.2.2 Objection 5: Oversimplification of Complex Systems</h3>
<p><strong>Critic</strong>: “Forcing rich socio-technical systems into discrete Bayesian networks necessarily loses crucial dynamics—feedback loops, emergent properties, institutional responses, and cultural factors that shape AI development. The models become precise but wrong.”</p>
<p><strong>Response</strong>: All models simplify by necessity—as Box noted, “All models are wrong, but some are useful.” The question becomes whether formal simplifications improve upon informal mental models:</p>
<p><strong>Transparent limitations</strong> make formal models’ shortcomings explicit. Unlike mental models where simplifications remain hidden, network representations clearly show what is and isn’t included. This transparency enables targeted criticism and improvement.</p>
<p><strong>Iterative refinement</strong> allows models to grow more sophisticated over time. Starting with first-order effects and adding complexity where it proves important follows successful practice in other domains. Climate models began simply and added dynamics as computational power and understanding grew.</p>
<p><strong>Complementary tools</strong> address different aspects of the system. Bayesian networks excel at probabilistic reasoning and intervention analysis. Other approaches—agent-based models, system dynamics, scenario planning—can capture different properties. AMTAIR provides one lens, not the only lens.</p>
<p><strong>Empirical adequacy</strong> ultimately judges models. If simplified representations enable better predictions and decisions than informal alternatives, their abstractions are justified. Early results suggest formal models, despite simplifications, outperform intuitive reasoning for complex risk assessment.</p>
<p>The goal isn’t creating perfect representations but useful ones. By making simplifications explicit and modifiable, formal models enable systematic improvement in ways mental models cannot.</p>
</section>
<section id="sec-idiosyncratic" class="level3">
<h3 class="anchored" data-anchor-id="sec-idiosyncratic">4.2.3 Objection 6: Idiosyncratic Implementation and Modeling Choices</h3>
<p><strong>Critic</strong>: “The specific choices made in AMTAIR’s implementation—from prompt design to parsing algorithms to visualization strategies—seem arbitrary. Different teams might make entirely different choices, leading to incompatible results. How can we trust conclusions that depend so heavily on implementation details?”</p>
<p><strong>Response</strong>: This concern about implementation dependency is valid and deserves careful consideration. However, several factors mitigate this issue:</p>
<p><strong>Convergent Design Principles</strong>: While specific implementations vary, fundamental design principles tend to converge. The two-stage extraction process (structure then probability) emerges naturally from how humans parse arguments. The use of intermediate representations follows established practice in computational linguistics. These aren’t arbitrary choices but responses to inherent challenges.</p>
<p><strong>Empirical Validation</strong>: The “correctness” of implementation choices isn’t philosophical but empirical. If different reasonable implementations extract similar structures and lead to similar policy conclusions, this demonstrates robustness. If they diverge dramatically, this reveals genuine ambiguity in source materials—itself valuable information.</p>
<p><strong>Transparent Methodology</strong>: By documenting all implementation choices and making code open source, AMTAIR enables replication and variation. Other teams can modify specific components while preserving overall architecture, testing which choices matter.</p>
<p><strong>Convergence at Higher Levels</strong>: Even if implementations differ in details, they may converge at levels that matter for coordination. If two systems extract slightly different network structures but reach similar conclusions about policy robustness, the implementation differences don’t undermine the approach’s value.</p>
<p><strong>Community Standards</strong>: As the field matures, community standards will likely emerge—not enforcing uniformity but establishing interoperability. This parallels development in other technical fields where multiple implementations coexist within shared frameworks.</p>
<p>The deeper insight is that implementation choices encode theoretical commitments. By making these explicit and variable, AMTAIR turns a bug into a feature—we can systematically explore how different assumptions affect conclusions, enhancing rather than undermining epistemic security.</p>
</section>
</section>
<section id="sec-red-teaming" class="level2">
<h2 class="anchored" data-anchor-id="sec-red-teaming">4.3 Red-Teaming Results</h2>
<!-- [-] TODO: Present results from systematic attempts to find weaknesses -->
<p>To identify failure modes, systematic adversarial testing of the AMTAIR system would be essential.</p>
<section id="sec-adversarial-extraction" class="level3">
<h3 class="anchored" data-anchor-id="sec-adversarial-extraction">4.3.1 Adversarial Extraction Attempts</h3>
<!-- [-] COMPLETELY REWRITE: Results were HALLUCINATED -- rewrite by describing what procedures etc. one would ideally follow -->
<p>A comprehensive red-teaming approach would test the system with:</p>
<p><strong>Contradictory Arguments</strong>: Texts containing logically inconsistent claims or probability estimates. The system should flag contradictions rather than silently reconciling them.</p>
<p><strong>Circular Reasoning</strong>: Arguments with circular dependencies that violate DAG requirements. Proper validation should detect and report such structural issues.</p>
<p><strong>Ambiguous Language</strong>: Texts using extremely vague or metaphorical language. The system should acknowledge extraction uncertainty rather than forcing precise interpretations.</p>
<p><strong>Deceptive Framings</strong>: Arguments crafted to imply false causal relationships. This tests whether the system merely extracts surface claims or requires deeper coherence.</p>
<p><strong>Adversarial Prompts</strong>: Inputs designed to trigger known LLM failure modes. This ensures robustness against prompt injection and manipulation attempts.</p>
<p>Each failure mode discovered would inform system improvements and user guidance.</p>
</section>
<section id="sec-robustness-findings" class="level3">
<h3 class="anchored" data-anchor-id="sec-robustness-findings">4.3.2 Robustness Findings</h3>
<p>Theoretical analysis suggests key vulnerabilities:</p>
<p><strong>Anchoring Effects</strong>: Language models may over-weight information presented early in documents, potentially biasing extraction toward initial framings.</p>
<p><strong>Authority Sensitivity</strong>: Extraction might be influenced by explicit credibility signals in text, potentially giving undue weight to claimed expertise.</p>
<p><strong>Complexity Limits</strong>: Performance likely degrades with very large argument structures, requiring hierarchical decomposition strategies.</p>
<p><strong>Context Windows</strong>: Long-range dependencies exceeding model context windows could be missed, fragmenting cohesive arguments.</p>
<p>Understanding these limitations enables appropriate use—leveraging strengths while compensating for weaknesses through human oversight and validation.</p>
</section>
<section id="sec-deployment-implications" class="level3">
<h3 class="anchored" data-anchor-id="sec-deployment-implications">4.3.3 Implications for Deployment</h3>
<p>These considerations suggest AMTAIR is suitable for:</p>
<ul>
<li><strong>Research applications</strong> with expert oversight</li>
<li><strong>Policy analysis</strong> of well-structured arguments</li>
<li><strong>Educational uses</strong> demonstrating formal reasoning</li>
<li><strong>Collaborative modeling</strong> with human verification</li>
</ul>
<p>But should be used cautiously for:</p>
<ul>
<li>Fully automated analysis without review</li>
<li>Adversarial or politically contentious texts</li>
<li>Real-time decision-making without validation</li>
<li>Arguments far outside training distribution</li>
</ul>
</section>
</section>
<section id="sec-epistemic-security" class="level2">
<h2 class="anchored" data-anchor-id="sec-epistemic-security">4.4 Enhancing Epistemic Security</h2>
<!-- [-] TODO: Analyze how formal modeling improves discourse quality -->
<p>Despite limitations, AMTAIR contributes to epistemic security in AI governance through several mechanisms.</p>
<section id="sec-inspectable-models" class="level3">
<h3 class="anchored" data-anchor-id="sec-inspectable-models">4.4.1 Making Models Inspectable</h3>
<p>The greatest epistemic benefit comes from forcing implicit models into explicit form. When an expert claims “misalignment likely leads to catastrophe,” formalization asks:</p>
<ul>
<li>Likely means what probability?</li>
<li>Through what causal pathways?</li>
<li>Under what assumptions?</li>
<li>With what evidence?</li>
</ul>
<p>This explicitation serves multiple functions:</p>
<p><strong>Clarity</strong>: Vague statements become precise claims subject to evaluation</p>
<p><strong>Comparability</strong>: Different experts’ models can be systematically compared</p>
<p><strong>Criticizability</strong>: Hidden assumptions become visible targets for challenge</p>
<p><strong>Updatability</strong>: Formal models can systematically incorporate new evidence</p>
</section>
<section id="sec-convergence-divergence" class="level3">
<h3 class="anchored" data-anchor-id="sec-convergence-divergence">4.4.2 Revealing Convergence and Divergence</h3>
<!-- [-] COMPLETELY REWRITE: Results were HALLUCINATED -- rewrite by describing what results we expect from theoretical considerations -->
<p>Theoretical analysis suggests formal comparison would reveal:</p>
<p><strong>Structural Patterns</strong>: Experts likely share more agreement about causal structures than probability values, suggesting common understanding of mechanisms despite quantitative disagreement.</p>
<p><strong>Crux Identification</strong>: Formal models make explicit which specific disagreements drive different conclusions, focusing discussion on genuinely critical differences.</p>
<p><strong>Hidden Agreements</strong>: Apparently conflicting positions might share substantial common ground obscured by different terminology or emphasis.</p>
<p><strong>Uncertainty Clustering</strong>: Areas of high uncertainty likely correlate across models, revealing where additional research would most reduce disagreement.</p>
<p>These patterns remain invisible in natural language debates but become analyzable through formalization.</p>
</section>
<section id="sec-collective-reasoning" class="level3">
<h3 class="anchored" data-anchor-id="sec-collective-reasoning">4.4.3 Improving Collective Reasoning</h3>
<p>AMTAIR enhances group epistemics through:</p>
<p><strong>Explicit uncertainty</strong>: Replacing “might,” “could,” “likely” with probability distributions reduces miscommunication and forces precision</p>
<p><strong>Compositional reasoning</strong>: Complex arguments decompose into manageable components that can be independently evaluated</p>
<p><strong>Evidence integration</strong>: New information updates specific parameters rather than requiring complete argument reconstruction</p>
<p><strong>Exploration tools</strong>: Stakeholders can modify assumptions and immediately see consequences, building intuition about model dynamics</p>
<!-- [-] COMPLETELY REWRITE: Results were HALLUCINATED -- rewrite by describing what benefits one can plausibly anticipate -->
<p>While empirical validation remains future work, theoretical considerations suggest these mechanisms could substantially improve coordination quality. By providing shared representations and systematic methods for managing disagreement, formal models create infrastructure for collective intelligence that transcends individual limitations.</p>
</section>
</section>
<section id="sec-scaling" class="level2">
<h2 class="anchored" data-anchor-id="sec-scaling">4.5 Scaling Challenges and Opportunities</h2>
<!-- [-] TODO: Examine how the modeling approach could complement existing initiatives -->
<p>Moving from prototype to widespread adoption faces both technical and social challenges.</p>
<section id="sec-technical-scaling" class="level3">
<h3 class="anchored" data-anchor-id="sec-technical-scaling">4.5.1 Technical Scaling</h3>
<p><strong>Computational complexity</strong> grows with network size, but several approaches help:</p>
<ul>
<li>Hierarchical decomposition for very large models</li>
<li>Caching and approximation for common queries</li>
<li>Distributed processing for extraction tasks</li>
<li>Incremental updating rather than full recomputation</li>
</ul>
<p><strong>Data quality</strong> varies dramatically across sources:</p>
<ul>
<li>Academic papers provide structured arguments</li>
<li>Blog posts offer rich ideas with less formal structure</li>
<li>Policy documents mix normative and empirical claims</li>
<li>Social media presents extreme extraction challenges</li>
</ul>
<p><strong>Integration complexity</strong> increases with ecosystem growth:</p>
<ul>
<li>Multiple LLM providers with different capabilities</li>
<li>Diverse visualization needs across users</li>
<li>Various export formats for downstream tools</li>
<li>Version control for evolving models</li>
</ul>
</section>
<section id="sec-social-scaling" class="level3">
<h3 class="anchored" data-anchor-id="sec-social-scaling">4.5.2 Social and Institutional Scaling</h3>
<p><strong>Adoption barriers</strong> include:</p>
<ul>
<li>Learning curve for formal methods</li>
<li>Institutional inertia in established processes</li>
<li>Concerns about replacing human judgment</li>
<li>Resource requirements for implementation</li>
</ul>
<p><strong>Trust building</strong> requires:</p>
<ul>
<li>Transparent methodology documentation</li>
<li>Published validation studies</li>
<li>High-profile successful applications</li>
<li>Community ownership and development</li>
</ul>
<p><strong>Sustainability</strong> depends on:</p>
<ul>
<li>Open source development model</li>
<li>Diverse funding sources</li>
<li>Academic and industry partnerships</li>
<li>Clear value demonstration</li>
</ul>
</section>
<section id="sec-impact-opportunities" class="level3">
<h3 class="anchored" data-anchor-id="sec-impact-opportunities">4.5.3 Opportunities for Impact</h3>
<p>Despite challenges, several factors favor adoption:</p>
<p><strong>Timing</strong>: AI governance needs tools now, creating receptive audiences</p>
<p><strong>Complementarity</strong>: AMTAIR enhances rather than replaces existing processes</p>
<p><strong>Flexibility</strong>: The approach adapts to different contexts and needs</p>
<p><strong>Network effects</strong>: Value increases as more perspectives are formalized</p>
<p>Early adopters in research organizations and think tanks can demonstrate value, creating momentum for broader adoption.</p>
</section>
</section>
<section id="sec-governance-integration" class="level2">
<h2 class="anchored" data-anchor-id="sec-governance-integration">4.6 Integration with Governance Frameworks</h2>
<!-- [-] TODO: Examine how modeling could complement existing AI governance -->
<p>AMTAIR complements rather than replaces existing governance approaches.</p>
<section id="sec-standards-integration" class="level3">
<h3 class="anchored" data-anchor-id="sec-standards-integration">4.6.1 Standards Development</h3>
<p>Technical standards bodies could use AMTAIR to:</p>
<ul>
<li>Model how proposed standards affect risk pathways</li>
<li>Compare different standard options systematically</li>
<li>Identify unintended consequences through pathway analysis</li>
<li>Build consensus through explicit model negotiation</li>
</ul>
<p>Example: Evaluating compute thresholds for AI system regulation by modeling how different thresholds affect capability development, safety investment, and competitive dynamics.</p>
</section>
<section id="sec-regulatory-integration" class="level3">
<h3 class="anchored" data-anchor-id="sec-regulatory-integration">4.6.2 Regulatory Design</h3>
<p>Regulators could apply the framework to:</p>
<ul>
<li>Assess regulatory impact across different scenarios</li>
<li>Identify enforcement challenges through explicit modeling</li>
<li>Compare international approaches systematically</li>
<li>Design adaptive regulations responsive to evidence</li>
</ul>
<p>Example: Analyzing how liability frameworks affect corporate AI development decisions under different market conditions.</p>
<!-- [-] Added citations about liability frameworks and corporate governance -->
<p>The extensive literature on corporate governance and liability frameworks <span class="citation" data-cites="cuomo2016">Cuomo, Mallin, and Zattoni (<a href="../ref/references.html#ref-cuomo2016" role="doc-biblioref">2016</a>)</span> <span class="citation" data-cites="demirag2000">Demirag, Sudarsanam, and WRIGHT (<a href="../ref/references.html#ref-demirag2000" role="doc-biblioref">2000</a>)</span> <span class="citation" data-cites="devilliers2021">De Villiers and Dimes (<a href="../ref/references.html#ref-devilliers2021" role="doc-biblioref">2021</a>)</span> <span class="citation" data-cites="divito2022">Di Vito and Trottier (<a href="../ref/references.html#ref-divito2022" role="doc-biblioref">2022</a>)</span> <span class="citation" data-cites="kaur2024">Kaur (<a href="../ref/references.html#ref-kaur2024" role="doc-biblioref">2024</a>)</span> <span class="citation" data-cites="list2011">List and Pettit (<a href="../ref/references.html#ref-list2011" role="doc-biblioref">2011</a>)</span> <span class="citation" data-cites="solomon2020">Solomon (<a href="../ref/references.html#ref-solomon2020" role="doc-biblioref">2020</a>)</span> provides theoretical grounding for understanding how regulatory interventions shape organizational behavior. AMTAIR could formalize these relationships in the specific context of AI development, making explicit how different liability regimes might incentivize or discourage safety investments.</p>
</section>
<section id="sec-international-integration" class="level3">
<h3 class="anchored" data-anchor-id="sec-international-integration">4.6.3 International Coordination</h3>
<p>Multilateral bodies could leverage shared models for:</p>
<ul>
<li>Establishing common risk assessments</li>
<li>Negotiating agreements with explicit assumptions</li>
<li>Monitoring compliance through parameter tracking</li>
<li>Adapting agreements as evidence emerges</li>
</ul>
<p>Example: Building shared models for AGI development scenarios to inform international AI governance treaties.</p>
</section>
<section id="sec-organizational-integration" class="level3">
<h3 class="anchored" data-anchor-id="sec-organizational-integration">4.6.4 Organizational Decision-Making</h3>
<p>Individual organizations could use AMTAIR for:</p>
<ul>
<li>Internal risk assessment and planning</li>
<li>Board-level communication about AI strategies</li>
<li>Research prioritization based on model sensitivity</li>
<li>Safety case development with explicit assumptions</li>
</ul>
<p>Example: An AI lab modeling how different safety investments affect both capability advancement and risk mitigation.</p>
</section>
</section>
<section id="sec-future-research" class="level2">
<h2 class="anchored" data-anchor-id="sec-future-research">4.7 Future Research Directions</h2>
<!-- [-] TODO: Acknowledge fundamental limitations regarding novel developments -->
<p>Several research directions<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> could enhance AMTAIR’s capabilities and impact.</p>
<section id="sec-technical-future" class="level3">
<h3 class="anchored" data-anchor-id="sec-technical-future">4.7.1 Technical Enhancements</h3>
<p><strong>Improved extraction</strong>: Fine-tuning language models specifically for argument extraction, handling implicit reasoning, and cross-document synthesis</p>
<p><strong>Richer representations</strong>: Temporal dynamics, continuous variables, and multi-agent interactions within extended frameworks</p>
<p><strong>Inference advances</strong>: Quantum computing applications, neural approximate inference, and hybrid symbolic-neural methods</p>
<p><strong>Validation methods</strong>: Automated consistency checking, anomaly detection in extracted models, and benchmark dataset development</p>
</section>
<section id="sec-methodological-future" class="level3">
<h3 class="anchored" data-anchor-id="sec-methodological-future">4.7.2 Methodological Extensions</h3>
<p><strong>Causal discovery</strong>: Inferring causal structures from data rather than just extracting from text</p>
<p><strong>Experimental integration</strong>: Connecting models to empirical results from AI safety experiments</p>
<p><strong>Dynamic updating</strong>: Continuous model refinement as new evidence emerges from research and deployment</p>
<p><strong>Uncertainty quantification</strong>: Richer representation of deep uncertainty and model confidence</p>
<!-- [-] Added citations about causal structure learning -->
<p>Recent advances in causal structure learning from both text and data <span class="citation" data-cites="babakov2025">Babakov et al. (<a href="../ref/references.html#ref-babakov2025" role="doc-biblioref">2025</a>)</span> <span class="citation" data-cites="ban2023">Ban et al. (<a href="../ref/references.html#ref-ban2023" role="doc-biblioref">2023</a>)</span> <span class="citation" data-cites="bethard2007">Bethard (<a href="../ref/references.html#ref-bethard2007" role="doc-biblioref">2007</a>)</span> <span class="citation" data-cites="chen2023">Chen et al. (<a href="../ref/references.html#ref-chen2023" role="doc-biblioref">2023</a>)</span> <span class="citation" data-cites="heinze-deml2018">Heinze-Deml, Maathuis, and Meinshausen (<a href="../ref/references.html#ref-heinze-deml2018" role="doc-biblioref">2018</a>)</span> <span class="citation" data-cites="squires2023">Squires and Uhler (<a href="../ref/references.html#ref-squires2023" role="doc-biblioref">2023</a>)</span> <span class="citation" data-cites="yang2022">Yang, Han, and Poon (<a href="../ref/references.html#ref-yang2022" role="doc-biblioref">2022</a>)</span> suggest promising directions for enhancing AMTAIR’s extraction capabilities. The theoretical foundations from <span class="citation" data-cites="duhem1954">Duhem (<a href="../ref/references.html#ref-duhem1954" role="doc-biblioref">1954</a>)</span> and <span class="citation" data-cites="meyer2022b">Meyer (<a href="../ref/references.html#ref-meyer2022b" role="doc-biblioref">2022</a>)</span> on the philosophy of science and knowledge structures provide epistemological grounding for these methodological extensions.</p>
</section>
<section id="sec-application-future" class="level3">
<h3 class="anchored" data-anchor-id="sec-application-future">4.7.3 Application Domains</h3>
<p><strong>Beyond AI safety</strong>: Climate risk, biosecurity, nuclear policy, and other existential risks</p>
<p><strong>Corporate governance</strong>: Strategic planning, risk management, and innovation assessment</p>
<p><strong>Scientific modeling</strong>: Formalizing theoretical arguments in emerging fields</p>
<p><strong>Educational tools</strong>: Teaching probabilistic reasoning and critical thinking</p>
</section>
<section id="sec-ecosystem-future" class="level3">
<h3 class="anchored" data-anchor-id="sec-ecosystem-future">4.7.4 Ecosystem Development</h3>
<p><strong>Open standards</strong>: Common formats for model exchange and tool interoperability</p>
<p><strong>Community platforms</strong>: Collaborative model development and sharing infrastructure</p>
<p><strong>Training programs</strong>: Building capacity for formal modeling in governance communities</p>
<p><strong>Quality assurance</strong>: Certification processes for high-stakes model applications</p>
<p>These directions could transform AMTAIR from a single tool into a broader ecosystem for enhanced reasoning about complex risks.</p>
</section>
</section>
<section id="sec-deep-uncertainties" class="level2">
<h2 class="anchored" data-anchor-id="sec-deep-uncertainties">4.8 Known Unknowns and Deep Uncertainties</h2>
<p>While AMTAIR enhances reasoning under uncertainty, fundamental limitations remain regarding truly novel developments that might fall outside existing conceptual frameworks.</p>
<section id="sec-uncertainty-categories" class="level3">
<h3 class="anchored" data-anchor-id="sec-uncertainty-categories">4.8.1 Categories of Deep Uncertainty</h3>
<p><strong>Novel Capabilities</strong>: Future AI developments may operate according to principles outside current scientific understanding. No amount of careful modeling can anticipate fundamental paradigm shifts in what intelligence can accomplish.</p>
<p><strong>Emergent Behaviors</strong>: Complex system properties that resist prediction from component analysis may dominate outcomes. The interaction between advanced AI systems and human society could produce wholly unexpected dynamics.</p>
<p><strong>Strategic Interactions</strong>: Game-theoretic dynamics with superhuman AI systems exceed human modeling capacity. We cannot reliably predict how entities smarter than us will behave strategically.</p>
<p><strong>Social Transformation</strong>: Unprecedented social and economic changes may invalidate current institutional assumptions. Our models assume continuity in basic social structures that AI might fundamentally alter.</p>
</section>
<section id="sec-adaptation-strategies" class="level3">
<h3 class="anchored" data-anchor-id="sec-adaptation-strategies">4.8.2 Adaptation Strategies for Deep Uncertainty</h3>
<p>Rather than pretending to model the unmodelable, AMTAIR incorporates several strategies:</p>
<p><strong>Model Architecture Flexibility</strong>: The modular structure enables rapid incorporation of new variables as novel factors become apparent. When surprises occur, models can be updated rather than discarded.</p>
<p><strong>Explicit Uncertainty Tracking</strong>: Confidence levels for each model component make clear where knowledge is solid versus speculative. This prevents false confidence in highly uncertain domains.</p>
<p><strong>Scenario Branching</strong>: Multiple model variants capture different assumptions about fundamental uncertainties. Rather than committing to one worldview, the system maintains portfolios of possibilities.</p>
<p><strong>Update Mechanisms</strong>: Integration with prediction markets and expert assessment enables rapid model revision as new information emerges. Models evolve rather than remaining static.</p>
</section>
<section id="sec-robust-principles" class="level3">
<h3 class="anchored" data-anchor-id="sec-robust-principles">4.8.3 Robust Decision-Making Principles</h3>
<p>Given deep uncertainty, certain decision principles become paramount:</p>
<p><strong>Option Value Preservation</strong>: Policies should maintain flexibility for future course corrections rather than locking in irreversible choices based on current models.</p>
<p><strong>Portfolio Diversification</strong>: Multiple approaches hedging across different uncertainty sources provide robustness against model error.</p>
<p><strong>Early Warning Systems</strong>: Monitoring for developments that would invalidate current models enables rapid response when assumptions break down.</p>
<p><strong>Adaptive Governance</strong>: Institutional mechanisms must enable rapid response to new information rather than rigid adherence to plans based on outdated models.</p>
<p>The goal is not to eliminate uncertainty but to make good decisions despite it. AMTAIR provides tools for systematic reasoning about what we do know while maintaining appropriate humility about what we don’t and can’t know.</p>
</section>
</section>
<section id="sec-implications-summary" class="level2">
<h2 class="anchored" data-anchor-id="sec-implications-summary">4.9 Summary of Implications</h2>
<p>The discussion reveals both the promise and limitations of computational approaches to AI governance coordination:</p>
<p><strong>Technical Feasibility</strong>: Despite imperfections, automated extraction and formal modeling prove practically viable for complex AI risk arguments.</p>
<p><strong>Epistemic Value</strong>: Making implicit models explicit, enabling systematic comparison, and supporting evidence integration enhance collective reasoning.</p>
<p><strong>Practical Limitations</strong>: Extraction boundaries, false precision risks, and implementation dependencies require careful management.</p>
<p><strong>Integration Potential</strong>: The approach complements rather than replaces existing governance frameworks, adding rigor without sacrificing flexibility.</p>
<p><strong>Future Development</strong>: Technical enhancements, methodological extensions, and ecosystem growth could amplify impact.</p>
<p><strong>Deep Uncertainty</strong>: Fundamental limits on predicting novel developments require maintaining humility and adaptability.</p>
<p>These findings suggest AMTAIR represents a valuable addition to the AI governance toolkit—not a panacea but a meaningful enhancement to our collective capacity for navigating unprecedented challenges.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-babakov2025" class="csl-entry" role="listitem">
Babakov, Nikolay, Adarsa Sivaprasad, Ehud Reiter, and Alberto Bugarín-Diz. 2025. <span>“Reusability of <span>Bayesian Networks</span> Case Studies: A Survey.”</span> <em>Applied Intelligence</em> 55 (6): 417. <a href="https://doi.org/10.1007/s10489-025-06289-5">https://doi.org/10.1007/s10489-025-06289-5</a>.
</div>
<div id="ref-ban2023" class="csl-entry" role="listitem">
Ban, Taiyu, Lyuzhou Chen, Derui Lyu, Xiangyu Wang, and Huanhuan Chen. 2023. <span>“Causal <span>Structure Learning Supervised</span> by <span>Large Language Model</span>.”</span> November 20, 2023. <a href="https://doi.org/10.48550/arXiv.2311.11689">https://doi.org/10.48550/arXiv.2311.11689</a>.
</div>
<div id="ref-bethard2007" class="csl-entry" role="listitem">
Bethard, Steven John. 2007. <span>“Finding Event, Temporal and Causal Structure in Text: <span>A</span> Machine Learning Approach.”</span> PhD thesis, University of Colorado at Boulder. <a href="https://search.proquest.com/openview/405fe32503123d9b5f4836dc3be4c011/1?pq-origsite=gscholar&amp;cbl=18750">https://search.proquest.com/openview/405fe32503123d9b5f4836dc3be4c011/1?pq-origsite=gscholar&amp;cbl=18750</a>.
</div>
<div id="ref-chen2023" class="csl-entry" role="listitem">
Chen, Lu, Ruqing Zhang, Wei Huang, Wei Chen, Jiafeng Guo, and Xueqi Cheng. 2023. <span>“Inducing <span>Causal Structure</span> for <span>Abstractive Text Summarization</span>.”</span> In <em>Proceedings of the 32nd <span>ACM International Conference</span> on <span>Information</span> and <span>Knowledge Management</span></em>, 213–23. Birmingham United Kingdom: ACM. <a href="https://doi.org/10.1145/3583780.3614934">https://doi.org/10.1145/3583780.3614934</a>.
</div>
<div id="ref-cuomo2016" class="csl-entry" role="listitem">
Cuomo, Francesca, Christine Mallin, and Alessandro Zattoni. 2016. <span>“Corporate Governance Codes: <span>A</span> Review and Research Agenda.”</span> <em>Corporate Governance: An International Review</em> 24 (3): 222–41. <a href="https://ueaeprints.uea.ac.uk/id/eprint/57664/">https://ueaeprints.uea.ac.uk/id/eprint/57664/</a>.
</div>
<div id="ref-devilliers2021" class="csl-entry" role="listitem">
De Villiers, Charl, and Ruth Dimes. 2021. <span>“Determinants, Mechanisms and Consequences of Corporate Governance Reporting: A Research Framework.”</span> <em>Journal of Management and Governance</em> 25 (1): 7–26. <a href="https://doi.org/10.1007/s10997-020-09530-0">https://doi.org/10.1007/s10997-020-09530-0</a>.
</div>
<div id="ref-demirag2000" class="csl-entry" role="listitem">
Demirag, Istemi, Sudi Sudarsanam, and MIKE WRIGHT. 2000. <span>“Corporate Governance: Overview and Research Agenda.”</span> <em>The British Accounting Review</em> 32 (4): 341–54. <a href="https://www.academia.edu/download/49469624/bare.2000.014620161009-3955-1dt4aq5.pdf">https://www.academia.edu/download/49469624/bare.2000.014620161009-3955-1dt4aq5.pdf</a>.
</div>
<div id="ref-divito2022" class="csl-entry" role="listitem">
Di Vito, Jackie, and Kim Trottier. 2022. <span>“A <span>Literature Review</span> on <span>Corporate Governance Mechanisms</span>: <span>Past</span>, <span>Present</span>, and <span>Future</span>*.”</span> <em>Accounting Perspectives</em> 21 (2): 207–35. <a href="https://doi.org/10.1111/1911-3838.12279">https://doi.org/10.1111/1911-3838.12279</a>.
</div>
<div id="ref-duhem1954" class="csl-entry" role="listitem">
Duhem, Pierre Maurice Marie. 1954. <em>The <span>Aim</span> and <span>Structure</span> of <span>Physical Theory</span></em>. 1. Princeton University Press.
</div>
<div id="ref-heinze-deml2018" class="csl-entry" role="listitem">
Heinze-Deml, Christina, Marloes H. Maathuis, and Nicolai Meinshausen. 2018. <span>“Causal <span>Structure Learning</span>.”</span> <em>Annual Review of Statistics and Its Application</em> 5 (1): 371–91. <a href="https://doi.org/10.1146/annurev-statistics-031017-100630">https://doi.org/10.1146/annurev-statistics-031017-100630</a>.
</div>
<div id="ref-kaur2024" class="csl-entry" role="listitem">
Kaur, Kawaljit. 2024. <span>“Corporate <span>Governance</span> and <span>Legal Accountability</span>: <span>A Critical Review</span> of <span>Global Practices</span>.”</span> <em>Journal of Law</em> 2 (6): 1–7. <a href="https://joi.shodhsagar.org/index.php/SSJOI/article/view/16">https://joi.shodhsagar.org/index.php/SSJOI/article/view/16</a>.
</div>
<div id="ref-list2011" class="csl-entry" role="listitem">
List, Christian, and Philip Pettit. 2011. <em>Group <span>Agency</span>: <span>The Possibility</span>, <span>Design</span>, and <span>Status</span> of <span>Corporate Agents</span></em>. Oxford University Press.
</div>
<div id="ref-meyer2022b" class="csl-entry" role="listitem">
Meyer, Valentin Jakob. 2022. <span>“A <span>Structure</span> of <span>Knowledge</span> &amp; the <span>Process</span> of <span>Science</span>.”</span> <em>Philosophy of the Social Sciences</em> First Course Paper. https://doi.org/<a href="https://www.vjmeyer.com/papers/essays">https://www.vjmeyer.com/papers/essays</a>.
</div>
<div id="ref-solomon2020" class="csl-entry" role="listitem">
Solomon, Jill. 2020. <em>Corporate Governance and Accountability</em>. John Wiley &amp; Sons. <a href="https://books.google.ca/books?hl=en&amp;lr=&amp;id=JAX9DwAAQBAJ&amp;oi=fnd&amp;pg=PR1&amp;dq=review+of+the+effects+of+liability+frameworks+on+corporate+governance+&amp;ots=ny23_vd-U0&amp;sig=3LuNNhvSWXriEeg-ipAdDIQGAgo">https://books.google.ca/books?hl=en&amp;lr=&amp;id=JAX9DwAAQBAJ&amp;oi=fnd&amp;pg=PR1&amp;dq=review+of+the+effects+of+liability+frameworks+on+corporate+governance+&amp;ots=ny23_vd-U0&amp;sig=3LuNNhvSWXriEeg-ipAdDIQGAgo</a>.
</div>
<div id="ref-squires2023" class="csl-entry" role="listitem">
Squires, Chandler, and Caroline Uhler. 2023. <span>“Causal <span>Structure Learning</span>: <span>A Combinatorial Perspective</span>.”</span> <em>Foundations of Computational Mathematics</em> 23 (5): 1781–1815. <a href="https://doi.org/10.1007/s10208-022-09581-9">https://doi.org/10.1007/s10208-022-09581-9</a>.
</div>
<div id="ref-yang2022" class="csl-entry" role="listitem">
Yang, Jie, Soyeon Caren Han, and Josiah Poon. 2022. <span>“A Survey on Extraction of Causal Relations from Natural Language Text.”</span> <em>Knowledge and Information Systems</em> 64 (5): 1161–86. <a href="https://doi.org/10.1007/s10115-022-01665-w">https://doi.org/10.1007/s10115-022-01665-w</a>.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Copulas provide a mathematically elegant way to separate marginal behavior from dependence structure<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>4<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/3.0.AMTAIR.html" class="pagination-link" aria-label="3. AMTAIR: Design and Implementation">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">3. AMTAIR: Design and Implementation</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/5.Conclusion.html" class="pagination-link" aria-label="5. Conclusion: Toward Coordinated AI Governance">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">5. Conclusion: Toward Coordinated AI Governance</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/VJMeyer/submission/edit/main/chapters/4.Discussion.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></div></div></footer></body></html>