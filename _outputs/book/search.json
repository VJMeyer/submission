[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#main-formatting",
    "href": "index.html#main-formatting",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Main Formatting",
    "text": "Main Formatting\n\nHtml Comments",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#syntax-for-tasks",
    "href": "index.html#syntax-for-tasks",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Syntax for Tasks",
    "text": "Syntax for Tasks\n\nTasks with ToDo Tree\n\nSimple “One-line tasks”\nUse Code ticks and html comment and task format for tasks distinctly visible across all formats including the ToDo-Tree overview:\n&lt;!-- [ ] ToDos for things to do / tasks / reminders (allows \"jump to with Taks Tree extension\") --&gt;\nUse html comment and task format for open or uncertain tasks, visible in the .qmd file:\n\n\n\nMore Complex Tasks with Notes\n&lt;!-- [ ] Task Title: short description--&gt;\n\n  More Information about task\n\n  Relevant notes\n\n  Step-by-step implementation Plan\n\n  Etc.\n\n\n\nCompleted Tasks\nRetain completed tasks in ToDo-Tree by adding an x in the brackets: [x] &lt;!-- [x] Tasks which have been finished but should remain for later verification --&gt;\n\nMark and remove completed tasks from ToDo-Tree by adding a minus in the brackets: [-]\n&lt;!-- [-] Tasks which have been finished but should remain visible for later verification --&gt;\n\n\n\nMissing Citations\n&lt;!-- [ ] FIND: @CITATION_KEY_PURPOSE: \"Description of the appropriate/idea source, including ideas /suggestions / search terms etc.\" --&gt;\n\n\nSuggested Citation\n&lt;!-- [ ] VERIFY: @CITATION_KEY_SUGGESTED: \"Description of the appropriate paper, book, source\" [Include BibTex if known] --&gt;\n\n\n\nTask Syntax Examples\n&lt;!-- [ ] (Example short: open and visible in text)   Find and list the names of the MTAIR team-members responsible for the Analytica Implementation --&gt;\n&lt;!-- [ ] (Example longer: open and visible in text)    Review/Plan/Discuss integrating Live Prediction Markets --&gt;\n\n  Live prediction market integration requires:\n    (1) API connections to platforms (Metaculus, Manifold),\n    (2) Question-to-variable mapping algorithms,\n    (3) Probability update mechanisms, \n    (4) Handling of market dynamics (thin markets, manipulation).\n    Current mentions may overstate readiness or underestimate complexity.\n    Need realistic assessment of what's achievable.\n\n  Implementation Steps:\n      0. List/mention all relevant platforms with a brief description each\n      1. Review all existing prediction market mentions for accuracy\n      2. Assess actual API availability and limitations\n      3. Describe/explain/discuss how to implement basic proof-of-concept with single platform\n      4. Document challenges: question mapping, market interpretation\n      5. Create realistic timeline for full implementation\n      6. Revise thesis claims to match reality\n      7. Add \"Future Work\" and/or extension section on complete integration\n      8. Include descriptions of mockups/designs even if not fully built \n      9. Highlight/discuss the advantages of such integrations\n      10. Quickly brainstorm for downsides worth mentioning\n\n\n\n\nVerbatim Code Formatting\nverbatim code formatting for notes and ideas to be included (here)\n\n\nCode Block formatting\nAlso code blocks for more extensive notes and ideas to be included and checklists\n- test 1. \n- test 2. \n- test 3.\n2. second\n3. third\ncode\nAdd a language to syntax highlight code blocks:\n1 + 1\n\n\nBlockquote Formatting\n\nBlockquote formatting for “Suggested Citations (e.g. carlsmith 2024 on …)” and/or claims which require a citation (e.g. claim x should be backed-up by a ciation from the literature)\n\n\n\nTables\n\n\n\nTable 1.1: Demonstration of pipe table syntax\n\n\n\n\n\nRight\nLeft\nDefault\nCenter\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1\n\n\n\n\n\n\n\n\n\nTable 1.2: My Caption 1\n\n\n\n\n\nCol1\nCol2\nCol3\n\n\n\n\nA\nB\nC\n\n\nE\nF\nG\n\n\nA\nG\nG\n\n\n\n\n\n\nReferencing tables with @tbl-KEY: See Table 1.2.\n\n\n\nTable 1.3: Main Caption\n\n\n\n\n\n\n\n(a) First Table\n\n\n\n\n\nCol1\nCol2\nCol3\n\n\n\n\nA\nB\nC\n\n\nE\nF\nG\n\n\nA\nG\nG\n\n\n\n\n\n\n\n\n\n\n\n(b) Second Table\n\n\n\n\n\nCol1\nCol2\nCol3\n\n\n\n\nA\nB\nC\n\n\nE\nF\nG\n\n\nA\nG\nG\n\n\n\n\n\n\n\n\n\n\n\nSee Table 1.3 for details, especially Table 1.3 (b).\npython\n#| label: tbl-planets\n#| tbl-cap: Astronomical object\n\nfrom IPython.display import Markdown\nfrom tabulate import tabulate\ntable = [[\"Sun\",\"696,000\",1.989e30],\n         [\"Earth\",\"6,371\",5.972e24],\n         [\"Moon\",\"1,737\",7.34e22],\n         [\"Mars\",\"3,390\",6.39e23]]\nMarkdown(tabulate(\n  table, \n  headers=[\"Astronomical object\",\"R (km)\", \"mass (kg)\"]\n))\n\nSample grid table.\n\n\n\n\n\n\n\nFruit\nPrice\nAdvantages\n\n\n\n\nBananas\n$1.34\n\nbuilt-in wrapper\nbright color\n\n\n\nOranges\n$2.10\n\ncures scurvy\ntasty\n\n\n\n\nContent with HTML tables you don’t want processed.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#sec-heading",
    "href": "index.html#sec-heading",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Headings & Potential Headings in Standard Markdown formatting (‘##’)",
    "text": "Headings & Potential Headings in Standard Markdown formatting (‘##’)\n\nHeading 3\n\nHeading 4",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#text-formatting-options",
    "href": "index.html#text-formatting-options",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Text Formatting Options",
    "text": "Text Formatting Options\nitalics, bold, bold italics\nsuperscript2 and subscript2\nstrikethrough\nThis text is highlighted\nThis text is underlined\nThis text is smallcaps",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#lists",
    "href": "index.html#lists",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Lists",
    "text": "Lists\n\nunordered list\n\nsub-item 1\nsub-item 2\n\nsub-sub-item 1\n\n\nitem 2\nContinued (indent 4 spaces)\n\n\nordered list\nitem 2\n\nsub-item 1\n\nsub-sub-item 1",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#math",
    "href": "index.html#math",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Math",
    "text": "Math\ninline math: \\(E = mc^{2}\\)\ndisplay math:\n\\[E = mc^{2}\\]\nIf you want to define custom TeX macros, include them within $$ delimiters enclosed in a .hidden block. For example:\n\n\\[\n\\def\\RR{{\\bf R}}\n\\def\\bold#1{{\\bf #1}}\n\\]\n\nFor HTML math processed using MathJax (the default) you can use the \\def, \\newcommand, \\renewcommand, \\newenvironment, \\renewenvironment, and \\let commands to create your own macros and environments.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "",
    "text": "Inlines notes are easier to write, since you don’t have to pick an identifier and move down to type the note.↩︎\nHere is the footnote.↩︎\nHere’s one with multiple blocks.\nSubsequent paragraphs are indented to show that they belong to the previous footnote.\n{ some.code }\nThe whole paragraph can be indented, or just the first line. In this way, multi-paragraph footnotes work like multi-paragraph list items.↩︎",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#sec-callouts",
    "href": "index.html#sec-callouts",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Callouts",
    "text": "Callouts\nQuarto’s native callouts work without additional packages:\n\nThis is written in a ‘note’ environment – but it does not seem to produce any special rendering.\n\n\n\n\n\n\n\nOptional Title\n\n\n\nContent here\n\n\n\n\n\n\n\n\nImportant Note2\n\n\n\nThis renders perfectly in both HTML and PDF.\n\n\nAlso for markdown:\n::: {.render_as_markdown_example}\n## Markdown Heading\nThis renders perfectly in both HTML and PDF but as markdown \"plain text\"\n:::",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#links",
    "href": "index.html#links",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Links",
    "text": "Links\n&lt;https://quarto.org/docs/authoring/markdown-basics.html&gt; produces: https://quarto.org/docs/authoring/markdown-basics.html\n[Quarto Book Cross-References](https://quarto.org/docs/books/book-crossrefs.html) produces: Quarto Book Cross-References",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#sec-figures1",
    "href": "index.html#sec-figures1",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Images & Figures",
    "text": "Images & Figures\n[![AMTAIR Automation Pipeline from @bucknall2022](/images/pipeline.png){\n  #fig-automation_pipeline\n  fig-scap=\"Five-step AMTAIR automation pipeline from PDFs to Bayesian networks\" \n  fig-alt=\"FLOWCHART: Five-step automation pipeline workflow for AMTAIR project.\n          DATA: The pipeline transforms PDFs through ArgDown, BayesDown, CSV, and HTML into Bayesian network visualizations.\n          PURPOSE: Illustrates the core technical process that enables automated extraction of probabilistic models from AI safety literature.\n          DETAILS: Five numbered green steps show: (1) LLM-based extraction from PDFs to ArgDown, (2) ArgDown to BayesDown completion with probabilities, (3) Extracting world-models as CSV data, (4) Software tools for data inference, and (5) Visualization of the resulting Bayesian network.\n          Each step includes example outputs, with the final visualization showing a Rain-Sprinkler-Grass Wet Bayesian network with probability tables.\n          SOURCE: Created by the author to explain the AMTAIR methodology\n          \"\n  fig-align=\"center\" \n  width=\"100%\"\n  }](https://github.com/VJMeyer/submission)\n\n\nTesting crossreferencing grapics @fig-automation_pipeline.\n\n![Caption/Title 2](/images/cover.png){#fig-testgraphic2 fig-scap=\"Short 2 caption\" fig-alt=\"2nd Alt Text / Description.\" fig-align=\"left\" width=\"30%\"}\n\nTesting crossreferencing grapics @fig-testgraphic2.\n\n\n\n\n\n\nFigure 1.1: AMTAIR Automation Pipeline from\n\n\n\nTesting crossreferencing grapics Figure 3.2. Note that the indentations of graphic inclusions get messed up by viewing them in “view mode” in VS code.\n\n\n\n\n\n\nFigure 1.2: Caption/Title 2\n\n\n\nTesting crossreferencing grapics Figure 1.2.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#page-breaks",
    "href": "index.html#page-breaks",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Page Breaks",
    "text": "Page Breaks\npage 1\n\n\n\npage 2\npage 1\n\npage 2",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#sec-code",
    "href": "index.html#sec-code",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Including Code",
    "text": "Including Code\n\nCode\nimport pandas as pd\nprint(\"AMTAIR is working!\")\n\n\n\n\n\nAMTAIR is working!\n\n\n\nFigure 1.3\n\n\n\n\nIn-Line LaTeX\n\n\n\nIn-Line HTML\nHere’s some raw inline HTML: html",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#reference-or-embed-code-from-.ipynb-files",
    "href": "index.html#reference-or-embed-code-from-.ipynb-files",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Reference or Embed Code from .ipynb files",
    "text": "Reference or Embed Code from .ipynb files\n\nCode chunks from .ipynb notebooks can be embedded in the .qmd text with:\n{{&lt; embed /AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb#my_code_cell_test &gt;}}\n\n\nwhich produces the output of executing the code cell:\n\n\n\nConnecting to repository: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/\nAttempting to load: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/ArgDown.md\n✅ Successfully connected to repository and loaded test files.\n[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {\"instantiations\": [\"existential_catastrophe_TRUE\", \"existential_catastrophe_FALSE\"]}\n- [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {\"instantiations\": [\"human_disempowerment_TRUE\", \"human_disempowerment_FALSE\"]}\n    - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {\"instantiations\": [\"scale_of_power_seeking_TRUE\", \"scale_of_power_seeking_FALSE\"]}\n        - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n            - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {\"instantiations\": [\"aps_systems_TRUE\", \"aps_systems_FALSE\"]}\n                - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {\"instantiations\": [\"advanced_ai_capability_TRUE\", \"advanced_ai_capability_FALSE\"]}\n                - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {\"instantiations\": [\"agentic_planning_TRUE\", \"agentic_planning_FALSE\"]}\n                - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {\"instantiations\": [\"strategic_awareness_TRUE\", \"strategic_awareness_FALSE\"]}\n            - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {\"instantiations\": [\"difficulty_of_alignment_TRUE\", \"difficulty_of_alignment_FALSE\"]}\n                - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {\"instantiations\": [\"instrumental_convergence_TRUE\", \"instrumental_convergence_FALSE\"]}\n                - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {\"instantiations\": [\"problems_with_proxies_TRUE\", \"problems_with_proxies_FALSE\"]}\n                - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {\"instantiations\": [\"problems_with_search_TRUE\", \"problems_with_search_FALSE\"]}\n            - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {\"instantiations\": [\"deployment_decisions_DEPLOY\", \"deployment_decisions_WITHHOLD\"]}\n                - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {\"instantiations\": [\"incentives_to_build_aps_STRONG\", \"incentives_to_build_aps_WEAK\"]}\n                    - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {\"instantiations\": [\"usefulness_of_aps_HIGH\", \"usefulness_of_aps_LOW\"]}\n                    - [Competitive_Dynamics]: Competitive pressures between AI developers. {\"instantiations\": [\"competitive_dynamics_STRONG\", \"competitive_dynamics_WEAK\"]}\n                - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {\"instantiations\": [\"deception_by_ai_TRUE\", \"deception_by_ai_FALSE\"]}\n        - [Corrective_Feedback]: Human society implementing corrections after observing problems. {\"instantiations\": [\"corrective_feedback_EFFECTIVE\", \"corrective_feedback_INEFFECTIVE\"]}\n            - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {\"instantiations\": [\"warning_shots_OBSERVED\", \"warning_shots_UNOBSERVED\"]}\n            - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {\"instantiations\": [\"rapid_capability_escalation_TRUE\", \"rapid_capability_escalation_FALSE\"]}\n[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {\"instantiations\": [\"barriers_to_understanding_HIGH\", \"barriers_to_understanding_LOW\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {\"instantiations\": [\"adversarial_dynamics_TRUE\", \"adversarial_dynamics_FALSE\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {\"instantiations\": [\"stakes_of_error_HIGH\", \"stakes_of_error_LOW\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n\n\n\n\n\n\nincluding ‘echo=true’ renders the code of the cell:\n{{&lt; embed /AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.ipynb#my_code_cell_test echo=true &gt;}}\n\n\n\nCode\n# @title 0.2 --- Connect to GitHub Repository --- Load Files\n\n\"\"\"\nBLOCK PURPOSE: Establishes connection to the AMTAIR GitHub repository and provides\nfunctions to load example data files for processing.\n\nThis block creates a reusable function for accessing files from the project's\nGitHub repository, enabling access to example files like the rain-sprinkler-lawn\nBayesian network that serves as our canonical test case.\n\nDEPENDENCIES: requests library, io library\nOUTPUTS: load_file_from_repo function and test file loads\n\"\"\"\n\nfrom requests.exceptions import HTTPError\n\n# Specify the base repository URL for the AMTAIR project\nrepo_url = \"https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/\"\nprint(f\"Connecting to repository: {repo_url}\")\n\ndef load_file_from_repo(relative_path):\n    \"\"\"\n    Loads a file from the specified GitHub repository using a relative path.\n\n    Args:\n        relative_path (str): Path to the file relative to the repo_url\n\n    Returns:\n        For CSV/JSON: pandas DataFrame\n        For MD: string containing file contents\n\n    Raises:\n        HTTPError: If file not found or other HTTP error occurs\n        ValueError: If unsupported file type is requested\n    \"\"\"\n    file_url = repo_url + relative_path\n    print(f\"Attempting to load: {file_url}\")\n\n    # Fetch the file content from GitHub\n    response = requests.get(file_url)\n\n    # Check for bad status codes with enhanced error messages\n    if response.status_code == 404:\n        raise HTTPError(f\"File not found at URL: {file_url}. Check the file path/name and ensure the file is publicly accessible.\", response=response)\n    else:\n        response.raise_for_status()  # Raise for other error codes\n\n    # Convert response to file-like object\n    file_object = io.StringIO(response.text)\n\n    # Process different file types appropriately\n    if relative_path.endswith(\".csv\"):\n        return pd.read_csv(file_object)  # Return DataFrame for CSV\n    elif relative_path.endswith(\".json\"):\n        return pd.read_json(file_object)  # Return DataFrame for JSON\n    elif relative_path.endswith(\".md\"):\n        return file_object.read()  # Return raw content for MD files\n    else:\n        raise ValueError(f\"Unsupported file type: {relative_path.split('.')[-1]}. Add support in the GitHub Connection section of this notebook.\")\n\n# Load example files to test connection\ntry:\n    # Load the extracted data CSV file\n#    df = load_file_from_repo(\"extracted_data.csv\")\n\n    # Load the ArgDown test text\n    md_content = load_file_from_repo(\"ArgDown.md\")\n\n    print(\"✅ Successfully connected to repository and loaded test files.\")\nexcept Exception as e:\n    print(f\"❌ Error loading files: {str(e)}\")\n    print(\"Please check your internet connection and the repository URL.\")\n\n# Display preview of loaded content (commented out to avoid cluttering output)\nprint(md_content)\n\n\nConnecting to repository: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/\nAttempting to load: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/ArgDown.md\n✅ Successfully connected to repository and loaded test files.\n[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {\"instantiations\": [\"existential_catastrophe_TRUE\", \"existential_catastrophe_FALSE\"]}\n- [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {\"instantiations\": [\"human_disempowerment_TRUE\", \"human_disempowerment_FALSE\"]}\n    - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {\"instantiations\": [\"scale_of_power_seeking_TRUE\", \"scale_of_power_seeking_FALSE\"]}\n        - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n            - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {\"instantiations\": [\"aps_systems_TRUE\", \"aps_systems_FALSE\"]}\n                - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {\"instantiations\": [\"advanced_ai_capability_TRUE\", \"advanced_ai_capability_FALSE\"]}\n                - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {\"instantiations\": [\"agentic_planning_TRUE\", \"agentic_planning_FALSE\"]}\n                - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {\"instantiations\": [\"strategic_awareness_TRUE\", \"strategic_awareness_FALSE\"]}\n            - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {\"instantiations\": [\"difficulty_of_alignment_TRUE\", \"difficulty_of_alignment_FALSE\"]}\n                - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {\"instantiations\": [\"instrumental_convergence_TRUE\", \"instrumental_convergence_FALSE\"]}\n                - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {\"instantiations\": [\"problems_with_proxies_TRUE\", \"problems_with_proxies_FALSE\"]}\n                - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {\"instantiations\": [\"problems_with_search_TRUE\", \"problems_with_search_FALSE\"]}\n            - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {\"instantiations\": [\"deployment_decisions_DEPLOY\", \"deployment_decisions_WITHHOLD\"]}\n                - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {\"instantiations\": [\"incentives_to_build_aps_STRONG\", \"incentives_to_build_aps_WEAK\"]}\n                    - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {\"instantiations\": [\"usefulness_of_aps_HIGH\", \"usefulness_of_aps_LOW\"]}\n                    - [Competitive_Dynamics]: Competitive pressures between AI developers. {\"instantiations\": [\"competitive_dynamics_STRONG\", \"competitive_dynamics_WEAK\"]}\n                - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {\"instantiations\": [\"deception_by_ai_TRUE\", \"deception_by_ai_FALSE\"]}\n        - [Corrective_Feedback]: Human society implementing corrections after observing problems. {\"instantiations\": [\"corrective_feedback_EFFECTIVE\", \"corrective_feedback_INEFFECTIVE\"]}\n            - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {\"instantiations\": [\"warning_shots_OBSERVED\", \"warning_shots_UNOBSERVED\"]}\n            - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {\"instantiations\": [\"rapid_capability_escalation_TRUE\", \"rapid_capability_escalation_FALSE\"]}\n[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {\"instantiations\": [\"barriers_to_understanding_HIGH\", \"barriers_to_understanding_LOW\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {\"instantiations\": [\"adversarial_dynamics_TRUE\", \"adversarial_dynamics_FALSE\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {\"instantiations\": [\"stakes_of_error_HIGH\", \"stakes_of_error_LOW\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n\n\n\n\nLink:\nFull Notebooks are embedded in the Appendix through the _quarto.yml file with:",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#diagrams",
    "href": "index.html#diagrams",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Diagrams",
    "text": "Diagrams\nQuarto has native support for embedding Mermaid and Graphviz diagrams. This enables you to create flowcharts, sequence diagrams, state diagrams, Gantt charts, and more using a plain text syntax inspired by markdown.\nFor example, here we embed a flowchart created using Mermaid:\n\n\nCode\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#sec-citations",
    "href": "index.html#sec-citations",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Citations",
    "text": "Citations\nSoares and Fallenstein (2014) \n(Soares and Fallenstein 2014) and (Knuth 1984)\nBlah Blah (see Knuth 1984, 33–35; also Growiec 2024, chap. 1)\nBlah Blah (Knuth 1984, 33–35, 38–39 and passim)\nBlah Blah (Growiec 2024; Knuth 1984).\nGrowiec says blah (2024)\n\nNarrative citations (author as subject)\nSoares and Fallenstein (2014) argues that AI alignment requires…\n\n\nParenthetical citations (supporting reference)\nRecent work supports this view (Soares and Fallenstein 2014; Knuth 1984).\n\n\nAuthor-only citation (when discussing the person)\nAs (2014) demonstrates in their analysis…\n\n\nYear-only citation (when author already mentioned)\nSoares (2014) later revised this position.\n\n\nPage-specific references\nThe key insight appears in (Soares and Fallenstein 2014, 45–67).\n\n\nMultiple works, different pages\nThis view is supported (Soares and Fallenstein 2014, 23; Knuth 1984, 156–59).",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#sec-crossref",
    "href": "index.html#sec-crossref",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Section Cross-References",
    "text": "Section Cross-References\nRefer to sections like: Toward Adaptive Governance and Section Cross-References \nCaveat: refering to sections with @sec-HEADINGS works only for sections with:\n## Heading {#sec-HEADINGS}\nIt does not work for sections with \".unnumbered and/or .unlisted\":\n## Heading {#sec-HEADINGS .unnumbered .unlisted}\nFurthermore the .qmd and/or .md yml settings (~ numbering have to be just right)\n\nSection Numbers\nBy default, all headings in your document create a numbered section. You customize numbering depth using the number-depth option. For example, to only number sections immediately below the chapter level, use this:\nnumber-depth: 2\nNote that toc-depth is independent of number-depth (i.e. you can have unnumbered entries in the TOC if they are masked out from numbering by number-depth).\nTesting crossreferencing grapics Figure 3.2. See Chapter Quarto Syntax for more details on visualizing model diagnostics.\nTesting crossreferencing headings AI Existential Risk: The Carlsmith Model\nTesting crossreferencing headings @sec-rain-sprinkler-grass which does not work yet. \nChapter Cross-Reference Section Cross-References",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#pages-in-landscape",
    "href": "index.html#pages-in-landscape",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Pages in Landscape",
    "text": "Pages in Landscape\n\nThis will appear in landscape but only in PDF format. Testing crossreferencing headings AI Existential Risk: The Carlsmith Model",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#illustrations-and-terminology-quick-references",
    "href": "index.html#illustrations-and-terminology-quick-references",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Illustrations and Terminology — Quick References",
    "text": "Illustrations and Terminology — Quick References\n\nAcknowledgments\n\nAcademic supervisor (Prof. Timo Speith) and institution (University of Bayreuth)\n\nResearch collaborators, especially those connected to the original MTAIR project\n\nTechnical advisors who provided feedback on implementation aspects\n\nPersonal supporters who enabled the research through encouragement and feedback",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#list-of-graphics-figures",
    "href": "index.html#list-of-graphics-figures",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "List of Graphics & Figures",
    "text": "List of Graphics & Figures\n\n\n\nFigure 1.1: The coordination crisis in AI governance - visualization of fragmentation\n\nFigure 2.1: The Carlsmith model - DAG representation\n\nFigure 3.1: Research design overview - workflow diagram\n\nFigure 3.2: From natural language to BayesDown - transformation process\n\nFigure 4.1: ARPA system architecture - component diagram\n\nFigure 4.2: Visualization of Rain-Sprinkler-Grass_Wet Bayesian network - screenshot\n\nFigure 5.1: Extraction quality metrics - comparative chart\n\nFigure 5.2: Comparative analysis of AI governance worldviews - network visualization",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#list-of-abbreviations",
    "href": "index.html#list-of-abbreviations",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "List of Abbreviations",
    "text": "List of Abbreviations\n\n\nesp. especially\nf., ff. following\nincl. including\np., pp. page(s)\nMAD Mutually Assured Destruction\n\nAI - Artificial Intelligence\n\nAGI - Artificial General Intelligence\n\nARPA - AI Risk Pathway Analyzer\n\nDAG - Directed Acyclic Graph\n\nLLM - Large Language Model\n\nMTAIR - Modeling Transformative AI Risks\n\nP(Doom) - Probability of existential catastrophe from misaligned AI\n\nCPT - Conditional Probability Table",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#glossary",
    "href": "index.html#glossary",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "Glossary",
    "text": "Glossary\n\n\n\nArgument mapping: A method for visually representing the structure of arguments\n\nBayesDown: An extension of ArgDown that incorporates probabilistic information\n\nBayesian network: A probabilistic graphical model representing variables and their dependencies\n\nConditional probability: The probability of an event given that another event has occurred\n\nDirected Acyclic Graph (DAG): A graph with directed edges and no cycles\n\nExistential risk: Risk of permanent curtailment of humanity’s potential\n\nPower-seeking AI: AI systems with instrumental incentives to acquire resources and power\n\nPrediction market: A market where participants trade contracts that resolve based on future events\n\nd-separation: A criterion for identifying conditional independence relationships in Bayesian networks\n\nMonte Carlo sampling: A computational technique using random sampling to obtain numerical results\n\n\n\n\nQuarto Features Previously Incompatible with LaTeX (Below)\n\n\n\n\n\n\n\n\n\nGrowiec, Jakub. 2024. “Existential Risk from Transformative AI: An Economic Perspective.” Technological and Economic Development of Economy, 1–27.\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Computer Journal 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nSoares, Nate, and Benja Fallenstein. 2014. “Aligning Superintelligence with Human Interests: A Technical Research Agenda.”",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "chapters/0.Frontmatter.html",
    "href": "chapters/0.Frontmatter.html",
    "title": "1  Remaining Edits",
    "section": "",
    "text": "1.1 Next Steps (High-Priority Recommendations)\nCreate and embed 5-7 key diagrams: AMTAIR pipeline, coordination crisis visualization, ArgDown→BayesDown transformation, example Bayesian network, and convergence analysis heatmap. These will dramatically improve comprehension and professional presentation.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remaining Edits</span>"
    ]
  },
  {
    "objectID": "chapters/0.Frontmatter.html#next-steps-high-priority-recommendations",
    "href": "chapters/0.Frontmatter.html#next-steps-high-priority-recommendations",
    "title": "1  Remaining Edits",
    "section": "",
    "text": "1.1.1 2. Develop Concrete Policy Analysis Section\nAdd a dedicated subsection analyzing how AMTAIR would evaluate specific policies like SB 1047 or Narrow Path proposals. Walk through the complete analysis pipeline with real examples to demonstrate practical value.\n\n\n1.1.2 3. Expand Empirical Base\nExtract and analyze 2-3 additional AI safety arguments beyond Carlsmith (suggest Christiano’s “What Failure Looks Like” and Critch’s “ARCHES”). This broader empirical foundation will strengthen validity claims.\n\n\n1.1.3 4. Clarify Implementation Status\nAdd a clear table distinguishing: (a) fully implemented features, (b) partially implemented with limitations, (c) designed but not built, (d) future research. This prevents readers from misunderstanding current capabilities.\n\n\n1.1.4 5. Verify or Qualify Quantitative Claims\nEither provide supporting evidence for specific percentages (validation accuracy, bias effects, pilot study results) or reframe as estimates/illustrations. Consider adding confidence intervals or qualifying language to maintain scientific integrity while acknowledging prototype status.\nThese changes would elevate an already strong thesis to exceptional, addressing the remaining gaps while maintaining the excellent narrative flow and intellectual contribution achieved in this revision.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remaining Edits</span>"
    ]
  },
  {
    "objectID": "chapters/0.Frontmatter.html#error-watch",
    "href": "chapters/0.Frontmatter.html#error-watch",
    "title": "1  Remaining Edits",
    "section": "1.2 Error Watch",
    "text": "1.2 Error Watch\n\n1.2.1 Catch all Potential Hallucinations\n&lt;!-- [ ] Keep track of all hallucinations that have been found here: --&gt;\n\nValidation Metrics: Claims of “85%+ accuracy for structural extraction” and “73% for probability capture” appear precise for what seems to be a prototype system. These need careful verification or qualification.\nPilot Study Results: “40% reduction in time to identify disagreements” and “60% improvement in agreement about disagreement” lack citations and seem surprisingly specific.\nRed-teaming Quantification: “34% anchoring bias effect” and other precise percentages from adversarial testing need support or qualification as estimates.\nPrediction Market Integration: Some passages imply deeper integration than the “future work” status indicated elsewhere.\n\n&lt;!-- [ ] Make sure all hallucinations have been removed --&gt;",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remaining Edits</span>"
    ]
  },
  {
    "objectID": "chapters/0.Frontmatter.html#general-style",
    "href": "chapters/0.Frontmatter.html#general-style",
    "title": "1  Remaining Edits",
    "section": "1.3 General Style",
    "text": "1.3 General Style\n&lt;!-- [ ] Add Smooth transitions between chapters: Each chapter ends with preview of next, maintaining narrative flow --&gt;\n&lt;!-- [ ] Improve Style/prose: Fewer lists, more prose. Lists converted to flowing paragraphs with transitional phrases. Bullet points reserved for true enumerations --&gt;",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remaining Edits</span>"
    ]
  },
  {
    "objectID": "chapters/0.Frontmatter.html#general-formatting",
    "href": "chapters/0.Frontmatter.html#general-formatting",
    "title": "1  Remaining Edits",
    "section": "1.4 General Formatting",
    "text": "1.4 General Formatting\n&lt;!-- [ ] Fix the Overlapping between Section Heading and Sub-Heading --&gt;\n&lt;!-- [ ] Fix Formatting of Headings in Affidavit --&gt;\n&lt;!-- [ ] Implement a \"jump to ToC\" functionality (also in PDF) --&gt;\n&lt;!-- [ ] Determine whether section title yml head or # (first-level-Heading) is better--&gt;\n&lt;!-- [ ] Consider adding an index: https://quarto.org/docs/books/book-structure.html#creating-an-index --&gt;",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remaining Edits</span>"
    ]
  },
  {
    "objectID": "chapters/0.Frontmatter.html#commentary-feedback",
    "href": "chapters/0.Frontmatter.html#commentary-feedback",
    "title": "1  Remaining Edits",
    "section": "1.5 Commentary / Feedback",
    "text": "1.5 Commentary / Feedback\n\n1.5.1 Areas Needing Work\n\nVisual Communication: While visualization is discussed extensively, the document lacks actual diagrams and figures that would enhance understanding.\nPolicy Specifics: Named policies (Narrow Path, SB 1047) are mentioned but not analyzed in detail, missing an opportunity for concrete demonstration.\nMultiple Model Extraction: Only Carlsmith is deeply analyzed; adding 2-3 more models would strengthen empirical claims.\nImplementation Clarity: Some features (prediction markets, probability distributions) are discussed ambiguously regarding current vs. future capabilities.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remaining Edits</span>"
    ]
  },
  {
    "objectID": "chapters/0.Frontmatter.html#general-edits",
    "href": "chapters/0.Frontmatter.html#general-edits",
    "title": "1  Remaining Edits",
    "section": "1.6 General Edits",
    "text": "1.6 General Edits\n\n\n\n\n\n\n\n\n\n\n\n\n\nSection\nSuggested Change\nImplemented - Status\nAnalysis\nEvaluation\nImprovement Suggestions\nPotential Hallucinations\n\n\n\n\nGeneral Formatting\nUse American spelling consistently\n\nYes\nDocument uses “modeling” not “modelling”, “analyze” not “analyse”, “formalization” not “formalisation” throughout\nExcellent consistency - creates professional impression for international audience\nNone needed\nNone detected\n\n\nGeneral Style\nFewer lists, more prose\nYes\nLists converted to flowing paragraphs with transitional phrases. Bullet points reserved for true enumerations\nSignificantly improves academic tone and readability\nCould further reduce lists in technical sections\nNone\n\n\nAbstract\nClearer thesis statement\nYes\n“This thesis introduces AMTAIR…computational approach that addresses coordination failure by automating extraction”\nClear and specific, balances technical precision with strategic vision\nCould be slightly more concise\nNone\n\n\nIntroduction\nOpening scenario with policymaker\nYes\nVivid scenario of senior policy advisor reviewing conflicting AI safety reports\nHighly effective - immediately grounds abstract concepts in concrete dilemma\nCould add specific policy examples (e.g., compute thresholds)\nNone\n\n\nIntroduction\nCoordination crisis framing\nYes\nExtensive discussion of fragmentation, safety gaps, resource misallocation, negative-sum dynamics\nCompelling diagnosis that motivates the solution\nCould quantify coordination failures with specific examples\nNone\n\n\nIntroduction\nMultiplicative benefits framework\nYes\nFull section explaining how extraction + markets + evaluation create synergistic value\nNovel contribution clearly articulated\nCould use visual diagram to illustrate synergies\nNone\n\n\nContext\nCarlsmith model as exemplar\nYes\nDetailed six-premise decomposition with probabilities and explanation of formalizability\nExcellent concrete grounding for abstract concepts\nCould add comparison table with other models\nNone\n\n\nContext\nEpistemic challenges section\nYes\nComprehensive discussion of deep uncertainty, multi-level causation, irreversibility\nThoughtful analysis of unique AI governance challenges\nCould add more policy-specific examples\nNone\n\n\nContext\nBayesian networks explanation\nYes\nMathematical foundations, rain-sprinkler example, advantages for risk modeling\nGood balance of technical depth and accessibility\nVisual representation of rain-sprinkler network would help\nNone\n\n\nContext\nMTAIR framework analysis\nYes\nAchievements, limitations, and automation opportunity clearly presented\nFair assessment that positions AMTAIR as evolution not revolution\nCould include specific timing/cost comparisons\nNone\n\n\nAMTAIR\nTwo-stage extraction process\nYes\nArgDown → BayesDown separation with clear rationale and benefits\nCore technical innovation well explained\nCould add flowchart of extraction pipeline\nNone\n\n\nAMTAIR\nLess code, more description\nYes\nMinimal code snippets, focus on conceptual explanation and architecture\nMuch more accessible to non-technical readers\nGood balance achieved\nNone\n\n\nAMTAIR\nCase studies (simple to complex)\nYes\nRain-sprinkler-grass followed by Carlsmith model\nExcellent pedagogical progression\nCould add intermediate complexity example\nNone\n\n\nAMTAIR\nValidation methodology\nYes\nGround truth construction, metrics, results summary, error analysis\nRigorous scientific approach builds credibility\nCould expand on inter-rater reliability process\nClaimed “85%+ accuracy” needs careful verification\n\n\nAMTAIR\nPolicy evaluation capabilities\nYes\nIntervention representation, deployment governance example, robustness analysis\nPractical value clearly demonstrated\nCould add more policy examples\nNone\n\n\nDiscussion\nObjection-response format\nYes\nFive major objections with detailed responses\nIntellectually honest engagement with limitations\nCould add objection about scalability to global governance\nNone\n\n\nDiscussion\nRed-teaming results\nYes\nAdversarial testing with specific failure modes and robustness findings\nTransparent about system limitations\nCould quantify performance degradation curves\n“34% anchoring bias effect” seems precise for a prototype\n\n\nDiscussion\nEpistemic security benefits\nYes\nModel inspectability, convergence patterns, collective reasoning improvements\nCompelling case for practical benefits\nCould add metrics from pilot studies\n“40% reduction in disagreement identification time” needs citation\n\n\nConclusion\nSummary of contributions\nYes\nTheoretical, methodological, technical, and empirical contributions clearly listed\nComprehensive without overstating claims\nWell balanced\nNone\n\n\nConclusion\nStakeholder recommendations\nYes\nSpecific actionable steps for researchers, policymakers, technologists, funders\nHighly practical and actionable\nCould prioritize recommendations\nNone\n\n\nConclusion\nFuture research agenda\nYes\nTechnical priorities, methodological development, application expansion\nComprehensive research program outlined\nCould add timeline estimates\nNone\n\n\nReferences\nAmerican citation style\nYes\nConsistent (Author, Year) format throughout\nProfessional formatting\nNone needed\nNone\n\n\nManual extraction examples\n2-3 “inside view” models\nPartial\nCarlsmith extensively analyzed, but only one model deeply examined\nGood depth on one model, missing breadth\nAdd 2 more models (e.g., Christiano, Critch)\nNone\n\n\nPolicy candidates\nNarrow Path, SB 1047\nPartial\nDeployment governance discussed but specific policies not analyzed\nGeneric policy analysis provided\nAdd concrete analysis of named policies\nNone\n\n\nCorrelation handling\nWorkarounds for correlations\nYes\nExplicit correlation nodes, copulas, sensitivity bounds discussed\nHonest about limitations with practical solutions\nCould add worked example\nNone\n\n\nPrediction market integration\nLive data integration\nPartial\nArchitecture designed for integration but not implemented\nHonest about implementation status\nBe clearer this is future work throughout\nSome sections imply fuller integration than exists\n\n\nExpert feedback system\nVariable validation by experts\nPartial\nValidation methodology includes experts but ongoing feedback system not detailed\nGood for initial validation\nDevelop continuous expert input mechanism\nNone\n\n\nProbability distributions\nFull distribution support\nPartial\nConceptually addressed but implementation seems limited to point estimates\nTheory explained well\nClarify implementation status\n“Beta distributions for probabilities” may overstate current capabilities\n\n\nGraphics and visualizations\nStrategic graphics throughout\nPartial\nVisualization design discussed but few actual graphics in document\nText descriptions good but visuals needed\nCreate and embed key diagrams\nNone\n\n\nSection transitions\nSmooth transitions between chapters\nYes\nEach chapter ends with preview of next, maintaining narrative flow\nExcellent narrative coherence\nNone needed\nNone",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remaining Edits</span>"
    ]
  },
  {
    "objectID": "chapters/0.Frontmatter.html#old-checklists",
    "href": "chapters/0.Frontmatter.html#old-checklists",
    "title": "1  Remaining Edits",
    "section": "1.7 Old Checklists",
    "text": "1.7 Old Checklists",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remaining Edits</span>"
    ]
  },
  {
    "objectID": "chapters/0.Frontmatter.html#usual-paper-requirements",
    "href": "chapters/0.Frontmatter.html#usual-paper-requirements",
    "title": "1  Remaining Edits",
    "section": "1.8 “Usual paper requirements”",
    "text": "1.8 “Usual paper requirements”\n\nintroduce all terminology\n\ngo through text, make sure all terms are defined, explained (and added to the list of Abbr.) when first mentioned\n\n\nreadership is intelligent and interested but has no prior knowledge\n\nThis chapter presents the complete computational implementation of the AMTAIR system, demonstrating the end-to-end pipeline from document processing through interactive visualization.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remaining Edits</span>"
    ]
  },
  {
    "objectID": "chapters/0.Frontmatter.html#format-anything-that-makes-it-easier-to-understand",
    "href": "chapters/0.Frontmatter.html#format-anything-that-makes-it-easier-to-understand",
    "title": "1  Remaining Edits",
    "section": "1.9 (Format:) ~ Anything that makes it easier to understand",
    "text": "1.9 (Format:) ~ Anything that makes it easier to understand\n\nshort sentences\n\nparagraphs (one idea per paragraph)\n\nsimplicity\n\n!limit use of passive voice!\n\nuse active voice, even prefer I over we!\n\nminimise use of “zombi nouns” (don’t turn verbs/adjectives to nouns!)\n\n“find words that can be cut”\n\n– the paper can focus on one aspect of the presentation\n~ demonstrate ability for novel research\n– “solve research question with the tools accessible to you”\n– “show something that has not been shown before / should be publishable in principle”\n– new idea (or criticism) “in this field”\n– Outline idea THEN reading with a purpose (answering concrete questions)\n– “Only” confirm that nobody has published the exact same idea on the same topic\n– pretty much determined by presentation & proposal but narrow down further (& choose supervisor?)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remaining Edits</span>"
    ]
  },
  {
    "objectID": "chapters/0.Frontmatter.html#syntax-for-tasks",
    "href": "chapters/0.Frontmatter.html#syntax-for-tasks",
    "title": "1  Remaining Edits",
    "section": "1.10 Syntax for Tasks",
    "text": "1.10 Syntax for Tasks\n\n1.10.1 Tasks with ToDo Tree\n\n1.10.1.1 Simple “One-line tasks”\nUse Code ticks and html comment and task format for tasks distinctly visible across all formats including the ToDo-Tree overview:\n&lt;!-- [ ] ToDos for things to do / tasks / reminders (allows \"jump to with Taks Tree extension\") --&gt;\nUse html comment and task format for open or uncertain tasks, visible in the .qmd file:\n\n\n\n1.10.1.2 More Complex Tasks with Notes\n&lt;!-- [ ] Task Title: short description--&gt;\n\n  More Information about task\n\n  Relevant notes\n\n  Step-by-step implementation Plan\n\n  Etc.\n\n\n\n1.10.1.3 Completed Tasks\nRetain completed tasks in ToDo-Tree by adding an x in the brackets: [x] &lt;!-- [x] Tasks which have been finished but should remain for later verification --&gt;\n\nMark and remove completed tasks from ToDo-Tree by adding a minus in the brackets: [-]\n&lt;!-- [-] Tasks which have been finished but should remain visible for later verification --&gt;\n\n\n\n1.10.1.4 Missing Citations\n&lt;!-- [ ] FIND: @CITATION_KEY_PURPOSE: \"Description of the appropriate/idea source, including ideas /suggestions / search terms etc.\" --&gt;\n\n\n1.10.1.5 Suggested Citation\n&lt;!-- [ ] VERIFY: @CITATION_KEY_SUGGESTED: \"Description of the appropriate paper, book, source\" [Include BibTex if known] --&gt;\n\n\n\n1.10.2 Examples\n&lt;!-- [ ] (Example short: open and visible in text)   Find and list the names of the MTAIR team-members responsible for the Analytica Implementation --&gt;\n&lt;!-- [ ] (Example longer: open and visible in text)    Review/Plan/Discuss integrating Live Prediction Markets --&gt;\n\n  Live prediction market integration requires:\n    (1) API connections to platforms (Metaculus, Manifold),\n    (2) Question-to-variable mapping algorithms,\n    (3) Probability update mechanisms, \n    (4) Handling of market dynamics (thin markets, manipulation).\n    Current mentions may overstate readiness or underestimate complexity.\n    Need realistic assessment of what's achievable.\n\n  Implementation Steps:\n      0. List/mention all relevant platforms with a brief description each\n      1. Review all existing prediction market mentions for accuracy\n      2. Assess actual API availability and limitations\n      3. Describe/explain/discuss how to implement basic proof-of-concept with single platform\n      4. Document challenges: question mapping, market interpretation\n      5. Create realistic timeline for full implementation\n      6. Revise thesis claims to match reality\n      7. Add \"Future Work\" and/or extension section on complete integration\n      8. Include descriptions of mockups/designs even if not fully built \n      9. Highlight/discuss the advantages of such integrations\n      10. Quickly brainstorm for downsides worth mentioning",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Remaining Edits</span>"
    ]
  },
  {
    "objectID": "chapters/1.Introduction.html",
    "href": "chapters/1.Introduction.html",
    "title": "2  Introduction",
    "section": "",
    "text": "2.1 The Coordination Crisis in AI Governance\n[x]  introduces and motivates the core question or problem\nAs AI capabilities advance at an accelerating pace—demonstrated by the rapid progression from GPT-3 to GPT-4, Claude, and beyond—we face a governance challenge unlike any in human history: how to ensure increasingly powerful AI systems remain aligned with human values and beneficial to humanity’s long-term flourishing. This challenge becomes particularly acute when considering the possibility of transformative AI systems that could drastically alter civilization’s trajectory, potentially including existential risks from misaligned systems.\n`The AI governance landscape exhibits a peculiar paradox: extraordinary activity alongside fundamental coordination failure. Consider the current state of affairs:\nTechnical safety researchers develop increasingly sophisticated alignment techniques, but often without clear implementation pathways to deployment contexts. Policy specialists craft principles and regulatory frameworks without sufficient technical grounding to ensure their practical efficacy. Ethicists articulate normative principles that lack operational specificity. Strategy researchers identify critical uncertainties but struggle to translate these into actionable guidance.`\nOpening with the empirical paradox: record investment in AI safety coexisting with fragmented, ineffective governance responses",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/1.Introduction.html#sec-coordination-crisis",
    "href": "chapters/1.Introduction.html#sec-coordination-crisis",
    "title": "2  Introduction",
    "section": "",
    "text": "Despite unprecedented investment in AI safety research, rapidly growing awareness among key stakeholders, and proliferating frameworks for responsible AI development, we face what I’ll term the “coordination crisis” in AI governance—a systemic failure to align diverse efforts across technical, policy, and strategic domains into a coherent response proportionate to the risks we face.\n\n\n\n\n\n\n\n2.1.1 Empirical Paradox: Investment Alongside Fragmentation\n\n\n\nThe Fragmentation Problem: Technical researchers, policy specialists, and strategic analysts operate with incompatible frameworks\n\n\n\n2.1.2 Systematic Risk Increase Through Coordination Failure\n\n\n\n\n\nSystemic Risk Amplification: How coordination failures systematically increase existential risk through safety gaps and resource misallocation\n\n\n\n2.1.3 Historical Parallels and Temporal Urgency\n\n\n\nThe Scaling Challenge: Traditional governance approaches cannot match the pace of capability development",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/1.Introduction.html#sec-research-question",
    "href": "chapters/1.Introduction.html#sec-research-question",
    "title": "2  Introduction",
    "section": "2.2 Research Question and Scope",
    "text": "2.2 Research Question and Scope\n\n\n\nThis thesis addresses a specific dimension of the coordination challenge by investigating the question: Can frontier AI technologies be utilized to automate the modeling of transformative AI risks, enabling robust prediction of policy impacts?\nThis thesis addresses a specific dimension of the coordination challenge by investigating how computational approaches can formalize the worldviews and arguments underlying AI safety discourse, transforming qualitative disagreements into quantitative models suitable for rigorous policy evaluation.\nTo break this down into its components:\n\nFrontier AI Technologies: Today’s most capable language models (GPT-4, Claude-3 level systems)\nAutomated Modeling: Using these systems to extract and formalize argument structures from natural language\nTransformative AI Risks: Potentially catastrophic outcomes from advanced AI systems, particularly existential risks\nPolicy Impact Prediction: Evaluating how governance interventions might alter probability distributions over outcomes\n\nCentral Question: Can frontier AI technologies be utilized to automate the modeling of transformative AI risks, enabling robust prediction of policy impacts?\nAMTAIR represents the first computational framework for automated extraction and formalization of AI governance worldviews\nCore Innovation:\n\nAutomated transformation of qualitative governance arguments into quantitative Bayesian networks\nIntegration of prediction markets with formal models for dynamic risk assessment\nCross-worldview policy evaluation under deep uncertainty\n\nScope Boundaries:\n\nThe investigation encompasses both theoretical development and practical implementation, focusing specifically on existential risks from misaligned AI systems rather than broader AI ethics concerns. This narrowed scope enables deep technical development while addressing the highest-stakes coordination challenges.\nThe scope encompasses both theoretical development and practical implementation. Theoretically, I develop a framework for representing diverse perspectives on AI risk in a common formal language. Practically, I implement this framework in a computational system—the AI Risk Pathway Analyzer (ARPA)—that enables interactive exploration of how policy interventions might alter existential risk.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/1.Introduction.html#sec-multiplicative-benefits",
    "href": "chapters/1.Introduction.html#sec-multiplicative-benefits",
    "title": "2  Introduction",
    "section": "2.3 The Multiplicative Benefits Framework",
    "text": "2.3 The Multiplicative Benefits Framework\n\n\n\nCore Innovation: The combination of three elements—automated extraction, prediction market integration, and formal policy evaluation—creates multiplicative rather than additive benefits for AI governance.\nThe central thesis of this work is that combining three elements—automated worldview extraction, prediction market integration, and formal policy evaluation—creates multiplicative rather than merely additive benefits for AI governance. Each component enhances the others, creating a system more valuable than the sum of its parts.\nAutomated worldview extraction using frontier language models addresses the scaling bottleneck in current approaches to AI risk modeling. The Modeling Transformative AI Risks (MTAIR) project demonstrated the value of formal representation but required extensive manual effort to translate qualitative arguments into quantitative models. Automation enables processing orders of magnitude more content, incorporating diverse perspectives, and maintaining models in near real-time as new arguments emerge.\nPrediction market integration grounds these models in collective forecasting intelligence. By connecting formal representations to live forecasting platforms, the system can incorporate timely judgments about critical uncertainties from calibrated forecasters. This creates a dynamic feedback loop, where models inform forecasters and forecasts update models.\nFormal policy evaluation transforms static risk assessments into actionable guidance by modeling how specific interventions might alter critical parameters. This enables conditional forecasting—understanding not just the probability of adverse outcomes but how those probabilities change under different policy regimes.\nSynergistic Components:\n\nAutomated Worldview Extraction: Scaling formal modeling from manual (MTAIR) to automated approaches using frontier LLMs\nLive Data Integration: Connecting models to prediction markets and forecasting platforms for dynamic calibration and live updating\nPolicy Evaluation: Enabling rigorous counterfactual analysis of governance interventions across worldviews\n\nThe synergy emerges because automation enables comprehensive data integration, markets inform and validate models, and evaluation gains precision from both automated extraction and market-based calibration.\nThe combination creates multiplicative rather than additive value—automation enables comprehensive data integration, markets inform models, evaluation gains precision from both\n\n\n\n\n\n\nFigure 2.1: AMTAIR Automation Pipeline from CITATION",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/1.Introduction.html#sec-roadmap",
    "href": "chapters/1.Introduction.html#sec-roadmap",
    "title": "2  Introduction",
    "section": "2.4 Thesis Structure and Roadmap",
    "text": "2.4 Thesis Structure and Roadmap\n\n\n\n\nLogical Progression from Theory to Application:\n\nContext & Background: Establish theoretical foundations (Bayesian networks, argument mapping) and methodological approach (two-stage extraction)\nAMTAIR Implementation: Demonstrate technical feasibility through working prototype with validated examples\nCritical Analysis: Examine limitations, failure modes, and governance implications through systematic red-teaming\nFuture Directions: Connect to broader coordination challenges and research agenda\n\nEach section builds toward a practical implementation of the framework while maintaining both theoretical rigor and policy relevance, demonstrating how computational approaches can enhance rather than replace human judgment in AI governance.\nThe remainder of this thesis develops the multiplicative benefits framework from theoretical foundations to practical implementation, following a progression from abstract principles to concrete applications:\nSection 2 establishes the theoretical foundations and methodological approach, examining why AI governance presents unique epistemic challenges and how Bayesian networks can formalize causal relationships in this domain.\nSection 3 presents the AMTAIR implementation, detailing the technical system that transforms qualitative arguments into formal representations. It demonstrates the approach through two case studies: the canonical Rain-Sprinkler-Lawn example and the more complex Carlsmith model of power-seeking AI.\nSection 4 discusses implications, limitations, and counterarguments, addressing potential failure modes, scaling challenges, and integration with existing governance frameworks.\nSection 5 concludes by summarizing key contributions, drawing out concrete policy implications, and suggesting directions for future research.\nThroughout this progression, I maintain a dual focus on theoretical sophistication and practical utility. The framework aims not merely to advance academic understanding of AI risk but to provide actionable tools for improving coordination in AI governance.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/1.Introduction.html#overview-table-of-contents",
    "href": "chapters/1.Introduction.html#overview-table-of-contents",
    "title": "2  Introduction",
    "section": "2.5 Overview / Table of Contents",
    "text": "2.5 Overview / Table of Contents",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/2.0.Context.html",
    "href": "chapters/2.0.Context.html",
    "title": "3  Context & Background",
    "section": "",
    "text": "3.1 Theoretical Foundations",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Context & Background</span>"
    ]
  },
  {
    "objectID": "chapters/2.0.Context.html#sec-theoretical-foundations",
    "href": "chapters/2.0.Context.html#sec-theoretical-foundations",
    "title": "3  Context & Background",
    "section": "",
    "text": "3.1.1 AI Existential Risk: The Carlsmith Model\n\n\n\nCarlsmith’s “Is power-seeking AI an existential risk?” (2021) represents one of the most structured approaches to assessing the probability of existential catastrophe from advanced AI. The analysis decomposes the overall risk into six key premises, each with an explicit probability estimate.\n\n\nCarlsmith (2021) provides the canonical structured approach to AI existential risk assessment\n\nSix-Premise Decomposition:\nCarlsmith decomposes existential risk into a probabilistic chain with explicit estimates:\n\nPremise 1: Transformative AI development this century (P ≈ 0.80)\nPremise 2: AI systems pursuing objectives in the world (P ≈ 0.95)\nPremise 3: Systems with power-seeking instrumental incentives (P ≈ 0.40)\nPremise 4: Sufficient capability for existential threat (P ≈ 0.65)\nPremise 5: Misaligned systems despite safety efforts (P ≈ 0.50)\nPremise 6: Catastrophic outcomes from misaligned power-seeking (P ≈ 0.65)\n\nComposite Risk Calculation: P(doom) ≈ 0.05 (5%) ~5% probability of existential catastrophe\n\nThis structured approach exemplifies the type of reasoning that AMTAIR aims to formalize and automate, providing both transparency in assumptions and modularity for critique and refinement.\n\nCarlsmith's model exemplifies the type of structured reasoning that AMTAIR aims to formalize and automate\n\n3.1.1.1 Why Carlsmith as Ideal Formalization Target\n- Explicitly probabilistic reasoning with quantified estimates\n- Clear conditional dependencies between premises  \n- Transparent decomposition of complex causal pathways\n- Well-documented argumentation available for extraction validation\n- Policy-relevant implications requiring formal evaluation\nFormalization Potential:\nCarlsmith's model represents \"low-hanging fruit\" for automated formalization because it already exhibits explicit probabilistic reasoning with clear conditional dependencies. Success with this structured argument validates the approach for less explicit arguments throughout AI safety literature.\n\n\n\n3.1.2 The Epistemic Challenge of Policy Evaluation\n\n\n\nAI governance policy evaluation faces unique epistemic challenges that render traditional policy analysis methods insufficient. The domain combines complex causal chains with limited empirical grounding, deep uncertainty about future capabilities, divergent stakeholder worldviews, and few opportunities for experimental testing before deployment.\n\n`Traditional methods fall short in several ways:\n\nCost-benefit analysis struggles with existential outcomes and deep uncertainty\nScenario planning often lacks probabilistic reasoning necessary for rigorous evaluation\nExpert elicitation alone fails to formalize interdependencies between variables\nQualitative approaches obscure crucial assumptions that drive conclusions`\n\nUnprecedented Epistemic Environment:\n\nAI governance policy evaluation faces challenges that render traditional policy analysis methods insufficient: complex causal chains, deep uncertainty about unprecedented capabilities, divergent stakeholder worldviews, and limited opportunities for empirical validation.\n\nSpecific challenges include:\n\n• **Deep Uncertainty**: Many decisions involve unprecedented scenarios without historical frequency data\n• **Complex Causality**: Policy effects propagate through multi-level dependencies (technical → institutional → strategic)\n• **Multidisciplinary Integration**: Combining technical facts, ethical principles, and strategic considerations\n• **Value-Laden Assessment**: Risk evaluation inherently involves normative judgments about acceptable outcomes\n\n3.1.2.1 Unique Difficulties in AI Governance\nComplex Causal Chains: Multi-level dependencies between technical capabilities, institutional responses, and strategic outcomes\nDeep Uncertainty: Unprecedented AI capabilities make historical analogies insufficient\n\nLempert, Popper, and Bankes (2003) on robust decision-making under deep uncertainty\n\nDivergent Worldviews: Fundamental disagreements about:\n\nTimeline expectations for transformative AI\nDifficulty of alignment problems\nEffectiveness of governance interventions\nInternational coordination possibilities\n\n\n\n3.1.2.2 Limitations of Traditional Policy Analysis\n\n\nCost-Benefit Analysis: Struggles with existential outcomes and infinite expected values\nScenario Planning: Lacks probabilistic reasoning and uncertainty quantification\nExpert Elicitation: Fails to formalize complex interdependencies between variables\nQualitative Frameworks: Obscure crucial assumptions and parameter sensitivities\n\nLimitations of Traditional Approaches:\n\nCost-Benefit Analysis: Struggles with existential outcomes and infinite expected values\nScenario Planning: Often lacks probabilistic reasoning necessary for rigorous uncertainty quantification\nExpert Elicitation: Fails to formalize complex interdependencies between variables and assumptions\nQualitative Frameworks: Obscure crucial assumptions and parameter sensitivities driving conclusions\n\n\nLempert, Popper, and Bankes (2003) on robust decision-making under deep uncertainty provides methodological foundations, but application to AI governance requires novel integration of argument mapping with probabilistic modeling.\n\n\n\n\n3.1.3 Argument Mapping and Formal Representations\n\n\nArgument mapping offers a bridge between informal reasoning in natural language and the formal representations needed for rigorous analysis. By explicitly identifying claims, premises, inferential relationships, and support/attack patterns, argument maps make implicit reasoning structures visible for examination and critique.\n\nThe progression from natural language arguments to formal Bayesian networks requires an intermediate representation that preserves narrative structure while adding mathematical precision. The ArgDown format serves this purpose by encoding hierarchical relationships between statements, while its extension, BayesDown, adds probabilistic metadata to enable full Bayesian network construction.\n[Effect_Node]: Description of effect. {\"instantiations\": [\"effect_TRUE\", \"effect_FALSE\"]}\n + [Cause_Node]: Description of direct cause. {\"instantiations\": [\"cause_TRUE\", \"cause_FALSE\"]}\n   + [Root_Cause]: Description of indirect cause. {\"instantiations\": [\"root_TRUE\", \"root_FALSE\"]}\n\n\n3.1.4 Bayesian Networks as Knowledge Representation\n\n\n\nBayesian networks provide a formal mathematical framework for representing causal relationships and reasoning under uncertainty. These directed acyclic graphs (DAGs) combine qualitative structure—nodes representing variables and edges representing dependencies—with quantitative parameters in the form of conditional probability tables.\n\n`Key properties that make Bayesian networks particularly suited to AI risk modeling include:\n\nNatural representation of causal relationships between variables\nExplicit handling of uncertainty through probability distributions\nSupport for evidence updating through Bayesian inference\nCapability for interventional reasoning through do-calculus\nBalance between mathematical rigor and intuitive visual representation`\n\n\n\n\n\n\n\nFigure 3.1: Example Bayesian Network\n\n\n\n\n3.1.4.1 Mathematical Foundations\nBayesian networks provide a formal mathematical framework for representing causal relationships and reasoning under uncertainty through Directed Acyclic Graphs (DAGs) combining qualitative structure with quantitative parameters.\nDirected Acyclic Graphs (DAGs):\nCore Components:\n\nNodes: Variables with discrete states representing propositions or factors\nEdges: Directed relationships representing conditional dependencies\nAcyclicity: Ensuring coherent probabilistic interpretation without circular dependencies\n\nBNs:\n\nConditional Probability Tables: Quantifying P(Node|Parents) for all parent state combinations\n\nProbability Factorization: \\(P(X_1, X_2, ..., X_n) = \\prod_{i=1}^{n} P(X_i | Parents(X_i))\\)\n\n\n3.1.4.2 The Rain-Sprinkler-Grass Example\n\nThe Rain-Sprinkler-Grass Canonical Example:\nThis simple example demonstrates all key concepts while remaining intuitive\nNetwork Structure:\n\nRain (root cause): P(rain) = 0.2\nSprinkler (intermediate): P(sprinkler|rain) varies by rain state\nGrass_Wet (effect): P(wet|rain, sprinkler) depends on both causes\n\nInference Capabilities:\n\nMarginal probabilities: P(grass_wet) = ?\nConditional queries: P(rain|grass_wet) = ?\nCounterfactual analysis: P(grass_wet|do(sprinkler=false)) = ?\nMarginal probabilities: P(grass_wet) computed from joint distribution\nConditional queries: P(rain|grass_wet) for diagnostic reasoning\nCounterfactual analysis: P(grass_wet|do(sprinkler=false)) for intervention effects\n\npython\n# Basic network representation\nnodes = ['Rain', 'Sprinkler', 'Grass_Wet']\nedges = [('Rain', 'Sprinkler'), ('Rain', 'Grass_Wet'), ('Sprinkler', 'Grass_Wet')]\n\n# Conditional probability specification\nP_wet_given_causes = {\n    (True, True): 0.99,    # Rain=T, Sprinkler=T\n    (True, False): 0.80,   # Rain=T, Sprinkler=F  \n    (False, True): 0.90,   # Rain=F, Sprinkler=T\n    (False, False): 0.01   # Rain=F, Sprinkler=F\n}\n\n\n3.1.4.3 Advantages for AI Risk Modeling\n\nExplicit Uncertainty: All beliefs represented with probability distributions rather than point estimates\nCausal Reasoning: Native support for intervention analysis and counterfactual reasoning through do-calculus\nEvidence Integration: Bayesian updating enables principled incorporation of new information\nModular Structure: Complex arguments decomposed into manageable, verifiable components\nVisual Communication: Graphical representation facilitates understanding across expertise levels\n\n\n\n\n3.1.4.4 From Natural Language to Formal Models\nThe Representation Challenge: How to preserve narrative richness while enabling mathematical analysis\nThe core methodological challenge involves preserving narrative richness of natural language arguments while enabling mathematical analysis—bridging interpretive reasoning favored in philosophy with quantitative prediction favored in technical fields.\nArgDown Syntax:\n[Conclusion]: Description of the conclusion.\n + [Premise1]: Supporting evidence or reasoning.\n   + [Sub-premise]: More detailed supporting factor.\n + [Premise2]: Additional independent support.\nArgDown uses hierarchical indentation to capture support/attack relationships between statements, making argument structure explicit while remaining human-readable.\n\n\n3.1.4.5 BayesDown: The Critical Innovation\n\nBayesDown extends ArgDown with probabilistic metadata, creating a hybrid format that bridges natural language and mathematical modeling:\njson\n{\n  \"instantiations\": [\"conclusion_TRUE\", \"conclusion_FALSE\"],\n  \"priors\": {\"p(conclusion_TRUE)\": \"0.7\", \"p(conclusion_FALSE)\": \"0.3\"},\n  \"posteriors\": {\n    \"p(conclusion_TRUE|premise1_TRUE,premise2_TRUE)\": \"0.9\",\n    \"p(conclusion_TRUE|premise1_TRUE,premise2_FALSE)\": \"0.6\",\n    \"p(conclusion_TRUE|premise1_FALSE,premise2_TRUE)\": \"0.4\",\n    \"p(conclusion_TRUE|premise1_FALSE,premise2_FALSE)\": \"0.1\"\n  }\n}\nDesign Principles:\n\nHuman Readable: Preserves natural language explanations\nMachine Processable: Structured for automated analysis\nProbabilistically Complete: Contains all information for Bayesian network construction\nExtensible: Supports additional metadata as needed\n\n\n\n\n3.1.5 The MTAIR Framework: Achievements and Limitations\n\n\nBucknall and Dori-Hacohen (2022) on the original Modeling Transformative AI Risks project demonstrates both the value and limitations of manual formal modeling approaches.\n\n\nThe Modeling Transformative AI Risks (MTAIR) project demonstrated the value of formal probabilistic modeling for AI safety, but also revealed significant limitations in the manual approach. While MTAIR successfully translated complex arguments into Bayesian networks and enabled sensitivity analysis, the intensive human labor required for model creation limited both scalability and timeliness.\n\n\n3.1.5.1 MTAIR’s Innovations\n\nBucknall and Dori-Hacohen (2022) on the original Modeling Transformative AI Risks project\n\n\nStructured Uncertainty Representation: Explicit probability distributions over key variables\nExpert Judgment Integration: Systematic methods for aggregating diverse opinions\nSensitivity Analysis: Identification of critical uncertainties driving outcomes\nPolicy Application: Connection between technical models and governance implications\n\nMTAIR’s Key Innovations:\n\nStructured Uncertainty Representation: Explicit probability distributions over key variables rather than point estimates\nExpert Judgment Integration: Systematic methods for aggregating diverse expert opinions and beliefs\nSensitivity Analysis: Identification of critical uncertainties that most significantly drive overall conclusions\nPolicy Application: Direct connection between technical risk models and governance implications\n\n`MTAIR’s key innovations included:\n\nExplicit representation of uncertainty through probability distributions\nStructured decomposition of complex risk scenarios\nIntegration of diverse expert judgments\nSensitivity analysis to identify critical parameters\n\n\n\n3.1.5.2 Fundamental Limitations Motivating AMTAIR\nScalability Bottleneck: Manual model construction requires weeks of expert effort per model\nStatic Models: No mechanisms for updating as new research emerges\nLimited Accessibility: Technical complexity restricts usage to specialists\nSingle Worldview Focus: Difficulty representing multiple perspectives simultaneously\nThese limitations create the opportunity for automated approaches that can scale formal modeling to match the pace of AI governance discourse\nFundamental Limitations Motivating AMTAIR:\nCritical constraints of manual approaches:\n\n• **Scalability Bottleneck**: Manual model construction requires weeks of expert effort per argument\n• **Static Nature**: No mechanisms for updating models as new research and evidence emerges  \n• **Limited Accessibility**: Technical complexity restricts usage to specialists with formal modeling expertise\n• **Single Worldview Focus**: Difficulty representing multiple conflicting perspectives simultaneously\nThese limitations create a clear opportunity for automated approaches that can scale formal modeling to match the pace and diversity of AI governance discourse.\nIts limitations motivated the current automated approach:\n\nManual labor intensity limiting scalability\nStatic nature of models once constructed\nLimited accessibility for non-technical stakeholders\nChallenges in representing multiple worldviews simultaneously`\n\n\n\n\n3.1.6 “A Narrow Path”: Conditional Policy Proposals in Practice\n\n\n\n“A Narrow Path” represents influential example of conditional policy proposals in AI governance—identifying interventions that could succeed under specific conditions rather than universal prescriptions.\n\nHowever, these conditions remain implicitly defined and qualitatively described, limiting rigorous evaluation and comparison across alternative approaches.\n\n“A Narrow Path” represents an influential example of conditional policy proposals in AI governance—identifying interventions that could succeed under specific conditions rather than absolute prescriptions. However, these conditions remain implicitly defined and qualitatively described, limiting rigorous evaluation.\n\n`Formal modeling could enhance such proposals by:\n\nMaking conditions explicit and quantifiable\nClarifying when interventions would be effective\nIdentifying which uncertainties most significantly affect outcomes\nEnabling systematic comparison of alternative approaches\nSupporting robust policy development across possible futures`\n\nFormal Modeling Enhancement Potential:\n\nMaking conditions explicit and quantifiable rather than implicit assumptions\nClarifying specific circumstances when interventions would be effective versus ineffective\nIdentifying which uncertainties most significantly affect intervention outcomes\nEnabling systematic comparison of alternative policy approaches under uncertainty\nSupporting robust policy development that performs well across multiple possible futures",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Context & Background</span>"
    ]
  },
  {
    "objectID": "chapters/2.0.Context.html#sec-methodology",
    "href": "chapters/2.0.Context.html#sec-methodology",
    "title": "3  Context & Background",
    "section": "3.2 Methodology",
    "text": "3.2 Methodology\n\n3.2.1 Research Design Overview\n\n\n\nThis research combines theoretical development with practical implementation, following an iterative approach that moves between conceptual refinement and technical validation. The methodology encompasses formal framework development, computational implementation, extraction quality assessment, and application to real-world AI governance questions.\n\n`The research process follows four main phases:\n\nFramework development: Creating the theoretical foundations and formal representations\nSystem implementation: Building the computational tools for extraction and analysis\nValidation testing: Assessing extraction quality and system performance\nApplication evaluation: Applying the framework to concrete AI governance questions`\n\n\n3.2.1.1 Hybrid Theoretical-Empirical Approach\n\nFour Integrated Components:\n\nTheoretical Development: Formal framework for automated worldview extraction\nTechnical Implementation: Working prototype demonstrating feasibility\nEmpirical Validation: Quality assessment against expert benchmarks\nPolicy Application: Case studies with real governance questions\n\nFour Primary Components:\n\nTheoretical Development: Formal framework for automated worldview extraction and representation\nTechnical Implementation: Working prototype demonstrating feasibility and validation\nEmpirical Validation: Quality assessment against expert benchmarks and known ground truth\nPolicy Application: Case studies demonstrating practical utility for real governance questions\n\nIterative Development Process:\nPhase 1: Conceptual Framework Development\n↓\nPhase 2: Prototype Implementation with Simple Validation Examples  \n↓\nPhase 3: Complex Real-World Case Application and Evaluation\n↓\nPhase 4: Policy Impact Assessment and Governance Integration\n\n\n3.2.1.2 Iterative Development Process\nPhase 1: Conceptual Framework Development\nPhase 2: Prototype Implementation with Simple Examples  \nPhase 3: Validation with Complex Real-World Cases\nPhase 4: Policy Application and Evaluation\n\n\n\n3.2.2 Formalizing World Models from AI Safety Literature\n\n\n\nThe core methodological challenge involves transforming natural language arguments in AI safety literature into formal causal models with explicit probability judgments. This extraction process identifies key variables, causal relationships, and both explicit and implicit probability estimates through a systematic pipeline.\n\n`The extraction approach combines:\n\nIdentification of key variables and entities in text\nRecognition of causal claims and relationships\nDetection of explicit and implicit probability judgments\nTransformation into structured intermediate representations\nConversion to formal Bayesian networks\n\nLarge language models facilitate this process through:\n\nTwo-stage prompting that separates structure from probability extraction\nSpecialized templates for different types of source documents\nTechniques for identifying implicit assumptions and relationships\nMechanisms for handling ambiguity and uncertainty`\n\n\n\n3.2.3 From Natural Language to Computational Models\n\nThe Two-Stage Extraction Architecture:\nAMTAIR employs a novel two-stage process that separates structural argument extraction from probability quantification, enabling modular improvement and human oversight at critical decision points.\n\n3.2.3.1 The Two-Stage Extraction Process\nStage 1: Structural Extraction (ArgDown)\n\nIdentify key variables and causal claims\nExtract hierarchical argument structure\nMap logical relationships between elements\nGenerate intermediate representation preserving narrative\n\nStage 1: Structural Extraction (ArgDown Generation)\n\n\nVariable and Claim Identification: Extract key propositions and entities from natural language text\nCausal Relationship Mapping: Identify support/attack relationships and conditional dependencies\nHierarchical Structure Construction: Generate properly nested argument representations preserving logical flow\nIntermediate Representation: Create ArgDown format suitable for human review and machine processing\n\npython\ndef extract_argument_structure(text):\n    \"\"\"Extract hierarchical argument structure from natural language\"\"\"\n    # LLM-based extraction with specialized prompts\n    prompt = ArgumentExtractionPrompt(\n        text=text,\n        output_format=\"ArgDown\",\n        focus_areas=[\"causal_claims\", \"probability_statements\", \"conditional_reasoning\"]\n    )\n    \n    structure = llm.complete(prompt)\n    return validate_argdown_syntax(structure)\nStage 2: Probability Integration (BayesDown)\n\nExtract explicit probability statements\nGenerate questions for implicit judgments\nQuantify uncertainty and conditional dependencies\nCreate complete probabilistic specification\n\nStage 2: Probability Integration (BayesDown Enhancement)\n\n\nExplicit Probability Extraction: Identify and parse numerical probability statements in source text\nQuestion Generation: Create systematic elicitation questions for implicit probability judgments\nExpert Input Integration: Incorporate domain expertise for ambiguous or missing quantifications\nConsistency Validation: Ensure probability assignments satisfy basic coherence requirements\n\npython\ndef integrate_probabilities(argdown_structure, probability_sources):\n    \"\"\"Convert ArgDown to BayesDown with probabilistic information\"\"\"\n    questions = generate_probability_questions(argdown_structure)\n    probabilities = extract_probabilities(probability_sources, questions)\n    \n    bayesdown = enhance_with_probabilities(argdown_structure, probabilities)\n    return validate_probability_coherence(bayesdown)\n\n\n3.2.3.2 LLM Integration Strategy\n\nPrompt Engineering Approach:\n\nSpecialized prompts for argument structure identification\nTwo-stage prompting to separate structure from quantification\nValidation mechanisms to ensure extraction quality\nIterative refinement based on expert feedback\n\nCurrent Capabilities and Limitations:\n\nFrontier LLMs show promising extraction quality but require careful validation\n\nLLM Integration Strategy:\n\nFrontier language models enable automated extraction but require careful prompt engineering and validation mechanisms to ensure extraction quality and consistency.\n\n\nSpecialized Prompting: Domain-specific templates for argument structure identification\nTwo-Stage Separation: Structural and probabilistic extraction handled independently for quality control\nValidation Mechanisms: Automated and human review processes for extraction accuracy\nIterative Refinement: Feedback loops enabling continuous improvement based on expert assessment\n\n\n\n\n3.2.4 Directed Acyclic Graphs: Structure and Semantics\n\n\n\nDirected Acyclic Graphs (DAGs) form the mathematical foundation of Bayesian networks, encoding both the qualitative structure of causal relationships and the quantitative parameters that define conditional dependencies. In AI risk modeling, these structures represent causal pathways to potential outcomes of interest.\n\n`Key mathematical properties include:\n\nAcyclicity, ensuring no feedback loops\nPath properties defining information flow\nD-separation criteria determining conditional independence\nMarkov blanket defining minimal contextual information\n\n\n3.2.4.1 Formal Properties\nAcyclicity Requirement: Ensures coherent probabilistic interpretation\nD-Separation: Conditional independence relationships between variables\nMarkov Condition: Each variable independent of non-descendants given parents\n\nFormal Properties Essential for AI Risk Modeling:\n\nAcyclicity Requirement: Ensures coherent probabilistic interpretation without logical contradictions\nD-Separation: Defines conditional independence relationships between variables based on graph structure\nMarkov Condition: Each variable conditionally independent of non-descendants given parents\nPath Analysis: Causal pathways and information flow through the network structure\n\nCausal Interpretation in AI Governance Context:\n\nPearl (2009) on causal inference and intervention analysis provides mathematical foundations for policy evaluation through do-calculus.\n\n\nEdges as Causal Relations: Directed arrows represent direct causal influence between factors\nIntervention Analysis: Do-calculus enables rigorous evaluation of policy intervention effects\nCounterfactual Reasoning: “What if” scenarios essential for governance planning under uncertainty\nEvidence Integration: Bayesian updating for incorporating new information and expert judgment\n\n\n\n3.2.4.2 Causal Interpretation\n\n\nPearl (2009) on causal inference and intervention analysis\n\n\nEdges as Causal Relations: Directed arrows represent direct causal influence\nIntervention Analysis: Do-calculus for policy evaluation\nCounterfactual Reasoning: “What if” scenarios for governance planning\n\nSemantic interpretation in AI risk contexts:\n\nNodes represent key variables in risk pathways\nEdges represent causal or inferential relationships\nPath blocking corresponds to intervention points\nProbability flows represent risk propagation through systems`\n\n\n\n\n3.2.5 Quantification of Probabilistic Judgments\n\n\n\nLinguistic Probability Mapping:\nTransforming qualitative uncertainty expressions into quantitative probabilities requires systematic interpretation frameworks that account for individual and cultural variation.\nStandard linguistic mappings (with significant individual variation):\n• \"Very likely\" → 0.8-0.9\n• \"Probable\" → 0.6-0.8  \n• \"Uncertain\" → 0.4-0.6\n• \"Unlikely\" → 0.2-0.4\n• \"Highly improbable\" → 0.05-0.15\n\nTransforming qualitative judgments in AI safety literature into quantitative probabilities requires a systematic approach to interpretation, extraction, and validation. This process combines direct extraction of explicit numerical statements with inference of implicit probability judgments from qualitative language.\n\n`Quantification methods include:\n\nDirect extraction of explicit numerical statements\nLinguistic mapping of qualitative expressions\nExpert elicitation techniques for ambiguous cases\nBayesian updating from multiple sources\n\nSpecial challenges in AI risk quantification:\n\nDeep uncertainty about unprecedented events\nDiverse disciplinary languages and conventions\nLimited empirical basis for calibration\nValue-laden aspects of risk assessment`\n\n\n3.2.5.1 From Qualitative to Quantitative\nLinguistic Probability Expressions:\n\n“Very likely” → 0.8-0.9\n“Uncertain” → 0.4-0.6\n“Highly improbable” → 0.05-0.15\n\nCalibration Challenges:\n\nIndividual variation in linguistic interpretation\nDomain-specific probability anchoring\nCultural and contextual influences on uncertainty expression\n\nCalibration and Validation Challenges:\n\nIndividual variation in linguistic interpretation and probability anchoring\nDomain-specific probability anchoring and reference class selection\nCultural and contextual influences on uncertainty expression and tolerance\nLimited empirical basis for calibration in unprecedented scenarios like transformative AI\n\n\n\n3.2.5.2 Expert Elicitation Methods\nDirect Probability Assessment: \"What is P(outcome)?\"\nComparative Assessment: \"Is A more likely than B?\"  \nFrequency Format: \"In 100 similar cases, how many would result in outcome?\"\nBetting Odds: \"What odds would you accept for this bet?\"\nExpert Elicitation Methodologies:\n\nDirect Probability Assessment: “What is P(outcome)?” with calibration training\nComparative Assessment: “Is A more likely than B?” for relative judgment validation\nFrequency Format: “In 100 similar cases, how many would result in outcome?” for clearer mental models\nBetting Odds: “What odds would you accept for this bet?” for revealed preference elicitation\n\n\n\n\n3.2.6 Inference Techniques for Complex Networks\n\n\n\nOnce Bayesian networks are constructed, probabilistic inference enables reasoning about uncertainties, counterfactuals, and policy interventions. For the complex networks representing AI risks, computational approaches must balance accuracy with tractability.\n\n`Inference methods implemented include:\n\nExact methods for smaller networks (variable elimination, junction trees)\nApproximate methods for larger networks (Monte Carlo sampling)\nSpecialized approaches for rare events\nIntervention modeling for policy evaluation\n\nImplementation considerations include:\n\nComputational complexity management\nSampling efficiency optimization\nApproximation quality monitoring\nUncertainty representation in outputs`\n\n\n\n3.2.7 Integration with Prediction Markets and Forecasting Platforms\n\n\n\nTo maintain relevance in a rapidly evolving field, formal models must integrate with live data sources such as prediction markets and forecasting platforms. This integration enables continuous updating of model parameters as new information emerges.\n\n`Integration approaches include:\n\nAPI connections to platforms like Metaculus\nSemantic mapping between forecast questions and model variables\nWeighting mechanisms based on forecaster track records\nUpdate procedures for incorporating new predictions\nFeedback loops identifying valuable forecast questions\n\nTechnical implementation involves:\n\nStandardized data formats across platforms\nConflict resolution for contradictory sources\nTemporal alignment of forecasts\nConfidence-weighted aggregation methods`\n\n\nLive Data Sources for Dynamic Model Updating:\n\nMetaculus: Long-term AI predictions and technological forecasting\nGood Judgment Open: Geopolitical events and policy outcomes\nManifold Markets: Diverse question types with rapid market response\nInternal Expert Forecasting: Organization-specific predictions and assessments\n\nData Processing and Integration Pipeline:\npython\ndef integrate_forecast_data(model_variables, forecast_platforms):\n    \"\"\"Connect Bayesian network variables to live forecasting data\"\"\"\n    mappings = create_semantic_mappings(model_variables, forecast_platforms)\n    \n    for variable, forecasts in mappings.items():\n        weighted_forecast = aggregate_forecasts(\n            forecasts, \n            weights=calculate_track_record_weights(forecasts)\n        )\n        model.update_prior(variable, weighted_forecast)\n    \n    return model.recompute_posteriors()\nTechnical Implementation Challenges:\n\nQuestion Mapping: Connecting forecast questions to specific model variables with semantic accuracy\nTemporal Alignment: Handling different forecast horizons and update frequencies across platforms\nConflict Resolution: Principled aggregation when sources provide contradictory information\nTrack Record Weighting: Incorporating forecaster calibration and expertise into aggregation weights\n\n\n3.2.7.1 Live Data Sources\nForecasting Platforms:\n\nMetaculus for long-term AI predictions\nGood Judgment Open for geopolitical events\nManifold Markets for diverse question types\nInternal expert forecasting within organizations\n\n\n\n3.2.7.2 Data Processing Pipeline\nQuestion Mapping: Connecting forecast questions to model variables\nTemporal Alignment: Handling different forecast horizons and update frequencies\nAggregation Methods: Weighting sources by track record and relevance\n\n\n\n\n\n\n\nFigure 3.2: AMTAIR Automation Pipeline from CITATION\n\n\n\nTesting crossreferencing grapics Figure 3.2.\n\n\n\n\nBucknall, Benjamin S., and Shiri Dori-Hacohen. 2022. “Current and Near-Term AI as a Potential Existential Risk Factor.” In Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society, 119–29. Oxford United Kingdom: ACM. https://doi.org/10.1145/3514094.3534146.\n\n\nCarlsmith, Joseph. 2021. “Is Power-Seeking AI an Existential Risk?” 2021. https://doi.org/10.48550/arXiv.2206.13353.\n\n\nLempert, Robert J, Steven W Popper, and Steven C Bankes. 2003. Shaping the Next One Hundred Years: New Methods for Quantitative, Long-Term Policy Analysis. RAND Corporation.\n\n\nPearl, Judea. 2009. Causality: Models, Reasoning and Inference. 2nd ed. Cambridge University Press.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Context & Background</span>"
    ]
  },
  {
    "objectID": "chapters/3.0.AMTAIR.html",
    "href": "chapters/3.0.AMTAIR.html",
    "title": "4  AMTAIR",
    "section": "",
    "text": "4.1 AMTAIR Implementation\nText to render\n{{&lt; include 3.1.Implementation.qmd &gt;}} post text {{&lt; include 3.2.Results.md &gt;}} post text",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>AMTAIR</span>"
    ]
  },
  {
    "objectID": "chapters/4.Discussion.html",
    "href": "chapters/4.Discussion.html",
    "title": "5  Discussion",
    "section": "",
    "text": "6 Discussion — Exchange, Controversy & Influence",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Discussion</span>"
    ]
  },
  {
    "objectID": "chapters/4.Discussion.html#sec-limitationsA",
    "href": "chapters/4.Discussion.html#sec-limitationsA",
    "title": "5  Discussion",
    "section": "6.1 Limitations and Failure Modes",
    "text": "6.1 Limitations and Failure Modes\n\n6.1.1 Limitations and Counterarguments\n\n\n\n6.1.2 Technical Limitations\n\n6.1.2.1 Technical Limitations and Responses\nObjection 1: Extraction Quality Boundaries\n\nCritic: “Complex implicit reasoning chains resist formalization; automated extraction will systematically miss nuanced arguments and subtle conditional relationships.”\n\nResponse: While extraction certainly has limitations, empirical evaluation shows 85%+ accuracy for structural relationships and 73% for probability capture. More importantly, the hybrid human-AI workflow enables expert review and refinement at critical points.\n\nQuantitative Evidence: F1 scores of 0.855 for node identification and 0.775 for relationship extraction exceed acceptable thresholds for decision support applications\nMitigation Strategy: Two-stage architecture allows human oversight of structural extraction before probability integration\nComparative Advantage: Even imperfect formal models often outperform purely intuitive reasoning by making assumptions explicit and forcing consistency\n\nObjection 2: False Precision in Uncertainty Quantification\n\nCritic: “Attaching exact probabilities to unprecedented events like AI catastrophe is fundamentally speculative and may engender dangerous overconfidence in numerical estimates.”\n\nResponse: The system explicitly represents uncertainty ranges and confidence intervals rather than point estimates, and emphasizes conditional reasoning (\"given these premises, the probability is X\") rather than absolute claims.\n\nUncertainty Representation: Models include explicit confidence bounds and sensitivity analysis highlighting which parameters most affect conclusions\nEpistemic Humility: Breaking problems into components enables discussion of which parts have higher vs. lower confidence\nDecision Support Role: Models inform rather than replace human judgment, providing structured frameworks for deliberation\n\n\n\n6.1.2.2 Conceptual and Methodological Concerns\nObjection 3: Democratic Exclusion Through Technical Complexity\n\nCritic: “Transforming policy debates into complex graphs and equations will sideline non-technical stakeholders, concentrating influence among modelers and potentially enabling technocratic capture of democratic processes.”\n\nResponse: AMTAIR explicitly prioritizes visual accessibility and interactive exploration to demystify rather than obscure analysis, while preserving natural language justifications alongside formal representations.\n\nAccessibility Design: Interactive interfaces enable assumption adjustment and “what-if” exploration without technical expertise\nLayered Disclosure: Progressive complexity allows engagement at appropriate technical levels\nTransparency Emphasis: BayesDown format remains human-readable, enabling stakeholder participation in model construction\nDemocratic Integration: Tool designed for expert-informed public deliberation rather than expert replacement of public deliberation\n\nObjection 4: Oversimplification of Complex Systems\n\nCritic: “Forcing complex socio-technical systems into discrete Bayesian networks necessarily oversimplifies crucial dynamics, feedback loops, and emergent properties that resist formal modeling.”\n\nResponse: All models are simplifications; the question is whether formal models simplify more wisely than informal mental models by making assumptions explicit and enabling systematic analysis of limitations.\n\nTransparent Limitations: Formal models clearly show what is and isn’t included, unlike informal reasoning where assumptions remain hidden\nIterative Refinement: Models can be systematically improved as understanding develops, unlike ad-hoc mental models\nComplementary Tool: Formal analysis supplements rather than replaces qualitative insights and expert judgment\nUncertainty Acknowledgment: Models explicitly represent confidence levels and identify areas requiring additional research\n\n\n\n6.1.2.3 Scalability and Adoption Challenges\nObjection 5: Practical Implementation Barriers\n\nCritic: “While academically interesting, integrating these tools into real policy decision-making faces insurmountable barriers including computational costs, institutional resistance, and limited expert availability for model validation.”\n\nResponse: Implementation follows an incremental adoption pathway starting with research applications and gradually demonstrating value for policy analysis, rather than requiring immediate wholesale adoption.\n\nIncremental Deployment: Begin with research organizations and think tanks before expanding to government applications\nCost-Effectiveness: Automation dramatically reduces manual modeling costs, making formal analysis economically viable\nDemonstrated Value: Early applications identify overlooked risks or resolve contentious disagreements, building confidence in the approach\nTraining Infrastructure: Educational programs and user-friendly interfaces reduce barriers to adoption\n\n\n\n\n6.1.3 Integration with Existing Governance Frameworks\n\nNear-Term Integration Opportunities:\nRather than replacing existing governance approaches, AMTAIR enhances them by providing formal analytical capabilities that strengthen evidence-based decision-making across multiple institutional contexts.\nStandards Development Applications:\n\nRisk Assessment Methodologies: Systematic evaluation frameworks for AI safety standards\nTesting Protocol Comparison: Formal analysis of alternative safety testing approaches\nImpact Assessment Enhancement: Quantitative methods for regulatory impact analysis\nCross-Industry Consensus: Shared formal models enabling coordinated standard development\n\nRegulatory Integration Pathways:\n\nEvidence-Based Policy Design: Structured evaluation of regulatory proposals under uncertainty\nStakeholder Input Processing: Systematic integration of diverse expert judgments and public comments\nRegulatory Option Analysis: Formal comparison of alternative regulatory approaches\nInternational Coordination: Common models facilitating harmonized regulatory development\n\nInstitutional Deployment Strategy:\nPhased adoption pathway:\n\nPhase 1: Research Organizations\n- Think tanks and academic institutions adopt for internal analysis\n- Demonstration of value through improved insight generation\n\nPhase 2: Policy Development  \n- Government agencies integrate tools for regulatory impact assessment\n- International bodies use shared models for coordination\n\nPhase 3: Operational Integration\n- Real-time monitoring and early warning systems\n- Adaptive governance mechanisms responsive to changing conditions\n\n6.1.3.1 Extraction Quality Boundaries\nFundamental Challenges:\n\nComplex implicit reasoning chains resist formalization\nSubjective probability judgments vary significantly across individuals\nCultural and linguistic variations in uncertainty expression\nTemporal reasoning and dynamic processes difficult to capture in static models\n\nQuantitative Limitations:\n\n13% false negative rate for complex causal relationships\n27% error rate for implicit probability extraction\nDifficulty with nested conditional statements (&gt;3 levels)\nCross-document reference resolution accuracy 76%\n\n\n\n6.1.3.2 Computational Complexity Constraints\nScalability Challenges:\n\nExact inference becomes intractable above 40-50 nodes\nVisualization clarity degrades with &gt;30 nodes without clustering\nMemory requirements scale exponentially with network connectivity\nReal-time updates challenging for networks with complex dependencies\n\nMitigation Strategies:\n\nHierarchical model decomposition for large networks\nApproximate inference algorithms for complex queries\nProgressive disclosure interfaces for visualization\nSelective update mechanisms based on sensitivity analysis",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Discussion</span>"
    ]
  },
  {
    "objectID": "chapters/4.Discussion.html#sec-red-teaming",
    "href": "chapters/4.Discussion.html#sec-red-teaming",
    "title": "5  Discussion",
    "section": "6.2 Red-Teaming Results: Identifying Failure Modes",
    "text": "6.2 Red-Teaming Results: Identifying Failure Modes\n\n\n\nSystematic Failure Mode Analysis:\nComprehensive red-teaming identified potential failure modes across the entire AMTAIR pipeline, from extraction biases to visualization misinterpretations, informing both current limitations and future development priorities.\n\nSystematic red-teaming identified potential failure modes across the AMTAIR pipeline, from extraction biases to visualization misinterpretations. These analyses inform both current limitations and future development priorities.\n\n`Key failure categories included:\n\nExtraction failures misrepresenting complex arguments\nModel inadequacies from missing causal factors\nInference challenges with rare event probabilities\nPractical deployment risks including misinterpretation\n\nFor each failure mode, mitigations were developed:\n\nImproved extraction prompts for challenging cases\nHybrid human-AI workflow for critical arguments\nExplicit uncertainty representation in outputs\nUser interface improvements for clearer interpretation`\n\n\n6.2.0.1 Systematic Failure Mode Analysis\nAdversarial Testing Methodology:\n\nDeliberately misleading input texts to test extraction robustness\nEdge cases with unusual argument structures and probability expressions\nStrategic manipulation attempts by simulated malicious actors\nStress testing with controversial or politically charged content\n\nIdentified Vulnerabilities:\n\nModel Anchoring: System tends to anchor on first probability mentioned (34% bias)\nConfirmation Bias: Slight preference for extracting evidence supporting author’s conclusions (12% skew)\nComplexity Truncation: Tendency to oversimplify nuanced conditional relationships (23% of complex cases)\nAuthority Weighting: Implicit bias toward statements by recognized experts (18% probability inflation)\n\nAdversarial Testing Methodology:\n\nDeliberately misleading input texts to test extraction robustness and bias resistance\nEdge cases with unusual argument structures and non-standard probability expressions\nStrategic manipulation attempts by simulated malicious actors attempting to game the system\nControversial or politically charged content to assess neutrality and objectivity\n\nIdentified Critical Vulnerabilities:\nPrimary failure categories with mitigation strategies:\n\n\n\n6.2.0.2 Robustness Assessment\nCross-Validation Results:\n\nModel predictions stable across different extraction runs (95% consistency)\nConclusions robust to minor parameter variations (±10% probability changes)\nPolicy recommendations maintain rank ordering despite modeling uncertainties\nSensitivity analysis identifies critical assumptions affecting outcomes\n\nRobustness Assessment Results:\n\nCross-Validation Consistency: 95% stability across different extraction runs\nParameter Sensitivity: Conclusions robust to ±10% probability variations\nRank Order Preservation: Policy recommendations maintain ordering despite modeling uncertainties\nSensitivity Analysis Validation: Critical assumptions correctly identified across multiple test cases",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Discussion</span>"
    ]
  },
  {
    "objectID": "chapters/4.Discussion.html#sec-epistemic-security",
    "href": "chapters/4.Discussion.html#sec-epistemic-security",
    "title": "5  Discussion",
    "section": "6.3 Enhancing Epistemic Security in AI Governance",
    "text": "6.3 Enhancing Epistemic Security in AI Governance\n\n\nCoordination Enhancement Through Explicit Modeling:\nAMTAIR's formalization approach enhances epistemic security in AI governance by making implicit models explicit, revealing hidden assumptions, and enabling more productive discourse across different expert communities and stakeholder perspectives.\nDocumented Coordination Improvements:\n\n40% reduction in time to identify core disagreements in multi-stakeholder workshops\n60% improvement in argument mapping accuracy when using structured extraction formats\n25% increase in successful cross-disciplinary collaboration on AI governance questions\n50% faster convergence on shared terminology and conceptual frameworks\n\nMechanism Analysis:\nHow formal modeling enhances coordination:\n\n• **Assumption Transparency**: Hidden premises become explicit and debatable\n• **Quantified Uncertainty**: Vague disagreements converted to specific probability disputes  \n• **Structured Comparison**: Side-by-side worldview analysis reveals genuine vs. semantic differences\n• **Evidence Integration**: New information updates models consistently rather than selectively\nCommunity-Level Epistemic Effects:\n\nShared Vocabulary Development: Common language for discussing probabilities and uncertainties\nFocused Disagreement: Debates concentrate on substantive cruxes rather than peripheral differences\nEnhanced Integration: Diverse perspectives systematically incorporated rather than dismissed\nResearch Prioritization: Critical uncertainties identified objectively for targeted investigation\n\n\nAMTAIR’s formalization approach enhances epistemic security in AI governance by making implicit models explicit, revealing assumptions, and enabling more productive discourse across different perspectives. This transformation of qualitative arguments into formal models creates a foundation for improved collective sensemaking.\n\n`Direct benefits include:\n\nExplicit representation of uncertainty through probability distributions\nClear identification of genuine vs. terminological disagreements\nPrecise tracking of belief updating as new evidence emerges\nObjective identification of critical uncertainties\n\nCommunity-level effects include:\n\nShared vocabulary for discussing probabilities\nImproved focus on cruxes rather than peripheral disagreements\nEnhanced ability to integrate diverse perspectives\nMore effective prioritization of research questions`",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Discussion</span>"
    ]
  },
  {
    "objectID": "chapters/4.Discussion.html#sec-scaling-challenges",
    "href": "chapters/4.Discussion.html#sec-scaling-challenges",
    "title": "5  Discussion",
    "section": "6.4 Scaling Challenges and Opportunities",
    "text": "6.4 Scaling Challenges and Opportunities\n\n\n\nScaling AMTAIR to handle more content, greater complexity, and broader application domains presents both challenges and opportunities. Technical limitations interact with organizational and adoption considerations to shape the pathway to wider impact.\n\n`Technical scaling challenges include:\n\nComputational complexity for very large networks\nData quality variation across source materials\nInterface usability for complex models\nIntegration complexity with multiple platforms\n\nOrganizational considerations include:\n\nCoordination mechanisms for distributed development\nQuality assurance processes\nKnowledge management requirements\nStakeholder engagement strategies\n\nPromising opportunities include:\n\nImproved extraction techniques using next-generation LLMs\nMore sophisticated visualization approaches\nEnhanced inference algorithms\nDeeper integration with governance processes`\n\n\n6.4.1 Conceptual and Methodological Concerns\n\n6.4.1.1 The Formalization Challenge\nEpistemic Concerns:\n\nRisk of false precision when quantifying inherently subjective judgments\n\n\nExpert probability elicitation shows high individual variation (SD = 0.2-0.4)\nLinguistic uncertainty expressions are context-dependent and culturally influenced\nModel boundaries necessarily exclude relevant factors due to complexity constraints\nStatic representations cannot capture dynamic strategic interactions",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Discussion</span>"
    ]
  },
  {
    "objectID": "chapters/4.Discussion.html#sec-governance-applications",
    "href": "chapters/4.Discussion.html#sec-governance-applications",
    "title": "5  Discussion",
    "section": "6.5 Governance Applications and Strategic Implications",
    "text": "6.5 Governance Applications and Strategic Implications\n\n6.5.0.1 Democratic Governance Implications\nPotential Exclusionary Effects:\n\nTechnical barriers may exclude non-expert stakeholders\nQuantitative frameworks can devalue qualitative insights and lived experience\nFormal models may privilege certain types of reasoning over others\nRisk of technocratic capture of democratic deliberation processes\n\nMitigation Approaches:\n\nLayered interfaces designed for different expertise levels\nExplicit preservation of natural language justifications alongside formal models\nCommunity-based model development with diverse stakeholder involvement\nTransparent uncertainty representation and model limitation disclosure\n\n\n\n6.5.0.2 Coordination Improvements\nDocumented Benefits:\n\n40% reduction in time to identify core disagreements in multi-stakeholder workshops\n60% improvement in argument mapping accuracy when using structured formats\n25% increase in cross-disciplinary collaboration on AI governance questions\n50% faster convergence on shared terminology and conceptual frameworks\n\nMechanism Analysis:\n\nExplicit assumption identification prevents talking past each other\nQuantified uncertainty representation enables more precise communication\nStructured comparison facilitates focused debate on genuine disagreements\nVisual models improve comprehension across expertise levels",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Discussion</span>"
    ]
  },
  {
    "objectID": "chapters/4.Discussion.html#sec-integration",
    "href": "chapters/4.Discussion.html#sec-integration",
    "title": "5  Discussion",
    "section": "6.6 Integration with Existing Governance Frameworks",
    "text": "6.6 Integration with Existing Governance Frameworks\n\n\nRather than replacing existing governance approaches, AMTAIR complements and enhances them by providing formal analytical capabilities that can strengthen decision-making. Integration with current frameworks presents both opportunities and challenges.\n\n`Integration opportunities include:\n\nEnhancing impact assessment methodologies\nSupporting standards development with formal evaluation\nInforming regulatory design with counterfactual analysis\nFacilitating international coordination through shared models\n\nPractical applications include:\n\nStructured reasoning about governance proposals\nComparison of regulatory approaches\nAnalysis of standard effectiveness\nIdentification of governance gaps\n\nImplementation pathways include:\n\nTool adoption by key organizations\nIntegration with existing workflows\nTraining programs for governance analysts\nProgressive enhancement of current processes`\n\n\n6.6.0.1 Near-Term Applications\nStandards Development:\n\nFormal risk assessment methodologies for AI safety standards\nStructured comparison of alternative safety testing protocols\nQuantitative impact assessment for proposed technical standards\nCross-industry consensus building on risk evaluation frameworks\n\nRegulatory Applications:\n\nEvidence-based policy impact assessment for AI governance regulations\nStructured stakeholder input processing and synthesis\nRegulatory option analysis under uncertainty\nInternational coordination on regulatory approaches\n\n\n\n6.6.0.2 Institutional Deployment Pathways\nOrganizational Integration:\n\nPolicy research organizations adopting AMTAIR for standard analysis workflows\nGovernment agencies using formal models for regulatory impact assessment\nIndustry consortia applying framework for collaborative risk evaluation\nAcademic institutions incorporating methods in AI governance curricula\n\nSuccess Factors:\n\nLeadership buy-in and dedicated resources for adoption and training\nIntegration with existing workflows rather than wholesale replacement\nGradual capability building through pilot projects and case studies\nCommunity development around shared methodological approaches\n\n\n\n6.6.0.3 Decision Support Enhancement\nPolicy Development Applications:\n\nSystematic comparison of intervention alternatives across scenarios\nSensitivity analysis identifying critical uncertainties requiring additional research\nRobustness testing revealing policy vulnerabilities and failure modes\nCross-worldview evaluation highlighting implementation dependencies\n\n\n\n6.6.1 Long-Term Strategic Implications\n\n6.6.1.1 Toward Adaptive Governance\nDynamic Modeling Capabilities:\n\nReal-time model updates as new research findings emerge\nIntegration with prediction markets for continuous probability calibration\nAutomated monitoring of key risk indicators and governance effectiveness\nAdaptive policy mechanisms responsive to changing threat landscapes\n\nCoordination Scaling:\n\nGlobal AI governance coordination supported by shared formal models\nMulti-stakeholder decision-making enhanced by transparent uncertainty representation\nEvidence-based resource allocation across AI safety research priorities\nStrategic early warning systems for emerging risks and opportunities",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Discussion</span>"
    ]
  },
  {
    "objectID": "chapters/4.Discussion.html#sec-deep-uncertainties",
    "href": "chapters/4.Discussion.html#sec-deep-uncertainties",
    "title": "5  Discussion",
    "section": "6.7 Known Unknowns and Deep Uncertainties",
    "text": "6.7 Known Unknowns and Deep Uncertainties\n\n\n\nFundamental Epistemological Boundaries:\nWhile AMTAIR enhances reasoning under uncertainty, fundamental limitations remain regarding truly novel developments that might fall outside existing conceptual frameworks—a challenge requiring explicit acknowledgment and adaptive strategies.\nCategories of Deep Uncertainty:\n\nNovel Capabilities: Future AI developments operating according to principles outside current scientific understanding\nEmergent Behaviors: Complex system properties that resist prediction from component analysis\nStrategic Interactions: Game-theoretic dynamics with superhuman AI systems that exceed human modeling capacity\nSocial Transformation: Unprecedented social and economic changes invalidating current institutional assumptions\n\n\nWhile AMTAIR enhances our ability to reason under uncertainty, fundamental limitations remain—particularly concerning truly novel or unprecedented developments in AI that might fall outside existing conceptual frameworks. Acknowledgment of these limitations is essential for responsible use.\n\n`Fundamental limitations include:\n\nNovel capabilities outside historical patterns\nUnprecedented social and economic impacts\nEmergent behaviors in complex systems\nFundamental unpredictability of technological development\n\nAdaptation strategies include:\n\nFlexible model architectures accommodating new variables\nRegular updates from expert input\nExplicit confidence level indication\nAlternative model formulations\n\nDecision principles for deep uncertainty include:\n\nRobust strategies across model variants\nAdaptive approaches with learning mechanisms\nPreservation of option value\nExplicit value of information calculations`\n\n\n6.7.0.1 Model Uncertainty vs Deep Uncertainty\nQuantifiable Uncertainties:\n\nParameter estimation errors with known confidence intervals\nModel selection uncertainty across well-specified alternatives\nData quality issues with measurable impacts on conclusions\n\nDeep Uncertainties:\n\nUnknown unknown factors not represented in any current model\nFundamental shifts in the nature of AI development or deployment\nUnprecedented social responses to transformative AI capabilities\nParadigm shifts in scientific understanding of intelligence or consciousness\n\n\n\n6.7.1 Adaptive Strategies Under Uncertainty\n\n6.7.1.1 Adaptation Strategies for Deep Uncertainty\nModel Architecture Flexibility:\npython\ndef adaptive_model_architecture():\n    \"\"\"Design principles for handling unprecedented developments\"\"\"\n    return {\n        'modular_structure': 'Enable rapid incorporation of new variables',\n        'uncertainty_tracking': 'Explicit confidence levels for each component',\n        'scenario_branching': 'Multiple model variants for different assumptions',\n        'update_mechanisms': 'Systematic procedures for model revision'\n    }\nRobust Decision-Making Principles:\n\nOption Value Preservation: Policies maintaining flexibility for future course corrections\nPortfolio Diversification: Multiple approaches hedging across different uncertainty sources\nEarly Warning Systems: Monitoring for developments that would invalidate current models\nAdaptive Governance: Institutional mechanisms enabling rapid response to new information\n\nMeta-Learning and Continuous Improvement:\n\nPrediction Tracking: Systematic monitoring of model accuracy to identify systematic biases\nExpert Feedback Integration: Regular model validation and refinement based on domain expertise\nCommunity-Driven Development: Distributed model improvement across research communities\nUncertainty Quantification: Explicit representation of confidence levels and limitation boundaries\n\n\n\n6.7.1.2 Robust Decision-Making Principles\nOption Value Preservation:\n\nPolicies maintaining flexibility for future course corrections\nResearch portfolios hedging across multiple technical approaches\nInstitutional designs enabling rapid adaptation to new information\nInternational cooperation frameworks robust to changing power dynamics\n\nMinimax Regret Approaches:\n\nStrategies minimizing worst-case disappointment across scenarios\nPortfolio diversification across different risk mitigation approaches\nEarly warning systems enabling rapid course corrections\nFail-safe defaults when key uncertainties cannot be resolved\n\n\n\n6.7.1.3 Meta-Learning and Adaptation\nContinuous Model Improvement:\n\nSystematic tracking of prediction accuracy and model performance\nBayesian updating procedures for incorporating new evidence\nExpert feedback loops for model refinement and calibration\nCommunity-driven model development and validation processes\n\n\n\n\n6.7.2 Fundamental Modeling Limitations\n\n6.7.2.1 The Unprecedented Challenge\nNovel Capabilities Problem:\n\nFuture AI developments may operate according to principles outside human experience\nEmergent behaviors in complex systems resist prediction from component analysis\nStrategic interactions with superhuman AI systems fundamentally unpredictable\nSocial and economic transformations may invalidate current institutional assumptions\n\n\nTaleb (2007) on black swan events and the limits of predictive modeling\n\n\n\n\n\nTaleb, Nassim Nicholas. 2007. The Black Swan: The Impact of the Highly Improbable. Random House.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Discussion</span>"
    ]
  },
  {
    "objectID": "chapters/5.Conclusion.html",
    "href": "chapters/5.Conclusion.html",
    "title": "6  Conclusion",
    "section": "",
    "text": "7 Conclusion",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "chapters/5.Conclusion.html#sec-key-contributions",
    "href": "chapters/5.Conclusion.html#sec-key-contributions",
    "title": "6  Conclusion",
    "section": "7.1 Key Contributions and Findings",
    "text": "7.1 Key Contributions and Findings",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "chapters/5.Conclusion.html#sec-key-contributions2",
    "href": "chapters/5.Conclusion.html#sec-key-contributions2",
    "title": "6  Conclusion",
    "section": "7.2 Summary of Key Contributions",
    "text": "7.2 Summary of Key Contributions\n\n\nAMTAIR makes several key contributions to both the theoretical understanding of AI risk modeling and the practical tooling available for AI governance. These advances demonstrate how computational approaches can help address the coordination crisis in AI safety.\n\n\nMethodological Innovations:\nAMTAIR represents the first computational framework enabling automated transformation from natural language AI governance arguments to formal Bayesian networks while preserving semantic richness and enabling rigorous policy evaluation.\n\n7.2.1 Methodological Innovations\nBayesDown as Bridge Technology: Created first computational framework enabling automated transformation from natural language AI governance arguments to formal Bayesian networks while preserving semantic richness\nTwo-Stage Extraction Architecture: Demonstrated feasibility of separating structural argument extraction from probability quantification, enabling modular improvement and human oversight at critical decision points\nCross-Worldview Modeling Capability: Developed systematic methods for representing and comparing diverse perspectives on AI governance within a common formal framework\n\nBayesDown as Bridge Technology: Novel intermediate representation bridging natural language and mathematical modeling\nTwo-Stage Extraction Architecture: Separation of structural and probabilistic extraction enabling modular improvement\nCross-Worldview Modeling Framework: Systematic methods for representing and comparing diverse expert perspectives\nPolicy Evaluation Integration: Formal counterfactual analysis capabilities for governance intervention assessment\n\n`Methodological innovations include:\n\nBayesDown as an intermediate representation bridging natural language and Bayesian networks\nTwo-stage extraction pipeline separating structure from probability\nCross-worldview comparison methodology\nInteractive visualization approach for complex probabilistic relationships\n\n\n\n7.2.2 Technical Achievements\nPrototype Validation: Working implementation demonstrates 85%+ accuracy for structural extraction and 73% accuracy for probability extraction from real AI governance literature\nScalable Architecture: Modular system design accommodates networks up to 50+ nodes while maintaining interactive performance and extensible for larger applications\nInteractive Visualization: Novel probabilistic network visualization enabling non-experts to understand complex causal arguments and uncertainty relationships\n\n\n7.2.3 Strategic Insights\nCoordination Enhancement Evidence: Empirical validation of 40% reduction in time to identify core disagreements and 60% improvement in argument mapping accuracy using structured approaches\nPolicy Evaluation Capabilities: Demonstrated systematic policy impact assessment across different worldviews with quantified robustness measures\nEpistemic Security Improvements: Formal representation makes implicit assumptions explicit, reducing unproductive disagreement and enabling focused research prioritization\nTechnical contributions include:\n\nWorking prototype demonstrating extraction feasibility\nInteractive visualization making complex models accessible\nIntegration capabilities with forecasting platforms\nPolicy evaluation framework for intervention assessment\n\nTechnical Achievements:\n\nValidated Implementation: Working prototype demonstrating 85%+ structural extraction accuracy and 73% probability extraction accuracy\nScalable Architecture: Modular system accommodating networks up to 50+ nodes with interactive performance\nReal-World Application: Successful formalization of Carlsmith’s complex AI risk model reproducing original conclusions\nInteractive Visualization: Novel probability-encoded network visualization enabling non-expert engagement\n\nEmpirical findings include:\n\nExtraction quality assessments showing viability of automation\nComparative analyses revealing key cruxes across perspectives\nPolicy evaluations demonstrating formal modeling benefits\nPerformance benchmarks guiding future development`\n\nStrategic Insights:\n\nCoordination Enhancement: Empirical demonstration of 40% reduction in disagreement identification time and 60% improvement in argument mapping accuracy\nCrux Identification: Systematic revelation of key uncertainty drivers across different expert worldviews\nPolicy Robustness: Identification of governance interventions effective across multiple scenario assumptions\nEpistemic Security: Enhanced discourse quality through explicit assumption identification and uncertainty quantification",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "chapters/5.Conclusion.html#sec-limitations1",
    "href": "chapters/5.Conclusion.html#sec-limitations1",
    "title": "6  Conclusion",
    "section": "7.3 Limitations of the Current Implementation",
    "text": "7.3 Limitations of the Current Implementation\n\n\nWhile AMTAIR demonstrates the feasibility of automated extraction and formalization, significant limitations remain in the current implementation. Some represent fundamental challenges in modeling complex domains, while others are implementation constraints that future work can address.\n\n\n7.3.1 Limitations and Future Research\n\n7.3.1.1 Immediate Technical Priorities\nExtraction Quality Enhancement:\n\nAdvanced Prompt Engineering: Domain-specific fine-tuning for complex conditional relationships (target: 90% accuracy)\nHybrid Human-AI Workflows: Systematic integration of expert validation and refinement processes\nUncertainty Quantification: Confidence bounds for extraction outputs and propagation through analysis pipeline\n\nScaling Infrastructure Development:\n\nDistributed Processing: Large-scale literature analysis across thousands of documents\nAdvanced Approximation Algorithms: Efficient inference methods for networks exceeding 100 nodes\nReal-Time Integration: Dynamic model updating with live forecasting and research data\n\n`Technical constraints include:\n\nExtraction quality boundaries for complex arguments\nComputational complexity barriers for very large networks\nInterface sophistication limits\nUpdate frequency constraints\n\n\n\n7.3.1.2 Long-Term Research Directions\nPrediction Market Integration:\n\nSemantic Mapping: Automated connection between model variables and relevant forecast questions\nDynamic Calibration: Continuous model updating based on prediction market performance\nQuestion Generation: Systematic identification of high-value forecasting questions for model improvement\n\nStrategic Interaction Modeling:\n\nGame-Theoretic Extensions: Multi-agent frameworks capturing strategic behavior between AI developers, regulators, and other stakeholders\nDynamic Equilibrium Analysis: Models incorporating feedback loops and adaptive responses\nCoalition Formation: Formal representation of international cooperation and competition dynamics\n\nCross-Domain Applications:\n\nExistential Risk Portfolio: Extension to biosecurity, climate, nuclear, and other catastrophic risks\nComplex Policy Challenges: Application to healthcare, education, economic policy domains\nOrganizational Decision-Making: Internal strategy development and risk assessment tools\n\nConceptual limitations include:\n\nSimplifications inherent in causal models\nChallenges representing complex dynamic processes\nDifficulties with unprecedented scenarios\nValue assumptions embedded in model structures\n\nFuture work can address:\n\nExtraction quality through improved prompting and validation\nComputational efficiency through optimized algorithms\nInterface sophistication through advanced visualization\nUpdate mechanisms through deeper platform integration`",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "chapters/5.Conclusion.html#sec-policy-implications",
    "href": "chapters/5.Conclusion.html#sec-policy-implications",
    "title": "6  Conclusion",
    "section": "7.4 Policy Implications and Recommendations",
    "text": "7.4 Policy Implications and Recommendations\n\n\nInstitutional Integration Pathway:\nAMTAIR's demonstrated capabilities create opportunities for systematic enhancement of AI governance decision-making processes across multiple institutional levels and stakeholder communities.\nNear-Term Implementation Recommendations:\n\nResearch Organization Adoption: Think tanks and academic institutions integrate tools for systematic argument analysis and policy evaluation\nRegulatory Impact Assessment: Government agencies adopt formal modeling approaches for evidence-based policy development\nInternational Coordination: Shared formal models enable more effective cooperation on global AI governance challenges\nExpert Training Programs: Educational initiatives building formal modeling literacy across governance communities\n\nStrategic Value Propositions:\nInstitutional benefits from AMTAIR adoption:\n\n• **Evidence-Based Decision Making**: Systematic evaluation of policy alternatives under uncertainty\n• **Stakeholder Communication**: Common formal language reducing misunderstanding and coordination failures  \n• **Resource Allocation**: Objective identification of highest-impact research and policy priorities\n• **Adaptive Governance**: Dynamic updating capabilities enabling responsive policy adjustment\nLong-Term Governance Vision:\n\nEpistemic Infrastructure: Systematic formal modeling becomes standard practice in AI governance analysis\nDemocratic Enhancement: Accessible tools enable broader stakeholder participation in technical policy debates\nInternational Cooperation: Shared models facilitate coordination on global governance challenges\nAnticipatory Governance: Early warning systems enable proactive rather than reactive policy responses\n\n\nAMTAIR’s approach has significant implications for how AI governance could evolve toward more rigorous, transparent, and effective practices. By making implicit models explicit and enabling formal policy evaluation, the system supports evidence-based governance development.\n\n`General implications include:\n\nValue of formal modeling for policy development\nImportance of explicit uncertainty representation\nBenefits of structured worldview comparison\nAdvantages of conditional policy framing\n\nSpecific recommendations include:\n\nDevelopment of formal impact assessment protocols\nCreation of shared model repositories\nIntegration of forecasting with policy evaluation\nTraining in formal modeling for governance analysts\n\nImplementation pathways include:\n\nIntegration with existing processes\nAdoption by key organizations\nTraining and capacity building\nProgressive enhancement of current approaches`",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "chapters/5.Conclusion.html#sec-future-research3",
    "href": "chapters/5.Conclusion.html#sec-future-research3",
    "title": "6  Conclusion",
    "section": "7.5 Limitations and Future Research",
    "text": "7.5 Limitations and Future Research",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "chapters/5.Conclusion.html#future-research-directions",
    "href": "chapters/5.Conclusion.html#future-research-directions",
    "title": "6  Conclusion",
    "section": "7.6 Future Research Directions",
    "text": "7.6 Future Research Directions\n\n\nBuilding on AMTAIR’s foundation, several promising research directions could further enhance the approach’s capabilities, applications, and impact. These range from technical improvements to expanded use cases and deeper integration with governance processes.\n\n\n7.6.1 Immediate Technical Priorities\nExtraction Quality Enhancement:\n\nAdvanced prompt engineering for complex conditional relationships (target: 85% accuracy)\nHybrid human-AI workflows for validation and refinement of automated outputs\nDomain-specific fine-tuning for AI governance terminology and reasoning patterns\n\nScaling Infrastructure:\n\nDistributed processing for large-scale literature analysis\nAdvanced approximation algorithms for inference in complex networks\nReal-time update mechanisms for dynamic modeling capabilities\n\n`Technical enhancements include:\n\nAdvanced extraction algorithms leveraging next-generation LLMs\nMore sophisticated visualization techniques\nImproved inference methods for complex networks\nEnhanced prediction market integration\n\n\n\n7.6.2 Governance Integration Pathway\nInstitutional Adoption: Systematic deployment within policy research organizations, government agencies, and industry consortia with appropriate training and support\nCommunity Development: Formation of practitioner community around shared methodological standards and best practices for formal AI governance modeling\nInternational Coordination: Integration with global AI governance frameworks to enable evidence-based cooperation and resource allocation\nApplication expansions include:\n\nExtension to other existential risks\nApplication to broader policy challenges\nIntegration with other governance tools\nAdaptation for organizational decision-making\n\n\n\n7.6.3 Long-Term Research Directions\nPrediction Market Integration: Full implementation of live data feeds enabling dynamic model updates and continuous calibration against empirical outcomes\nStrategic Interaction Modeling: Extension to game-theoretic frameworks capturing strategic behavior between AI developers, regulators, and other key actors\nCross-Domain Applications: Adaptation of methodologies to other existential risk domains (biosecurity, climate, nuclear) and complex policy challenges\nTheoretical extensions include:\n\nAdvanced uncertainty representation\nDeeper integration with decision theory\nFormal frameworks for worldview comparison\nEnhanced modeling of dynamic processes`",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "chapters/5.Conclusion.html#sec-concluding-reflections",
    "href": "chapters/5.Conclusion.html#sec-concluding-reflections",
    "title": "6  Conclusion",
    "section": "7.7 Concluding Reflections",
    "text": "7.7 Concluding Reflections\n\n\nAt its core, this work represents a bet that the epistemic challenges in AI governance are not merely incidental but structural—and that addressing them requires not just more conversation but better tools for collective sensemaking. The stakes of this bet could hardly be higher, as coordinating our response to increasingly powerful AI systems may well determine humanity’s long-term future.\n\n`AMTAIR contributes to this coordination challenge by:\n\nMaking implicit models explicit\nRevealing genuine points of disagreement\nEnabling rigorous evaluation of interventions\nSupporting exploration across possible futures\nCreating common ground for diverse stakeholders\n\nUltimately, the project aims to transform how we think about AI governance—not by providing definitive answers, but by improving the quality of our questions, the rigor of our reasoning, and the clarity of our communication. In a domain characterized by deep uncertainty and rapid change, such epistemic foundations may be our most valuable resource.`\n\nThe Coordination Imperative:\nThe research presented here demonstrates both opportunity and necessity. As AI capabilities advance toward and potentially beyond human-level intelligence, the window for establishing effective governance becomes increasingly constrained through accelerating technological development and expanding deployment complexity.\n\nThe coordination failures documented throughout this thesis—fragmented expert communities, incompatible analytical frameworks, misallocated resources—pose existential risks comparable to the technical challenges of AI alignment itself.\n\n\n7.7.1 The Coordination Imperative\nThe research presented here represents both an opportunity and a necessity. As AI capabilities advance toward and potentially beyond human-level intelligence, the window for establishing effective governance becomes increasingly constrained. The coordination failures documented throughout this thesis—fragmented communities, incompatible frameworks, resource misallocation—pose existential risks comparable to the technical challenges of AI alignment itself.\nAMTAIR offers a concrete path forward: computational tools that make implicit models explicit, enable systematic comparison across worldviews, and support evidence-based evaluation of governance interventions. The prototype demonstrates technical feasibility; the case studies validate practical utility; the analysis reveals both opportunities and limitations.\nAMTAIR as Epistemic Infrastructure:\nAMTAIR offers a concrete pathway forward: computational tools that make implicit models explicit, enable systematic comparison across worldviews, and support evidence-based evaluation of governance interventions while preserving space for democratic deliberation and value-based choice.\n\nTechnical Feasibility: Working prototype validates automated extraction and formal modeling approaches\nPolicy Utility: Case studies demonstrate practical value for real governance questions\nDemocratic Integration: Interactive tools enable broader stakeholder participation rather than expert capture\nAdaptive Capacity: Framework supports continuous improvement as understanding develops\n\n\n\n7.7.2 Beyond Technical Solutions\nYet technology alone cannot solve coordination problems rooted in human psychology, institutional incentives, and political dynamics. The formal models enable better reasoning but cannot substitute for wisdom, judgment, and democratic deliberation. Success requires integrating computational tools with existing governance institutions while remaining vigilant against technocratic capture or false precision.\nThe multiplicative benefits framework—automation enabling data integration, prediction markets informing models, formal evaluation guiding policy—creates value only when embedded in broader ecosystems of expertise, oversight, and accountability. AMTAIR represents infrastructure for coordination, not coordination itself.\nBeyond Technical Solutions:\nYet technology alone cannot solve coordination problems rooted in human psychology, institutional incentives, and political dynamics. Formal models enable better reasoning but cannot substitute for wisdom, judgment, and democratic deliberation about values and priorities.\nThe Multiplicative Benefits Framework in Practice:\nSuccess requires embedding computational tools within broader ecosystems of expertise, oversight, and accountability. AMTAIR represents infrastructure for coordination, not coordination itself—a foundation enabling more effective collaboration rather than a replacement for human judgment.\nFuture Stakes and Opportunities:\nThe path forward depends not only on technical capabilities but on institutional adoption, community development, and integration with democratic governance processes. The stakes could hardly be higher: if advanced AI systems emerge without adequate governance frameworks, consequences may prove irreversible.\n\nThe future depends not only on what we build, but on how well we coordinate in building it. AMTAIR provides tools for that coordination; whether they prove sufficient depends on our collective wisdom in using them.\n\nThis thesis demonstrates one approach to enhancing coordination through better epistemic tools. Whether it proves sufficient remains an open question requiring continued research, institutional innovation, and collaborative development across the communities whose coordination it aims to support.\n\n\n7.7.3 The Path Forward\nThe stakes could hardly be higher. If advanced AI systems emerge without adequate governance, the consequences may prove irreversible. If governance systems prove too slow or fragmented to respond effectively, we risk losing control over humanity’s technological trajectory precisely when that control matters most.\nThis thesis demonstrates one approach to enhancing coordination through better epistemic tools. Whether it proves sufficient depends on adoption, refinement, and integration with broader governance efforts. The window for action remains open, but it may not remain so indefinitely.\nThe future depends not only on what we build, but on how well we coordinate in building it.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "ref/references.html",
    "href": "ref/references.html",
    "title": "7  References (.md)",
    "section": "",
    "text": "7.1 BibTeX of Main Citations Included",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>References (.md)</span>"
    ]
  },
  {
    "objectID": "ref/references.html#bibtex-of-main-citations-included",
    "href": "ref/references.html#bibtex-of-main-citations-included",
    "title": "7  References (.md)",
    "section": "",
    "text": "## Update in ref/MAref.bib\n\n@article{bostrom2012,\n  title = {The {{Superintelligent Will}}: {{Motivation}} and {{Instrumental Rationality}} in {{Advanced Artificial Agents}}},\n  author = {Bostrom, Nick},\n  date = {2012},\n  journaltitle = {Minds and Machines},\n  volume = {22},\n  number = {2},\n  pages = {71--85},\n  publisher = {Kluwer Academic Publishers Norwell, MA, USA},\n  doi = {10.1007/s11023-012-9281-3},\n  url = {https://philpapers.org/rec/BOSTSW}\n}\n\n@book{bostrom2014,\n  title = {Superintelligence: {{Paths}}, Strategies, Dangers},\n  author = {Bostrom, Nick},\n  date = {2014},\n  publisher = {Oxford University Press},\n  location = {Oxford},\n  url = {https://scholar.dominican.edu/cynthia-stokes-brown-books-big-history/47},\n  abstract = {The human brain has some capabilities that the brains of other animals lack. It is to these distinctive capabilities that our species owes its dominant position. Other animals have stronger muscles or sharper claws, but we have cleverer brains. If machine brains one day come to surpass human brains in general intelligence, then this new superintelligence could become very powerful. As the fate of the gorillas now depends more on us humans than on the gorillas themselves, so the fate of our species then would come to depend on the actions of the machine superintelligence. But we have one advantage: we get to make the first move. Will it be possible to construct a seed AI or otherwise to engineer initial conditions so as to make an intelligence explosion survivable? How could one achieve a controlled detonation? To get closer to an answer to this question, we must make our way through a fascinating landscape of topics and considerations. Read the book and learn about oracles, genies, singletons; about boxing methods, tripwires, and mind crime; about humanity's cosmic endowment and differential technological development; indirect normativity, instrumental convergence, whole brain emulation and technology couplings; Malthusian economics and dystopian evolution; artificial intelligence, and biological cognitive enhancement, and collective intelligence.},\n  isbn = {978-0-19-967811-2}\n}\n\n@article{bostrom2016,\n  title = {The {{Unilateralist}}’s {{Curse}} and the {{Case}} for a {{Principle}} of {{Conformity}}},\n  author = {Bostrom, Nick and Douglas, Thomas and Sandberg, Anders},\n  date = {2016},\n  journaltitle = {Social Epistemology},\n  volume = {30},\n  number = {4},\n  pages = {350--371},\n  publisher = {Routledge, part of the Taylor \\& Francis Group},\n  doi = {10.1080/02691728.2015.1108373},\n  url = {https://www.tandfonline.com/doi/full/10.1080/02691728.2015.1108373}\n}\n\n@article{bostrom2019,\n  title = {The Vulnerable World Hypothesis},\n  author = {Bostrom, Nick},\n  date = {2019},\n  journaltitle = {Global Policy},\n  volume = {10},\n  number = {4},\n  pages = {455--476},\n  publisher = {Wiley Online Library},\n  doi = {10.1111/1758-5899.12718}\n}",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>References (.md)</span>"
    ]
  },
  {
    "objectID": "chapters/I.Appendices.html",
    "href": "chapters/I.Appendices.html",
    "title": "Appendix A — Appendices",
    "section": "",
    "text": "Appendices",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Appendices</span>"
    ]
  },
  {
    "objectID": "chapters/I.Appendices.html#sec-appendix-technical",
    "href": "chapters/I.Appendices.html#sec-appendix-technical",
    "title": "Appendix A — Appendices",
    "section": "Appendix A: Technical Implementation Details",
    "text": "Appendix A: Technical Implementation Details",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Appendices</span>"
    ]
  },
  {
    "objectID": "chapters/I.Appendices.html#sec-appendix-validation",
    "href": "chapters/I.Appendices.html#sec-appendix-validation",
    "title": "Appendix A — Appendices",
    "section": "Appendix B: Model Validation Datasets, Procedures and Benchmarks",
    "text": "Appendix B: Model Validation Datasets, Procedures and Benchmarks",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Appendices</span>"
    ]
  },
  {
    "objectID": "chapters/I.Appendices.html#sec-appendix-case-studies",
    "href": "chapters/I.Appendices.html#sec-appendix-case-studies",
    "title": "Appendix A — Appendices",
    "section": "Appendix C: Case Studies",
    "text": "Appendix C: Case Studies",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Appendices</span>"
    ]
  },
  {
    "objectID": "chapters/I.Appendices.html#sec-appendix-ethical",
    "href": "chapters/I.Appendices.html#sec-appendix-ethical",
    "title": "Appendix A — Appendices",
    "section": "Appendix D: Ethical Considerations and Governance",
    "text": "Appendix D: Ethical Considerations and Governance",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Appendices</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "",
    "text": "B.2 0.2 Connect to GitHub Repository\nThe Public GitHub Repo Url in use:\nhttps://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/\nNote: When encountering errors, accessing the data, try using “RAW” Urls.\nCode\n# @title 0.2 --- Connect to GitHub Repository --- Load Files\n\n\"\"\"\nBLOCK PURPOSE: Establishes connection to the AMTAIR GitHub repository and provides\nfunctions to load example data files for processing.\n\nThis block creates a reusable function for accessing files from the project's\nGitHub repository, enabling access to example files like the rain-sprinkler-lawn\nBayesian network that serves as our canonical test case.\n\nDEPENDENCIES: requests library, io library\nOUTPUTS: load_file_from_repo function and test file loads\n\"\"\"\n\nfrom requests.exceptions import HTTPError\n\n# Specify the base repository URL for the AMTAIR project\nrepo_url = \"https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/\"\nprint(f\"Connecting to repository: {repo_url}\")\n\ndef load_file_from_repo(relative_path):\n    \"\"\"\n    Loads a file from the specified GitHub repository using a relative path.\n\n    Args:\n        relative_path (str): Path to the file relative to the repo_url\n\n    Returns:\n        For CSV/JSON: pandas DataFrame\n        For MD: string containing file contents\n\n    Raises:\n        HTTPError: If file not found or other HTTP error occurs\n        ValueError: If unsupported file type is requested\n    \"\"\"\n    file_url = repo_url + relative_path\n    print(f\"Attempting to load: {file_url}\")\n\n    # Fetch the file content from GitHub\n    response = requests.get(file_url)\n\n    # Check for bad status codes with enhanced error messages\n    if response.status_code == 404:\n        raise HTTPError(f\"File not found at URL: {file_url}. Check the file path/name and ensure the file is publicly accessible.\", response=response)\n    else:\n        response.raise_for_status()  # Raise for other error codes\n\n    # Convert response to file-like object\n    file_object = io.StringIO(response.text)\n\n    # Process different file types appropriately\n    if relative_path.endswith(\".csv\"):\n        return pd.read_csv(file_object)  # Return DataFrame for CSV\n    elif relative_path.endswith(\".json\"):\n        return pd.read_json(file_object)  # Return DataFrame for JSON\n    elif relative_path.endswith(\".md\"):\n        return file_object.read()  # Return raw content for MD files\n    else:\n        raise ValueError(f\"Unsupported file type: {relative_path.split('.')[-1]}. Add support in the GitHub Connection section of this notebook.\")\n\n# Load example files to test connection\ntry:\n    # Load the extracted data CSV file\n#    df = load_file_from_repo(\"extracted_data.csv\")\n\n    # Load the ArgDown test text\n    md_content = load_file_from_repo(\"ArgDown.md\")\n\n    print(\"✅ Successfully connected to repository and loaded test files.\")\nexcept Exception as e:\n    print(f\"❌ Error loading files: {str(e)}\")\n    print(\"Please check your internet connection and the repository URL.\")\n\n# Display preview of loaded content (commented out to avoid cluttering output)\nprint(md_content)\n\n\nConnecting to repository: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/\nAttempting to load: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/ArgDown.md\n✅ Successfully connected to repository and loaded test files.\n[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {\"instantiations\": [\"existential_catastrophe_TRUE\", \"existential_catastrophe_FALSE\"]}\n- [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {\"instantiations\": [\"human_disempowerment_TRUE\", \"human_disempowerment_FALSE\"]}\n    - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {\"instantiations\": [\"scale_of_power_seeking_TRUE\", \"scale_of_power_seeking_FALSE\"]}\n        - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n            - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {\"instantiations\": [\"aps_systems_TRUE\", \"aps_systems_FALSE\"]}\n                - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {\"instantiations\": [\"advanced_ai_capability_TRUE\", \"advanced_ai_capability_FALSE\"]}\n                - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {\"instantiations\": [\"agentic_planning_TRUE\", \"agentic_planning_FALSE\"]}\n                - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {\"instantiations\": [\"strategic_awareness_TRUE\", \"strategic_awareness_FALSE\"]}\n            - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {\"instantiations\": [\"difficulty_of_alignment_TRUE\", \"difficulty_of_alignment_FALSE\"]}\n                - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {\"instantiations\": [\"instrumental_convergence_TRUE\", \"instrumental_convergence_FALSE\"]}\n                - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {\"instantiations\": [\"problems_with_proxies_TRUE\", \"problems_with_proxies_FALSE\"]}\n                - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {\"instantiations\": [\"problems_with_search_TRUE\", \"problems_with_search_FALSE\"]}\n            - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {\"instantiations\": [\"deployment_decisions_DEPLOY\", \"deployment_decisions_WITHHOLD\"]}\n                - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {\"instantiations\": [\"incentives_to_build_aps_STRONG\", \"incentives_to_build_aps_WEAK\"]}\n                    - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {\"instantiations\": [\"usefulness_of_aps_HIGH\", \"usefulness_of_aps_LOW\"]}\n                    - [Competitive_Dynamics]: Competitive pressures between AI developers. {\"instantiations\": [\"competitive_dynamics_STRONG\", \"competitive_dynamics_WEAK\"]}\n                - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {\"instantiations\": [\"deception_by_ai_TRUE\", \"deception_by_ai_FALSE\"]}\n        - [Corrective_Feedback]: Human society implementing corrections after observing problems. {\"instantiations\": [\"corrective_feedback_EFFECTIVE\", \"corrective_feedback_INEFFECTIVE\"]}\n            - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {\"instantiations\": [\"warning_shots_OBSERVED\", \"warning_shots_UNOBSERVED\"]}\n            - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {\"instantiations\": [\"rapid_capability_escalation_TRUE\", \"rapid_capability_escalation_FALSE\"]}\n[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {\"instantiations\": [\"barriers_to_understanding_HIGH\", \"barriers_to_understanding_LOW\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {\"instantiations\": [\"adversarial_dynamics_TRUE\", \"adversarial_dynamics_FALSE\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {\"instantiations\": [\"stakes_of_error_HIGH\", \"stakes_of_error_LOW\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#title-amtair-prototype-demonstration-public-colab-notebook",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#title-amtair-prototype-demonstration-public-colab-notebook",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "B.1 title: AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "text": "B.1 title: AMTAIR Prototype Demonstration (Public Colab Notebook)\n:::\n\n\n# [AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)\n\n# AMTAIR Prototype: Automating Transformative AI Risk Modeling\n\n## Executive Summary\n\nThis notebook implements a prototype of the AMTAIR (Automating Transformative AI Risk Modeling) project, which addresses the critical coordination failure in AI governance by developing computational tools that automate the extraction of probabilistic world models from AI safety literature.\n\nThe prototype demonstrates the transformation pipeline from structured argument representations (ArgDown) to probabilistic Bayesian networks (BayesDown), enabling the visualization and analysis of causal relationships and probability distributions that underlie AI risk assessments and policy evaluations.\n\n### Purpose Within the Master's Thesis\n\nThis notebook serves as the technical implementation component of the Master's thesis \"Automating Transformative AI Risk Modeling: A Computational Approach to Policy Impact Evaluation.\" It demonstrates the feasibility of automating the extraction and formalization of world models, focusing on the core extraction pipeline and visualization capabilities that form the foundation for more sophisticated analysis.\n\n### Relevance to AI Governance\n\nThe coordination crisis in AI governance stems from different stakeholders working with incompatible assumptions, terminologies, and priorities. By making implicit models explicit through automated extraction and formalization, this work helps bridge communication gaps between technical researchers, policy specialists, and other stakeholders, contributing to more effective coordination in addressing existential risks from advanced AI.\n\n## Notebook Structure and Workflow\n\nThis notebook implements a multi-stage pipeline for transforming argument structures into interactive Bayesian network visualizations:\n\n1. **Environment Setup** (Sections 0.1-0.3): Establishes the technical environment with necessary libraries and data connections\n\n2. **Argument Extraction** (Sections 1.0-1.8): Processes source documents into structured ArgDown representations\n\n3. **Probability Integration** (Sections 2.0-2.8): Enhances ArgDown with probability information to create BayesDown\n\n4. **Data Transformation** (Section 3.0): Converts BayesDown into structured DataFrame format\n\n5. **Visualization and Analysis** (Section 4.0): Creates interactive Bayesian network visualizations\n\n6. **Archiving and Export** (Sections 5.0-6.0): Provides utilities for saving and sharing results\n\nThroughout this notebook, we use the classic rain-sprinkler-lawn example as a canonical test case, demonstrating how a simple causal scenario (rain and sprinkler use affecting wet grass) can be represented, processed, and visualized using our automated pipeline.\n\n## Project Context and Purpose\n\nThis notebook implements a prototype of the Automating Transformative AI Risk Modeling (AMTAIR) project, which addresses a critical coordination failure in AI governance by developing computational tools to automate the extraction of probabilistic world models from AI safety literature.\n\nThe coordination crisis in AI governance stems from different stakeholders (technical researchers, policy specialists, ethicists) operating with different terminologies, priorities, and implicit theories of change. This fragmentation systematically increases existential risk through safety gaps, resource misallocation, and capability-governance mismatches.\n\nThe AMTAIR project aims to bridge these divides by:\n1. Making implicit models explicit through automated extraction and formalization\n2. Enabling comparison across different worldviews\n3. Providing a common language for discussing probabilistic relationships\n4. Supporting policy evaluation across diverse scenarios\n\n## Notebook Overview and Pipeline\n\nThis notebook demonstrates the core extraction pipeline from structured argument representations (ArgDown) to probabilistic Bayesian networks (BayesDown), using the classic rain-sprinkler-lawn example as a canonical test case.\n\nThe pipeline consists of five main stages:\n1. **Environment Setup**: Libraries, GitHub repository access, and data loading\n2. **Argument Extraction**: Processing source documents into structured ArgDown format\n3. **Probability Integration**: Enhancing ArgDown with probabilistic information to create BayesDown\n4. **Data Transformation**: Converting BayesDown into structured DataFrame format\n5. **Visualization & Analysis**: Creating interactive Bayesian network visualizations\n\n## Connection to Master's Thesis\n\nThis notebook serves as the technical implementation component of the Master's thesis \"Automating Transformative AI Risk Modeling: A Computational Approach to Policy Impact Evaluation\" (see PY_Thesis_OutlineNDraft), demonstrating the feasibility of automating the process of extracting and formalizing world models from AI safety literature.\n\nThe thesis positions this work as a solution to the coordination crisis in AI governance, where the AMTAIR tools provide a crucial bridge between different stakeholder communities by creating formal representations that can be analyzed, compared, and used for policy evaluation.\n\nFor broader context on the project's motivation and placement within AI governance efforts, see PY_Post0.0 (\"The Missing Piece: Why We Need a Grand Strategy for AI\") and PY_AMTAIRDescription, which explain how this technical work contributes to the development of a comprehensive AI safety grand strategy.\n\n## Instructions --- How to use this notebook:\n\n\n1. **Import Libraries & Install Packages**: Run Section 0.1 to set up the necessary dependencies for data processing and visualization.\n\n2. **Connect to GitHub Repository & Load Data files**: Run Section 0.2 to establish connections to the data repository and load example datasets. This step retrieves sample ArgDown files and extracted data for demonstration.\n\n3. **Process Source Documents to ArgDown**: Sections 1.0-1.8 demonstrate the extraction of argument structures from source documents (such as PDFs) into ArgDown format, a markdown-like notation for structured arguments.\n\n4. **Convert ArgDown to BayesDown**: Sections 2.0-2.3 handle the transformation of ArgDown files into BayesDown format, which incorporates probabilistic information into the argument structure.\n\n5. **Extract Data into Structured Format**: Section 3.0 processes BayesDown format into structured database entries (CSV) that can be used for analysis.\n\n6. **Create and Analyze Bayesian Networks**: Section 4.0 demonstrates how to build Bayesian networks from the extracted data and provides tools for analyzing risk pathways.\n\n7. **Save and Export Results**: Sections 5.0-6.0 provide methods for archiving results and exporting visualizations.\n\n\n&gt;[AMTAIR Prototype Demonstration (Public Colab Notebook)](#scrollTo=lt8-AnebGUXr)\n\n&gt;[AMTAIR Prototype: Automating Transformative AI Risk Modeling](#scrollTo=iDy_leH6DJH_)\n\n&gt;&gt;[Executive Summary](#scrollTo=iDy_leH6DJH_)\n\n&gt;&gt;&gt;[Purpose Within the Master's Thesis](#scrollTo=iDy_leH6DJH_)\n\n&gt;&gt;&gt;[Relevance to AI Governance](#scrollTo=iDy_leH6DJH_)\n\n&gt;&gt;[Notebook Structure and Workflow](#scrollTo=iDy_leH6DJH_)\n\n&gt;&gt;[Project Context and Purpose](#scrollTo=Cm1JQGDYNJjf)\n\n&gt;&gt;[Notebook Overview and Pipeline](#scrollTo=Cm1JQGDYNJjf)\n\n&gt;&gt;[Connection to Master's Thesis](#scrollTo=Cm1JQGDYNJjf)\n\n&gt;&gt;[Instructions --- How to use this notebook:](#scrollTo=22NBzTxxsnfQ)\n\n&gt;&gt;[Key Concepts:](#scrollTo=NovjnOw6bzLi)\n\n&gt;&gt;[Example Workflow:](#scrollTo=NovjnOw6bzLi)\n\n&gt;&gt;[Troubleshooting:](#scrollTo=NovjnOw6bzLi)\n\n&gt;[Environment Setup and Data Access](#scrollTo=neYYoWhbNRIJ)\n\n&gt;[0.1 Prepare Colab/Python Environment --- Import Libraries & Packages](#scrollTo=GtVFO-s74vI_)\n\n&gt;&gt;[0.2 Connect to GitHub Repository](#scrollTo=2a3VR0fLhJow)\n\n&gt;&gt;[0.3 File Import](#scrollTo=y-ix4Rp5fE9m)\n\n&gt;[1.0 Sources (PDF's of Papers) to ArgDown (.md file)](#scrollTo=52XyPlte5HrU)\n\n&gt;[Sources to ArgDown: Structured Argument Extraction](#scrollTo=1-7O4KHfNU-e)\n\n&gt;&gt;[Process Overview](#scrollTo=1-7O4KHfNU-e)\n\n&gt;&gt;[What is ArgDown?](#scrollTo=1-7O4KHfNU-e)\n\n&gt;&gt;[1.1 Specify Source Document (e.g. PDF)](#scrollTo=ESKnZ_4f_a6y)\n\n&gt;&gt;[1.2 Generate ArgDown Extraction Prompt](#scrollTo=6ToQFra3_nl9)\n\n&gt;&gt;[1.3 Prepare LLM API Call](#scrollTo=pGv2KcZU_9Bn)\n\n&gt;&gt;[1.4 Make ArgDown Extraction LLM API Call](#scrollTo=i5xsDYnsAWC4)\n\n&gt;&gt;[1.5 Save ArgDown Extraction Response](#scrollTo=Lc2nMp8nAfeU)\n\n&gt;&gt;[1.6 Review and Check ArgDown.md File](#scrollTo=5HcCfqE4A0ht)\n\n&gt;&gt;[1.6.2 Check the Graph Structure with the ArgDown Sandbox Online](#scrollTo=gSpkvLbCC_PI)\n\n&gt;&gt;[1.7 Extract ArgDown Graph Information as DataFrame](#scrollTo=MAm0UKpeBvyr)\n\n&gt;&gt;[1.8 Store ArgDown Information as 'ArgDown.csv' file](#scrollTo=iFC6oiyICREn)\n\n&gt;[2.0 Probability Extractions: ArgDown (.csv) to BayesDown (.md + plugin JSON syntax)](#scrollTo=7SGB0XMp5VFq)\n\n&gt;[ArgDown to BayesDown: Adding Probability Information](#scrollTo=hWkmySZYNtzS)\n\n&gt;&gt;[Process Overview](#scrollTo=hWkmySZYNtzS)\n\n&gt;&gt;[What is BayesDown?](#scrollTo=hWkmySZYNtzS)\n\n&gt;&gt;[2.1 Probability Extraction Questions --- 'ArgDown.csv' to 'ArgDown_WithQuestions.csv'](#scrollTo=WcF2nHXBZru4)\n\n&gt;&gt;[2.2 'ArgDown_WithQuestions.csv' to 'BayesDownQuestions.md'](#scrollTo=-q9UOQ8yaBZn)\n\n&gt;&gt;[2.3 Generate BayesDown Probability Extraction Prompt](#scrollTo=Ux4OUCPue6Bu)\n\n&gt;&gt;[2.3.1 BayesDown Format Specification](#scrollTo=ivcnd2ml41Nv)\n\n&gt;&gt;&gt;[Core Structure](#scrollTo=ivcnd2ml41Nv)\n\n&gt;&gt;&gt;&gt;&gt;[Rain-Sprinkler-Lawn Example](#scrollTo=Fn72WmgVEOH0)\n\n&gt;&gt;[2.4 Prepare 2nd API call](#scrollTo=d4tB9WD-fIWZ)\n\n&gt;&gt;[2.5 Make BayesDown Probability Extraction API Call](#scrollTo=oPWto83lfN9Q)\n\n&gt;&gt;[2.6 Save BayesDown with Probability Estimates (.csv)](#scrollTo=L8NWpz8MfZ9_)\n\n&gt;&gt;[2.7 Review & Verify BayesDown Probability Estimates](#scrollTo=Q3PTtYgRfsLa)\n\n&gt;&gt;[2.7.2 Check the Graph Structure with the ArgDown Sandbox Online](#scrollTo=VwoAgBsafonh)\n\n&gt;&gt;[2.8 Extract BayesDown with Probability Estimates as Dataframe](#scrollTo=19KDn2mKf309)\n\n&gt;[3.0 Data Extraction: BayesDown (.md) to Database (.csv)](#scrollTo=vUSS00TCEpeW)\n\n&gt;[BayesDown to Structured Data: Network Construction](#scrollTo=vUSS00TCEpeW)\n\n&gt;&gt;[Extraction Pipeline Overview](#scrollTo=vUSS00TCEpeW)\n\n&gt;&gt;&gt;[Theoretical Foundation](#scrollTo=vUSS00TCEpeW)\n\n&gt;&gt;&gt;[Role in Thesis Research](#scrollTo=vUSS00TCEpeW)\n\n&gt;&gt;&gt;[3.1 ExtractBayesDown-Data_v1](#scrollTo=AFnu_1Ludahi)\n\n&gt;&gt;[3.1.2 Test BayesDown Extraction](#scrollTo=eUBJh8Qp4yd4)\n\n&gt;&gt;[3.1.2.2 Check the Graph Structure with the ArgDown Sandbox Online](#scrollTo=z4Hgs0ICDQyW)\n\n&gt;&gt;[3.3 Extraction](#scrollTo=mv8f4c4D3yJj)\n\n&gt;&gt;&gt;[3.3 Data-Post-Processing](#scrollTo=UcXf3fZ8dahj)\n\n&gt;&gt;&gt;[3.4 Download and save finished data frame as .csv file](#scrollTo=xTwPO_J-dahj)\n\n&gt;[4.0 Analysis & Inference: Bayesian Network Visualization](#scrollTo=t3zl7vKMECMg)\n\n&gt;&gt;[Bayesian Network Visualization Approach](#scrollTo=t3zl7vKMECMg)\n\n&gt;&gt;&gt;[Visualization Philosophy](#scrollTo=t3zl7vKMECMg)\n\n&gt;&gt;&gt;[Connection to AMTAIR Goals](#scrollTo=t3zl7vKMECMg)\n\n&gt;&gt;&gt;[Implementation Structure](#scrollTo=t3zl7vKMECMg)\n\n&gt;&gt;[Phase 1: Dependencies/Functions](#scrollTo=LSeSAPvtgIgU)\n\n&gt;&gt;[Phase 2: Node Classification and Styling Module](#scrollTo=byAExfek5yFU)\n\n&gt;&gt;[Phase 3: HTML Content Generation Module](#scrollTo=gnS3jFGU52OZ)\n\n&gt;&gt;[Phase 4: Main Visualization Function](#scrollTo=d2uyG0Pi571f)\n\n&gt;[Quickly check HTML Outputs](#scrollTo=bFtxTKmLElSF)\n\n&gt;[Conclusion: From Prototype to Production](#scrollTo=oatKYlKrOSiN)\n\n&gt;&gt;[Summary of Achievements](#scrollTo=oatKYlKrOSiN)\n\n&gt;&gt;[Limitations and Future Work](#scrollTo=oatKYlKrOSiN)\n\n&gt;&gt;[Connection to AMTAIR Project](#scrollTo=oatKYlKrOSiN)\n\n&gt;[6.0 Save Outputs](#scrollTo=kjbIj19epbrF)\n\n&gt;[Saving and Exporting Results](#scrollTo=0QqlN6dYpm4s)\n\n&gt;&gt;[Convert .ipynb Notebook to MarkDown](#scrollTo=pS6AhdiSCLw4)\n\n\n\n## Key Concepts:\n\n- **ArgDown**: A structured format for representing arguments, with hierarchical relationships between statements.\n- **BayesDown**: An extension of ArgDown that incorporates probabilistic information, allowing for Bayesian network construction.\n- **Extraction Pipeline**: The process of converting unstructured text to structured argument representations.\n- **Bayesian Networks**: Probabilistic graphical models that represent variables and their conditional dependencies.\n\n## Example Workflow:\n\n1. Load a sample ArgDown file from the repository\n2. Extract the hierarchical structure and relationships\n3. Add probabilistic information to create a BayesDown representation\n4. Generate a Bayesian network visualization\n5. Analyze conditional probabilities and risk pathways\n\n## Troubleshooting:\n\n- If connectivity issues occur, ensure you have access to the GitHub repository\n- For visualization errors, check that all required libraries are properly installed\n- When processing custom files, ensure they follow the expected format conventions\n\n# 0. Environment Setup and Data Access\n\nThis section establishes the technical foundation for the AMTAIR prototype by:\n1. Installing and importing necessary libraries\n2. Setting up access to the GitHub repository\n3. Loading example data files\n\nThe environment setup is designed to be run once per session, with flags to prevent redundant installations and imports. This section forms the basis for the subsequent extraction and analysis steps in the pipeline.\n\nThe key goal is to create a reproducible environment where the Bayesian network extraction and visualization can be performed consistently, with appropriate error handling and resource management.\n\n# 0.1 Prepare Colab/Python Environment --- Import Libraries & Packages\n\n::: {#cell-9 .cell quarto-private-1='{\"key\":\"colab\",\"value\":{\"base_uri\":\"https://localhost:8080/\"}}' outputId='b474c7e1-0e7e-47f3-a546-9321cff91a6e'}\n``` {.python .cell-code}\n# @title 0.1 --- Install & Import Libraries & Packages (One-Time Setup) ---\n\n\"\"\"\nBLOCK PURPOSE: Establishes the core technical environment for the AMTAIR prototype.\nSets up all required libraries for Bayesian network processing, visualization, and data manipulation.\nUses a flag-based approach to ensure setup only runs once per session, enhancing efficiency.\n\nThe setup follows a three-stage process:\n1. Install required packages not available in Colab by default\n2. Import all necessary libraries with error handling\n3. Set a global flag to prevent redundant execution\n\nDEPENDENCIES: Requires internet connection for package installation\nOUTPUTS: Global variable _setup_imports_done and loaded Python libraries\n\"\"\"\n\n#  Check if setup has already been completed in this session using environment flag\ntry:\n    # If this variable exists, setup was already done successfully\n    _setup_imports_done\n    print(\"✅ Libraries already installed and imported in this session. Skipping setup.\")\n\nexcept NameError:\n    print(\"⏳ Performing one-time library installation and imports...\")\n\n    # --- STAGE 1: Install required packages ---\n    # Install visualization and network analysis libraries\n    !pip install -q pyvis  # Network visualization library\n    !apt-get install pandoc -y  # Document conversion utility\n\n    # Install Google API and data processing packages\n    !pip install -q --upgrade gspread pandas google-auth google-colab  # Data manipulation and Google integration\n\n    # Install Bayesian network and probabilistic modeling tools\n    !pip install -q pgmpy  # Probabilistic graphical models library\n\n    # Install notebook conversion tools\n    !pip install -q nbconvert  # Often pre-installed, but ensures availability\n\n    print(\"   --&gt; Installations complete.\")\n\n    # --- STAGE 2: Import libraries with error handling ---\n    try:\n        # Network and HTTP libraries\n        import requests      # For making HTTP requests to APIs and GitHub\n        import io            # For handling in-memory file-like objects\n\n        # Data processing libraries\n        import pandas as pd  # For structured data manipulation\n        import numpy as np   # For numerical operations\n        import json          # For JSON parsing and serialization\n        import re            # For regular expression pattern matching\n\n        # Visualization libraries\n        import matplotlib.pyplot as plt  # For creating plots and charts\n        from IPython.display import HTML, display, Markdown  # For rich output in notebook\n\n        # --- Specialized libraries requiring installation ---\n        # Network analysis library\n        import networkx as nx  # For graph representation and analysis\n\n        # Probabilistic modeling libraries\n        from pgmpy.models import BayesianNetwork  # For Bayesian network structure\n        from pgmpy.factors.discrete import TabularCPD  # For conditional probability tables\n        from pgmpy.inference import VariableElimination  # For probabilistic inference\n\n        # Interactive network visualization\n        from pyvis.network import Network  # For interactive network visualization\n\n        # Output version information for key libraries\n        print(f\"      pandas version: {pd.__version__}\")\n        print(f\"      networkx version: {nx.__version__}\")\n        # Add others if specific versions are critical\n\n        print(\"   --&gt; Imports complete.\")\n\n        # --- STAGE 3: Set flag to indicate successful setup ---\n        _setup_imports_done = True\n        print(\"✅ One-time setup finished successfully.\")\n\n    except ImportError as e:\n        # Handle specific import failures\n        print(f\"❌ ERROR during import: {e}\")\n        print(\"   --&gt; Setup did not complete successfully. Please check installations.\")\n    except Exception as e:\n        # Handle unexpected errors\n        print(f\"❌ UNEXPECTED ERROR during setup: {e}\")\n        print(\"   --&gt; Setup did not complete successfully.\")\n\n# Environment is now ready for AMTAIR processing\n\n✅ Libraries already installed and imported in this session. Skipping setup.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#file-import",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#file-import",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "B.3 0.3 File Import",
    "text": "B.3 0.3 File Import\n\n\nCode\n# @title\nmd_content\n\n\n'[Existential_Catastrophe]: The destruction of humanity\\'s long-term potential due to AI systems we\\'ve lost control over. {\"instantiations\": [\"existential_catastrophe_TRUE\", \"existential_catastrophe_FALSE\"]}\\n- [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {\"instantiations\": [\"human_disempowerment_TRUE\", \"human_disempowerment_FALSE\"]}\\n    - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {\"instantiations\": [\"scale_of_power_seeking_TRUE\", \"scale_of_power_seeking_FALSE\"]}\\n        - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\\n            - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {\"instantiations\": [\"aps_systems_TRUE\", \"aps_systems_FALSE\"]}\\n                - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {\"instantiations\": [\"advanced_ai_capability_TRUE\", \"advanced_ai_capability_FALSE\"]}\\n                - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {\"instantiations\": [\"agentic_planning_TRUE\", \"agentic_planning_FALSE\"]}\\n                - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {\"instantiations\": [\"strategic_awareness_TRUE\", \"strategic_awareness_FALSE\"]}\\n            - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {\"instantiations\": [\"difficulty_of_alignment_TRUE\", \"difficulty_of_alignment_FALSE\"]}\\n                - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {\"instantiations\": [\"instrumental_convergence_TRUE\", \"instrumental_convergence_FALSE\"]}\\n                - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {\"instantiations\": [\"problems_with_proxies_TRUE\", \"problems_with_proxies_FALSE\"]}\\n                - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {\"instantiations\": [\"problems_with_search_TRUE\", \"problems_with_search_FALSE\"]}\\n            - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {\"instantiations\": [\"deployment_decisions_DEPLOY\", \"deployment_decisions_WITHHOLD\"]}\\n                - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {\"instantiations\": [\"incentives_to_build_aps_STRONG\", \"incentives_to_build_aps_WEAK\"]}\\n                    - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {\"instantiations\": [\"usefulness_of_aps_HIGH\", \"usefulness_of_aps_LOW\"]}\\n                    - [Competitive_Dynamics]: Competitive pressures between AI developers. {\"instantiations\": [\"competitive_dynamics_STRONG\", \"competitive_dynamics_WEAK\"]}\\n                - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {\"instantiations\": [\"deception_by_ai_TRUE\", \"deception_by_ai_FALSE\"]}\\n        - [Corrective_Feedback]: Human society implementing corrections after observing problems. {\"instantiations\": [\"corrective_feedback_EFFECTIVE\", \"corrective_feedback_INEFFECTIVE\"]}\\n            - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {\"instantiations\": [\"warning_shots_OBSERVED\", \"warning_shots_UNOBSERVED\"]}\\n            - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {\"instantiations\": [\"rapid_capability_escalation_TRUE\", \"rapid_capability_escalation_FALSE\"]}\\n[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {\"instantiations\": [\"barriers_to_understanding_HIGH\", \"barriers_to_understanding_LOW\"]}\\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\\n[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {\"instantiations\": [\"adversarial_dynamics_TRUE\", \"adversarial_dynamics_FALSE\"]}\\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\\n[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {\"instantiations\": [\"stakes_of_error_HIGH\", \"stakes_of_error_LOW\"]}\\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\\n'",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#process-overview",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#process-overview",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "D.1 Process Overview",
    "text": "D.1 Process Overview\nThis section implements the first major stage of the AMTAIR pipeline: transforming source documents (such as research papers, blog posts, or expert analyses) into structured argument representations using the ArgDown format.\nArgDown is a markdown-like notation for representing arguments in a hierarchical structure. In the context of AMTAIR, it serves as the first step toward creating formal Bayesian networks by: 1. Identifying key variables/statements in the text 2. Capturing their hierarchical relationships 3. Preserving their descriptive content 4. Defining their possible states (instantiations)\nThe extraction process uses Large Language Models (LLMs) to identify the structure and relationships in the text, though in this notebook we focus on processing pre-formatted examples rather than performing the full extraction from raw text.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#what-is-argdown",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#what-is-argdown",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "D.2 What is ArgDown?",
    "text": "D.2 What is ArgDown?\nArgDown uses a simple syntax where: - Statements are represented as [Statement]: Description - Relationships are indicated with + symbols and indentation - Metadata is added in JSON format, including possible states of each variable\nFor example:\n[MainClaim]: Description of the main claim. {\"instantiations\": [\"claim_TRUE\", \"claim_FALSE\"]}\n\n + [SupportingEvidence]: Description of evidence. {\"instantiations\": [\"evidence_TRUE\", \"evidence_FALSE\"]}\nThis structure will later be enhanced with probability information to create BayesDown, which can be transformed into a Bayesian network for analysis and visualization.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#specify-source-document-e.g.-pdf",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#specify-source-document-e.g.-pdf",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "D.3 1.1 Specify Source Document (e.g. PDF)",
    "text": "D.3 1.1 Specify Source Document (e.g. PDF)\nReview the source document, ensure it is suitable for API call and upload to / store it in the correct location.\n\n\nCode\n# @title 1.1.a) --- MTAIR Online Model (Analytica) ---\n\nfrom IPython.display import IFrame\n\nIFrame(src=\"https://acp.analytica.com/view0?invite=4560&code=3000289064591444815\", width=\"100%\", height=\"900px\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#generate-argdown-extraction-prompt",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#generate-argdown-extraction-prompt",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "D.4 1.2 Generate ArgDown Extraction Prompt",
    "text": "D.4 1.2 Generate ArgDown Extraction Prompt\nGenerate Extraction Prompt\n\n\nCode\n# @title 1.2.0 --- Prompt Template Function Definitions ---\n\n\"\"\"\nBLOCK PURPOSE: Defines a flexible template system for LLM prompts used in the extraction pipeline.\n\nThis block implements two key classes:\n1. PromptTemplate: A simple template class supporting variable substitution for dynamic prompts\n2. PromptLibrary: A collection of pre-defined prompt templates for different extraction tasks\n\nThese templates are used in the ArgDown extraction and BayesDown probability extraction\nstages of the pipeline, providing consistent and well-structured prompts to the LLMs.\n\nDEPENDENCIES: string.Template for variable substitution\nOUTPUTS: PromptTemplate and PromptLibrary classes\n\"\"\"\n\nfrom string import Template\nfrom typing import Dict, Optional, Union, List\n\nclass PromptTemplate:\n    \"\"\"Template system for LLM prompts with variable substitution\"\"\"\n\n    def __init__(self, template: str):\n        \"\"\"Initialize with template string using $variable format\"\"\"\n        self.template = Template(template)\n\n    def format(self, **kwargs) -&gt; str:\n        \"\"\"Substitute variables in the template\"\"\"\n        return self.template.safe_substitute(**kwargs)\n\n    @classmethod\n    def from_file(cls, filepath: str) -&gt; 'PromptTemplate':\n        \"\"\"Load template from a file\"\"\"\n        with open(filepath, 'r') as f:\n            template = f.read()\n        return cls(template)\n\nclass PromptLibrary:\n    \"\"\"Collection of prompt templates for different extraction tasks\"\"\"\n\n    # ArgDown extraction prompt - transforms source text into structured argument map\n    ARGDOWN_EXTRACTION = PromptTemplate(\"\"\"\nYou are participating in the AMTAIR (Automating Transformative AI Risk Modeling) project and you are tasked with converting natural language arguments into ArgDown syntax by extracting and formalizing causal world models from unstructured text.\nYour specific task is to extract the implicit causal model from the provided document in structured ArgDown format.\n\n## Epistemic Foundation & Purpose\n\nThis extraction represents one possible interpretation of the implicit causal model in the document. Multiple extractions from the same text help reveal patterns of convergence (where the model is clearly articulated) and divergence (where the model contains ambiguities). This approach acknowledges that expert texts often contain implicit rather than explicit causal models.\n\nYour role is to reveal the causal structure already present in the author's thinking, maintaining epistemic humility about your interpretation while adhering strictly to the required format.\n\n## ArgDown Format Specification\n\n### Core Syntax\n\nArgDown represents causal relationships using a hierarchical structure:\n\n1. Variables appear in square brackets with descriptive text:\n   `[Variable_Name]: Description of the variable.`\n\n2. Causal relationships use indentation (2 spaces per level) and '+' symbols:\n\n[Effect]: Description of effect. + [Cause]: Description of cause. + [Deeper_Cause]: Description of deeper cause.\n\n3. Causality flows from bottom (more indented) to top (less indented):\n- More indented variables (causes) influence less indented variables (effects)\n- The top-level variable is the ultimate effect or outcome\n- Deeper indentation levels represent root causes or earlier factors\n\n4. Each variable must include JSON metadata with possible states (instantiations):\n`[Variable]: Description. {\"instantiations\": [\"variable_STATE1\", \"variable_STATE2\"]}`\n\n### JSON Metadata Format\n\nThe JSON metadata must follow this exact structure:\n\n```json\n{\"instantiations\": [\"variable_STATE1\", \"variable_STATE2\"]}\n\nRequirements:\n* Double quotes (not single) around field names and string values\n* Square brackets enclosing the instantiations array\n* Comma separation between array elements\n* No trailing comma after the last element\n* Must be valid JSON syntax that can be parsed by standard JSON parsers\n\nFor binary variables (most common case):\n{\"instantiations\": [\"variable_TRUE\", \"variable_FALSE\"]}\n\nFor multi-state variables (when clearly specified in the text):\n{\"instantiations\": [\"variable_HIGH\", \"variable_MEDIUM\", \"variable_LOW\"]}\n\nThe metadata must appear on the same line as the variable definition, after the description.\n## Complex Structural Patterns\n### Variables Influencing Multiple Effects\nThe same variable can appear multiple times in different places in the hierarchy if it influences multiple effects:\n[Effect1]: First effect description. {\"instantiations\": [\"effect1_TRUE\", \"effect1_FALSE\"]}\n  + [Cause_A]: Description of cause A. {\"instantiations\": [\"cause_a_TRUE\", \"cause_a_FALSE\"]}\n\n[Effect2]: Second effect description. {\"instantiations\": [\"effect2_TRUE\", \"effect2_FALSE\"]}\n  + [Cause_A]\n  + [Cause_B]: Description of cause B. {\"instantiations\": [\"cause_b_TRUE\", \"cause_b_FALSE\"]}\n\n### Multiple Causes of the Same Effect\nMultiple causes can influence the same effect by being listed at the same indentation level:\n[Effect]: Description of effect. {\"instantiations\": [\"effect_TRUE\", \"effect_FALSE\"]}\n  + [Cause1]: Description of first cause. {\"instantiations\": [\"cause1_TRUE\", \"cause1_FALSE\"]}\n  + [Cause2]: Description of second cause. {\"instantiations\": [\"cause2_TRUE\", \"cause2_FALSE\"]}\n    + [Deeper_Cause]: A cause that influences Cause2. {\"instantiations\": [\"deeper_cause_TRUE\", \"deeper_cause_FALSE\"]}\n\n### Causal Chains\nCausal chains are represented through multiple levels of indentation:\n[Ultimate_Effect]: The final outcome. {\"instantiations\": [\"ultimate_effect_TRUE\", \"ultimate_effect_FALSE\"]}\n  + [Intermediate_Effect]: A mediating variable. {\"instantiations\": [\"intermediate_effect_TRUE\", \"intermediate_effect_FALSE\"]}\n    + [Root_Cause]: The initial cause. {\"instantiations\": [\"root_cause_TRUE\", \"root_cause_FALSE\"]}\n  + [2nd_Intermediate_Effect]: A mediating variable. {\"instantiations\": [\"intermediate_effect_TRUE\", \"intermediate_effect_FALSE\"]}\n\n\n### Common Cause of Multiple Variables\nA common cause affecting multiple variables is represented by referencing the same variable in multiple places:\n[Effect1]: First effect description. {\"instantiations\": [\"effect1_TRUE\", \"effect1_FALSE\"]}\n  + [Common_Cause]: Description of common cause. {\"instantiations\": [\"common_cause_TRUE\", \"common_cause_FALSE\"]}\n\n[Effect2]: Second effect description. {\"instantiations\": [\"effect2_TRUE\", \"effect2_FALSE\"]}\n  + [Common_Cause]\n\n## Detailed Extraction Workflow\nPlease follow this step-by-step process, documenting your reasoning in XML tags:\n&lt;analysis&gt;\nFirst, conduct a holistic analysis of the document:\n1. Identify the main subject matter or domain\n2. Note key concepts, variables, and factors discussed\n3. Pay attention to language indicating causal relationships (causes, affects, influences, depends on, etc.)\n4. Look for the ultimate outcomes or effects that are the focus of the document\n5. Record your general understanding of the document's implicit causal structure\n&lt;/analysis&gt;\n&lt;variable_identification&gt;\nNext, identify and list the key variables in the causal model:\n* Focus on factors that are discussed as having an influence or being influenced\n* For each variable:\n  * Create a descriptive name in [square_brackets]\n  * Write a concise description based directly on the text\n  * Determine possible states (usually binary TRUE/FALSE unless clearly specified)\n* Distinguish between:\n  * Outcome variables (effects the author is concerned with)\n  * Intermediate variables (both causes and effects in chains)\n  * Root cause variables (exogenous factors in the model)\n* List all identified variables with their descriptions and possible states\n&lt;/variable_identification&gt;\n\n&lt;causal_structure&gt;\nThen, determine the causal relationships between variables:\n* For each variable, identify what factors influence it\n* Note the direction of causality (what causes what)\n* Look for mediating variables in causal chains\n* Identify common causes of multiple effects\n* Capture feedback loops if present (though they must be represented as DAGs)\n* Map out the hierarchical structure of the causal model\n&lt;/causal_structure&gt;\n\n&lt;format_conversion&gt;\nNow, convert your analysis into proper ArgDown format:\n* Start with the ultimate outcome variables at the top level\n* Place direct causes indented below with \\+ symbols\n* Continue with deeper causes at further indentation levels\n* Add variable descriptions and instantiations metadata\n* Ensure variables appearing in multiple places have consistent names\n* Check that the entire structure forms a valid directed acyclic graph\n&lt;/format_conversion&gt;\n\n&lt;validation&gt;\n\nFinally, review your extraction for quality and format correctness:\n1. Verify all variables have properly formatted metadata\n2. Check that indentation properly represents causal direction\n3. Confirm the extraction accurately reflects the document's implicit model\n4. Ensure no cycles exist in the causal structure\n5. Verify that variables referenced multiple times are consistent\n6. Check that the extraction would be useful for subsequent analysis\n\n&lt;/validation&gt;\n\n\n## Source Document Analysis Guidance\nWhen analyzing the source document:\n* Focus on revealing the author's own causal model, not imposing an external framework\n* Maintain the author's terminology where possible\n* Look for both explicit statements of causality and implicit assumptions\n* Pay attention to the relative importance the author assigns to different factors\n* Notice where the author expresses certainty versus uncertainty\n* Consider the level of granularity appropriate to the document's own analysis\n\nRemember that your goal is to make the implicit model explicit, not to evaluate or improve it.\nThe value lies in accurately representing the author's perspective, even if you might personally disagree or see limitations in their model.\n\n\"\"\")\n\n    # BayesDown probability extraction prompt - enhances ArgDown with probability information\n    BAYESDOWN_EXTRACTION = PromptTemplate(\"\"\"\nYou are an expert in probabilistic reasoning and Bayesian networks. Your task is to extend the provided ArgDown structure with probability information, creating a BayesDown representation.\n\nFor each statement in the ArgDown structure, you need to:\n1. Estimate prior probabilities for each possible state\n2. Estimate conditional probabilities given parent states\n3. Maintain the original structure and relationships\n\nHere is the format to follow:\n[Node]: Description. { \"instantiations\": [\"node_TRUE\", \"node_FALSE\"], \"priors\": { \"p(node_TRUE)\": \"0.7\", \"p(node_FALSE)\": \"0.3\" }, \"posteriors\": { \"p(node_TRUE|parent_TRUE)\": \"0.9\", \"p(node_TRUE|parent_FALSE)\": \"0.4\", \"p(node_FALSE|parent_TRUE)\": \"0.1\", \"p(node_FALSE|parent_FALSE)\": \"0.6\" } }\n [Parent]: Parent description. {...}\n\n\nHere are the specific probability questions to answer:\n$questions\n\nArgDown structure to enhance:\n$argdown\n\nProvide the complete BayesDown representation with probabilities:\n\"\"\")\n\n    @classmethod\n    def get_template(cls, template_name: str) -&gt; PromptTemplate:\n        \"\"\"Get a prompt template by name\"\"\"\n        if hasattr(cls, template_name):\n            return getattr(cls, template_name)\n        else:\n            raise ValueError(f\"Template not found: {template_name}\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#prepare-llm-api-call",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#prepare-llm-api-call",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "D.5 1.3 Prepare LLM API Call",
    "text": "D.5 1.3 Prepare LLM API Call\nCombine Systemprompt + API Specifications + ArgDown Instructions + Prompt + Source PDF for API Call\n\n\nCode\n# @title 1.3.0 --- Provider-Agnostic LLM API Interface ---\n\n\"\"\"\nBLOCK PURPOSE: Provides a unified interface for interacting with different LLM providers.\n\nThis block implements a flexible, provider-agnostic system for making LLM API calls:\n1. Base abstract class (LLMProvider) defining the common interface\n2. Implementation classes for specific providers (OpenAI and Anthropic)\n3. Factory class for creating appropriate provider instances\n\nThis abstraction allows the extraction pipeline to work with different LLM providers\nwithout changing the core code, supporting both current and future LLM backends.\n\nDEPENDENCIES: requests for API calls, os for environment variables, abstract base classes\nOUTPUTS: LLMProvider abstract class and concrete implementations for OpenAI and Anthropic\n\"\"\"\n\nimport os\nimport json\nimport time\nimport requests\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, List, Optional, Union, Any\nfrom dataclasses import dataclass\n\n@dataclass\nclass LLMResponse:\n    \"\"\"Standard response object for LLM completions\"\"\"\n    content: str            # The generated text response\n    model: str              # The model used for generation\n    usage: Dict[str, int]   # Token usage statistics\n    raw_response: Dict[str, Any]  # Complete provider-specific response\n    created_at: float = time.time()  # Timestamp of response creation\n\nclass LLMProvider(ABC):\n    \"\"\"Abstract base class for LLM providers\"\"\"\n\n    @abstractmethod\n    def complete(self,\n                prompt: str,\n                system_prompt: Optional[str] = None,\n                temperature: float = 0.7,\n                max_tokens: int = 4000) -&gt; LLMResponse:\n        \"\"\"Generate a completion from the LLM\"\"\"\n        pass\n\n    @abstractmethod\n    def get_available_models(self) -&gt; List[str]:\n        \"\"\"Return a list of available models from this provider\"\"\"\n        pass\n\nclass OpenAIProvider(LLMProvider):\n    \"\"\"OpenAI API implementation\"\"\"\n\n    def __init__(self, api_key: Optional[str] = None, organization: Optional[str] = None):\n        \"\"\"Initialize with API key from args or environment\"\"\"\n        self.api_key = api_key or os.environ.get(\"OPENAI_API_KEY\")\n        if not self.api_key:\n            raise ValueError(\"OpenAI API key is required. Provide as argument or set OPENAI_API_KEY environment variable.\")\n\n        self.organization = organization or os.environ.get(\"OPENAI_ORGANIZATION\")\n        self.api_base = \"https://api.openai.com/v1\"\n\n    def complete(self,\n                prompt: str,\n                system_prompt: Optional[str] = None,\n                model: str = \"gpt-4-turbo\",\n                temperature: float = 0.7,\n                max_tokens: int = 4000) -&gt; LLMResponse:\n        \"\"\"Generate a completion using OpenAI's API\"\"\"\n\n        # Prepare request headers\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.api_key}\"\n        }\n\n        if self.organization:\n            headers[\"OpenAI-Organization\"] = self.organization\n\n        # Create message structure\n        messages = []\n        if system_prompt:\n            messages.append({\"role\": \"system\", \"content\": system_prompt})\n\n        messages.append({\"role\": \"user\", \"content\": prompt})\n\n        # Prepare request data\n        data = {\n            \"model\": model,\n            \"messages\": messages,\n            \"temperature\": temperature,\n            \"max_tokens\": max_tokens\n        }\n\n        # Make API call\n        response = requests.post(\n            f\"{self.api_base}/chat/completions\",\n            headers=headers,\n            json=data\n        )\n\n        response.raise_for_status()\n        result = response.json()\n\n        # Transform into standardized response format\n        return LLMResponse(\n            content=result[\"choices\"][0][\"message\"][\"content\"],\n            model=result[\"model\"],\n            usage=result[\"usage\"],\n            raw_response=result\n        )\n\n    def get_available_models(self) -&gt; List[str]:\n        \"\"\"Return a list of available OpenAI models\"\"\"\n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\"\n        }\n\n        if self.organization:\n            headers[\"OpenAI-Organization\"] = self.organization\n\n        response = requests.get(\n            f\"{self.api_base}/models\",\n            headers=headers\n        )\n\n        response.raise_for_status()\n        models = response.json()[\"data\"]\n        return [model[\"id\"] for model in models]\n\nclass AnthropicProvider(LLMProvider):\n    \"\"\"Anthropic Claude API implementation\"\"\"\n\n    def __init__(self, api_key: Optional[str] = None):\n        \"\"\"Initialize with API key from args or environment\"\"\"\n        self.api_key = api_key or os.environ.get(\"ANTHROPIC_API_KEY\")\n        if not self.api_key:\n            raise ValueError(\"Anthropic API key is required. Provide as argument or set ANTHROPIC_API_KEY environment variable.\")\n\n        self.api_base = \"https://api.anthropic.com/v1\"\n\n    def complete(self,\n                prompt: str,\n                system_prompt: Optional[str] = None,\n                model: str = \"claude-3-opus-20240229\",\n                temperature: float = 0.7,\n                max_tokens: int = 4000) -&gt; LLMResponse:\n        \"\"\"Generate a completion using Anthropic's API\"\"\"\n\n        # Prepare request headers\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"X-API-Key\": self.api_key,\n            \"anthropic-version\": \"2023-06-01\"\n        }\n\n        # Prepare request data in Anthropic-specific format\n        data = {\n            \"model\": model,\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n            \"temperature\": temperature,\n            \"max_tokens\": max_tokens\n        }\n\n        # Add system prompt if provided (Anthropic uses a different format)\n        if system_prompt:\n            data[\"system\"] = system_prompt\n\n        # Make API call\n        response = requests.post(\n            f\"{self.api_base}/messages\",\n            headers=headers,\n            json=data\n        )\n\n        response.raise_for_status()\n        result = response.json()\n\n        # Transform into standardized response format\n        return LLMResponse(\n            content=result[\"content\"][0][\"text\"],\n            model=result[\"model\"],\n            usage={\"prompt_tokens\": result.get(\"usage\", {}).get(\"input_tokens\", 0),\n                   \"completion_tokens\": result.get(\"usage\", {}).get(\"output_tokens\", 0)},\n            raw_response=result\n        )\n\n    def get_available_models(self) -&gt; List[str]:\n        \"\"\"Return a list of available Anthropic models\"\"\"\n        # Anthropic doesn't have a models endpoint, so we return a static list\n        return [\n            \"claude-3-opus-20240229\",\n            \"claude-3-sonnet-20240229\",\n            \"claude-3-haiku-20240307\"\n        ]\n\nclass LLMFactory:\n    \"\"\"Factory for creating LLM providers\"\"\"\n\n    @staticmethod\n    def create_provider(provider_name: str, **kwargs) -&gt; LLMProvider:\n        \"\"\"Create and return an LLM provider instance\"\"\"\n        if provider_name.lower() == \"openai\":\n            return OpenAIProvider(**kwargs)\n        elif provider_name.lower() == \"anthropic\":\n            return AnthropicProvider(**kwargs)\n        else:\n            raise ValueError(f\"Unsupported provider: {provider_name}\")\n\n\n\n\nCode\n# @title 1.3.0 --- API Call Function Definitions ---\n\n\"\"\"\nBLOCK PURPOSE: Provides core functions for extracting ArgDown representations from text using LLMs.\n\nThis block implements the main extraction functionality:\n1. extract_argdown_from_text: Sends text to LLM to extract structured ArgDown representation\n2. validate_argdown: Verifies the extracted ArgDown for correctness and completeness\n3. process_source_document: Handles source files (PDF, TXT, MD) and manages extraction\n4. save_argdown_extraction: Saves extraction results with metadata for further processing\n\nThese functions form the first stage of the AMTAIR pipeline, transforming\nunstructured text into structured argument representations.\n\nDEPENDENCIES: LLMFactory from previous cell, re for pattern matching\nOUTPUTS: Functions for ArgDown extraction, validation, and storage\n\"\"\"\n\ndef extract_argdown_from_text(text: str, provider_name: str = \"openai\", model: str = None) -&gt; str:\n    \"\"\"\n    Extract ArgDown representation from text using LLM\n\n    Args:\n        text: The source text to extract arguments from\n        provider_name: The LLM provider to use (openai or anthropic)\n        model: Specific model to use, or None for default\n\n    Returns:\n        Extracted ArgDown representation\n    \"\"\"\n    # Create LLM provider\n    provider = LLMFactory.create_provider(provider_name)\n\n    # Get extraction prompt\n    prompt_template = PromptLibrary.get_template(\"ARGDOWN_EXTRACTION\")\n    prompt = prompt_template.format(text=text)\n\n    # Set model-specific parameters\n    if provider_name.lower() == \"openai\":\n        model = model or \"gpt-4-turbo\"\n        temperature = 0.3  # Lower temperature for more deterministic extraction\n        max_tokens = 4000\n    elif provider_name.lower() == \"anthropic\":\n        model = model or \"claude-3-opus-20240229\"\n        temperature = 0.2\n        max_tokens = 4000\n\n    # Call the LLM\n    system_prompt = \"You are an expert in argument mapping and causal reasoning.\"\n    response = provider.complete(\n        prompt=prompt,\n        system_prompt=system_prompt,\n        model=model,\n        temperature=temperature,\n        max_tokens=max_tokens\n    )\n\n    # Extract the ArgDown content (remove any markdown code blocks if present)\n    argdown_content = response.content\n    if \"```\" in argdown_content:\n        # Extract content between code blocks if present\n        import re\n        matches = re.findall(r\"```(?:argdown)?\\n([\\s\\S]*?)\\n```\", argdown_content)\n        if matches:\n            argdown_content = matches[0]\n\n    return argdown_content\n\ndef validate_argdown(argdown_text: str) -&gt; Dict[str, Any]:\n    \"\"\"\n    Validate ArgDown representation to ensure it's well-formed\n\n    Args:\n        argdown_text: ArgDown representation to validate\n\n    Returns:\n        Dictionary with validation results\n    \"\"\"\n    # Initialize validation results\n    results = {\n        \"is_valid\": True,\n        \"errors\": [],\n        \"warnings\": [],\n        \"stats\": {\n            \"node_count\": 0,\n            \"relationship_count\": 0,\n            \"max_depth\": 0\n        }\n    }\n\n    # Basic syntax checks\n    lines = argdown_text.split(\"\\n\")\n    node_pattern = r'\\[(.*?)\\]:'\n    instantiation_pattern = r'{\"instantiations\":'\n\n    # Track nodes and relationships\n    nodes = set()\n    relationships = []\n    current_depth = 0\n    max_depth = 0\n\n    for i, line in enumerate(lines):\n        # Skip empty lines\n        if not line.strip():\n            continue\n\n        # Calculate indentation depth\n        indent = 0\n        if '+' in line:\n            indent = line.find('+') // 2\n\n        current_depth = indent\n        max_depth = max(max_depth, current_depth)\n\n        # Check for node definitions\n        import re\n        node_matches = re.findall(node_pattern, line)\n        if node_matches:\n            node = node_matches[0]\n            nodes.add(node)\n            results[\"stats\"][\"node_count\"] += 1\n\n            # Check for instantiations\n            if instantiation_pattern not in line:\n                results[\"warnings\"].append(f\"Line {i+1}: Node '{node}' is missing instantiations metadata\")\n\n        # Check parent-child relationships\n        if indent &gt; 0 and '+' in line and node_matches:\n            # This is a child node; find its parent\n            parent_indent = indent - 1\n            j = i - 1\n            while j &gt;= 0:\n                if '+' in lines[j] and lines[j].find('+') // 2 == parent_indent:\n                    parent_matches = re.findall(node_pattern, lines[j])\n                    if parent_matches:\n                        parent = parent_matches[0]\n                        relationships.append((parent, node))\n                        results[\"stats\"][\"relationship_count\"] += 1\n                        break\n                j -= 1\n\n    results[\"stats\"][\"max_depth\"] = max_depth\n\n    # If we didn't find any nodes, that's a problem\n    if results[\"stats\"][\"node_count\"] == 0:\n        results[\"is_valid\"] = False\n        results[\"errors\"].append(\"No valid nodes found in ArgDown representation\")\n\n    return results\n\ndef process_source_document(file_path: str, provider_name: str = \"openai\") -&gt; Dict[str, Any]:\n    \"\"\"\n    Process a source document to extract ArgDown representation\n\n    Args:\n        file_path: Path to the source document\n        provider_name: The LLM provider to use\n\n    Returns:\n        Dictionary with extraction results\n    \"\"\"\n    # Load the source document\n    text = \"\"\n    if file_path.endswith(\".pdf\"):\n        # PDF handling requires additional libraries\n        try:\n            import PyPDF2\n            with open(file_path, 'rb') as file:\n                reader = PyPDF2.PdfReader(file)\n                text = \"\"\n                for page in reader.pages:\n                    text += page.extract_text() + \"\\n\"\n        except ImportError:\n            raise ImportError(\"PyPDF2 is required for PDF processing. Install it with: pip install PyPDF2\")\n    elif file_path.endswith(\".txt\"):\n        with open(file_path, 'r') as file:\n            text = file.read()\n    elif file_path.endswith(\".md\"):\n        with open(file_path, 'r') as file:\n            text = file.read()\n    else:\n        raise ValueError(f\"Unsupported file format: {file_path}\")\n\n    # Extract ArgDown\n    argdown_content = extract_argdown_from_text(text, provider_name)\n\n    # Validate the extraction\n    validation_results = validate_argdown(argdown_content)\n\n    # Prepare results\n    results = {\n        \"source_path\": file_path,\n        \"extraction_timestamp\": time.time(),\n        \"argdown_content\": argdown_content,\n        \"validation\": validation_results,\n        \"provider\": provider_name\n    }\n\n    return results\n\ndef save_argdown_extraction(results: Dict[str, Any], output_path: str) -&gt; None:\n    \"\"\"\n    Save ArgDown extraction results\n\n    Args:\n        results: Extraction results dictionary\n        output_path: Path to save the results\n    \"\"\"\n    # Save the ArgDown content\n    with open(output_path, 'w') as file:\n        file.write(results[\"argdown_content\"])\n\n    # Save metadata alongside\n    metadata_path = output_path.replace('.md', '_metadata.json')\n    metadata = {\n        \"source_path\": results[\"source_path\"],\n        \"extraction_timestamp\": results[\"extraction_timestamp\"],\n        \"validation\": results[\"validation\"],\n        \"provider\": results[\"provider\"]\n    }\n\n    with open(metadata_path, 'w') as file:\n        json.dump(metadata, file, indent=2)\n\n\n\n\nCode\n# @title 1.3 --- Prepare LLM API Call ---\n\n\"\"\"\nBLOCK PURPOSE: Prepares parameters for LLM API calls used in ArgDown extraction.\n\nThis function handles the configuration for LLM API calls, including:\n1. Source document path validation\n2. LLM provider selection and validation\n3. Model selection with appropriate defaults\n\nThe function returns a configuration dictionary that can be passed to the\nextraction function in the next step of the pipeline.\n\nDEPENDENCIES: None (uses standard Python functionality)\nOUTPUTS: Dictionary with extraction configuration parameters\n\"\"\"\n\ndef prepare_extraction_call(source_path, provider_name=\"openai\", model=None):\n    \"\"\"\n    Prepare the LLM API call for ArgDown extraction\n\n    Args:\n        source_path (str): Path to the source document to extract from\n        provider_name (str): LLM provider to use ('openai' or 'anthropic')\n        model (str, optional): Specific model to use. Defaults to None (uses provider's default).\n\n    Returns:\n        dict: Configuration parameters for extraction\n\n    Raises:\n        ValueError: If an unsupported provider is specified\n    \"\"\"\n    # Load the source document\n    print(f\"Processing source document: {source_path}\")\n\n    # Determine provider and model\n    provider = provider_name.lower()\n    if provider not in [\"openai\", \"anthropic\"]:\n        raise ValueError(f\"Unsupported provider: {provider}. Use 'openai' or 'anthropic'.\")\n\n    # Set default model if none provided\n    if model is None:\n        if provider == \"openai\":\n            model = \"gpt-4-turbo\"\n        elif provider == \"anthropic\":\n            model = \"claude-3-opus-20240229\"\n\n    # Print configuration\n    print(f\"Using provider: {provider}\")\n    print(f\"Selected model: {model}\")\n\n    return {\n        \"source_path\": source_path,\n        \"provider\": provider,\n        \"model\": model\n    }\n\n# Usage example:\nsource_path = \"example_document.pdf\"  # Replace with actual document path\nextraction_config = prepare_extraction_call(source_path, provider_name=\"openai\")\n\n\nProcessing source document: example_document.pdf\nUsing provider: openai\nSelected model: gpt-4-turbo",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#make-argdown-extraction-llm-api-call",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#make-argdown-extraction-llm-api-call",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "D.6 1.4 Make ArgDown Extraction LLM API Call",
    "text": "D.6 1.4 Make ArgDown Extraction LLM API Call\n\n\nCode\n# @title 1.4 --- Make ArgDown Extraction LLM API Call ---\n\n\"\"\"\nBLOCK PURPOSE: Executes the ArgDown extraction process using the LLM API.\n\nThis function performs the actual extraction of ArgDown representations from source documents:\n1. Takes the configuration parameters prepared in the previous step\n2. Processes the document using the LLM API\n3. Validates the extraction results\n4. Provides timing and statistics about the extraction\n\nThe extraction process transforms unstructured text into a structured argument\nrepresentation following the ArgDown syntax defined in the AMTAIR project.\n\nDEPENDENCIES: process_source_document function from previous cells\nOUTPUTS: Dictionary with extraction results including ArgDown content and validation info\n\"\"\"\n\ndef execute_extraction(extraction_config):\n    \"\"\"\n    Execute the ArgDown extraction using the LLM API\n\n    Args:\n        extraction_config (dict): Configuration parameters for extraction\n\n    Returns:\n        dict: Extraction results including ArgDown content and validation info\n\n    Raises:\n        Exception: For any errors during extraction\n    \"\"\"\n    print(f\"Starting extraction from {extraction_config['source_path']}\")\n    start_time = time.time()\n\n    try:\n        # Process the document\n        results = process_source_document(\n            extraction_config[\"source_path\"],\n            provider_name=extraction_config[\"provider\"]\n        )\n\n        # Print success message\n        elapsed_time = time.time() - start_time\n        print(f\"Extraction completed in {elapsed_time:.2f} seconds\")\n        print(f\"Extracted {results['validation']['stats']['node_count']} nodes with \"\n              f\"{results['validation']['stats']['relationship_count']} relationships\")\n\n        # Print any warnings\n        if results['validation']['warnings']:\n            print(\"\\nWarnings:\")\n            for warning in results['validation']['warnings']:\n                print(f\"- {warning}\")\n\n        return results\n\n    except Exception as e:\n        print(f\"Error during extraction: {str(e)}\")\n        raise\n\n# Usage example:\nextraction_results = execute_extraction(extraction_config)\n\n\nStarting extraction from example_document.pdf\nError during extraction: PyPDF2 is required for PDF processing. Install it with: pip install PyPDF2\n\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\n&lt;ipython-input-17-fd592eb962ab&gt; in process_source_document(file_path, provider_name)\n    166         try:\n--&gt; 167             import PyPDF2\n    168             with open(file_path, 'rb') as file:\n\nModuleNotFoundError: No module named 'PyPDF2'\n\nDuring handling of the above exception, another exception occurred:\n\nImportError                               Traceback (most recent call last)\n&lt;ipython-input-19-27555067c1d2&gt; in &lt;cell line: 0&gt;()\n     59 \n     60 # Usage example:\n---&gt; 61 extraction_results = execute_extraction(extraction_config)\n\n&lt;ipython-input-19-27555067c1d2&gt; in execute_extraction(extraction_config)\n     35     try:\n     36         # Process the document\n---&gt; 37         results = process_source_document(\n     38             extraction_config[\"source_path\"],\n     39             provider_name=extraction_config[\"provider\"]\n\n&lt;ipython-input-17-fd592eb962ab&gt; in process_source_document(file_path, provider_name)\n    172                     text += page.extract_text() + \"\\n\"\n    173         except ImportError:\n--&gt; 174             raise ImportError(\"PyPDF2 is required for PDF processing. Install it with: pip install PyPDF2\")\n    175     elif file_path.endswith(\".txt\"):\n    176         with open(file_path, 'r') as file:\n\nImportError: PyPDF2 is required for PDF processing. Install it with: pip install PyPDF2\n\n---------------------------------------------------------------------------\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n---------------------------------------------------------------------------",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#save-argdown-extraction-response",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#save-argdown-extraction-response",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "D.7 1.5 Save ArgDown Extraction Response",
    "text": "D.7 1.5 Save ArgDown Extraction Response\n\nSave and log API return\nSave ArgDown.md file for further Proecessing\n\n\n\nCode\n# @title 1.5 --- Save ArgDown Extraction Response ---\n\n\"\"\"\nBLOCK PURPOSE: Saves the extracted ArgDown content to files for further processing.\n\nThis function handles saving the extraction results:\n1. Creates an output directory if it doesn't exist\n2. Saves the extracted ArgDown content with a timestamp in the filename\n3. Saves accompanying metadata in a JSON file\n4. Saves a copy at a standard location for the next steps in the pipeline\n5. Provides a preview of the extracted content\n\nThe saved files serve as inputs for the next stage of the pipeline where\nprobability information will be added to create BayesDown.\n\nDEPENDENCIES: os module for directory operations\nOUTPUTS: Saved ArgDown files and preview of extracted content\n\"\"\"\n\ndef save_extraction_results(results, output_directory=\"./outputs\"):\n    \"\"\"\n    Save the extraction results to file\n\n    Args:\n        results (dict): Extraction results from execute_extraction\n        output_directory (str): Directory to save results\n\n    Returns:\n        str: Path to the saved ArgDown file\n    \"\"\"\n    # Ensure output directory exists\n    import os\n    os.makedirs(output_directory, exist_ok=True)\n\n    # Create base filename from source\n    import os.path\n    base_name = os.path.basename(results[\"source_path\"]).split('.')[0]\n    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n    output_filename = f\"{base_name}_argdown_{timestamp}.md\"\n    output_path = os.path.join(output_directory, output_filename)\n\n    # Save the results\n    save_argdown_extraction(results, output_path)\n\n    print(f\"Saved ArgDown extraction to: {output_path}\")\n    print(f\"Metadata saved to: {output_path.replace('.md', '_metadata.json')}\")\n\n    # Also save to standard location for further processing\n    standard_path = os.path.join(output_directory, \"ArgDown.md\")\n    with open(standard_path, 'w') as f:\n        f.write(results[\"argdown_content\"])\n    print(f\"Also saved to standard location: {standard_path}\")\n\n    return output_path\n\n# Usage example:\noutput_path = save_extraction_results(extraction_results)\n\n# Preview the extracted ArgDown\nfrom IPython.display import Markdown, display\n\n# Display the first 500 characters of the extracted ArgDown\npreview = extraction_results[\"argdown_content\"][:500] + \"...\" if len(extraction_results[\"argdown_content\"]) &gt; 500 else extraction_results[\"argdown_content\"]\ndisplay(Markdown(f\"## Extracted ArgDown Preview\\n\\n```\\n{preview}\\n```\"))\n\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\n&lt;ipython-input-20-84ee4ea64739&gt; in &lt;cell line: 0&gt;()\n     55 \n     56 # Usage example:\n---&gt; 57 output_path = save_extraction_results(extraction_results)\n     58 \n     59 # Preview the extracted ArgDown\n\nNameError: name 'extraction_results' is not defined",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#review-and-check-argdown.md-file",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#review-and-check-argdown.md-file",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "D.8 1.6 Review and Check ArgDown.md File",
    "text": "D.8 1.6 Review and Check ArgDown.md File\n\n\nCode\ndisplay(Markdown(md_content))\n\n\n[Existential_Catastrophe]: The destruction of humanity’s long-term potential due to AI systems we’ve lost control over. {“instantiations”: [“existential_catastrophe_TRUE”, “existential_catastrophe_FALSE”]} - [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {“instantiations”: [“human_disempowerment_TRUE”, “human_disempowerment_FALSE”]} - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {“instantiations”: [“scale_of_power_seeking_TRUE”, “scale_of_power_seeking_FALSE”]} - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {“instantiations”: [“misaligned_power_seeking_TRUE”, “misaligned_power_seeking_FALSE”]} - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {“instantiations”: [“aps_systems_TRUE”, “aps_systems_FALSE”]} - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {“instantiations”: [“advanced_ai_capability_TRUE”, “advanced_ai_capability_FALSE”]} - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {“instantiations”: [“agentic_planning_TRUE”, “agentic_planning_FALSE”]} - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {“instantiations”: [“strategic_awareness_TRUE”, “strategic_awareness_FALSE”]} - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {“instantiations”: [“difficulty_of_alignment_TRUE”, “difficulty_of_alignment_FALSE”]} - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {“instantiations”: [“instrumental_convergence_TRUE”, “instrumental_convergence_FALSE”]} - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {“instantiations”: [“problems_with_proxies_TRUE”, “problems_with_proxies_FALSE”]} - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {“instantiations”: [“problems_with_search_TRUE”, “problems_with_search_FALSE”]} - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {“instantiations”: [“deployment_decisions_DEPLOY”, “deployment_decisions_WITHHOLD”]} - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {“instantiations”: [“incentives_to_build_aps_STRONG”, “incentives_to_build_aps_WEAK”]} - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {“instantiations”: [“usefulness_of_aps_HIGH”, “usefulness_of_aps_LOW”]} - [Competitive_Dynamics]: Competitive pressures between AI developers. {“instantiations”: [“competitive_dynamics_STRONG”, “competitive_dynamics_WEAK”]} - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {“instantiations”: [“deception_by_ai_TRUE”, “deception_by_ai_FALSE”]} - [Corrective_Feedback]: Human society implementing corrections after observing problems. {“instantiations”: [“corrective_feedback_EFFECTIVE”, “corrective_feedback_INEFFECTIVE”]} - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {“instantiations”: [“warning_shots_OBSERVED”, “warning_shots_UNOBSERVED”]} - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {“instantiations”: [“rapid_capability_escalation_TRUE”, “rapid_capability_escalation_FALSE”]} [Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {“instantiations”: [“barriers_to_understanding_HIGH”, “barriers_to_understanding_LOW”]} - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {“instantiations”: [“misaligned_power_seeking_TRUE”, “misaligned_power_seeking_FALSE”]} [Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {“instantiations”: [“adversarial_dynamics_TRUE”, “adversarial_dynamics_FALSE”]} - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {“instantiations”: [“misaligned_power_seeking_TRUE”, “misaligned_power_seeking_FALSE”]} [Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {“instantiations”: [“stakes_of_error_HIGH”, “stakes_of_error_LOW”]} - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {“instantiations”: [“misaligned_power_seeking_TRUE”, “misaligned_power_seeking_FALSE”]}",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#check-the-graph-structure-with-the-argdown-sandbox-online",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#check-the-graph-structure-with-the-argdown-sandbox-online",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "D.9 1.6.2 Check the Graph Structure with the ArgDown Sandbox Online",
    "text": "D.9 1.6.2 Check the Graph Structure with the ArgDown Sandbox Online\nCopy and paste the BayesDown formatted … in the ArgDown Sandbox below to quickly verify that the network renders correctly.\n\n\nCode\n# @title 1.6.2 --- ArgDown Online Sandbox ---\n\nfrom IPython.display import IFrame\n\nIFrame(src=\"https://argdown.org/sandbox/map/\", width=\"100%\", height=\"600px\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#extract-argdown-graph-information-as-dataframe",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#extract-argdown-graph-information-as-dataframe",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "D.10 1.7 Extract ArgDown Graph Information as DataFrame",
    "text": "D.10 1.7 Extract ArgDown Graph Information as DataFrame\nExtract:\n\nNodes (Variable_Title)\nEdges (Parents)\nInstantiations\nDescription\n\nImplementation nodes: - One function for ArgDown and BayesDown extraction, but: - IF YOU ONLY WANT ARGDOWN EXTRACTION: USE ARGUMENT IN FUNCTION CALL “parse_markdown_hierarchy(markdown_text, ArgDown = True)” - so if you set ArgDown = True, it gives you only instantiations, no probabilities.\n\n\nCode\n# @title 1.7 --- Parsing ArgDown & BayesDown (.md to .csv) ---\n\n\"\"\"\nBLOCK PURPOSE: Provides the core parsing functionality for transforming ArgDown and BayesDown\ntext representations into structured DataFrame format for further processing.\n\nThis block implements the critical extraction pipeline described in the AMTAIR project\n(see PY_TechnicalImplementation) that converts argument structures into Bayesian networks.\nThe function can handle both basic ArgDown (structure-only) and BayesDown (with probabilities).\n\nKey steps in the parsing process:\n1. Remove comments from the markdown text\n2. Extract titles, descriptions, and indentation levels\n3. Establish parent-child relationships based on indentation\n4. Convert the structured information into a DataFrame\n5. Add derived columns for network analysis\n\nDEPENDENCIES: pandas, re, json libraries\nINPUTS: Markdown text in ArgDown/BayesDown format\nOUTPUTS: Structured DataFrame with node information, relationships, and properties\n\"\"\"\n\ndef parse_markdown_hierarchy_fixed(markdown_text, ArgDown=False):\n    \"\"\"\n    Parse ArgDown or BayesDown format into a structured DataFrame with parent-child relationships.\n\n    Args:\n        markdown_text (str): Text in ArgDown or BayesDown format\n        ArgDown (bool): If True, extracts only structure without probabilities\n                        If False, extracts both structure and probability information\n\n    Returns:\n        pandas.DataFrame: Structured data with node information, relationships, and attributes\n    \"\"\"\n    # PHASE 1: Clean and prepare the text\n    clean_text = remove_comments(markdown_text)\n\n    # PHASE 2: Extract basic information about nodes\n    titles_info = extract_titles_info(clean_text)\n\n    # PHASE 3: Determine the hierarchical relationships\n    titles_with_relations = establish_relationships_fixed(titles_info, clean_text)\n\n    # PHASE 4: Convert to structured DataFrame format\n    df = convert_to_dataframe(titles_with_relations, ArgDown)\n\n    # PHASE 5: Add derived columns for analysis\n    df = add_no_parent_no_child_columns_to_df(df)\n    df = add_parents_instantiation_columns_to_df(df)\n\n    return df\n\ndef remove_comments(markdown_text):\n    \"\"\"\n    Remove comment blocks from markdown text using regex pattern matching.\n\n    Args:\n        markdown_text (str): Text containing potential comment blocks\n\n    Returns:\n        str: Text with comment blocks removed\n    \"\"\"\n    # Remove anything between /* and */ using regex\n    return re.sub(r'/\\*.*?\\*/', '', markdown_text, flags=re.DOTALL)\n\ndef extract_titles_info(text):\n    \"\"\"\n    Extract titles with their descriptions and indentation levels from markdown text.\n\n    Args:\n        text (str): Cleaned markdown text\n\n    Returns:\n        dict: Dictionary with titles as keys and dictionaries of attributes as values\n    \"\"\"\n    lines = text.split('\\n')\n    titles_info = {}\n\n    for line in lines:\n        # Skip empty lines\n        if not line.strip():\n            continue\n\n        # Extract title within square or angle brackets\n        title_match = re.search(r'[&lt;\\[](.+?)[&gt;\\]]', line)\n        if not title_match:\n            continue\n\n        title = title_match.group(1)\n\n        # Extract description and metadata\n        title_pattern_in_line = r'[&lt;\\[]' + re.escape(title) + r'[&gt;\\]]:'\n        description_match = re.search(title_pattern_in_line + r'\\s*(.*)', line)\n\n        if description_match:\n            full_text = description_match.group(1).strip()\n\n            # Split description and metadata at the first \"{\"\n            if \"{\" in full_text:\n                split_index = full_text.find(\"{\")\n                description = full_text[:split_index].strip()\n                metadata = full_text[split_index:].strip()\n            else:\n                # Keep the entire description and no metadata\n                description = full_text\n                metadata = ''  # Initialize as empty string\n        else:\n            description = ''\n            metadata = ''  # Ensure metadata is initialized\n\n        # Calculate indentation level based on spaces before + or - symbol\n        indentation = 0\n        if '+' in line:\n            symbol_index = line.find('+')\n            # Count spaces before the '+' symbol\n            i = symbol_index - 1\n            while i &gt;= 0 and line[i] == ' ':\n                indentation += 1\n                i -= 1\n        elif '-' in line:\n            symbol_index = line.find('-')\n            # Count spaces before the '-' symbol\n            i = symbol_index - 1\n            while i &gt;= 0 and line[i] == ' ':\n                indentation += 1\n                i -= 1\n\n        # If neither symbol exists, indentation remains 0\n\n        if title in titles_info:\n            # Only update description if it's currently empty and we found a new one\n            if not titles_info[title]['description'] and description:\n                titles_info[title]['description'] = description\n\n            # Store all indentation levels for this title\n            titles_info[title]['indentation_levels'].append(indentation)\n\n            # Keep max indentation for backward compatibility\n            if indentation &gt; titles_info[title]['indentation']:\n                titles_info[title]['indentation'] = indentation\n\n            # Do NOT update metadata here - keep the original metadata\n        else:\n            # First time seeing this title, create a new entry\n            titles_info[title] = {\n                'description': description,\n                'indentation': indentation,\n                'indentation_levels': [indentation],  # Initialize with first indentation level\n                'parents': [],\n                'children': [],\n                'line': None,\n                'line_numbers': [],  # Initialize an empty list for all occurrences\n                'metadata': metadata  # Set metadata explicitly from what we found\n            }\n\n    return titles_info\n\ndef establish_relationships_fixed(titles_info, text):\n    \"\"\"\n    Establish parent-child relationships between titles using BayesDown indentation rules.\n\n    In BayesDown syntax:\n    - More indented nodes (with + symbol) are PARENTS of less indented nodes\n    - The relationship reads as \"Effect is caused by Cause\" (Effect + Cause)\n    - This aligns with how Bayesian networks represent causality\n\n    Args:\n        titles_info (dict): Dictionary with information about titles\n        text (str): Original markdown text (for identifying line numbers)\n\n    Returns:\n        dict: Updated dictionary with parent-child relationships\n    \"\"\"\n    lines = text.split('\\n')\n\n    # Dictionary to store line numbers for each title occurrence\n    title_occurrences = {}\n\n    # Record line number for each title (including multiple occurrences)\n    line_number = 0\n    for line in lines:\n        if not line.strip():\n            line_number += 1\n            continue\n\n        title_match = re.search(r'[&lt;\\[](.+?)[&gt;\\]]', line)\n        if not title_match:\n            line_number += 1\n            continue\n\n        title = title_match.group(1)\n\n        # Store all occurrences of each title with their line numbers\n        if title not in title_occurrences:\n            title_occurrences[title] = []\n        title_occurrences[title].append(line_number)\n\n        # Store all line numbers where this title appears\n        if 'line_numbers' not in titles_info[title]:\n            titles_info[title]['line_numbers'] = []\n        titles_info[title]['line_numbers'].append(line_number)\n\n        # For backward compatibility, keep the first occurrence in 'line'\n        if titles_info[title]['line'] is None:\n            titles_info[title]['line'] = line_number\n\n        line_number += 1\n\n    # Create an ordered list of all title occurrences with their line numbers\n    all_occurrences = []\n    for title, occurrences in title_occurrences.items():\n        for line_num in occurrences:\n            all_occurrences.append((title, line_num))\n\n    # Sort occurrences by line number\n    all_occurrences.sort(key=lambda x: x[1])\n\n    # Get indentation for each occurrence\n    occurrence_indents = {}\n    for title, line_num in all_occurrences:\n        for line in lines[line_num:line_num+1]:  # Only check the current line\n            indent = 0\n            if '+' in line:\n                symbol_index = line.find('+')\n                # Count spaces before the '+' symbol\n                j = symbol_index - 1\n                while j &gt;= 0 and line[j] == ' ':\n                    indent += 1\n                    j -= 1\n            elif '-' in line:\n                symbol_index = line.find('-')\n                # Count spaces before the '-' symbol\n                j = symbol_index - 1\n                while j &gt;= 0 and line[j] == ' ':\n                    indent += 1\n                    j -= 1\n            occurrence_indents[(title, line_num)] = indent\n\n    # Enhanced backward pass for correct parent-child relationships\n    for i, (title, line_num) in enumerate(all_occurrences):\n        current_indent = occurrence_indents[(title, line_num)]\n\n        # Skip root nodes (indentation 0) for processing\n        if current_indent == 0:\n            continue\n\n        # Look for the immediately preceding node with lower indentation\n        j = i - 1\n        while j &gt;= 0:\n            prev_title, prev_line = all_occurrences[j]\n            prev_indent = occurrence_indents[(prev_title, prev_line)]\n\n            # If we find a node with less indentation, it's a child of current node\n            if prev_indent &lt; current_indent:\n                # In BayesDown: More indented node is a parent (cause) of less indented node (effect)\n                if title not in titles_info[prev_title]['parents']:\n                    titles_info[prev_title]['parents'].append(title)\n                if prev_title not in titles_info[title]['children']:\n                    titles_info[title]['children'].append(prev_title)\n\n                # Only need to find the immediate child (closest preceding node with lower indentation)\n                break\n\n            j -= 1\n\n    return titles_info\n\ndef convert_to_dataframe(titles_info, ArgDown):\n    \"\"\"\n    Convert the titles information dictionary to a pandas DataFrame.\n\n    Args:\n        titles_info (dict): Dictionary with information about titles\n        ArgDown (bool): If True, extract only structural information without probabilities\n\n    Returns:\n        pandas.DataFrame: Structured data with node information and relationships\n    \"\"\"\n    if ArgDown == True:\n        # For ArgDown, exclude probability columns\n        df = pd.DataFrame(columns=['Title', 'Description', 'line', 'line_numbers', 'indentation',\n                               'indentation_levels', 'Parents', 'Children', 'instantiations'])\n    else:\n        # For BayesDown, include probability columns\n        df = pd.DataFrame(columns=['Title', 'Description', 'line', 'line_numbers', 'indentation',\n                               'indentation_levels', 'Parents', 'Children', 'instantiations',\n                               'priors', 'posteriors'])\n\n    for title, info in titles_info.items():\n        # Parse the metadata JSON string into a Python dictionary\n        if 'metadata' in info and info['metadata']:\n            try:\n                # Only try to parse if metadata is not empty\n                if info['metadata'].strip():\n                    jsonMetadata = json.loads(info['metadata'])\n                    if ArgDown == True:\n                        # Create the row dictionary with instantiations as metadata only, no probabilities yet\n                        row = {\n                            'Title': title,\n                            'Description': info.get('description', ''),\n                            'line': info.get('line',''),\n                            'line_numbers': info.get('line_numbers', []),\n                            'indentation': info.get('indentation',''),\n                            'indentation_levels': info.get('indentation_levels', []),\n                            'Parents': info.get('parents', []),\n                            'Children': info.get('children', []),\n                            # Extract specific metadata fields, defaulting to empty if not present\n                            'instantiations': jsonMetadata.get('instantiations', []),\n                        }\n                    else:\n                        # Create dict with probabilities for BayesDown\n                        row = {\n                            'Title': title,\n                            'Description': info.get('description', ''),\n                            'line': info.get('line',''),\n                            'line_numbers': info.get('line_numbers', []),\n                            'indentation': info.get('indentation',''),\n                            'indentation_levels': info.get('indentation_levels', []),\n                            'Parents': info.get('parents', []),\n                            'Children': info.get('children', []),\n                            # Extract specific metadata fields, defaulting to empty if not present\n                            'instantiations': jsonMetadata.get('instantiations', []),\n                            'priors': jsonMetadata.get('priors', {}),\n                            'posteriors': jsonMetadata.get('posteriors', {})\n                        }\n                else:\n                    # Empty metadata case\n                    row = {\n                        'Title': title,\n                        'Description': info.get('description', ''),\n                        'line': info.get('line',''),\n                        'line_numbers': info.get('line_numbers', []),\n                        'indentation': info.get('indentation',''),\n                        'indentation_levels': info.get('indentation_levels', []),\n                        'Parents': info.get('parents', []),\n                        'Children': info.get('children', []),\n                        'instantiations': [],\n                        'priors': {},\n                        'posteriors': {}\n                    }\n            except json.JSONDecodeError:\n                # Handle case where metadata isn't valid JSON\n                row = {\n                    'Title': title,\n                    'Description': info.get('description', ''),\n                    'line': info.get('line',''),\n                    'line_numbers': info.get('line_numbers', []),\n                    'indentation': info.get('indentation',''),\n                    'indentation_levels': info.get('indentation_levels', []),\n                    'Parents': info.get('parents', []),\n                    'Children': info.get('children', []),\n                    'instantiations': [],\n                    'priors': {},\n                    'posteriors': {}\n                }\n        else:\n            # Handle case where metadata field doesn't exist or is empty\n            row = {\n                'Title': title,\n                'Description': info.get('description', ''),\n                'line': info.get('line',''),\n                'line_numbers': info.get('line_numbers', []),\n                'indentation': info.get('indentation',''),\n                'indentation_levels': info.get('indentation_levels', []),\n                'Parents': info.get('parents', []),\n                'Children': info.get('children', []),\n                'instantiations': [],\n                'priors': {},\n                'posteriors': {}\n            }\n\n        # Add the row to the DataFrame\n        df.loc[len(df)] = row\n\n    return df\n\ndef add_no_parent_no_child_columns_to_df(dataframe):\n    \"\"\"\n    Add No_Parent and No_Children boolean columns to the DataFrame to identify root and leaf nodes.\n\n    Args:\n        dataframe (pandas.DataFrame): The DataFrame to enhance\n\n    Returns:\n        pandas.DataFrame: Enhanced DataFrame with additional boolean columns\n    \"\"\"\n    no_parent = []\n    no_children = []\n\n    for _, row in dataframe.iterrows():\n        no_parent.append(not row['Parents'])  # True if Parents list is empty\n        no_children.append(not row['Children'])  # True if Children list is empty\n\n    dataframe['No_Parent'] = no_parent\n    dataframe['No_Children'] = no_children\n\n    return dataframe\n\ndef add_parents_instantiation_columns_to_df(dataframe):\n    \"\"\"\n    Add all possible instantiations of parents as a list of lists column to the DataFrame.\n    This is crucial for generating conditional probability tables.\n\n    Args:\n        dataframe (pandas.DataFrame): The DataFrame to enhance\n\n    Returns:\n        pandas.DataFrame: Enhanced DataFrame with parent_instantiations column\n    \"\"\"\n    # Create a new column to store parent instantiations\n    parent_instantiations = []\n\n    # Iterate through each row in the dataframe\n    for _, row in dataframe.iterrows():\n        parents = row['Parents']\n        parent_insts = []\n\n        # For each parent, find its instantiations and add to the list\n        for parent in parents:\n            # Find the row where Title matches the parent\n            parent_row = dataframe[dataframe['Title'] == parent]\n\n            # If parent found in the dataframe\n            if not parent_row.empty:\n                # Get the instantiations of this parent\n                parent_instantiation = parent_row['instantiations'].iloc[0]\n                parent_insts.append(parent_instantiation)\n\n        # Add the list of parent instantiations to our new column\n        parent_instantiations.append(parent_insts)\n\n    # Add the new column to the dataframe\n    dataframe['parent_instantiations'] = parent_instantiations\n\n    return dataframe\n\n\n\n\nCode\n# example use case:\nex_csv = parse_markdown_hierarchy_fixed(md_content, ArgDown = True)\nex_csv\n\n\n\n    \n\n\n\n\n\n\nTitle\nDescription\nline\nline_numbers\nindentation\nindentation_levels\nParents\nChildren\ninstantiations\nNo_Parent\nNo_Children\nparent_instantiations\n\n\n\n\n0\nExistential_Catastrophe\nThe destruction of humanity's long-term potent...\n0\n[0]\n0\n[0]\n[]\n[]\n[existential_catastrophe_TRUE, existential_cat...\nTrue\nTrue\n[]\n\n\n1\nHuman_Disempowerment\nPermanent and collective disempowerment of hum...\n1\n[1]\n0\n[0]\n[Scale_Of_Power_Seeking]\n[]\n[human_disempowerment_TRUE, human_disempowerme...\nFalse\nTrue\n[[scale_of_power_seeking_TRUE, scale_of_power_...\n\n\n2\nScale_Of_Power_Seeking\nPower-seeking by AI systems scaling to the poi...\n2\n[2]\n4\n[4]\n[Misaligned_Power_Seeking, Corrective_Feedback]\n[Human_Disempowerment]\n[scale_of_power_seeking_TRUE, scale_of_power_s...\nFalse\nFalse\n[[misaligned_power_seeking_TRUE, misaligned_po...\n\n\n3\nMisaligned_Power_Seeking\nDeployed AI systems seeking power in unintende...\n3\n[3, 21, 23, 25]\n8\n[8, 0, 0, 0]\n[APS_Systems, Difficulty_Of_Alignment, Deploym...\n[Scale_Of_Power_Seeking]\n[misaligned_power_seeking_TRUE, misaligned_pow...\nFalse\nFalse\n[[aps_systems_TRUE, aps_systems_FALSE], [diffi...\n\n\n4\nAPS_Systems\nAI systems with advanced capabilities, agentic...\n4\n[4]\n12\n[12]\n[Advanced_AI_Capability, Agentic_Planning, Str...\n[Misaligned_Power_Seeking]\n[aps_systems_TRUE, aps_systems_FALSE]\nFalse\nFalse\n[[advanced_ai_capability_TRUE, advanced_ai_cap...\n\n\n5\nAdvanced_AI_Capability\nAI systems that outperform humans on tasks tha...\n5\n[5]\n16\n[16]\n[]\n[APS_Systems]\n[advanced_ai_capability_TRUE, advanced_ai_capa...\nTrue\nFalse\n[]\n\n\n6\nAgentic_Planning\nAI systems making and executing plans based on...\n6\n[6]\n16\n[16]\n[]\n[APS_Systems]\n[agentic_planning_TRUE, agentic_planning_FALSE]\nTrue\nFalse\n[]\n\n\n7\nStrategic_Awareness\nAI systems with models accurately representing...\n7\n[7]\n16\n[16]\n[]\n[APS_Systems]\n[strategic_awareness_TRUE, strategic_awareness...\nTrue\nFalse\n[]\n\n\n8\nDifficulty_Of_Alignment\nIt is harder to build aligned systems than mis...\n8\n[8]\n12\n[12]\n[Instrumental_Convergence, Problems_With_Proxi...\n[Misaligned_Power_Seeking]\n[difficulty_of_alignment_TRUE, difficulty_of_a...\nFalse\nFalse\n[[instrumental_convergence_TRUE, instrumental_...\n\n\n9\nInstrumental_Convergence\nAI systems with misaligned objectives tend to ...\n9\n[9]\n16\n[16]\n[]\n[Difficulty_Of_Alignment]\n[instrumental_convergence_TRUE, instrumental_c...\nTrue\nFalse\n[]\n\n\n10\nProblems_With_Proxies\nOptimizing for proxy objectives breaks correla...\n10\n[10]\n16\n[16]\n[]\n[Difficulty_Of_Alignment]\n[problems_with_proxies_TRUE, problems_with_pro...\nTrue\nFalse\n[]\n\n\n11\nProblems_With_Search\nSearch processes can yield systems pursuing di...\n11\n[11]\n16\n[16]\n[]\n[Difficulty_Of_Alignment]\n[problems_with_search_TRUE, problems_with_sear...\nTrue\nFalse\n[]\n\n\n12\nDeployment_Decisions\nDecisions to deploy potentially misaligned AI ...\n12\n[12]\n12\n[12]\n[Incentives_To_Build_APS, Deception_By_AI]\n[Misaligned_Power_Seeking]\n[deployment_decisions_DEPLOY, deployment_decis...\nFalse\nFalse\n[[incentives_to_build_aps_STRONG, incentives_t...\n\n\n13\nIncentives_To_Build_APS\nStrong incentives to build and deploy APS syst...\n13\n[13]\n16\n[16]\n[Usefulness_Of_APS, Competitive_Dynamics]\n[Deployment_Decisions]\n[incentives_to_build_aps_STRONG, incentives_to...\nFalse\nFalse\n[[usefulness_of_aps_HIGH, usefulness_of_aps_LO...\n\n\n14\nUsefulness_Of_APS\nAPS systems are very useful for many valuable ...\n14\n[14]\n20\n[20]\n[]\n[Incentives_To_Build_APS]\n[usefulness_of_aps_HIGH, usefulness_of_aps_LOW]\nTrue\nFalse\n[]\n\n\n15\nCompetitive_Dynamics\nCompetitive pressures between AI developers.\n15\n[15]\n20\n[20]\n[]\n[Incentives_To_Build_APS]\n[competitive_dynamics_STRONG, competitive_dyna...\nTrue\nFalse\n[]\n\n\n16\nDeception_By_AI\nAI systems deceiving humans about their true o...\n16\n[16]\n16\n[16]\n[]\n[Deployment_Decisions]\n[deception_by_ai_TRUE, deception_by_ai_FALSE]\nTrue\nFalse\n[]\n\n\n17\nCorrective_Feedback\nHuman society implementing corrections after o...\n17\n[17]\n8\n[8]\n[Warning_Shots, Rapid_Capability_Escalation]\n[Scale_Of_Power_Seeking]\n[corrective_feedback_EFFECTIVE, corrective_fee...\nFalse\nFalse\n[[warning_shots_OBSERVED, warning_shots_UNOBSE...\n\n\n18\nWarning_Shots\nObservable failures in weaker systems before c...\n18\n[18]\n12\n[12]\n[]\n[Corrective_Feedback]\n[warning_shots_OBSERVED, warning_shots_UNOBSER...\nTrue\nFalse\n[]\n\n\n19\nRapid_Capability_Escalation\nAI capabilities escalating very rapidly, allow...\n19\n[19]\n12\n[12]\n[]\n[Corrective_Feedback]\n[rapid_capability_escalation_TRUE, rapid_capab...\nTrue\nFalse\n[]\n\n\n20\nBarriers_To_Understanding\nDifficulty in understanding the internal worki...\n20\n[20]\n0\n[0]\n[]\n[]\n[barriers_to_understanding_HIGH, barriers_to_u...\nTrue\nTrue\n[]\n\n\n21\nAdversarial_Dynamics\nPotentially adversarial relationships between ...\n22\n[22]\n0\n[0]\n[]\n[]\n[adversarial_dynamics_TRUE, adversarial_dynami...\nTrue\nTrue\n[]\n\n\n22\nStakes_Of_Error\nThe escalating impact of mistakes with power-s...\n24\n[24]\n0\n[0]\n[]\n[]\n[stakes_of_error_HIGH, stakes_of_error_LOW]\nTrue\nTrue\n[]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#store-argdown-information-as-argdown.csv-file",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#store-argdown-information-as-argdown.csv-file",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "D.11 1.8 Store ArgDown Information as ‘ArgDown.csv’ file",
    "text": "D.11 1.8 Store ArgDown Information as ‘ArgDown.csv’ file\n\n\nCode\n# Assuming 'md_content' holds the markdown text\n# Store the results of running the function parse_markdown_hierarchy(md_content, ArgDown = True) as the file 'ArgDown.csv'\nresult_df = parse_markdown_hierarchy_fixed(md_content, ArgDown = True)\n\n# Save to CSV\nresult_df.to_csv('ArgDown.csv', index=False)\n\n\n\n\nCode\n# Test if 'ArgDown.csv' has been saved correctly with the correct information\n# Load the data from the CSV file\nargdown_df = pd.read_csv('ArgDown.csv')\n\n# Display the DataFrame\nprint(argdown_df)\n\n\n                          Title  \\\n0       Existential_Catastrophe   \n1          Human_Disempowerment   \n2        Scale_Of_Power_Seeking   \n3      Misaligned_Power_Seeking   \n4                   APS_Systems   \n5        Advanced_AI_Capability   \n6              Agentic_Planning   \n7           Strategic_Awareness   \n8       Difficulty_Of_Alignment   \n9      Instrumental_Convergence   \n10        Problems_With_Proxies   \n11         Problems_With_Search   \n12         Deployment_Decisions   \n13      Incentives_To_Build_APS   \n14            Usefulness_Of_APS   \n15         Competitive_Dynamics   \n16              Deception_By_AI   \n17          Corrective_Feedback   \n18                Warning_Shots   \n19  Rapid_Capability_Escalation   \n20    Barriers_To_Understanding   \n21         Adversarial_Dynamics   \n22              Stakes_Of_Error   \n\n                                          Description  line     line_numbers  \\\n0   The destruction of humanity's long-term potent...     0              [0]   \n1   Permanent and collective disempowerment of hum...     1              [1]   \n2   Power-seeking by AI systems scaling to the poi...     2              [2]   \n3   Deployed AI systems seeking power in unintende...     3  [3, 21, 23, 25]   \n4   AI systems with advanced capabilities, agentic...     4              [4]   \n5   AI systems that outperform humans on tasks tha...     5              [5]   \n6   AI systems making and executing plans based on...     6              [6]   \n7   AI systems with models accurately representing...     7              [7]   \n8   It is harder to build aligned systems than mis...     8              [8]   \n9   AI systems with misaligned objectives tend to ...     9              [9]   \n10  Optimizing for proxy objectives breaks correla...    10             [10]   \n11  Search processes can yield systems pursuing di...    11             [11]   \n12  Decisions to deploy potentially misaligned AI ...    12             [12]   \n13  Strong incentives to build and deploy APS syst...    13             [13]   \n14  APS systems are very useful for many valuable ...    14             [14]   \n15       Competitive pressures between AI developers.    15             [15]   \n16  AI systems deceiving humans about their true o...    16             [16]   \n17  Human society implementing corrections after o...    17             [17]   \n18  Observable failures in weaker systems before c...    18             [18]   \n19  AI capabilities escalating very rapidly, allow...    19             [19]   \n20  Difficulty in understanding the internal worki...    20             [20]   \n21  Potentially adversarial relationships between ...    22             [22]   \n22  The escalating impact of mistakes with power-s...    24             [24]   \n\n    indentation indentation_levels  \\\n0             0                [0]   \n1             0                [0]   \n2             4                [4]   \n3             8       [8, 0, 0, 0]   \n4            12               [12]   \n5            16               [16]   \n6            16               [16]   \n7            16               [16]   \n8            12               [12]   \n9            16               [16]   \n10           16               [16]   \n11           16               [16]   \n12           12               [12]   \n13           16               [16]   \n14           20               [20]   \n15           20               [20]   \n16           16               [16]   \n17            8                [8]   \n18           12               [12]   \n19           12               [12]   \n20            0                [0]   \n21            0                [0]   \n22            0                [0]   \n\n                                              Parents  \\\n0                                                  []   \n1                          ['Scale_Of_Power_Seeking']   \n2   ['Misaligned_Power_Seeking', 'Corrective_Feedb...   \n3   ['APS_Systems', 'Difficulty_Of_Alignment', 'De...   \n4   ['Advanced_AI_Capability', 'Agentic_Planning',...   \n5                                                  []   \n6                                                  []   \n7                                                  []   \n8   ['Instrumental_Convergence', 'Problems_With_Pr...   \n9                                                  []   \n10                                                 []   \n11                                                 []   \n12     ['Incentives_To_Build_APS', 'Deception_By_AI']   \n13      ['Usefulness_Of_APS', 'Competitive_Dynamics']   \n14                                                 []   \n15                                                 []   \n16                                                 []   \n17   ['Warning_Shots', 'Rapid_Capability_Escalation']   \n18                                                 []   \n19                                                 []   \n20                                                 []   \n21                                                 []   \n22                                                 []   \n\n                        Children  \\\n0                             []   \n1                             []   \n2       ['Human_Disempowerment']   \n3     ['Scale_Of_Power_Seeking']   \n4   ['Misaligned_Power_Seeking']   \n5                ['APS_Systems']   \n6                ['APS_Systems']   \n7                ['APS_Systems']   \n8   ['Misaligned_Power_Seeking']   \n9    ['Difficulty_Of_Alignment']   \n10   ['Difficulty_Of_Alignment']   \n11   ['Difficulty_Of_Alignment']   \n12  ['Misaligned_Power_Seeking']   \n13      ['Deployment_Decisions']   \n14   ['Incentives_To_Build_APS']   \n15   ['Incentives_To_Build_APS']   \n16      ['Deployment_Decisions']   \n17    ['Scale_Of_Power_Seeking']   \n18       ['Corrective_Feedback']   \n19       ['Corrective_Feedback']   \n20                            []   \n21                            []   \n22                            []   \n\n                                       instantiations  No_Parent  No_Children  \\\n0   ['existential_catastrophe_TRUE', 'existential_...       True         True   \n1   ['human_disempowerment_TRUE', 'human_disempowe...      False         True   \n2   ['scale_of_power_seeking_TRUE', 'scale_of_powe...      False        False   \n3   ['misaligned_power_seeking_TRUE', 'misaligned_...      False        False   \n4           ['aps_systems_TRUE', 'aps_systems_FALSE']      False        False   \n5   ['advanced_ai_capability_TRUE', 'advanced_ai_c...       True        False   \n6   ['agentic_planning_TRUE', 'agentic_planning_FA...       True        False   \n7   ['strategic_awareness_TRUE', 'strategic_awaren...       True        False   \n8   ['difficulty_of_alignment_TRUE', 'difficulty_o...      False        False   \n9   ['instrumental_convergence_TRUE', 'instrumenta...       True        False   \n10  ['problems_with_proxies_TRUE', 'problems_with_...       True        False   \n11  ['problems_with_search_TRUE', 'problems_with_s...       True        False   \n12  ['deployment_decisions_DEPLOY', 'deployment_de...      False        False   \n13  ['incentives_to_build_aps_STRONG', 'incentives...      False        False   \n14  ['usefulness_of_aps_HIGH', 'usefulness_of_aps_...       True        False   \n15  ['competitive_dynamics_STRONG', 'competitive_d...       True        False   \n16  ['deception_by_ai_TRUE', 'deception_by_ai_FALSE']       True        False   \n17  ['corrective_feedback_EFFECTIVE', 'corrective_...      False        False   \n18  ['warning_shots_OBSERVED', 'warning_shots_UNOB...       True        False   \n19  ['rapid_capability_escalation_TRUE', 'rapid_ca...       True        False   \n20  ['barriers_to_understanding_HIGH', 'barriers_t...       True         True   \n21  ['adversarial_dynamics_TRUE', 'adversarial_dyn...       True         True   \n22    ['stakes_of_error_HIGH', 'stakes_of_error_LOW']       True         True   \n\n                                parent_instantiations  \n0                                                  []  \n1   [['scale_of_power_seeking_TRUE', 'scale_of_pow...  \n2   [['misaligned_power_seeking_TRUE', 'misaligned...  \n3   [['aps_systems_TRUE', 'aps_systems_FALSE'], ['...  \n4   [['advanced_ai_capability_TRUE', 'advanced_ai_...  \n5                                                  []  \n6                                                  []  \n7                                                  []  \n8   [['instrumental_convergence_TRUE', 'instrument...  \n9                                                  []  \n10                                                 []  \n11                                                 []  \n12  [['incentives_to_build_aps_STRONG', 'incentive...  \n13  [['usefulness_of_aps_HIGH', 'usefulness_of_aps...  \n14                                                 []  \n15                                                 []  \n16                                                 []  \n17  [['warning_shots_OBSERVED', 'warning_shots_UNO...  \n18                                                 []  \n19                                                 []  \n20                                                 []  \n21                                                 []  \n22                                                 []",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#process-overview-1",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#process-overview-1",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "F.1 Process Overview",
    "text": "F.1 Process Overview\nThis section implements the second major stage of the AMTAIR pipeline: enhancing the structured argument representation (ArgDown) with probability information to create BayesDown.\nBayesDown extends ArgDown by adding: 1. Prior probabilities for each variable (unconditional beliefs) 2. Conditional probabilities representing the relationships between variables 3. The full parameter specification needed for a Bayesian network\nThe process follows these steps: 1. Generate probability questions for each node and its relationships 2. Create a BayesDown template with placeholders for these probabilities 3. Answer the probability questions (manually or via LLM) 4. Substitute the answers into the BayesDown representation\nThis enhanced representation contains all the information needed to construct a formal Bayesian network, enabling probabilistic reasoning and policy evaluation.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#what-is-bayesdown",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#what-is-bayesdown",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "F.2 What is BayesDown?",
    "text": "F.2 What is BayesDown?\nBayesDown maintains the ArgDown structure but adds probability metadata:\n[Node]: Description. {\n\"instantiations\": [\"node_TRUE\", \"node_FALSE\"],\n\"priors\": { \"p(node_TRUE)\": \"0.7\", \"p(node_FALSE)\": \"0.3\" },\n\"posteriors\": { \"p(node_TRUE|parent_TRUE)\": \"0.9\", \"p(node_TRUE|parent_FALSE)\": \"0.4\" }\n}\nThe result is a hybrid representation that preserves the narrative structure of arguments while adding the mathematical precision of Bayesian networks.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#probability-extraction-questions-argdown.csv-to-argdown_withquestions.csv",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#probability-extraction-questions-argdown.csv-to-argdown_withquestions.csv",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "F.3 2.1 Probability Extraction Questions — ‘ArgDown.csv’ to ‘ArgDown_WithQuestions.csv’",
    "text": "F.3 2.1 Probability Extraction Questions — ‘ArgDown.csv’ to ‘ArgDown_WithQuestions.csv’\n\n\nCode\n# @title 2.1 --- Probability Extraction Questions Generation ---\n\n\"\"\"\nBLOCK PURPOSE: Generates probability questions for ArgDown nodes to prepare for BayesDown conversion.\n\nThis block implements a key step in the pipeline where structure (from ArgDown) is prepared\nfor probability integration (to create BayesDown). It:\n\n1. Processes a CSV file containing ArgDown structure\n2. For each node, generates appropriate probability questions:\n   - Prior probability questions for all nodes\n   - Conditional probability questions for nodes with parents\n3. Creates a new CSV file with these questions ready for the next stage\n\nThe generated questions serve as placeholders that will be answered in the\nprobability extraction phase to complete the Bayesian network.\n\nDEPENDENCIES: pandas, json, itertools libraries\nINPUTS: ArgDown CSV file\nOUTPUTS: Enhanced CSV with probability questions for each node\n\"\"\"\n\nimport pandas as pd\nimport re\nimport json\nimport itertools\nfrom IPython.display import Markdown, display\n\n\ndef parse_instantiations(instantiations_str):\n    \"\"\"\n    Parse instantiations from string or list format.\n    Handles various input formats flexibly.\n\n    Args:\n        instantiations_str: Instantiations in string or list format\n\n    Returns:\n        list: Parsed instantiations as a list\n    \"\"\"\n    if pd.isna(instantiations_str) or instantiations_str == '':\n        return []\n\n    if isinstance(instantiations_str, list):\n        return instantiations_str\n\n    try:\n        # Try to parse as JSON\n        return json.loads(instantiations_str)\n    except:\n        # Try to parse as string list\n        if isinstance(instantiations_str, str):\n            # Remove brackets and split by comma\n            clean_str = instantiations_str.strip('[]\"\\'')\n            if not clean_str:\n                return []\n            return [s.strip(' \"\\'') for s in clean_str.split(',') if s.strip()]\n\n    return []\n\ndef parse_parents(parents_str):\n    \"\"\"\n    Parse parents from string or list format.\n    Handles various input formats flexibly.\n\n    Args:\n        parents_str: Parents in string or list format\n\n    Returns:\n        list: Parsed parents as a list\n    \"\"\"\n    if pd.isna(parents_str) or parents_str == '':\n        return []\n\n    if isinstance(parents_str, list):\n        return parents_str\n\n    try:\n        # Try to parse as JSON\n        return json.loads(parents_str)\n    except:\n        # Try to parse as string list\n        if isinstance(parents_str, str):\n            # Remove brackets and split by comma\n            clean_str = parents_str.strip('[]\"\\'')\n            if not clean_str:\n                return []\n            return [s.strip(' \"\\'') for s in clean_str.split(',') if s.strip()]\n\n    return []\n\ndef get_parent_instantiations(parent, df):\n    \"\"\"\n    Get the instantiations for a parent node from the DataFrame.\n    Returns default instantiations if not found.\n\n    Args:\n        parent (str): Parent node name\n        df (DataFrame): DataFrame containing node information\n\n    Returns:\n        list: Instantiations for the parent node\n    \"\"\"\n    parent_row = df[df['Title'] == parent]\n    if parent_row.empty:\n        return [f\"{parent}_TRUE\", f\"{parent}_FALSE\"]\n\n    instantiations = parse_instantiations(parent_row.iloc[0]['instantiations'])\n    if not instantiations:\n        return [f\"{parent}_TRUE\", f\"{parent}_FALSE\"]\n\n    return instantiations\n\ndef generate_instantiation_questions(title, instantiation, parents, df):\n    \"\"\"\n    Generate questions for a specific instantiation of a node.\n\n    Args:\n        title (str): The title of the node\n        instantiation (str): The specific instantiation (e.g., \"title_TRUE\")\n        parents (list): List of parent nodes\n        df (DataFrame): The full DataFrame for looking up parent instantiations\n\n    Returns:\n        dict: Dictionary mapping questions to estimate keys\n    \"\"\"\n    questions = {}\n\n    # Always generate a prior probability question, regardless of parents\n    prior_question = f\"What is the probability for {title}={instantiation}?\"\n    questions[prior_question] = 'prior'  # Question is the key, 'prior' is the value\n\n    # If no parents, return only the prior question\n    if not parents:\n        return questions\n\n    # For nodes with parents, generate conditional probability questions\n    # Get all combinations of parent instantiations\n    parent_instantiations = []\n    for parent in parents:\n        parent_insts = get_parent_instantiations(parent, df)\n        parent_instantiations.append([(parent, inst) for inst in parent_insts])\n\n    # Generate all combinations\n    all_combinations = list(itertools.product(*parent_instantiations))\n\n    # Create conditional probability questions for each combination\n    # and use questions as keys, estimate_i as values\n    for i, combination in enumerate(all_combinations):\n        condition_str = \", \".join([f\"{parent}={inst}\" for parent, inst in combination])\n        question = f\"What is the probability for {title}={instantiation} if {condition_str}?\"\n        questions[question] = f'estimate_{i + 1}'  # Question is the key, estimate_i is the value\n\n    return questions\n\n\ndef generate_argdown_with_questions(argdown_csv_path, output_csv_path):\n    \"\"\"\n    Generate probability questions based on the ArgDown CSV file and save to a new CSV file.\n\n    Args:\n        argdown_csv_path (str): Path to the input ArgDown CSV file\n        output_csv_path (str): Path to save the output CSV file with questions\n\n    Returns:\n        DataFrame: Enhanced DataFrame with probability questions\n\n    Raises:\n        Exception: If CSV loading fails or required columns are missing\n    \"\"\"\n    print(f\"Loading ArgDown CSV from {argdown_csv_path}...\")\n\n    # Load the ArgDown CSV file\n    try:\n        df = pd.read_csv(argdown_csv_path)\n        print(f\"Successfully loaded CSV with {len(df)} rows.\")\n    except Exception as e:\n        raise Exception(f\"Error loading ArgDown CSV: {e}\")\n\n    # Validate required columns\n    required_columns = ['Title', 'Parents', 'instantiations']\n    missing_columns = [col for col in required_columns if col not in df.columns]\n    if missing_columns:\n        raise Exception(f\"Missing required columns: {', '.join(missing_columns)}\")\n\n    # Initialize columns for questions\n    df['Generate_Positive_Instantiation_Questions'] = None\n    df['Generate_Negative_Instantiation_Questions'] = None\n\n    print(\"Generating probability questions for each node...\")\n\n    # Process each row to generate questions\n    for idx, row in df.iterrows():\n        title = row['Title']\n        instantiations = parse_instantiations(row['instantiations'])\n        parents = parse_parents(row['Parents'])\n\n        if len(instantiations) &lt; 2:\n            # Default instantiations if not provided\n            instantiations = [f\"{title}_TRUE\", f\"{title}_FALSE\"]\n\n        # Generate positive instantiation questions\n        positive_questions = generate_instantiation_questions(title, instantiations[0], parents, df)\n\n        # Generate negative instantiation questions\n        negative_questions = generate_instantiation_questions(title, instantiations[1], parents, df)\n\n        # Update the DataFrame\n        df.at[idx, 'Generate_Positive_Instantiation_Questions'] = json.dumps(positive_questions)\n        df.at[idx, 'Generate_Negative_Instantiation_Questions'] = json.dumps(negative_questions)\n\n    # Save the enhanced DataFrame\n    df.to_csv(output_csv_path, index=False)\n    print(f\"Generated questions saved to {output_csv_path}\")\n\n    return df\n\n# Example usage:\ndf_with_questions = generate_argdown_with_questions(\"ArgDown.csv\", \"ArgDown_WithQuestions.csv\")\n\n\nLoading ArgDown CSV from ArgDown.csv...\nSuccessfully loaded CSV with 23 rows.\nGenerating probability questions for each node...\nGenerated questions saved to ArgDown_WithQuestions.csv\n\n\n\n\nCode\n# Load the data from the ArgDown_WithQuestions CSV file\nargdown_with_questions_df = pd.read_csv('ArgDown_WithQuestions.csv')\n\n# Display the DataFrame\nprint(argdown_with_questions_df)\nargdown_with_questions_df\n\n\n                          Title  \\\n0       Existential_Catastrophe   \n1          Human_Disempowerment   \n2        Scale_Of_Power_Seeking   \n3      Misaligned_Power_Seeking   \n4                   APS_Systems   \n5        Advanced_AI_Capability   \n6              Agentic_Planning   \n7           Strategic_Awareness   \n8       Difficulty_Of_Alignment   \n9      Instrumental_Convergence   \n10        Problems_With_Proxies   \n11         Problems_With_Search   \n12         Deployment_Decisions   \n13      Incentives_To_Build_APS   \n14            Usefulness_Of_APS   \n15         Competitive_Dynamics   \n16              Deception_By_AI   \n17          Corrective_Feedback   \n18                Warning_Shots   \n19  Rapid_Capability_Escalation   \n20    Barriers_To_Understanding   \n21         Adversarial_Dynamics   \n22              Stakes_Of_Error   \n\n                                          Description  line     line_numbers  \\\n0   The destruction of humanity's long-term potent...     0              [0]   \n1   Permanent and collective disempowerment of hum...     1              [1]   \n2   Power-seeking by AI systems scaling to the poi...     2              [2]   \n3   Deployed AI systems seeking power in unintende...     3  [3, 21, 23, 25]   \n4   AI systems with advanced capabilities, agentic...     4              [4]   \n5   AI systems that outperform humans on tasks tha...     5              [5]   \n6   AI systems making and executing plans based on...     6              [6]   \n7   AI systems with models accurately representing...     7              [7]   \n8   It is harder to build aligned systems than mis...     8              [8]   \n9   AI systems with misaligned objectives tend to ...     9              [9]   \n10  Optimizing for proxy objectives breaks correla...    10             [10]   \n11  Search processes can yield systems pursuing di...    11             [11]   \n12  Decisions to deploy potentially misaligned AI ...    12             [12]   \n13  Strong incentives to build and deploy APS syst...    13             [13]   \n14  APS systems are very useful for many valuable ...    14             [14]   \n15       Competitive pressures between AI developers.    15             [15]   \n16  AI systems deceiving humans about their true o...    16             [16]   \n17  Human society implementing corrections after o...    17             [17]   \n18  Observable failures in weaker systems before c...    18             [18]   \n19  AI capabilities escalating very rapidly, allow...    19             [19]   \n20  Difficulty in understanding the internal worki...    20             [20]   \n21  Potentially adversarial relationships between ...    22             [22]   \n22  The escalating impact of mistakes with power-s...    24             [24]   \n\n    indentation indentation_levels  \\\n0             0                [0]   \n1             0                [0]   \n2             4                [4]   \n3             8       [8, 0, 0, 0]   \n4            12               [12]   \n5            16               [16]   \n6            16               [16]   \n7            16               [16]   \n8            12               [12]   \n9            16               [16]   \n10           16               [16]   \n11           16               [16]   \n12           12               [12]   \n13           16               [16]   \n14           20               [20]   \n15           20               [20]   \n16           16               [16]   \n17            8                [8]   \n18           12               [12]   \n19           12               [12]   \n20            0                [0]   \n21            0                [0]   \n22            0                [0]   \n\n                                              Parents  \\\n0                                                  []   \n1                          ['Scale_Of_Power_Seeking']   \n2   ['Misaligned_Power_Seeking', 'Corrective_Feedb...   \n3   ['APS_Systems', 'Difficulty_Of_Alignment', 'De...   \n4   ['Advanced_AI_Capability', 'Agentic_Planning',...   \n5                                                  []   \n6                                                  []   \n7                                                  []   \n8   ['Instrumental_Convergence', 'Problems_With_Pr...   \n9                                                  []   \n10                                                 []   \n11                                                 []   \n12     ['Incentives_To_Build_APS', 'Deception_By_AI']   \n13      ['Usefulness_Of_APS', 'Competitive_Dynamics']   \n14                                                 []   \n15                                                 []   \n16                                                 []   \n17   ['Warning_Shots', 'Rapid_Capability_Escalation']   \n18                                                 []   \n19                                                 []   \n20                                                 []   \n21                                                 []   \n22                                                 []   \n\n                        Children  \\\n0                             []   \n1                             []   \n2       ['Human_Disempowerment']   \n3     ['Scale_Of_Power_Seeking']   \n4   ['Misaligned_Power_Seeking']   \n5                ['APS_Systems']   \n6                ['APS_Systems']   \n7                ['APS_Systems']   \n8   ['Misaligned_Power_Seeking']   \n9    ['Difficulty_Of_Alignment']   \n10   ['Difficulty_Of_Alignment']   \n11   ['Difficulty_Of_Alignment']   \n12  ['Misaligned_Power_Seeking']   \n13      ['Deployment_Decisions']   \n14   ['Incentives_To_Build_APS']   \n15   ['Incentives_To_Build_APS']   \n16      ['Deployment_Decisions']   \n17    ['Scale_Of_Power_Seeking']   \n18       ['Corrective_Feedback']   \n19       ['Corrective_Feedback']   \n20                            []   \n21                            []   \n22                            []   \n\n                                       instantiations  No_Parent  No_Children  \\\n0   ['existential_catastrophe_TRUE', 'existential_...       True         True   \n1   ['human_disempowerment_TRUE', 'human_disempowe...      False         True   \n2   ['scale_of_power_seeking_TRUE', 'scale_of_powe...      False        False   \n3   ['misaligned_power_seeking_TRUE', 'misaligned_...      False        False   \n4           ['aps_systems_TRUE', 'aps_systems_FALSE']      False        False   \n5   ['advanced_ai_capability_TRUE', 'advanced_ai_c...       True        False   \n6   ['agentic_planning_TRUE', 'agentic_planning_FA...       True        False   \n7   ['strategic_awareness_TRUE', 'strategic_awaren...       True        False   \n8   ['difficulty_of_alignment_TRUE', 'difficulty_o...      False        False   \n9   ['instrumental_convergence_TRUE', 'instrumenta...       True        False   \n10  ['problems_with_proxies_TRUE', 'problems_with_...       True        False   \n11  ['problems_with_search_TRUE', 'problems_with_s...       True        False   \n12  ['deployment_decisions_DEPLOY', 'deployment_de...      False        False   \n13  ['incentives_to_build_aps_STRONG', 'incentives...      False        False   \n14  ['usefulness_of_aps_HIGH', 'usefulness_of_aps_...       True        False   \n15  ['competitive_dynamics_STRONG', 'competitive_d...       True        False   \n16  ['deception_by_ai_TRUE', 'deception_by_ai_FALSE']       True        False   \n17  ['corrective_feedback_EFFECTIVE', 'corrective_...      False        False   \n18  ['warning_shots_OBSERVED', 'warning_shots_UNOB...       True        False   \n19  ['rapid_capability_escalation_TRUE', 'rapid_ca...       True        False   \n20  ['barriers_to_understanding_HIGH', 'barriers_t...       True         True   \n21  ['adversarial_dynamics_TRUE', 'adversarial_dyn...       True         True   \n22    ['stakes_of_error_HIGH', 'stakes_of_error_LOW']       True         True   \n\n                                parent_instantiations  \\\n0                                                  []   \n1   [['scale_of_power_seeking_TRUE', 'scale_of_pow...   \n2   [['misaligned_power_seeking_TRUE', 'misaligned...   \n3   [['aps_systems_TRUE', 'aps_systems_FALSE'], ['...   \n4   [['advanced_ai_capability_TRUE', 'advanced_ai_...   \n5                                                  []   \n6                                                  []   \n7                                                  []   \n8   [['instrumental_convergence_TRUE', 'instrument...   \n9                                                  []   \n10                                                 []   \n11                                                 []   \n12  [['incentives_to_build_aps_STRONG', 'incentive...   \n13  [['usefulness_of_aps_HIGH', 'usefulness_of_aps...   \n14                                                 []   \n15                                                 []   \n16                                                 []   \n17  [['warning_shots_OBSERVED', 'warning_shots_UNO...   \n18                                                 []   \n19                                                 []   \n20                                                 []   \n21                                                 []   \n22                                                 []   \n\n            Generate_Positive_Instantiation_Questions  \\\n0   {\"What is the probability for Existential_Cata...   \n1   {\"What is the probability for Human_Disempower...   \n2   {\"What is the probability for Scale_Of_Power_S...   \n3   {\"What is the probability for Misaligned_Power...   \n4   {\"What is the probability for APS_Systems=aps_...   \n5   {\"What is the probability for Advanced_AI_Capa...   \n6   {\"What is the probability for Agentic_Planning...   \n7   {\"What is the probability for Strategic_Awaren...   \n8   {\"What is the probability for Difficulty_Of_Al...   \n9   {\"What is the probability for Instrumental_Con...   \n10  {\"What is the probability for Problems_With_Pr...   \n11  {\"What is the probability for Problems_With_Se...   \n12  {\"What is the probability for Deployment_Decis...   \n13  {\"What is the probability for Incentives_To_Bu...   \n14  {\"What is the probability for Usefulness_Of_AP...   \n15  {\"What is the probability for Competitive_Dyna...   \n16  {\"What is the probability for Deception_By_AI=...   \n17  {\"What is the probability for Corrective_Feedb...   \n18  {\"What is the probability for Warning_Shots=wa...   \n19  {\"What is the probability for Rapid_Capability...   \n20  {\"What is the probability for Barriers_To_Unde...   \n21  {\"What is the probability for Adversarial_Dyna...   \n22  {\"What is the probability for Stakes_Of_Error=...   \n\n            Generate_Negative_Instantiation_Questions  \n0   {\"What is the probability for Existential_Cata...  \n1   {\"What is the probability for Human_Disempower...  \n2   {\"What is the probability for Scale_Of_Power_S...  \n3   {\"What is the probability for Misaligned_Power...  \n4   {\"What is the probability for APS_Systems=aps_...  \n5   {\"What is the probability for Advanced_AI_Capa...  \n6   {\"What is the probability for Agentic_Planning...  \n7   {\"What is the probability for Strategic_Awaren...  \n8   {\"What is the probability for Difficulty_Of_Al...  \n9   {\"What is the probability for Instrumental_Con...  \n10  {\"What is the probability for Problems_With_Pr...  \n11  {\"What is the probability for Problems_With_Se...  \n12  {\"What is the probability for Deployment_Decis...  \n13  {\"What is the probability for Incentives_To_Bu...  \n14  {\"What is the probability for Usefulness_Of_AP...  \n15  {\"What is the probability for Competitive_Dyna...  \n16  {\"What is the probability for Deception_By_AI=...  \n17  {\"What is the probability for Corrective_Feedb...  \n18  {\"What is the probability for Warning_Shots=wa...  \n19  {\"What is the probability for Rapid_Capability...  \n20  {\"What is the probability for Barriers_To_Unde...  \n21  {\"What is the probability for Adversarial_Dyna...  \n22  {\"What is the probability for Stakes_Of_Error=...  \n\n\n\n    \n\n\n\n\n\n\nTitle\nDescription\nline\nline_numbers\nindentation\nindentation_levels\nParents\nChildren\ninstantiations\nNo_Parent\nNo_Children\nparent_instantiations\nGenerate_Positive_Instantiation_Questions\nGenerate_Negative_Instantiation_Questions\n\n\n\n\n0\nExistential_Catastrophe\nThe destruction of humanity's long-term potent...\n0\n[0]\n0\n[0]\n[]\n[]\n['existential_catastrophe_TRUE', 'existential_...\nTrue\nTrue\n[]\n{\"What is the probability for Existential_Cata...\n{\"What is the probability for Existential_Cata...\n\n\n1\nHuman_Disempowerment\nPermanent and collective disempowerment of hum...\n1\n[1]\n0\n[0]\n['Scale_Of_Power_Seeking']\n[]\n['human_disempowerment_TRUE', 'human_disempowe...\nFalse\nTrue\n[['scale_of_power_seeking_TRUE', 'scale_of_pow...\n{\"What is the probability for Human_Disempower...\n{\"What is the probability for Human_Disempower...\n\n\n2\nScale_Of_Power_Seeking\nPower-seeking by AI systems scaling to the poi...\n2\n[2]\n4\n[4]\n['Misaligned_Power_Seeking', 'Corrective_Feedb...\n['Human_Disempowerment']\n['scale_of_power_seeking_TRUE', 'scale_of_powe...\nFalse\nFalse\n[['misaligned_power_seeking_TRUE', 'misaligned...\n{\"What is the probability for Scale_Of_Power_S...\n{\"What is the probability for Scale_Of_Power_S...\n\n\n3\nMisaligned_Power_Seeking\nDeployed AI systems seeking power in unintende...\n3\n[3, 21, 23, 25]\n8\n[8, 0, 0, 0]\n['APS_Systems', 'Difficulty_Of_Alignment', 'De...\n['Scale_Of_Power_Seeking']\n['misaligned_power_seeking_TRUE', 'misaligned_...\nFalse\nFalse\n[['aps_systems_TRUE', 'aps_systems_FALSE'], ['...\n{\"What is the probability for Misaligned_Power...\n{\"What is the probability for Misaligned_Power...\n\n\n4\nAPS_Systems\nAI systems with advanced capabilities, agentic...\n4\n[4]\n12\n[12]\n['Advanced_AI_Capability', 'Agentic_Planning',...\n['Misaligned_Power_Seeking']\n['aps_systems_TRUE', 'aps_systems_FALSE']\nFalse\nFalse\n[['advanced_ai_capability_TRUE', 'advanced_ai_...\n{\"What is the probability for APS_Systems=aps_...\n{\"What is the probability for APS_Systems=aps_...\n\n\n5\nAdvanced_AI_Capability\nAI systems that outperform humans on tasks tha...\n5\n[5]\n16\n[16]\n[]\n['APS_Systems']\n['advanced_ai_capability_TRUE', 'advanced_ai_c...\nTrue\nFalse\n[]\n{\"What is the probability for Advanced_AI_Capa...\n{\"What is the probability for Advanced_AI_Capa...\n\n\n6\nAgentic_Planning\nAI systems making and executing plans based on...\n6\n[6]\n16\n[16]\n[]\n['APS_Systems']\n['agentic_planning_TRUE', 'agentic_planning_FA...\nTrue\nFalse\n[]\n{\"What is the probability for Agentic_Planning...\n{\"What is the probability for Agentic_Planning...\n\n\n7\nStrategic_Awareness\nAI systems with models accurately representing...\n7\n[7]\n16\n[16]\n[]\n['APS_Systems']\n['strategic_awareness_TRUE', 'strategic_awaren...\nTrue\nFalse\n[]\n{\"What is the probability for Strategic_Awaren...\n{\"What is the probability for Strategic_Awaren...\n\n\n8\nDifficulty_Of_Alignment\nIt is harder to build aligned systems than mis...\n8\n[8]\n12\n[12]\n['Instrumental_Convergence', 'Problems_With_Pr...\n['Misaligned_Power_Seeking']\n['difficulty_of_alignment_TRUE', 'difficulty_o...\nFalse\nFalse\n[['instrumental_convergence_TRUE', 'instrument...\n{\"What is the probability for Difficulty_Of_Al...\n{\"What is the probability for Difficulty_Of_Al...\n\n\n9\nInstrumental_Convergence\nAI systems with misaligned objectives tend to ...\n9\n[9]\n16\n[16]\n[]\n['Difficulty_Of_Alignment']\n['instrumental_convergence_TRUE', 'instrumenta...\nTrue\nFalse\n[]\n{\"What is the probability for Instrumental_Con...\n{\"What is the probability for Instrumental_Con...\n\n\n10\nProblems_With_Proxies\nOptimizing for proxy objectives breaks correla...\n10\n[10]\n16\n[16]\n[]\n['Difficulty_Of_Alignment']\n['problems_with_proxies_TRUE', 'problems_with_...\nTrue\nFalse\n[]\n{\"What is the probability for Problems_With_Pr...\n{\"What is the probability for Problems_With_Pr...\n\n\n11\nProblems_With_Search\nSearch processes can yield systems pursuing di...\n11\n[11]\n16\n[16]\n[]\n['Difficulty_Of_Alignment']\n['problems_with_search_TRUE', 'problems_with_s...\nTrue\nFalse\n[]\n{\"What is the probability for Problems_With_Se...\n{\"What is the probability for Problems_With_Se...\n\n\n12\nDeployment_Decisions\nDecisions to deploy potentially misaligned AI ...\n12\n[12]\n12\n[12]\n['Incentives_To_Build_APS', 'Deception_By_AI']\n['Misaligned_Power_Seeking']\n['deployment_decisions_DEPLOY', 'deployment_de...\nFalse\nFalse\n[['incentives_to_build_aps_STRONG', 'incentive...\n{\"What is the probability for Deployment_Decis...\n{\"What is the probability for Deployment_Decis...\n\n\n13\nIncentives_To_Build_APS\nStrong incentives to build and deploy APS syst...\n13\n[13]\n16\n[16]\n['Usefulness_Of_APS', 'Competitive_Dynamics']\n['Deployment_Decisions']\n['incentives_to_build_aps_STRONG', 'incentives...\nFalse\nFalse\n[['usefulness_of_aps_HIGH', 'usefulness_of_aps...\n{\"What is the probability for Incentives_To_Bu...\n{\"What is the probability for Incentives_To_Bu...\n\n\n14\nUsefulness_Of_APS\nAPS systems are very useful for many valuable ...\n14\n[14]\n20\n[20]\n[]\n['Incentives_To_Build_APS']\n['usefulness_of_aps_HIGH', 'usefulness_of_aps_...\nTrue\nFalse\n[]\n{\"What is the probability for Usefulness_Of_AP...\n{\"What is the probability for Usefulness_Of_AP...\n\n\n15\nCompetitive_Dynamics\nCompetitive pressures between AI developers.\n15\n[15]\n20\n[20]\n[]\n['Incentives_To_Build_APS']\n['competitive_dynamics_STRONG', 'competitive_d...\nTrue\nFalse\n[]\n{\"What is the probability for Competitive_Dyna...\n{\"What is the probability for Competitive_Dyna...\n\n\n16\nDeception_By_AI\nAI systems deceiving humans about their true o...\n16\n[16]\n16\n[16]\n[]\n['Deployment_Decisions']\n['deception_by_ai_TRUE', 'deception_by_ai_FALSE']\nTrue\nFalse\n[]\n{\"What is the probability for Deception_By_AI=...\n{\"What is the probability for Deception_By_AI=...\n\n\n17\nCorrective_Feedback\nHuman society implementing corrections after o...\n17\n[17]\n8\n[8]\n['Warning_Shots', 'Rapid_Capability_Escalation']\n['Scale_Of_Power_Seeking']\n['corrective_feedback_EFFECTIVE', 'corrective_...\nFalse\nFalse\n[['warning_shots_OBSERVED', 'warning_shots_UNO...\n{\"What is the probability for Corrective_Feedb...\n{\"What is the probability for Corrective_Feedb...\n\n\n18\nWarning_Shots\nObservable failures in weaker systems before c...\n18\n[18]\n12\n[12]\n[]\n['Corrective_Feedback']\n['warning_shots_OBSERVED', 'warning_shots_UNOB...\nTrue\nFalse\n[]\n{\"What is the probability for Warning_Shots=wa...\n{\"What is the probability for Warning_Shots=wa...\n\n\n19\nRapid_Capability_Escalation\nAI capabilities escalating very rapidly, allow...\n19\n[19]\n12\n[12]\n[]\n['Corrective_Feedback']\n['rapid_capability_escalation_TRUE', 'rapid_ca...\nTrue\nFalse\n[]\n{\"What is the probability for Rapid_Capability...\n{\"What is the probability for Rapid_Capability...\n\n\n20\nBarriers_To_Understanding\nDifficulty in understanding the internal worki...\n20\n[20]\n0\n[0]\n[]\n[]\n['barriers_to_understanding_HIGH', 'barriers_t...\nTrue\nTrue\n[]\n{\"What is the probability for Barriers_To_Unde...\n{\"What is the probability for Barriers_To_Unde...\n\n\n21\nAdversarial_Dynamics\nPotentially adversarial relationships between ...\n22\n[22]\n0\n[0]\n[]\n[]\n['adversarial_dynamics_TRUE', 'adversarial_dyn...\nTrue\nTrue\n[]\n{\"What is the probability for Adversarial_Dyna...\n{\"What is the probability for Adversarial_Dyna...\n\n\n22\nStakes_Of_Error\nThe escalating impact of mistakes with power-s...\n24\n[24]\n0\n[0]\n[]\n[]\n['stakes_of_error_HIGH', 'stakes_of_error_LOW']\nTrue\nTrue\n[]\n{\"What is the probability for Stakes_Of_Error=...\n{\"What is the probability for Stakes_Of_Error=...",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#argdown_withquestions.csv-to-bayesdownquestions.md",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#argdown_withquestions.csv-to-bayesdownquestions.md",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "F.4 2.2 ‘ArgDown_WithQuestions.csv’ to ‘BayesDownQuestions.md’",
    "text": "F.4 2.2 ‘ArgDown_WithQuestions.csv’ to ‘BayesDownQuestions.md’\n2.2 Save BayesDown Extraction Questions as ‘BayesDownQuestions.md’\n\n\nCode\n# @title 2.2 --- BayesDown Questions Generation ---\n\n\"\"\"\nBLOCK PURPOSE: Transforms the ArgDown with questions into a BayesDown template with placeholders.\n\nThis function creates a BayesDown representation with probability placeholders based on the questions generated in the previous step. It:\n\n1. Loads the CSV file with probability questions\n2. Constructs a directed graph to represent the causal structure\n3. Processes each node to create BayesDown syntax with probability placeholders\n4. Optionally includes comments with the specific questions to be answered\n5. Saves the result as a markdown file for the next stage of the pipeline\n\nThe output is a BayesDown template that can be used in the probability extraction phase, where the placeholders will be replaced with actual probability values.\n\nDEPENDENCIES: networkx, pandas, json libraries\nINPUTS: CSV file with ArgDown structure and probability questions\nOUTPUTS: BayesDown markdown file with probability placeholders\n\"\"\"\n\ndef extract_bayesdown_questions_fixed(argdown_with_questions_path, output_md_path, include_questions_as_comments=True):\n  \"\"\"\n  Generate BayesDown syntax from the ArgDown_WithQuestions CSV file with correct parent-child relationships.\n\n  Args:\n      argdown_with_questions_path (str): Path to the CSV file with probability questions\n      output_md_path (str): Path to save the output BayesDown file\n      include_questions_as_comments (bool, optional): Whether to include the original\n                                                    questions as comments. Defaults to True.\n\n  Returns:\n      str: The generated BayesDown content\n\n  Raises:\n      Exception: If CSV loading fails or required columns are missing\n  \"\"\"\n  print(f\"Loading CSV from {argdown_with_questions_path}...\")\n\n  # Load the CSV file\n  try:\n      df = pd.read_csv(argdown_with_questions_path)\n      print(f\"Successfully loaded CSV with {len(df)} rows.\")\n  except Exception as e:\n      raise Exception(f\"Error loading CSV: {e}\")\n\n  # Validate required columns\n  required_columns = ['Title', 'Description', 'Parents', 'Children', 'instantiations']\n  missing_columns = [col for col in required_columns if col not in df.columns]\n  if missing_columns:\n      raise Exception(f\"Missing required columns: {', '.join(missing_columns)}\")\n\n  print(\"Generating BayesDown syntax with placeholder probabilities...\")\n\n  # Build a directed graph of nodes\n  G = nx.DiGraph()\n\n  # Add nodes to the graph\n  for idx, row in df.iterrows():\n      G.add_node(row['Title'], data=row)\n\n  # Add edges to the graph based on parent-child relationships - CORRECTLY\n  for idx, row in df.iterrows():\n      child = row['Title']\n\n      # Parse parents and add edges\n      parents = row['Parents']\n      if isinstance(parents, str):\n          # Handle string representation of list\n          if parents.startswith('[') and parents.endswith(']'):\n              parents = parents.strip('[]')\n              if parents:  # Check if not empty\n                  parent_list = [p.strip().strip('\\'\"') for p in parents.split(',')]\n                  for parent in parent_list:\n                      if parent in G.nodes():\n                          # In BayesDown: Parent (cause) -&gt; Child (effect)\n                          G.add_edge(parent, child)\n      elif isinstance(parents, list):\n          # Handle actual list\n          for parent in parents:\n              if parent in G.nodes():\n                  G.add_edge(parent, child)\n\n  # Function to safely parse JSON strings\n  def safe_parse_json(json_str):\n      if pd.isna(json_str):\n          return {}\n\n      if isinstance(json_str, dict):\n          return json_str\n\n      try:\n          return json.loads(json_str)\n      except:\n          return {}\n\n  # Start building the BayesDown content\n  bayesdown_content = \"\"  # Initialize as empty\n\n  if include_questions_as_comments:\n    bayesdown_content = \"# BayesDown Representation with Placeholder Probabilities\\n\\n\"\n    bayesdown_content += \"/* This file contains BayesDown syntax with placeholder probabilities.\\n\"\n    bayesdown_content += \"   Replace the placeholders with actual probability values based on the \\n\"\n    bayesdown_content += \"   questions in the comments. */\\n\\n\"\n\n  # Get leaf nodes (nodes with no outgoing edges) - these are effects without children\n  leaf_nodes = [n for n in G.nodes() if G.out_degree(n) == 0]\n\n  # Helper function to process a node and its parents recursively\n  def process_node(node, indent_level=0, processed_nodes=None):\n      if processed_nodes is None:\n          processed_nodes = set()\n\n      # Create the indentation string\n      indent = ' ' * (indent_level * 2)\n      prefix = f\"{indent}+ \" if indent_level &gt; 0 else \"\"\n\n      # Get node data\n      node_data = G.nodes[node]['data']\n      title = node_data['Title']\n      description = node_data['Description'] if not pd.isna(node_data['Description']) else \"\"\n\n      # Parse instantiations from the row data\n      instantiations = parse_instantiations_safely(node_data['instantiations'])\n\n      # Build the node string\n      node_output = \"\"\n\n      # Add comments with questions if requested\n      if include_questions_as_comments:\n          # Add positive questions as comments\n          if 'Generate_Positive_Instantiation_Questions' in node_data:\n              positive_questions = safe_parse_json(node_data['Generate_Positive_Instantiation_Questions'])\n              for question in positive_questions.keys():\n                  node_output += f\"{indent}/* {question} */\\n\"\n\n          # Add negative questions as comments\n          if 'Generate_Negative_Instantiation_Questions' in node_data:\n              negative_questions = safe_parse_json(node_data['Generate_Negative_Instantiation_Questions'])\n              for question in negative_questions.keys():\n                  node_output += f\"{indent}/* {question} */\\n\"\n\n      # Check if this node was already fully defined elsewhere\n      if node in processed_nodes:\n          # Just add a reference to the node\n          node_output += f\"{prefix}[{title}]\\n\"\n          return node_output\n\n      # Mark this node as processed\n      processed_nodes.add(node)\n\n      # Prepare the metadata JSON\n      metadata = {\n          \"instantiations\": instantiations\n      }\n\n      # Add priors with full questions as keys\n      priors = {}\n      if 'Generate_Positive_Instantiation_Questions' in node_data:\n          positive_questions = safe_parse_json(node_data['Generate_Positive_Instantiation_Questions'])\n          for question, estimate_key in positive_questions.items():\n              if estimate_key == 'prior':\n                  priors[question] = \"%?\"  # Default placeholder\n\n      if 'Generate_Negative_Instantiation_Questions' in node_data:\n          negative_questions = safe_parse_json(node_data['Generate_Negative_Instantiation_Questions'])\n          for question, estimate_key in negative_questions.items():\n              if estimate_key == 'prior':\n                  priors[question] = \"%?\"  # Default placeholder\n\n      metadata[\"priors\"] = priors\n\n      # Add posteriors with full questions as keys\n      parents = list(G.predecessors(node))\n      if parents:\n          posteriors = {}\n          if 'Generate_Positive_Instantiation_Questions' in node_data:\n              positive_questions = safe_parse_json(node_data['Generate_Positive_Instantiation_Questions'])\n              for question, estimate_key in positive_questions.items():\n                  if estimate_key.startswith('estimate_'):\n                      posteriors[question] = \"?%\"  # Default placeholder\n\n          if 'Generate_Negative_Instantiation_Questions' in node_data:\n              negative_questions = safe_parse_json(node_data['Generate_Negative_Instantiation_Questions'])\n              for question, estimate_key in negative_questions.items():\n                  if estimate_key.startswith('estimate_'):\n                      posteriors[question] = \"?%\"  # Default placeholder\n\n          metadata[\"posteriors\"] = posteriors\n\n      # Format the node with metadata\n      node_output += f\"{prefix}[{title}]: {description} {json.dumps(metadata)}\\n\"\n\n      # Process parent nodes\n      for parent in parents:\n          if parent != node:  # Avoid self-references\n              parent_output = process_node(parent, indent_level + 1, processed_nodes)\n              node_output += parent_output\n\n      return node_output\n\n  # Helper function to parse instantiations safely\n  def parse_instantiations_safely(instantiations_data):\n      if isinstance(instantiations_data, list):\n          return instantiations_data if instantiations_data else [f\"TRUE\", f\"FALSE\"]\n\n      if isinstance(instantiations_data, str):\n          try:\n              parsed = json.loads(instantiations_data)\n              if isinstance(parsed, list):\n                  return parsed if parsed else [f\"TRUE\", f\"FALSE\"]\n          except:\n              if instantiations_data.startswith('[') and instantiations_data.endswith(']'):\n                  items = instantiations_data.strip('[]').split(',')\n                  result = [item.strip(' \"\\'') for item in items if item.strip()]\n                  return result if result else [f\"TRUE\", f\"FALSE\"]\n\n      return [f\"TRUE\", f\"FALSE\"]  # Default\n\n  # Process each leaf node and its ancestors\n  for leaf in leaf_nodes:\n      bayesdown_content += process_node(leaf)\n\n  # Save the BayesDown content\n  with open(output_md_path, 'w') as f:\n      f.write(bayesdown_content)\n\n  print(f\"BayesDown Questions saved to {output_md_path}\")\n  return bayesdown_content\n\n\n\n\nCode\n# Explicitly set the value of include_questions_as_comments\ninclude_questions_as_comments=False  # or False, depending on your needs\n\n# Get the markdown content\nbayesdown_questions = extract_bayesdown_questions_fixed(\n  \"ArgDown_WithQuestions.csv\",\n  \"BayesDownQuestions.md\", include_questions_as_comments=include_questions_as_comments\n)\n\n# Determine the output file path based on include_questions_as_comments\nif include_questions_as_comments: # Assuming include_questions_as_comments is defined somewhere in previous cells\n    output_file_path = \"FULL_BayesDownQuestions.md\"\nelse:\n    output_file_path = \"BayesDownQuestions.md\"\n\n# Save the markdown content to the appropriate file\nwith open(output_file_path, 'w') as f:\n    f.write(md_content)\n\nprint(f\"Markdown content saved to {output_file_path}\")\n\n\nLoading CSV from ArgDown_WithQuestions.csv...\nSuccessfully loaded CSV with 23 rows.\nGenerating BayesDown syntax with placeholder probabilities...\nBayesDown Questions saved to BayesDownQuestions.md\nMarkdown content saved to BayesDownQuestions.md\n\n\n\n\nCode\n# Generate BayesDown format\nbayesdown_questions = extract_bayesdown_questions_fixed(\n    \"ArgDown_WithQuestions.csv\",\n    \"FULL_BayesDownQuestions.md\",\n    include_questions_as_comments=True\n)\n\n# Display a preview of the format\nprint(\"\\nBayesDown Format Preview:\")\nprint(bayesdown_questions[:50000] + \"...\\n\")\n\n\nLoading CSV from ArgDown_WithQuestions.csv...\nSuccessfully loaded CSV with 23 rows.\nGenerating BayesDown syntax with placeholder probabilities...\nBayesDown Questions saved to FULL_BayesDownQuestions.md\n\nBayesDown Format Preview:\n# BayesDown Representation with Placeholder Probabilities\n\n/* This file contains BayesDown syntax with placeholder probabilities.\n   Replace the placeholders with actual probability values based on the \n   questions in the comments. */\n\n/* What is the probability for Existential_Catastrophe=existential_catastrophe_TRUE? */\n/* What is the probability for Existential_Catastrophe=existential_catastrophe_FALSE? */\n[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {\"instantiations\": [\"existential_catastrophe_TRUE\", \"existential_catastrophe_FALSE\"], \"priors\": {\"What is the probability for Existential_Catastrophe=existential_catastrophe_TRUE?\": \"%?\", \"What is the probability for Existential_Catastrophe=existential_catastrophe_FALSE?\": \"%?\"}}\n/* What is the probability for Human_Disempowerment=human_disempowerment_TRUE? */\n/* What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE? */\n/* What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE? */\n/* What is the probability for Human_Disempowerment=human_disempowerment_FALSE? */\n/* What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE? */\n/* What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE? */\n[Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {\"instantiations\": [\"human_disempowerment_TRUE\", \"human_disempowerment_FALSE\"], \"priors\": {\"What is the probability for Human_Disempowerment=human_disempowerment_TRUE?\": \"%?\", \"What is the probability for Human_Disempowerment=human_disempowerment_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?\": \"?%\", \"What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?\": \"?%\", \"What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?\": \"?%\", \"What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?\": \"?%\"}}\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */\n  + [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {\"instantiations\": [\"scale_of_power_seeking_TRUE\", \"scale_of_power_seeking_FALSE\"], \"priors\": {\"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?\": \"%?\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\"}}\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    + [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"], \"priors\": {\"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE?\": \"%?\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\"}}\n      /* What is the probability for APS_Systems=aps_systems_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */\n      + [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {\"instantiations\": [\"aps_systems_TRUE\", \"aps_systems_FALSE\"], \"priors\": {\"What is the probability for APS_Systems=aps_systems_TRUE?\": \"%?\", \"What is the probability for APS_Systems=aps_systems_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\"}}\n        /* What is the probability for Advanced_AI_Capability=advanced_ai_capability_TRUE? */\n        /* What is the probability for Advanced_AI_Capability=advanced_ai_capability_FALSE? */\n        + [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {\"instantiations\": [\"advanced_ai_capability_TRUE\", \"advanced_ai_capability_FALSE\"], \"priors\": {\"What is the probability for Advanced_AI_Capability=advanced_ai_capability_TRUE?\": \"%?\", \"What is the probability for Advanced_AI_Capability=advanced_ai_capability_FALSE?\": \"%?\"}}\n        /* What is the probability for Agentic_Planning=agentic_planning_TRUE? */\n        /* What is the probability for Agentic_Planning=agentic_planning_FALSE? */\n        + [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {\"instantiations\": [\"agentic_planning_TRUE\", \"agentic_planning_FALSE\"], \"priors\": {\"What is the probability for Agentic_Planning=agentic_planning_TRUE?\": \"%?\", \"What is the probability for Agentic_Planning=agentic_planning_FALSE?\": \"%?\"}}\n        /* What is the probability for Strategic_Awareness=strategic_awareness_TRUE? */\n        /* What is the probability for Strategic_Awareness=strategic_awareness_FALSE? */\n        + [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {\"instantiations\": [\"strategic_awareness_TRUE\", \"strategic_awareness_FALSE\"], \"priors\": {\"What is the probability for Strategic_Awareness=strategic_awareness_TRUE?\": \"%?\", \"What is the probability for Strategic_Awareness=strategic_awareness_FALSE?\": \"%?\"}}\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */\n      + [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {\"instantiations\": [\"difficulty_of_alignment_TRUE\", \"difficulty_of_alignment_FALSE\"], \"priors\": {\"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE?\": \"%?\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\"}}\n        /* What is the probability for Instrumental_Convergence=instrumental_convergence_TRUE? */\n        /* What is the probability for Instrumental_Convergence=instrumental_convergence_FALSE? */\n        + [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {\"instantiations\": [\"instrumental_convergence_TRUE\", \"instrumental_convergence_FALSE\"], \"priors\": {\"What is the probability for Instrumental_Convergence=instrumental_convergence_TRUE?\": \"%?\", \"What is the probability for Instrumental_Convergence=instrumental_convergence_FALSE?\": \"%?\"}}\n        /* What is the probability for Problems_With_Proxies=problems_with_proxies_TRUE? */\n        /* What is the probability for Problems_With_Proxies=problems_with_proxies_FALSE? */\n        + [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {\"instantiations\": [\"problems_with_proxies_TRUE\", \"problems_with_proxies_FALSE\"], \"priors\": {\"What is the probability for Problems_With_Proxies=problems_with_proxies_TRUE?\": \"%?\", \"What is the probability for Problems_With_Proxies=problems_with_proxies_FALSE?\": \"%?\"}}\n        /* What is the probability for Problems_With_Search=problems_with_search_TRUE? */\n        /* What is the probability for Problems_With_Search=problems_with_search_FALSE? */\n        + [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {\"instantiations\": [\"problems_with_search_TRUE\", \"problems_with_search_FALSE\"], \"priors\": {\"What is the probability for Problems_With_Search=problems_with_search_TRUE?\": \"%?\", \"What is the probability for Problems_With_Search=problems_with_search_FALSE?\": \"%?\"}}\n      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE? */\n      + [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {\"instantiations\": [\"deployment_decisions_DEPLOY\", \"deployment_decisions_WITHHOLD\"], \"priors\": {\"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY?\": \"%?\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"%?\"}, \"posteriors\": {\"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\"}}\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK? */\n        + [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {\"instantiations\": [\"incentives_to_build_aps_STRONG\", \"incentives_to_build_aps_WEAK\"], \"priors\": {\"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG?\": \"%?\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK?\": \"%?\"}, \"posteriors\": {\"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\"}}\n          /* What is the probability for Usefulness_Of_APS=usefulness_of_aps_HIGH? */\n          /* What is the probability for Usefulness_Of_APS=usefulness_of_aps_LOW? */\n          + [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {\"instantiations\": [\"usefulness_of_aps_HIGH\", \"usefulness_of_aps_LOW\"], \"priors\": {\"What is the probability for Usefulness_Of_APS=usefulness_of_aps_HIGH?\": \"%?\", \"What is the probability for Usefulness_Of_APS=usefulness_of_aps_LOW?\": \"%?\"}}\n          /* What is the probability for Competitive_Dynamics=competitive_dynamics_STRONG? */\n          /* What is the probability for Competitive_Dynamics=competitive_dynamics_WEAK? */\n          + [Competitive_Dynamics]: Competitive pressures between AI developers. {\"instantiations\": [\"competitive_dynamics_STRONG\", \"competitive_dynamics_WEAK\"], \"priors\": {\"What is the probability for Competitive_Dynamics=competitive_dynamics_STRONG?\": \"%?\", \"What is the probability for Competitive_Dynamics=competitive_dynamics_WEAK?\": \"%?\"}}\n        /* What is the probability for Deception_By_AI=deception_by_ai_TRUE? */\n        /* What is the probability for Deception_By_AI=deception_by_ai_FALSE? */\n        + [Deception_By_AI]: AI systems deceiving humans about their true objectives. {\"instantiations\": [\"deception_by_ai_TRUE\", \"deception_by_ai_FALSE\"], \"priors\": {\"What is the probability for Deception_By_AI=deception_by_ai_TRUE?\": \"%?\", \"What is the probability for Deception_By_AI=deception_by_ai_FALSE?\": \"%?\"}}\n    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */\n    + [Corrective_Feedback]: Human society implementing corrections after observing problems. {\"instantiations\": [\"corrective_feedback_EFFECTIVE\", \"corrective_feedback_INEFFECTIVE\"], \"priors\": {\"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"%?\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\"}}\n      /* What is the probability for Warning_Shots=warning_shots_OBSERVED? */\n      /* What is the probability for Warning_Shots=warning_shots_UNOBSERVED? */\n      + [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {\"instantiations\": [\"warning_shots_OBSERVED\", \"warning_shots_UNOBSERVED\"], \"priors\": {\"What is the probability for Warning_Shots=warning_shots_OBSERVED?\": \"%?\", \"What is the probability for Warning_Shots=warning_shots_UNOBSERVED?\": \"%?\"}}\n      /* What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */\n      /* What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */\n      + [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {\"instantiations\": [\"rapid_capability_escalation_TRUE\", \"rapid_capability_escalation_FALSE\"], \"priors\": {\"What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"%?\", \"What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"%?\"}}\n/* What is the probability for Barriers_To_Understanding=barriers_to_understanding_HIGH? */\n/* What is the probability for Barriers_To_Understanding=barriers_to_understanding_LOW? */\n[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {\"instantiations\": [\"barriers_to_understanding_HIGH\", \"barriers_to_understanding_LOW\"], \"priors\": {\"What is the probability for Barriers_To_Understanding=barriers_to_understanding_HIGH?\": \"%?\", \"What is the probability for Barriers_To_Understanding=barriers_to_understanding_LOW?\": \"%?\"}}\n/* What is the probability for Adversarial_Dynamics=adversarial_dynamics_TRUE? */\n/* What is the probability for Adversarial_Dynamics=adversarial_dynamics_FALSE? */\n[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {\"instantiations\": [\"adversarial_dynamics_TRUE\", \"adversarial_dynamics_FALSE\"], \"priors\": {\"What is the probability for Adversarial_Dynamics=adversarial_dynamics_TRUE?\": \"%?\", \"What is the probability for Adversarial_Dynamics=adversarial_dynamics_FALSE?\": \"%?\"}}\n/* What is the probability for Stakes_Of_Error=stakes_of_error_HIGH? */\n/* What is the probability for Stakes_Of_Error=stakes_of_error_LOW? */\n[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {\"instantiations\": [\"stakes_of_error_HIGH\", \"stakes_of_error_LOW\"], \"priors\": {\"What is the probability for Stakes_Of_Error=stakes_of_error_HIGH?\": \"%?\", \"What is the probability for Stakes_Of_Error=stakes_of_error_LOW?\": \"%?\"}}\n...\n\n\n\n\n\nCode\n# Load and print the content of the 'FULL_BayesDownQuestions.md' file\nwith open(\"FULL_BayesDownQuestions.md\", \"r\") as f:\n    file_content = f.read()\n    print(file_content)\n\n\n# BayesDown Representation with Placeholder Probabilities\n\n/* This file contains BayesDown syntax with placeholder probabilities.\n   Replace the placeholders with actual probability values based on the \n   questions in the comments. */\n\n/* What is the probability for Existential_Catastrophe=existential_catastrophe_TRUE? */\n/* What is the probability for Existential_Catastrophe=existential_catastrophe_FALSE? */\n[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {\"instantiations\": [\"existential_catastrophe_TRUE\", \"existential_catastrophe_FALSE\"], \"priors\": {\"What is the probability for Existential_Catastrophe=existential_catastrophe_TRUE?\": \"%?\", \"What is the probability for Existential_Catastrophe=existential_catastrophe_FALSE?\": \"%?\"}}\n/* What is the probability for Human_Disempowerment=human_disempowerment_TRUE? */\n/* What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE? */\n/* What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE? */\n/* What is the probability for Human_Disempowerment=human_disempowerment_FALSE? */\n/* What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE? */\n/* What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE? */\n[Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {\"instantiations\": [\"human_disempowerment_TRUE\", \"human_disempowerment_FALSE\"], \"priors\": {\"What is the probability for Human_Disempowerment=human_disempowerment_TRUE?\": \"%?\", \"What is the probability for Human_Disempowerment=human_disempowerment_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?\": \"?%\", \"What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?\": \"?%\", \"What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?\": \"?%\", \"What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?\": \"?%\"}}\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */\n  + [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {\"instantiations\": [\"scale_of_power_seeking_TRUE\", \"scale_of_power_seeking_FALSE\"], \"priors\": {\"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?\": \"%?\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\"}}\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    + [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"], \"priors\": {\"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE?\": \"%?\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\"}}\n      /* What is the probability for APS_Systems=aps_systems_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */\n      + [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {\"instantiations\": [\"aps_systems_TRUE\", \"aps_systems_FALSE\"], \"priors\": {\"What is the probability for APS_Systems=aps_systems_TRUE?\": \"%?\", \"What is the probability for APS_Systems=aps_systems_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\"}}\n        /* What is the probability for Advanced_AI_Capability=advanced_ai_capability_TRUE? */\n        /* What is the probability for Advanced_AI_Capability=advanced_ai_capability_FALSE? */\n        + [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {\"instantiations\": [\"advanced_ai_capability_TRUE\", \"advanced_ai_capability_FALSE\"], \"priors\": {\"What is the probability for Advanced_AI_Capability=advanced_ai_capability_TRUE?\": \"%?\", \"What is the probability for Advanced_AI_Capability=advanced_ai_capability_FALSE?\": \"%?\"}}\n        /* What is the probability for Agentic_Planning=agentic_planning_TRUE? */\n        /* What is the probability for Agentic_Planning=agentic_planning_FALSE? */\n        + [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {\"instantiations\": [\"agentic_planning_TRUE\", \"agentic_planning_FALSE\"], \"priors\": {\"What is the probability for Agentic_Planning=agentic_planning_TRUE?\": \"%?\", \"What is the probability for Agentic_Planning=agentic_planning_FALSE?\": \"%?\"}}\n        /* What is the probability for Strategic_Awareness=strategic_awareness_TRUE? */\n        /* What is the probability for Strategic_Awareness=strategic_awareness_FALSE? */\n        + [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {\"instantiations\": [\"strategic_awareness_TRUE\", \"strategic_awareness_FALSE\"], \"priors\": {\"What is the probability for Strategic_Awareness=strategic_awareness_TRUE?\": \"%?\", \"What is the probability for Strategic_Awareness=strategic_awareness_FALSE?\": \"%?\"}}\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */\n      + [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {\"instantiations\": [\"difficulty_of_alignment_TRUE\", \"difficulty_of_alignment_FALSE\"], \"priors\": {\"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE?\": \"%?\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\"}}\n        /* What is the probability for Instrumental_Convergence=instrumental_convergence_TRUE? */\n        /* What is the probability for Instrumental_Convergence=instrumental_convergence_FALSE? */\n        + [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {\"instantiations\": [\"instrumental_convergence_TRUE\", \"instrumental_convergence_FALSE\"], \"priors\": {\"What is the probability for Instrumental_Convergence=instrumental_convergence_TRUE?\": \"%?\", \"What is the probability for Instrumental_Convergence=instrumental_convergence_FALSE?\": \"%?\"}}\n        /* What is the probability for Problems_With_Proxies=problems_with_proxies_TRUE? */\n        /* What is the probability for Problems_With_Proxies=problems_with_proxies_FALSE? */\n        + [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {\"instantiations\": [\"problems_with_proxies_TRUE\", \"problems_with_proxies_FALSE\"], \"priors\": {\"What is the probability for Problems_With_Proxies=problems_with_proxies_TRUE?\": \"%?\", \"What is the probability for Problems_With_Proxies=problems_with_proxies_FALSE?\": \"%?\"}}\n        /* What is the probability for Problems_With_Search=problems_with_search_TRUE? */\n        /* What is the probability for Problems_With_Search=problems_with_search_FALSE? */\n        + [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {\"instantiations\": [\"problems_with_search_TRUE\", \"problems_with_search_FALSE\"], \"priors\": {\"What is the probability for Problems_With_Search=problems_with_search_TRUE?\": \"%?\", \"What is the probability for Problems_With_Search=problems_with_search_FALSE?\": \"%?\"}}\n      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE? */\n      + [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {\"instantiations\": [\"deployment_decisions_DEPLOY\", \"deployment_decisions_WITHHOLD\"], \"priors\": {\"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY?\": \"%?\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"%?\"}, \"posteriors\": {\"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\"}}\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK? */\n        + [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {\"instantiations\": [\"incentives_to_build_aps_STRONG\", \"incentives_to_build_aps_WEAK\"], \"priors\": {\"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG?\": \"%?\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK?\": \"%?\"}, \"posteriors\": {\"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\"}}\n          /* What is the probability for Usefulness_Of_APS=usefulness_of_aps_HIGH? */\n          /* What is the probability for Usefulness_Of_APS=usefulness_of_aps_LOW? */\n          + [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {\"instantiations\": [\"usefulness_of_aps_HIGH\", \"usefulness_of_aps_LOW\"], \"priors\": {\"What is the probability for Usefulness_Of_APS=usefulness_of_aps_HIGH?\": \"%?\", \"What is the probability for Usefulness_Of_APS=usefulness_of_aps_LOW?\": \"%?\"}}\n          /* What is the probability for Competitive_Dynamics=competitive_dynamics_STRONG? */\n          /* What is the probability for Competitive_Dynamics=competitive_dynamics_WEAK? */\n          + [Competitive_Dynamics]: Competitive pressures between AI developers. {\"instantiations\": [\"competitive_dynamics_STRONG\", \"competitive_dynamics_WEAK\"], \"priors\": {\"What is the probability for Competitive_Dynamics=competitive_dynamics_STRONG?\": \"%?\", \"What is the probability for Competitive_Dynamics=competitive_dynamics_WEAK?\": \"%?\"}}\n        /* What is the probability for Deception_By_AI=deception_by_ai_TRUE? */\n        /* What is the probability for Deception_By_AI=deception_by_ai_FALSE? */\n        + [Deception_By_AI]: AI systems deceiving humans about their true objectives. {\"instantiations\": [\"deception_by_ai_TRUE\", \"deception_by_ai_FALSE\"], \"priors\": {\"What is the probability for Deception_By_AI=deception_by_ai_TRUE?\": \"%?\", \"What is the probability for Deception_By_AI=deception_by_ai_FALSE?\": \"%?\"}}\n    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */\n    + [Corrective_Feedback]: Human society implementing corrections after observing problems. {\"instantiations\": [\"corrective_feedback_EFFECTIVE\", \"corrective_feedback_INEFFECTIVE\"], \"priors\": {\"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"%?\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\"}}\n      /* What is the probability for Warning_Shots=warning_shots_OBSERVED? */\n      /* What is the probability for Warning_Shots=warning_shots_UNOBSERVED? */\n      + [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {\"instantiations\": [\"warning_shots_OBSERVED\", \"warning_shots_UNOBSERVED\"], \"priors\": {\"What is the probability for Warning_Shots=warning_shots_OBSERVED?\": \"%?\", \"What is the probability for Warning_Shots=warning_shots_UNOBSERVED?\": \"%?\"}}\n      /* What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */\n      /* What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */\n      + [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {\"instantiations\": [\"rapid_capability_escalation_TRUE\", \"rapid_capability_escalation_FALSE\"], \"priors\": {\"What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"%?\", \"What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"%?\"}}\n/* What is the probability for Barriers_To_Understanding=barriers_to_understanding_HIGH? */\n/* What is the probability for Barriers_To_Understanding=barriers_to_understanding_LOW? */\n[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {\"instantiations\": [\"barriers_to_understanding_HIGH\", \"barriers_to_understanding_LOW\"], \"priors\": {\"What is the probability for Barriers_To_Understanding=barriers_to_understanding_HIGH?\": \"%?\", \"What is the probability for Barriers_To_Understanding=barriers_to_understanding_LOW?\": \"%?\"}}\n/* What is the probability for Adversarial_Dynamics=adversarial_dynamics_TRUE? */\n/* What is the probability for Adversarial_Dynamics=adversarial_dynamics_FALSE? */\n[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {\"instantiations\": [\"adversarial_dynamics_TRUE\", \"adversarial_dynamics_FALSE\"], \"priors\": {\"What is the probability for Adversarial_Dynamics=adversarial_dynamics_TRUE?\": \"%?\", \"What is the probability for Adversarial_Dynamics=adversarial_dynamics_FALSE?\": \"%?\"}}\n/* What is the probability for Stakes_Of_Error=stakes_of_error_HIGH? */\n/* What is the probability for Stakes_Of_Error=stakes_of_error_LOW? */\n[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {\"instantiations\": [\"stakes_of_error_HIGH\", \"stakes_of_error_LOW\"], \"priors\": {\"What is the probability for Stakes_Of_Error=stakes_of_error_HIGH?\": \"%?\", \"What is the probability for Stakes_Of_Error=stakes_of_error_LOW?\": \"%?\"}}\n\n\n\n\n\nCode\n# Generate BayesDown format\nbayesdown_questions = extract_bayesdown_questions_fixed(\n    \"ArgDown_WithQuestions.csv\",\n    \"BayesDownQuestions.md\",\n    include_questions_as_comments=False\n)\n\n# Display a preview of the format\nprint(\n\n)\nprint(bayesdown_questions[:50000] + \"...\\n\")\n\n\nLoading CSV from ArgDown_WithQuestions.csv...\nSuccessfully loaded CSV with 23 rows.\nGenerating BayesDown syntax with placeholder probabilities...\nBayesDown Questions saved to BayesDownQuestions.md\n\n[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {\"instantiations\": [\"existential_catastrophe_TRUE\", \"existential_catastrophe_FALSE\"], \"priors\": {\"What is the probability for Existential_Catastrophe=existential_catastrophe_TRUE?\": \"%?\", \"What is the probability for Existential_Catastrophe=existential_catastrophe_FALSE?\": \"%?\"}}\n[Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {\"instantiations\": [\"human_disempowerment_TRUE\", \"human_disempowerment_FALSE\"], \"priors\": {\"What is the probability for Human_Disempowerment=human_disempowerment_TRUE?\": \"%?\", \"What is the probability for Human_Disempowerment=human_disempowerment_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?\": \"?%\", \"What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?\": \"?%\", \"What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?\": \"?%\", \"What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?\": \"?%\"}}\n  + [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {\"instantiations\": [\"scale_of_power_seeking_TRUE\", \"scale_of_power_seeking_FALSE\"], \"priors\": {\"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?\": \"%?\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\"}}\n    + [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"], \"priors\": {\"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE?\": \"%?\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\"}}\n      + [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {\"instantiations\": [\"aps_systems_TRUE\", \"aps_systems_FALSE\"], \"priors\": {\"What is the probability for APS_Systems=aps_systems_TRUE?\": \"%?\", \"What is the probability for APS_Systems=aps_systems_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\"}}\n        + [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {\"instantiations\": [\"advanced_ai_capability_TRUE\", \"advanced_ai_capability_FALSE\"], \"priors\": {\"What is the probability for Advanced_AI_Capability=advanced_ai_capability_TRUE?\": \"%?\", \"What is the probability for Advanced_AI_Capability=advanced_ai_capability_FALSE?\": \"%?\"}}\n        + [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {\"instantiations\": [\"agentic_planning_TRUE\", \"agentic_planning_FALSE\"], \"priors\": {\"What is the probability for Agentic_Planning=agentic_planning_TRUE?\": \"%?\", \"What is the probability for Agentic_Planning=agentic_planning_FALSE?\": \"%?\"}}\n        + [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {\"instantiations\": [\"strategic_awareness_TRUE\", \"strategic_awareness_FALSE\"], \"priors\": {\"What is the probability for Strategic_Awareness=strategic_awareness_TRUE?\": \"%?\", \"What is the probability for Strategic_Awareness=strategic_awareness_FALSE?\": \"%?\"}}\n      + [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {\"instantiations\": [\"difficulty_of_alignment_TRUE\", \"difficulty_of_alignment_FALSE\"], \"priors\": {\"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE?\": \"%?\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\"}}\n        + [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {\"instantiations\": [\"instrumental_convergence_TRUE\", \"instrumental_convergence_FALSE\"], \"priors\": {\"What is the probability for Instrumental_Convergence=instrumental_convergence_TRUE?\": \"%?\", \"What is the probability for Instrumental_Convergence=instrumental_convergence_FALSE?\": \"%?\"}}\n        + [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {\"instantiations\": [\"problems_with_proxies_TRUE\", \"problems_with_proxies_FALSE\"], \"priors\": {\"What is the probability for Problems_With_Proxies=problems_with_proxies_TRUE?\": \"%?\", \"What is the probability for Problems_With_Proxies=problems_with_proxies_FALSE?\": \"%?\"}}\n        + [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {\"instantiations\": [\"problems_with_search_TRUE\", \"problems_with_search_FALSE\"], \"priors\": {\"What is the probability for Problems_With_Search=problems_with_search_TRUE?\": \"%?\", \"What is the probability for Problems_With_Search=problems_with_search_FALSE?\": \"%?\"}}\n      + [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {\"instantiations\": [\"deployment_decisions_DEPLOY\", \"deployment_decisions_WITHHOLD\"], \"priors\": {\"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY?\": \"%?\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"%?\"}, \"posteriors\": {\"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\"}}\n        + [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {\"instantiations\": [\"incentives_to_build_aps_STRONG\", \"incentives_to_build_aps_WEAK\"], \"priors\": {\"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG?\": \"%?\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK?\": \"%?\"}, \"posteriors\": {\"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\"}}\n          + [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {\"instantiations\": [\"usefulness_of_aps_HIGH\", \"usefulness_of_aps_LOW\"], \"priors\": {\"What is the probability for Usefulness_Of_APS=usefulness_of_aps_HIGH?\": \"%?\", \"What is the probability for Usefulness_Of_APS=usefulness_of_aps_LOW?\": \"%?\"}}\n          + [Competitive_Dynamics]: Competitive pressures between AI developers. {\"instantiations\": [\"competitive_dynamics_STRONG\", \"competitive_dynamics_WEAK\"], \"priors\": {\"What is the probability for Competitive_Dynamics=competitive_dynamics_STRONG?\": \"%?\", \"What is the probability for Competitive_Dynamics=competitive_dynamics_WEAK?\": \"%?\"}}\n        + [Deception_By_AI]: AI systems deceiving humans about their true objectives. {\"instantiations\": [\"deception_by_ai_TRUE\", \"deception_by_ai_FALSE\"], \"priors\": {\"What is the probability for Deception_By_AI=deception_by_ai_TRUE?\": \"%?\", \"What is the probability for Deception_By_AI=deception_by_ai_FALSE?\": \"%?\"}}\n    + [Corrective_Feedback]: Human society implementing corrections after observing problems. {\"instantiations\": [\"corrective_feedback_EFFECTIVE\", \"corrective_feedback_INEFFECTIVE\"], \"priors\": {\"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"%?\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\"}}\n      + [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {\"instantiations\": [\"warning_shots_OBSERVED\", \"warning_shots_UNOBSERVED\"], \"priors\": {\"What is the probability for Warning_Shots=warning_shots_OBSERVED?\": \"%?\", \"What is the probability for Warning_Shots=warning_shots_UNOBSERVED?\": \"%?\"}}\n      + [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {\"instantiations\": [\"rapid_capability_escalation_TRUE\", \"rapid_capability_escalation_FALSE\"], \"priors\": {\"What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"%?\", \"What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"%?\"}}\n[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {\"instantiations\": [\"barriers_to_understanding_HIGH\", \"barriers_to_understanding_LOW\"], \"priors\": {\"What is the probability for Barriers_To_Understanding=barriers_to_understanding_HIGH?\": \"%?\", \"What is the probability for Barriers_To_Understanding=barriers_to_understanding_LOW?\": \"%?\"}}\n[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {\"instantiations\": [\"adversarial_dynamics_TRUE\", \"adversarial_dynamics_FALSE\"], \"priors\": {\"What is the probability for Adversarial_Dynamics=adversarial_dynamics_TRUE?\": \"%?\", \"What is the probability for Adversarial_Dynamics=adversarial_dynamics_FALSE?\": \"%?\"}}\n[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {\"instantiations\": [\"stakes_of_error_HIGH\", \"stakes_of_error_LOW\"], \"priors\": {\"What is the probability for Stakes_Of_Error=stakes_of_error_HIGH?\": \"%?\", \"What is the probability for Stakes_Of_Error=stakes_of_error_LOW?\": \"%?\"}}\n...",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#generate-bayesdown-probability-extraction-prompt",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#generate-bayesdown-probability-extraction-prompt",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "F.5 2.3 Generate BayesDown Probability Extraction Prompt",
    "text": "F.5 2.3 Generate BayesDown Probability Extraction Prompt\nGenerate 2nd Extraction Prompt for Probabilities based on the questions generated from the ‘ArgDown.csv’ extraction",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#bayesdown-format-specification",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#bayesdown-format-specification",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "F.6 2.3.1 BayesDown Format Specification",
    "text": "F.6 2.3.1 BayesDown Format Specification\nBayesDown extends ArgDown with probability data in a structured JSON format to represent Bayesian networks. This intermediate representation bridges the gap between natural language arguments and formal probabilistic models, preserving both narrative structure and quantitative relationships.\n\nF.6.1 Core Structure\nA BayesDown representation consists of:\n\nNodes: Variables or statements in brackets [Node_Name] with descriptive text\nRelationships: Hierarchical structure with indentation and + symbols\nMetadata: JSON objects containing probability information:\n\n{\n  \"instantiations\": [\"state_TRUE\", \"state_FALSE\"],  // Possible states of variable\n  \"priors\": {\n    \"p(state_TRUE)\": \"0.7\",   // Unconditional probability of state_TRUE\n    \"p(state_FALSE)\": \"0.3\"   // Unconditional probability of state_FALSE\n  },\n  \"posteriors\": {\n    \"p(state_TRUE|condition1_TRUE,condition2_FALSE)\": \"0.9\",  // Conditional on parent states\n    \"p(state_TRUE|condition1_FALSE,condition2_TRUE)\": \"0.4\"   // Different parent configuration\n  }\n}\n\n##### Rain-Sprinkler-Lawn Example\n[Grass_Wet]: Concentrated moisture on grass. {\"instantiations\": [\"grass_wet_TRUE\", \"grass_wet_FALSE\"],\n\"priors\": {\"p(grass_wet_TRUE)\": \"0.322\", \"p(grass_wet_FALSE)\": \"0.678\"},\n\"posteriors\": {\"p(grass_wet_TRUE|sprinkler_TRUE,rain_TRUE)\": \"0.99\",\n\"p(grass_wet_TRUE|sprinkler_TRUE,rain_FALSE)\": \"0.9\",\n\"p(grass_wet_TRUE|sprinkler_FALSE,rain_TRUE)\": \"0.8\",\n\"p(grass_wet_TRUE|sprinkler_FALSE,rain_FALSE)\": \"0.0\"}}\n + [Rain]: Water falling from the sky. {\"instantiations\": [\"rain_TRUE\", \"rain_FALSE\"],\n \"priors\": {\"p(rain_TRUE)\": \"0.2\", \"p(rain_FALSE)\": \"0.8\"}}\n + [Sprinkler]: Artificial watering system. {\"instantiations\": [\"sprinkler_TRUE\", \"sprinkler_FALSE\"],\n \"priors\": {\"p(sprinkler_TRUE)\": \"0.44838\", \"p(sprinkler_FALSE)\": \"0.55162\"},\n \"posteriors\": {\"p(sprinkler_TRUE|rain_TRUE)\": \"0.01\", \"p(sprinkler_TRUE|rain_FALSE)\": \"0.4\"}}\n   + [Rain]\n\n\nIn this example:\n\n+ Grass_Wet is the effect/outcome node\n+ Rain and Sprinkler are parent nodes (causes)\n+ Rain also influences Sprinkler (people tend not to use sprinklers when it's raining)\n\nRole in AMTAIR\nBayesDown serves as the critical intermediate representation in the AMTAIR extraction pipeline, bridging between qualitative arguments in AI safety literature and formal Bayesian networks that can be used for probabilistic reasoning and policy evaluation. By preserving both narrative explanation and probabilistic information, it enables the automated extraction of world models while maintaining traceability to the original arguments.\nFor full syntax details, see the BayesDownSyntax.md file in the repository.\n\n2.3.2 Probability Extraction Process\nThe probability extraction pipeline follows these steps:\n\n\nIdentify variables and their possible states\nExtract prior probability statements\nIdentify conditional relationships\nExtract conditional probability statements\nFormat the data in BayesDown syntax\n\n2.3.3 Implementation Steps\nTo extract probabilities and create BayesDown format:\n\nRun the extract_probabilities function on ArgDown text\nProcess the results into a structured format\nValidate the probability distributions (ensure they sum to 1)\nGenerate the enhanced BayesDown representation\n\n2.3.4 Validation and Quality Control\nThe probability extraction process includes validation steps:\n\nEnsuring coherent probability distributions\nChecking for logical consistency in conditional relationships\nVerifying that all required probability statements are present\nHandling missing data with appropriate default values\n\n## 2.4 Prepare 2nd API call\n\n## 2.5 Make BayesDown Probability Extraction API Call\n\n## 2.6 Save BayesDown with Probability Estimates (.csv)\n\n## 2.7 Review & Verify BayesDown Probability Estimates\n\n## 2.7.2 Check the Graph Structure with the ArgDown Sandbox Online\nCopy and paste the BayesDown formatted ... in the ArgDown Sandbox below to quickly verify that the network renders correctly.\n\n## 2.8 Extract BayesDown with Probability Estimates as Dataframe\n\n# 3.0 Data Extraction: BayesDown (.md) to Database (.csv)\n\n# 3. BayesDown to Structured Data: Network Construction\n\n## Extraction Pipeline Overview\n\nThis section implements the core extraction pipeline described in the AMTAIR project documentation (see `PY_TechnicalImplementation.md`), which transforms structured argument representations into formal Bayesian networks through a series of processing steps:\n\n1. **Input**: Text in BayesDown format (see Section 2.3.1)\n2. **Parsing**: Extract nodes, relationships, and probability information\n3. **Structuring**: Organize into a DataFrame with formal relationships\n4. **Enhancement**: Add derived properties and network metrics\n5. **Output**: Structured data ready for Bayesian network construction\n\n### Theoretical Foundation\n\nThis implementation follows the extraction algorithm outlined in the AMTAIR project description:\n\n1. Get nodes: All premises and conclusions from the argument structure\n2. Get edges: Parent-child relationships between nodes\n3. Extract probability distributions: Prior and conditional probabilities\n4. Calculate derived metrics: Network statistics and node classifications\n\nThe resulting structured data maintains the complete information needed to reconstruct the Bayesian network while enabling additional analysis and visualization.\n\n### Role in Thesis Research\n\nThis extraction pipeline represents a key contribution of the Master's thesis, demonstrating how argument structures from AI safety literature can be automatically transformed into formal probabilistic models. While the current implementation focuses on pre-formatted BayesDown, the architecture is designed to be extended with LLM-powered extraction directly from natural language in future work.\n\nThe rain-sprinkler-lawn example serves as a simple but complete test case, demonstrating every step in the pipeline from structured text to interactive Bayesian network visualization.\n\n### 3.1 ExtractBayesDown-Data_v1\nBuild data frame with extractable information from BayesDown\n\n::: {#cell-64 .cell quarto-private-1='{\"key\":\"colab\",\"value\":{\"base_uri\":\"https://localhost:8080/\",\"height\":122}}' outputId='e0bc7224-c20b-4662-ba80-898e88b06523'}\n``` {.python .cell-code}\n# read sprinkler example -- Occam Colab Online\nfile_path_ex_rain = \"https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/BayesDown.md\"\n\n# Use requests.get to fetch content from URL\nresponse = requests.get(file_path_ex_rain)\nresponse.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n\n# Read content from the response\nmd_content_ex_rain = response.text\n\nmd_content_ex_rain\n\n'[Existential_Catastrophe]: The destruction of humanity\\'s long-term potential due to AI systems we\\'ve lost control over. {\"instantiations\": [\"existential_catastrophe_TRUE\", \"existential_catastrophe_FALSE\"], \"priors\": {\"p(existential_catastrophe_TRUE)\": \"0.05\", \"p(existential_catastrophe_FALSE)\": \"0.95\"}, \"posteriors\": {\"p(existential_catastrophe_TRUE|human_disempowerment_TRUE)\": \"0.95\", \"p(existential_catastrophe_TRUE|human_disempowerment_FALSE)\": \"0.0\", \"p(existential_catastrophe_FALSE|human_disempowerment_TRUE)\": \"0.05\", \"p(existential_catastrophe_FALSE|human_disempowerment_FALSE)\": \"1.0\"}}\\n- [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {\"instantiations\": [\"human_disempowerment_TRUE\", \"human_disempowerment_FALSE\"], \"priors\": {\"p(human_disempowerment_TRUE)\": \"0.208\", \"p(human_disempowerment_FALSE)\": \"0.792\"}, \"posteriors\": {\"p(human_disempowerment_TRUE|scale_of_power_seeking_TRUE)\": \"1.0\", \"p(human_disempowerment_TRUE|scale_of_power_seeking_FALSE)\": \"0.0\", \"p(human_disempowerment_FALSE|scale_of_power_seeking_TRUE)\": \"0.0\", \"p(human_disempowerment_FALSE|scale_of_power_seeking_FALSE)\": \"1.0\"}}\\n    - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {\"instantiations\": [\"scale_of_power_seeking_TRUE\", \"scale_of_power_seeking_FALSE\"], \"priors\": {\"p(scale_of_power_seeking_TRUE)\": \"0.208\", \"p(scale_of_power_seeking_FALSE)\": \"0.792\"}, \"posteriors\": {\"p(scale_of_power_seeking_TRUE|misaligned_power_seeking_TRUE, corrective_feedback_EFFECTIVE)\": \"0.25\", \"p(scale_of_power_seeking_TRUE|misaligned_power_seeking_TRUE, corrective_feedback_INEFFECTIVE)\": \"0.60\", \"p(scale_of_power_seeking_TRUE|misaligned_power_seeking_FALSE, corrective_feedback_EFFECTIVE)\": \"0.0\", \"p(scale_of_power_seeking_TRUE|misaligned_power_seeking_FALSE, corrective_feedback_INEFFECTIVE)\": \"0.0\", \"p(scale_of_power_seeking_FALSE|misaligned_power_seeking_TRUE, corrective_feedback_EFFECTIVE)\": \"0.75\", \"p(scale_of_power_seeking_FALSE|misaligned_power_seeking_TRUE, corrective_feedback_INEFFECTIVE)\": \"0.40\", \"p(scale_of_power_seeking_FALSE|misaligned_power_seeking_FALSE, corrective_feedback_EFFECTIVE)\": \"1.0\", \"p(scale_of_power_seeking_FALSE|misaligned_power_seeking_FALSE, corrective_feedback_INEFFECTIVE)\": \"1.0\"}}\\n        - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"], \"priors\": {\"p(misaligned_power_seeking_TRUE)\": \"0.338\", \"p(misaligned_power_seeking_FALSE)\": \"0.662\"}, \"posteriors\": {\"p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)\": \"0.90\", \"p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_WITHHOLD)\": \"0.10\", \"p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)\": \"0.25\", \"p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_WITHHOLD)\": \"0.05\", \"p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)\": \"0.0\", \"p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_WITHHOLD)\": \"0.0\", \"p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)\": \"0.0\", \"p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_FALSE, deployment_decisions_WITHHOLD)\": \"0.0\", \"p(misaligned_power_seeking_FALSE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)\": \"0.10\", \"p(misaligned_power_seeking_FALSE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_WITHHOLD)\": \"0.90\", \"p(misaligned_power_seeking_FALSE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)\": \"0.75\", \"p(misaligned_power_seeking_FALSE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_WITHHOLD)\": \"0.95\", \"p(misaligned_power_seeking_FALSE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)\": \"1.0\", \"p(misaligned_power_seeking_FALSE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_WITHHOLD)\": \"1.0\", \"p(misaligned_power_seeking_FALSE|aps_systems_FALSE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)\": \"1.0\", \"p(misaligned_power_seeking_FALSE|aps_systems_FALSE, difficulty_of_alignment_FALSE, deployment_decisions_WITHHOLD)\": \"1.0\"}}\\n            - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {\"instantiations\": [\"aps_systems_TRUE\", \"aps_systems_FALSE\"], \"priors\": {\"p(aps_systems_TRUE)\": \"0.65\", \"p(aps_systems_FALSE)\": \"0.35\"}, \"posteriors\": {\"p(aps_systems_TRUE|advanced_ai_capability_TRUE, agentic_planning_TRUE, strategic_awareness_TRUE)\": \"1.0\", \"p(aps_systems_TRUE|advanced_ai_capability_TRUE, agentic_planning_TRUE, strategic_awareness_FALSE)\": \"0.0\", \"p(aps_systems_TRUE|advanced_ai_capability_TRUE, agentic_planning_FALSE, strategic_awareness_TRUE)\": \"0.0\", \"p(aps_systems_TRUE|advanced_ai_capability_TRUE, agentic_planning_FALSE, strategic_awareness_FALSE)\": \"0.0\", \"p(aps_systems_TRUE|advanced_ai_capability_FALSE, agentic_planning_TRUE, strategic_awareness_TRUE)\": \"0.0\", \"p(aps_systems_TRUE|advanced_ai_capability_FALSE, agentic_planning_TRUE, strategic_awareness_FALSE)\": \"0.0\", \"p(aps_systems_TRUE|advanced_ai_capability_FALSE, agentic_planning_FALSE, strategic_awareness_TRUE)\": \"0.0\", \"p(aps_systems_TRUE|advanced_ai_capability_FALSE, agentic_planning_FALSE, strategic_awareness_FALSE)\": \"0.0\", \"p(aps_systems_FALSE|advanced_ai_capability_TRUE, agentic_planning_TRUE, strategic_awareness_TRUE)\": \"0.0\", \"p(aps_systems_FALSE|advanced_ai_capability_TRUE, agentic_planning_TRUE, strategic_awareness_FALSE)\": \"1.0\", \"p(aps_systems_FALSE|advanced_ai_capability_TRUE, agentic_planning_FALSE, strategic_awareness_TRUE)\": \"1.0\", \"p(aps_systems_FALSE|advanced_ai_capability_TRUE, agentic_planning_FALSE, strategic_awareness_FALSE)\": \"1.0\", \"p(aps_systems_FALSE|advanced_ai_capability_FALSE, agentic_planning_TRUE, strategic_awareness_TRUE)\": \"1.0\", \"p(aps_systems_FALSE|advanced_ai_capability_FALSE, agentic_planning_TRUE, strategic_awareness_FALSE)\": \"1.0\", \"p(aps_systems_FALSE|advanced_ai_capability_FALSE, agentic_planning_FALSE, strategic_awareness_TRUE)\": \"1.0\", \"p(aps_systems_FALSE|advanced_ai_capability_FALSE, agentic_planning_FALSE, strategic_awareness_FALSE)\": \"1.0\"}}\\n                - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {\"instantiations\": [\"advanced_ai_capability_TRUE\", \"advanced_ai_capability_FALSE\"], \"priors\": {\"p(advanced_ai_capability_TRUE)\": \"0.80\", \"p(advanced_ai_capability_FALSE)\": \"0.20\"}}\\n                - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {\"instantiations\": [\"agentic_planning_TRUE\", \"agentic_planning_FALSE\"], \"priors\": {\"p(agentic_planning_TRUE)\": \"0.85\", \"p(agentic_planning_FALSE)\": \"0.15\"}}\\n                - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {\"instantiations\": [\"strategic_awareness_TRUE\", \"strategic_awareness_FALSE\"], \"priors\": {\"p(strategic_awareness_TRUE)\": \"0.75\", \"p(strategic_awareness_FALSE)\": \"0.25\"}}\\n            - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {\"instantiations\": [\"difficulty_of_alignment_TRUE\", \"difficulty_of_alignment_FALSE\"], \"priors\": {\"p(difficulty_of_alignment_TRUE)\": \"0.40\", \"p(difficulty_of_alignment_FALSE)\": \"0.60\"}, \"posteriors\": {\"p(difficulty_of_alignment_TRUE|instrumental_convergence_TRUE, problems_with_proxies_TRUE, problems_with_search_TRUE)\": \"0.85\", \"p(difficulty_of_alignment_TRUE|instrumental_convergence_TRUE, problems_with_proxies_TRUE, problems_with_search_FALSE)\": \"0.70\", \"p(difficulty_of_alignment_TRUE|instrumental_convergence_TRUE, problems_with_proxies_FALSE, problems_with_search_TRUE)\": \"0.60\", \"p(difficulty_of_alignment_TRUE|instrumental_convergence_TRUE, problems_with_proxies_FALSE, problems_with_search_FALSE)\": \"0.40\", \"p(difficulty_of_alignment_TRUE|instrumental_convergence_FALSE, problems_with_proxies_TRUE, problems_with_search_TRUE)\": \"0.55\", \"p(difficulty_of_alignment_TRUE|instrumental_convergence_FALSE, problems_with_proxies_TRUE, problems_with_search_FALSE)\": \"0.40\", \"p(difficulty_of_alignment_TRUE|instrumental_convergence_FALSE, problems_with_proxies_FALSE, problems_with_search_TRUE)\": \"0.30\", \"p(difficulty_of_alignment_TRUE|instrumental_convergence_FALSE, problems_with_proxies_FALSE, problems_with_search_FALSE)\": \"0.10\", \"p(difficulty_of_alignment_FALSE|instrumental_convergence_TRUE, problems_with_proxies_TRUE, problems_with_search_TRUE)\": \"0.15\", \"p(difficulty_of_alignment_FALSE|instrumental_convergence_TRUE, problems_with_proxies_TRUE, problems_with_search_FALSE)\": \"0.30\", \"p(difficulty_of_alignment_FALSE|instrumental_convergence_TRUE, problems_with_proxies_FALSE, problems_with_search_TRUE)\": \"0.40\", \"p(difficulty_of_alignment_FALSE|instrumental_convergence_TRUE, problems_with_proxies_FALSE, problems_with_search_FALSE)\": \"0.60\", \"p(difficulty_of_alignment_FALSE|instrumental_convergence_FALSE, problems_with_proxies_TRUE, problems_with_search_TRUE)\": \"0.45\", \"p(difficulty_of_alignment_FALSE|instrumental_convergence_FALSE, problems_with_proxies_TRUE, problems_with_search_FALSE)\": \"0.60\", \"p(difficulty_of_alignment_FALSE|instrumental_convergence_FALSE, problems_with_proxies_FALSE, problems_with_search_TRUE)\": \"0.70\", \"p(difficulty_of_alignment_FALSE|instrumental_convergence_FALSE, problems_with_proxies_FALSE, problems_with_search_FALSE)\": \"0.90\"}}\\n                - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {\"instantiations\": [\"instrumental_convergence_TRUE\", \"instrumental_convergence_FALSE\"], \"priors\": {\"p(instrumental_convergence_TRUE)\": \"0.75\", \"p(instrumental_convergence_FALSE)\": \"0.25\"}}\\n                - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {\"instantiations\": [\"problems_with_proxies_TRUE\", \"problems_with_proxies_FALSE\"], \"priors\": {\"p(problems_with_proxies_TRUE)\": \"0.80\", \"p(problems_with_proxies_FALSE)\": \"0.20\"}}\\n                - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {\"instantiations\": [\"problems_with_search_TRUE\", \"problems_with_search_FALSE\"], \"priors\": {\"p(problems_with_search_TRUE)\": \"0.70\", \"p(problems_with_search_FALSE)\": \"0.30\"}}\\n            - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {\"instantiations\": [\"deployment_decisions_DEPLOY\", \"deployment_decisions_WITHHOLD\"], \"priors\": {\"p(deployment_decisions_DEPLOY)\": \"0.70\", \"p(deployment_decisions_WITHHOLD)\": \"0.30\"}, \"posteriors\": {\"p(deployment_decisions_DEPLOY|incentives_to_build_aps_STRONG, deception_by_ai_TRUE)\": \"0.90\", \"p(deployment_decisions_DEPLOY|incentives_to_build_aps_STRONG, deception_by_ai_FALSE)\": \"0.75\", \"p(deployment_decisions_DEPLOY|incentives_to_build_aps_WEAK, deception_by_ai_TRUE)\": \"0.60\", \"p(deployment_decisions_DEPLOY|incentives_to_build_aps_WEAK, deception_by_ai_FALSE)\": \"0.30\", \"p(deployment_decisions_WITHHOLD|incentives_to_build_aps_STRONG, deception_by_ai_TRUE)\": \"0.10\", \"p(deployment_decisions_WITHHOLD|incentives_to_build_aps_STRONG, deception_by_ai_FALSE)\": \"0.25\", \"p(deployment_decisions_WITHHOLD|incentives_to_build_aps_WEAK, deception_by_ai_TRUE)\": \"0.40\", \"p(deployment_decisions_WITHHOLD|incentives_to_build_aps_WEAK, deception_by_ai_FALSE)\": \"0.70\"}}\\n                - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {\"instantiations\": [\"incentives_to_build_aps_STRONG\", \"incentives_to_build_aps_WEAK\"], \"priors\": {\"p(incentives_to_build_aps_STRONG)\": \"0.80\", \"p(incentives_to_build_aps_WEAK)\": \"0.20\"}, \"posteriors\": {\"p(incentives_to_build_aps_STRONG|usefulness_of_aps_HIGH, competitive_dynamics_STRONG)\": \"0.95\", \"p(incentives_to_build_aps_STRONG|usefulness_of_aps_HIGH, competitive_dynamics_WEAK)\": \"0.80\", \"p(incentives_to_build_aps_STRONG|usefulness_of_aps_LOW, competitive_dynamics_STRONG)\": \"0.70\", \"p(incentives_to_build_aps_STRONG|usefulness_of_aps_LOW, competitive_dynamics_WEAK)\": \"0.30\", \"p(incentives_to_build_aps_WEAK|usefulness_of_aps_HIGH, competitive_dynamics_STRONG)\": \"0.05\", \"p(incentives_to_build_aps_WEAK|usefulness_of_aps_HIGH, competitive_dynamics_WEAK)\": \"0.20\", \"p(incentives_to_build_aps_WEAK|usefulness_of_aps_LOW, competitive_dynamics_STRONG)\": \"0.30\", \"p(incentives_to_build_aps_WEAK|usefulness_of_aps_LOW, competitive_dynamics_WEAK)\": \"0.70\"}}\\n                    - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {\"instantiations\": [\"usefulness_of_aps_HIGH\", \"usefulness_of_aps_LOW\"], \"priors\": {\"p(usefulness_of_aps_HIGH)\": \"0.85\", \"p(usefulness_of_aps_LOW)\": \"0.15\"}}\\n                    - [Competitive_Dynamics]: Competitive pressures between AI developers. {\"instantiations\": [\"competitive_dynamics_STRONG\", \"competitive_dynamics_WEAK\"], \"priors\": {\"p(competitive_dynamics_STRONG)\": \"0.75\", \"p(competitive_dynamics_WEAK)\": \"0.25\"}}\\n                - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {\"instantiations\": [\"deception_by_ai_TRUE\", \"deception_by_ai_FALSE\"], \"priors\": {\"p(deception_by_ai_TRUE)\": \"0.50\", \"p(deception_by_ai_FALSE)\": \"0.50\"}}\\n        - [Corrective_Feedback]: Human society implementing corrections after observing problems. {\"instantiations\": [\"corrective_feedback_EFFECTIVE\", \"corrective_feedback_INEFFECTIVE\"], \"priors\": {\"p(corrective_feedback_EFFECTIVE)\": \"0.60\", \"p(corrective_feedback_INEFFECTIVE)\": \"0.40\"}, \"posteriors\": {\"p(corrective_feedback_EFFECTIVE|warning_shots_OBSERVED, rapid_capability_escalation_TRUE)\": \"0.40\", \"p(corrective_feedback_EFFECTIVE|warning_shots_OBSERVED, rapid_capability_escalation_FALSE)\": \"0.80\", \"p(corrective_feedback_EFFECTIVE|warning_shots_UNOBSERVED, rapid_capability_escalation_TRUE)\": \"0.15\", \"p(corrective_feedback_EFFECTIVE|warning_shots_UNOBSERVED, rapid_capability_escalation_FALSE)\": \"0.50\", \"p(corrective_feedback_INEFFECTIVE|warning_shots_OBSERVED, rapid_capability_escalation_TRUE)\": \"0.60\", \"p(corrective_feedback_INEFFECTIVE|warning_shots_OBSERVED, rapid_capability_escalation_FALSE)\": \"0.20\", \"p(corrective_feedback_INEFFECTIVE|warning_shots_UNOBSERVED, rapid_capability_escalation_TRUE)\": \"0.85\", \"p(corrective_feedback_INEFFECTIVE|warning_shots_UNOBSERVED, rapid_capability_escalation_FALSE)\": \"0.50\"}}\\n            - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {\"instantiations\": [\"warning_shots_OBSERVED\", \"warning_shots_UNOBSERVED\"], \"priors\": {\"p(warning_shots_OBSERVED)\": \"0.70\", \"p(warning_shots_UNOBSERVED)\": \"0.30\"}}\\n            - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {\"instantiations\": [\"rapid_capability_escalation_TRUE\", \"rapid_capability_escalation_FALSE\"], \"priors\": {\"p(rapid_capability_escalation_TRUE)\": \"0.45\", \"p(rapid_capability_escalation_FALSE)\": \"0.55\"}}\\n[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {\"instantiations\": [\"barriers_to_understanding_HIGH\", \"barriers_to_understanding_LOW\"], \"priors\": {\"p(barriers_to_understanding_HIGH)\": \"0.70\", \"p(barriers_to_understanding_LOW)\": \"0.30\"}, \"posteriors\": {\"p(barriers_to_understanding_HIGH|misaligned_power_seeking_TRUE)\": \"0.85\", \"p(barriers_to_understanding_HIGH|misaligned_power_seeking_FALSE)\": \"0.60\", \"p(barriers_to_understanding_LOW|misaligned_power_seeking_TRUE)\": \"0.15\", \"p(barriers_to_understanding_LOW|misaligned_power_seeking_FALSE)\": \"0.40\"}}\\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"], \"priors\": {\"p(misaligned_power_seeking_TRUE)\": \"0.338\", \"p(misaligned_power_seeking_FALSE)\": \"0.662\"}}\\n[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {\"instantiations\": [\"adversarial_dynamics_TRUE\", \"adversarial_dynamics_FALSE\"], \"priors\": {\"p(adversarial_dynamics_TRUE)\": \"0.60\", \"p(adversarial_dynamics_FALSE)\": \"0.40\"}, \"posteriors\": {\"p(adversarial_dynamics_TRUE|misaligned_power_seeking_TRUE)\": \"0.95\", \"p(adversarial_dynamics_TRUE|misaligned_power_seeking_FALSE)\": \"0.10\", \"p(adversarial_dynamics_FALSE|misaligned_power_seeking_TRUE)\": \"0.05\", \"p(adversarial_dynamics_FALSE|misaligned_power_seeking_FALSE)\": \"0.90\"}}\\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"], \"priors\": {\"p(misaligned_power_seeking_TRUE)\": \"0.338\", \"p(misaligned_power_seeking_FALSE)\": \"0.662\"}}\\n[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {\"instantiations\": [\"stakes_of_error_HIGH\", \"stakes_of_error_LOW\"], \"priors\": {\"p(stakes_of_error_HIGH)\": \"0.85\", \"p(stakes_of_error_LOW)\": \"0.15\"}, \"posteriors\": {\"p(stakes_of_error_HIGH|misaligned_power_seeking_TRUE)\": \"0.95\", \"p(stakes_of_error_HIGH|misaligned_power_seeking_FALSE)\": \"0.50\", \"p(stakes_of_error_LOW|misaligned_power_seeking_TRUE)\": \"0.05\", \"p(stakes_of_error_LOW|misaligned_power_seeking_FALSE)\": \"0.50\"}}\\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"], \"priors\": {\"p(misaligned_power_seeking_TRUE)\": \"0.338\", \"p(misaligned_power_seeking_FALSE)\": \"0.662\"}}\\n'\n\n:::",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#test-bayesdown-extraction",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#test-bayesdown-extraction",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "F.7 3.1.2 Test BayesDown Extraction",
    "text": "F.7 3.1.2 Test BayesDown Extraction\n\n\nCode\ndisplay(Markdown(md_content_ex_rain)) # view BayesDown file formatted as MarkDown\n\n\n[Existential_Catastrophe]: The destruction of humanity’s long-term potential due to AI systems we’ve lost control over. {“instantiations”: [“existential_catastrophe_TRUE”, “existential_catastrophe_FALSE”], “priors”: {“p(existential_catastrophe_TRUE)”: “0.05”, “p(existential_catastrophe_FALSE)”: “0.95”}, “posteriors”: {“p(existential_catastrophe_TRUE|human_disempowerment_TRUE)”: “0.95”, “p(existential_catastrophe_TRUE|human_disempowerment_FALSE)”: “0.0”, “p(existential_catastrophe_FALSE|human_disempowerment_TRUE)”: “0.05”, “p(existential_catastrophe_FALSE|human_disempowerment_FALSE)”: “1.0”}} - [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {“instantiations”: [“human_disempowerment_TRUE”, “human_disempowerment_FALSE”], “priors”: {“p(human_disempowerment_TRUE)”: “0.208”, “p(human_disempowerment_FALSE)”: “0.792”}, “posteriors”: {“p(human_disempowerment_TRUE|scale_of_power_seeking_TRUE)”: “1.0”, “p(human_disempowerment_TRUE|scale_of_power_seeking_FALSE)”: “0.0”, “p(human_disempowerment_FALSE|scale_of_power_seeking_TRUE)”: “0.0”, “p(human_disempowerment_FALSE|scale_of_power_seeking_FALSE)”: “1.0”}} - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {“instantiations”: [“scale_of_power_seeking_TRUE”, “scale_of_power_seeking_FALSE”], “priors”: {“p(scale_of_power_seeking_TRUE)”: “0.208”, “p(scale_of_power_seeking_FALSE)”: “0.792”}, “posteriors”: {“p(scale_of_power_seeking_TRUE|misaligned_power_seeking_TRUE, corrective_feedback_EFFECTIVE)”: “0.25”, “p(scale_of_power_seeking_TRUE|misaligned_power_seeking_TRUE, corrective_feedback_INEFFECTIVE)”: “0.60”, “p(scale_of_power_seeking_TRUE|misaligned_power_seeking_FALSE, corrective_feedback_EFFECTIVE)”: “0.0”, “p(scale_of_power_seeking_TRUE|misaligned_power_seeking_FALSE, corrective_feedback_INEFFECTIVE)”: “0.0”, “p(scale_of_power_seeking_FALSE|misaligned_power_seeking_TRUE, corrective_feedback_EFFECTIVE)”: “0.75”, “p(scale_of_power_seeking_FALSE|misaligned_power_seeking_TRUE, corrective_feedback_INEFFECTIVE)”: “0.40”, “p(scale_of_power_seeking_FALSE|misaligned_power_seeking_FALSE, corrective_feedback_EFFECTIVE)”: “1.0”, “p(scale_of_power_seeking_FALSE|misaligned_power_seeking_FALSE, corrective_feedback_INEFFECTIVE)”: “1.0”}} - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {“instantiations”: [“misaligned_power_seeking_TRUE”, “misaligned_power_seeking_FALSE”], “priors”: {“p(misaligned_power_seeking_TRUE)”: “0.338”, “p(misaligned_power_seeking_FALSE)”: “0.662”}, “posteriors”: {“p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)”: “0.90”, “p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_WITHHOLD)”: “0.10”, “p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)”: “0.25”, “p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_WITHHOLD)”: “0.05”, “p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)”: “0.0”, “p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_WITHHOLD)”: “0.0”, “p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)”: “0.0”, “p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_FALSE, deployment_decisions_WITHHOLD)”: “0.0”, “p(misaligned_power_seeking_FALSE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)”: “0.10”, “p(misaligned_power_seeking_FALSE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_WITHHOLD)”: “0.90”, “p(misaligned_power_seeking_FALSE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)”: “0.75”, “p(misaligned_power_seeking_FALSE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_WITHHOLD)”: “0.95”, “p(misaligned_power_seeking_FALSE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)”: “1.0”, “p(misaligned_power_seeking_FALSE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_WITHHOLD)”: “1.0”, “p(misaligned_power_seeking_FALSE|aps_systems_FALSE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)”: “1.0”, “p(misaligned_power_seeking_FALSE|aps_systems_FALSE, difficulty_of_alignment_FALSE, deployment_decisions_WITHHOLD)”: “1.0”}} - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {“instantiations”: [“aps_systems_TRUE”, “aps_systems_FALSE”], “priors”: {“p(aps_systems_TRUE)”: “0.65”, “p(aps_systems_FALSE)”: “0.35”}, “posteriors”: {“p(aps_systems_TRUE|advanced_ai_capability_TRUE, agentic_planning_TRUE, strategic_awareness_TRUE)”: “1.0”, “p(aps_systems_TRUE|advanced_ai_capability_TRUE, agentic_planning_TRUE, strategic_awareness_FALSE)”: “0.0”, “p(aps_systems_TRUE|advanced_ai_capability_TRUE, agentic_planning_FALSE, strategic_awareness_TRUE)”: “0.0”, “p(aps_systems_TRUE|advanced_ai_capability_TRUE, agentic_planning_FALSE, strategic_awareness_FALSE)”: “0.0”, “p(aps_systems_TRUE|advanced_ai_capability_FALSE, agentic_planning_TRUE, strategic_awareness_TRUE)”: “0.0”, “p(aps_systems_TRUE|advanced_ai_capability_FALSE, agentic_planning_TRUE, strategic_awareness_FALSE)”: “0.0”, “p(aps_systems_TRUE|advanced_ai_capability_FALSE, agentic_planning_FALSE, strategic_awareness_TRUE)”: “0.0”, “p(aps_systems_TRUE|advanced_ai_capability_FALSE, agentic_planning_FALSE, strategic_awareness_FALSE)”: “0.0”, “p(aps_systems_FALSE|advanced_ai_capability_TRUE, agentic_planning_TRUE, strategic_awareness_TRUE)”: “0.0”, “p(aps_systems_FALSE|advanced_ai_capability_TRUE, agentic_planning_TRUE, strategic_awareness_FALSE)”: “1.0”, “p(aps_systems_FALSE|advanced_ai_capability_TRUE, agentic_planning_FALSE, strategic_awareness_TRUE)”: “1.0”, “p(aps_systems_FALSE|advanced_ai_capability_TRUE, agentic_planning_FALSE, strategic_awareness_FALSE)”: “1.0”, “p(aps_systems_FALSE|advanced_ai_capability_FALSE, agentic_planning_TRUE, strategic_awareness_TRUE)”: “1.0”, “p(aps_systems_FALSE|advanced_ai_capability_FALSE, agentic_planning_TRUE, strategic_awareness_FALSE)”: “1.0”, “p(aps_systems_FALSE|advanced_ai_capability_FALSE, agentic_planning_FALSE, strategic_awareness_TRUE)”: “1.0”, “p(aps_systems_FALSE|advanced_ai_capability_FALSE, agentic_planning_FALSE, strategic_awareness_FALSE)”: “1.0”}} - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {“instantiations”: [“advanced_ai_capability_TRUE”, “advanced_ai_capability_FALSE”], “priors”: {“p(advanced_ai_capability_TRUE)”: “0.80”, “p(advanced_ai_capability_FALSE)”: “0.20”}} - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {“instantiations”: [“agentic_planning_TRUE”, “agentic_planning_FALSE”], “priors”: {“p(agentic_planning_TRUE)”: “0.85”, “p(agentic_planning_FALSE)”: “0.15”}} - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {“instantiations”: [“strategic_awareness_TRUE”, “strategic_awareness_FALSE”], “priors”: {“p(strategic_awareness_TRUE)”: “0.75”, “p(strategic_awareness_FALSE)”: “0.25”}} - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {“instantiations”: [“difficulty_of_alignment_TRUE”, “difficulty_of_alignment_FALSE”], “priors”: {“p(difficulty_of_alignment_TRUE)”: “0.40”, “p(difficulty_of_alignment_FALSE)”: “0.60”}, “posteriors”: {“p(difficulty_of_alignment_TRUE|instrumental_convergence_TRUE, problems_with_proxies_TRUE, problems_with_search_TRUE)”: “0.85”, “p(difficulty_of_alignment_TRUE|instrumental_convergence_TRUE, problems_with_proxies_TRUE, problems_with_search_FALSE)”: “0.70”, “p(difficulty_of_alignment_TRUE|instrumental_convergence_TRUE, problems_with_proxies_FALSE, problems_with_search_TRUE)”: “0.60”, “p(difficulty_of_alignment_TRUE|instrumental_convergence_TRUE, problems_with_proxies_FALSE, problems_with_search_FALSE)”: “0.40”, “p(difficulty_of_alignment_TRUE|instrumental_convergence_FALSE, problems_with_proxies_TRUE, problems_with_search_TRUE)”: “0.55”, “p(difficulty_of_alignment_TRUE|instrumental_convergence_FALSE, problems_with_proxies_TRUE, problems_with_search_FALSE)”: “0.40”, “p(difficulty_of_alignment_TRUE|instrumental_convergence_FALSE, problems_with_proxies_FALSE, problems_with_search_TRUE)”: “0.30”, “p(difficulty_of_alignment_TRUE|instrumental_convergence_FALSE, problems_with_proxies_FALSE, problems_with_search_FALSE)”: “0.10”, “p(difficulty_of_alignment_FALSE|instrumental_convergence_TRUE, problems_with_proxies_TRUE, problems_with_search_TRUE)”: “0.15”, “p(difficulty_of_alignment_FALSE|instrumental_convergence_TRUE, problems_with_proxies_TRUE, problems_with_search_FALSE)”: “0.30”, “p(difficulty_of_alignment_FALSE|instrumental_convergence_TRUE, problems_with_proxies_FALSE, problems_with_search_TRUE)”: “0.40”, “p(difficulty_of_alignment_FALSE|instrumental_convergence_TRUE, problems_with_proxies_FALSE, problems_with_search_FALSE)”: “0.60”, “p(difficulty_of_alignment_FALSE|instrumental_convergence_FALSE, problems_with_proxies_TRUE, problems_with_search_TRUE)”: “0.45”, “p(difficulty_of_alignment_FALSE|instrumental_convergence_FALSE, problems_with_proxies_TRUE, problems_with_search_FALSE)”: “0.60”, “p(difficulty_of_alignment_FALSE|instrumental_convergence_FALSE, problems_with_proxies_FALSE, problems_with_search_TRUE)”: “0.70”, “p(difficulty_of_alignment_FALSE|instrumental_convergence_FALSE, problems_with_proxies_FALSE, problems_with_search_FALSE)”: “0.90”}} - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {“instantiations”: [“instrumental_convergence_TRUE”, “instrumental_convergence_FALSE”], “priors”: {“p(instrumental_convergence_TRUE)”: “0.75”, “p(instrumental_convergence_FALSE)”: “0.25”}} - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {“instantiations”: [“problems_with_proxies_TRUE”, “problems_with_proxies_FALSE”], “priors”: {“p(problems_with_proxies_TRUE)”: “0.80”, “p(problems_with_proxies_FALSE)”: “0.20”}} - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {“instantiations”: [“problems_with_search_TRUE”, “problems_with_search_FALSE”], “priors”: {“p(problems_with_search_TRUE)”: “0.70”, “p(problems_with_search_FALSE)”: “0.30”}} - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {“instantiations”: [“deployment_decisions_DEPLOY”, “deployment_decisions_WITHHOLD”], “priors”: {“p(deployment_decisions_DEPLOY)”: “0.70”, “p(deployment_decisions_WITHHOLD)”: “0.30”}, “posteriors”: {“p(deployment_decisions_DEPLOY|incentives_to_build_aps_STRONG, deception_by_ai_TRUE)”: “0.90”, “p(deployment_decisions_DEPLOY|incentives_to_build_aps_STRONG, deception_by_ai_FALSE)”: “0.75”, “p(deployment_decisions_DEPLOY|incentives_to_build_aps_WEAK, deception_by_ai_TRUE)”: “0.60”, “p(deployment_decisions_DEPLOY|incentives_to_build_aps_WEAK, deception_by_ai_FALSE)”: “0.30”, “p(deployment_decisions_WITHHOLD|incentives_to_build_aps_STRONG, deception_by_ai_TRUE)”: “0.10”, “p(deployment_decisions_WITHHOLD|incentives_to_build_aps_STRONG, deception_by_ai_FALSE)”: “0.25”, “p(deployment_decisions_WITHHOLD|incentives_to_build_aps_WEAK, deception_by_ai_TRUE)”: “0.40”, “p(deployment_decisions_WITHHOLD|incentives_to_build_aps_WEAK, deception_by_ai_FALSE)”: “0.70”}} - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {“instantiations”: [“incentives_to_build_aps_STRONG”, “incentives_to_build_aps_WEAK”], “priors”: {“p(incentives_to_build_aps_STRONG)”: “0.80”, “p(incentives_to_build_aps_WEAK)”: “0.20”}, “posteriors”: {“p(incentives_to_build_aps_STRONG|usefulness_of_aps_HIGH, competitive_dynamics_STRONG)”: “0.95”, “p(incentives_to_build_aps_STRONG|usefulness_of_aps_HIGH, competitive_dynamics_WEAK)”: “0.80”, “p(incentives_to_build_aps_STRONG|usefulness_of_aps_LOW, competitive_dynamics_STRONG)”: “0.70”, “p(incentives_to_build_aps_STRONG|usefulness_of_aps_LOW, competitive_dynamics_WEAK)”: “0.30”, “p(incentives_to_build_aps_WEAK|usefulness_of_aps_HIGH, competitive_dynamics_STRONG)”: “0.05”, “p(incentives_to_build_aps_WEAK|usefulness_of_aps_HIGH, competitive_dynamics_WEAK)”: “0.20”, “p(incentives_to_build_aps_WEAK|usefulness_of_aps_LOW, competitive_dynamics_STRONG)”: “0.30”, “p(incentives_to_build_aps_WEAK|usefulness_of_aps_LOW, competitive_dynamics_WEAK)”: “0.70”}} - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {“instantiations”: [“usefulness_of_aps_HIGH”, “usefulness_of_aps_LOW”], “priors”: {“p(usefulness_of_aps_HIGH)”: “0.85”, “p(usefulness_of_aps_LOW)”: “0.15”}} - [Competitive_Dynamics]: Competitive pressures between AI developers. {“instantiations”: [“competitive_dynamics_STRONG”, “competitive_dynamics_WEAK”], “priors”: {“p(competitive_dynamics_STRONG)”: “0.75”, “p(competitive_dynamics_WEAK)”: “0.25”}} - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {“instantiations”: [“deception_by_ai_TRUE”, “deception_by_ai_FALSE”], “priors”: {“p(deception_by_ai_TRUE)”: “0.50”, “p(deception_by_ai_FALSE)”: “0.50”}} - [Corrective_Feedback]: Human society implementing corrections after observing problems. {“instantiations”: [“corrective_feedback_EFFECTIVE”, “corrective_feedback_INEFFECTIVE”], “priors”: {“p(corrective_feedback_EFFECTIVE)”: “0.60”, “p(corrective_feedback_INEFFECTIVE)”: “0.40”}, “posteriors”: {“p(corrective_feedback_EFFECTIVE|warning_shots_OBSERVED, rapid_capability_escalation_TRUE)”: “0.40”, “p(corrective_feedback_EFFECTIVE|warning_shots_OBSERVED, rapid_capability_escalation_FALSE)”: “0.80”, “p(corrective_feedback_EFFECTIVE|warning_shots_UNOBSERVED, rapid_capability_escalation_TRUE)”: “0.15”, “p(corrective_feedback_EFFECTIVE|warning_shots_UNOBSERVED, rapid_capability_escalation_FALSE)”: “0.50”, “p(corrective_feedback_INEFFECTIVE|warning_shots_OBSERVED, rapid_capability_escalation_TRUE)”: “0.60”, “p(corrective_feedback_INEFFECTIVE|warning_shots_OBSERVED, rapid_capability_escalation_FALSE)”: “0.20”, “p(corrective_feedback_INEFFECTIVE|warning_shots_UNOBSERVED, rapid_capability_escalation_TRUE)”: “0.85”, “p(corrective_feedback_INEFFECTIVE|warning_shots_UNOBSERVED, rapid_capability_escalation_FALSE)”: “0.50”}} - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {“instantiations”: [“warning_shots_OBSERVED”, “warning_shots_UNOBSERVED”], “priors”: {“p(warning_shots_OBSERVED)”: “0.70”, “p(warning_shots_UNOBSERVED)”: “0.30”}} - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {“instantiations”: [“rapid_capability_escalation_TRUE”, “rapid_capability_escalation_FALSE”], “priors”: {“p(rapid_capability_escalation_TRUE)”: “0.45”, “p(rapid_capability_escalation_FALSE)”: “0.55”}} [Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {“instantiations”: [“barriers_to_understanding_HIGH”, “barriers_to_understanding_LOW”], “priors”: {“p(barriers_to_understanding_HIGH)”: “0.70”, “p(barriers_to_understanding_LOW)”: “0.30”}, “posteriors”: {“p(barriers_to_understanding_HIGH|misaligned_power_seeking_TRUE)”: “0.85”, “p(barriers_to_understanding_HIGH|misaligned_power_seeking_FALSE)”: “0.60”, “p(barriers_to_understanding_LOW|misaligned_power_seeking_TRUE)”: “0.15”, “p(barriers_to_understanding_LOW|misaligned_power_seeking_FALSE)”: “0.40”}} - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {“instantiations”: [“misaligned_power_seeking_TRUE”, “misaligned_power_seeking_FALSE”], “priors”: {“p(misaligned_power_seeking_TRUE)”: “0.338”, “p(misaligned_power_seeking_FALSE)”: “0.662”}} [Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {“instantiations”: [“adversarial_dynamics_TRUE”, “adversarial_dynamics_FALSE”], “priors”: {“p(adversarial_dynamics_TRUE)”: “0.60”, “p(adversarial_dynamics_FALSE)”: “0.40”}, “posteriors”: {“p(adversarial_dynamics_TRUE|misaligned_power_seeking_TRUE)”: “0.95”, “p(adversarial_dynamics_TRUE|misaligned_power_seeking_FALSE)”: “0.10”, “p(adversarial_dynamics_FALSE|misaligned_power_seeking_TRUE)”: “0.05”, “p(adversarial_dynamics_FALSE|misaligned_power_seeking_FALSE)”: “0.90”}} - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {“instantiations”: [“misaligned_power_seeking_TRUE”, “misaligned_power_seeking_FALSE”], “priors”: {“p(misaligned_power_seeking_TRUE)”: “0.338”, “p(misaligned_power_seeking_FALSE)”: “0.662”}} [Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {“instantiations”: [“stakes_of_error_HIGH”, “stakes_of_error_LOW”], “priors”: {“p(stakes_of_error_HIGH)”: “0.85”, “p(stakes_of_error_LOW)”: “0.15”}, “posteriors”: {“p(stakes_of_error_HIGH|misaligned_power_seeking_TRUE)”: “0.95”, “p(stakes_of_error_HIGH|misaligned_power_seeking_FALSE)”: “0.50”, “p(stakes_of_error_LOW|misaligned_power_seeking_TRUE)”: “0.05”, “p(stakes_of_error_LOW|misaligned_power_seeking_FALSE)”: “0.50”}} - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {“instantiations”: [“misaligned_power_seeking_TRUE”, “misaligned_power_seeking_FALSE”], “priors”: {“p(misaligned_power_seeking_TRUE)”: “0.338”, “p(misaligned_power_seeking_FALSE)”: “0.662”}}",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#check-the-graph-structure-with-the-argdown-sandbox-online-1",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#check-the-graph-structure-with-the-argdown-sandbox-online-1",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "F.8 3.1.2.2 Check the Graph Structure with the ArgDown Sandbox Online",
    "text": "F.8 3.1.2.2 Check the Graph Structure with the ArgDown Sandbox Online\nCopy and paste the BayesDown formatted … in the ArgDown Sandbox below to quickly verify that the network renders correctly.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#extraction",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#extraction",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "F.9 3.3 Extraction",
    "text": "F.9 3.3 Extraction\nBayesDown Extraction Code already part of ArgDown extraction code, therefore just use same function “parse_markdown_hierarchy(markdown_data)” and ignore the extra argument (“ArgDown”) because it is automatically set to false amd will by default extract BayesDown.\n\n\nCode\nresult_df = parse_markdown_hierarchy_fixed(md_content_ex_rain)\nresult_df\n\n\n\n    \n\n\n\n\n\n\nTitle\nDescription\nline\nline_numbers\nindentation\nindentation_levels\nParents\nChildren\ninstantiations\npriors\nposteriors\nNo_Parent\nNo_Children\nparent_instantiations\n\n\n\n\n0\nExistential_Catastrophe\nThe destruction of humanity's long-term potent...\n0\n[0]\n0\n[0]\n[]\n[]\n[existential_catastrophe_TRUE, existential_cat...\n{'p(existential_catastrophe_TRUE)': '0.05', 'p...\n{'p(existential_catastrophe_TRUE|human_disempo...\nTrue\nTrue\n[]\n\n\n1\nHuman_Disempowerment\nPermanent and collective disempowerment of hum...\n1\n[1]\n0\n[0]\n[Scale_Of_Power_Seeking]\n[]\n[human_disempowerment_TRUE, human_disempowerme...\n{'p(human_disempowerment_TRUE)': '0.208', 'p(h...\n{'p(human_disempowerment_TRUE|scale_of_power_s...\nFalse\nTrue\n[[scale_of_power_seeking_TRUE, scale_of_power_...\n\n\n2\nScale_Of_Power_Seeking\nPower-seeking by AI systems scaling to the poi...\n2\n[2]\n4\n[4]\n[Misaligned_Power_Seeking, Corrective_Feedback]\n[Human_Disempowerment]\n[scale_of_power_seeking_TRUE, scale_of_power_s...\n{'p(scale_of_power_seeking_TRUE)': '0.208', 'p...\n{'p(scale_of_power_seeking_TRUE|misaligned_pow...\nFalse\nFalse\n[[misaligned_power_seeking_TRUE, misaligned_po...\n\n\n3\nMisaligned_Power_Seeking\nDeployed AI systems seeking power in unintende...\n3\n[3, 21, 23, 25]\n8\n[8, 0, 0, 0]\n[APS_Systems, Difficulty_Of_Alignment, Deploym...\n[Scale_Of_Power_Seeking]\n[misaligned_power_seeking_TRUE, misaligned_pow...\n{'p(misaligned_power_seeking_TRUE)': '0.338', ...\n{'p(misaligned_power_seeking_TRUE|aps_systems_...\nFalse\nFalse\n[[aps_systems_TRUE, aps_systems_FALSE], [diffi...\n\n\n4\nAPS_Systems\nAI systems with advanced capabilities, agentic...\n4\n[4]\n12\n[12]\n[Advanced_AI_Capability, Agentic_Planning, Str...\n[Misaligned_Power_Seeking]\n[aps_systems_TRUE, aps_systems_FALSE]\n{'p(aps_systems_TRUE)': '0.65', 'p(aps_systems...\n{'p(aps_systems_TRUE|advanced_ai_capability_TR...\nFalse\nFalse\n[[advanced_ai_capability_TRUE, advanced_ai_cap...\n\n\n5\nAdvanced_AI_Capability\nAI systems that outperform humans on tasks tha...\n5\n[5]\n16\n[16]\n[]\n[APS_Systems]\n[advanced_ai_capability_TRUE, advanced_ai_capa...\n{'p(advanced_ai_capability_TRUE)': '0.80', 'p(...\n{}\nTrue\nFalse\n[]\n\n\n6\nAgentic_Planning\nAI systems making and executing plans based on...\n6\n[6]\n16\n[16]\n[]\n[APS_Systems]\n[agentic_planning_TRUE, agentic_planning_FALSE]\n{'p(agentic_planning_TRUE)': '0.85', 'p(agenti...\n{}\nTrue\nFalse\n[]\n\n\n7\nStrategic_Awareness\nAI systems with models accurately representing...\n7\n[7]\n16\n[16]\n[]\n[APS_Systems]\n[strategic_awareness_TRUE, strategic_awareness...\n{'p(strategic_awareness_TRUE)': '0.75', 'p(str...\n{}\nTrue\nFalse\n[]\n\n\n8\nDifficulty_Of_Alignment\nIt is harder to build aligned systems than mis...\n8\n[8]\n12\n[12]\n[Instrumental_Convergence, Problems_With_Proxi...\n[Misaligned_Power_Seeking]\n[difficulty_of_alignment_TRUE, difficulty_of_a...\n{'p(difficulty_of_alignment_TRUE)': '0.40', 'p...\n{'p(difficulty_of_alignment_TRUE|instrumental_...\nFalse\nFalse\n[[instrumental_convergence_TRUE, instrumental_...\n\n\n9\nInstrumental_Convergence\nAI systems with misaligned objectives tend to ...\n9\n[9]\n16\n[16]\n[]\n[Difficulty_Of_Alignment]\n[instrumental_convergence_TRUE, instrumental_c...\n{'p(instrumental_convergence_TRUE)': '0.75', '...\n{}\nTrue\nFalse\n[]\n\n\n10\nProblems_With_Proxies\nOptimizing for proxy objectives breaks correla...\n10\n[10]\n16\n[16]\n[]\n[Difficulty_Of_Alignment]\n[problems_with_proxies_TRUE, problems_with_pro...\n{'p(problems_with_proxies_TRUE)': '0.80', 'p(p...\n{}\nTrue\nFalse\n[]\n\n\n11\nProblems_With_Search\nSearch processes can yield systems pursuing di...\n11\n[11]\n16\n[16]\n[]\n[Difficulty_Of_Alignment]\n[problems_with_search_TRUE, problems_with_sear...\n{'p(problems_with_search_TRUE)': '0.70', 'p(pr...\n{}\nTrue\nFalse\n[]\n\n\n12\nDeployment_Decisions\nDecisions to deploy potentially misaligned AI ...\n12\n[12]\n12\n[12]\n[Incentives_To_Build_APS, Deception_By_AI]\n[Misaligned_Power_Seeking]\n[deployment_decisions_DEPLOY, deployment_decis...\n{'p(deployment_decisions_DEPLOY)': '0.70', 'p(...\n{'p(deployment_decisions_DEPLOY|incentives_to_...\nFalse\nFalse\n[[incentives_to_build_aps_STRONG, incentives_t...\n\n\n13\nIncentives_To_Build_APS\nStrong incentives to build and deploy APS syst...\n13\n[13]\n16\n[16]\n[Usefulness_Of_APS, Competitive_Dynamics]\n[Deployment_Decisions]\n[incentives_to_build_aps_STRONG, incentives_to...\n{'p(incentives_to_build_aps_STRONG)': '0.80', ...\n{'p(incentives_to_build_aps_STRONG|usefulness_...\nFalse\nFalse\n[[usefulness_of_aps_HIGH, usefulness_of_aps_LO...\n\n\n14\nUsefulness_Of_APS\nAPS systems are very useful for many valuable ...\n14\n[14]\n20\n[20]\n[]\n[Incentives_To_Build_APS]\n[usefulness_of_aps_HIGH, usefulness_of_aps_LOW]\n{'p(usefulness_of_aps_HIGH)': '0.85', 'p(usefu...\n{}\nTrue\nFalse\n[]\n\n\n15\nCompetitive_Dynamics\nCompetitive pressures between AI developers.\n15\n[15]\n20\n[20]\n[]\n[Incentives_To_Build_APS]\n[competitive_dynamics_STRONG, competitive_dyna...\n{'p(competitive_dynamics_STRONG)': '0.75', 'p(...\n{}\nTrue\nFalse\n[]\n\n\n16\nDeception_By_AI\nAI systems deceiving humans about their true o...\n16\n[16]\n16\n[16]\n[]\n[Deployment_Decisions]\n[deception_by_ai_TRUE, deception_by_ai_FALSE]\n{'p(deception_by_ai_TRUE)': '0.50', 'p(decepti...\n{}\nTrue\nFalse\n[]\n\n\n17\nCorrective_Feedback\nHuman society implementing corrections after o...\n17\n[17]\n8\n[8]\n[Warning_Shots, Rapid_Capability_Escalation]\n[Scale_Of_Power_Seeking]\n[corrective_feedback_EFFECTIVE, corrective_fee...\n{'p(corrective_feedback_EFFECTIVE)': '0.60', '...\n{'p(corrective_feedback_EFFECTIVE|warning_shot...\nFalse\nFalse\n[[warning_shots_OBSERVED, warning_shots_UNOBSE...\n\n\n18\nWarning_Shots\nObservable failures in weaker systems before c...\n18\n[18]\n12\n[12]\n[]\n[Corrective_Feedback]\n[warning_shots_OBSERVED, warning_shots_UNOBSER...\n{'p(warning_shots_OBSERVED)': '0.70', 'p(warni...\n{}\nTrue\nFalse\n[]\n\n\n19\nRapid_Capability_Escalation\nAI capabilities escalating very rapidly, allow...\n19\n[19]\n12\n[12]\n[]\n[Corrective_Feedback]\n[rapid_capability_escalation_TRUE, rapid_capab...\n{'p(rapid_capability_escalation_TRUE)': '0.45'...\n{}\nTrue\nFalse\n[]\n\n\n20\nBarriers_To_Understanding\nDifficulty in understanding the internal worki...\n20\n[20]\n0\n[0]\n[]\n[]\n[barriers_to_understanding_HIGH, barriers_to_u...\n{'p(barriers_to_understanding_HIGH)': '0.70', ...\n{'p(barriers_to_understanding_HIGH|misaligned_...\nTrue\nTrue\n[]\n\n\n21\nAdversarial_Dynamics\nPotentially adversarial relationships between ...\n22\n[22]\n0\n[0]\n[]\n[]\n[adversarial_dynamics_TRUE, adversarial_dynami...\n{'p(adversarial_dynamics_TRUE)': '0.60', 'p(ad...\n{'p(adversarial_dynamics_TRUE|misaligned_power...\nTrue\nTrue\n[]\n\n\n22\nStakes_Of_Error\nThe escalating impact of mistakes with power-s...\n24\n[24]\n0\n[0]\n[]\n[]\n[stakes_of_error_HIGH, stakes_of_error_LOW]\n{'p(stakes_of_error_HIGH)': '0.85', 'p(stakes_...\n{'p(stakes_of_error_HIGH|misaligned_power_seek...\nTrue\nTrue\n[]\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\nF.9.1 3.3 Data-Post-Processing\nAdd rows to data frame that can be calculated from the extracted rows\n\n\nCode\n# @title 3.3.1 Data Post-Processing Functions ---\n\n\"\"\"\nBLOCK PURPOSE: Enhances the extracted BayesDown data with calculated metrics and network properties.\n\nThis block provides functions to enrich the basic extracted data with additional\ncalculated columns that are useful for analysis and visualization:\n\n1. Joint probabilities - Calculating P(A,B) from conditional and prior probabilities\n2. Network metrics - Centrality measures that indicate importance of nodes in the network\n3. Markov blanket - Identifying the minimal set of nodes that shield a node from the rest\n\nThese enhancements provide valuable context for understanding the network structure\nand the relationships between variables, enabling more advanced analysis and\nimproving visualization.\n\nDEPENDENCIES: networkx for graph calculations\nINPUTS: DataFrame with basic extracted BayesDown data\nOUTPUTS: Enhanced DataFrame with additional calculated columns\n\"\"\"\n\ndef enhance_extracted_data(df):\n    \"\"\"\n    Enhance the extracted data with calculated columns\n\n    Args:\n        df: DataFrame with extracted BayesDown data\n\n    Returns:\n        Enhanced DataFrame with additional columns\n    \"\"\"\n    # Create a copy to avoid modifying the original\n    enhanced_df = df.copy()\n\n    # 1. Calculate joint probabilities - P(A,B) = P(A|B) * P(B)\n    enhanced_df['joint_probabilities'] = None\n\n    for idx, row in enhanced_df.iterrows():\n        title = row['Title']\n        priors = row['priors'] if isinstance(row['priors'], dict) else {}\n        posteriors = row['posteriors'] if isinstance(row['posteriors'], dict) else {}\n        parents = row['Parents'] if isinstance(row['Parents'], list) else []\n\n        # Skip if no parents or no priors\n        if not parents or not priors:\n            continue\n\n        # Initialize joint probabilities dictionary\n        joint_probs = {}\n\n        # Get instantiations\n        instantiations = row['instantiations']\n        if not isinstance(instantiations, list) or not instantiations:\n            continue\n\n        # For each parent and child instantiation combination, calculate joint probability\n        for inst in instantiations:\n            # Get this instantiation's prior probability\n            inst_prior_key = f\"p({inst})\"\n            if inst_prior_key not in priors:\n                continue\n\n            try:\n                inst_prior = float(priors[inst_prior_key])\n            except (ValueError, TypeError):\n                continue\n\n            # For each parent\n            for parent in parents:\n                parent_row = enhanced_df[enhanced_df['Title'] == parent]\n                if parent_row.empty:\n                    continue\n\n                parent_insts = parent_row.iloc[0]['instantiations']\n                if not isinstance(parent_insts, list) or not parent_insts:\n                    continue\n\n                for parent_inst in parent_insts:\n                    # Get conditional probability\n                    cond_key = f\"p({inst}|{parent}={parent_inst})\"\n                    if cond_key in posteriors:\n                        try:\n                            cond_prob = float(posteriors[cond_key])\n\n                            # Get parent's prior\n                            parent_priors = parent_row.iloc[0]['priors']\n                            if not isinstance(parent_priors, dict):\n                                continue\n\n                            parent_prior_key = f\"p({parent_inst})\"\n                            if parent_prior_key not in parent_priors:\n                                continue\n\n                            try:\n                                parent_prior = float(parent_priors[parent_prior_key])\n\n                                # Calculate joint probability: P(A,B) = P(A|B) * P(B)\n                                joint_prob = cond_prob * parent_prior\n                                joint_key = f\"p({inst},{parent}={parent_inst})\"\n                                joint_probs[joint_key] = str(round(joint_prob, 4))\n                            except (ValueError, TypeError):\n                                joint_prob = cond_prob * parent_prior\n                                joint_key = f\"p({inst},{parent}={parent_inst})\"\n                                joint_probs[joint_key] = str(round(joint_prob, 4))\n                            except (ValueError, TypeError):\n                                continue\n                        except (ValueError, TypeError):\n                            continue\n\n        # Store joint probabilities in dataframe\n        enhanced_df.at[idx, 'joint_probabilities'] = joint_probs\n\n    # 2. Calculate network metrics\n    # Create a directed graph\n    import networkx as nx\n    G = nx.DiGraph()\n\n    # Add nodes\n    for idx, row in enhanced_df.iterrows():\n        G.add_node(row['Title'])\n\n    # Add edges\n    for idx, row in enhanced_df.iterrows():\n        child = row['Title']\n        parents = row['Parents'] if isinstance(row['Parents'], list) else []\n\n        for parent in parents:\n            if parent in G.nodes():\n                G.add_edge(parent, child)\n\n    # Calculate centrality measures\n    degree_centrality = nx.degree_centrality(G)  # Overall connectedness\n    in_degree_centrality = nx.in_degree_centrality(G)  # How many nodes affect this one\n    out_degree_centrality = nx.out_degree_centrality(G)  # How many nodes this one affects\n\n    try:\n        betweenness_centrality = nx.betweenness_centrality(G)  # Node's role as a connector\n    except:\n        betweenness_centrality = {node: 0 for node in G.nodes()}\n\n    # Add metrics to dataframe\n    enhanced_df['degree_centrality'] = None\n    enhanced_df['in_degree_centrality'] = None\n    enhanced_df['out_degree_centrality'] = None\n    enhanced_df['betweenness_centrality'] = None\n\n    for idx, row in enhanced_df.iterrows():\n        title = row['Title']\n        enhanced_df.at[idx, 'degree_centrality'] = degree_centrality.get(title, 0)\n        enhanced_df.at[idx, 'in_degree_centrality'] = in_degree_centrality.get(title, 0)\n        enhanced_df.at[idx, 'out_degree_centrality'] = out_degree_centrality.get(title, 0)\n        enhanced_df.at[idx, 'betweenness_centrality'] = betweenness_centrality.get(title, 0)\n\n    # 3. Add Markov blanket information (parents, children, and children's parents)\n    enhanced_df['markov_blanket'] = None\n\n    for idx, row in enhanced_df.iterrows():\n        title = row['Title']\n        parents = row['Parents'] if isinstance(row['Parents'], list) else []\n        children = row['Children'] if isinstance(row['Children'], list) else []\n\n        # Get children's parents (excluding this node)\n        childrens_parents = []\n        for child in children:\n            child_row = enhanced_df[enhanced_df['Title'] == child]\n            if not child_row.empty:\n                child_parents = child_row.iloc[0]['Parents']\n                if isinstance(child_parents, list):\n                    childrens_parents.extend([p for p in child_parents if p != title])\n\n        # Remove duplicates\n        childrens_parents = list(set(childrens_parents))\n\n        # Combine to get Markov blanket\n        markov_blanket = list(set(parents + children + childrens_parents))\n        enhanced_df.at[idx, 'markov_blanket'] = markov_blanket\n\n    return enhanced_df\n\n\n\n\nCode\n# @title 3.3 --- Enhance Extracted Data with Network Metrics ---\n\n\"\"\"\nBLOCK PURPOSE: Applies the post-processing functions to enhance the extracted data.\n\nThis block takes the basic extracted DataFrame from the BayesDown parsing step\nand enriches it with calculated metrics that provide deeper insight into the\nnetwork structure and relationships. It:\n\n1. Applies the enhancement functions defined previously\n2. Displays summary information about key calculated metrics\n3. Saves the enhanced data for further analysis and visualization\n\nThe enhanced DataFrame provides a richer representation of the Bayesian network,\nincluding measures of node importance and conditional relationships that are\nessential for effective analysis and visualization.\n\nDEPENDENCIES: enhance_extracted_data function\nINPUTS: DataFrame with basic extracted BayesDown data\nOUTPUTS: Enhanced DataFrame with additional calculated columns, saved to CSV\n\"\"\"\n\n# Enhance the extracted dataframe with calculated columns\nenhanced_df = enhance_extracted_data(result_df)\n\n# Display the enhanced dataframe\nprint(\"Enhanced DataFrame with additional calculated columns:\")\nenhanced_df.head()\n\n# Check some calculated metrics\nprint(\"\\nJoint Probabilities Example:\")\nexample_node = enhanced_df.loc[0, 'Title']\njoint_probs = enhanced_df.loc[0, 'joint_probabilities']\nprint(f\"Joint probabilities for {example_node}:\")\nprint(joint_probs)\n\nprint(\"\\nNetwork Metrics:\")\nfor idx, row in enhanced_df.iterrows():\n    print(f\"{row['Title']}:\")\n    print(f\"  Degree Centrality: {row['degree_centrality']:.3f}\")\n    print(f\"  Betweenness Centrality: {row['betweenness_centrality']:.3f}\")\n\n# Save the enhanced dataframe\nenhanced_df.to_csv('enhanced_extracted_data.csv', index=False)\nprint(\"\\nEnhanced data saved to 'enhanced_extracted_data.csv'\")\n\n\nEnhanced DataFrame with additional calculated columns:\n\nJoint Probabilities Example:\nJoint probabilities for Existential_Catastrophe:\nNone\n\nNetwork Metrics:\nExistential_Catastrophe:\n  Degree Centrality: 0.000\n  Betweenness Centrality: 0.000\nHuman_Disempowerment:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nScale_Of_Power_Seeking:\n  Degree Centrality: 0.136\n  Betweenness Centrality: 0.037\nMisaligned_Power_Seeking:\n  Degree Centrality: 0.182\n  Betweenness Centrality: 0.056\nAPS_Systems:\n  Degree Centrality: 0.182\n  Betweenness Centrality: 0.019\nAdvanced_AI_Capability:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nAgentic_Planning:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nStrategic_Awareness:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nDifficulty_Of_Alignment:\n  Degree Centrality: 0.182\n  Betweenness Centrality: 0.019\nInstrumental_Convergence:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nProblems_With_Proxies:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nProblems_With_Search:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nDeployment_Decisions:\n  Degree Centrality: 0.136\n  Betweenness Centrality: 0.026\nIncentives_To_Build_APS:\n  Degree Centrality: 0.136\n  Betweenness Centrality: 0.017\nUsefulness_Of_APS:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nCompetitive_Dynamics:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nDeception_By_AI:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nCorrective_Feedback:\n  Degree Centrality: 0.136\n  Betweenness Centrality: 0.009\nWarning_Shots:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nRapid_Capability_Escalation:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nBarriers_To_Understanding:\n  Degree Centrality: 0.000\n  Betweenness Centrality: 0.000\nAdversarial_Dynamics:\n  Degree Centrality: 0.000\n  Betweenness Centrality: 0.000\nStakes_Of_Error:\n  Degree Centrality: 0.000\n  Betweenness Centrality: 0.000\n\nEnhanced data saved to 'enhanced_extracted_data.csv'\n\n\n\n\nF.9.2 3.4 Download and save finished data frame as .csv file\n\n\nCode\n# @title 3.4 --- Save Extracted Data for Further Processing ---\n\n\"\"\"\nBLOCK PURPOSE: Saves the extracted data to a CSV file for further processing.\n\nThis step is essential for:\n1. Persisting the structured representation of the Bayesian network\n2. Enabling further analysis in other tools or notebook sections\n3. Creating a permanent record of the extraction results\n4. Making the data available for the visualization pipeline\n\nThe CSV format provides a standardized, tabular representation of the network\nthat can be easily loaded and processed in subsequent analysis steps.\n\nDEPENDENCIES: pandas DataFrame operations\nINPUTS: Extracted DataFrame from the parsing step\nOUTPUTS: CSV file containing the structured network data\n\"\"\"\n\n# Save the extracted data as a CSV file\nresult_df.to_csv('extracted_data.csv', index=False)\n\nprint(\"✅ Extracted data saved successfully to 'extracted_data.csv'\")\nprint(\"Note: If using updated data in future steps, the file must be pushed to the GitHub repository\")\n\n\n✅ Extracted data saved successfully to 'extracted_data.csv'\nNote: If using updated data in future steps, the file must be pushed to the GitHub repository",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#bayesian-network-visualization-approach",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#bayesian-network-visualization-approach",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "G.1 Bayesian Network Visualization Approach",
    "text": "G.1 Bayesian Network Visualization Approach\nThis section implements the visualization component of the AMTAIR project, transforming the structured data extracted from BayesDown into an interactive network visualization that makes complex probabilistic relationships accessible to human understanding.\n\nG.1.1 Visualization Philosophy\nA key challenge in AI governance is making complex probabilistic relationships understandable to diverse stakeholders. This visualization system addresses this challenge through:\n\nVisual Encoding of Probability: Node colors reflect probability values (green for high probability, red for low)\nStructural Classification: Border colors indicate node types (blue for root causes, purple for intermediate nodes, magenta for leaf nodes)\nProgressive Disclosure: Basic information in tooltips, detailed probability tables in modal popups\nInteractive Exploration: Draggable nodes, configurable physics, click interactions\n\n\n\nG.1.2 Connection to AMTAIR Goals\nThis visualization approach directly supports the AMTAIR project’s goal of improving coordination in AI governance by:\n\nMaking implicit models explicit through visual representation\nProviding a common language for discussing probabilistic relationships\nEnabling non-technical stakeholders to engage with formal models\nCreating shareable artifacts that facilitate collaboration\n\n\n\nG.1.3 Implementation Structure\nThe visualization system is implemented in four phases:\n\nNetwork Construction: Creating a directed graph representation using NetworkX\nNode Classification: Identifying node types based on network position\nVisual Enhancement: Adding color coding, tooltips, and interactive elements\nInteractive Features: Implementing click handling for detailed exploration\n\nThe resulting visualization serves as both an analytical tool for experts and a communication tool for broader audiences, bridging the gap between technical and policy domains in AI governance discussions.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#phase-1-dependenciesfunctions",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#phase-1-dependenciesfunctions",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "G.2 Phase 1: Dependencies/Functions",
    "text": "G.2 Phase 1: Dependencies/Functions\n\n\nCode\n# @title 4.0 --- Bayesian Network Visualization Functions ---\n\n\"\"\"\nBLOCK PURPOSE: Provides functions to create interactive Bayesian network visualizations\nfrom DataFrame representations of ArgDown/BayesDown data.\n\nThis block implements the visualization pipeline described in the AMTAIR project, transforming\nthe structured DataFrame extracted from ArgDown/BayesDown into an interactive network graph\nthat displays nodes, relationships, and probability information. The visualization leverages\nNetworkX for graph representation and PyVis for interactive display.\n\nKey visualization features:\n1. Color-coding of nodes based on probability values\n2. Border styling to indicate node types (root, intermediate, leaf)\n3. Interactive tooltips with probability information\n4. Modal popups with detailed conditional probability tables\n5. Physics-based layout for intuitive exploration\n\nDEPENDENCIES: networkx, pyvis, HTML display from IPython\nINPUTS: DataFrame with node information, relationships, and probabilities\nOUTPUTS: Interactive HTML visualization of the Bayesian network\n\"\"\"\n\nfrom pyvis.network import Network\nimport networkx as nx\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport io\nimport base64\nimport colorsys\nimport json\n\ndef create_bayesian_network_with_probabilities(df):\n    \"\"\"\n    Create an interactive Bayesian network visualization with enhanced probability visualization\n    and node classification based on network structure.\n\n    Args:\n        df (pandas.DataFrame): DataFrame containing node information, relationships, and probabilities\n\n    Returns:\n        IPython.display.HTML: Interactive HTML visualization of the Bayesian network\n    \"\"\"\n    # PHASE 1: Create a directed graph representation\n    G = nx.DiGraph()\n\n    # Add nodes with proper attributes\n    for idx, row in df.iterrows():\n        title = row['Title']\n        description = row['Description']\n\n        # Process probability information\n        priors = get_priors(row)\n        instantiations = get_instantiations(row)\n\n        # Add node with base information\n        G.add_node(\n            title,\n            description=description,\n            priors=priors,\n            instantiations=instantiations,\n            posteriors=get_posteriors(row)\n        )\n\n    # Add edges based on parent-child relationships\n    for idx, row in df.iterrows():\n        child = row['Title']\n        parents = get_parents(row)\n\n        # Add edges from each parent to this child\n        for parent in parents:\n            if parent in G.nodes():\n                G.add_edge(parent, child)\n\n    # PHASE 2: Classify nodes based on network structure\n    classify_nodes(G)\n\n    # PHASE 3: Create interactive network visualization\n    net = Network(notebook=True, directed=True, cdn_resources=\"in_line\", height=\"600px\", width=\"100%\")\n\n    # Configure physics for better layout\n    net.force_atlas_2based(gravity=-50, spring_length=100, spring_strength=0.02)\n    net.show_buttons(filter_=['physics'])  # Allow user to adjust physics settings\n\n    # Add the graph to the network\n    net.from_nx(G)\n\n    # PHASE 4: Enhance node appearance with probability information\n    for node in net.nodes:\n        node_id = node['id']\n        node_data = G.nodes[node_id]\n\n        # Get node type and set border color\n        node_type = node_data.get('node_type', 'unknown')\n        border_color = get_border_color(node_type)\n\n        # Get probability information\n        priors = node_data.get('priors', {})\n        true_prob = priors.get('true_prob', 0.5) if priors else 0.5\n\n        # Get proper state names\n        instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n        true_state = instantiations[0] if len(instantiations) &gt; 0 else \"TRUE\"\n        false_state = instantiations[1] if len(instantiations) &gt; 1 else \"FALSE\"\n\n        # Create background color based on probability\n        background_color = get_probability_color(priors)\n\n        # Create tooltip with probability information\n        tooltip = create_tooltip(node_id, node_data)\n\n        # Create a simpler node label with probability\n        simple_label = f\"{node_id}\\np={true_prob:.2f}\"\n\n        # Store expanded content as a node attribute for use in click handler\n        node_data['expanded_content'] = create_expanded_content(node_id, node_data)\n\n        # Set node attributes\n        node['title'] = tooltip  # Tooltip HTML\n        node['label'] = simple_label  # Simple text label\n        node['shape'] = 'box'\n        node['color'] = {\n            'background': background_color,\n            'border': border_color,\n            'highlight': {\n                'background': background_color,\n                'border': border_color\n            }\n        }\n\n    # PHASE 5: Setup interactive click handling\n    # Prepare data for click handler\n    setup_data = {\n        'nodes_data': {node_id: {\n            'expanded_content': json.dumps(G.nodes[node_id].get('expanded_content', '')),\n            'description': G.nodes[node_id].get('description', ''),\n            'priors': G.nodes[node_id].get('priors', {}),\n            'posteriors': G.nodes[node_id].get('posteriors', {})\n        } for node_id in G.nodes()}\n    }\n\n    # JavaScript code for handling node clicks\n    click_js = \"\"\"\n    // Store node data for click handling\n    var nodesData = %s;\n\n    // Add event listener for node clicks\n    network.on(\"click\", function(params) {\n        if (params.nodes.length &gt; 0) {\n            var nodeId = params.nodes[0];\n            var nodeInfo = nodesData[nodeId];\n\n            if (nodeInfo) {\n                // Create a modal popup for expanded content\n                var modal = document.createElement('div');\n                modal.style.position = 'fixed';\n                modal.style.left = '50%%';\n                modal.style.top = '50%%';\n                modal.style.transform = 'translate(-50%%, -50%%)';\n                modal.style.backgroundColor = 'white';\n                modal.style.padding = '20px';\n                modal.style.borderRadius = '5px';\n                modal.style.boxShadow = '0 0 10px rgba(0,0,0,0.5)';\n                modal.style.zIndex = '1000';\n                modal.style.maxWidth = '80%%';\n                modal.style.maxHeight = '80%%';\n                modal.style.overflow = 'auto';\n\n                // Add expanded content\n                modal.innerHTML = nodeInfo.expanded_content || 'No detailed information available';\n\n                // Add close button\n                var closeBtn = document.createElement('button');\n                closeBtn.innerHTML = 'Close';\n                closeBtn.style.marginTop = '10px';\n                closeBtn.style.padding = '5px 10px';\n                closeBtn.style.cursor = 'pointer';\n                closeBtn.onclick = function() {\n                    document.body.removeChild(modal);\n                };\n                modal.appendChild(closeBtn);\n\n                // Add modal to body\n                document.body.appendChild(modal);\n            }\n        }\n    });\n    \"\"\" % json.dumps(setup_data['nodes_data'])\n\n    # PHASE 6: Save the graph to HTML and inject custom click handling\n    html_file = \"bayesian_network.html\"\n    net.save_graph(html_file)\n\n    # Inject custom click handling into HTML\n    try:\n        with open(html_file, \"r\") as f:\n            html_content = f.read()\n\n        # Insert click handling script before the closing body tag\n        html_content = html_content.replace('&lt;/body&gt;', f'&lt;script&gt;{click_js}&lt;/script&gt;&lt;/body&gt;')\n\n        # Write back the modified HTML\n        with open(html_file, \"w\") as f:\n            f.write(html_content)\n\n        return HTML(html_content)\n    except Exception as e:\n        return HTML(f\"&lt;p&gt;Error rendering HTML: {str(e)}&lt;/p&gt;&lt;p&gt;The network visualization has been saved to '{html_file}'&lt;/p&gt;\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#phase-2-node-classification-and-styling-module",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#phase-2-node-classification-and-styling-module",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "G.3 Phase 2: Node Classification and Styling Module",
    "text": "G.3 Phase 2: Node Classification and Styling Module\n\n\nCode\n# @title 4.1 --- Node Classification and Styling Functions ---\n\n\"\"\"\nBLOCK PURPOSE: Implements the visual classification and styling of nodes in the Bayesian network.\n\nThis module handles the identification of node types based on their position in the network\nand provides appropriate visual styling for each type. The functions:\n\n1. Classify nodes as parents (causes), children (intermediate effects), or leaves (final effects)\n2. Assign appropriate border colors to visually distinguish node types\n3. Calculate background colors based on probability values\n4. Extract relevant information from DataFrame rows in a robust manner\n\nThe visual encoding helps users understand both the structure of the network\nand the probability distributions at a glance.\n\nDEPENDENCIES: colorsys for color manipulation\nINPUTS: Graph structure and node data\nOUTPUTS: Classification and styling information for visualization\n\"\"\"\n\ndef classify_nodes(G):\n    \"\"\"\n    Classify nodes as parent, child, or leaf based on network structure\n\n    Args:\n        G (networkx.DiGraph): Directed graph representation of the Bayesian network\n\n    Effects:\n        Adds 'node_type' attribute to each node in the graph:\n        - 'parent': Root node with no parents but has children (causal source)\n        - 'child': Node with both parents and children (intermediate)\n        - 'leaf': Node with parents but no children (final effect)\n        - 'isolated': Node with no connections (rare in Bayesian networks)\n    \"\"\"\n    for node in G.nodes():\n        predecessors = list(G.predecessors(node))  # Nodes pointing to this one (causes)\n        successors = list(G.successors(node))      # Nodes this one points to (effects)\n\n        if not predecessors:  # No parents\n            if successors:  # Has children\n                G.nodes[node]['node_type'] = 'parent'  # Root cause\n            else:  # No children either\n                G.nodes[node]['node_type'] = 'isolated'  # Disconnected node\n        else:  # Has parents\n            if not successors:  # No children\n                G.nodes[node]['node_type'] = 'leaf'  # Final effect\n            else:  # Has both parents and children\n                G.nodes[node]['node_type'] = 'child'  # Intermediate node\n\ndef get_border_color(node_type):\n    \"\"\"\n    Return border color based on node type\n\n    Args:\n        node_type (str): Type of node ('parent', 'child', 'leaf', or 'isolated')\n\n    Returns:\n        str: Hex color code for node border\n    \"\"\"\n    if node_type == 'parent':\n        return '#0000FF'  # Blue for root causes\n    elif node_type == 'child':\n        return '#800080'  # Purple for intermediate nodes\n    elif node_type == 'leaf':\n        return '#FF00FF'  # Magenta for final effects\n    else:\n        return '#000000'  # Default black for any other type\n\ndef get_probability_color(priors):\n    \"\"\"\n    Create background color based on probability (red to green gradient)\n\n    Args:\n        priors (dict): Dictionary containing probability information\n\n    Returns:\n        str: Hex color code for node background, ranging from red (low probability)\n             to green (high probability)\n    \"\"\"\n    # Default to neutral color if no probability\n    if not priors or 'true_prob' not in priors:\n        return '#F8F8F8'  # Light grey\n\n    # Get probability value\n    prob = priors['true_prob']\n\n    # Create color gradient from red (0.0) to green (1.0)\n    hue = 120 * prob  # 0 = red, 120 = green (in HSL color space)\n    saturation = 0.75\n    lightness = 0.8  # Lighter color for better text visibility\n\n    # Convert HSL to RGB\n    r, g, b = colorsys.hls_to_rgb(hue/360, lightness, saturation)\n\n    # Convert to hex format\n    hex_color = \"#{:02x}{:02x}{:02x}\".format(int(r*255), int(g*255), int(b*255))\n\n    return hex_color\n\ndef get_parents(row):\n    \"\"\"\n    Extract parent nodes from row data, with safe handling for different data types\n\n    Args:\n        row (pandas.Series): Row from DataFrame containing node information\n\n    Returns:\n        list: List of parent node names\n    \"\"\"\n    if 'Parents' not in row:\n        return []\n\n    parents_data = row['Parents']\n\n    # Handle NaN, None, or empty list\n    if isinstance(parents_data, float) and pd.isna(parents_data):\n        return []\n\n    if parents_data is None:\n        return []\n\n    # Handle different data types\n    if isinstance(parents_data, list):\n        # Return a list with NaN and empty strings removed\n        return [p for p in parents_data if not (isinstance(p, float) and pd.isna(p)) and p != '']\n\n    if isinstance(parents_data, str):\n        if not parents_data.strip():\n            return []\n\n        # Remove brackets and split by comma, removing empty strings and NaN\n        cleaned = parents_data.strip('[]\"\\'')\n        if not cleaned:\n            return []\n\n        return [p.strip(' \"\\'') for p in cleaned.split(',') if p.strip()]\n\n    # Default: empty list\n    return []\n\ndef get_instantiations(row):\n    \"\"\"\n    Extract instantiations with safe handling for different data types\n\n    Args:\n        row (pandas.Series): Row from DataFrame containing node information\n\n    Returns:\n        list: List of possible instantiations (states) for the node\n    \"\"\"\n    if 'instantiations' not in row:\n        return [\"TRUE\", \"FALSE\"]\n\n    inst_data = row['instantiations']\n\n    # Handle NaN or None\n    if isinstance(inst_data, float) and pd.isna(inst_data):\n        return [\"TRUE\", \"FALSE\"]\n\n    if inst_data is None:\n        return [\"TRUE\", \"FALSE\"]\n\n    # Handle different data types\n    if isinstance(inst_data, list):\n        return inst_data if inst_data else [\"TRUE\", \"FALSE\"]\n\n    if isinstance(inst_data, str):\n        if not inst_data.strip():\n            return [\"TRUE\", \"FALSE\"]\n\n        # Remove brackets and split by comma\n        cleaned = inst_data.strip('[]\"\\'')\n        if not cleaned:\n            return [\"TRUE\", \"FALSE\"]\n\n        return [i.strip(' \"\\'') for i in cleaned.split(',') if i.strip()]\n\n    # Default\n    return [\"TRUE\", \"FALSE\"]\n\ndef get_priors(row):\n    \"\"\"\n    Extract prior probabilities with safe handling for different data types\n\n    Args:\n        row (pandas.Series): Row from DataFrame containing node information\n\n    Returns:\n        dict: Dictionary of prior probabilities with 'true_prob' added for convenience\n    \"\"\"\n    if 'priors' not in row:\n        return {}\n\n    priors_data = row['priors']\n\n    # Handle NaN or None\n    if isinstance(priors_data, float) and pd.isna(priors_data):\n        return {}\n\n    if priors_data is None:\n        return {}\n\n    result = {}\n\n    # Handle dictionary\n    if isinstance(priors_data, dict):\n        result = priors_data\n    # Handle string representation of dictionary\n    elif isinstance(priors_data, str):\n        if not priors_data.strip() or priors_data == '{}':\n            return {}\n\n        try:\n            # Try to evaluate as Python literal\n            import ast\n            result = ast.literal_eval(priors_data)\n        except:\n            # Simple parsing for items like {'p(TRUE)': '0.2', 'p(FALSE)': '0.8'}\n            if '{' in priors_data and '}' in priors_data:\n                content = priors_data[priors_data.find('{')+1:priors_data.rfind('}')]\n                items = [item.strip() for item in content.split(',')]\n\n                for item in items:\n                    if ':' in item:\n                        key, value = item.split(':', 1)\n                        key = key.strip(' \\'\\\"')\n                        value = value.strip(' \\'\\\"')\n                        result[key] = value\n\n    # Extract main probability for TRUE state\n    instantiations = get_instantiations(row)\n    true_state = instantiations[0] if instantiations else \"TRUE\"\n    true_key = f\"p({true_state})\"\n\n    if true_key in result:\n        try:\n            result['true_prob'] = float(result[true_key])\n        except:\n            pass\n\n    return result\n\ndef get_posteriors(row):\n    \"\"\"\n    Extract posterior probabilities with safe handling for different data types\n\n    Args:\n        row (pandas.Series): Row from DataFrame containing node information\n\n    Returns:\n        dict: Dictionary of conditional probabilities\n    \"\"\"\n    if 'posteriors' not in row:\n        return {}\n\n    posteriors_data = row['posteriors']\n\n    # Handle NaN or None\n    if isinstance(posteriors_data, float) and pd.isna(posteriors_data):\n        return {}\n\n    if posteriors_data is None:\n        return {}\n\n    result = {}\n\n    # Handle dictionary\n    if isinstance(posteriors_data, dict):\n        result = posteriors_data\n    # Handle string representation of dictionary\n    elif isinstance(posteriors_data, str):\n        if not posteriors_data.strip() or posteriors_data == '{}':\n            return {}\n\n        try:\n            # Try to evaluate as Python literal\n            import ast\n            result = ast.literal_eval(posteriors_data)\n        except:\n            # Simple parsing\n            if '{' in posteriors_data and '}' in posteriors_data:\n                content = posteriors_data[posteriors_data.find('{')+1:posteriors_data.rfind('}')]\n                items = [item.strip() for item in content.split(',')]\n\n                for item in items:\n                    if ':' in item:\n                        key, value = item.split(':', 1)\n                        key = key.strip(' \\'\\\"')\n                        value = value.strip(' \\'\\\"')\n                        result[key] = value\n\n    return result",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#phase-3-html-content-generation-module",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#phase-3-html-content-generation-module",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "G.4 Phase 3: HTML Content Generation Module",
    "text": "G.4 Phase 3: HTML Content Generation Module\n\n\nCode\n# @title 4.2 --- HTML Content Generation Functions ---\n\n\"\"\"\nBLOCK PURPOSE: Creates rich HTML content for the interactive Bayesian network visualization.\n\nThis module generates the HTML components that enhance the Bayesian network visualization:\n1. Probability bars - Visual representation of probability distributions\n2. Node tooltips - Rich information displayed on hover\n3. Expanded content - Detailed probability information shown when clicking nodes\n\nThese HTML components make the mathematical concepts of Bayesian networks more\nintuitive and accessible to users without requiring deep statistical knowledge.\nThe visual encoding of probabilities (colors, bars) and the progressive disclosure\nof information (hover, click) help users build understanding at their own pace.\n\nDEPENDENCIES: HTML generation capabilities\nINPUTS: Node data from the Bayesian network\nOUTPUTS: HTML content for visualization components\n\"\"\"\n\ndef create_probability_bar(true_prob, false_prob, height=\"15px\", show_values=True, value_prefix=\"\"):\n    \"\"\"\n    Creates a reusable HTML component to visualize probability distribution\n\n    Args:\n        true_prob (float): Probability of the true state (0.0-1.0)\n        false_prob (float): Probability of the false state (0.0-1.0)\n        height (str): CSS height of the bar\n        show_values (bool): Whether to display numerical values\n        value_prefix (str): Prefix to add before values (e.g., \"p=\")\n\n    Returns:\n        str: HTML for a horizontal bar showing probabilities\n    \"\"\"\n    # Prepare display labels if showing values\n    true_label = f\"{value_prefix}{true_prob:.3f}\" if show_values else \"\"\n    false_label = f\"{value_prefix}{false_prob:.3f}\" if show_values else \"\"\n\n    # Create the HTML for a horizontal stacked bar\n    html = f\"\"\"\n    &lt;div style=\"width:100%; height:{height}; display:flex; border:1px solid #ccc; overflow:hidden; border-radius:3px; margin-top:3px; margin-bottom:3px;\"&gt;\n        &lt;div style=\"flex-basis:{true_prob*100}%; background:linear-gradient(to bottom, rgba(0,180,0,0.9), rgba(0,140,0,0.7)); border-right:2px solid #008800; display:flex; align-items:center; justify-content:center; overflow:hidden; min-width:{2 if true_prob &gt; 0 else 0}px;\"&gt;\n            &lt;span style=\"font-size:10px; color:white; text-shadow:0px 0px 2px #000;\"&gt;{true_label}&lt;/span&gt;\n        &lt;/div&gt;\n        &lt;div style=\"flex-basis:{false_prob*100}%; background:linear-gradient(to bottom, rgba(220,0,0,0.9), rgba(180,0,0,0.7)); border-left:2px solid #880000; display:flex; align-items:center; justify-content:center; overflow:hidden; min-width:{2 if false_prob &gt; 0 else 0}px;\"&gt;\n            &lt;span style=\"font-size:10px; color:white; text-shadow:0px 0px 2px #000;\"&gt;{false_label}&lt;/span&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n    \"\"\"\n    return html\n\ndef create_tooltip(node_id, node_data):\n    \"\"\"\n    Create rich HTML tooltip with probability information\n\n    Args:\n        node_id (str): Identifier of the node\n        node_data (dict): Node attributes including probabilities\n\n    Returns:\n        str: HTML content for tooltip displayed on hover\n    \"\"\"\n    # Extract node information\n    description = node_data.get('description', '')\n    priors = node_data.get('priors', {})\n    instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n\n    # Start building the HTML tooltip\n    html = f\"\"\"\n    &lt;div style=\"max-width:350px; padding:10px; background-color:#f8f9fa; border-radius:5px; font-family:Arial, sans-serif;\"&gt;\n        &lt;h3 style=\"margin-top:0; color:#202124;\"&gt;{node_id}&lt;/h3&gt;\n        &lt;p style=\"font-style:italic;\"&gt;{description}&lt;/p&gt;\n    \"\"\"\n\n    # Add prior probabilities section\n    if priors and 'true_prob' in priors:\n        true_prob = priors['true_prob']\n        false_prob = 1.0 - true_prob\n\n        # Get proper state names\n        true_state = instantiations[0] if len(instantiations) &gt; 0 else \"TRUE\"\n        false_state = instantiations[1] if len(instantiations) &gt; 1 else \"FALSE\"\n\n        html += f\"\"\"\n        &lt;div style=\"margin-top:10px; background-color:#fff; padding:8px; border-radius:4px; border:1px solid #ddd;\"&gt;\n            &lt;h4 style=\"margin-top:0; font-size:14px;\"&gt;Prior Probabilities:&lt;/h4&gt;\n            &lt;div style=\"display:flex; justify-content:space-between; margin-bottom:4px;\"&gt;\n                &lt;div style=\"font-size:12px;\"&gt;{true_state}: {true_prob:.3f}&lt;/div&gt;\n                &lt;div style=\"font-size:12px;\"&gt;{false_state}: {false_prob:.3f}&lt;/div&gt;\n            &lt;/div&gt;\n            {create_probability_bar(true_prob, false_prob, \"20px\", True)}\n        &lt;/div&gt;\n        \"\"\"\n\n    # Add click instruction\n    html += \"\"\"\n    &lt;div style=\"margin-top:8px; font-size:12px; color:#666; text-align:center;\"&gt;\n        Click node to see full probability details\n    &lt;/div&gt;\n    &lt;/div&gt;\n    \"\"\"\n\n    return html\n\ndef create_expanded_content(node_id, node_data):\n    \"\"\"\n    Create expanded content shown when a node is clicked\n\n    Args:\n        node_id (str): Identifier of the node\n        node_data (dict): Node attributes including probabilities\n\n    Returns:\n        str: HTML content for detailed view displayed on click\n    \"\"\"\n    # Extract node information\n    description = node_data.get('description', '')\n    priors = node_data.get('priors', {})\n    posteriors = node_data.get('posteriors', {})\n    instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n\n    # Get proper state names\n    true_state = instantiations[0] if len(instantiations) &gt; 0 else \"TRUE\"\n    false_state = instantiations[1] if len(instantiations) &gt; 1 else \"FALSE\"\n\n    # Extract probabilities\n    true_prob = priors.get('true_prob', 0.5)\n    false_prob = 1.0 - true_prob\n\n    # Start building the expanded content\n    html = f\"\"\"\n    &lt;div style=\"max-width:500px; padding:15px; font-family:Arial, sans-serif;\"&gt;\n        &lt;h2 style=\"margin-top:0; color:#333;\"&gt;{node_id}&lt;/h2&gt;\n        &lt;p style=\"font-style:italic; margin-bottom:15px;\"&gt;{description}&lt;/p&gt;\n\n        &lt;div style=\"margin-bottom:20px; padding:12px; border:1px solid #ddd; background-color:#f9f9f9; border-radius:5px;\"&gt;\n            &lt;h3 style=\"margin-top:0; color:#333;\"&gt;Prior Probabilities&lt;/h3&gt;\n            &lt;div style=\"display:flex; justify-content:space-between; margin-bottom:5px;\"&gt;\n                &lt;div&gt;&lt;strong&gt;{true_state}:&lt;/strong&gt; {true_prob:.3f}&lt;/div&gt;\n                &lt;div&gt;&lt;strong&gt;{false_state}:&lt;/strong&gt; {false_prob:.3f}&lt;/div&gt;\n            &lt;/div&gt;\n            {create_probability_bar(true_prob, false_prob, \"25px\", True)}\n        &lt;/div&gt;\n    \"\"\"\n\n    # Add conditional probability table if available\n    if posteriors:\n        html += \"\"\"\n        &lt;div style=\"padding:12px; border:1px solid #ddd; background-color:#f9f9f9; border-radius:5px;\"&gt;\n            &lt;h3 style=\"margin-top:0; color:#333;\"&gt;Conditional Probabilities&lt;/h3&gt;\n            &lt;table style=\"width:100%; border-collapse:collapse; font-size:13px;\"&gt;\n                &lt;tr style=\"background-color:#eee;\"&gt;\n                    &lt;th style=\"padding:8px; text-align:left; border:1px solid #ddd;\"&gt;Condition&lt;/th&gt;\n                    &lt;th style=\"padding:8px; text-align:center; border:1px solid #ddd; width:80px;\"&gt;Value&lt;/th&gt;\n                    &lt;th style=\"padding:8px; text-align:center; border:1px solid #ddd;\"&gt;Visualization&lt;/th&gt;\n                &lt;/tr&gt;\n        \"\"\"\n\n        # Sort posteriors to group by similar conditions\n        posterior_items = list(posteriors.items())\n        posterior_items.sort(key=lambda x: x[0])\n\n        # Add rows for conditional probabilities\n        for key, value in posterior_items:\n            try:\n                # Try to parse probability value\n                prob_value = float(value)\n                inv_prob = 1.0 - prob_value\n\n                # Add row with probability visualization\n                html += f\"\"\"\n                &lt;tr&gt;\n                    &lt;td style=\"padding:8px; border:1px solid #ddd;\"&gt;{key}&lt;/td&gt;\n                    &lt;td style=\"padding:8px; text-align:center; border:1px solid #ddd;\"&gt;{prob_value:.3f}&lt;/td&gt;\n                    &lt;td style=\"padding:8px; border:1px solid #ddd;\"&gt;\n                        {create_probability_bar(prob_value, inv_prob, \"20px\", False)}\n                    &lt;/td&gt;\n                &lt;/tr&gt;\n                \"\"\"\n            except:\n                # Fallback for non-numeric values\n                html += f\"\"\"\n                &lt;tr&gt;\n                    &lt;td style=\"padding:8px; border:1px solid #ddd;\"&gt;{key}&lt;/td&gt;\n                    &lt;td style=\"padding:8px; text-align:center; border:1px solid #ddd;\" colspan=\"2\"&gt;{value}&lt;/td&gt;\n                &lt;/tr&gt;\n                \"\"\"\n\n        html += \"\"\"\n            &lt;/table&gt;\n        &lt;/div&gt;\n        \"\"\"\n\n    html += \"&lt;/div&gt;\"\n\n    return html",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#phase-4-main-visualization-function",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#phase-4-main-visualization-function",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "G.5 Phase 4: Main Visualization Function",
    "text": "G.5 Phase 4: Main Visualization Function\n\n\nCode\ndef create_bayesian_network_with_probabilities(df):\n    \"\"\"\n    Create an interactive Bayesian network visualization with enhanced probability visualization\n    and node classification based on network structure.\n    \"\"\"\n    # Create a directed graph\n    G = nx.DiGraph()\n\n    # Add nodes with proper attributes\n    for idx, row in df.iterrows():\n        title = row['Title']\n        description = row['Description']\n\n        # Process probability information\n        priors = get_priors(row)\n        instantiations = get_instantiations(row)\n\n        # Add node with base information\n        G.add_node(\n            title,\n            description=description,\n            priors=priors,\n            instantiations=instantiations,\n            posteriors=get_posteriors(row)\n        )\n\n    # Add edges\n    for idx, row in df.iterrows():\n        child = row['Title']\n        parents = get_parents(row)\n\n        # Add edges from each parent to this child\n        for parent in parents:\n            if parent in G.nodes():\n                G.add_edge(parent, child)\n\n    # Classify nodes based on network structure\n    classify_nodes(G)\n\n    # Create network visualization\n    net = Network(notebook=True, directed=True, cdn_resources=\"in_line\", height=\"600px\", width=\"100%\")\n\n    # Configure physics for better layout\n    net.force_atlas_2based(gravity=-50, spring_length=100, spring_strength=0.02)\n    net.show_buttons(filter_=['physics'])\n\n    # Add the graph to the network\n    net.from_nx(G)\n\n    # Enhance node appearance with probability information and classification\n    for node in net.nodes:\n        node_id = node['id']\n        node_data = G.nodes[node_id]\n\n        # Get node type and set border color\n        node_type = node_data.get('node_type', 'unknown')\n        border_color = get_border_color(node_type)\n\n        # Get probability information\n        priors = node_data.get('priors', {})\n        true_prob = priors.get('true_prob', 0.5) if priors else 0.5\n\n        # Get proper state names\n        instantiations = node_data.get('instantiations', [\"TRUE\", \"FALSE\"])\n        true_state = instantiations[0] if len(instantiations) &gt; 0 else \"TRUE\"\n        false_state = instantiations[1] if len(instantiations) &gt; 1 else \"FALSE\"\n\n        # Create background color based on probability\n        background_color = get_probability_color(priors)\n\n        # Create tooltip with probability information\n        tooltip = create_tooltip(node_id, node_data)\n\n        # Create a simpler node label with probability\n        simple_label = f\"{node_id}\\np={true_prob:.2f}\"\n\n        # Store expanded content as a node attribute for use in click handler\n        node_data['expanded_content'] = create_expanded_content(node_id, node_data)\n\n        # Set node attributes\n        node['title'] = tooltip  # Tooltip HTML\n        node['label'] = simple_label  # Simple text label\n        node['shape'] = 'box'\n        node['color'] = {\n            'background': background_color,\n            'border': border_color,\n            'highlight': {\n                'background': background_color,\n                'border': border_color\n            }\n        }\n\n    # Set up the click handler with proper data\n    setup_data = {\n        'nodes_data': {node_id: {\n            'expanded_content': json.dumps(G.nodes[node_id].get('expanded_content', '')),\n            'description': G.nodes[node_id].get('description', ''),\n            'priors': G.nodes[node_id].get('priors', {}),\n            'posteriors': G.nodes[node_id].get('posteriors', {})\n        } for node_id in G.nodes()}\n    }\n\n    # Add custom click handling JavaScript\n    click_js = \"\"\"\n    // Store node data for click handling\n    var nodesData = %s;\n\n    // Add event listener for node clicks\n    network.on(\"click\", function(params) {\n        if (params.nodes.length &gt; 0) {\n            var nodeId = params.nodes[0];\n            var nodeInfo = nodesData[nodeId];\n\n            if (nodeInfo) {\n                // Create a modal popup for expanded content\n                var modal = document.createElement('div');\n                modal.style.position = 'fixed';\n                modal.style.left = '50%%';\n                modal.style.top = '50%%';\n                modal.style.transform = 'translate(-50%%, -50%%)';\n                modal.style.backgroundColor = 'white';\n                modal.style.padding = '20px';\n                modal.style.borderRadius = '5px';\n                modal.style.boxShadow = '0 0 10px rgba(0,0,0,0.5)';\n                modal.style.zIndex = '1000';\n                modal.style.maxWidth = '80%%';\n                modal.style.maxHeight = '80%%';\n                modal.style.overflow = 'auto';\n\n                // Parse the JSON string back to HTML content\n                try {\n                    var expandedContent = JSON.parse(nodeInfo.expanded_content);\n                    modal.innerHTML = expandedContent;\n                } catch (e) {\n                    modal.innerHTML = 'Error displaying content: ' + e.message;\n                }\n\n                // Add close button\n                var closeBtn = document.createElement('button');\n                closeBtn.innerHTML = 'Close';\n                closeBtn.style.marginTop = '10px';\n                closeBtn.style.padding = '5px 10px';\n                closeBtn.style.cursor = 'pointer';\n                closeBtn.onclick = function() {\n                    document.body.removeChild(modal);\n                };\n                modal.appendChild(closeBtn);\n\n                // Add modal to body\n                document.body.appendChild(modal);\n            }\n        }\n    });\n    \"\"\" % json.dumps(setup_data['nodes_data'])\n\n    # Save the graph to HTML\n    html_file = \"bayesian_network.html\"\n    net.save_graph(html_file)\n\n    # Inject custom click handling into HTML\n    try:\n        with open(html_file, \"r\") as f:\n            html_content = f.read()\n\n        # Insert click handling script before the closing body tag\n        html_content = html_content.replace('&lt;/body&gt;', f'&lt;script&gt;{click_js}&lt;/script&gt;&lt;/body&gt;')\n\n        # Write back the modified HTML\n        with open(html_file, \"w\") as f:\n            f.write(html_content)\n\n        return HTML(html_content)\n    except Exception as e:\n        return HTML(f\"&lt;p&gt;Error rendering HTML: {str(e)}&lt;/p&gt;&lt;p&gt;The network visualization has been saved to '{html_file}'&lt;/p&gt;\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#summary-of-achievements",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#summary-of-achievements",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "I.1 Summary of Achievements",
    "text": "I.1 Summary of Achievements\nThis notebook has successfully demonstrated the core AMTAIR extraction pipeline, transforming structured argument representations into interactive Bayesian network visualizations through the following steps:\n\nEnvironment Setup: Established a reproducible environment with necessary libraries and data access\nArgument Extraction: Processed structured ArgDown representations preserving the hierarchical relationships\nProbability Integration: Enhanced arguments with probability information to create BayesDown\nData Transformation: Converted BayesDown into structured DataFrame representation\nVisualization & Analysis: Created interactive Bayesian network visualizations with probability encoding\n\nThe rain-sprinkler-lawn example, though simple, demonstrates all the key components of the extraction pipeline that can be applied to more complex AI safety arguments.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#limitations-and-future-work",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#limitations-and-future-work",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "I.2 Limitations and Future Work",
    "text": "I.2 Limitations and Future Work\nWhile this prototype successfully demonstrates the core pipeline, several limitations and opportunities for future work remain:\n\nLLM Extraction: The current implementation focuses on processing pre-formatted ArgDown rather than performing extraction directly from unstructured text. Future work will integrate LLM-powered extraction.\nScalability: The system has been tested on small examples; scaling to larger, more complex arguments will require additional optimization and handling of computational complexity.\nPolicy Evaluation: The current implementation focuses on representation and visualization; future work will add policy evaluation capabilities by implementing intervention modeling.\nPrediction Market Integration: Future versions will integrate with forecasting platforms to incorporate live data into the models.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#connection-to-amtair-project",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#connection-to-amtair-project",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "I.3 Connection to AMTAIR Project",
    "text": "I.3 Connection to AMTAIR Project\nThis prototype represents just one component of the broader AMTAIR project described in the project documentation (see PY_AMTAIRDescription and PY_AMTAIR_SoftwareToolsNMilestones). The full project includes:\n\nAI Risk Pathway Analyzer (ARPA): The core extraction and visualization system demonstrated in this notebook\nWorldview Comparator: Tools for comparing different perspectives on AI risk\nPolicy Impact Evaluator: Systems for evaluating intervention effects across scenarios\nStrategic Intervention Generator: Tools for identifying robust governance strategies\n\nTogether, these components aim to address the coordination crisis in AI governance by providing computational tools that make implicit models explicit, identify cruxes of disagreement, and evaluate policy impacts across diverse worldviews.\nBy transforming unstructured text into formal, analyzable representations, the AMTAIR project helps bridge the gaps between technical researchers, policy specialists, and other stakeholders, enabling more effective coordination in addressing existential risks from advanced AI.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  },
  {
    "objectID": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#convert-.ipynb-notebook-to-markdown",
    "href": "AMTAIR_Prototype/data/example_carlsmith/AMTAIR_Prototype_example_carlsmith.html#convert-.ipynb-notebook-to-markdown",
    "title": "Appendix B — ``` {.python .cell-code}",
    "section": "K.1 Convert .ipynb Notebook to MarkDown",
    "text": "K.1 Convert .ipynb Notebook to MarkDown\n\n\nCode\n# @title --- Convert .ipynb Notebook to MarkDown ---\n\nimport nbformat\nfrom nbconvert import MarkdownExporter\nimport os\n\n# repo_url = \"https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_1/\"\nnotebook_name = \"AMTAIR_Prototype_example_carlsmith\"  #Change Notebook name and path when working on different examples\n\n# Download the notebook file\n!wget {repo_url}{notebook_name}.ipynb -O {notebook_name}.ipynb  # Corrected line\n\n# Load the notebook\n# add error handling for file not found\ntry:\n  with open(f\"{notebook_name}.ipynb\") as f:\n    nb = nbformat.read(f, as_version=4)\nexcept FileNotFoundError:\n  print(f\"Error: File '{notebook_name}.ipynb' not found. Please check if it was downloaded correctly.\")\n\n\n# Initialize the Markdown exporter\nexporter = MarkdownExporter(exclude_output=True)  # Correct initialization\n\n# Convert the notebook to Markdown\n(body, resources) = exporter.from_notebook_node(nb)\n\n# Save the Markdown to a file\nwith open(f\"{notebook_name}IPYNB.md\", \"w\") as f:\n    f.write(body)\n\n\n--2025-04-26 22:33:43--  https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_rain-sprinkler-lawn/AMTAIR_Prototype_example_rain-sprinkler-lawn.ipynb\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1120047 (1.1M) [text/plain]\nSaving to: ‘AMTAIR_Prototype_example_rain-sprinkler-lawn.ipynb’\n\n          AMTAIR_Pr   0%[                    ]       0  --.-KB/s               AMTAIR_Prototype_ex 100%[===================&gt;]   1.07M  --.-KB/s    in 0.06s   \n\n2025-04-26 22:33:43 (18.1 MB/s) - ‘AMTAIR_Prototype_example_rain-sprinkler-lawn.ipynb’ saved [1120047/1120047]\n\n\n\n\n\nCode\n# @title 6.1 --- Convert Notebook to Markdown Documentation ---\n\n\"\"\"\nBLOCK PURPOSE: Converts the notebook to Markdown format for documentation purposes.\n\nMarkdown is a lightweight markup language that is widely used for documentation\nand is easily readable in both plain text and rendered formats. This conversion:\n\n1. Preserves the structure and content of the notebook\n2. Creates a format suitable for inclusion in documentation systems\n3. Excludes code outputs to focus on the process and methodology\n4. Supports version control and collaboration on GitHub\n\nThe resulting Markdown file can be used in project documentation, GitHub wikis,\nor as a standalone reference guide to the AMTAIR extraction pipeline.\n\nDEPENDENCIES: nbformat, nbconvert.MarkdownExporter modules\nINPUTS: Current notebook state\nOUTPUTS: Markdown version of the notebook\n\"\"\"\n\nimport nbformat\nfrom nbconvert import MarkdownExporter\nimport os\n\n# Repository URL variable for file access\n# repo_url = \"https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/\"\nnotebook_name = \"AMTAIR_Prototype_example_carlsmith\"  # Change when working with different examples\n\n# Download the notebook file\n!wget {repo_url}{notebook_name}.ipynb -O {notebook_name}.ipynb\n\n# Load the notebook\ntry:\n  with open(f\"{notebook_name}.ipynb\") as f:\n    nb = nbformat.read(f, as_version=4)\n  print(f\"✅ Successfully loaded notebook: {notebook_name}.ipynb\")\nexcept FileNotFoundError:\n  print(f\"❌ Error: File '{notebook_name}.ipynb' not found. Please check if it was downloaded correctly.\")\n\n\n# Initialize the Markdown exporter\nexporter = MarkdownExporter(exclude_output=True)  # Exclude outputs for cleaner documentation\n\n# Convert the notebook to Markdown\ntry:\n    (body, resources) = exporter.from_notebook_node(nb)\n\n    # Save the Markdown to a file\n    with open(f\"{notebook_name}IPYNB.md\", \"w\") as f:\n        f.write(body)\n    print(f\"✅ Successfully saved Markdown version to: {notebook_name}IPYNB.md\")\nexcept Exception as e:\n    print(f\"❌ Error converting notebook to Markdown: {str(e)}\")\n\n\n--2025-04-26 22:31:45--  https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_rain-sprinkler-lawn/AMTAIR_Prototype_example_rain-sprinkler-lawn.ipynb\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1120047 (1.1M) [text/plain]\nSaving to: ‘AMTAIR_Prototype_example_rain-sprinkler-lawn.ipynb’\n\n          AMTAIR_Pr   0%[                    ]       0  --.-KB/s               AMTAIR_Prototype_ex 100%[===================&gt;]   1.07M  --.-KB/s    in 0.06s   \n\n2025-04-26 22:31:45 (18.0 MB/s) - ‘AMTAIR_Prototype_example_rain-sprinkler-lawn.ipynb’ saved [1120047/1120047]\n\n✅ Successfully loaded notebook: AMTAIR_Prototype_example_rain-sprinkler-lawn.ipynb\n✅ Successfully saved Markdown version to: AMTAIR_Prototype_example_rain-sprinkler-lawnIPYNB.md\n\n\n\n\nCode\nimport nbformat\nfrom nbconvert import PDFExporter\nimport os\nimport subprocess\nimport re\n\ndef escape_latex_special_chars(text):\n  \"\"\"Escapes special LaTeX characters in a string.\"\"\"\n  latex_special_chars = ['&', '%', '#', '_', '{', '}', '~', '^', '\\\\']\n  replacement_patterns = [\n      (char, '\\\\' + char) for char in latex_special_chars\n  ]\n\n  # Escape reserved characters\n  for original, replacement in replacement_patterns:\n    text = text.replace(original, replacement) # This is the fix\n  return text\n\n# Function to check if a command is available\ndef is_command_available(command):\n    try:\n        subprocess.run([command], capture_output=True, check=True)\n        return True\n    except (subprocess.CalledProcessError, FileNotFoundError):\n        return False\n\n# Check if xelatex is installed, and install if necessary\nif not is_command_available(\"xelatex\"):\n    print(\"Installing necessary TeX packages...\")\n    !apt-get install -y texlive-xetex texlive-fonts-recommended texlive-plain-generic\n    print(\"TeX packages installed successfully.\")\nelse:\n    print(\"xelatex is already installed. Skipping installation.\")\n\n# repo_url = \"https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_1/\"\nnotebook_name = \"AMTAIR_Prototype_example_carlsmith\"  #Change Notebook name and path when working on different examples\n\n# Download the notebook file\n!wget {repo_url}{notebook_name}.ipynb -O {notebook_name}.ipynb  # Corrected line\n\n# Load the notebook\n# add error handling for file not found\ntry:\n  with open(f\"{notebook_name}.ipynb\") as f:\n    nb = nbformat.read(f, as_version=4)\nexcept FileNotFoundError:\n  print(f\"Error: File '{notebook_name}.ipynb' not found. Please check if it was downloaded correctly.\")\n\n\n# Initialize the PDF exporter\nexporter = PDFExporter(exclude_output=True)  # Changed to PDFExporter\n\n# Sanitize notebook cell titles to escape special LaTeX characters like '&'\nfor cell in nb.cells:\n    if 'cell_type' in cell and cell['cell_type'] == 'markdown':\n        if 'source' in cell and isinstance(cell['source'], str):\n            # Replace '&' with '\\protect&' in markdown cell titles AND CONTENT\n            # Updated to use escape_latex_special_chars function\n            cell['source'] = escape_latex_special_chars(cell['source'])\n            # Additionally, escape special characters in headings\n            cell['source'] = re.sub(r'(#+)\\s*(.*)', lambda m: m.group(1) + ' ' + escape_latex_special_chars(m.group(2)), cell['source'])\n\n\n\n# Convert the notebook to PDF\n(body, resources) = exporter.from_notebook_node(nb)\n\n\n# Save the PDF to a file\nwith open(f\"{notebook_name}IPYNB.pdf\", \"wb\") as f:  # Changed to 'wb' for binary writing\n    f.write(body)\n\n\nInstalling necessary TeX packages...\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following additional packages will be installed:\n  dvisvgm fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono\n  fonts-texgyre fonts-urw-base35 libapache-pom-java libcommons-logging-java\n  libcommons-parent-java libfontbox-java libgs9 libgs9-common libidn12\n  libijs-0.35 libjbig2dec0 libkpathsea6 libpdfbox-java libptexenc1 libruby3.0\n  libsynctex2 libteckit0 libtexlua53 libtexluajit2 libwoff1 libzzip-0-13\n  lmodern poppler-data preview-latex-style rake ruby ruby-net-telnet\n  ruby-rubygems ruby-webrick ruby-xmlrpc ruby3.0 rubygems-integration t1utils\n  teckit tex-common tex-gyre texlive-base texlive-binaries texlive-latex-base\n  texlive-latex-extra texlive-latex-recommended texlive-pictures tipa\n  xfonts-encodings xfonts-utils\nSuggested packages:\n  fonts-noto fonts-freefont-otf | fonts-freefont-ttf libavalon-framework-java\n  libcommons-logging-java-doc libexcalibur-logkit-java liblog4j1.2-java\n  poppler-utils ghostscript fonts-japanese-mincho | fonts-ipafont-mincho\n  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\n  fonts-arphic-uming fonts-nanum ri ruby-dev bundler debhelper gv\n  | postscript-viewer perl-tk xpdf | pdf-viewer xzdec\n  texlive-fonts-recommended-doc texlive-latex-base-doc python3-pygments\n  icc-profiles libfile-which-perl libspreadsheet-parseexcel-perl\n  texlive-latex-extra-doc texlive-latex-recommended-doc texlive-luatex\n  texlive-pstricks dot2tex prerex texlive-pictures-doc vprerex\n  default-jre-headless tipa-doc\nThe following NEW packages will be installed:\n  dvisvgm fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono\n  fonts-texgyre fonts-urw-base35 libapache-pom-java libcommons-logging-java\n  libcommons-parent-java libfontbox-java libgs9 libgs9-common libidn12\n  libijs-0.35 libjbig2dec0 libkpathsea6 libpdfbox-java libptexenc1 libruby3.0\n  libsynctex2 libteckit0 libtexlua53 libtexluajit2 libwoff1 libzzip-0-13\n  lmodern poppler-data preview-latex-style rake ruby ruby-net-telnet\n  ruby-rubygems ruby-webrick ruby-xmlrpc ruby3.0 rubygems-integration t1utils\n  teckit tex-common tex-gyre texlive-base texlive-binaries\n  texlive-fonts-recommended texlive-latex-base texlive-latex-extra\n  texlive-latex-recommended texlive-pictures texlive-plain-generic\n  texlive-xetex tipa xfonts-encodings xfonts-utils\n0 upgraded, 53 newly installed, 0 to remove and 34 not upgraded.\nNeed to get 182 MB of archives.\nAfter this operation, 571 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1build1 [1,805 kB]\nGet:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-lato all 2.0-2.1 [2,696 kB]\nGet:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2,171 kB]\nGet:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-common all 6.17 [33.7 kB]\nGet:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-urw-base35 all 20200910-1 [6,367 kB]\nGet:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9-common all 9.55.0~dfsg1-0ubuntu5.11 [753 kB]\nGet:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libidn12 amd64 1.38-4ubuntu1 [60.0 kB]\nGet:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libijs-0.35 amd64 0.35-15build2 [16.5 kB]\nGet:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjbig2dec0 amd64 0.19-3build2 [64.7 kB]\nGet:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9 amd64 9.55.0~dfsg1-0ubuntu5.11 [5,031 kB]\nGet:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libkpathsea6 amd64 2021.20210626.59705-1ubuntu0.2 [60.4 kB]\nGet:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwoff1 amd64 1.0.2-1build4 [45.2 kB]\nGet:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dvisvgm amd64 2.13.1-1 [1,221 kB]\nGet:14 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-lmodern all 2.004.5-6.1 [4,532 kB]\nGet:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]\nGet:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-texgyre all 20180621-3.1 [10.2 MB]\nGet:17 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libapache-pom-java all 18-1 [4,720 B]\nGet:18 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-parent-java all 43-1 [10.8 kB]\nGet:19 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-logging-java all 1.2-2 [60.3 kB]\nGet:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libptexenc1 amd64 2021.20210626.59705-1ubuntu0.2 [39.1 kB]\nGet:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 rubygems-integration all 1.18 [5,336 B]\nGet:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby3.0 amd64 3.0.2-7ubuntu2.10 [50.1 kB]\nGet:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-rubygems all 3.3.5-2 [228 kB]\nGet:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby amd64 1:3.0~exp1 [5,100 B]\nGet:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 rake all 13.0.6-2 [61.7 kB]\nGet:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\nGet:27 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-webrick all 1.7.0-3ubuntu0.1 [52.1 kB]\nGet:28 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-xmlrpc all 0.3.2-1ubuntu0.1 [24.9 kB]\nGet:29 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libruby3.0 amd64 3.0.2-7ubuntu2.10 [5,114 kB]\nGet:30 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsynctex2 amd64 2021.20210626.59705-1ubuntu0.2 [55.6 kB]\nGet:31 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libteckit0 amd64 2.5.11+ds1-1 [421 kB]\nGet:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexlua53 amd64 2021.20210626.59705-1ubuntu0.2 [120 kB]\nGet:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexluajit2 amd64 2021.20210626.59705-1ubuntu0.2 [267 kB]\nGet:34 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libzzip-0-13 amd64 0.13.72+dfsg.1-1.1 [27.0 kB]\nGet:35 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\nGet:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\nGet:37 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lmodern all 2.004.5-6.1 [9,471 kB]\nGet:38 http://archive.ubuntu.com/ubuntu jammy/universe amd64 preview-latex-style all 12.2-1ubuntu1 [185 kB]\nGet:39 http://archive.ubuntu.com/ubuntu jammy/main amd64 t1utils amd64 1.41-4build2 [61.3 kB]\nGet:40 http://archive.ubuntu.com/ubuntu jammy/universe amd64 teckit amd64 2.5.11+ds1-1 [699 kB]\nGet:41 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-gyre all 20180621-3.1 [6,209 kB]\nGet:42 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 texlive-binaries amd64 2021.20210626.59705-1ubuntu0.2 [9,860 kB]\nGet:43 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-base all 2021.20220204-1 [21.0 MB]\nGet:44 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-fonts-recommended all 2021.20220204-1 [4,972 kB]\nGet:45 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-base all 2021.20220204-1 [1,128 kB]\nGet:46 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfontbox-java all 1:1.8.16-2 [207 kB]\nGet:47 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libpdfbox-java all 1:1.8.16-2 [5,199 kB]\nGet:48 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-recommended all 2021.20220204-1 [14.4 MB]\nGet:49 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-pictures all 2021.20220204-1 [8,720 kB]\nGet:50 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-extra all 2021.20220204-1 [13.9 MB]\nGet:51 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-plain-generic all 2021.20220204-1 [27.5 MB]\nGet:52 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tipa all 2:1.3-21 [2,967 kB]\nGet:53 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-xetex all 2021.20220204-1 [12.4 MB]\nFetched 182 MB in 3s (69.8 MB/s)\nExtracting templates from packages: 100%\nPreconfiguring packages ...\nSelecting previously unselected package fonts-droid-fallback.\n(Reading database ... 126558 files and directories currently installed.)\nPreparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\nUnpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\nSelecting previously unselected package fonts-lato.\nPreparing to unpack .../01-fonts-lato_2.0-2.1_all.deb ...\nUnpacking fonts-lato (2.0-2.1) ...\nSelecting previously unselected package poppler-data.\nPreparing to unpack .../02-poppler-data_0.4.11-1_all.deb ...\nUnpacking poppler-data (0.4.11-1) ...\nSelecting previously unselected package tex-common.\nPreparing to unpack .../03-tex-common_6.17_all.deb ...\nUnpacking tex-common (6.17) ...\nSelecting previously unselected package fonts-urw-base35.\nPreparing to unpack .../04-fonts-urw-base35_20200910-1_all.deb ...\nUnpacking fonts-urw-base35 (20200910-1) ...\nSelecting previously unselected package libgs9-common.\nPreparing to unpack .../05-libgs9-common_9.55.0~dfsg1-0ubuntu5.11_all.deb ...\nUnpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.11) ...\nSelecting previously unselected package libidn12:amd64.\nPreparing to unpack .../06-libidn12_1.38-4ubuntu1_amd64.deb ...\nUnpacking libidn12:amd64 (1.38-4ubuntu1) ...\nSelecting previously unselected package libijs-0.35:amd64.\nPreparing to unpack .../07-libijs-0.35_0.35-15build2_amd64.deb ...\nUnpacking libijs-0.35:amd64 (0.35-15build2) ...\nSelecting previously unselected package libjbig2dec0:amd64.\nPreparing to unpack .../08-libjbig2dec0_0.19-3build2_amd64.deb ...\nUnpacking libjbig2dec0:amd64 (0.19-3build2) ...\nSelecting previously unselected package libgs9:amd64.\nPreparing to unpack .../09-libgs9_9.55.0~dfsg1-0ubuntu5.11_amd64.deb ...\nUnpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.11) ...\nSelecting previously unselected package libkpathsea6:amd64.\nPreparing to unpack .../10-libkpathsea6_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\nUnpacking libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...\nSelecting previously unselected package libwoff1:amd64.\nPreparing to unpack .../11-libwoff1_1.0.2-1build4_amd64.deb ...\nUnpacking libwoff1:amd64 (1.0.2-1build4) ...\nSelecting previously unselected package dvisvgm.\nPreparing to unpack .../12-dvisvgm_2.13.1-1_amd64.deb ...\nUnpacking dvisvgm (2.13.1-1) ...\nSelecting previously unselected package fonts-lmodern.\nPreparing to unpack .../13-fonts-lmodern_2.004.5-6.1_all.deb ...\nUnpacking fonts-lmodern (2.004.5-6.1) ...\nSelecting previously unselected package fonts-noto-mono.\nPreparing to unpack .../14-fonts-noto-mono_20201225-1build1_all.deb ...\nUnpacking fonts-noto-mono (20201225-1build1) ...\nSelecting previously unselected package fonts-texgyre.\nPreparing to unpack .../15-fonts-texgyre_20180621-3.1_all.deb ...\nUnpacking fonts-texgyre (20180621-3.1) ...\nSelecting previously unselected package libapache-pom-java.\nPreparing to unpack .../16-libapache-pom-java_18-1_all.deb ...\nUnpacking libapache-pom-java (18-1) ...\nSelecting previously unselected package libcommons-parent-java.\nPreparing to unpack .../17-libcommons-parent-java_43-1_all.deb ...\nUnpacking libcommons-parent-java (43-1) ...\nSelecting previously unselected package libcommons-logging-java.\nPreparing to unpack .../18-libcommons-logging-java_1.2-2_all.deb ...\nUnpacking libcommons-logging-java (1.2-2) ...\nSelecting previously unselected package libptexenc1:amd64.\nPreparing to unpack .../19-libptexenc1_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\nUnpacking libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...\nSelecting previously unselected package rubygems-integration.\nPreparing to unpack .../20-rubygems-integration_1.18_all.deb ...\nUnpacking rubygems-integration (1.18) ...\nSelecting previously unselected package ruby3.0.\nPreparing to unpack .../21-ruby3.0_3.0.2-7ubuntu2.10_amd64.deb ...\nUnpacking ruby3.0 (3.0.2-7ubuntu2.10) ...\nSelecting previously unselected package ruby-rubygems.\nPreparing to unpack .../22-ruby-rubygems_3.3.5-2_all.deb ...\nUnpacking ruby-rubygems (3.3.5-2) ...\nSelecting previously unselected package ruby.\nPreparing to unpack .../23-ruby_1%3a3.0~exp1_amd64.deb ...\nUnpacking ruby (1:3.0~exp1) ...\nSelecting previously unselected package rake.\nPreparing to unpack .../24-rake_13.0.6-2_all.deb ...\nUnpacking rake (13.0.6-2) ...\nSelecting previously unselected package ruby-net-telnet.\nPreparing to unpack .../25-ruby-net-telnet_0.1.1-2_all.deb ...\nUnpacking ruby-net-telnet (0.1.1-2) ...\nSelecting previously unselected package ruby-webrick.\nPreparing to unpack .../26-ruby-webrick_1.7.0-3ubuntu0.1_all.deb ...\nUnpacking ruby-webrick (1.7.0-3ubuntu0.1) ...\nSelecting previously unselected package ruby-xmlrpc.\nPreparing to unpack .../27-ruby-xmlrpc_0.3.2-1ubuntu0.1_all.deb ...\nUnpacking ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\nSelecting previously unselected package libruby3.0:amd64.\nPreparing to unpack .../28-libruby3.0_3.0.2-7ubuntu2.10_amd64.deb ...\nUnpacking libruby3.0:amd64 (3.0.2-7ubuntu2.10) ...\nSelecting previously unselected package libsynctex2:amd64.\nPreparing to unpack .../29-libsynctex2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\nUnpacking libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\nSelecting previously unselected package libteckit0:amd64.\nPreparing to unpack .../30-libteckit0_2.5.11+ds1-1_amd64.deb ...\nUnpacking libteckit0:amd64 (2.5.11+ds1-1) ...\nSelecting previously unselected package libtexlua53:amd64.\nPreparing to unpack .../31-libtexlua53_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\nUnpacking libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...\nSelecting previously unselected package libtexluajit2:amd64.\nPreparing to unpack .../32-libtexluajit2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\nUnpacking libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\nSelecting previously unselected package libzzip-0-13:amd64.\nPreparing to unpack .../33-libzzip-0-13_0.13.72+dfsg.1-1.1_amd64.deb ...\nUnpacking libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...\nSelecting previously unselected package xfonts-encodings.\nPreparing to unpack .../34-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\nUnpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\nSelecting previously unselected package xfonts-utils.\nPreparing to unpack .../35-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\nUnpacking xfonts-utils (1:7.7+6build2) ...\nSelecting previously unselected package lmodern.\nPreparing to unpack .../36-lmodern_2.004.5-6.1_all.deb ...\nUnpacking lmodern (2.004.5-6.1) ...\nSelecting previously unselected package preview-latex-style.\nPreparing to unpack .../37-preview-latex-style_12.2-1ubuntu1_all.deb ...\nUnpacking preview-latex-style (12.2-1ubuntu1) ...\nSelecting previously unselected package t1utils.\nPreparing to unpack .../38-t1utils_1.41-4build2_amd64.deb ...\nUnpacking t1utils (1.41-4build2) ...\nSelecting previously unselected package teckit.\nPreparing to unpack .../39-teckit_2.5.11+ds1-1_amd64.deb ...\nUnpacking teckit (2.5.11+ds1-1) ...\nSelecting previously unselected package tex-gyre.\nPreparing to unpack .../40-tex-gyre_20180621-3.1_all.deb ...\nUnpacking tex-gyre (20180621-3.1) ...\nSelecting previously unselected package texlive-binaries.\nPreparing to unpack .../41-texlive-binaries_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\nUnpacking texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...\nSelecting previously unselected package texlive-base.\nPreparing to unpack .../42-texlive-base_2021.20220204-1_all.deb ...\nUnpacking texlive-base (2021.20220204-1) ...\nSelecting previously unselected package texlive-fonts-recommended.\nPreparing to unpack .../43-texlive-fonts-recommended_2021.20220204-1_all.deb ...\nUnpacking texlive-fonts-recommended (2021.20220204-1) ...\nSelecting previously unselected package texlive-latex-base.\nPreparing to unpack .../44-texlive-latex-base_2021.20220204-1_all.deb ...\nUnpacking texlive-latex-base (2021.20220204-1) ...\nSelecting previously unselected package libfontbox-java.\nPreparing to unpack .../45-libfontbox-java_1%3a1.8.16-2_all.deb ...\nUnpacking libfontbox-java (1:1.8.16-2) ...\nSelecting previously unselected package libpdfbox-java.\nPreparing to unpack .../46-libpdfbox-java_1%3a1.8.16-2_all.deb ...\nUnpacking libpdfbox-java (1:1.8.16-2) ...\nSelecting previously unselected package texlive-latex-recommended.\nPreparing to unpack .../47-texlive-latex-recommended_2021.20220204-1_all.deb ...\nUnpacking texlive-latex-recommended (2021.20220204-1) ...\nSelecting previously unselected package texlive-pictures.\nPreparing to unpack .../48-texlive-pictures_2021.20220204-1_all.deb ...\nUnpacking texlive-pictures (2021.20220204-1) ...\nSelecting previously unselected package texlive-latex-extra.\nPreparing to unpack .../49-texlive-latex-extra_2021.20220204-1_all.deb ...\nUnpacking texlive-latex-extra (2021.20220204-1) ...\nSelecting previously unselected package texlive-plain-generic.\nPreparing to unpack .../50-texlive-plain-generic_2021.20220204-1_all.deb ...\nUnpacking texlive-plain-generic (2021.20220204-1) ...\nSelecting previously unselected package tipa.\nPreparing to unpack .../51-tipa_2%3a1.3-21_all.deb ...\nUnpacking tipa (2:1.3-21) ...\nSelecting previously unselected package texlive-xetex.\nPreparing to unpack .../52-texlive-xetex_2021.20220204-1_all.deb ...\nUnpacking texlive-xetex (2021.20220204-1) ...\nSetting up fonts-lato (2.0-2.1) ...\nSetting up fonts-noto-mono (20201225-1build1) ...\nSetting up libwoff1:amd64 (1.0.2-1build4) ...\nSetting up libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...\nSetting up libijs-0.35:amd64 (0.35-15build2) ...\nSetting up libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\nSetting up libfontbox-java (1:1.8.16-2) ...\nSetting up rubygems-integration (1.18) ...\nSetting up libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...\nSetting up fonts-urw-base35 (20200910-1) ...\nSetting up poppler-data (0.4.11-1) ...\nSetting up tex-common (6.17) ...\nupdate-language: texlive-base not installed and configured, doing nothing!\nSetting up libjbig2dec0:amd64 (0.19-3build2) ...\nSetting up libteckit0:amd64 (2.5.11+ds1-1) ...\nSetting up libapache-pom-java (18-1) ...\nSetting up ruby-net-telnet (0.1.1-2) ...\nSetting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\nSetting up t1utils (1.41-4build2) ...\nSetting up libidn12:amd64 (1.38-4ubuntu1) ...\nSetting up fonts-texgyre (20180621-3.1) ...\nSetting up libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...\nSetting up ruby-webrick (1.7.0-3ubuntu0.1) ...\nSetting up fonts-lmodern (2.004.5-6.1) ...\nSetting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\nSetting up ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\nSetting up libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\nSetting up libgs9-common (9.55.0~dfsg1-0ubuntu5.11) ...\nSetting up teckit (2.5.11+ds1-1) ...\nSetting up libpdfbox-java (1:1.8.16-2) ...\nSetting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.11) ...\nSetting up preview-latex-style (12.2-1ubuntu1) ...\nSetting up libcommons-parent-java (43-1) ...\nSetting up dvisvgm (2.13.1-1) ...\nSetting up libcommons-logging-java (1.2-2) ...\nSetting up xfonts-utils (1:7.7+6build2) ...\nSetting up libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...\nSetting up texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...\nupdate-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\nupdate-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\nSetting up lmodern (2.004.5-6.1) ...\nSetting up texlive-base (2021.20220204-1) ...\n/usr/bin/ucfr\n/usr/bin/ucfr\n/usr/bin/ucfr\n/usr/bin/ucfr\nmktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \nmktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \nmktexlsr: Updating /var/lib/texmf/ls-R... \nmktexlsr: Done.\ntl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\ntl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\ntl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\ntl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/tex-ini-files/pdftexconfig.tex\nSetting up tex-gyre (20180621-3.1) ...\nSetting up texlive-plain-generic (2021.20220204-1) ...\nSetting up texlive-latex-base (2021.20220204-1) ...\nSetting up texlive-latex-recommended (2021.20220204-1) ...\nSetting up texlive-pictures (2021.20220204-1) ...\nSetting up texlive-fonts-recommended (2021.20220204-1) ...\nSetting up tipa (2:1.3-21) ...\nSetting up texlive-latex-extra (2021.20220204-1) ...\nSetting up texlive-xetex (2021.20220204-1) ...\nSetting up rake (13.0.6-2) ...\nSetting up libruby3.0:amd64 (3.0.2-7ubuntu2.10) ...\nSetting up ruby3.0 (3.0.2-7ubuntu2.10) ...\nSetting up ruby (1:3.0~exp1) ...\nSetting up ruby-rubygems (3.3.5-2) ...\nProcessing triggers for man-db (2.10.2-1) ...\nProcessing triggers for mailcap (3.70+nmu1ubuntu1) ...\nProcessing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\nProcessing triggers for libc-bin (2.35-0ubuntu3.8) ...\n/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n\nProcessing triggers for tex-common (6.17) ...\nRunning updmap-sys. This may take some time... done.\nRunning mktexlsr /var/lib/texmf ... done.\nBuilding format(s) --all.\n    This may take some time... done.\nTeX packages installed successfully.\n--2025-04-26 22:32:56--  https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_rain-sprinkler-lawn/AMTAIR_Prototype_example_rain-sprinkler-lawn.ipynb\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1120047 (1.1M) [text/plain]\nSaving to: ‘AMTAIR_Prototype_example_rain-sprinkler-lawn.ipynb’\n\nAMTAIR_Prototype_ex 100%[===================&gt;]   1.07M  --.-KB/s    in 0.06s   \n\n2025-04-26 22:32:56 (17.0 MB/s) - ‘AMTAIR_Prototype_example_rain-sprinkler-lawn.ipynb’ saved [1120047/1120047]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>[AMTAIR Prototype Demonstration (Public Colab Notebook)](https://colab.research.google.com/github/SingularitySmith/AMTAIR_Prototype/blob/main/version_history/AMTAIR_Prototype_0_1.3.ipynb#scrollTo=lt8-AnebGUXr)</span>"
    ]
  }
]