[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n\nAbstract\n\n\nOutline(s): Table of Contents",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "chapters/Introduction.html",
    "href": "chapters/Introduction.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Abstract\nThe coordination crisis in AI governance presents a paradoxical challenge: unprecedented investment in AI safety coexists alongside fundamental coordination failures across technical, policy, and ethical domains. These divisions systematically increase existential risk by creating safety gaps, misallocating resources, and fostering inconsistent approaches to interdependent problems.\nThe AMTAIR system implements an end-to-end pipeline that transforms unstructured text into interactive Bayesian networks through a novel two-stage extraction process: first capturing argument structure in ArgDown format, then enhancing it with probability information in BayesDown. This approach bridges communication gaps between stakeholders by making implicit models explicit, enabling comparison across different worldviews, providing a common language for discussing probabilistic relationships, and supporting policy evaluation across diverse scenarios.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/Introduction.html#sec-abstract",
    "href": "chapters/Introduction.html#sec-abstract",
    "title": "1  Introduction",
    "section": "",
    "text": "The coordination crisis in AI governance presents a paradoxical challenge: unprecedented investment in AI safety coexists alongside fundamental coordination failures across technical, policy, and ethical domains. These divisions systematically increase existential risk. This thesis introduces AMTAIR (Automating Transformative AI Risk Modeling), a computational approach addressing this coordination failure by automating the extraction of probabilistic world models from AI safety literature using frontier language models. The system implements an end-to-end pipeline transforming unstructured text into interactive Bayesian networks through a novel two-stage extraction process that bridges communication gaps between stakeholders.\n\n\n\n\nThis thesis introduces AMTAIR (Automating Transformative AI Risk Modeling), a computational approach that addresses this coordination failure by automating the extraction of probabilistic world models from AI safety literature using frontier language models.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/Introduction.html#sec-coordination-crisis",
    "href": "chapters/Introduction.html#sec-coordination-crisis",
    "title": "1  Introduction",
    "section": "2.1 The Coordination Crisis in AI Governance",
    "text": "2.1 The Coordination Crisis in AI Governance\n\n\nAs AI capabilities advance at an accelerating pace—demonstrated by the rapid progression from GPT-3 to GPT-4, Claude, and beyond—we face a governance challenge unlike any in human history: how to ensure increasingly powerful AI systems remain aligned with human values and beneficial to humanity’s long-term flourishing. This challenge becomes particularly acute when considering the possibility of transformative AI systems that could drastically alter civilization’s trajectory, potentially including existential risks from misaligned systems.\n\nDespite unprecedented investment in AI safety research, rapidly growing awareness among key stakeholders, and proliferating frameworks for responsible AI development, we face what I’ll term the “coordination crisis” in AI governance—a systemic failure to align diverse efforts across technical, policy, and strategic domains into a coherent response proportionate to the risks we face.\n\n`The AI governance landscape exhibits a peculiar paradox: extraordinary activity alongside fundamental coordination failure. Consider the current state of affairs:\nTechnical safety researchers develop increasingly sophisticated alignment techniques, but often without clear implementation pathways to deployment contexts. Policy specialists craft principles and regulatory frameworks without sufficient technical grounding to ensure their practical efficacy. Ethicists articulate normative principles that lack operational specificity. Strategy researchers identify critical uncertainties but struggle to translate these into actionable guidance.`\n\nOpening with the empirical paradox: record investment in AI safety coexisting with fragmented, ineffective governance responses\n\n\n2.1.1 Empirical Paradox: Investment Alongside Fragmentation\n\n\n\nThe Fragmentation Problem: Technical researchers, policy specialists, and strategic analysts operate with incompatible frameworks\n\n\n\n2.1.2 Systematic Risk Increase Through Coordination Failure\n\n\n\n\n\nSystemic Risk Amplification: How coordination failures systematically increase existential risk through safety gaps and resource misallocation\n\n\n\n2.1.3 Historical Parallels and Temporal Urgency\n\n\n\nThe Scaling Challenge: Traditional governance approaches cannot match the pace of capability development",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/Introduction.html#sec-research-question",
    "href": "chapters/Introduction.html#sec-research-question",
    "title": "1  Introduction",
    "section": "2.2 Research Question and Scope",
    "text": "2.2 Research Question and Scope\n\n\n\nThis thesis addresses a specific dimension of the coordination challenge by investigating the question: Can frontier AI technologies be utilized to automate the modeling of transformative AI risks, enabling robust prediction of policy impacts?\nThis thesis addresses a specific dimension of the coordination challenge by investigating how computational approaches can formalize the worldviews and arguments underlying AI safety discourse, transforming qualitative disagreements into quantitative models suitable for rigorous policy evaluation.\nTo break this down into its components:\n\nFrontier AI Technologies: Today’s most capable language models (GPT-4, Claude-3 level systems)\nAutomated Modeling: Using these systems to extract and formalize argument structures from natural language\nTransformative AI Risks: Potentially catastrophic outcomes from advanced AI systems, particularly existential risks\nPolicy Impact Prediction: Evaluating how governance interventions might alter probability distributions over outcomes\n\nCentral Question: Can frontier AI technologies be utilized to automate the modeling of transformative AI risks, enabling robust prediction of policy impacts?\nAMTAIR represents the first computational framework for automated extraction and formalization of AI governance worldviews\nCore Innovation:\n\nAutomated transformation of qualitative governance arguments into quantitative Bayesian networks\nIntegration of prediction markets with formal models for dynamic risk assessment\nCross-worldview policy evaluation under deep uncertainty\n\nScope Boundaries:\n\nThe investigation encompasses both theoretical development and practical implementation, focusing specifically on existential risks from misaligned AI systems rather than broader AI ethics concerns. This narrowed scope enables deep technical development while addressing the highest-stakes coordination challenges.\nThe scope encompasses both theoretical development and practical implementation. Theoretically, I develop a framework for representing diverse perspectives on AI risk in a common formal language. Practically, I implement this framework in a computational system—the AI Risk Pathway Analyzer (ARPA)—that enables interactive exploration of how policy interventions might alter existential risk.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/Introduction.html#sec-multiplicative-benefits",
    "href": "chapters/Introduction.html#sec-multiplicative-benefits",
    "title": "1  Introduction",
    "section": "2.3 The Multiplicative Benefits Framework",
    "text": "2.3 The Multiplicative Benefits Framework\n\n \nCore Innovation: The combination of three elements—automated extraction, prediction market integration, and formal policy evaluation—creates multiplicative rather than additive benefits for AI governance.\nThe central thesis of this work is that combining three elements—automated worldview extraction, prediction market integration, and formal policy evaluation—creates multiplicative rather than merely additive benefits for AI governance. Each component enhances the others, creating a system more valuable than the sum of its parts.\nAutomated worldview extraction using frontier language models addresses the scaling bottleneck in current approaches to AI risk modeling. The Modeling Transformative AI Risks (MTAIR) project demonstrated the value of formal representation but required extensive manual effort to translate qualitative arguments into quantitative models. Automation enables processing orders of magnitude more content, incorporating diverse perspectives, and maintaining models in near real-time as new arguments emerge.\nPrediction market integration grounds these models in collective forecasting intelligence. By connecting formal representations to live forecasting platforms, the system can incorporate timely judgments about critical uncertainties from calibrated forecasters. This creates a dynamic feedback loop, where models inform forecasters and forecasts update models.\nFormal policy evaluation transforms static risk assessments into actionable guidance by modeling how specific interventions might alter critical parameters. This enables conditional forecasting—understanding not just the probability of adverse outcomes but how those probabilities change under different policy regimes.\nSynergistic Components:\n\nAutomated Worldview Extraction: Scaling formal modeling from manual (MTAIR) to automated approaches using frontier LLMs\nLive Data Integration: Connecting models to prediction markets and forecasting platforms for dynamic calibration and live updating\nPolicy Evaluation: Enabling rigorous counterfactual analysis of governance interventions across worldviews\n\nThe synergy emerges because automation enables comprehensive data integration, markets inform and validate models, and evaluation gains precision from both automated extraction and market-based calibration.\nThe combination creates multiplicative rather than additive value—automation enables comprehensive data integration, markets inform models, evaluation gains precision from both\n\n\n\n\n\n\nFigure 2.1: AMTAIR Automation Pipeline from CITATION",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/Introduction.html#sec-roadmap",
    "href": "chapters/Introduction.html#sec-roadmap",
    "title": "1  Introduction",
    "section": "2.4 Thesis Structure and Roadmap",
    "text": "2.4 Thesis Structure and Roadmap\n\n \n\nLogical Progression from Theory to Application:\n\nContext & Background: Establish theoretical foundations (Bayesian networks, argument mapping) and methodological approach (two-stage extraction)\nAMTAIR Implementation: Demonstrate technical feasibility through working prototype with validated examples\nCritical Analysis: Examine limitations, failure modes, and governance implications through systematic red-teaming\nFuture Directions: Connect to broader coordination challenges and research agenda\n\nEach section builds toward a practical implementation of the framework while maintaining both theoretical rigor and policy relevance, demonstrating how computational approaches can enhance rather than replace human judgment in AI governance.\nThe remainder of this thesis develops the multiplicative benefits framework from theoretical foundations to practical implementation, following a progression from abstract principles to concrete applications:\nSection 2 establishes the theoretical foundations and methodological approach, examining why AI governance presents unique epistemic challenges and how Bayesian networks can formalize causal relationships in this domain.\nSection 3 presents the AMTAIR implementation, detailing the technical system that transforms qualitative arguments into formal representations. It demonstrates the approach through two case studies: the canonical Rain-Sprinkler-Lawn example and the more complex Carlsmith model of power-seeking AI.\nSection 4 discusses implications, limitations, and counterarguments, addressing potential failure modes, scaling challenges, and integration with existing governance frameworks.\nSection 5 concludes by summarizing key contributions, drawing out concrete policy implications, and suggesting directions for future research.\nThroughout this progression, I maintain a dual focus on theoretical sophistication and practical utility. The framework aims not merely to advance academic understanding of AI risk but to provide actionable tools for improving coordination in AI governance.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/Introduction.html#overview-table-of-contents",
    "href": "chapters/Introduction.html#overview-table-of-contents",
    "title": "1  Introduction",
    "section": "2.5 Overview / Table of Contents",
    "text": "2.5 Overview / Table of Contents",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/Context.html",
    "href": "chapters/Context.html",
    "title": "2  Context",
    "section": "",
    "text": "3 Context & Background",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Context</span>"
    ]
  },
  {
    "objectID": "chapters/Context.html#sec-theoretical-foundations",
    "href": "chapters/Context.html#sec-theoretical-foundations",
    "title": "2  Context",
    "section": "3.1 Theoretical Foundations",
    "text": "3.1 Theoretical Foundations\n\n3.1.1 AI Existential Risk: The Carlsmith Model\n\n\n\nCarlsmith’s “Is power-seeking AI an existential risk?” (2021) represents one of the most structured approaches to assessing the probability of existential catastrophe from advanced AI. The analysis decomposes the overall risk into six key premises, each with an explicit probability estimate.\n\n`The six key premises are:\n\nDevelopment of transformative AI systems this century (80%)\nAI systems pursuing objectives in the world (95%)\nSystems with power-seeking instrumental incentives (40%)\nSystems with sufficient capability to pose existential threats (65%)\nAI systems not aligned with human values (50%)\nMisaligned, power-seeking systems causing existential catastrophe (65%)`\n\n\n\n3.1.2 The Epistemic Challenge of Policy Evaluation\n\n\n\nAI governance policy evaluation faces unique epistemic challenges that render traditional policy analysis methods insufficient. The domain combines complex causal chains with limited empirical grounding, deep uncertainty about future capabilities, divergent stakeholder worldviews, and few opportunities for experimental testing before deployment.\n\n`Traditional methods fall short in several ways:\n\nCost-benefit analysis struggles with existential outcomes and deep uncertainty\nScenario planning often lacks probabilistic reasoning necessary for rigorous evaluation\nExpert elicitation alone fails to formalize interdependencies between variables\nQualitative approaches obscure crucial assumptions that drive conclusions`\n\n\n\n3.1.3 Argument Mapping and Formal Representations\n\n\nArgument mapping offers a bridge between informal reasoning in natural language and the formal representations needed for rigorous analysis. By explicitly identifying claims, premises, inferential relationships, and support/attack patterns, argument maps make implicit reasoning structures visible for examination and critique.\n\nThe progression from natural language arguments to formal Bayesian networks requires an intermediate representation that preserves narrative structure while adding mathematical precision. The ArgDown format serves this purpose by encoding hierarchical relationships between statements, while its extension, BayesDown, adds probabilistic metadata to enable full Bayesian network construction.\n[Effect_Node]: Description of effect. {\"instantiations\": [\"effect_TRUE\", \"effect_FALSE\"]}\n + [Cause_Node]: Description of direct cause. {\"instantiations\": [\"cause_TRUE\", \"cause_FALSE\"]}\n   + [Root_Cause]: Description of indirect cause. {\"instantiations\": [\"root_TRUE\", \"root_FALSE\"]}\n\n\n3.1.4 Bayesian Networks as Knowledge Representation\n\n\n\nBayesian networks provide a formal mathematical framework for representing causal relationships and reasoning under uncertainty. These directed acyclic graphs (DAGs) combine qualitative structure—nodes representing variables and edges representing dependencies—with quantitative parameters in the form of conditional probability tables.\n\n`Key properties that make Bayesian networks particularly suited to AI risk modeling include:\n\nNatural representation of causal relationships between variables\nExplicit handling of uncertainty through probability distributions\nSupport for evidence updating through Bayesian inference\nCapability for interventional reasoning through do-calculus\nBalance between mathematical rigor and intuitive visual representation`\n\n\n\n\n\n\n\nFigure 3.1: Example Bayesian Network\n\n\n\n\n\n3.1.5 The MTAIR Framework: Achievements and Limitations\n\n\nThe Modeling Transformative AI Risks (MTAIR) project demonstrated the value of formal probabilistic modeling for AI safety, but also revealed significant limitations in the manual approach. While MTAIR successfully translated complex arguments into Bayesian networks and enabled sensitivity analysis, the intensive human labor required for model creation limited both scalability and timeliness.\n\n`MTAIR’s key innovations included:\n\nExplicit representation of uncertainty through probability distributions\nStructured decomposition of complex risk scenarios\nIntegration of diverse expert judgments\nSensitivity analysis to identify critical parameters\n\nIts limitations motivated the current automated approach:\n\nManual labor intensity limiting scalability\nStatic nature of models once constructed\nLimited accessibility for non-technical stakeholders\nChallenges in representing multiple worldviews simultaneously`\n\n\n\n3.1.6 “A Narrow Path”: Conditional Policy Proposals in Practice\n\n\n“A Narrow Path” represents an influential example of conditional policy proposals in AI governance—identifying interventions that could succeed under specific conditions rather than absolute prescriptions. However, these conditions remain implicitly defined and qualitatively described, limiting rigorous evaluation.\n\n`Formal modeling could enhance such proposals by:\n\nMaking conditions explicit and quantifiable\nClarifying when interventions would be effective\nIdentifying which uncertainties most significantly affect outcomes\nEnabling systematic comparison of alternative approaches\nSupporting robust policy development across possible futures`",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Context</span>"
    ]
  },
  {
    "objectID": "chapters/Context.html#sec-methodology",
    "href": "chapters/Context.html#sec-methodology",
    "title": "2  Context",
    "section": "3.2 Methodology",
    "text": "3.2 Methodology\n\n3.2.1 Research Design Overview\n\n\n\nThis research combines theoretical development with practical implementation, following an iterative approach that moves between conceptual refinement and technical validation. The methodology encompasses formal framework development, computational implementation, extraction quality assessment, and application to real-world AI governance questions.\n\n`The research process follows four main phases:\n\nFramework development: Creating the theoretical foundations and formal representations\nSystem implementation: Building the computational tools for extraction and analysis\nValidation testing: Assessing extraction quality and system performance\nApplication evaluation: Applying the framework to concrete AI governance questions`\n\n\n\n3.2.2 Formalizing World Models from AI Safety Literature\n\n\n\nThe core methodological challenge involves transforming natural language arguments in AI safety literature into formal causal models with explicit probability judgments. This extraction process identifies key variables, causal relationships, and both explicit and implicit probability estimates through a systematic pipeline.\n\n`The extraction approach combines:\n\nIdentification of key variables and entities in text\nRecognition of causal claims and relationships\nDetection of explicit and implicit probability judgments\nTransformation into structured intermediate representations\nConversion to formal Bayesian networks\n\nLarge language models facilitate this process through:\n\nTwo-stage prompting that separates structure from probability extraction\nSpecialized templates for different types of source documents\nTechniques for identifying implicit assumptions and relationships\nMechanisms for handling ambiguity and uncertainty`\n\n\n\n3.2.3 Directed Acyclic Graphs: Structure and Semantics\n\n\n\nDirected Acyclic Graphs (DAGs) form the mathematical foundation of Bayesian networks, encoding both the qualitative structure of causal relationships and the quantitative parameters that define conditional dependencies. In AI risk modeling, these structures represent causal pathways to potential outcomes of interest.\n\n`Key mathematical properties include:\n\nAcyclicity, ensuring no feedback loops\nPath properties defining information flow\nD-separation criteria determining conditional independence\nMarkov blanket defining minimal contextual information\n\nSemantic interpretation in AI risk contexts:\n\nNodes represent key variables in risk pathways\nEdges represent causal or inferential relationships\nPath blocking corresponds to intervention points\nProbability flows represent risk propagation through systems`\n\n\n\n3.2.4 Quantification Approaches for Probabilistic Judgments\n\n\n\nTransforming qualitative judgments in AI safety literature into quantitative probabilities requires a systematic approach to interpretation, extraction, and validation. This process combines direct extraction of explicit numerical statements with inference of implicit probability judgments from qualitative language.\n\n`Quantification methods include:\n\nDirect extraction of explicit numerical statements\nLinguistic mapping of qualitative expressions\nExpert elicitation techniques for ambiguous cases\nBayesian updating from multiple sources\n\nSpecial challenges in AI risk quantification:\n\nDeep uncertainty about unprecedented events\nDiverse disciplinary languages and conventions\nLimited empirical basis for calibration\nValue-laden aspects of risk assessment`\n\n\n\n3.2.5 Inference Techniques for Complex Networks\n\n\n\nOnce Bayesian networks are constructed, probabilistic inference enables reasoning about uncertainties, counterfactuals, and policy interventions. For the complex networks representing AI risks, computational approaches must balance accuracy with tractability.\n\n`Inference methods implemented include:\n\nExact methods for smaller networks (variable elimination, junction trees)\nApproximate methods for larger networks (Monte Carlo sampling)\nSpecialized approaches for rare events\nIntervention modeling for policy evaluation\n\nImplementation considerations include:\n\nComputational complexity management\nSampling efficiency optimization\nApproximation quality monitoring\nUncertainty representation in outputs`\n\n\n\n3.2.6 Integration with Prediction Markets and Forecasting Platforms\n\n\n\nTo maintain relevance in a rapidly evolving field, formal models must integrate with live data sources such as prediction markets and forecasting platforms. This integration enables continuous updating of model parameters as new information emerges.\n\n`Integration approaches include:\n\nAPI connections to platforms like Metaculus\nSemantic mapping between forecast questions and model variables\nWeighting mechanisms based on forecaster track records\nUpdate procedures for incorporating new predictions\nFeedback loops identifying valuable forecast questions\n\nTechnical implementation involves:\n\nStandardized data formats across platforms\nConflict resolution for contradictory sources\nTemporal alignment of forecasts\nConfidence-weighted aggregation methods`\n\n\n\n\n\n\n\nFigure 3.2: AMTAIR Automation Pipeline from CITATION\n\n\n\nTesting crossreferencing grapics Figure 6.1.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Context</span>"
    ]
  },
  {
    "objectID": "chapters/AMTAIR.html",
    "href": "chapters/AMTAIR.html",
    "title": "3  AMTAIR",
    "section": "",
    "text": "3.1 AMTAIR Implementation\nText to render",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>AMTAIR</span>"
    ]
  },
  {
    "objectID": "chapters/AMTAIR.html#sec-software-implementation",
    "href": "chapters/AMTAIR.html#sec-software-implementation",
    "title": "3  AMTAIR",
    "section": "3.2 Software Implementation",
    "text": "3.2 Software Implementation\n\n3.2.1 System Architecture and Data Flow\n\n\n\nThe AMTAIR system implements an end-to-end pipeline from unstructured text to interactive Bayesian network visualization. Its modular architecture comprises five main components that progressively transform information from natural language into formal models.\n\n`Core system components include:\n\nText Ingestion and Preprocessing: Handles format normalization, metadata extraction, and relevance filtering\nBayesDown Extraction: Identifies argument structures, causal relationships, and probabilistic judgments\nStructured Data Transformation: Parses representations into standardized data formats\nBayesian Network Construction: Creates formal network representations with nodes and edges\nInteractive Visualization: Renders networks as explorable visual interfaces`\n\n\n\n\n3.2.2 Rain-Sprinkler-Grass Example Implementation\n\n\n\nThe Rain-Sprinkler-Grass example serves as a canonical test case demonstrating each step in the AMTAIR pipeline. This simple causal scenario—where both rain and sprinkler use can cause wet grass, and rain influences sprinkler use—provides an intuitive introduction to Bayesian network concepts while exercising all system components.\n\n`The implementation walkthrough includes:\n\nSource representation in natural language\nExtraction to ArgDown format with structural relationships\nEnhancement to BayesDown with probability information\nTransformation into structured data tables\nConstruction of the Bayesian network\nInteractive visualization with probability encoding`\n\n\n\n3.2.3 Carlsmith Implementation\n\n\n\nApplied to Carlsmith’s model of power-seeking AI, the AMTAIR pipeline demonstrates its capacity to handle complex real-world causal structures. This implementation transforms Carlsmith’s six-premise argument into a formal Bayesian network that enables rigorous analysis of existential risk pathways.\n\n`Key aspects of the implementation include:\n\nExtraction of the multi-level causal structure\nRepresentation of Carlsmith’s explicit probability estimates\nIdentification of implicit conditional relationships\nVisualization of the complete risk model\nAnalysis of critical pathways and parameters`\n\n\n\n3.2.4 Inference & Extensions\n\n\n\nBeyond basic representation, AMTAIR implements advanced analytical capabilities that enable reasoning about uncertainties, counterfactuals, and policy interventions. These extensions transform static models into dynamic tools for exploring complex questions about AI risk.\n\n`Key inference capabilities include:\n\nProbability queries for outcomes of interest\nSensitivity analysis identifying critical parameters\nCounterfactual reasoning for policy evaluation\nIntervention modeling for strategy development\nComparative analysis across different worldviews`\n\nPOST TEXT\npost text",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>AMTAIR</span>"
    ]
  },
  {
    "objectID": "chapters/AMTAIR.html#sec-results",
    "href": "chapters/AMTAIR.html#sec-results",
    "title": "3  AMTAIR",
    "section": "3.3 Results",
    "text": "3.3 Results\n\n3.3.1 Extraction Quality Assessment\n\n\n\nEvaluation of extraction quality compared automated AMTAIR results against manual expert annotation, revealing both capabilities and limitations of the approach. Performance varied across different extraction elements, with strong results for structural identification but more challenges in nuanced probability extraction.\n\n`Quantitative assessment showed:\n\nEntity identification: 92% precision, 87% recall\nRelationship extraction: 83% precision, 79% recall\nProbability estimation: 75% precision, 68% recall\nOverall F1 score: 0.81 across all extraction types\n\nQualitative analysis identified:\n\nStrengths in structural extraction and explicit relationships\nChallenges with implicit assumptions and complex conditionals\nVariation across different source document styles\nComplementarity with expert review processes`\n\n\n\n3.3.2 Computational Performance Analysis\n\n\n\nAMTAIR’s computational performance was benchmarked across networks of varying size and complexity to understand scalability characteristics and resource requirements. Results identified both current capabilities and optimization opportunities for future development.\n\n`Performance analysis revealed:\n\nLinear scaling for extraction and parsing stages\nExponential complexity challenges for exact inference in large networks\nVisualization rendering bottlenecks for networks &gt;50 nodes\nEffective approximation methods for maintaining interactive performance\n\nBenchmark results for complete pipeline:\n\nSmall networks (5-10 nodes): &lt; 3 seconds end-to-end\nMedium networks (10-50 nodes): 5-30 seconds\nLarge networks (50+ nodes): 45+ seconds, requiring optimization`\n\n\n\n3.3.3 Case Study: The Carlsmith Model Formalized\n\n\nThe formalization of Carlsmith’s power-seeking AI risk model demonstrates AMTAIR’s ability to capture complex real-world arguments. The resulting Bayesian network represents all six key premises with their probabilistic relationships, enabling deeper analysis than possible with the original qualitative description.\n\n`The formalized model reveals:\n\n21 distinct variables capturing main premises and sub-components\n27 directional relationships representing causal connections\nFull specification of conditional probability tables\nIdentification of implicit assumptions in the original argument\nAggregate risk calculation matching Carlsmith’s ~5% estimate`\n\n\n\n\n\n\n\nFigure 3.1: Formalized Carlsmith Model\n\n\n\n\n\n3.3.4 Comparative Analysis of AI Governance Worldviews\n\n\n\nBy applying AMTAIR to multiple prominent AI governance perspectives, structural similarities and differences between worldviews become explicit. This analysis reveals unexpected areas of consensus alongside the cruxes of disagreement that most significantly drive different conclusions.\n\n`Comparative analysis identified:\n\nCommon causal structures across technical and governance communities\nShared variables but divergent probability assessments\nCritical cruxes centering on alignment difficulty and capability development\nAreas of consensus on the need for improved coordination\n\nCross-perspective visualization revealed:\n\nShared concern about instrumental convergence\nDivergence on governance efficacy expectations\nDifferent weighting of accident vs. misuse scenarios\nVarying timelines for advanced capability development`\n\n\n\n3.3.5 Policy Impact Evaluation: Proof of Concept\n\n\n\nThe policy impact evaluation capability demonstrates how formal modeling clarifies the conditions under which specific governance interventions would be effective. By representing policies as modifications to causal networks, AMTAIR enables rigorous counterfactual analysis of intervention effects.\n\n`Policy evaluation results showed:\n\nDifferential effectiveness of compute governance across worldviews\nRobustness of safety standards interventions to parameter uncertainty\nCritical dependencies for international coordination success\nComplementary effects of combined policy portfolios\n\nSensitivity analysis revealed:\n\nKey uncertain parameters driving intervention outcomes\nThreshold conditions for policy effectiveness\nRobustness characteristics across scenarios\nImplementation factors critical for success`\n\npost text",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>AMTAIR</span>"
    ]
  },
  {
    "objectID": "chapters/Discussion.html",
    "href": "chapters/Discussion.html",
    "title": "4  Discussion",
    "section": "",
    "text": "5 Discussion — Exchange, Controversy & Influence",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Discussion</span>"
    ]
  },
  {
    "objectID": "chapters/Discussion.html#sec-red-teaming",
    "href": "chapters/Discussion.html#sec-red-teaming",
    "title": "4  Discussion",
    "section": "5.1 Red-Teaming Results: Identifying Failure Modes",
    "text": "5.1 Red-Teaming Results: Identifying Failure Modes\n\n\n\nSystematic red-teaming identified potential failure modes across the AMTAIR pipeline, from extraction biases to visualization misinterpretations. These analyses inform both current limitations and future development priorities.\n\n`Key failure categories included:\n\nExtraction failures misrepresenting complex arguments\nModel inadequacies from missing causal factors\nInference challenges with rare event probabilities\nPractical deployment risks including misinterpretation\n\nFor each failure mode, mitigations were developed:\n\nImproved extraction prompts for challenging cases\nHybrid human-AI workflow for critical arguments\nExplicit uncertainty representation in outputs\nUser interface improvements for clearer interpretation`",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Discussion</span>"
    ]
  },
  {
    "objectID": "chapters/Discussion.html#sec-epistemic-security",
    "href": "chapters/Discussion.html#sec-epistemic-security",
    "title": "4  Discussion",
    "section": "5.2 Enhancing Epistemic Security in AI Governance",
    "text": "5.2 Enhancing Epistemic Security in AI Governance\n\n\nAMTAIR’s formalization approach enhances epistemic security in AI governance by making implicit models explicit, revealing assumptions, and enabling more productive discourse across different perspectives. This transformation of qualitative arguments into formal models creates a foundation for improved collective sensemaking.\n\n`Direct benefits include:\n\nExplicit representation of uncertainty through probability distributions\nClear identification of genuine vs. terminological disagreements\nPrecise tracking of belief updating as new evidence emerges\nObjective identification of critical uncertainties\n\nCommunity-level effects include:\n\nShared vocabulary for discussing probabilities\nImproved focus on cruxes rather than peripheral disagreements\nEnhanced ability to integrate diverse perspectives\nMore effective prioritization of research questions`",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Discussion</span>"
    ]
  },
  {
    "objectID": "chapters/Discussion.html#sec-scaling-challenges",
    "href": "chapters/Discussion.html#sec-scaling-challenges",
    "title": "4  Discussion",
    "section": "5.3 Scaling Challenges and Opportunities",
    "text": "5.3 Scaling Challenges and Opportunities\n\n\n\nScaling AMTAIR to handle more content, greater complexity, and broader application domains presents both challenges and opportunities. Technical limitations interact with organizational and adoption considerations to shape the pathway to wider impact.\n\n`Technical scaling challenges include:\n\nComputational complexity for very large networks\nData quality variation across source materials\nInterface usability for complex models\nIntegration complexity with multiple platforms\n\nOrganizational considerations include:\n\nCoordination mechanisms for distributed development\nQuality assurance processes\nKnowledge management requirements\nStakeholder engagement strategies\n\nPromising opportunities include:\n\nImproved extraction techniques using next-generation LLMs\nMore sophisticated visualization approaches\nEnhanced inference algorithms\nDeeper integration with governance processes`",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Discussion</span>"
    ]
  },
  {
    "objectID": "chapters/Discussion.html#sec-integration",
    "href": "chapters/Discussion.html#sec-integration",
    "title": "4  Discussion",
    "section": "5.4 Integration with Existing Governance Frameworks",
    "text": "5.4 Integration with Existing Governance Frameworks\n\n\nRather than replacing existing governance approaches, AMTAIR complements and enhances them by providing formal analytical capabilities that can strengthen decision-making. Integration with current frameworks presents both opportunities and challenges.\n\n`Integration opportunities include:\n\nEnhancing impact assessment methodologies\nSupporting standards development with formal evaluation\nInforming regulatory design with counterfactual analysis\nFacilitating international coordination through shared models\n\nPractical applications include:\n\nStructured reasoning about governance proposals\nComparison of regulatory approaches\nAnalysis of standard effectiveness\nIdentification of governance gaps\n\nImplementation pathways include:\n\nTool adoption by key organizations\nIntegration with existing workflows\nTraining programs for governance analysts\nProgressive enhancement of current processes`",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Discussion</span>"
    ]
  },
  {
    "objectID": "chapters/Discussion.html#sec-deep-uncertainties",
    "href": "chapters/Discussion.html#sec-deep-uncertainties",
    "title": "4  Discussion",
    "section": "5.5 Known Unknowns and Deep Uncertainties",
    "text": "5.5 Known Unknowns and Deep Uncertainties\n\n\n\nWhile AMTAIR enhances our ability to reason under uncertainty, fundamental limitations remain—particularly concerning truly novel or unprecedented developments in AI that might fall outside existing conceptual frameworks. Acknowledgment of these limitations is essential for responsible use.\n\n`Fundamental limitations include:\n\nNovel capabilities outside historical patterns\nUnprecedented social and economic impacts\nEmergent behaviors in complex systems\nFundamental unpredictability of technological development\n\nAdaptation strategies include:\n\nFlexible model architectures accommodating new variables\nRegular updates from expert input\nExplicit confidence level indication\nAlternative model formulations\n\nDecision principles for deep uncertainty include:\n\nRobust strategies across model variants\nAdaptive approaches with learning mechanisms\nPreservation of option value\nExplicit value of information calculations`",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Discussion</span>"
    ]
  },
  {
    "objectID": "chapters/Conclusion.html",
    "href": "chapters/Conclusion.html",
    "title": "5  Conclusion",
    "section": "",
    "text": "6 Conclusion",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "chapters/Conclusion.html#sec-key-contributions",
    "href": "chapters/Conclusion.html#sec-key-contributions",
    "title": "5  Conclusion",
    "section": "6.1 Key Contributions and Findings",
    "text": "6.1 Key Contributions and Findings\n\n\nAMTAIR makes several key contributions to both the theoretical understanding of AI risk modeling and the practical tooling available for AI governance. These advances demonstrate how computational approaches can help address the coordination crisis in AI safety.\n\n`Methodological innovations include:\n\nBayesDown as an intermediate representation bridging natural language and Bayesian networks\nTwo-stage extraction pipeline separating structure from probability\nCross-worldview comparison methodology\nInteractive visualization approach for complex probabilistic relationships\n\nTechnical contributions include:\n\nWorking prototype demonstrating extraction feasibility\nInteractive visualization making complex models accessible\nIntegration capabilities with forecasting platforms\nPolicy evaluation framework for intervention assessment\n\nEmpirical findings include:\n\nExtraction quality assessments showing viability of automation\nComparative analyses revealing key cruxes across perspectives\nPolicy evaluations demonstrating formal modeling benefits\nPerformance benchmarks guiding future development`",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "chapters/Conclusion.html#sec-limitations",
    "href": "chapters/Conclusion.html#sec-limitations",
    "title": "5  Conclusion",
    "section": "6.2 Limitations of the Current Implementation",
    "text": "6.2 Limitations of the Current Implementation\n\n\nWhile AMTAIR demonstrates the feasibility of automated extraction and formalization, significant limitations remain in the current implementation. Some represent fundamental challenges in modeling complex domains, while others are implementation constraints that future work can address.\n\n`Technical constraints include:\n\nExtraction quality boundaries for complex arguments\nComputational complexity barriers for very large networks\nInterface sophistication limits\nUpdate frequency constraints\n\nConceptual limitations include:\n\nSimplifications inherent in causal models\nChallenges representing complex dynamic processes\nDifficulties with unprecedented scenarios\nValue assumptions embedded in model structures\n\nFuture work can address:\n\nExtraction quality through improved prompting and validation\nComputational efficiency through optimized algorithms\nInterface sophistication through advanced visualization\nUpdate mechanisms through deeper platform integration`",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "chapters/Conclusion.html#sec-policy-implications",
    "href": "chapters/Conclusion.html#sec-policy-implications",
    "title": "5  Conclusion",
    "section": "6.3 Policy Implications and Recommendations",
    "text": "6.3 Policy Implications and Recommendations\n\n\nAMTAIR’s approach has significant implications for how AI governance could evolve toward more rigorous, transparent, and effective practices. By making implicit models explicit and enabling formal policy evaluation, the system supports evidence-based governance development.\n\n`General implications include:\n\nValue of formal modeling for policy development\nImportance of explicit uncertainty representation\nBenefits of structured worldview comparison\nAdvantages of conditional policy framing\n\nSpecific recommendations include:\n\nDevelopment of formal impact assessment protocols\nCreation of shared model repositories\nIntegration of forecasting with policy evaluation\nTraining in formal modeling for governance analysts\n\nImplementation pathways include:\n\nIntegration with existing processes\nAdoption by key organizations\nTraining and capacity building\nProgressive enhancement of current approaches`",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "chapters/Conclusion.html#sec-future-research",
    "href": "chapters/Conclusion.html#sec-future-research",
    "title": "5  Conclusion",
    "section": "6.4 Future Research Directions",
    "text": "6.4 Future Research Directions\n\n\nBuilding on AMTAIR’s foundation, several promising research directions could further enhance the approach’s capabilities, applications, and impact. These range from technical improvements to expanded use cases and deeper integration with governance processes.\n\n`Technical enhancements include:\n\nAdvanced extraction algorithms leveraging next-generation LLMs\nMore sophisticated visualization techniques\nImproved inference methods for complex networks\nEnhanced prediction market integration\n\nApplication expansions include:\n\nExtension to other existential risks\nApplication to broader policy challenges\nIntegration with other governance tools\nAdaptation for organizational decision-making\n\nTheoretical extensions include:\n\nAdvanced uncertainty representation\nDeeper integration with decision theory\nFormal frameworks for worldview comparison\nEnhanced modeling of dynamic processes`",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "chapters/Conclusion.html#sec-concluding-reflections",
    "href": "chapters/Conclusion.html#sec-concluding-reflections",
    "title": "5  Conclusion",
    "section": "6.5 Concluding Reflections",
    "text": "6.5 Concluding Reflections\n\n\nAt its core, this work represents a bet that the epistemic challenges in AI governance are not merely incidental but structural—and that addressing them requires not just more conversation but better tools for collective sensemaking. The stakes of this bet could hardly be higher, as coordinating our response to increasingly powerful AI systems may well determine humanity’s long-term future.\n\n`AMTAIR contributes to this coordination challenge by:\n\nMaking implicit models explicit\nRevealing genuine points of disagreement\nEnabling rigorous evaluation of interventions\nSupporting exploration across possible futures\nCreating common ground for diverse stakeholders\n\nUltimately, the project aims to transform how we think about AI governance—not by providing definitive answers, but by improving the quality of our questions, the rigor of our reasoning, and the clarity of our communication. In a domain characterized by deep uncertainty and rapid change, such epistemic foundations may be our most valuable resource.`",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "chapters/Frontmatter.html",
    "href": "chapters/Frontmatter.html",
    "title": "Frontmatter",
    "section": "",
    "text": "Acknowledgments",
    "crumbs": [
      "Frontmatter"
    ]
  },
  {
    "objectID": "chapters/Frontmatter.html#list-of-tables",
    "href": "chapters/Frontmatter.html#list-of-tables",
    "title": "Frontmatter",
    "section": "List of Tables",
    "text": "List of Tables\nTable 1: Table name\nTable 2: Table name\nTable 3: Table name\n\nFigure 1.1: The coordination crisis in AI governance - visualization of fragmentation\n\nFigure 2.1: The Carlsmith model - DAG representation\n\nFigure 3.1: Research design overview - workflow diagram\n\nFigure 3.2: From natural language to BayesDown - transformation process\n\nFigure 4.1: ARPA system architecture - component diagram\n\nFigure 4.2: Visualization of Rain-Sprinkler-Grass_Wet Bayesian network - screenshot\n\nFigure 5.1: Extraction quality metrics - comparative chart\n\nFigure 5.2: Comparative analysis of AI governance worldviews - network visualization\n\nTable 2.1: Comparison of approaches to AI risk modeling\n\nTable 3.1: Probabilistic translation guide for qualitative expressions\n\nTable 4.1: System component responsibilities and interactions\n\nTable 5.1: Policy impact evaluation results - summary metrics",
    "crumbs": [
      "Frontmatter"
    ]
  },
  {
    "objectID": "chapters/Frontmatter.html#list-of-graphics-figures",
    "href": "chapters/Frontmatter.html#list-of-graphics-figures",
    "title": "Frontmatter",
    "section": "List of Graphics & Figures",
    "text": "List of Graphics & Figures",
    "crumbs": [
      "Frontmatter"
    ]
  },
  {
    "objectID": "chapters/Frontmatter.html#list-of-abbreviations",
    "href": "chapters/Frontmatter.html#list-of-abbreviations",
    "title": "Frontmatter",
    "section": "List of Abbreviations",
    "text": "List of Abbreviations\nesp. especially\nf., ff. following\nincl. including\np., pp. page(s)\nMAD Mutually Assured Destruction\n\nAI - Artificial Intelligence\n\nAGI - Artificial General Intelligence\n\nARPA - AI Risk Pathway Analyzer\n\nDAG - Directed Acyclic Graph\n\nLLM - Large Language Model\n\nMTAIR - Modeling Transformative AI Risks\n\nP(Doom) - Probability of existential catastrophe from misaligned AI\n\nCPT - Conditional Probability Table",
    "crumbs": [
      "Frontmatter"
    ]
  },
  {
    "objectID": "chapters/Frontmatter.html#glossary",
    "href": "chapters/Frontmatter.html#glossary",
    "title": "Frontmatter",
    "section": "Glossary",
    "text": "Glossary\n\nArgument mapping: A method for visually representing the structure of arguments\n\nBayesDown: An extension of ArgDown that incorporates probabilistic information\n\nBayesian network: A probabilistic graphical model representing variables and their dependencies\n\nConditional probability: The probability of an event given that another event has occurred\n\nDirected Acyclic Graph (DAG): A graph with directed edges and no cycles\n\nExistential risk: Risk of permanent curtailment of humanity’s potential\n\nPower-seeking AI: AI systems with instrumental incentives to acquire resources and power\n\nPrediction market: A market where participants trade contracts that resolve based on future events\n\nd-separation: A criterion for identifying conditional independence relationships in Bayesian networks\n\nMonte Carlo sampling: A computational technique using random sampling to obtain numerical results",
    "crumbs": [
      "Frontmatter"
    ]
  },
  {
    "objectID": "chapters/Frontmatter.html#checklists",
    "href": "chapters/Frontmatter.html#checklists",
    "title": "Frontmatter",
    "section": "Checklists ",
    "text": "Checklists",
    "crumbs": [
      "Frontmatter"
    ]
  },
  {
    "objectID": "chapters/Frontmatter.html#usual-paper-requirements",
    "href": "chapters/Frontmatter.html#usual-paper-requirements",
    "title": "Frontmatter",
    "section": "“Usual paper requirements”",
    "text": "“Usual paper requirements”\n\nintroduce all terminology\n\ngo through text, make sure all terms are defined, explained (and added to the list of Abbr.) when first mentioned\n\n\nreadership is intelligent and interested but has no prior knowledge",
    "crumbs": [
      "Frontmatter"
    ]
  },
  {
    "objectID": "chapters/Frontmatter.html#format-anything-that-makes-it-easier-to-understand",
    "href": "chapters/Frontmatter.html#format-anything-that-makes-it-easier-to-understand",
    "title": "Frontmatter",
    "section": "(Format:) ~ Anything that makes it easier to understand",
    "text": "(Format:) ~ Anything that makes it easier to understand\n\nshort sentences\n\nparagraphs (one idea per paragraph)\n\nsimplicity\n\n!limit use of passive voice!\n\nuse active voice, even prefer I over we!\n\nminimise use of “zombi nouns” (don’t turn verbs/adjectives to nouns!)\n\n“find words that can be cut”\n\n– the paper can focus on one aspect of the presentation\n– “open door policy” for (content) questions\n~ demonstrate ability for novel research\n– “solve research question with the tools accessible to you”\n– “show something that has not been shown before / should be publishable in principle”\n– new idea (or criticism) “in this field”\n– Outline idea THEN reading with a purpose (answering concrete questions)\n– “Only” confirm that nobody has published the exact same idea on the same topic\n– pretty much determined by presentation & proposal but narrow down further (& choose supervisor?)\n\nQuarto Features Incompatible with LaTeX (Below)",
    "crumbs": [
      "Frontmatter"
    ]
  },
  {
    "objectID": "ref/references.html",
    "href": "ref/references.html",
    "title": "6  Quarto Syntax",
    "section": "",
    "text": "Figures\nTesting crossreferencing grapics Figure 6.1.\nTesting crossreferencing grapics Figure 6.2.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quarto Syntax</span>"
    ]
  },
  {
    "objectID": "ref/references.html#sec-figues",
    "href": "ref/references.html#sec-figues",
    "title": "6  Quarto Syntax",
    "section": "",
    "text": "Figure 6.1: AMTAIR Automation Pipeline from Bucknall and Dori-Hacohen (2022)\n\n\n\n\n\n\n\n\n\n\nFigure 6.2: Caption/Title 2",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quarto Syntax</span>"
    ]
  },
  {
    "objectID": "ref/references.html#sec-citations",
    "href": "ref/references.html#sec-citations",
    "title": "6  Quarto Syntax",
    "section": "Citations",
    "text": "Citations\nSoares and Fallenstein (2014) \n(Soares and Fallenstein 2014) and (Knuth 1984)\nBlah Blah (see Knuth 1984, 33–35; also Growiec 2024, chap. 1)\nBlah Blah (Knuth 1984, 33–35, 38–39 and passim)\nBlah Blah (Growiec 2024; Knuth 1984).\nGrowiec says blah (2024)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quarto Syntax</span>"
    ]
  },
  {
    "objectID": "ref/references.html#sec-heading",
    "href": "ref/references.html#sec-heading",
    "title": "6  Quarto Syntax",
    "section": "6.1 Headings & Potential Headings",
    "text": "6.1 Headings & Potential Headings\n\n\nverbatim code formatting for notes and ideas to be included (here)\nAlso code blocks for more extensive notes and ideas to be included and checklists\n- test 1. \n- test 2. \n- test 3.\n2. second\n3. third\n\n\nBlockquote formatting for “Suggested Citations (e.g. carlsmith 2024 on …)” and/or claims which require a citation (e.g. claim x should be backed-up by a ciation from the literature)\n\nHere is an inline note.1\nHere is a footnote reference,2\nHere’s some raw inline HTML: html\npage 1\n\npage 2\n\n\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\n\n\nTesting crossreferencing grapics Figure 6.1.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quarto Syntax</span>"
    ]
  },
  {
    "objectID": "ref/references.html#footnotes",
    "href": "ref/references.html#footnotes",
    "title": "6  Quarto Syntax",
    "section": "",
    "text": "Inlines notes are easier to write, since you don’t have to pick an identifier and move down to type the note.↩︎\nHere is the footnote.↩︎",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Quarto Syntax</span>"
    ]
  },
  {
    "objectID": "chapters/Appendices.html",
    "href": "chapters/Appendices.html",
    "title": "Appendix A — Appendices",
    "section": "",
    "text": "Appendices",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Appendices</span>"
    ]
  },
  {
    "objectID": "chapters/Appendices.html#sec-appendix-technical",
    "href": "chapters/Appendices.html#sec-appendix-technical",
    "title": "Appendix A — Appendices",
    "section": "Appendix A: Technical Implementation Details",
    "text": "Appendix A: Technical Implementation Details",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Appendices</span>"
    ]
  },
  {
    "objectID": "chapters/Appendices.html#sec-appendix-validation",
    "href": "chapters/Appendices.html#sec-appendix-validation",
    "title": "Appendix A — Appendices",
    "section": "Appendix B: Model Validation Procedures",
    "text": "Appendix B: Model Validation Procedures",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Appendices</span>"
    ]
  },
  {
    "objectID": "chapters/Appendices.html#sec-appendix-case-studies",
    "href": "chapters/Appendices.html#sec-appendix-case-studies",
    "title": "Appendix A — Appendices",
    "section": "Appendix C: Case Studies",
    "text": "Appendix C: Case Studies",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Appendices</span>"
    ]
  },
  {
    "objectID": "chapters/Appendices.html#sec-appendix-ethical",
    "href": "chapters/Appendices.html#sec-appendix-ethical",
    "title": "Appendix A — Appendices",
    "section": "Appendix D: Ethical Considerations",
    "text": "Appendix D: Ethical Considerations",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Appendices</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html",
    "href": "chapters/appendixA.html",
    "title": "Appendix B — appendixA",
    "section": "",
    "text": "testtext",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>appendixA</span>"
    ]
  }
]