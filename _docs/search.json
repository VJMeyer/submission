[
  {
    "objectID": "chapters/intro.html",
    "href": "chapters/intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Quarto\nThis is a booooook created from markdown and executable code.\nSee (Knuth 1984) and Knuth (1984) for additional discussion of literate programming.\nRegular markdown and \\(E=mc^2\\) equations.\n\\[\\begin{align}\na &= b + c \\\\\nd &= e * f\n\\end{align}\\]\nQuarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/intro.html#running-code",
    "href": "chapters/intro.html#running-code",
    "title": "1  Introduction",
    "section": "1.2 Running Code",
    "text": "1.2 Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n\nCode\n1 + 1\n\n\n2\n\n\nYou can add options to executable code like this\n\n\n4\n\n\nThe echo: false option disables the printing of code (only output is displayed).\nMore markdown.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/summary.html",
    "href": "chapters/summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n\nCode\n1 + 1\n\n\n[1] 2\n\n\n\n3 Explore Earthquakes\nCharlotte Wickham\nRead a clean version of data:\nCreate spatial plot:\n\n\n\n\n\n\n\n\nFigure 3.1: Locations of earthquakes on La Palma since 2017",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "article/ref/references.html",
    "href": "article/ref/references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Computer\nJournal 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Automating the Modelling of Transformative Artificial Intelligence Risks",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n\nCode\n1 + 1\n\n\n2",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "chapters/appendixA.html",
    "href": "chapters/appendixA.html",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "",
    "text": "8.6.2 3.3 Data-Post-Processing\n:::\nAdd rows to data frame that can be calculated from the extracted rows\nEnhanced DataFrame with additional calculated columns:\n\nJoint Probabilities Example:\nJoint probabilities for Existential_Catastrophe:\nNone\n\nNetwork Metrics:\nExistential_Catastrophe:\n  Degree Centrality: 0.000\n  Betweenness Centrality: 0.000\nHuman_Disempowerment:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nScale_Of_Power_Seeking:\n  Degree Centrality: 0.136\n  Betweenness Centrality: 0.037\nMisaligned_Power_Seeking:\n  Degree Centrality: 0.182\n  Betweenness Centrality: 0.056\nAPS_Systems:\n  Degree Centrality: 0.182\n  Betweenness Centrality: 0.019\nAdvanced_AI_Capability:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nAgentic_Planning:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nStrategic_Awareness:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nDifficulty_Of_Alignment:\n  Degree Centrality: 0.182\n  Betweenness Centrality: 0.019\nInstrumental_Convergence:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nProblems_With_Proxies:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nProblems_With_Search:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nDeployment_Decisions:\n  Degree Centrality: 0.136\n  Betweenness Centrality: 0.026\nIncentives_To_Build_APS:\n  Degree Centrality: 0.136\n  Betweenness Centrality: 0.017\nUsefulness_Of_APS:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nCompetitive_Dynamics:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nDeception_By_AI:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nCorrective_Feedback:\n  Degree Centrality: 0.136\n  Betweenness Centrality: 0.009\nWarning_Shots:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nRapid_Capability_Escalation:\n  Degree Centrality: 0.045\n  Betweenness Centrality: 0.000\nBarriers_To_Understanding:\n  Degree Centrality: 0.000\n  Betweenness Centrality: 0.000\nAdversarial_Dynamics:\n  Degree Centrality: 0.000\n  Betweenness Centrality: 0.000\nStakes_Of_Error:\n  Degree Centrality: 0.000\n  Betweenness Centrality: 0.000\n\nEnhanced data saved to 'enhanced_extracted_data.csv'",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#executive-summary",
    "href": "chapters/appendixA.html#executive-summary",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "2.1 Executive Summary",
    "text": "2.1 Executive Summary\nThis notebook implements a prototype of the AMTAIR (Automating Transformative AI Risk Modeling) project, which addresses the critical coordination failure in AI governance by developing computational tools that automate the extraction of probabilistic world models from AI safety literature.\nThe prototype demonstrates the transformation pipeline from structured argument representations (ArgDown) to probabilistic Bayesian networks (BayesDown), enabling the visualization and analysis of causal relationships and probability distributions that underlie AI risk assessments and policy evaluations.\n\n2.1.1 Purpose Within the Master’s Thesis\nThis notebook serves as the technical implementation component of the Master’s thesis “Automating Transformative AI Risk Modeling: A Computational Approach to Policy Impact Evaluation.” It demonstrates the feasibility of automating the extraction and formalization of world models, focusing on the core extraction pipeline and visualization capabilities that form the foundation for more sophisticated analysis.\n\n\n2.1.2 Relevance to AI Governance\nThe coordination crisis in AI governance stems from different stakeholders working with incompatible assumptions, terminologies, and priorities. By making implicit models explicit through automated extraction and formalization, this work helps bridge communication gaps between technical researchers, policy specialists, and other stakeholders, contributing to more effective coordination in addressing existential risks from advanced AI.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#notebook-structure-and-workflow",
    "href": "chapters/appendixA.html#notebook-structure-and-workflow",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "2.2 Notebook Structure and Workflow",
    "text": "2.2 Notebook Structure and Workflow\nThis notebook implements a multi-stage pipeline for transforming argument structures into interactive Bayesian network visualizations:\n\nEnvironment Setup (Sections 0.1-0.3): Establishes the technical environment with necessary libraries and data connections\nArgument Extraction (Sections 1.0-1.8): Processes source documents into structured ArgDown representations\nProbability Integration (Sections 2.0-2.8): Enhances ArgDown with probability information to create BayesDown\nData Transformation (Section 3.0): Converts BayesDown into structured DataFrame format\nVisualization and Analysis (Section 4.0): Creates interactive Bayesian network visualizations\nArchiving and Export (Sections 5.0-6.0): Provides utilities for saving and sharing results\n\nThroughout this notebook, we use the classic rain-sprinkler-lawn example as a canonical test case, demonstrating how a simple causal scenario (rain and sprinkler use affecting wet grass) can be represented, processed, and visualized using our automated pipeline.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#project-context-and-purpose",
    "href": "chapters/appendixA.html#project-context-and-purpose",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "2.3 Project Context and Purpose",
    "text": "2.3 Project Context and Purpose\nThis notebook implements a prototype of the Automating Transformative AI Risk Modeling (AMTAIR) project, which addresses a critical coordination failure in AI governance by developing computational tools to automate the extraction of probabilistic world models from AI safety literature.\nThe coordination crisis in AI governance stems from different stakeholders (technical researchers, policy specialists, ethicists) operating with different terminologies, priorities, and implicit theories of change. This fragmentation systematically increases existential risk through safety gaps, resource misallocation, and capability-governance mismatches.\nThe AMTAIR project aims to bridge these divides by: 1. Making implicit models explicit through automated extraction and formalization 2. Enabling comparison across different worldviews 3. Providing a common language for discussing probabilistic relationships 4. Supporting policy evaluation across diverse scenarios",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#notebook-overview-and-pipeline",
    "href": "chapters/appendixA.html#notebook-overview-and-pipeline",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "2.4 Notebook Overview and Pipeline",
    "text": "2.4 Notebook Overview and Pipeline\nThis notebook demonstrates the core extraction pipeline from structured argument representations (ArgDown) to probabilistic Bayesian networks (BayesDown), using the classic rain-sprinkler-lawn example as a canonical test case.\nThe pipeline consists of five main stages: 1. Environment Setup: Libraries, GitHub repository access, and data loading 2. Argument Extraction: Processing source documents into structured ArgDown format 3. Probability Integration: Enhancing ArgDown with probabilistic information to create BayesDown 4. Data Transformation: Converting BayesDown into structured DataFrame format 5. Visualization & Analysis: Creating interactive Bayesian network visualizations",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#connection-to-masters-thesis",
    "href": "chapters/appendixA.html#connection-to-masters-thesis",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "2.5 Connection to Master’s Thesis",
    "text": "2.5 Connection to Master’s Thesis\nThis notebook serves as the technical implementation component of the Master’s thesis “Automating Transformative AI Risk Modeling: A Computational Approach to Policy Impact Evaluation” (see PY_Thesis_OutlineNDraft), demonstrating the feasibility of automating the process of extracting and formalizing world models from AI safety literature.\nThe thesis positions this work as a solution to the coordination crisis in AI governance, where the AMTAIR tools provide a crucial bridge between different stakeholder communities by creating formal representations that can be analyzed, compared, and used for policy evaluation.\nFor broader context on the project’s motivation and placement within AI governance efforts, see PY_Post0.0 (“The Missing Piece: Why We Need a Grand Strategy for AI”) and PY_AMTAIRDescription, which explain how this technical work contributes to the development of a comprehensive AI safety grand strategy.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#instructions-how-to-use-this-notebook",
    "href": "chapters/appendixA.html#instructions-how-to-use-this-notebook",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "2.6 Instructions — How to use this notebook:",
    "text": "2.6 Instructions — How to use this notebook:\n\nImport Libraries & Install Packages: Run Section 0.1 to set up the necessary dependencies for data processing and visualization.\nConnect to GitHub Repository & Load Data files: Run Section 0.2 to establish connections to the data repository and load example datasets. This step retrieves sample ArgDown files and extracted data for demonstration.\nProcess Source Documents to ArgDown: Sections 1.0-1.8 demonstrate the extraction of argument structures from source documents (such as PDFs) into ArgDown format, a markdown-like notation for structured arguments.\nConvert ArgDown to BayesDown: Sections 2.0-2.3 handle the transformation of ArgDown files into BayesDown format, which incorporates probabilistic information into the argument structure.\nExtract Data into Structured Format: Section 3.0 processes BayesDown format into structured database entries (CSV) that can be used for analysis.\nCreate and Analyze Bayesian Networks: Section 4.0 demonstrates how to build Bayesian networks from the extracted data and provides tools for analyzing risk pathways.\nSave and Export Results: Sections 5.0-6.0 provide methods for archiving results and exporting visualizations.\n\n\nAMTAIR Prototype Demonstration (Public Colab Notebook)\n\n\nAMTAIR Prototype: Automating Transformative AI Risk Modeling\n\n\n\nExecutive Summary\n\n\n\n\n\nPurpose Within the Master’s Thesis\n\n\n\n\n\n\nRelevance to AI Governance\n\n\n\n\n\nNotebook Structure and Workflow\n\n\n\n\nProject Context and Purpose\n\n\n\n\nNotebook Overview and Pipeline\n\n\n\n\nConnection to Master’s Thesis\n\n\n\n\nInstructions — How to use this notebook:\n\n\n\n\nKey Concepts:\n\n\n\n\nExample Workflow:\n\n\n\n\nTroubleshooting:\n\n\n\nEnvironment Setup and Data Access\n\n\n0.1 Prepare Colab/Python Environment — Import Libraries & Packages\n\n\n\n0.2 Connect to GitHub Repository\n\n\n\n\n0.3 File Import\n\n\n\n1.0 Sources (PDF’s of Papers) to ArgDown (.md file)\n\n\nSources to ArgDown: Structured Argument Extraction\n\n\n\nProcess Overview\n\n\n\n\nWhat is ArgDown?\n\n\n\n\n1.1 Specify Source Document (e.g. PDF)\n\n\n\n\n1.2 Generate ArgDown Extraction Prompt\n\n\n\n\n1.3 Prepare LLM API Call\n\n\n\n\n1.4 Make ArgDown Extraction LLM API Call\n\n\n\n\n1.5 Save ArgDown Extraction Response\n\n\n\n\n1.6 Review and Check ArgDown.md File\n\n\n\n\n1.6.2 Check the Graph Structure with the ArgDown Sandbox Online\n\n\n\n\n1.7 Extract ArgDown Graph Information as DataFrame\n\n\n\n\n1.8 Store ArgDown Information as ‘ArgDown.csv’ file\n\n\n\n2.0 Probability Extractions: ArgDown (.csv) to BayesDown (.md + plugin JSON syntax)\n\n\nArgDown to BayesDown: Adding Probability Information\n\n\n\nProcess Overview\n\n\n\n\nWhat is BayesDown?\n\n\n\n\n2.1 Probability Extraction Questions — ‘ArgDown.csv’ to ‘ArgDown_WithQuestions.csv’\n\n\n\n\n2.2 ‘ArgDown_WithQuestions.csv’ to ‘BayesDownQuestions.md’\n\n\n\n\n2.3 Generate BayesDown Probability Extraction Prompt\n\n\n\n\n2.3.1 BayesDown Format Specification\n\n\n\n\n\nCore Structure\n\n\n\n\n\n\n\n\nRain-Sprinkler-Lawn Example\n\n\n\n\n\n\n\n2.4 Prepare 2nd API call\n\n\n\n\n2.5 Make BayesDown Probability Extraction API Call\n\n\n\n\n2.6 Save BayesDown with Probability Estimates (.csv)\n\n\n\n\n2.7 Review & Verify BayesDown Probability Estimates\n\n\n\n\n2.7.2 Check the Graph Structure with the ArgDown Sandbox Online\n\n\n\n\n2.8 Extract BayesDown with Probability Estimates as Dataframe\n\n\n\n3.0 Data Extraction: BayesDown (.md) to Database (.csv)\n\n\nBayesDown to Structured Data: Network Construction\n\n\n\nExtraction Pipeline Overview\n\n\n\n\n\nTheoretical Foundation\n\n\n\n\n\n\nRole in Thesis Research\n\n\n\n\n\n\n3.1 ExtractBayesDown-Data_v1\n\n\n\n\n\n3.1.2 Test BayesDown Extraction\n\n\n\n\n3.1.2.2 Check the Graph Structure with the ArgDown Sandbox Online\n\n\n\n\n3.3 Extraction\n\n\n\n\n\n3.3 Data-Post-Processing\n\n\n\n\n\n\n3.4 Download and save finished data frame as .csv file\n\n\n\n\nAnalysis & Inference: Bayesian Network Visualization\n\n\n\nBayesian Network Visualization Approach\n\n\n\n\n\nVisualization Philosophy\n\n\n\n\n\n\nConnection to AMTAIR Goals\n\n\n\n\n\n\nImplementation Structure\n\n\n\n\n\nPhase 1: Dependencies/Functions\n\n\n\n\nPhase 2: Node Classification and Styling Module\n\n\n\n\nPhase 3: HTML Content Generation Module\n\n\n\n\nPhase 4: Main Visualization Function\n\n\n\nQuickly check HTML Outputs\n\n\nConclusion: From Prototype to Production\n\n\n\nSummary of Achievements\n\n\n\n\nLimitations and Future Work\n\n\n\n\nConnection to AMTAIR Project\n\n\n\n6.0 Save Outputs\n\n\nSaving and Exporting Results\n\n\n\nConvert .ipynb Notebook to MarkDown",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#key-concepts",
    "href": "chapters/appendixA.html#key-concepts",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "2.7 Key Concepts:",
    "text": "2.7 Key Concepts:\n\nArgDown: A structured format for representing arguments, with hierarchical relationships between statements.\nBayesDown: An extension of ArgDown that incorporates probabilistic information, allowing for Bayesian network construction.\nExtraction Pipeline: The process of converting unstructured text to structured argument representations.\nBayesian Networks: Probabilistic graphical models that represent variables and their conditional dependencies.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#example-workflow",
    "href": "chapters/appendixA.html#example-workflow",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "2.8 Example Workflow:",
    "text": "2.8 Example Workflow:\n\nLoad a sample ArgDown file from the repository\nExtract the hierarchical structure and relationships\nAdd probabilistic information to create a BayesDown representation\nGenerate a Bayesian network visualization\nAnalyze conditional probabilities and risk pathways",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#troubleshooting",
    "href": "chapters/appendixA.html#troubleshooting",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "2.9 Troubleshooting:",
    "text": "2.9 Troubleshooting:\n\nIf connectivity issues occur, ensure you have access to the GitHub repository\nFor visualization errors, check that all required libraries are properly installed\nWhen processing custom files, ensure they follow the expected format conventions",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#connect-to-github-repository",
    "href": "chapters/appendixA.html#connect-to-github-repository",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "4.1 0.2 Connect to GitHub Repository",
    "text": "4.1 0.2 Connect to GitHub Repository\nThe Public GitHub Repo Url in use:\nhttps://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/\nNote: When encountering errors, accessing the data, try using “RAW” Urls.\n\n\nConnecting to repository: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/\nAttempting to load: https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_carlsmith/ArgDown.md\n✅ Successfully connected to repository and loaded test files.\n[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {\"instantiations\": [\"existential_catastrophe_TRUE\", \"existential_catastrophe_FALSE\"]}\n- [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {\"instantiations\": [\"human_disempowerment_TRUE\", \"human_disempowerment_FALSE\"]}\n    - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {\"instantiations\": [\"scale_of_power_seeking_TRUE\", \"scale_of_power_seeking_FALSE\"]}\n        - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n            - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {\"instantiations\": [\"aps_systems_TRUE\", \"aps_systems_FALSE\"]}\n                - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {\"instantiations\": [\"advanced_ai_capability_TRUE\", \"advanced_ai_capability_FALSE\"]}\n                - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {\"instantiations\": [\"agentic_planning_TRUE\", \"agentic_planning_FALSE\"]}\n                - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {\"instantiations\": [\"strategic_awareness_TRUE\", \"strategic_awareness_FALSE\"]}\n            - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {\"instantiations\": [\"difficulty_of_alignment_TRUE\", \"difficulty_of_alignment_FALSE\"]}\n                - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {\"instantiations\": [\"instrumental_convergence_TRUE\", \"instrumental_convergence_FALSE\"]}\n                - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {\"instantiations\": [\"problems_with_proxies_TRUE\", \"problems_with_proxies_FALSE\"]}\n                - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {\"instantiations\": [\"problems_with_search_TRUE\", \"problems_with_search_FALSE\"]}\n            - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {\"instantiations\": [\"deployment_decisions_DEPLOY\", \"deployment_decisions_WITHHOLD\"]}\n                - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {\"instantiations\": [\"incentives_to_build_aps_STRONG\", \"incentives_to_build_aps_WEAK\"]}\n                    - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {\"instantiations\": [\"usefulness_of_aps_HIGH\", \"usefulness_of_aps_LOW\"]}\n                    - [Competitive_Dynamics]: Competitive pressures between AI developers. {\"instantiations\": [\"competitive_dynamics_STRONG\", \"competitive_dynamics_WEAK\"]}\n                - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {\"instantiations\": [\"deception_by_ai_TRUE\", \"deception_by_ai_FALSE\"]}\n        - [Corrective_Feedback]: Human society implementing corrections after observing problems. {\"instantiations\": [\"corrective_feedback_EFFECTIVE\", \"corrective_feedback_INEFFECTIVE\"]}\n            - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {\"instantiations\": [\"warning_shots_OBSERVED\", \"warning_shots_UNOBSERVED\"]}\n            - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {\"instantiations\": [\"rapid_capability_escalation_TRUE\", \"rapid_capability_escalation_FALSE\"]}\n[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {\"instantiations\": [\"barriers_to_understanding_HIGH\", \"barriers_to_understanding_LOW\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {\"instantiations\": [\"adversarial_dynamics_TRUE\", \"adversarial_dynamics_FALSE\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\n[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {\"instantiations\": [\"stakes_of_error_HIGH\", \"stakes_of_error_LOW\"]}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#file-import",
    "href": "chapters/appendixA.html#file-import",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "4.2 0.3 File Import",
    "text": "4.2 0.3 File Import\n\n\n'[Existential_Catastrophe]: The destruction of humanity\\'s long-term potential due to AI systems we\\'ve lost control over. {\"instantiations\": [\"existential_catastrophe_TRUE\", \"existential_catastrophe_FALSE\"]}\\n- [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {\"instantiations\": [\"human_disempowerment_TRUE\", \"human_disempowerment_FALSE\"]}\\n    - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {\"instantiations\": [\"scale_of_power_seeking_TRUE\", \"scale_of_power_seeking_FALSE\"]}\\n        - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\\n            - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {\"instantiations\": [\"aps_systems_TRUE\", \"aps_systems_FALSE\"]}\\n                - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {\"instantiations\": [\"advanced_ai_capability_TRUE\", \"advanced_ai_capability_FALSE\"]}\\n                - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {\"instantiations\": [\"agentic_planning_TRUE\", \"agentic_planning_FALSE\"]}\\n                - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {\"instantiations\": [\"strategic_awareness_TRUE\", \"strategic_awareness_FALSE\"]}\\n            - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {\"instantiations\": [\"difficulty_of_alignment_TRUE\", \"difficulty_of_alignment_FALSE\"]}\\n                - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {\"instantiations\": [\"instrumental_convergence_TRUE\", \"instrumental_convergence_FALSE\"]}\\n                - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {\"instantiations\": [\"problems_with_proxies_TRUE\", \"problems_with_proxies_FALSE\"]}\\n                - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {\"instantiations\": [\"problems_with_search_TRUE\", \"problems_with_search_FALSE\"]}\\n            - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {\"instantiations\": [\"deployment_decisions_DEPLOY\", \"deployment_decisions_WITHHOLD\"]}\\n                - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {\"instantiations\": [\"incentives_to_build_aps_STRONG\", \"incentives_to_build_aps_WEAK\"]}\\n                    - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {\"instantiations\": [\"usefulness_of_aps_HIGH\", \"usefulness_of_aps_LOW\"]}\\n                    - [Competitive_Dynamics]: Competitive pressures between AI developers. {\"instantiations\": [\"competitive_dynamics_STRONG\", \"competitive_dynamics_WEAK\"]}\\n                - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {\"instantiations\": [\"deception_by_ai_TRUE\", \"deception_by_ai_FALSE\"]}\\n        - [Corrective_Feedback]: Human society implementing corrections after observing problems. {\"instantiations\": [\"corrective_feedback_EFFECTIVE\", \"corrective_feedback_INEFFECTIVE\"]}\\n            - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {\"instantiations\": [\"warning_shots_OBSERVED\", \"warning_shots_UNOBSERVED\"]}\\n            - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {\"instantiations\": [\"rapid_capability_escalation_TRUE\", \"rapid_capability_escalation_FALSE\"]}\\n[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {\"instantiations\": [\"barriers_to_understanding_HIGH\", \"barriers_to_understanding_LOW\"]}\\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\\n[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {\"instantiations\": [\"adversarial_dynamics_TRUE\", \"adversarial_dynamics_FALSE\"]}\\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\\n[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {\"instantiations\": [\"stakes_of_error_HIGH\", \"stakes_of_error_LOW\"]}\\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"]}\\n'",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#process-overview",
    "href": "chapters/appendixA.html#process-overview",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "6.1 Process Overview",
    "text": "6.1 Process Overview\nThis section implements the first major stage of the AMTAIR pipeline: transforming source documents (such as research papers, blog posts, or expert analyses) into structured argument representations using the ArgDown format.\nArgDown is a markdown-like notation for representing arguments in a hierarchical structure. In the context of AMTAIR, it serves as the first step toward creating formal Bayesian networks by: 1. Identifying key variables/statements in the text 2. Capturing their hierarchical relationships 3. Preserving their descriptive content 4. Defining their possible states (instantiations)\nThe extraction process uses Large Language Models (LLMs) to identify the structure and relationships in the text, though in this notebook we focus on processing pre-formatted examples rather than performing the full extraction from raw text.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#what-is-argdown",
    "href": "chapters/appendixA.html#what-is-argdown",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "6.2 What is ArgDown?",
    "text": "6.2 What is ArgDown?\nArgDown uses a simple syntax where: - Statements are represented as [Statement]: Description - Relationships are indicated with + symbols and indentation - Metadata is added in JSON format, including possible states of each variable\nFor example:\n[MainClaim]: Description of the main claim. {\"instantiations\": [\"claim_TRUE\", \"claim_FALSE\"]}\n\n + [SupportingEvidence]: Description of evidence. {\"instantiations\": [\"evidence_TRUE\", \"evidence_FALSE\"]}\nThis structure will later be enhanced with probability information to create BayesDown, which can be transformed into a Bayesian network for analysis and visualization.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#specify-source-document-e.g.-pdf",
    "href": "chapters/appendixA.html#specify-source-document-e.g.-pdf",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "6.3 1.1 Specify Source Document (e.g. PDF)",
    "text": "6.3 1.1 Specify Source Document (e.g. PDF)\nReview the source document, ensure it is suitable for API call and upload to / store it in the correct location.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#generate-argdown-extraction-prompt",
    "href": "chapters/appendixA.html#generate-argdown-extraction-prompt",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "6.4 1.2 Generate ArgDown Extraction Prompt",
    "text": "6.4 1.2 Generate ArgDown Extraction Prompt\nGenerate Extraction Prompt",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#prepare-llm-api-call",
    "href": "chapters/appendixA.html#prepare-llm-api-call",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "6.5 1.3 Prepare LLM API Call",
    "text": "6.5 1.3 Prepare LLM API Call\nCombine Systemprompt + API Specifications + ArgDown Instructions + Prompt + Source PDF for API Call\n\n\nProcessing source document: example_document.pdf\nUsing provider: openai\nSelected model: gpt-4-turbo",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#make-argdown-extraction-llm-api-call",
    "href": "chapters/appendixA.html#make-argdown-extraction-llm-api-call",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "6.6 1.4 Make ArgDown Extraction LLM API Call",
    "text": "6.6 1.4 Make ArgDown Extraction LLM API Call\n\n\nStarting extraction from example_document.pdf\nError during extraction: PyPDF2 is required for PDF processing. Install it with: pip install PyPDF2\n\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\n&lt;ipython-input-17-fd592eb962ab&gt; in process_source_document(file_path, provider_name)\n    166         try:\n--&gt; 167             import PyPDF2\n    168             with open(file_path, 'rb') as file:\n\nModuleNotFoundError: No module named 'PyPDF2'\n\nDuring handling of the above exception, another exception occurred:\n\nImportError                               Traceback (most recent call last)\n&lt;ipython-input-19-27555067c1d2&gt; in &lt;cell line: 0&gt;()\n     59 \n     60 # Usage example:\n---&gt; 61 extraction_results = execute_extraction(extraction_config)\n\n&lt;ipython-input-19-27555067c1d2&gt; in execute_extraction(extraction_config)\n     35     try:\n     36         # Process the document\n---&gt; 37         results = process_source_document(\n     38             extraction_config[\"source_path\"],\n     39             provider_name=extraction_config[\"provider\"]\n\n&lt;ipython-input-17-fd592eb962ab&gt; in process_source_document(file_path, provider_name)\n    172                     text += page.extract_text() + \"\\n\"\n    173         except ImportError:\n--&gt; 174             raise ImportError(\"PyPDF2 is required for PDF processing. Install it with: pip install PyPDF2\")\n    175     elif file_path.endswith(\".txt\"):\n    176         with open(file_path, 'r') as file:\n\nImportError: PyPDF2 is required for PDF processing. Install it with: pip install PyPDF2\n\n---------------------------------------------------------------------------\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n---------------------------------------------------------------------------",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#save-argdown-extraction-response",
    "href": "chapters/appendixA.html#save-argdown-extraction-response",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "6.7 1.5 Save ArgDown Extraction Response",
    "text": "6.7 1.5 Save ArgDown Extraction Response\n\nSave and log API return\nSave ArgDown.md file for further Proecessing\n\n\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\n&lt;ipython-input-20-84ee4ea64739&gt; in &lt;cell line: 0&gt;()\n     55 \n     56 # Usage example:\n---&gt; 57 output_path = save_extraction_results(extraction_results)\n     58 \n     59 # Preview the extracted ArgDown\n\nNameError: name 'extraction_results' is not defined",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#review-and-check-argdown.md-file",
    "href": "chapters/appendixA.html#review-and-check-argdown.md-file",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "6.8 1.6 Review and Check ArgDown.md File",
    "text": "6.8 1.6 Review and Check ArgDown.md File\n\n\n[Existential_Catastrophe]: The destruction of humanity’s long-term potential due to AI systems we’ve lost control over. {“instantiations”: [“existential_catastrophe_TRUE”, “existential_catastrophe_FALSE”]} - [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {“instantiations”: [“human_disempowerment_TRUE”, “human_disempowerment_FALSE”]} - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {“instantiations”: [“scale_of_power_seeking_TRUE”, “scale_of_power_seeking_FALSE”]} - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {“instantiations”: [“misaligned_power_seeking_TRUE”, “misaligned_power_seeking_FALSE”]} - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {“instantiations”: [“aps_systems_TRUE”, “aps_systems_FALSE”]} - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {“instantiations”: [“advanced_ai_capability_TRUE”, “advanced_ai_capability_FALSE”]} - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {“instantiations”: [“agentic_planning_TRUE”, “agentic_planning_FALSE”]} - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {“instantiations”: [“strategic_awareness_TRUE”, “strategic_awareness_FALSE”]} - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {“instantiations”: [“difficulty_of_alignment_TRUE”, “difficulty_of_alignment_FALSE”]} - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {“instantiations”: [“instrumental_convergence_TRUE”, “instrumental_convergence_FALSE”]} - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {“instantiations”: [“problems_with_proxies_TRUE”, “problems_with_proxies_FALSE”]} - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {“instantiations”: [“problems_with_search_TRUE”, “problems_with_search_FALSE”]} - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {“instantiations”: [“deployment_decisions_DEPLOY”, “deployment_decisions_WITHHOLD”]} - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {“instantiations”: [“incentives_to_build_aps_STRONG”, “incentives_to_build_aps_WEAK”]} - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {“instantiations”: [“usefulness_of_aps_HIGH”, “usefulness_of_aps_LOW”]} - [Competitive_Dynamics]: Competitive pressures between AI developers. {“instantiations”: [“competitive_dynamics_STRONG”, “competitive_dynamics_WEAK”]} - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {“instantiations”: [“deception_by_ai_TRUE”, “deception_by_ai_FALSE”]} - [Corrective_Feedback]: Human society implementing corrections after observing problems. {“instantiations”: [“corrective_feedback_EFFECTIVE”, “corrective_feedback_INEFFECTIVE”]} - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {“instantiations”: [“warning_shots_OBSERVED”, “warning_shots_UNOBSERVED”]} - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {“instantiations”: [“rapid_capability_escalation_TRUE”, “rapid_capability_escalation_FALSE”]} [Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {“instantiations”: [“barriers_to_understanding_HIGH”, “barriers_to_understanding_LOW”]} - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {“instantiations”: [“misaligned_power_seeking_TRUE”, “misaligned_power_seeking_FALSE”]} [Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {“instantiations”: [“adversarial_dynamics_TRUE”, “adversarial_dynamics_FALSE”]} - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {“instantiations”: [“misaligned_power_seeking_TRUE”, “misaligned_power_seeking_FALSE”]} [Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {“instantiations”: [“stakes_of_error_HIGH”, “stakes_of_error_LOW”]} - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {“instantiations”: [“misaligned_power_seeking_TRUE”, “misaligned_power_seeking_FALSE”]}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#check-the-graph-structure-with-the-argdown-sandbox-online",
    "href": "chapters/appendixA.html#check-the-graph-structure-with-the-argdown-sandbox-online",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "6.9 1.6.2 Check the Graph Structure with the ArgDown Sandbox Online",
    "text": "6.9 1.6.2 Check the Graph Structure with the ArgDown Sandbox Online\nCopy and paste the BayesDown formatted … in the ArgDown Sandbox below to quickly verify that the network renders correctly.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#extract-argdown-graph-information-as-dataframe",
    "href": "chapters/appendixA.html#extract-argdown-graph-information-as-dataframe",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "6.10 1.7 Extract ArgDown Graph Information as DataFrame",
    "text": "6.10 1.7 Extract ArgDown Graph Information as DataFrame\nExtract:\n\nNodes (Variable_Title)\nEdges (Parents)\nInstantiations\nDescription\n\nImplementation nodes: - One function for ArgDown and BayesDown extraction, but: - IF YOU ONLY WANT ARGDOWN EXTRACTION: USE ARGUMENT IN FUNCTION CALL “parse_markdown_hierarchy(markdown_text, ArgDown = True)” - so if you set ArgDown = True, it gives you only instantiations, no probabilities.\n\n\n\n    \n\n\n\n\n\n\nTitle\nDescription\nline\nline_numbers\nindentation\nindentation_levels\nParents\nChildren\ninstantiations\nNo_Parent\nNo_Children\nparent_instantiations\n\n\n\n\n0\nExistential_Catastrophe\nThe destruction of humanity's long-term potent...\n0\n[0]\n0\n[0]\n[]\n[]\n[existential_catastrophe_TRUE, existential_cat...\nTrue\nTrue\n[]\n\n\n1\nHuman_Disempowerment\nPermanent and collective disempowerment of hum...\n1\n[1]\n0\n[0]\n[Scale_Of_Power_Seeking]\n[]\n[human_disempowerment_TRUE, human_disempowerme...\nFalse\nTrue\n[[scale_of_power_seeking_TRUE, scale_of_power_...\n\n\n2\nScale_Of_Power_Seeking\nPower-seeking by AI systems scaling to the poi...\n2\n[2]\n4\n[4]\n[Misaligned_Power_Seeking, Corrective_Feedback]\n[Human_Disempowerment]\n[scale_of_power_seeking_TRUE, scale_of_power_s...\nFalse\nFalse\n[[misaligned_power_seeking_TRUE, misaligned_po...\n\n\n3\nMisaligned_Power_Seeking\nDeployed AI systems seeking power in unintende...\n3\n[3, 21, 23, 25]\n8\n[8, 0, 0, 0]\n[APS_Systems, Difficulty_Of_Alignment, Deploym...\n[Scale_Of_Power_Seeking]\n[misaligned_power_seeking_TRUE, misaligned_pow...\nFalse\nFalse\n[[aps_systems_TRUE, aps_systems_FALSE], [diffi...\n\n\n4\nAPS_Systems\nAI systems with advanced capabilities, agentic...\n4\n[4]\n12\n[12]\n[Advanced_AI_Capability, Agentic_Planning, Str...\n[Misaligned_Power_Seeking]\n[aps_systems_TRUE, aps_systems_FALSE]\nFalse\nFalse\n[[advanced_ai_capability_TRUE, advanced_ai_cap...\n\n\n5\nAdvanced_AI_Capability\nAI systems that outperform humans on tasks tha...\n5\n[5]\n16\n[16]\n[]\n[APS_Systems]\n[advanced_ai_capability_TRUE, advanced_ai_capa...\nTrue\nFalse\n[]\n\n\n6\nAgentic_Planning\nAI systems making and executing plans based on...\n6\n[6]\n16\n[16]\n[]\n[APS_Systems]\n[agentic_planning_TRUE, agentic_planning_FALSE]\nTrue\nFalse\n[]\n\n\n7\nStrategic_Awareness\nAI systems with models accurately representing...\n7\n[7]\n16\n[16]\n[]\n[APS_Systems]\n[strategic_awareness_TRUE, strategic_awareness...\nTrue\nFalse\n[]\n\n\n8\nDifficulty_Of_Alignment\nIt is harder to build aligned systems than mis...\n8\n[8]\n12\n[12]\n[Instrumental_Convergence, Problems_With_Proxi...\n[Misaligned_Power_Seeking]\n[difficulty_of_alignment_TRUE, difficulty_of_a...\nFalse\nFalse\n[[instrumental_convergence_TRUE, instrumental_...\n\n\n9\nInstrumental_Convergence\nAI systems with misaligned objectives tend to ...\n9\n[9]\n16\n[16]\n[]\n[Difficulty_Of_Alignment]\n[instrumental_convergence_TRUE, instrumental_c...\nTrue\nFalse\n[]\n\n\n10\nProblems_With_Proxies\nOptimizing for proxy objectives breaks correla...\n10\n[10]\n16\n[16]\n[]\n[Difficulty_Of_Alignment]\n[problems_with_proxies_TRUE, problems_with_pro...\nTrue\nFalse\n[]\n\n\n11\nProblems_With_Search\nSearch processes can yield systems pursuing di...\n11\n[11]\n16\n[16]\n[]\n[Difficulty_Of_Alignment]\n[problems_with_search_TRUE, problems_with_sear...\nTrue\nFalse\n[]\n\n\n12\nDeployment_Decisions\nDecisions to deploy potentially misaligned AI ...\n12\n[12]\n12\n[12]\n[Incentives_To_Build_APS, Deception_By_AI]\n[Misaligned_Power_Seeking]\n[deployment_decisions_DEPLOY, deployment_decis...\nFalse\nFalse\n[[incentives_to_build_aps_STRONG, incentives_t...\n\n\n13\nIncentives_To_Build_APS\nStrong incentives to build and deploy APS syst...\n13\n[13]\n16\n[16]\n[Usefulness_Of_APS, Competitive_Dynamics]\n[Deployment_Decisions]\n[incentives_to_build_aps_STRONG, incentives_to...\nFalse\nFalse\n[[usefulness_of_aps_HIGH, usefulness_of_aps_LO...\n\n\n14\nUsefulness_Of_APS\nAPS systems are very useful for many valuable ...\n14\n[14]\n20\n[20]\n[]\n[Incentives_To_Build_APS]\n[usefulness_of_aps_HIGH, usefulness_of_aps_LOW]\nTrue\nFalse\n[]\n\n\n15\nCompetitive_Dynamics\nCompetitive pressures between AI developers.\n15\n[15]\n20\n[20]\n[]\n[Incentives_To_Build_APS]\n[competitive_dynamics_STRONG, competitive_dyna...\nTrue\nFalse\n[]\n\n\n16\nDeception_By_AI\nAI systems deceiving humans about their true o...\n16\n[16]\n16\n[16]\n[]\n[Deployment_Decisions]\n[deception_by_ai_TRUE, deception_by_ai_FALSE]\nTrue\nFalse\n[]\n\n\n17\nCorrective_Feedback\nHuman society implementing corrections after o...\n17\n[17]\n8\n[8]\n[Warning_Shots, Rapid_Capability_Escalation]\n[Scale_Of_Power_Seeking]\n[corrective_feedback_EFFECTIVE, corrective_fee...\nFalse\nFalse\n[[warning_shots_OBSERVED, warning_shots_UNOBSE...\n\n\n18\nWarning_Shots\nObservable failures in weaker systems before c...\n18\n[18]\n12\n[12]\n[]\n[Corrective_Feedback]\n[warning_shots_OBSERVED, warning_shots_UNOBSER...\nTrue\nFalse\n[]\n\n\n19\nRapid_Capability_Escalation\nAI capabilities escalating very rapidly, allow...\n19\n[19]\n12\n[12]\n[]\n[Corrective_Feedback]\n[rapid_capability_escalation_TRUE, rapid_capab...\nTrue\nFalse\n[]\n\n\n20\nBarriers_To_Understanding\nDifficulty in understanding the internal worki...\n20\n[20]\n0\n[0]\n[]\n[]\n[barriers_to_understanding_HIGH, barriers_to_u...\nTrue\nTrue\n[]\n\n\n21\nAdversarial_Dynamics\nPotentially adversarial relationships between ...\n22\n[22]\n0\n[0]\n[]\n[]\n[adversarial_dynamics_TRUE, adversarial_dynami...\nTrue\nTrue\n[]\n\n\n22\nStakes_Of_Error\nThe escalating impact of mistakes with power-s...\n24\n[24]\n0\n[0]\n[]\n[]\n[stakes_of_error_HIGH, stakes_of_error_LOW]\nTrue\nTrue\n[]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#store-argdown-information-as-argdown.csv-file",
    "href": "chapters/appendixA.html#store-argdown-information-as-argdown.csv-file",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "6.11 1.8 Store ArgDown Information as ‘ArgDown.csv’ file",
    "text": "6.11 1.8 Store ArgDown Information as ‘ArgDown.csv’ file\n\n\n                          Title  \\\n0       Existential_Catastrophe   \n1          Human_Disempowerment   \n2        Scale_Of_Power_Seeking   \n3      Misaligned_Power_Seeking   \n4                   APS_Systems   \n5        Advanced_AI_Capability   \n6              Agentic_Planning   \n7           Strategic_Awareness   \n8       Difficulty_Of_Alignment   \n9      Instrumental_Convergence   \n10        Problems_With_Proxies   \n11         Problems_With_Search   \n12         Deployment_Decisions   \n13      Incentives_To_Build_APS   \n14            Usefulness_Of_APS   \n15         Competitive_Dynamics   \n16              Deception_By_AI   \n17          Corrective_Feedback   \n18                Warning_Shots   \n19  Rapid_Capability_Escalation   \n20    Barriers_To_Understanding   \n21         Adversarial_Dynamics   \n22              Stakes_Of_Error   \n\n                                          Description  line     line_numbers  \\\n0   The destruction of humanity's long-term potent...     0              [0]   \n1   Permanent and collective disempowerment of hum...     1              [1]   \n2   Power-seeking by AI systems scaling to the poi...     2              [2]   \n3   Deployed AI systems seeking power in unintende...     3  [3, 21, 23, 25]   \n4   AI systems with advanced capabilities, agentic...     4              [4]   \n5   AI systems that outperform humans on tasks tha...     5              [5]   \n6   AI systems making and executing plans based on...     6              [6]   \n7   AI systems with models accurately representing...     7              [7]   \n8   It is harder to build aligned systems than mis...     8              [8]   \n9   AI systems with misaligned objectives tend to ...     9              [9]   \n10  Optimizing for proxy objectives breaks correla...    10             [10]   \n11  Search processes can yield systems pursuing di...    11             [11]   \n12  Decisions to deploy potentially misaligned AI ...    12             [12]   \n13  Strong incentives to build and deploy APS syst...    13             [13]   \n14  APS systems are very useful for many valuable ...    14             [14]   \n15       Competitive pressures between AI developers.    15             [15]   \n16  AI systems deceiving humans about their true o...    16             [16]   \n17  Human society implementing corrections after o...    17             [17]   \n18  Observable failures in weaker systems before c...    18             [18]   \n19  AI capabilities escalating very rapidly, allow...    19             [19]   \n20  Difficulty in understanding the internal worki...    20             [20]   \n21  Potentially adversarial relationships between ...    22             [22]   \n22  The escalating impact of mistakes with power-s...    24             [24]   \n\n    indentation indentation_levels  \\\n0             0                [0]   \n1             0                [0]   \n2             4                [4]   \n3             8       [8, 0, 0, 0]   \n4            12               [12]   \n5            16               [16]   \n6            16               [16]   \n7            16               [16]   \n8            12               [12]   \n9            16               [16]   \n10           16               [16]   \n11           16               [16]   \n12           12               [12]   \n13           16               [16]   \n14           20               [20]   \n15           20               [20]   \n16           16               [16]   \n17            8                [8]   \n18           12               [12]   \n19           12               [12]   \n20            0                [0]   \n21            0                [0]   \n22            0                [0]   \n\n                                              Parents  \\\n0                                                  []   \n1                          ['Scale_Of_Power_Seeking']   \n2   ['Misaligned_Power_Seeking', 'Corrective_Feedb...   \n3   ['APS_Systems', 'Difficulty_Of_Alignment', 'De...   \n4   ['Advanced_AI_Capability', 'Agentic_Planning',...   \n5                                                  []   \n6                                                  []   \n7                                                  []   \n8   ['Instrumental_Convergence', 'Problems_With_Pr...   \n9                                                  []   \n10                                                 []   \n11                                                 []   \n12     ['Incentives_To_Build_APS', 'Deception_By_AI']   \n13      ['Usefulness_Of_APS', 'Competitive_Dynamics']   \n14                                                 []   \n15                                                 []   \n16                                                 []   \n17   ['Warning_Shots', 'Rapid_Capability_Escalation']   \n18                                                 []   \n19                                                 []   \n20                                                 []   \n21                                                 []   \n22                                                 []   \n\n                        Children  \\\n0                             []   \n1                             []   \n2       ['Human_Disempowerment']   \n3     ['Scale_Of_Power_Seeking']   \n4   ['Misaligned_Power_Seeking']   \n5                ['APS_Systems']   \n6                ['APS_Systems']   \n7                ['APS_Systems']   \n8   ['Misaligned_Power_Seeking']   \n9    ['Difficulty_Of_Alignment']   \n10   ['Difficulty_Of_Alignment']   \n11   ['Difficulty_Of_Alignment']   \n12  ['Misaligned_Power_Seeking']   \n13      ['Deployment_Decisions']   \n14   ['Incentives_To_Build_APS']   \n15   ['Incentives_To_Build_APS']   \n16      ['Deployment_Decisions']   \n17    ['Scale_Of_Power_Seeking']   \n18       ['Corrective_Feedback']   \n19       ['Corrective_Feedback']   \n20                            []   \n21                            []   \n22                            []   \n\n                                       instantiations  No_Parent  No_Children  \\\n0   ['existential_catastrophe_TRUE', 'existential_...       True         True   \n1   ['human_disempowerment_TRUE', 'human_disempowe...      False         True   \n2   ['scale_of_power_seeking_TRUE', 'scale_of_powe...      False        False   \n3   ['misaligned_power_seeking_TRUE', 'misaligned_...      False        False   \n4           ['aps_systems_TRUE', 'aps_systems_FALSE']      False        False   \n5   ['advanced_ai_capability_TRUE', 'advanced_ai_c...       True        False   \n6   ['agentic_planning_TRUE', 'agentic_planning_FA...       True        False   \n7   ['strategic_awareness_TRUE', 'strategic_awaren...       True        False   \n8   ['difficulty_of_alignment_TRUE', 'difficulty_o...      False        False   \n9   ['instrumental_convergence_TRUE', 'instrumenta...       True        False   \n10  ['problems_with_proxies_TRUE', 'problems_with_...       True        False   \n11  ['problems_with_search_TRUE', 'problems_with_s...       True        False   \n12  ['deployment_decisions_DEPLOY', 'deployment_de...      False        False   \n13  ['incentives_to_build_aps_STRONG', 'incentives...      False        False   \n14  ['usefulness_of_aps_HIGH', 'usefulness_of_aps_...       True        False   \n15  ['competitive_dynamics_STRONG', 'competitive_d...       True        False   \n16  ['deception_by_ai_TRUE', 'deception_by_ai_FALSE']       True        False   \n17  ['corrective_feedback_EFFECTIVE', 'corrective_...      False        False   \n18  ['warning_shots_OBSERVED', 'warning_shots_UNOB...       True        False   \n19  ['rapid_capability_escalation_TRUE', 'rapid_ca...       True        False   \n20  ['barriers_to_understanding_HIGH', 'barriers_t...       True         True   \n21  ['adversarial_dynamics_TRUE', 'adversarial_dyn...       True         True   \n22    ['stakes_of_error_HIGH', 'stakes_of_error_LOW']       True         True   \n\n                                parent_instantiations  \n0                                                  []  \n1   [['scale_of_power_seeking_TRUE', 'scale_of_pow...  \n2   [['misaligned_power_seeking_TRUE', 'misaligned...  \n3   [['aps_systems_TRUE', 'aps_systems_FALSE'], ['...  \n4   [['advanced_ai_capability_TRUE', 'advanced_ai_...  \n5                                                  []  \n6                                                  []  \n7                                                  []  \n8   [['instrumental_convergence_TRUE', 'instrument...  \n9                                                  []  \n10                                                 []  \n11                                                 []  \n12  [['incentives_to_build_aps_STRONG', 'incentive...  \n13  [['usefulness_of_aps_HIGH', 'usefulness_of_aps...  \n14                                                 []  \n15                                                 []  \n16                                                 []  \n17  [['warning_shots_OBSERVED', 'warning_shots_UNO...  \n18                                                 []  \n19                                                 []  \n20                                                 []  \n21                                                 []  \n22                                                 []",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#process-overview-1",
    "href": "chapters/appendixA.html#process-overview-1",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "8.1 Process Overview",
    "text": "8.1 Process Overview\nThis section implements the second major stage of the AMTAIR pipeline: enhancing the structured argument representation (ArgDown) with probability information to create BayesDown.\nBayesDown extends ArgDown by adding: 1. Prior probabilities for each variable (unconditional beliefs) 2. Conditional probabilities representing the relationships between variables 3. The full parameter specification needed for a Bayesian network\nThe process follows these steps: 1. Generate probability questions for each node and its relationships 2. Create a BayesDown template with placeholders for these probabilities 3. Answer the probability questions (manually or via LLM) 4. Substitute the answers into the BayesDown representation\nThis enhanced representation contains all the information needed to construct a formal Bayesian network, enabling probabilistic reasoning and policy evaluation.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#what-is-bayesdown",
    "href": "chapters/appendixA.html#what-is-bayesdown",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "8.2 What is BayesDown?",
    "text": "8.2 What is BayesDown?\nBayesDown maintains the ArgDown structure but adds probability metadata:\n[Node]: Description. {\n\"instantiations\": [\"node_TRUE\", \"node_FALSE\"],\n\"priors\": { \"p(node_TRUE)\": \"0.7\", \"p(node_FALSE)\": \"0.3\" },\n\"posteriors\": { \"p(node_TRUE|parent_TRUE)\": \"0.9\", \"p(node_TRUE|parent_FALSE)\": \"0.4\" }\n}\nThe result is a hybrid representation that preserves the narrative structure of arguments while adding the mathematical precision of Bayesian networks.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#probability-extraction-questions-argdown.csv-to-argdown_withquestions.csv",
    "href": "chapters/appendixA.html#probability-extraction-questions-argdown.csv-to-argdown_withquestions.csv",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "8.3 2.1 Probability Extraction Questions — ‘ArgDown.csv’ to ‘ArgDown_WithQuestions.csv’",
    "text": "8.3 2.1 Probability Extraction Questions — ‘ArgDown.csv’ to ‘ArgDown_WithQuestions.csv’\n\n\nLoading ArgDown CSV from ArgDown.csv...\nSuccessfully loaded CSV with 23 rows.\nGenerating probability questions for each node...\nGenerated questions saved to ArgDown_WithQuestions.csv\n\n\n\n\n                          Title  \\\n0       Existential_Catastrophe   \n1          Human_Disempowerment   \n2        Scale_Of_Power_Seeking   \n3      Misaligned_Power_Seeking   \n4                   APS_Systems   \n5        Advanced_AI_Capability   \n6              Agentic_Planning   \n7           Strategic_Awareness   \n8       Difficulty_Of_Alignment   \n9      Instrumental_Convergence   \n10        Problems_With_Proxies   \n11         Problems_With_Search   \n12         Deployment_Decisions   \n13      Incentives_To_Build_APS   \n14            Usefulness_Of_APS   \n15         Competitive_Dynamics   \n16              Deception_By_AI   \n17          Corrective_Feedback   \n18                Warning_Shots   \n19  Rapid_Capability_Escalation   \n20    Barriers_To_Understanding   \n21         Adversarial_Dynamics   \n22              Stakes_Of_Error   \n\n                                          Description  line     line_numbers  \\\n0   The destruction of humanity's long-term potent...     0              [0]   \n1   Permanent and collective disempowerment of hum...     1              [1]   \n2   Power-seeking by AI systems scaling to the poi...     2              [2]   \n3   Deployed AI systems seeking power in unintende...     3  [3, 21, 23, 25]   \n4   AI systems with advanced capabilities, agentic...     4              [4]   \n5   AI systems that outperform humans on tasks tha...     5              [5]   \n6   AI systems making and executing plans based on...     6              [6]   \n7   AI systems with models accurately representing...     7              [7]   \n8   It is harder to build aligned systems than mis...     8              [8]   \n9   AI systems with misaligned objectives tend to ...     9              [9]   \n10  Optimizing for proxy objectives breaks correla...    10             [10]   \n11  Search processes can yield systems pursuing di...    11             [11]   \n12  Decisions to deploy potentially misaligned AI ...    12             [12]   \n13  Strong incentives to build and deploy APS syst...    13             [13]   \n14  APS systems are very useful for many valuable ...    14             [14]   \n15       Competitive pressures between AI developers.    15             [15]   \n16  AI systems deceiving humans about their true o...    16             [16]   \n17  Human society implementing corrections after o...    17             [17]   \n18  Observable failures in weaker systems before c...    18             [18]   \n19  AI capabilities escalating very rapidly, allow...    19             [19]   \n20  Difficulty in understanding the internal worki...    20             [20]   \n21  Potentially adversarial relationships between ...    22             [22]   \n22  The escalating impact of mistakes with power-s...    24             [24]   \n\n    indentation indentation_levels  \\\n0             0                [0]   \n1             0                [0]   \n2             4                [4]   \n3             8       [8, 0, 0, 0]   \n4            12               [12]   \n5            16               [16]   \n6            16               [16]   \n7            16               [16]   \n8            12               [12]   \n9            16               [16]   \n10           16               [16]   \n11           16               [16]   \n12           12               [12]   \n13           16               [16]   \n14           20               [20]   \n15           20               [20]   \n16           16               [16]   \n17            8                [8]   \n18           12               [12]   \n19           12               [12]   \n20            0                [0]   \n21            0                [0]   \n22            0                [0]   \n\n                                              Parents  \\\n0                                                  []   \n1                          ['Scale_Of_Power_Seeking']   \n2   ['Misaligned_Power_Seeking', 'Corrective_Feedb...   \n3   ['APS_Systems', 'Difficulty_Of_Alignment', 'De...   \n4   ['Advanced_AI_Capability', 'Agentic_Planning',...   \n5                                                  []   \n6                                                  []   \n7                                                  []   \n8   ['Instrumental_Convergence', 'Problems_With_Pr...   \n9                                                  []   \n10                                                 []   \n11                                                 []   \n12     ['Incentives_To_Build_APS', 'Deception_By_AI']   \n13      ['Usefulness_Of_APS', 'Competitive_Dynamics']   \n14                                                 []   \n15                                                 []   \n16                                                 []   \n17   ['Warning_Shots', 'Rapid_Capability_Escalation']   \n18                                                 []   \n19                                                 []   \n20                                                 []   \n21                                                 []   \n22                                                 []   \n\n                        Children  \\\n0                             []   \n1                             []   \n2       ['Human_Disempowerment']   \n3     ['Scale_Of_Power_Seeking']   \n4   ['Misaligned_Power_Seeking']   \n5                ['APS_Systems']   \n6                ['APS_Systems']   \n7                ['APS_Systems']   \n8   ['Misaligned_Power_Seeking']   \n9    ['Difficulty_Of_Alignment']   \n10   ['Difficulty_Of_Alignment']   \n11   ['Difficulty_Of_Alignment']   \n12  ['Misaligned_Power_Seeking']   \n13      ['Deployment_Decisions']   \n14   ['Incentives_To_Build_APS']   \n15   ['Incentives_To_Build_APS']   \n16      ['Deployment_Decisions']   \n17    ['Scale_Of_Power_Seeking']   \n18       ['Corrective_Feedback']   \n19       ['Corrective_Feedback']   \n20                            []   \n21                            []   \n22                            []   \n\n                                       instantiations  No_Parent  No_Children  \\\n0   ['existential_catastrophe_TRUE', 'existential_...       True         True   \n1   ['human_disempowerment_TRUE', 'human_disempowe...      False         True   \n2   ['scale_of_power_seeking_TRUE', 'scale_of_powe...      False        False   \n3   ['misaligned_power_seeking_TRUE', 'misaligned_...      False        False   \n4           ['aps_systems_TRUE', 'aps_systems_FALSE']      False        False   \n5   ['advanced_ai_capability_TRUE', 'advanced_ai_c...       True        False   \n6   ['agentic_planning_TRUE', 'agentic_planning_FA...       True        False   \n7   ['strategic_awareness_TRUE', 'strategic_awaren...       True        False   \n8   ['difficulty_of_alignment_TRUE', 'difficulty_o...      False        False   \n9   ['instrumental_convergence_TRUE', 'instrumenta...       True        False   \n10  ['problems_with_proxies_TRUE', 'problems_with_...       True        False   \n11  ['problems_with_search_TRUE', 'problems_with_s...       True        False   \n12  ['deployment_decisions_DEPLOY', 'deployment_de...      False        False   \n13  ['incentives_to_build_aps_STRONG', 'incentives...      False        False   \n14  ['usefulness_of_aps_HIGH', 'usefulness_of_aps_...       True        False   \n15  ['competitive_dynamics_STRONG', 'competitive_d...       True        False   \n16  ['deception_by_ai_TRUE', 'deception_by_ai_FALSE']       True        False   \n17  ['corrective_feedback_EFFECTIVE', 'corrective_...      False        False   \n18  ['warning_shots_OBSERVED', 'warning_shots_UNOB...       True        False   \n19  ['rapid_capability_escalation_TRUE', 'rapid_ca...       True        False   \n20  ['barriers_to_understanding_HIGH', 'barriers_t...       True         True   \n21  ['adversarial_dynamics_TRUE', 'adversarial_dyn...       True         True   \n22    ['stakes_of_error_HIGH', 'stakes_of_error_LOW']       True         True   \n\n                                parent_instantiations  \\\n0                                                  []   \n1   [['scale_of_power_seeking_TRUE', 'scale_of_pow...   \n2   [['misaligned_power_seeking_TRUE', 'misaligned...   \n3   [['aps_systems_TRUE', 'aps_systems_FALSE'], ['...   \n4   [['advanced_ai_capability_TRUE', 'advanced_ai_...   \n5                                                  []   \n6                                                  []   \n7                                                  []   \n8   [['instrumental_convergence_TRUE', 'instrument...   \n9                                                  []   \n10                                                 []   \n11                                                 []   \n12  [['incentives_to_build_aps_STRONG', 'incentive...   \n13  [['usefulness_of_aps_HIGH', 'usefulness_of_aps...   \n14                                                 []   \n15                                                 []   \n16                                                 []   \n17  [['warning_shots_OBSERVED', 'warning_shots_UNO...   \n18                                                 []   \n19                                                 []   \n20                                                 []   \n21                                                 []   \n22                                                 []   \n\n            Generate_Positive_Instantiation_Questions  \\\n0   {\"What is the probability for Existential_Cata...   \n1   {\"What is the probability for Human_Disempower...   \n2   {\"What is the probability for Scale_Of_Power_S...   \n3   {\"What is the probability for Misaligned_Power...   \n4   {\"What is the probability for APS_Systems=aps_...   \n5   {\"What is the probability for Advanced_AI_Capa...   \n6   {\"What is the probability for Agentic_Planning...   \n7   {\"What is the probability for Strategic_Awaren...   \n8   {\"What is the probability for Difficulty_Of_Al...   \n9   {\"What is the probability for Instrumental_Con...   \n10  {\"What is the probability for Problems_With_Pr...   \n11  {\"What is the probability for Problems_With_Se...   \n12  {\"What is the probability for Deployment_Decis...   \n13  {\"What is the probability for Incentives_To_Bu...   \n14  {\"What is the probability for Usefulness_Of_AP...   \n15  {\"What is the probability for Competitive_Dyna...   \n16  {\"What is the probability for Deception_By_AI=...   \n17  {\"What is the probability for Corrective_Feedb...   \n18  {\"What is the probability for Warning_Shots=wa...   \n19  {\"What is the probability for Rapid_Capability...   \n20  {\"What is the probability for Barriers_To_Unde...   \n21  {\"What is the probability for Adversarial_Dyna...   \n22  {\"What is the probability for Stakes_Of_Error=...   \n\n            Generate_Negative_Instantiation_Questions  \n0   {\"What is the probability for Existential_Cata...  \n1   {\"What is the probability for Human_Disempower...  \n2   {\"What is the probability for Scale_Of_Power_S...  \n3   {\"What is the probability for Misaligned_Power...  \n4   {\"What is the probability for APS_Systems=aps_...  \n5   {\"What is the probability for Advanced_AI_Capa...  \n6   {\"What is the probability for Agentic_Planning...  \n7   {\"What is the probability for Strategic_Awaren...  \n8   {\"What is the probability for Difficulty_Of_Al...  \n9   {\"What is the probability for Instrumental_Con...  \n10  {\"What is the probability for Problems_With_Pr...  \n11  {\"What is the probability for Problems_With_Se...  \n12  {\"What is the probability for Deployment_Decis...  \n13  {\"What is the probability for Incentives_To_Bu...  \n14  {\"What is the probability for Usefulness_Of_AP...  \n15  {\"What is the probability for Competitive_Dyna...  \n16  {\"What is the probability for Deception_By_AI=...  \n17  {\"What is the probability for Corrective_Feedb...  \n18  {\"What is the probability for Warning_Shots=wa...  \n19  {\"What is the probability for Rapid_Capability...  \n20  {\"What is the probability for Barriers_To_Unde...  \n21  {\"What is the probability for Adversarial_Dyna...  \n22  {\"What is the probability for Stakes_Of_Error=...  \n\n\n\n    \n\n\n\n\n\n\nTitle\nDescription\nline\nline_numbers\nindentation\nindentation_levels\nParents\nChildren\ninstantiations\nNo_Parent\nNo_Children\nparent_instantiations\nGenerate_Positive_Instantiation_Questions\nGenerate_Negative_Instantiation_Questions\n\n\n\n\n0\nExistential_Catastrophe\nThe destruction of humanity's long-term potent...\n0\n[0]\n0\n[0]\n[]\n[]\n['existential_catastrophe_TRUE', 'existential_...\nTrue\nTrue\n[]\n{\"What is the probability for Existential_Cata...\n{\"What is the probability for Existential_Cata...\n\n\n1\nHuman_Disempowerment\nPermanent and collective disempowerment of hum...\n1\n[1]\n0\n[0]\n['Scale_Of_Power_Seeking']\n[]\n['human_disempowerment_TRUE', 'human_disempowe...\nFalse\nTrue\n[['scale_of_power_seeking_TRUE', 'scale_of_pow...\n{\"What is the probability for Human_Disempower...\n{\"What is the probability for Human_Disempower...\n\n\n2\nScale_Of_Power_Seeking\nPower-seeking by AI systems scaling to the poi...\n2\n[2]\n4\n[4]\n['Misaligned_Power_Seeking', 'Corrective_Feedb...\n['Human_Disempowerment']\n['scale_of_power_seeking_TRUE', 'scale_of_powe...\nFalse\nFalse\n[['misaligned_power_seeking_TRUE', 'misaligned...\n{\"What is the probability for Scale_Of_Power_S...\n{\"What is the probability for Scale_Of_Power_S...\n\n\n3\nMisaligned_Power_Seeking\nDeployed AI systems seeking power in unintende...\n3\n[3, 21, 23, 25]\n8\n[8, 0, 0, 0]\n['APS_Systems', 'Difficulty_Of_Alignment', 'De...\n['Scale_Of_Power_Seeking']\n['misaligned_power_seeking_TRUE', 'misaligned_...\nFalse\nFalse\n[['aps_systems_TRUE', 'aps_systems_FALSE'], ['...\n{\"What is the probability for Misaligned_Power...\n{\"What is the probability for Misaligned_Power...\n\n\n4\nAPS_Systems\nAI systems with advanced capabilities, agentic...\n4\n[4]\n12\n[12]\n['Advanced_AI_Capability', 'Agentic_Planning',...\n['Misaligned_Power_Seeking']\n['aps_systems_TRUE', 'aps_systems_FALSE']\nFalse\nFalse\n[['advanced_ai_capability_TRUE', 'advanced_ai_...\n{\"What is the probability for APS_Systems=aps_...\n{\"What is the probability for APS_Systems=aps_...\n\n\n5\nAdvanced_AI_Capability\nAI systems that outperform humans on tasks tha...\n5\n[5]\n16\n[16]\n[]\n['APS_Systems']\n['advanced_ai_capability_TRUE', 'advanced_ai_c...\nTrue\nFalse\n[]\n{\"What is the probability for Advanced_AI_Capa...\n{\"What is the probability for Advanced_AI_Capa...\n\n\n6\nAgentic_Planning\nAI systems making and executing plans based on...\n6\n[6]\n16\n[16]\n[]\n['APS_Systems']\n['agentic_planning_TRUE', 'agentic_planning_FA...\nTrue\nFalse\n[]\n{\"What is the probability for Agentic_Planning...\n{\"What is the probability for Agentic_Planning...\n\n\n7\nStrategic_Awareness\nAI systems with models accurately representing...\n7\n[7]\n16\n[16]\n[]\n['APS_Systems']\n['strategic_awareness_TRUE', 'strategic_awaren...\nTrue\nFalse\n[]\n{\"What is the probability for Strategic_Awaren...\n{\"What is the probability for Strategic_Awaren...\n\n\n8\nDifficulty_Of_Alignment\nIt is harder to build aligned systems than mis...\n8\n[8]\n12\n[12]\n['Instrumental_Convergence', 'Problems_With_Pr...\n['Misaligned_Power_Seeking']\n['difficulty_of_alignment_TRUE', 'difficulty_o...\nFalse\nFalse\n[['instrumental_convergence_TRUE', 'instrument...\n{\"What is the probability for Difficulty_Of_Al...\n{\"What is the probability for Difficulty_Of_Al...\n\n\n9\nInstrumental_Convergence\nAI systems with misaligned objectives tend to ...\n9\n[9]\n16\n[16]\n[]\n['Difficulty_Of_Alignment']\n['instrumental_convergence_TRUE', 'instrumenta...\nTrue\nFalse\n[]\n{\"What is the probability for Instrumental_Con...\n{\"What is the probability for Instrumental_Con...\n\n\n10\nProblems_With_Proxies\nOptimizing for proxy objectives breaks correla...\n10\n[10]\n16\n[16]\n[]\n['Difficulty_Of_Alignment']\n['problems_with_proxies_TRUE', 'problems_with_...\nTrue\nFalse\n[]\n{\"What is the probability for Problems_With_Pr...\n{\"What is the probability for Problems_With_Pr...\n\n\n11\nProblems_With_Search\nSearch processes can yield systems pursuing di...\n11\n[11]\n16\n[16]\n[]\n['Difficulty_Of_Alignment']\n['problems_with_search_TRUE', 'problems_with_s...\nTrue\nFalse\n[]\n{\"What is the probability for Problems_With_Se...\n{\"What is the probability for Problems_With_Se...\n\n\n12\nDeployment_Decisions\nDecisions to deploy potentially misaligned AI ...\n12\n[12]\n12\n[12]\n['Incentives_To_Build_APS', 'Deception_By_AI']\n['Misaligned_Power_Seeking']\n['deployment_decisions_DEPLOY', 'deployment_de...\nFalse\nFalse\n[['incentives_to_build_aps_STRONG', 'incentive...\n{\"What is the probability for Deployment_Decis...\n{\"What is the probability for Deployment_Decis...\n\n\n13\nIncentives_To_Build_APS\nStrong incentives to build and deploy APS syst...\n13\n[13]\n16\n[16]\n['Usefulness_Of_APS', 'Competitive_Dynamics']\n['Deployment_Decisions']\n['incentives_to_build_aps_STRONG', 'incentives...\nFalse\nFalse\n[['usefulness_of_aps_HIGH', 'usefulness_of_aps...\n{\"What is the probability for Incentives_To_Bu...\n{\"What is the probability for Incentives_To_Bu...\n\n\n14\nUsefulness_Of_APS\nAPS systems are very useful for many valuable ...\n14\n[14]\n20\n[20]\n[]\n['Incentives_To_Build_APS']\n['usefulness_of_aps_HIGH', 'usefulness_of_aps_...\nTrue\nFalse\n[]\n{\"What is the probability for Usefulness_Of_AP...\n{\"What is the probability for Usefulness_Of_AP...\n\n\n15\nCompetitive_Dynamics\nCompetitive pressures between AI developers.\n15\n[15]\n20\n[20]\n[]\n['Incentives_To_Build_APS']\n['competitive_dynamics_STRONG', 'competitive_d...\nTrue\nFalse\n[]\n{\"What is the probability for Competitive_Dyna...\n{\"What is the probability for Competitive_Dyna...\n\n\n16\nDeception_By_AI\nAI systems deceiving humans about their true o...\n16\n[16]\n16\n[16]\n[]\n['Deployment_Decisions']\n['deception_by_ai_TRUE', 'deception_by_ai_FALSE']\nTrue\nFalse\n[]\n{\"What is the probability for Deception_By_AI=...\n{\"What is the probability for Deception_By_AI=...\n\n\n17\nCorrective_Feedback\nHuman society implementing corrections after o...\n17\n[17]\n8\n[8]\n['Warning_Shots', 'Rapid_Capability_Escalation']\n['Scale_Of_Power_Seeking']\n['corrective_feedback_EFFECTIVE', 'corrective_...\nFalse\nFalse\n[['warning_shots_OBSERVED', 'warning_shots_UNO...\n{\"What is the probability for Corrective_Feedb...\n{\"What is the probability for Corrective_Feedb...\n\n\n18\nWarning_Shots\nObservable failures in weaker systems before c...\n18\n[18]\n12\n[12]\n[]\n['Corrective_Feedback']\n['warning_shots_OBSERVED', 'warning_shots_UNOB...\nTrue\nFalse\n[]\n{\"What is the probability for Warning_Shots=wa...\n{\"What is the probability for Warning_Shots=wa...\n\n\n19\nRapid_Capability_Escalation\nAI capabilities escalating very rapidly, allow...\n19\n[19]\n12\n[12]\n[]\n['Corrective_Feedback']\n['rapid_capability_escalation_TRUE', 'rapid_ca...\nTrue\nFalse\n[]\n{\"What is the probability for Rapid_Capability...\n{\"What is the probability for Rapid_Capability...\n\n\n20\nBarriers_To_Understanding\nDifficulty in understanding the internal worki...\n20\n[20]\n0\n[0]\n[]\n[]\n['barriers_to_understanding_HIGH', 'barriers_t...\nTrue\nTrue\n[]\n{\"What is the probability for Barriers_To_Unde...\n{\"What is the probability for Barriers_To_Unde...\n\n\n21\nAdversarial_Dynamics\nPotentially adversarial relationships between ...\n22\n[22]\n0\n[0]\n[]\n[]\n['adversarial_dynamics_TRUE', 'adversarial_dyn...\nTrue\nTrue\n[]\n{\"What is the probability for Adversarial_Dyna...\n{\"What is the probability for Adversarial_Dyna...\n\n\n22\nStakes_Of_Error\nThe escalating impact of mistakes with power-s...\n24\n[24]\n0\n[0]\n[]\n[]\n['stakes_of_error_HIGH', 'stakes_of_error_LOW']\nTrue\nTrue\n[]\n{\"What is the probability for Stakes_Of_Error=...\n{\"What is the probability for Stakes_Of_Error=...",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#argdown_withquestions.csv-to-bayesdownquestions.md",
    "href": "chapters/appendixA.html#argdown_withquestions.csv-to-bayesdownquestions.md",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "8.4 2.2 ‘ArgDown_WithQuestions.csv’ to ‘BayesDownQuestions.md’",
    "text": "8.4 2.2 ‘ArgDown_WithQuestions.csv’ to ‘BayesDownQuestions.md’\n2.2 Save BayesDown Extraction Questions as ‘BayesDownQuestions.md’\n\n\nLoading CSV from ArgDown_WithQuestions.csv...\nSuccessfully loaded CSV with 23 rows.\nGenerating BayesDown syntax with placeholder probabilities...\nBayesDown Questions saved to BayesDownQuestions.md\nMarkdown content saved to BayesDownQuestions.md\n\n\n\n\nLoading CSV from ArgDown_WithQuestions.csv...\nSuccessfully loaded CSV with 23 rows.\nGenerating BayesDown syntax with placeholder probabilities...\nBayesDown Questions saved to FULL_BayesDownQuestions.md\n\nBayesDown Format Preview:\n# BayesDown Representation with Placeholder Probabilities\n\n/* This file contains BayesDown syntax with placeholder probabilities.\n   Replace the placeholders with actual probability values based on the \n   questions in the comments. */\n\n/* What is the probability for Existential_Catastrophe=existential_catastrophe_TRUE? */\n/* What is the probability for Existential_Catastrophe=existential_catastrophe_FALSE? */\n[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {\"instantiations\": [\"existential_catastrophe_TRUE\", \"existential_catastrophe_FALSE\"], \"priors\": {\"What is the probability for Existential_Catastrophe=existential_catastrophe_TRUE?\": \"%?\", \"What is the probability for Existential_Catastrophe=existential_catastrophe_FALSE?\": \"%?\"}}\n/* What is the probability for Human_Disempowerment=human_disempowerment_TRUE? */\n/* What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE? */\n/* What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE? */\n/* What is the probability for Human_Disempowerment=human_disempowerment_FALSE? */\n/* What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE? */\n/* What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE? */\n[Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {\"instantiations\": [\"human_disempowerment_TRUE\", \"human_disempowerment_FALSE\"], \"priors\": {\"What is the probability for Human_Disempowerment=human_disempowerment_TRUE?\": \"%?\", \"What is the probability for Human_Disempowerment=human_disempowerment_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?\": \"?%\", \"What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?\": \"?%\", \"What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?\": \"?%\", \"What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?\": \"?%\"}}\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */\n  + [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {\"instantiations\": [\"scale_of_power_seeking_TRUE\", \"scale_of_power_seeking_FALSE\"], \"priors\": {\"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?\": \"%?\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\"}}\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    + [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"], \"priors\": {\"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE?\": \"%?\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\"}}\n      /* What is the probability for APS_Systems=aps_systems_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */\n      + [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {\"instantiations\": [\"aps_systems_TRUE\", \"aps_systems_FALSE\"], \"priors\": {\"What is the probability for APS_Systems=aps_systems_TRUE?\": \"%?\", \"What is the probability for APS_Systems=aps_systems_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\"}}\n        /* What is the probability for Advanced_AI_Capability=advanced_ai_capability_TRUE? */\n        /* What is the probability for Advanced_AI_Capability=advanced_ai_capability_FALSE? */\n        + [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {\"instantiations\": [\"advanced_ai_capability_TRUE\", \"advanced_ai_capability_FALSE\"], \"priors\": {\"What is the probability for Advanced_AI_Capability=advanced_ai_capability_TRUE?\": \"%?\", \"What is the probability for Advanced_AI_Capability=advanced_ai_capability_FALSE?\": \"%?\"}}\n        /* What is the probability for Agentic_Planning=agentic_planning_TRUE? */\n        /* What is the probability for Agentic_Planning=agentic_planning_FALSE? */\n        + [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {\"instantiations\": [\"agentic_planning_TRUE\", \"agentic_planning_FALSE\"], \"priors\": {\"What is the probability for Agentic_Planning=agentic_planning_TRUE?\": \"%?\", \"What is the probability for Agentic_Planning=agentic_planning_FALSE?\": \"%?\"}}\n        /* What is the probability for Strategic_Awareness=strategic_awareness_TRUE? */\n        /* What is the probability for Strategic_Awareness=strategic_awareness_FALSE? */\n        + [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {\"instantiations\": [\"strategic_awareness_TRUE\", \"strategic_awareness_FALSE\"], \"priors\": {\"What is the probability for Strategic_Awareness=strategic_awareness_TRUE?\": \"%?\", \"What is the probability for Strategic_Awareness=strategic_awareness_FALSE?\": \"%?\"}}\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */\n      + [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {\"instantiations\": [\"difficulty_of_alignment_TRUE\", \"difficulty_of_alignment_FALSE\"], \"priors\": {\"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE?\": \"%?\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\"}}\n        /* What is the probability for Instrumental_Convergence=instrumental_convergence_TRUE? */\n        /* What is the probability for Instrumental_Convergence=instrumental_convergence_FALSE? */\n        + [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {\"instantiations\": [\"instrumental_convergence_TRUE\", \"instrumental_convergence_FALSE\"], \"priors\": {\"What is the probability for Instrumental_Convergence=instrumental_convergence_TRUE?\": \"%?\", \"What is the probability for Instrumental_Convergence=instrumental_convergence_FALSE?\": \"%?\"}}\n        /* What is the probability for Problems_With_Proxies=problems_with_proxies_TRUE? */\n        /* What is the probability for Problems_With_Proxies=problems_with_proxies_FALSE? */\n        + [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {\"instantiations\": [\"problems_with_proxies_TRUE\", \"problems_with_proxies_FALSE\"], \"priors\": {\"What is the probability for Problems_With_Proxies=problems_with_proxies_TRUE?\": \"%?\", \"What is the probability for Problems_With_Proxies=problems_with_proxies_FALSE?\": \"%?\"}}\n        /* What is the probability for Problems_With_Search=problems_with_search_TRUE? */\n        /* What is the probability for Problems_With_Search=problems_with_search_FALSE? */\n        + [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {\"instantiations\": [\"problems_with_search_TRUE\", \"problems_with_search_FALSE\"], \"priors\": {\"What is the probability for Problems_With_Search=problems_with_search_TRUE?\": \"%?\", \"What is the probability for Problems_With_Search=problems_with_search_FALSE?\": \"%?\"}}\n      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE? */\n      + [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {\"instantiations\": [\"deployment_decisions_DEPLOY\", \"deployment_decisions_WITHHOLD\"], \"priors\": {\"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY?\": \"%?\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"%?\"}, \"posteriors\": {\"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\"}}\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK? */\n        + [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {\"instantiations\": [\"incentives_to_build_aps_STRONG\", \"incentives_to_build_aps_WEAK\"], \"priors\": {\"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG?\": \"%?\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK?\": \"%?\"}, \"posteriors\": {\"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\"}}\n          /* What is the probability for Usefulness_Of_APS=usefulness_of_aps_HIGH? */\n          /* What is the probability for Usefulness_Of_APS=usefulness_of_aps_LOW? */\n          + [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {\"instantiations\": [\"usefulness_of_aps_HIGH\", \"usefulness_of_aps_LOW\"], \"priors\": {\"What is the probability for Usefulness_Of_APS=usefulness_of_aps_HIGH?\": \"%?\", \"What is the probability for Usefulness_Of_APS=usefulness_of_aps_LOW?\": \"%?\"}}\n          /* What is the probability for Competitive_Dynamics=competitive_dynamics_STRONG? */\n          /* What is the probability for Competitive_Dynamics=competitive_dynamics_WEAK? */\n          + [Competitive_Dynamics]: Competitive pressures between AI developers. {\"instantiations\": [\"competitive_dynamics_STRONG\", \"competitive_dynamics_WEAK\"], \"priors\": {\"What is the probability for Competitive_Dynamics=competitive_dynamics_STRONG?\": \"%?\", \"What is the probability for Competitive_Dynamics=competitive_dynamics_WEAK?\": \"%?\"}}\n        /* What is the probability for Deception_By_AI=deception_by_ai_TRUE? */\n        /* What is the probability for Deception_By_AI=deception_by_ai_FALSE? */\n        + [Deception_By_AI]: AI systems deceiving humans about their true objectives. {\"instantiations\": [\"deception_by_ai_TRUE\", \"deception_by_ai_FALSE\"], \"priors\": {\"What is the probability for Deception_By_AI=deception_by_ai_TRUE?\": \"%?\", \"What is the probability for Deception_By_AI=deception_by_ai_FALSE?\": \"%?\"}}\n    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */\n    + [Corrective_Feedback]: Human society implementing corrections after observing problems. {\"instantiations\": [\"corrective_feedback_EFFECTIVE\", \"corrective_feedback_INEFFECTIVE\"], \"priors\": {\"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"%?\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\"}}\n      /* What is the probability for Warning_Shots=warning_shots_OBSERVED? */\n      /* What is the probability for Warning_Shots=warning_shots_UNOBSERVED? */\n      + [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {\"instantiations\": [\"warning_shots_OBSERVED\", \"warning_shots_UNOBSERVED\"], \"priors\": {\"What is the probability for Warning_Shots=warning_shots_OBSERVED?\": \"%?\", \"What is the probability for Warning_Shots=warning_shots_UNOBSERVED?\": \"%?\"}}\n      /* What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */\n      /* What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */\n      + [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {\"instantiations\": [\"rapid_capability_escalation_TRUE\", \"rapid_capability_escalation_FALSE\"], \"priors\": {\"What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"%?\", \"What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"%?\"}}\n/* What is the probability for Barriers_To_Understanding=barriers_to_understanding_HIGH? */\n/* What is the probability for Barriers_To_Understanding=barriers_to_understanding_LOW? */\n[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {\"instantiations\": [\"barriers_to_understanding_HIGH\", \"barriers_to_understanding_LOW\"], \"priors\": {\"What is the probability for Barriers_To_Understanding=barriers_to_understanding_HIGH?\": \"%?\", \"What is the probability for Barriers_To_Understanding=barriers_to_understanding_LOW?\": \"%?\"}}\n/* What is the probability for Adversarial_Dynamics=adversarial_dynamics_TRUE? */\n/* What is the probability for Adversarial_Dynamics=adversarial_dynamics_FALSE? */\n[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {\"instantiations\": [\"adversarial_dynamics_TRUE\", \"adversarial_dynamics_FALSE\"], \"priors\": {\"What is the probability for Adversarial_Dynamics=adversarial_dynamics_TRUE?\": \"%?\", \"What is the probability for Adversarial_Dynamics=adversarial_dynamics_FALSE?\": \"%?\"}}\n/* What is the probability for Stakes_Of_Error=stakes_of_error_HIGH? */\n/* What is the probability for Stakes_Of_Error=stakes_of_error_LOW? */\n[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {\"instantiations\": [\"stakes_of_error_HIGH\", \"stakes_of_error_LOW\"], \"priors\": {\"What is the probability for Stakes_Of_Error=stakes_of_error_HIGH?\": \"%?\", \"What is the probability for Stakes_Of_Error=stakes_of_error_LOW?\": \"%?\"}}\n...\n\n\n\n\n\n# BayesDown Representation with Placeholder Probabilities\n\n/* This file contains BayesDown syntax with placeholder probabilities.\n   Replace the placeholders with actual probability values based on the \n   questions in the comments. */\n\n/* What is the probability for Existential_Catastrophe=existential_catastrophe_TRUE? */\n/* What is the probability for Existential_Catastrophe=existential_catastrophe_FALSE? */\n[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {\"instantiations\": [\"existential_catastrophe_TRUE\", \"existential_catastrophe_FALSE\"], \"priors\": {\"What is the probability for Existential_Catastrophe=existential_catastrophe_TRUE?\": \"%?\", \"What is the probability for Existential_Catastrophe=existential_catastrophe_FALSE?\": \"%?\"}}\n/* What is the probability for Human_Disempowerment=human_disempowerment_TRUE? */\n/* What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE? */\n/* What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE? */\n/* What is the probability for Human_Disempowerment=human_disempowerment_FALSE? */\n/* What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE? */\n/* What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE? */\n[Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {\"instantiations\": [\"human_disempowerment_TRUE\", \"human_disempowerment_FALSE\"], \"priors\": {\"What is the probability for Human_Disempowerment=human_disempowerment_TRUE?\": \"%?\", \"What is the probability for Human_Disempowerment=human_disempowerment_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?\": \"?%\", \"What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?\": \"?%\", \"What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?\": \"?%\", \"What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?\": \"?%\"}}\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE? */\n  /* What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE? */\n  + [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {\"instantiations\": [\"scale_of_power_seeking_TRUE\", \"scale_of_power_seeking_FALSE\"], \"priors\": {\"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?\": \"%?\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\"}}\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY? */\n    /* What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD? */\n    + [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"], \"priors\": {\"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE?\": \"%?\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\"}}\n      /* What is the probability for APS_Systems=aps_systems_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE? */\n      /* What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE? */\n      + [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {\"instantiations\": [\"aps_systems_TRUE\", \"aps_systems_FALSE\"], \"priors\": {\"What is the probability for APS_Systems=aps_systems_TRUE?\": \"%?\", \"What is the probability for APS_Systems=aps_systems_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\"}}\n        /* What is the probability for Advanced_AI_Capability=advanced_ai_capability_TRUE? */\n        /* What is the probability for Advanced_AI_Capability=advanced_ai_capability_FALSE? */\n        + [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {\"instantiations\": [\"advanced_ai_capability_TRUE\", \"advanced_ai_capability_FALSE\"], \"priors\": {\"What is the probability for Advanced_AI_Capability=advanced_ai_capability_TRUE?\": \"%?\", \"What is the probability for Advanced_AI_Capability=advanced_ai_capability_FALSE?\": \"%?\"}}\n        /* What is the probability for Agentic_Planning=agentic_planning_TRUE? */\n        /* What is the probability for Agentic_Planning=agentic_planning_FALSE? */\n        + [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {\"instantiations\": [\"agentic_planning_TRUE\", \"agentic_planning_FALSE\"], \"priors\": {\"What is the probability for Agentic_Planning=agentic_planning_TRUE?\": \"%?\", \"What is the probability for Agentic_Planning=agentic_planning_FALSE?\": \"%?\"}}\n        /* What is the probability for Strategic_Awareness=strategic_awareness_TRUE? */\n        /* What is the probability for Strategic_Awareness=strategic_awareness_FALSE? */\n        + [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {\"instantiations\": [\"strategic_awareness_TRUE\", \"strategic_awareness_FALSE\"], \"priors\": {\"What is the probability for Strategic_Awareness=strategic_awareness_TRUE?\": \"%?\", \"What is the probability for Strategic_Awareness=strategic_awareness_FALSE?\": \"%?\"}}\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE? */\n      /* What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE? */\n      + [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {\"instantiations\": [\"difficulty_of_alignment_TRUE\", \"difficulty_of_alignment_FALSE\"], \"priors\": {\"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE?\": \"%?\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\"}}\n        /* What is the probability for Instrumental_Convergence=instrumental_convergence_TRUE? */\n        /* What is the probability for Instrumental_Convergence=instrumental_convergence_FALSE? */\n        + [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {\"instantiations\": [\"instrumental_convergence_TRUE\", \"instrumental_convergence_FALSE\"], \"priors\": {\"What is the probability for Instrumental_Convergence=instrumental_convergence_TRUE?\": \"%?\", \"What is the probability for Instrumental_Convergence=instrumental_convergence_FALSE?\": \"%?\"}}\n        /* What is the probability for Problems_With_Proxies=problems_with_proxies_TRUE? */\n        /* What is the probability for Problems_With_Proxies=problems_with_proxies_FALSE? */\n        + [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {\"instantiations\": [\"problems_with_proxies_TRUE\", \"problems_with_proxies_FALSE\"], \"priors\": {\"What is the probability for Problems_With_Proxies=problems_with_proxies_TRUE?\": \"%?\", \"What is the probability for Problems_With_Proxies=problems_with_proxies_FALSE?\": \"%?\"}}\n        /* What is the probability for Problems_With_Search=problems_with_search_TRUE? */\n        /* What is the probability for Problems_With_Search=problems_with_search_FALSE? */\n        + [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {\"instantiations\": [\"problems_with_search_TRUE\", \"problems_with_search_FALSE\"], \"priors\": {\"What is the probability for Problems_With_Search=problems_with_search_TRUE?\": \"%?\", \"What is the probability for Problems_With_Search=problems_with_search_FALSE?\": \"%?\"}}\n      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE? */\n      /* What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE? */\n      + [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {\"instantiations\": [\"deployment_decisions_DEPLOY\", \"deployment_decisions_WITHHOLD\"], \"priors\": {\"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY?\": \"%?\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"%?\"}, \"posteriors\": {\"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\"}}\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG? */\n        /* What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK? */\n        + [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {\"instantiations\": [\"incentives_to_build_aps_STRONG\", \"incentives_to_build_aps_WEAK\"], \"priors\": {\"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG?\": \"%?\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK?\": \"%?\"}, \"posteriors\": {\"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\"}}\n          /* What is the probability for Usefulness_Of_APS=usefulness_of_aps_HIGH? */\n          /* What is the probability for Usefulness_Of_APS=usefulness_of_aps_LOW? */\n          + [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {\"instantiations\": [\"usefulness_of_aps_HIGH\", \"usefulness_of_aps_LOW\"], \"priors\": {\"What is the probability for Usefulness_Of_APS=usefulness_of_aps_HIGH?\": \"%?\", \"What is the probability for Usefulness_Of_APS=usefulness_of_aps_LOW?\": \"%?\"}}\n          /* What is the probability for Competitive_Dynamics=competitive_dynamics_STRONG? */\n          /* What is the probability for Competitive_Dynamics=competitive_dynamics_WEAK? */\n          + [Competitive_Dynamics]: Competitive pressures between AI developers. {\"instantiations\": [\"competitive_dynamics_STRONG\", \"competitive_dynamics_WEAK\"], \"priors\": {\"What is the probability for Competitive_Dynamics=competitive_dynamics_STRONG?\": \"%?\", \"What is the probability for Competitive_Dynamics=competitive_dynamics_WEAK?\": \"%?\"}}\n        /* What is the probability for Deception_By_AI=deception_by_ai_TRUE? */\n        /* What is the probability for Deception_By_AI=deception_by_ai_FALSE? */\n        + [Deception_By_AI]: AI systems deceiving humans about their true objectives. {\"instantiations\": [\"deception_by_ai_TRUE\", \"deception_by_ai_FALSE\"], \"priors\": {\"What is the probability for Deception_By_AI=deception_by_ai_TRUE?\": \"%?\", \"What is the probability for Deception_By_AI=deception_by_ai_FALSE?\": \"%?\"}}\n    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */\n    /* What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */\n    + [Corrective_Feedback]: Human society implementing corrections after observing problems. {\"instantiations\": [\"corrective_feedback_EFFECTIVE\", \"corrective_feedback_INEFFECTIVE\"], \"priors\": {\"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"%?\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\"}}\n      /* What is the probability for Warning_Shots=warning_shots_OBSERVED? */\n      /* What is the probability for Warning_Shots=warning_shots_UNOBSERVED? */\n      + [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {\"instantiations\": [\"warning_shots_OBSERVED\", \"warning_shots_UNOBSERVED\"], \"priors\": {\"What is the probability for Warning_Shots=warning_shots_OBSERVED?\": \"%?\", \"What is the probability for Warning_Shots=warning_shots_UNOBSERVED?\": \"%?\"}}\n      /* What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_TRUE? */\n      /* What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_FALSE? */\n      + [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {\"instantiations\": [\"rapid_capability_escalation_TRUE\", \"rapid_capability_escalation_FALSE\"], \"priors\": {\"What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"%?\", \"What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"%?\"}}\n/* What is the probability for Barriers_To_Understanding=barriers_to_understanding_HIGH? */\n/* What is the probability for Barriers_To_Understanding=barriers_to_understanding_LOW? */\n[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {\"instantiations\": [\"barriers_to_understanding_HIGH\", \"barriers_to_understanding_LOW\"], \"priors\": {\"What is the probability for Barriers_To_Understanding=barriers_to_understanding_HIGH?\": \"%?\", \"What is the probability for Barriers_To_Understanding=barriers_to_understanding_LOW?\": \"%?\"}}\n/* What is the probability for Adversarial_Dynamics=adversarial_dynamics_TRUE? */\n/* What is the probability for Adversarial_Dynamics=adversarial_dynamics_FALSE? */\n[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {\"instantiations\": [\"adversarial_dynamics_TRUE\", \"adversarial_dynamics_FALSE\"], \"priors\": {\"What is the probability for Adversarial_Dynamics=adversarial_dynamics_TRUE?\": \"%?\", \"What is the probability for Adversarial_Dynamics=adversarial_dynamics_FALSE?\": \"%?\"}}\n/* What is the probability for Stakes_Of_Error=stakes_of_error_HIGH? */\n/* What is the probability for Stakes_Of_Error=stakes_of_error_LOW? */\n[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {\"instantiations\": [\"stakes_of_error_HIGH\", \"stakes_of_error_LOW\"], \"priors\": {\"What is the probability for Stakes_Of_Error=stakes_of_error_HIGH?\": \"%?\", \"What is the probability for Stakes_Of_Error=stakes_of_error_LOW?\": \"%?\"}}\n\n\n\n\n\nLoading CSV from ArgDown_WithQuestions.csv...\nSuccessfully loaded CSV with 23 rows.\nGenerating BayesDown syntax with placeholder probabilities...\nBayesDown Questions saved to BayesDownQuestions.md\n\n[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {\"instantiations\": [\"existential_catastrophe_TRUE\", \"existential_catastrophe_FALSE\"], \"priors\": {\"What is the probability for Existential_Catastrophe=existential_catastrophe_TRUE?\": \"%?\", \"What is the probability for Existential_Catastrophe=existential_catastrophe_FALSE?\": \"%?\"}}\n[Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {\"instantiations\": [\"human_disempowerment_TRUE\", \"human_disempowerment_FALSE\"], \"priors\": {\"What is the probability for Human_Disempowerment=human_disempowerment_TRUE?\": \"%?\", \"What is the probability for Human_Disempowerment=human_disempowerment_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?\": \"?%\", \"What is the probability for Human_Disempowerment=human_disempowerment_TRUE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?\": \"?%\", \"What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?\": \"?%\", \"What is the probability for Human_Disempowerment=human_disempowerment_FALSE if Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?\": \"?%\"}}\n  + [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {\"instantiations\": [\"scale_of_power_seeking_TRUE\", \"scale_of_power_seeking_FALSE\"], \"priors\": {\"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE?\": \"%?\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_TRUE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_TRUE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"?%\", \"What is the probability for Scale_Of_Power_Seeking=scale_of_power_seeking_FALSE if Misaligned_Power_Seeking=misaligned_power_seeking_FALSE, Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"?%\"}}\n    + [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"], \"priors\": {\"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE?\": \"%?\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_TRUE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_TRUE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_TRUE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_DEPLOY?\": \"?%\", \"What is the probability for Misaligned_Power_Seeking=misaligned_power_seeking_FALSE if APS_Systems=aps_systems_FALSE, Difficulty_Of_Alignment=difficulty_of_alignment_FALSE, Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"?%\"}}\n      + [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {\"instantiations\": [\"aps_systems_TRUE\", \"aps_systems_FALSE\"], \"priors\": {\"What is the probability for APS_Systems=aps_systems_TRUE?\": \"%?\", \"What is the probability for APS_Systems=aps_systems_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_TRUE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_TRUE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_TRUE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_TRUE?\": \"?%\", \"What is the probability for APS_Systems=aps_systems_FALSE if Advanced_AI_Capability=advanced_ai_capability_FALSE, Agentic_Planning=agentic_planning_FALSE, Strategic_Awareness=strategic_awareness_FALSE?\": \"?%\"}}\n        + [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {\"instantiations\": [\"advanced_ai_capability_TRUE\", \"advanced_ai_capability_FALSE\"], \"priors\": {\"What is the probability for Advanced_AI_Capability=advanced_ai_capability_TRUE?\": \"%?\", \"What is the probability for Advanced_AI_Capability=advanced_ai_capability_FALSE?\": \"%?\"}}\n        + [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {\"instantiations\": [\"agentic_planning_TRUE\", \"agentic_planning_FALSE\"], \"priors\": {\"What is the probability for Agentic_Planning=agentic_planning_TRUE?\": \"%?\", \"What is the probability for Agentic_Planning=agentic_planning_FALSE?\": \"%?\"}}\n        + [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {\"instantiations\": [\"strategic_awareness_TRUE\", \"strategic_awareness_FALSE\"], \"priors\": {\"What is the probability for Strategic_Awareness=strategic_awareness_TRUE?\": \"%?\", \"What is the probability for Strategic_Awareness=strategic_awareness_FALSE?\": \"%?\"}}\n      + [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {\"instantiations\": [\"difficulty_of_alignment_TRUE\", \"difficulty_of_alignment_FALSE\"], \"priors\": {\"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE?\": \"%?\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_TRUE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_TRUE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_TRUE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_TRUE?\": \"?%\", \"What is the probability for Difficulty_Of_Alignment=difficulty_of_alignment_FALSE if Instrumental_Convergence=instrumental_convergence_FALSE, Problems_With_Proxies=problems_with_proxies_FALSE, Problems_With_Search=problems_with_search_FALSE?\": \"?%\"}}\n        + [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {\"instantiations\": [\"instrumental_convergence_TRUE\", \"instrumental_convergence_FALSE\"], \"priors\": {\"What is the probability for Instrumental_Convergence=instrumental_convergence_TRUE?\": \"%?\", \"What is the probability for Instrumental_Convergence=instrumental_convergence_FALSE?\": \"%?\"}}\n        + [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {\"instantiations\": [\"problems_with_proxies_TRUE\", \"problems_with_proxies_FALSE\"], \"priors\": {\"What is the probability for Problems_With_Proxies=problems_with_proxies_TRUE?\": \"%?\", \"What is the probability for Problems_With_Proxies=problems_with_proxies_FALSE?\": \"%?\"}}\n        + [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {\"instantiations\": [\"problems_with_search_TRUE\", \"problems_with_search_FALSE\"], \"priors\": {\"What is the probability for Problems_With_Search=problems_with_search_TRUE?\": \"%?\", \"What is the probability for Problems_With_Search=problems_with_search_FALSE?\": \"%?\"}}\n      + [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {\"instantiations\": [\"deployment_decisions_DEPLOY\", \"deployment_decisions_WITHHOLD\"], \"priors\": {\"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY?\": \"%?\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD?\": \"%?\"}, \"posteriors\": {\"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_DEPLOY if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_STRONG, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_TRUE?\": \"?%\", \"What is the probability for Deployment_Decisions=deployment_decisions_WITHHOLD if Incentives_To_Build_APS=incentives_to_build_aps_WEAK, Deception_By_AI=deception_by_ai_FALSE?\": \"?%\"}}\n        + [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {\"instantiations\": [\"incentives_to_build_aps_STRONG\", \"incentives_to_build_aps_WEAK\"], \"priors\": {\"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG?\": \"%?\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK?\": \"%?\"}, \"posteriors\": {\"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_STRONG if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_HIGH, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_STRONG?\": \"?%\", \"What is the probability for Incentives_To_Build_APS=incentives_to_build_aps_WEAK if Usefulness_Of_APS=usefulness_of_aps_LOW, Competitive_Dynamics=competitive_dynamics_WEAK?\": \"?%\"}}\n          + [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {\"instantiations\": [\"usefulness_of_aps_HIGH\", \"usefulness_of_aps_LOW\"], \"priors\": {\"What is the probability for Usefulness_Of_APS=usefulness_of_aps_HIGH?\": \"%?\", \"What is the probability for Usefulness_Of_APS=usefulness_of_aps_LOW?\": \"%?\"}}\n          + [Competitive_Dynamics]: Competitive pressures between AI developers. {\"instantiations\": [\"competitive_dynamics_STRONG\", \"competitive_dynamics_WEAK\"], \"priors\": {\"What is the probability for Competitive_Dynamics=competitive_dynamics_STRONG?\": \"%?\", \"What is the probability for Competitive_Dynamics=competitive_dynamics_WEAK?\": \"%?\"}}\n        + [Deception_By_AI]: AI systems deceiving humans about their true objectives. {\"instantiations\": [\"deception_by_ai_TRUE\", \"deception_by_ai_FALSE\"], \"priors\": {\"What is the probability for Deception_By_AI=deception_by_ai_TRUE?\": \"%?\", \"What is the probability for Deception_By_AI=deception_by_ai_FALSE?\": \"%?\"}}\n    + [Corrective_Feedback]: Human society implementing corrections after observing problems. {\"instantiations\": [\"corrective_feedback_EFFECTIVE\", \"corrective_feedback_INEFFECTIVE\"], \"priors\": {\"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE?\": \"%?\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE?\": \"%?\"}, \"posteriors\": {\"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_EFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_OBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"?%\", \"What is the probability for Corrective_Feedback=corrective_feedback_INEFFECTIVE if Warning_Shots=warning_shots_UNOBSERVED, Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"?%\"}}\n      + [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {\"instantiations\": [\"warning_shots_OBSERVED\", \"warning_shots_UNOBSERVED\"], \"priors\": {\"What is the probability for Warning_Shots=warning_shots_OBSERVED?\": \"%?\", \"What is the probability for Warning_Shots=warning_shots_UNOBSERVED?\": \"%?\"}}\n      + [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {\"instantiations\": [\"rapid_capability_escalation_TRUE\", \"rapid_capability_escalation_FALSE\"], \"priors\": {\"What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_TRUE?\": \"%?\", \"What is the probability for Rapid_Capability_Escalation=rapid_capability_escalation_FALSE?\": \"%?\"}}\n[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {\"instantiations\": [\"barriers_to_understanding_HIGH\", \"barriers_to_understanding_LOW\"], \"priors\": {\"What is the probability for Barriers_To_Understanding=barriers_to_understanding_HIGH?\": \"%?\", \"What is the probability for Barriers_To_Understanding=barriers_to_understanding_LOW?\": \"%?\"}}\n[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {\"instantiations\": [\"adversarial_dynamics_TRUE\", \"adversarial_dynamics_FALSE\"], \"priors\": {\"What is the probability for Adversarial_Dynamics=adversarial_dynamics_TRUE?\": \"%?\", \"What is the probability for Adversarial_Dynamics=adversarial_dynamics_FALSE?\": \"%?\"}}\n[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {\"instantiations\": [\"stakes_of_error_HIGH\", \"stakes_of_error_LOW\"], \"priors\": {\"What is the probability for Stakes_Of_Error=stakes_of_error_HIGH?\": \"%?\", \"What is the probability for Stakes_Of_Error=stakes_of_error_LOW?\": \"%?\"}}\n...",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#generate-bayesdown-probability-extraction-prompt",
    "href": "chapters/appendixA.html#generate-bayesdown-probability-extraction-prompt",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "8.5 2.3 Generate BayesDown Probability Extraction Prompt",
    "text": "8.5 2.3 Generate BayesDown Probability Extraction Prompt\nGenerate 2nd Extraction Prompt for Probabilities based on the questions generated from the ‘ArgDown.csv’ extraction",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#bayesdown-format-specification",
    "href": "chapters/appendixA.html#bayesdown-format-specification",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "8.6 2.3.1 BayesDown Format Specification",
    "text": "8.6 2.3.1 BayesDown Format Specification\nBayesDown extends ArgDown with probability data in a structured JSON format to represent Bayesian networks. This intermediate representation bridges the gap between natural language arguments and formal probabilistic models, preserving both narrative structure and quantitative relationships.\n\n8.6.1 Core Structure\nA BayesDown representation consists of:\n\nNodes: Variables or statements in brackets [Node_Name] with descriptive text\nRelationships: Hierarchical structure with indentation and + symbols\nMetadata: JSON objects containing probability information:\n\n{\n  \"instantiations\": [\"state_TRUE\", \"state_FALSE\"],  // Possible states of variable\n  \"priors\": {\n    \"p(state_TRUE)\": \"0.7\",   // Unconditional probability of state_TRUE\n    \"p(state_FALSE)\": \"0.3\"   // Unconditional probability of state_FALSE\n  },\n  \"posteriors\": {\n    \"p(state_TRUE|condition1_TRUE,condition2_FALSE)\": \"0.9\",  // Conditional on parent states\n    \"p(state_TRUE|condition1_FALSE,condition2_TRUE)\": \"0.4\"   // Different parent configuration\n  }\n}\n\n##### Rain-Sprinkler-Lawn Example\n[Grass_Wet]: Concentrated moisture on grass. {\"instantiations\": [\"grass_wet_TRUE\", \"grass_wet_FALSE\"],\n\"priors\": {\"p(grass_wet_TRUE)\": \"0.322\", \"p(grass_wet_FALSE)\": \"0.678\"},\n\"posteriors\": {\"p(grass_wet_TRUE|sprinkler_TRUE,rain_TRUE)\": \"0.99\",\n\"p(grass_wet_TRUE|sprinkler_TRUE,rain_FALSE)\": \"0.9\",\n\"p(grass_wet_TRUE|sprinkler_FALSE,rain_TRUE)\": \"0.8\",\n\"p(grass_wet_TRUE|sprinkler_FALSE,rain_FALSE)\": \"0.0\"}}\n + [Rain]: Water falling from the sky. {\"instantiations\": [\"rain_TRUE\", \"rain_FALSE\"],\n \"priors\": {\"p(rain_TRUE)\": \"0.2\", \"p(rain_FALSE)\": \"0.8\"}}\n + [Sprinkler]: Artificial watering system. {\"instantiations\": [\"sprinkler_TRUE\", \"sprinkler_FALSE\"],\n \"priors\": {\"p(sprinkler_TRUE)\": \"0.44838\", \"p(sprinkler_FALSE)\": \"0.55162\"},\n \"posteriors\": {\"p(sprinkler_TRUE|rain_TRUE)\": \"0.01\", \"p(sprinkler_TRUE|rain_FALSE)\": \"0.4\"}}\n   + [Rain]\n\n\nIn this example:\n\n+ Grass_Wet is the effect/outcome node\n+ Rain and Sprinkler are parent nodes (causes)\n+ Rain also influences Sprinkler (people tend not to use sprinklers when it's raining)\n\nRole in AMTAIR\nBayesDown serves as the critical intermediate representation in the AMTAIR extraction pipeline, bridging between qualitative arguments in AI safety literature and formal Bayesian networks that can be used for probabilistic reasoning and policy evaluation. By preserving both narrative explanation and probabilistic information, it enables the automated extraction of world models while maintaining traceability to the original arguments.\nFor full syntax details, see the BayesDownSyntax.md file in the repository.\n\n2.3.2 Probability Extraction Process\nThe probability extraction pipeline follows these steps:\n\n\nIdentify variables and their possible states\nExtract prior probability statements\nIdentify conditional relationships\nExtract conditional probability statements\nFormat the data in BayesDown syntax\n\n2.3.3 Implementation Steps\nTo extract probabilities and create BayesDown format:\n\nRun the extract_probabilities function on ArgDown text\nProcess the results into a structured format\nValidate the probability distributions (ensure they sum to 1)\nGenerate the enhanced BayesDown representation\n\n2.3.4 Validation and Quality Control\nThe probability extraction process includes validation steps:\n\nEnsuring coherent probability distributions\nChecking for logical consistency in conditional relationships\nVerifying that all required probability statements are present\nHandling missing data with appropriate default values\n\n## 2.4 Prepare 2nd API call\n\n## 2.5 Make BayesDown Probability Extraction API Call\n\n## 2.6 Save BayesDown with Probability Estimates (.csv)\n\n## 2.7 Review & Verify BayesDown Probability Estimates\n\n## 2.7.2 Check the Graph Structure with the ArgDown Sandbox Online\nCopy and paste the BayesDown formatted ... in the ArgDown Sandbox below to quickly verify that the network renders correctly.\n\n## 2.8 Extract BayesDown with Probability Estimates as Dataframe\n\n# 3.0 Data Extraction: BayesDown (.md) to Database (.csv)\n\n# 3. BayesDown to Structured Data: Network Construction\n\n## Extraction Pipeline Overview\n\nThis section implements the core extraction pipeline described in the AMTAIR project documentation (see `PY_TechnicalImplementation.md`), which transforms structured argument representations into formal Bayesian networks through a series of processing steps:\n\n1. **Input**: Text in BayesDown format (see Section 2.3.1)\n2. **Parsing**: Extract nodes, relationships, and probability information\n3. **Structuring**: Organize into a DataFrame with formal relationships\n4. **Enhancement**: Add derived properties and network metrics\n5. **Output**: Structured data ready for Bayesian network construction\n\n### Theoretical Foundation\n\nThis implementation follows the extraction algorithm outlined in the AMTAIR project description:\n\n1. Get nodes: All premises and conclusions from the argument structure\n2. Get edges: Parent-child relationships between nodes\n3. Extract probability distributions: Prior and conditional probabilities\n4. Calculate derived metrics: Network statistics and node classifications\n\nThe resulting structured data maintains the complete information needed to reconstruct the Bayesian network while enabling additional analysis and visualization.\n\n### Role in Thesis Research\n\nThis extraction pipeline represents a key contribution of the Master's thesis, demonstrating how argument structures from AI safety literature can be automatically transformed into formal probabilistic models. While the current implementation focuses on pre-formatted BayesDown, the architecture is designed to be extended with LLM-powered extraction directly from natural language in future work.\n\nThe rain-sprinkler-lawn example serves as a simple but complete test case, demonstrating every step in the pipeline from structured text to interactive Bayesian network visualization.\n\n### 3.1 ExtractBayesDown-Data_v1\nBuild data frame with extractable information from BayesDown\n\n::: {#cell-63 .cell quarto-private-1='{\"key\":\"colab\",\"value\":{\"base_uri\":\"https://localhost:8080/\",\"height\":122}}' outputId='e0bc7224-c20b-4662-ba80-898e88b06523'}\n\n::: {.cell-output .cell-output-display execution_count=34}\n‘[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {“instantiations”: [“existential_catastrophe_TRUE”, “existential_catastrophe_FALSE”], “priors”: {“p(existential_catastrophe_TRUE)”: “0.05”, “p(existential_catastrophe_FALSE)”: “0.95”}, “posteriors”: {“p(existential_catastrophe_TRUE|human_disempowerment_TRUE)”: “0.95”, “p(existential_catastrophe_TRUE|human_disempowerment_FALSE)”: “0.0”, “p(existential_catastrophe_FALSE|human_disempowerment_TRUE)”: “0.05”, “p(existential_catastrophe_FALSE|human_disempowerment_FALSE)”: “1.0”}}- [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {“instantiations”: [“human_disempowerment_TRUE”, “human_disempowerment_FALSE”], “priors”: {“p(human_disempowerment_TRUE)”: “0.208”, “p(human_disempowerment_FALSE)”: “0.792”}, “posteriors”: {“p(human_disempowerment_TRUE|scale_of_power_seeking_TRUE)”: “1.0”, “p(human_disempowerment_TRUE|scale_of_power_seeking_FALSE)”: “0.0”, “p(human_disempowerment_FALSE|scale_of_power_seeking_TRUE)”: “0.0”, “p(human_disempowerment_FALSE|scale_of_power_seeking_FALSE)”: “1.0”}}- [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {“instantiations”: [“scale_of_power_seeking_TRUE”, “scale_of_power_seeking_FALSE”], “priors”: {“p(scale_of_power_seeking_TRUE)”: “0.208”, “p(scale_of_power_seeking_FALSE)”: “0.792”}, “posteriors”: {“p(scale_of_power_seeking_TRUE|misaligned_power_seeking_TRUE, corrective_feedback_EFFECTIVE)”: “0.25”, “p(scale_of_power_seeking_TRUE|misaligned_power_seeking_TRUE, corrective_feedback_INEFFECTIVE)”: “0.60”, “p(scale_of_power_seeking_TRUE|misaligned_power_seeking_FALSE, corrective_feedback_EFFECTIVE)”: “0.0”, “p(scale_of_power_seeking_TRUE|misaligned_power_seeking_FALSE, corrective_feedback_INEFFECTIVE)”: “0.0”, “p(scale_of_power_seeking_FALSE|misaligned_power_seeking_TRUE, corrective_feedback_EFFECTIVE)”: “0.75”, “p(scale_of_power_seeking_FALSE|misaligned_power_seeking_TRUE, corrective_feedback_INEFFECTIVE)”: “0.40”, “p(scale_of_power_seeking_FALSE|misaligned_power_seeking_FALSE, corrective_feedback_EFFECTIVE)”: “1.0”, “p(scale_of_power_seeking_FALSE|misaligned_power_seeking_FALSE, corrective_feedback_INEFFECTIVE)”: “1.0”}}- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {“instantiations”: [“misaligned_power_seeking_TRUE”, “misaligned_power_seeking_FALSE”], “priors”: {“p(misaligned_power_seeking_TRUE)”: “0.338”, “p(misaligned_power_seeking_FALSE)”: “0.662”}, “posteriors”: {“p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)”: “0.90”, “p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_WITHHOLD)”: “0.10”, “p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)”: “0.25”, “p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_WITHHOLD)”: “0.05”, “p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)”: “0.0”, “p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_WITHHOLD)”: “0.0”, “p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)”: “0.0”, “p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_FALSE, deployment_decisions_WITHHOLD)”: “0.0”, “p(misaligned_power_seeking_FALSE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)”: “0.10”, “p(misaligned_power_seeking_FALSE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_WITHHOLD)”: “0.90”, “p(misaligned_power_seeking_FALSE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)”: “0.75”, “p(misaligned_power_seeking_FALSE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_WITHHOLD)”: “0.95”, “p(misaligned_power_seeking_FALSE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)”: “1.0”, “p(misaligned_power_seeking_FALSE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_WITHHOLD)”: “1.0”, “p(misaligned_power_seeking_FALSE|aps_systems_FALSE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)”: “1.0”, “p(misaligned_power_seeking_FALSE|aps_systems_FALSE, difficulty_of_alignment_FALSE, deployment_decisions_WITHHOLD)”: “1.0”}}- [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {“instantiations”: [“aps_systems_TRUE”, “aps_systems_FALSE”], “priors”: {“p(aps_systems_TRUE)”: “0.65”, “p(aps_systems_FALSE)”: “0.35”}, “posteriors”: {“p(aps_systems_TRUE|advanced_ai_capability_TRUE, agentic_planning_TRUE, strategic_awareness_TRUE)”: “1.0”, “p(aps_systems_TRUE|advanced_ai_capability_TRUE, agentic_planning_TRUE, strategic_awareness_FALSE)”: “0.0”, “p(aps_systems_TRUE|advanced_ai_capability_TRUE, agentic_planning_FALSE, strategic_awareness_TRUE)”: “0.0”, “p(aps_systems_TRUE|advanced_ai_capability_TRUE, agentic_planning_FALSE, strategic_awareness_FALSE)”: “0.0”, “p(aps_systems_TRUE|advanced_ai_capability_FALSE, agentic_planning_TRUE, strategic_awareness_TRUE)”: “0.0”, “p(aps_systems_TRUE|advanced_ai_capability_FALSE, agentic_planning_TRUE, strategic_awareness_FALSE)”: “0.0”, “p(aps_systems_TRUE|advanced_ai_capability_FALSE, agentic_planning_FALSE, strategic_awareness_TRUE)”: “0.0”, “p(aps_systems_TRUE|advanced_ai_capability_FALSE, agentic_planning_FALSE, strategic_awareness_FALSE)”: “0.0”, “p(aps_systems_FALSE|advanced_ai_capability_TRUE, agentic_planning_TRUE, strategic_awareness_TRUE)”: “0.0”, “p(aps_systems_FALSE|advanced_ai_capability_TRUE, agentic_planning_TRUE, strategic_awareness_FALSE)”: “1.0”, “p(aps_systems_FALSE|advanced_ai_capability_TRUE, agentic_planning_FALSE, strategic_awareness_TRUE)”: “1.0”, “p(aps_systems_FALSE|advanced_ai_capability_TRUE, agentic_planning_FALSE, strategic_awareness_FALSE)”: “1.0”, “p(aps_systems_FALSE|advanced_ai_capability_FALSE, agentic_planning_TRUE, strategic_awareness_TRUE)”: “1.0”, “p(aps_systems_FALSE|advanced_ai_capability_FALSE, agentic_planning_TRUE, strategic_awareness_FALSE)”: “1.0”, “p(aps_systems_FALSE|advanced_ai_capability_FALSE, agentic_planning_FALSE, strategic_awareness_TRUE)”: “1.0”, “p(aps_systems_FALSE|advanced_ai_capability_FALSE, agentic_planning_FALSE, strategic_awareness_FALSE)”: “1.0”}}- [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {“instantiations”: [“advanced_ai_capability_TRUE”, “advanced_ai_capability_FALSE”], “priors”: {“p(advanced_ai_capability_TRUE)”: “0.80”, “p(advanced_ai_capability_FALSE)”: “0.20”}}- [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {“instantiations”: [“agentic_planning_TRUE”, “agentic_planning_FALSE”], “priors”: {“p(agentic_planning_TRUE)”: “0.85”, “p(agentic_planning_FALSE)”: “0.15”}}- [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {“instantiations”: [“strategic_awareness_TRUE”, “strategic_awareness_FALSE”], “priors”: {“p(strategic_awareness_TRUE)”: “0.75”, “p(strategic_awareness_FALSE)”: “0.25”}}- [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {“instantiations”: [“difficulty_of_alignment_TRUE”, “difficulty_of_alignment_FALSE”], “priors”: {“p(difficulty_of_alignment_TRUE)”: “0.40”, “p(difficulty_of_alignment_FALSE)”: “0.60”}, “posteriors”: {“p(difficulty_of_alignment_TRUE|instrumental_convergence_TRUE, problems_with_proxies_TRUE, problems_with_search_TRUE)”: “0.85”, “p(difficulty_of_alignment_TRUE|instrumental_convergence_TRUE, problems_with_proxies_TRUE, problems_with_search_FALSE)”: “0.70”, “p(difficulty_of_alignment_TRUE|instrumental_convergence_TRUE, problems_with_proxies_FALSE, problems_with_search_TRUE)”: “0.60”, “p(difficulty_of_alignment_TRUE|instrumental_convergence_TRUE, problems_with_proxies_FALSE, problems_with_search_FALSE)”: “0.40”, “p(difficulty_of_alignment_TRUE|instrumental_convergence_FALSE, problems_with_proxies_TRUE, problems_with_search_TRUE)”: “0.55”, “p(difficulty_of_alignment_TRUE|instrumental_convergence_FALSE, problems_with_proxies_TRUE, problems_with_search_FALSE)”: “0.40”, “p(difficulty_of_alignment_TRUE|instrumental_convergence_FALSE, problems_with_proxies_FALSE, problems_with_search_TRUE)”: “0.30”, “p(difficulty_of_alignment_TRUE|instrumental_convergence_FALSE, problems_with_proxies_FALSE, problems_with_search_FALSE)”: “0.10”, “p(difficulty_of_alignment_FALSE|instrumental_convergence_TRUE, problems_with_proxies_TRUE, problems_with_search_TRUE)”: “0.15”, “p(difficulty_of_alignment_FALSE|instrumental_convergence_TRUE, problems_with_proxies_TRUE, problems_with_search_FALSE)”: “0.30”, “p(difficulty_of_alignment_FALSE|instrumental_convergence_TRUE, problems_with_proxies_FALSE, problems_with_search_TRUE)”: “0.40”, “p(difficulty_of_alignment_FALSE|instrumental_convergence_TRUE, problems_with_proxies_FALSE, problems_with_search_FALSE)”: “0.60”, “p(difficulty_of_alignment_FALSE|instrumental_convergence_FALSE, problems_with_proxies_TRUE, problems_with_search_TRUE)”: “0.45”, “p(difficulty_of_alignment_FALSE|instrumental_convergence_FALSE, problems_with_proxies_TRUE, problems_with_search_FALSE)”: “0.60”, “p(difficulty_of_alignment_FALSE|instrumental_convergence_FALSE, problems_with_proxies_FALSE, problems_with_search_TRUE)”: “0.70”, “p(difficulty_of_alignment_FALSE|instrumental_convergence_FALSE, problems_with_proxies_FALSE, problems_with_search_FALSE)”: “0.90”}}- [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {“instantiations”: [“instrumental_convergence_TRUE”, “instrumental_convergence_FALSE”], “priors”: {“p(instrumental_convergence_TRUE)”: “0.75”, “p(instrumental_convergence_FALSE)”: “0.25”}}- [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {“instantiations”: [“problems_with_proxies_TRUE”, “problems_with_proxies_FALSE”], “priors”: {“p(problems_with_proxies_TRUE)”: “0.80”, “p(problems_with_proxies_FALSE)”: “0.20”}}- [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {“instantiations”: [“problems_with_search_TRUE”, “problems_with_search_FALSE”], “priors”: {“p(problems_with_search_TRUE)”: “0.70”, “p(problems_with_search_FALSE)”: “0.30”}}- [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {“instantiations”: [“deployment_decisions_DEPLOY”, “deployment_decisions_WITHHOLD”], “priors”: {“p(deployment_decisions_DEPLOY)”: “0.70”, “p(deployment_decisions_WITHHOLD)”: “0.30”}, “posteriors”: {“p(deployment_decisions_DEPLOY|incentives_to_build_aps_STRONG, deception_by_ai_TRUE)”: “0.90”, “p(deployment_decisions_DEPLOY|incentives_to_build_aps_STRONG, deception_by_ai_FALSE)”: “0.75”, “p(deployment_decisions_DEPLOY|incentives_to_build_aps_WEAK, deception_by_ai_TRUE)”: “0.60”, “p(deployment_decisions_DEPLOY|incentives_to_build_aps_WEAK, deception_by_ai_FALSE)”: “0.30”, “p(deployment_decisions_WITHHOLD|incentives_to_build_aps_STRONG, deception_by_ai_TRUE)”: “0.10”, “p(deployment_decisions_WITHHOLD|incentives_to_build_aps_STRONG, deception_by_ai_FALSE)”: “0.25”, “p(deployment_decisions_WITHHOLD|incentives_to_build_aps_WEAK, deception_by_ai_TRUE)”: “0.40”, “p(deployment_decisions_WITHHOLD|incentives_to_build_aps_WEAK, deception_by_ai_FALSE)”: “0.70”}}- [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {“instantiations”: [“incentives_to_build_aps_STRONG”, “incentives_to_build_aps_WEAK”], “priors”: {“p(incentives_to_build_aps_STRONG)”: “0.80”, “p(incentives_to_build_aps_WEAK)”: “0.20”}, “posteriors”: {“p(incentives_to_build_aps_STRONG|usefulness_of_aps_HIGH, competitive_dynamics_STRONG)”: “0.95”, “p(incentives_to_build_aps_STRONG|usefulness_of_aps_HIGH, competitive_dynamics_WEAK)”: “0.80”, “p(incentives_to_build_aps_STRONG|usefulness_of_aps_LOW, competitive_dynamics_STRONG)”: “0.70”, “p(incentives_to_build_aps_STRONG|usefulness_of_aps_LOW, competitive_dynamics_WEAK)”: “0.30”, “p(incentives_to_build_aps_WEAK|usefulness_of_aps_HIGH, competitive_dynamics_STRONG)”: “0.05”, “p(incentives_to_build_aps_WEAK|usefulness_of_aps_HIGH, competitive_dynamics_WEAK)”: “0.20”, “p(incentives_to_build_aps_WEAK|usefulness_of_aps_LOW, competitive_dynamics_STRONG)”: “0.30”, “p(incentives_to_build_aps_WEAK|usefulness_of_aps_LOW, competitive_dynamics_WEAK)”: “0.70”}}- [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {“instantiations”: [“usefulness_of_aps_HIGH”, “usefulness_of_aps_LOW”], “priors”: {“p(usefulness_of_aps_HIGH)”: “0.85”, “p(usefulness_of_aps_LOW)”: “0.15”}}- [Competitive_Dynamics]: Competitive pressures between AI developers. {“instantiations”: [“competitive_dynamics_STRONG”, “competitive_dynamics_WEAK”], “priors”: {“p(competitive_dynamics_STRONG)”: “0.75”, “p(competitive_dynamics_WEAK)”: “0.25”}}- [Deception_By_AI]: AI systems deceiving humans about their true objectives. {“instantiations”: [“deception_by_ai_TRUE”, “deception_by_ai_FALSE”], “priors”: {“p(deception_by_ai_TRUE)”: “0.50”, “p(deception_by_ai_FALSE)”: “0.50”}}- [Corrective_Feedback]: Human society implementing corrections after observing problems. {“instantiations”: [“corrective_feedback_EFFECTIVE”, “corrective_feedback_INEFFECTIVE”], “priors”: {“p(corrective_feedback_EFFECTIVE)”: “0.60”, “p(corrective_feedback_INEFFECTIVE)”: “0.40”}, “posteriors”: {“p(corrective_feedback_EFFECTIVE|warning_shots_OBSERVED, rapid_capability_escalation_TRUE)”: “0.40”, “p(corrective_feedback_EFFECTIVE|warning_shots_OBSERVED, rapid_capability_escalation_FALSE)”: “0.80”, “p(corrective_feedback_EFFECTIVE|warning_shots_UNOBSERVED, rapid_capability_escalation_TRUE)”: “0.15”, “p(corrective_feedback_EFFECTIVE|warning_shots_UNOBSERVED, rapid_capability_escalation_FALSE)”: “0.50”, “p(corrective_feedback_INEFFECTIVE|warning_shots_OBSERVED, rapid_capability_escalation_TRUE)”: “0.60”, “p(corrective_feedback_INEFFECTIVE|warning_shots_OBSERVED, rapid_capability_escalation_FALSE)”: “0.20”, “p(corrective_feedback_INEFFECTIVE|warning_shots_UNOBSERVED, rapid_capability_escalation_TRUE)”: “0.85”, “p(corrective_feedback_INEFFECTIVE|warning_shots_UNOBSERVED, rapid_capability_escalation_FALSE)”: “0.50”}}- [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {“instantiations”: [“warning_shots_OBSERVED”, “warning_shots_UNOBSERVED”], “priors”: {“p(warning_shots_OBSERVED)”: “0.70”, “p(warning_shots_UNOBSERVED)”: “0.30”}}- [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {“instantiations”: [“rapid_capability_escalation_TRUE”, “rapid_capability_escalation_FALSE”], “priors”: {“p(rapid_capability_escalation_TRUE)”: “0.45”, “p(rapid_capability_escalation_FALSE)”: “0.55”}}: Difficulty in understanding the internal workings of advanced AI systems. {“instantiations”: [“barriers_to_understanding_HIGH”, “barriers_to_understanding_LOW”], “priors”: {“p(barriers_to_understanding_HIGH)”: “0.70”, “p(barriers_to_understanding_LOW)”: “0.30”}, “posteriors”: {“p(barriers_to_understanding_HIGH|misaligned_power_seeking_TRUE)”: “0.85”, “p(barriers_to_understanding_HIGH|misaligned_power_seeking_FALSE)”: “0.60”, “p(barriers_to_understanding_LOW|misaligned_power_seeking_TRUE)”: “0.15”, “p(barriers_to_understanding_LOW|misaligned_power_seeking_FALSE)”: “0.40”}}- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {“instantiations”: [“misaligned_power_seeking_TRUE”, “misaligned_power_seeking_FALSE”], “priors”: {“p(misaligned_power_seeking_TRUE)”: “0.338”, “p(misaligned_power_seeking_FALSE)”: “0.662”}}: Potentially adversarial relationships between humans and power-seeking AI. {“instantiations”: [“adversarial_dynamics_TRUE”, “adversarial_dynamics_FALSE”], “priors”: {“p(adversarial_dynamics_TRUE)”: “0.60”, “p(adversarial_dynamics_FALSE)”: “0.40”}, “posteriors”: {“p(adversarial_dynamics_TRUE|misaligned_power_seeking_TRUE)”: “0.95”, “p(adversarial_dynamics_TRUE|misaligned_power_seeking_FALSE)”: “0.10”, “p(adversarial_dynamics_FALSE|misaligned_power_seeking_TRUE)”: “0.05”, “p(adversarial_dynamics_FALSE|misaligned_power_seeking_FALSE)”: “0.90”}}- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {“instantiations”: [“misaligned_power_seeking_TRUE”, “misaligned_power_seeking_FALSE”], “priors”: {“p(misaligned_power_seeking_TRUE)”: “0.338”, “p(misaligned_power_seeking_FALSE)”: “0.662”}}: The escalating impact of mistakes with power-seeking AI systems. {“instantiations”: [“stakes_of_error_HIGH”, “stakes_of_error_LOW”], “priors”: {“p(stakes_of_error_HIGH)”: “0.85”, “p(stakes_of_error_LOW)”: “0.15”}, “posteriors”: {“p(stakes_of_error_HIGH|misaligned_power_seeking_TRUE)”: “0.95”, “p(stakes_of_error_HIGH|misaligned_power_seeking_FALSE)”: “0.50”, “p(stakes_of_error_LOW|misaligned_power_seeking_TRUE)”: “0.05”, “p(stakes_of_error_LOW|misaligned_power_seeking_FALSE)”: “0.50”}}- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {“instantiations”: [“misaligned_power_seeking_TRUE”, “misaligned_power_seeking_FALSE”], “priors”: {“p(misaligned_power_seeking_TRUE)”: “0.338”, “p(misaligned_power_seeking_FALSE)”: “0.662”}}’\n:::\n:::\n\n\n## 3.1.2 Test BayesDown Extraction\n\n\n::: {#cell-66 .cell quarto-private-1='{\"key\":\"colab\",\"value\":{\"base_uri\":\"https://localhost:8080/\",\"height\":1000}}' outputId='a859bf73-6cf1-4ce0-d4c0-4ff827584086'}\n\n::: {.cell-output .cell-output-display .cell-output-markdown}\n[Existential_Catastrophe]: The destruction of humanity's long-term potential due to AI systems we've lost control over. {\"instantiations\": [\"existential_catastrophe_TRUE\", \"existential_catastrophe_FALSE\"], \"priors\": {\"p(existential_catastrophe_TRUE)\": \"0.05\", \"p(existential_catastrophe_FALSE)\": \"0.95\"}, \"posteriors\": {\"p(existential_catastrophe_TRUE|human_disempowerment_TRUE)\": \"0.95\", \"p(existential_catastrophe_TRUE|human_disempowerment_FALSE)\": \"0.0\", \"p(existential_catastrophe_FALSE|human_disempowerment_TRUE)\": \"0.05\", \"p(existential_catastrophe_FALSE|human_disempowerment_FALSE)\": \"1.0\"}}\n- [Human_Disempowerment]: Permanent and collective disempowerment of humanity relative to AI systems. {\"instantiations\": [\"human_disempowerment_TRUE\", \"human_disempowerment_FALSE\"], \"priors\": {\"p(human_disempowerment_TRUE)\": \"0.208\", \"p(human_disempowerment_FALSE)\": \"0.792\"}, \"posteriors\": {\"p(human_disempowerment_TRUE|scale_of_power_seeking_TRUE)\": \"1.0\", \"p(human_disempowerment_TRUE|scale_of_power_seeking_FALSE)\": \"0.0\", \"p(human_disempowerment_FALSE|scale_of_power_seeking_TRUE)\": \"0.0\", \"p(human_disempowerment_FALSE|scale_of_power_seeking_FALSE)\": \"1.0\"}}\n    - [Scale_Of_Power_Seeking]: Power-seeking by AI systems scaling to the point of permanently disempowering all of humanity. {\"instantiations\": [\"scale_of_power_seeking_TRUE\", \"scale_of_power_seeking_FALSE\"], \"priors\": {\"p(scale_of_power_seeking_TRUE)\": \"0.208\", \"p(scale_of_power_seeking_FALSE)\": \"0.792\"}, \"posteriors\": {\"p(scale_of_power_seeking_TRUE|misaligned_power_seeking_TRUE, corrective_feedback_EFFECTIVE)\": \"0.25\", \"p(scale_of_power_seeking_TRUE|misaligned_power_seeking_TRUE, corrective_feedback_INEFFECTIVE)\": \"0.60\", \"p(scale_of_power_seeking_TRUE|misaligned_power_seeking_FALSE, corrective_feedback_EFFECTIVE)\": \"0.0\", \"p(scale_of_power_seeking_TRUE|misaligned_power_seeking_FALSE, corrective_feedback_INEFFECTIVE)\": \"0.0\", \"p(scale_of_power_seeking_FALSE|misaligned_power_seeking_TRUE, corrective_feedback_EFFECTIVE)\": \"0.75\", \"p(scale_of_power_seeking_FALSE|misaligned_power_seeking_TRUE, corrective_feedback_INEFFECTIVE)\": \"0.40\", \"p(scale_of_power_seeking_FALSE|misaligned_power_seeking_FALSE, corrective_feedback_EFFECTIVE)\": \"1.0\", \"p(scale_of_power_seeking_FALSE|misaligned_power_seeking_FALSE, corrective_feedback_INEFFECTIVE)\": \"1.0\"}}\n        - [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"], \"priors\": {\"p(misaligned_power_seeking_TRUE)\": \"0.338\", \"p(misaligned_power_seeking_FALSE)\": \"0.662\"}, \"posteriors\": {\"p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)\": \"0.90\", \"p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_WITHHOLD)\": \"0.10\", \"p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)\": \"0.25\", \"p(misaligned_power_seeking_TRUE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_WITHHOLD)\": \"0.05\", \"p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)\": \"0.0\", \"p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_WITHHOLD)\": \"0.0\", \"p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)\": \"0.0\", \"p(misaligned_power_seeking_TRUE|aps_systems_FALSE, difficulty_of_alignment_FALSE, deployment_decisions_WITHHOLD)\": \"0.0\", \"p(misaligned_power_seeking_FALSE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)\": \"0.10\", \"p(misaligned_power_seeking_FALSE|aps_systems_TRUE, difficulty_of_alignment_TRUE, deployment_decisions_WITHHOLD)\": \"0.90\", \"p(misaligned_power_seeking_FALSE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)\": \"0.75\", \"p(misaligned_power_seeking_FALSE|aps_systems_TRUE, difficulty_of_alignment_FALSE, deployment_decisions_WITHHOLD)\": \"0.95\", \"p(misaligned_power_seeking_FALSE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_DEPLOY)\": \"1.0\", \"p(misaligned_power_seeking_FALSE|aps_systems_FALSE, difficulty_of_alignment_TRUE, deployment_decisions_WITHHOLD)\": \"1.0\", \"p(misaligned_power_seeking_FALSE|aps_systems_FALSE, difficulty_of_alignment_FALSE, deployment_decisions_DEPLOY)\": \"1.0\", \"p(misaligned_power_seeking_FALSE|aps_systems_FALSE, difficulty_of_alignment_FALSE, deployment_decisions_WITHHOLD)\": \"1.0\"}}\n            - [APS_Systems]: AI systems with advanced capabilities, agentic planning, and strategic awareness. {\"instantiations\": [\"aps_systems_TRUE\", \"aps_systems_FALSE\"], \"priors\": {\"p(aps_systems_TRUE)\": \"0.65\", \"p(aps_systems_FALSE)\": \"0.35\"}, \"posteriors\": {\"p(aps_systems_TRUE|advanced_ai_capability_TRUE, agentic_planning_TRUE, strategic_awareness_TRUE)\": \"1.0\", \"p(aps_systems_TRUE|advanced_ai_capability_TRUE, agentic_planning_TRUE, strategic_awareness_FALSE)\": \"0.0\", \"p(aps_systems_TRUE|advanced_ai_capability_TRUE, agentic_planning_FALSE, strategic_awareness_TRUE)\": \"0.0\", \"p(aps_systems_TRUE|advanced_ai_capability_TRUE, agentic_planning_FALSE, strategic_awareness_FALSE)\": \"0.0\", \"p(aps_systems_TRUE|advanced_ai_capability_FALSE, agentic_planning_TRUE, strategic_awareness_TRUE)\": \"0.0\", \"p(aps_systems_TRUE|advanced_ai_capability_FALSE, agentic_planning_TRUE, strategic_awareness_FALSE)\": \"0.0\", \"p(aps_systems_TRUE|advanced_ai_capability_FALSE, agentic_planning_FALSE, strategic_awareness_TRUE)\": \"0.0\", \"p(aps_systems_TRUE|advanced_ai_capability_FALSE, agentic_planning_FALSE, strategic_awareness_FALSE)\": \"0.0\", \"p(aps_systems_FALSE|advanced_ai_capability_TRUE, agentic_planning_TRUE, strategic_awareness_TRUE)\": \"0.0\", \"p(aps_systems_FALSE|advanced_ai_capability_TRUE, agentic_planning_TRUE, strategic_awareness_FALSE)\": \"1.0\", \"p(aps_systems_FALSE|advanced_ai_capability_TRUE, agentic_planning_FALSE, strategic_awareness_TRUE)\": \"1.0\", \"p(aps_systems_FALSE|advanced_ai_capability_TRUE, agentic_planning_FALSE, strategic_awareness_FALSE)\": \"1.0\", \"p(aps_systems_FALSE|advanced_ai_capability_FALSE, agentic_planning_TRUE, strategic_awareness_TRUE)\": \"1.0\", \"p(aps_systems_FALSE|advanced_ai_capability_FALSE, agentic_planning_TRUE, strategic_awareness_FALSE)\": \"1.0\", \"p(aps_systems_FALSE|advanced_ai_capability_FALSE, agentic_planning_FALSE, strategic_awareness_TRUE)\": \"1.0\", \"p(aps_systems_FALSE|advanced_ai_capability_FALSE, agentic_planning_FALSE, strategic_awareness_FALSE)\": \"1.0\"}}\n                - [Advanced_AI_Capability]: AI systems that outperform humans on tasks that grant significant power in the world. {\"instantiations\": [\"advanced_ai_capability_TRUE\", \"advanced_ai_capability_FALSE\"], \"priors\": {\"p(advanced_ai_capability_TRUE)\": \"0.80\", \"p(advanced_ai_capability_FALSE)\": \"0.20\"}}\n                - [Agentic_Planning]: AI systems making and executing plans based on world models to achieve objectives. {\"instantiations\": [\"agentic_planning_TRUE\", \"agentic_planning_FALSE\"], \"priors\": {\"p(agentic_planning_TRUE)\": \"0.85\", \"p(agentic_planning_FALSE)\": \"0.15\"}}\n                - [Strategic_Awareness]: AI systems with models accurately representing power dynamics with humans. {\"instantiations\": [\"strategic_awareness_TRUE\", \"strategic_awareness_FALSE\"], \"priors\": {\"p(strategic_awareness_TRUE)\": \"0.75\", \"p(strategic_awareness_FALSE)\": \"0.25\"}}\n            - [Difficulty_Of_Alignment]: It is harder to build aligned systems than misaligned systems that are attractive to deploy. {\"instantiations\": [\"difficulty_of_alignment_TRUE\", \"difficulty_of_alignment_FALSE\"], \"priors\": {\"p(difficulty_of_alignment_TRUE)\": \"0.40\", \"p(difficulty_of_alignment_FALSE)\": \"0.60\"}, \"posteriors\": {\"p(difficulty_of_alignment_TRUE|instrumental_convergence_TRUE, problems_with_proxies_TRUE, problems_with_search_TRUE)\": \"0.85\", \"p(difficulty_of_alignment_TRUE|instrumental_convergence_TRUE, problems_with_proxies_TRUE, problems_with_search_FALSE)\": \"0.70\", \"p(difficulty_of_alignment_TRUE|instrumental_convergence_TRUE, problems_with_proxies_FALSE, problems_with_search_TRUE)\": \"0.60\", \"p(difficulty_of_alignment_TRUE|instrumental_convergence_TRUE, problems_with_proxies_FALSE, problems_with_search_FALSE)\": \"0.40\", \"p(difficulty_of_alignment_TRUE|instrumental_convergence_FALSE, problems_with_proxies_TRUE, problems_with_search_TRUE)\": \"0.55\", \"p(difficulty_of_alignment_TRUE|instrumental_convergence_FALSE, problems_with_proxies_TRUE, problems_with_search_FALSE)\": \"0.40\", \"p(difficulty_of_alignment_TRUE|instrumental_convergence_FALSE, problems_with_proxies_FALSE, problems_with_search_TRUE)\": \"0.30\", \"p(difficulty_of_alignment_TRUE|instrumental_convergence_FALSE, problems_with_proxies_FALSE, problems_with_search_FALSE)\": \"0.10\", \"p(difficulty_of_alignment_FALSE|instrumental_convergence_TRUE, problems_with_proxies_TRUE, problems_with_search_TRUE)\": \"0.15\", \"p(difficulty_of_alignment_FALSE|instrumental_convergence_TRUE, problems_with_proxies_TRUE, problems_with_search_FALSE)\": \"0.30\", \"p(difficulty_of_alignment_FALSE|instrumental_convergence_TRUE, problems_with_proxies_FALSE, problems_with_search_TRUE)\": \"0.40\", \"p(difficulty_of_alignment_FALSE|instrumental_convergence_TRUE, problems_with_proxies_FALSE, problems_with_search_FALSE)\": \"0.60\", \"p(difficulty_of_alignment_FALSE|instrumental_convergence_FALSE, problems_with_proxies_TRUE, problems_with_search_TRUE)\": \"0.45\", \"p(difficulty_of_alignment_FALSE|instrumental_convergence_FALSE, problems_with_proxies_TRUE, problems_with_search_FALSE)\": \"0.60\", \"p(difficulty_of_alignment_FALSE|instrumental_convergence_FALSE, problems_with_proxies_FALSE, problems_with_search_TRUE)\": \"0.70\", \"p(difficulty_of_alignment_FALSE|instrumental_convergence_FALSE, problems_with_proxies_FALSE, problems_with_search_FALSE)\": \"0.90\"}}\n                - [Instrumental_Convergence]: AI systems with misaligned objectives tend to seek power as an instrumental goal. {\"instantiations\": [\"instrumental_convergence_TRUE\", \"instrumental_convergence_FALSE\"], \"priors\": {\"p(instrumental_convergence_TRUE)\": \"0.75\", \"p(instrumental_convergence_FALSE)\": \"0.25\"}}\n                - [Problems_With_Proxies]: Optimizing for proxy objectives breaks correlations with intended goals. {\"instantiations\": [\"problems_with_proxies_TRUE\", \"problems_with_proxies_FALSE\"], \"priors\": {\"p(problems_with_proxies_TRUE)\": \"0.80\", \"p(problems_with_proxies_FALSE)\": \"0.20\"}}\n                - [Problems_With_Search]: Search processes can yield systems pursuing different objectives than intended. {\"instantiations\": [\"problems_with_search_TRUE\", \"problems_with_search_FALSE\"], \"priors\": {\"p(problems_with_search_TRUE)\": \"0.70\", \"p(problems_with_search_FALSE)\": \"0.30\"}}\n            - [Deployment_Decisions]: Decisions to deploy potentially misaligned AI systems. {\"instantiations\": [\"deployment_decisions_DEPLOY\", \"deployment_decisions_WITHHOLD\"], \"priors\": {\"p(deployment_decisions_DEPLOY)\": \"0.70\", \"p(deployment_decisions_WITHHOLD)\": \"0.30\"}, \"posteriors\": {\"p(deployment_decisions_DEPLOY|incentives_to_build_aps_STRONG, deception_by_ai_TRUE)\": \"0.90\", \"p(deployment_decisions_DEPLOY|incentives_to_build_aps_STRONG, deception_by_ai_FALSE)\": \"0.75\", \"p(deployment_decisions_DEPLOY|incentives_to_build_aps_WEAK, deception_by_ai_TRUE)\": \"0.60\", \"p(deployment_decisions_DEPLOY|incentives_to_build_aps_WEAK, deception_by_ai_FALSE)\": \"0.30\", \"p(deployment_decisions_WITHHOLD|incentives_to_build_aps_STRONG, deception_by_ai_TRUE)\": \"0.10\", \"p(deployment_decisions_WITHHOLD|incentives_to_build_aps_STRONG, deception_by_ai_FALSE)\": \"0.25\", \"p(deployment_decisions_WITHHOLD|incentives_to_build_aps_WEAK, deception_by_ai_TRUE)\": \"0.40\", \"p(deployment_decisions_WITHHOLD|incentives_to_build_aps_WEAK, deception_by_ai_FALSE)\": \"0.70\"}}\n                - [Incentives_To_Build_APS]: Strong incentives to build and deploy APS systems. {\"instantiations\": [\"incentives_to_build_aps_STRONG\", \"incentives_to_build_aps_WEAK\"], \"priors\": {\"p(incentives_to_build_aps_STRONG)\": \"0.80\", \"p(incentives_to_build_aps_WEAK)\": \"0.20\"}, \"posteriors\": {\"p(incentives_to_build_aps_STRONG|usefulness_of_aps_HIGH, competitive_dynamics_STRONG)\": \"0.95\", \"p(incentives_to_build_aps_STRONG|usefulness_of_aps_HIGH, competitive_dynamics_WEAK)\": \"0.80\", \"p(incentives_to_build_aps_STRONG|usefulness_of_aps_LOW, competitive_dynamics_STRONG)\": \"0.70\", \"p(incentives_to_build_aps_STRONG|usefulness_of_aps_LOW, competitive_dynamics_WEAK)\": \"0.30\", \"p(incentives_to_build_aps_WEAK|usefulness_of_aps_HIGH, competitive_dynamics_STRONG)\": \"0.05\", \"p(incentives_to_build_aps_WEAK|usefulness_of_aps_HIGH, competitive_dynamics_WEAK)\": \"0.20\", \"p(incentives_to_build_aps_WEAK|usefulness_of_aps_LOW, competitive_dynamics_STRONG)\": \"0.30\", \"p(incentives_to_build_aps_WEAK|usefulness_of_aps_LOW, competitive_dynamics_WEAK)\": \"0.70\"}}\n                    - [Usefulness_Of_APS]: APS systems are very useful for many valuable tasks. {\"instantiations\": [\"usefulness_of_aps_HIGH\", \"usefulness_of_aps_LOW\"], \"priors\": {\"p(usefulness_of_aps_HIGH)\": \"0.85\", \"p(usefulness_of_aps_LOW)\": \"0.15\"}}\n                    - [Competitive_Dynamics]: Competitive pressures between AI developers. {\"instantiations\": [\"competitive_dynamics_STRONG\", \"competitive_dynamics_WEAK\"], \"priors\": {\"p(competitive_dynamics_STRONG)\": \"0.75\", \"p(competitive_dynamics_WEAK)\": \"0.25\"}}\n                - [Deception_By_AI]: AI systems deceiving humans about their true objectives. {\"instantiations\": [\"deception_by_ai_TRUE\", \"deception_by_ai_FALSE\"], \"priors\": {\"p(deception_by_ai_TRUE)\": \"0.50\", \"p(deception_by_ai_FALSE)\": \"0.50\"}}\n        - [Corrective_Feedback]: Human society implementing corrections after observing problems. {\"instantiations\": [\"corrective_feedback_EFFECTIVE\", \"corrective_feedback_INEFFECTIVE\"], \"priors\": {\"p(corrective_feedback_EFFECTIVE)\": \"0.60\", \"p(corrective_feedback_INEFFECTIVE)\": \"0.40\"}, \"posteriors\": {\"p(corrective_feedback_EFFECTIVE|warning_shots_OBSERVED, rapid_capability_escalation_TRUE)\": \"0.40\", \"p(corrective_feedback_EFFECTIVE|warning_shots_OBSERVED, rapid_capability_escalation_FALSE)\": \"0.80\", \"p(corrective_feedback_EFFECTIVE|warning_shots_UNOBSERVED, rapid_capability_escalation_TRUE)\": \"0.15\", \"p(corrective_feedback_EFFECTIVE|warning_shots_UNOBSERVED, rapid_capability_escalation_FALSE)\": \"0.50\", \"p(corrective_feedback_INEFFECTIVE|warning_shots_OBSERVED, rapid_capability_escalation_TRUE)\": \"0.60\", \"p(corrective_feedback_INEFFECTIVE|warning_shots_OBSERVED, rapid_capability_escalation_FALSE)\": \"0.20\", \"p(corrective_feedback_INEFFECTIVE|warning_shots_UNOBSERVED, rapid_capability_escalation_TRUE)\": \"0.85\", \"p(corrective_feedback_INEFFECTIVE|warning_shots_UNOBSERVED, rapid_capability_escalation_FALSE)\": \"0.50\"}}\n            - [Warning_Shots]: Observable failures in weaker systems before catastrophic risks. {\"instantiations\": [\"warning_shots_OBSERVED\", \"warning_shots_UNOBSERVED\"], \"priors\": {\"p(warning_shots_OBSERVED)\": \"0.70\", \"p(warning_shots_UNOBSERVED)\": \"0.30\"}}\n            - [Rapid_Capability_Escalation]: AI capabilities escalating very rapidly, allowing little time for correction. {\"instantiations\": [\"rapid_capability_escalation_TRUE\", \"rapid_capability_escalation_FALSE\"], \"priors\": {\"p(rapid_capability_escalation_TRUE)\": \"0.45\", \"p(rapid_capability_escalation_FALSE)\": \"0.55\"}}\n[Barriers_To_Understanding]: Difficulty in understanding the internal workings of advanced AI systems. {\"instantiations\": [\"barriers_to_understanding_HIGH\", \"barriers_to_understanding_LOW\"], \"priors\": {\"p(barriers_to_understanding_HIGH)\": \"0.70\", \"p(barriers_to_understanding_LOW)\": \"0.30\"}, \"posteriors\": {\"p(barriers_to_understanding_HIGH|misaligned_power_seeking_TRUE)\": \"0.85\", \"p(barriers_to_understanding_HIGH|misaligned_power_seeking_FALSE)\": \"0.60\", \"p(barriers_to_understanding_LOW|misaligned_power_seeking_TRUE)\": \"0.15\", \"p(barriers_to_understanding_LOW|misaligned_power_seeking_FALSE)\": \"0.40\"}}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"], \"priors\": {\"p(misaligned_power_seeking_TRUE)\": \"0.338\", \"p(misaligned_power_seeking_FALSE)\": \"0.662\"}}\n[Adversarial_Dynamics]: Potentially adversarial relationships between humans and power-seeking AI. {\"instantiations\": [\"adversarial_dynamics_TRUE\", \"adversarial_dynamics_FALSE\"], \"priors\": {\"p(adversarial_dynamics_TRUE)\": \"0.60\", \"p(adversarial_dynamics_FALSE)\": \"0.40\"}, \"posteriors\": {\"p(adversarial_dynamics_TRUE|misaligned_power_seeking_TRUE)\": \"0.95\", \"p(adversarial_dynamics_TRUE|misaligned_power_seeking_FALSE)\": \"0.10\", \"p(adversarial_dynamics_FALSE|misaligned_power_seeking_TRUE)\": \"0.05\", \"p(adversarial_dynamics_FALSE|misaligned_power_seeking_FALSE)\": \"0.90\"}}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"], \"priors\": {\"p(misaligned_power_seeking_TRUE)\": \"0.338\", \"p(misaligned_power_seeking_FALSE)\": \"0.662\"}}\n[Stakes_Of_Error]: The escalating impact of mistakes with power-seeking AI systems. {\"instantiations\": [\"stakes_of_error_HIGH\", \"stakes_of_error_LOW\"], \"priors\": {\"p(stakes_of_error_HIGH)\": \"0.85\", \"p(stakes_of_error_LOW)\": \"0.15\"}, \"posteriors\": {\"p(stakes_of_error_HIGH|misaligned_power_seeking_TRUE)\": \"0.95\", \"p(stakes_of_error_HIGH|misaligned_power_seeking_FALSE)\": \"0.50\", \"p(stakes_of_error_LOW|misaligned_power_seeking_TRUE)\": \"0.05\", \"p(stakes_of_error_LOW|misaligned_power_seeking_FALSE)\": \"0.50\"}}\n- [Misaligned_Power_Seeking]: Deployed AI systems seeking power in unintended and high-impact ways due to problems with their objectives. {\"instantiations\": [\"misaligned_power_seeking_TRUE\", \"misaligned_power_seeking_FALSE\"], \"priors\": {\"p(misaligned_power_seeking_TRUE)\": \"0.338\", \"p(misaligned_power_seeking_FALSE)\": \"0.662\"}}\n\n:::\n:::\n\n\n## 3.1.2.2 Check the Graph Structure with the ArgDown Sandbox Online\nCopy and paste the BayesDown formatted ... in the ArgDown Sandbox below to quickly verify that the network renders correctly.\n\n## 3.3 Extraction\nBayesDown Extraction Code already part of ArgDown extraction code, therefore just use same function \"parse_markdown_hierarchy(markdown_data)\" and ignore the extra argument (\"ArgDown\") because it is automatically set to false amd will by default extract BayesDown.\n\n::: {#cell-69 .cell outputId='515f7e7f-c291-4d26-a515-b3d8c27d0952' quarto-private-1='{\"key\":\"colab\",\"value\":{\"base_uri\":\"https://localhost:8080/\",\"height\":1000}}'}\n\n::: {.cell-output .cell-output-display execution_count=36}\n```{=html}\n\n  &lt;div id=\"df-5d612629-5d59-46d5-83da-3b1655374873\" class=\"colab-df-container\"&gt;\n    &lt;div&gt;\n&lt;style scoped&gt;\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n&lt;/style&gt;\n&lt;table border=\"1\" class=\"dataframe\"&gt;\n  &lt;thead&gt;\n    &lt;tr style=\"text-align: right;\"&gt;\n      &lt;th&gt;&lt;/th&gt;\n      &lt;th&gt;Title&lt;/th&gt;\n      &lt;th&gt;Description&lt;/th&gt;\n      &lt;th&gt;line&lt;/th&gt;\n      &lt;th&gt;line_numbers&lt;/th&gt;\n      &lt;th&gt;indentation&lt;/th&gt;\n      &lt;th&gt;indentation_levels&lt;/th&gt;\n      &lt;th&gt;Parents&lt;/th&gt;\n      &lt;th&gt;Children&lt;/th&gt;\n      &lt;th&gt;instantiations&lt;/th&gt;\n      &lt;th&gt;priors&lt;/th&gt;\n      &lt;th&gt;posteriors&lt;/th&gt;\n      &lt;th&gt;No_Parent&lt;/th&gt;\n      &lt;th&gt;No_Children&lt;/th&gt;\n      &lt;th&gt;parent_instantiations&lt;/th&gt;\n    &lt;/tr&gt;\n  &lt;/thead&gt;\n  &lt;tbody&gt;\n    &lt;tr&gt;\n      &lt;th&gt;0&lt;/th&gt;\n      &lt;td&gt;Existential_Catastrophe&lt;/td&gt;\n      &lt;td&gt;The destruction of humanity's long-term potent...&lt;/td&gt;\n      &lt;td&gt;0&lt;/td&gt;\n      &lt;td&gt;[0]&lt;/td&gt;\n      &lt;td&gt;0&lt;/td&gt;\n      &lt;td&gt;[0]&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n      &lt;td&gt;[existential_catastrophe_TRUE, existential_cat...&lt;/td&gt;\n      &lt;td&gt;{'p(existential_catastrophe_TRUE)': '0.05', 'p...&lt;/td&gt;\n      &lt;td&gt;{'p(existential_catastrophe_TRUE|human_disempo...&lt;/td&gt;\n      &lt;td&gt;True&lt;/td&gt;\n      &lt;td&gt;True&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;1&lt;/th&gt;\n      &lt;td&gt;Human_Disempowerment&lt;/td&gt;\n      &lt;td&gt;Permanent and collective disempowerment of hum...&lt;/td&gt;\n      &lt;td&gt;1&lt;/td&gt;\n      &lt;td&gt;[1]&lt;/td&gt;\n      &lt;td&gt;0&lt;/td&gt;\n      &lt;td&gt;[0]&lt;/td&gt;\n      &lt;td&gt;[Scale_Of_Power_Seeking]&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n      &lt;td&gt;[human_disempowerment_TRUE, human_disempowerme...&lt;/td&gt;\n      &lt;td&gt;{'p(human_disempowerment_TRUE)': '0.208', 'p(h...&lt;/td&gt;\n      &lt;td&gt;{'p(human_disempowerment_TRUE|scale_of_power_s...&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;True&lt;/td&gt;\n      &lt;td&gt;[[scale_of_power_seeking_TRUE, scale_of_power_...&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;2&lt;/th&gt;\n      &lt;td&gt;Scale_Of_Power_Seeking&lt;/td&gt;\n      &lt;td&gt;Power-seeking by AI systems scaling to the poi...&lt;/td&gt;\n      &lt;td&gt;2&lt;/td&gt;\n      &lt;td&gt;[2]&lt;/td&gt;\n      &lt;td&gt;4&lt;/td&gt;\n      &lt;td&gt;[4]&lt;/td&gt;\n      &lt;td&gt;[Misaligned_Power_Seeking, Corrective_Feedback]&lt;/td&gt;\n      &lt;td&gt;[Human_Disempowerment]&lt;/td&gt;\n      &lt;td&gt;[scale_of_power_seeking_TRUE, scale_of_power_s...&lt;/td&gt;\n      &lt;td&gt;{'p(scale_of_power_seeking_TRUE)': '0.208', 'p...&lt;/td&gt;\n      &lt;td&gt;{'p(scale_of_power_seeking_TRUE|misaligned_pow...&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;[[misaligned_power_seeking_TRUE, misaligned_po...&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;3&lt;/th&gt;\n      &lt;td&gt;Misaligned_Power_Seeking&lt;/td&gt;\n      &lt;td&gt;Deployed AI systems seeking power in unintende...&lt;/td&gt;\n      &lt;td&gt;3&lt;/td&gt;\n      &lt;td&gt;[3, 21, 23, 25]&lt;/td&gt;\n      &lt;td&gt;8&lt;/td&gt;\n      &lt;td&gt;[8, 0, 0, 0]&lt;/td&gt;\n      &lt;td&gt;[APS_Systems, Difficulty_Of_Alignment, Deploym...&lt;/td&gt;\n      &lt;td&gt;[Scale_Of_Power_Seeking]&lt;/td&gt;\n      &lt;td&gt;[misaligned_power_seeking_TRUE, misaligned_pow...&lt;/td&gt;\n      &lt;td&gt;{'p(misaligned_power_seeking_TRUE)': '0.338', ...&lt;/td&gt;\n      &lt;td&gt;{'p(misaligned_power_seeking_TRUE|aps_systems_...&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;[[aps_systems_TRUE, aps_systems_FALSE], [diffi...&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;4&lt;/th&gt;\n      &lt;td&gt;APS_Systems&lt;/td&gt;\n      &lt;td&gt;AI systems with advanced capabilities, agentic...&lt;/td&gt;\n      &lt;td&gt;4&lt;/td&gt;\n      &lt;td&gt;[4]&lt;/td&gt;\n      &lt;td&gt;12&lt;/td&gt;\n      &lt;td&gt;[12]&lt;/td&gt;\n      &lt;td&gt;[Advanced_AI_Capability, Agentic_Planning, Str...&lt;/td&gt;\n      &lt;td&gt;[Misaligned_Power_Seeking]&lt;/td&gt;\n      &lt;td&gt;[aps_systems_TRUE, aps_systems_FALSE]&lt;/td&gt;\n      &lt;td&gt;{'p(aps_systems_TRUE)': '0.65', 'p(aps_systems...&lt;/td&gt;\n      &lt;td&gt;{'p(aps_systems_TRUE|advanced_ai_capability_TR...&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;[[advanced_ai_capability_TRUE, advanced_ai_cap...&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;5&lt;/th&gt;\n      &lt;td&gt;Advanced_AI_Capability&lt;/td&gt;\n      &lt;td&gt;AI systems that outperform humans on tasks tha...&lt;/td&gt;\n      &lt;td&gt;5&lt;/td&gt;\n      &lt;td&gt;[5]&lt;/td&gt;\n      &lt;td&gt;16&lt;/td&gt;\n      &lt;td&gt;[16]&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n      &lt;td&gt;[APS_Systems]&lt;/td&gt;\n      &lt;td&gt;[advanced_ai_capability_TRUE, advanced_ai_capa...&lt;/td&gt;\n      &lt;td&gt;{'p(advanced_ai_capability_TRUE)': '0.80', 'p(...&lt;/td&gt;\n      &lt;td&gt;{}&lt;/td&gt;\n      &lt;td&gt;True&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;6&lt;/th&gt;\n      &lt;td&gt;Agentic_Planning&lt;/td&gt;\n      &lt;td&gt;AI systems making and executing plans based on...&lt;/td&gt;\n      &lt;td&gt;6&lt;/td&gt;\n      &lt;td&gt;[6]&lt;/td&gt;\n      &lt;td&gt;16&lt;/td&gt;\n      &lt;td&gt;[16]&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n      &lt;td&gt;[APS_Systems]&lt;/td&gt;\n      &lt;td&gt;[agentic_planning_TRUE, agentic_planning_FALSE]&lt;/td&gt;\n      &lt;td&gt;{'p(agentic_planning_TRUE)': '0.85', 'p(agenti...&lt;/td&gt;\n      &lt;td&gt;{}&lt;/td&gt;\n      &lt;td&gt;True&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;7&lt;/th&gt;\n      &lt;td&gt;Strategic_Awareness&lt;/td&gt;\n      &lt;td&gt;AI systems with models accurately representing...&lt;/td&gt;\n      &lt;td&gt;7&lt;/td&gt;\n      &lt;td&gt;[7]&lt;/td&gt;\n      &lt;td&gt;16&lt;/td&gt;\n      &lt;td&gt;[16]&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n      &lt;td&gt;[APS_Systems]&lt;/td&gt;\n      &lt;td&gt;[strategic_awareness_TRUE, strategic_awareness...&lt;/td&gt;\n      &lt;td&gt;{'p(strategic_awareness_TRUE)': '0.75', 'p(str...&lt;/td&gt;\n      &lt;td&gt;{}&lt;/td&gt;\n      &lt;td&gt;True&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;8&lt;/th&gt;\n      &lt;td&gt;Difficulty_Of_Alignment&lt;/td&gt;\n      &lt;td&gt;It is harder to build aligned systems than mis...&lt;/td&gt;\n      &lt;td&gt;8&lt;/td&gt;\n      &lt;td&gt;[8]&lt;/td&gt;\n      &lt;td&gt;12&lt;/td&gt;\n      &lt;td&gt;[12]&lt;/td&gt;\n      &lt;td&gt;[Instrumental_Convergence, Problems_With_Proxi...&lt;/td&gt;\n      &lt;td&gt;[Misaligned_Power_Seeking]&lt;/td&gt;\n      &lt;td&gt;[difficulty_of_alignment_TRUE, difficulty_of_a...&lt;/td&gt;\n      &lt;td&gt;{'p(difficulty_of_alignment_TRUE)': '0.40', 'p...&lt;/td&gt;\n      &lt;td&gt;{'p(difficulty_of_alignment_TRUE|instrumental_...&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;[[instrumental_convergence_TRUE, instrumental_...&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;9&lt;/th&gt;\n      &lt;td&gt;Instrumental_Convergence&lt;/td&gt;\n      &lt;td&gt;AI systems with misaligned objectives tend to ...&lt;/td&gt;\n      &lt;td&gt;9&lt;/td&gt;\n      &lt;td&gt;[9]&lt;/td&gt;\n      &lt;td&gt;16&lt;/td&gt;\n      &lt;td&gt;[16]&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n      &lt;td&gt;[Difficulty_Of_Alignment]&lt;/td&gt;\n      &lt;td&gt;[instrumental_convergence_TRUE, instrumental_c...&lt;/td&gt;\n      &lt;td&gt;{'p(instrumental_convergence_TRUE)': '0.75', '...&lt;/td&gt;\n      &lt;td&gt;{}&lt;/td&gt;\n      &lt;td&gt;True&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;10&lt;/th&gt;\n      &lt;td&gt;Problems_With_Proxies&lt;/td&gt;\n      &lt;td&gt;Optimizing for proxy objectives breaks correla...&lt;/td&gt;\n      &lt;td&gt;10&lt;/td&gt;\n      &lt;td&gt;[10]&lt;/td&gt;\n      &lt;td&gt;16&lt;/td&gt;\n      &lt;td&gt;[16]&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n      &lt;td&gt;[Difficulty_Of_Alignment]&lt;/td&gt;\n      &lt;td&gt;[problems_with_proxies_TRUE, problems_with_pro...&lt;/td&gt;\n      &lt;td&gt;{'p(problems_with_proxies_TRUE)': '0.80', 'p(p...&lt;/td&gt;\n      &lt;td&gt;{}&lt;/td&gt;\n      &lt;td&gt;True&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;11&lt;/th&gt;\n      &lt;td&gt;Problems_With_Search&lt;/td&gt;\n      &lt;td&gt;Search processes can yield systems pursuing di...&lt;/td&gt;\n      &lt;td&gt;11&lt;/td&gt;\n      &lt;td&gt;[11]&lt;/td&gt;\n      &lt;td&gt;16&lt;/td&gt;\n      &lt;td&gt;[16]&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n      &lt;td&gt;[Difficulty_Of_Alignment]&lt;/td&gt;\n      &lt;td&gt;[problems_with_search_TRUE, problems_with_sear...&lt;/td&gt;\n      &lt;td&gt;{'p(problems_with_search_TRUE)': '0.70', 'p(pr...&lt;/td&gt;\n      &lt;td&gt;{}&lt;/td&gt;\n      &lt;td&gt;True&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;12&lt;/th&gt;\n      &lt;td&gt;Deployment_Decisions&lt;/td&gt;\n      &lt;td&gt;Decisions to deploy potentially misaligned AI ...&lt;/td&gt;\n      &lt;td&gt;12&lt;/td&gt;\n      &lt;td&gt;[12]&lt;/td&gt;\n      &lt;td&gt;12&lt;/td&gt;\n      &lt;td&gt;[12]&lt;/td&gt;\n      &lt;td&gt;[Incentives_To_Build_APS, Deception_By_AI]&lt;/td&gt;\n      &lt;td&gt;[Misaligned_Power_Seeking]&lt;/td&gt;\n      &lt;td&gt;[deployment_decisions_DEPLOY, deployment_decis...&lt;/td&gt;\n      &lt;td&gt;{'p(deployment_decisions_DEPLOY)': '0.70', 'p(...&lt;/td&gt;\n      &lt;td&gt;{'p(deployment_decisions_DEPLOY|incentives_to_...&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;[[incentives_to_build_aps_STRONG, incentives_t...&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;13&lt;/th&gt;\n      &lt;td&gt;Incentives_To_Build_APS&lt;/td&gt;\n      &lt;td&gt;Strong incentives to build and deploy APS syst...&lt;/td&gt;\n      &lt;td&gt;13&lt;/td&gt;\n      &lt;td&gt;[13]&lt;/td&gt;\n      &lt;td&gt;16&lt;/td&gt;\n      &lt;td&gt;[16]&lt;/td&gt;\n      &lt;td&gt;[Usefulness_Of_APS, Competitive_Dynamics]&lt;/td&gt;\n      &lt;td&gt;[Deployment_Decisions]&lt;/td&gt;\n      &lt;td&gt;[incentives_to_build_aps_STRONG, incentives_to...&lt;/td&gt;\n      &lt;td&gt;{'p(incentives_to_build_aps_STRONG)': '0.80', ...&lt;/td&gt;\n      &lt;td&gt;{'p(incentives_to_build_aps_STRONG|usefulness_...&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;[[usefulness_of_aps_HIGH, usefulness_of_aps_LO...&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;14&lt;/th&gt;\n      &lt;td&gt;Usefulness_Of_APS&lt;/td&gt;\n      &lt;td&gt;APS systems are very useful for many valuable ...&lt;/td&gt;\n      &lt;td&gt;14&lt;/td&gt;\n      &lt;td&gt;[14]&lt;/td&gt;\n      &lt;td&gt;20&lt;/td&gt;\n      &lt;td&gt;[20]&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n      &lt;td&gt;[Incentives_To_Build_APS]&lt;/td&gt;\n      &lt;td&gt;[usefulness_of_aps_HIGH, usefulness_of_aps_LOW]&lt;/td&gt;\n      &lt;td&gt;{'p(usefulness_of_aps_HIGH)': '0.85', 'p(usefu...&lt;/td&gt;\n      &lt;td&gt;{}&lt;/td&gt;\n      &lt;td&gt;True&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;15&lt;/th&gt;\n      &lt;td&gt;Competitive_Dynamics&lt;/td&gt;\n      &lt;td&gt;Competitive pressures between AI developers.&lt;/td&gt;\n      &lt;td&gt;15&lt;/td&gt;\n      &lt;td&gt;[15]&lt;/td&gt;\n      &lt;td&gt;20&lt;/td&gt;\n      &lt;td&gt;[20]&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n      &lt;td&gt;[Incentives_To_Build_APS]&lt;/td&gt;\n      &lt;td&gt;[competitive_dynamics_STRONG, competitive_dyna...&lt;/td&gt;\n      &lt;td&gt;{'p(competitive_dynamics_STRONG)': '0.75', 'p(...&lt;/td&gt;\n      &lt;td&gt;{}&lt;/td&gt;\n      &lt;td&gt;True&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;16&lt;/th&gt;\n      &lt;td&gt;Deception_By_AI&lt;/td&gt;\n      &lt;td&gt;AI systems deceiving humans about their true o...&lt;/td&gt;\n      &lt;td&gt;16&lt;/td&gt;\n      &lt;td&gt;[16]&lt;/td&gt;\n      &lt;td&gt;16&lt;/td&gt;\n      &lt;td&gt;[16]&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n      &lt;td&gt;[Deployment_Decisions]&lt;/td&gt;\n      &lt;td&gt;[deception_by_ai_TRUE, deception_by_ai_FALSE]&lt;/td&gt;\n      &lt;td&gt;{'p(deception_by_ai_TRUE)': '0.50', 'p(decepti...&lt;/td&gt;\n      &lt;td&gt;{}&lt;/td&gt;\n      &lt;td&gt;True&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;17&lt;/th&gt;\n      &lt;td&gt;Corrective_Feedback&lt;/td&gt;\n      &lt;td&gt;Human society implementing corrections after o...&lt;/td&gt;\n      &lt;td&gt;17&lt;/td&gt;\n      &lt;td&gt;[17]&lt;/td&gt;\n      &lt;td&gt;8&lt;/td&gt;\n      &lt;td&gt;[8]&lt;/td&gt;\n      &lt;td&gt;[Warning_Shots, Rapid_Capability_Escalation]&lt;/td&gt;\n      &lt;td&gt;[Scale_Of_Power_Seeking]&lt;/td&gt;\n      &lt;td&gt;[corrective_feedback_EFFECTIVE, corrective_fee...&lt;/td&gt;\n      &lt;td&gt;{'p(corrective_feedback_EFFECTIVE)': '0.60', '...&lt;/td&gt;\n      &lt;td&gt;{'p(corrective_feedback_EFFECTIVE|warning_shot...&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;[[warning_shots_OBSERVED, warning_shots_UNOBSE...&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;18&lt;/th&gt;\n      &lt;td&gt;Warning_Shots&lt;/td&gt;\n      &lt;td&gt;Observable failures in weaker systems before c...&lt;/td&gt;\n      &lt;td&gt;18&lt;/td&gt;\n      &lt;td&gt;[18]&lt;/td&gt;\n      &lt;td&gt;12&lt;/td&gt;\n      &lt;td&gt;[12]&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n      &lt;td&gt;[Corrective_Feedback]&lt;/td&gt;\n      &lt;td&gt;[warning_shots_OBSERVED, warning_shots_UNOBSER...&lt;/td&gt;\n      &lt;td&gt;{'p(warning_shots_OBSERVED)': '0.70', 'p(warni...&lt;/td&gt;\n      &lt;td&gt;{}&lt;/td&gt;\n      &lt;td&gt;True&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;19&lt;/th&gt;\n      &lt;td&gt;Rapid_Capability_Escalation&lt;/td&gt;\n      &lt;td&gt;AI capabilities escalating very rapidly, allow...&lt;/td&gt;\n      &lt;td&gt;19&lt;/td&gt;\n      &lt;td&gt;[19]&lt;/td&gt;\n      &lt;td&gt;12&lt;/td&gt;\n      &lt;td&gt;[12]&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n      &lt;td&gt;[Corrective_Feedback]&lt;/td&gt;\n      &lt;td&gt;[rapid_capability_escalation_TRUE, rapid_capab...&lt;/td&gt;\n      &lt;td&gt;{'p(rapid_capability_escalation_TRUE)': '0.45'...&lt;/td&gt;\n      &lt;td&gt;{}&lt;/td&gt;\n      &lt;td&gt;True&lt;/td&gt;\n      &lt;td&gt;False&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;20&lt;/th&gt;\n      &lt;td&gt;Barriers_To_Understanding&lt;/td&gt;\n      &lt;td&gt;Difficulty in understanding the internal worki...&lt;/td&gt;\n      &lt;td&gt;20&lt;/td&gt;\n      &lt;td&gt;[20]&lt;/td&gt;\n      &lt;td&gt;0&lt;/td&gt;\n      &lt;td&gt;[0]&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n      &lt;td&gt;[barriers_to_understanding_HIGH, barriers_to_u...&lt;/td&gt;\n      &lt;td&gt;{'p(barriers_to_understanding_HIGH)': '0.70', ...&lt;/td&gt;\n      &lt;td&gt;{'p(barriers_to_understanding_HIGH|misaligned_...&lt;/td&gt;\n      &lt;td&gt;True&lt;/td&gt;\n      &lt;td&gt;True&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;21&lt;/th&gt;\n      &lt;td&gt;Adversarial_Dynamics&lt;/td&gt;\n      &lt;td&gt;Potentially adversarial relationships between ...&lt;/td&gt;\n      &lt;td&gt;22&lt;/td&gt;\n      &lt;td&gt;[22]&lt;/td&gt;\n      &lt;td&gt;0&lt;/td&gt;\n      &lt;td&gt;[0]&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n      &lt;td&gt;[adversarial_dynamics_TRUE, adversarial_dynami...&lt;/td&gt;\n      &lt;td&gt;{'p(adversarial_dynamics_TRUE)': '0.60', 'p(ad...&lt;/td&gt;\n      &lt;td&gt;{'p(adversarial_dynamics_TRUE|misaligned_power...&lt;/td&gt;\n      &lt;td&gt;True&lt;/td&gt;\n      &lt;td&gt;True&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;th&gt;22&lt;/th&gt;\n      &lt;td&gt;Stakes_Of_Error&lt;/td&gt;\n      &lt;td&gt;The escalating impact of mistakes with power-s...&lt;/td&gt;\n      &lt;td&gt;24&lt;/td&gt;\n      &lt;td&gt;[24]&lt;/td&gt;\n      &lt;td&gt;0&lt;/td&gt;\n      &lt;td&gt;[0]&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n      &lt;td&gt;[stakes_of_error_HIGH, stakes_of_error_LOW]&lt;/td&gt;\n      &lt;td&gt;{'p(stakes_of_error_HIGH)': '0.85', 'p(stakes_...&lt;/td&gt;\n      &lt;td&gt;{'p(stakes_of_error_HIGH|misaligned_power_seek...&lt;/td&gt;\n      &lt;td&gt;True&lt;/td&gt;\n      &lt;td&gt;True&lt;/td&gt;\n      &lt;td&gt;[]&lt;/td&gt;\n    &lt;/tr&gt;\n  &lt;/tbody&gt;\n&lt;/table&gt;\n&lt;/div&gt;\n    &lt;div class=\"colab-df-buttons\"&gt;\n\n  &lt;div class=\"colab-df-container\"&gt;\n    &lt;button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d612629-5d59-46d5-83da-3b1655374873')\"\n            title=\"Convert this dataframe to an interactive table.\"\n            style=\"display:none;\"&gt;\n\n  &lt;svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\"&gt;\n    &lt;path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/&gt;\n  &lt;/svg&gt;\n    &lt;/button&gt;\n\n  &lt;style&gt;\n    .colab-df-container {\n      display:flex;\n      gap: 12px;\n    }\n\n    .colab-df-convert {\n      background-color: #E8F0FE;\n      border: none;\n      border-radius: 50%;\n      cursor: pointer;\n      display: none;\n      fill: #1967D2;\n      height: 32px;\n      padding: 0 0 0 0;\n      width: 32px;\n    }\n\n    .colab-df-convert:hover {\n      background-color: #E2EBFA;\n      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n      fill: #174EA6;\n    }\n\n    .colab-df-buttons div {\n      margin-bottom: 4px;\n    }\n\n    [theme=dark] .colab-df-convert {\n      background-color: #3B4455;\n      fill: #D2E3FC;\n    }\n\n    [theme=dark] .colab-df-convert:hover {\n      background-color: #434B5C;\n      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n      fill: #FFFFFF;\n    }\n  &lt;/style&gt;\n\n    &lt;script&gt;\n      const buttonEl =\n        document.querySelector('#df-5d612629-5d59-46d5-83da-3b1655374873 button.colab-df-convert');\n      buttonEl.style.display =\n        google.colab.kernel.accessAllowed ? 'block' : 'none';\n\n      async function convertToInteractive(key) {\n        const element = document.querySelector('#df-5d612629-5d59-46d5-83da-3b1655374873');\n        const dataTable =\n          await google.colab.kernel.invokeFunction('convertToInteractive',\n                                                    [key], {});\n        if (!dataTable) return;\n\n        const docLinkHtml = 'Like what you see? Visit the ' +\n          '&lt;a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;'\n          + ' to learn more about interactive tables.';\n        element.innerHTML = '';\n        dataTable['output_type'] = 'display_data';\n        await google.colab.output.renderOutput(dataTable, element);\n        const docLink = document.createElement('div');\n        docLink.innerHTML = docLinkHtml;\n        element.appendChild(docLink);\n      }\n    &lt;/script&gt;\n  &lt;/div&gt;\n\n\n    &lt;div id=\"df-a250fd1f-3ae9-4228-af89-ece8d7b6b4ba\"&gt;\n      &lt;button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a250fd1f-3ae9-4228-af89-ece8d7b6b4ba')\"\n                title=\"Suggest charts\"\n                style=\"display:none;\"&gt;\n\n&lt;svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n     width=\"24px\"&gt;\n    &lt;g&gt;\n        &lt;path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/&gt;\n    &lt;/g&gt;\n&lt;/svg&gt;\n      &lt;/button&gt;\n\n&lt;style&gt;\n  .colab-df-quickchart {\n      --bg-color: #E8F0FE;\n      --fill-color: #1967D2;\n      --hover-bg-color: #E2EBFA;\n      --hover-fill-color: #174EA6;\n      --disabled-fill-color: #AAA;\n      --disabled-bg-color: #DDD;\n  }\n\n  [theme=dark] .colab-df-quickchart {\n      --bg-color: #3B4455;\n      --fill-color: #D2E3FC;\n      --hover-bg-color: #434B5C;\n      --hover-fill-color: #FFFFFF;\n      --disabled-bg-color: #3B4455;\n      --disabled-fill-color: #666;\n  }\n\n  .colab-df-quickchart {\n    background-color: var(--bg-color);\n    border: none;\n    border-radius: 50%;\n    cursor: pointer;\n    display: none;\n    fill: var(--fill-color);\n    height: 32px;\n    padding: 0;\n    width: 32px;\n  }\n\n  .colab-df-quickchart:hover {\n    background-color: var(--hover-bg-color);\n    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n    fill: var(--button-hover-fill-color);\n  }\n\n  .colab-df-quickchart-complete:disabled,\n  .colab-df-quickchart-complete:disabled:hover {\n    background-color: var(--disabled-bg-color);\n    fill: var(--disabled-fill-color);\n    box-shadow: none;\n  }\n\n  .colab-df-spinner {\n    border: 2px solid var(--fill-color);\n    border-color: transparent;\n    border-bottom-color: var(--fill-color);\n    animation:\n      spin 1s steps(1) infinite;\n  }\n\n  @keyframes spin {\n    0% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n      border-left-color: var(--fill-color);\n    }\n    20% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    30% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n      border-right-color: var(--fill-color);\n    }\n    40% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    60% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n    }\n    80% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-bottom-color: var(--fill-color);\n    }\n    90% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n    }\n  }\n&lt;/style&gt;\n\n      &lt;script&gt;\n        async function quickchart(key) {\n          const quickchartButtonEl =\n            document.querySelector('#' + key + ' button');\n          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n          quickchartButtonEl.classList.add('colab-df-spinner');\n          try {\n            const charts = await google.colab.kernel.invokeFunction(\n                'suggestCharts', [key], {});\n          } catch (error) {\n            console.error('Error during call to suggestCharts:', error);\n          }\n          quickchartButtonEl.classList.remove('colab-df-spinner');\n          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n        }\n        (() =&gt; {\n          let quickchartButtonEl =\n            document.querySelector('#df-a250fd1f-3ae9-4228-af89-ece8d7b6b4ba button');\n          quickchartButtonEl.style.display =\n            google.colab.kernel.accessAllowed ? 'block' : 'none';\n        })();\n      &lt;/script&gt;\n    &lt;/div&gt;\n\n  &lt;div id=\"id_7742e5c7-c1be-4dba-888a-5ba16cfc6364\"&gt;\n    &lt;style&gt;\n      .colab-df-generate {\n        background-color: #E8F0FE;\n        border: none;\n        border-radius: 50%;\n        cursor: pointer;\n        display: none;\n        fill: #1967D2;\n        height: 32px;\n        padding: 0 0 0 0;\n        width: 32px;\n      }\n\n      .colab-df-generate:hover {\n        background-color: #E2EBFA;\n        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n        fill: #174EA6;\n      }\n\n      [theme=dark] .colab-df-generate {\n        background-color: #3B4455;\n        fill: #D2E3FC;\n      }\n\n      [theme=dark] .colab-df-generate:hover {\n        background-color: #434B5C;\n        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n        fill: #FFFFFF;\n      }\n    &lt;/style&gt;\n    &lt;button class=\"colab-df-generate\" onclick=\"generateWithVariable('result_df')\"\n            title=\"Generate code using this dataframe.\"\n            style=\"display:none;\"&gt;\n\n  &lt;svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n       width=\"24px\"&gt;\n    &lt;path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/&gt;\n  &lt;/svg&gt;\n    &lt;/button&gt;\n    &lt;script&gt;\n      (() =&gt; {\n      const buttonEl =\n        document.querySelector('#id_7742e5c7-c1be-4dba-888a-5ba16cfc6364 button.colab-df-generate');\n      buttonEl.style.display =\n        google.colab.kernel.accessAllowed ? 'block' : 'none';\n\n      buttonEl.onclick = () =&gt; {\n        google.colab.notebook.generateWithVariable('result_df');\n      }\n      })();\n    &lt;/script&gt;\n  &lt;/div&gt;\n\n    &lt;/div&gt;\n  &lt;/div&gt;",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#bayesian-network-visualization-approach",
    "href": "chapters/appendixA.html#bayesian-network-visualization-approach",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "9.1 Bayesian Network Visualization Approach",
    "text": "9.1 Bayesian Network Visualization Approach\nThis section implements the visualization component of the AMTAIR project, transforming the structured data extracted from BayesDown into an interactive network visualization that makes complex probabilistic relationships accessible to human understanding.\n\n9.1.1 Visualization Philosophy\nA key challenge in AI governance is making complex probabilistic relationships understandable to diverse stakeholders. This visualization system addresses this challenge through:\n\nVisual Encoding of Probability: Node colors reflect probability values (green for high probability, red for low)\nStructural Classification: Border colors indicate node types (blue for root causes, purple for intermediate nodes, magenta for leaf nodes)\nProgressive Disclosure: Basic information in tooltips, detailed probability tables in modal popups\nInteractive Exploration: Draggable nodes, configurable physics, click interactions\n\n\n\n9.1.2 Connection to AMTAIR Goals\nThis visualization approach directly supports the AMTAIR project’s goal of improving coordination in AI governance by:\n\nMaking implicit models explicit through visual representation\nProviding a common language for discussing probabilistic relationships\nEnabling non-technical stakeholders to engage with formal models\nCreating shareable artifacts that facilitate collaboration\n\n\n\n9.1.3 Implementation Structure\nThe visualization system is implemented in four phases:\n\nNetwork Construction: Creating a directed graph representation using NetworkX\nNode Classification: Identifying node types based on network position\nVisual Enhancement: Adding color coding, tooltips, and interactive elements\nInteractive Features: Implementing click handling for detailed exploration\n\nThe resulting visualization serves as both an analytical tool for experts and a communication tool for broader audiences, bridging the gap between technical and policy domains in AI governance discussions.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#phase-1-dependenciesfunctions",
    "href": "chapters/appendixA.html#phase-1-dependenciesfunctions",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "9.2 Phase 1: Dependencies/Functions",
    "text": "9.2 Phase 1: Dependencies/Functions",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#phase-2-node-classification-and-styling-module",
    "href": "chapters/appendixA.html#phase-2-node-classification-and-styling-module",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "9.3 Phase 2: Node Classification and Styling Module",
    "text": "9.3 Phase 2: Node Classification and Styling Module",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#phase-3-html-content-generation-module",
    "href": "chapters/appendixA.html#phase-3-html-content-generation-module",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "9.4 Phase 3: HTML Content Generation Module",
    "text": "9.4 Phase 3: HTML Content Generation Module",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#phase-4-main-visualization-function",
    "href": "chapters/appendixA.html#phase-4-main-visualization-function",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "9.5 Phase 4: Main Visualization Function",
    "text": "9.5 Phase 4: Main Visualization Function",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#summary-of-achievements",
    "href": "chapters/appendixA.html#summary-of-achievements",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "11.1 Summary of Achievements",
    "text": "11.1 Summary of Achievements\nThis notebook has successfully demonstrated the core AMTAIR extraction pipeline, transforming structured argument representations into interactive Bayesian network visualizations through the following steps:\n\nEnvironment Setup: Established a reproducible environment with necessary libraries and data access\nArgument Extraction: Processed structured ArgDown representations preserving the hierarchical relationships\nProbability Integration: Enhanced arguments with probability information to create BayesDown\nData Transformation: Converted BayesDown into structured DataFrame representation\nVisualization & Analysis: Created interactive Bayesian network visualizations with probability encoding\n\nThe rain-sprinkler-lawn example, though simple, demonstrates all the key components of the extraction pipeline that can be applied to more complex AI safety arguments.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#limitations-and-future-work",
    "href": "chapters/appendixA.html#limitations-and-future-work",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "11.2 Limitations and Future Work",
    "text": "11.2 Limitations and Future Work\nWhile this prototype successfully demonstrates the core pipeline, several limitations and opportunities for future work remain:\n\nLLM Extraction: The current implementation focuses on processing pre-formatted ArgDown rather than performing extraction directly from unstructured text. Future work will integrate LLM-powered extraction.\nScalability: The system has been tested on small examples; scaling to larger, more complex arguments will require additional optimization and handling of computational complexity.\nPolicy Evaluation: The current implementation focuses on representation and visualization; future work will add policy evaluation capabilities by implementing intervention modeling.\nPrediction Market Integration: Future versions will integrate with forecasting platforms to incorporate live data into the models.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#connection-to-amtair-project",
    "href": "chapters/appendixA.html#connection-to-amtair-project",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "11.3 Connection to AMTAIR Project",
    "text": "11.3 Connection to AMTAIR Project\nThis prototype represents just one component of the broader AMTAIR project described in the project documentation (see PY_AMTAIRDescription and PY_AMTAIR_SoftwareToolsNMilestones). The full project includes:\n\nAI Risk Pathway Analyzer (ARPA): The core extraction and visualization system demonstrated in this notebook\nWorldview Comparator: Tools for comparing different perspectives on AI risk\nPolicy Impact Evaluator: Systems for evaluating intervention effects across scenarios\nStrategic Intervention Generator: Tools for identifying robust governance strategies\n\nTogether, these components aim to address the coordination crisis in AI governance by providing computational tools that make implicit models explicit, identify cruxes of disagreement, and evaluate policy impacts across diverse worldviews.\nBy transforming unstructured text into formal, analyzable representations, the AMTAIR project helps bridge the gaps between technical researchers, policy specialists, and other stakeholders, enabling more effective coordination in addressing existential risks from advanced AI.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/appendixA.html#convert-.ipynb-notebook-to-markdown",
    "href": "chapters/appendixA.html#convert-.ipynb-notebook-to-markdown",
    "title": "1 AMTAIR Prototype Demonstration (Public Colab Notebook)",
    "section": "13.1 Convert .ipynb Notebook to MarkDown",
    "text": "13.1 Convert .ipynb Notebook to MarkDown\n\n\n--2025-04-26 22:33:43--  https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_rain-sprinkler-lawn/AMTAIR_Prototype_example_rain-sprinkler-lawn.ipynb\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1120047 (1.1M) [text/plain]\nSaving to: ‘AMTAIR_Prototype_example_rain-sprinkler-lawn.ipynb’\n\n          AMTAIR_Pr   0%[                    ]       0  --.-KB/s               AMTAIR_Prototype_ex 100%[===================&gt;]   1.07M  --.-KB/s    in 0.06s   \n\n2025-04-26 22:33:43 (18.1 MB/s) - ‘AMTAIR_Prototype_example_rain-sprinkler-lawn.ipynb’ saved [1120047/1120047]\n\n\n\n\n\n--2025-04-26 22:31:45--  https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_rain-sprinkler-lawn/AMTAIR_Prototype_example_rain-sprinkler-lawn.ipynb\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1120047 (1.1M) [text/plain]\nSaving to: ‘AMTAIR_Prototype_example_rain-sprinkler-lawn.ipynb’\n\n          AMTAIR_Pr   0%[                    ]       0  --.-KB/s               AMTAIR_Prototype_ex 100%[===================&gt;]   1.07M  --.-KB/s    in 0.06s   \n\n2025-04-26 22:31:45 (18.0 MB/s) - ‘AMTAIR_Prototype_example_rain-sprinkler-lawn.ipynb’ saved [1120047/1120047]\n\n✅ Successfully loaded notebook: AMTAIR_Prototype_example_rain-sprinkler-lawn.ipynb\n✅ Successfully saved Markdown version to: AMTAIR_Prototype_example_rain-sprinkler-lawnIPYNB.md\n\n\n\n\nInstalling necessary TeX packages...\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following additional packages will be installed:\n  dvisvgm fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono\n  fonts-texgyre fonts-urw-base35 libapache-pom-java libcommons-logging-java\n  libcommons-parent-java libfontbox-java libgs9 libgs9-common libidn12\n  libijs-0.35 libjbig2dec0 libkpathsea6 libpdfbox-java libptexenc1 libruby3.0\n  libsynctex2 libteckit0 libtexlua53 libtexluajit2 libwoff1 libzzip-0-13\n  lmodern poppler-data preview-latex-style rake ruby ruby-net-telnet\n  ruby-rubygems ruby-webrick ruby-xmlrpc ruby3.0 rubygems-integration t1utils\n  teckit tex-common tex-gyre texlive-base texlive-binaries texlive-latex-base\n  texlive-latex-extra texlive-latex-recommended texlive-pictures tipa\n  xfonts-encodings xfonts-utils\nSuggested packages:\n  fonts-noto fonts-freefont-otf | fonts-freefont-ttf libavalon-framework-java\n  libcommons-logging-java-doc libexcalibur-logkit-java liblog4j1.2-java\n  poppler-utils ghostscript fonts-japanese-mincho | fonts-ipafont-mincho\n  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\n  fonts-arphic-uming fonts-nanum ri ruby-dev bundler debhelper gv\n  | postscript-viewer perl-tk xpdf | pdf-viewer xzdec\n  texlive-fonts-recommended-doc texlive-latex-base-doc python3-pygments\n  icc-profiles libfile-which-perl libspreadsheet-parseexcel-perl\n  texlive-latex-extra-doc texlive-latex-recommended-doc texlive-luatex\n  texlive-pstricks dot2tex prerex texlive-pictures-doc vprerex\n  default-jre-headless tipa-doc\nThe following NEW packages will be installed:\n  dvisvgm fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono\n  fonts-texgyre fonts-urw-base35 libapache-pom-java libcommons-logging-java\n  libcommons-parent-java libfontbox-java libgs9 libgs9-common libidn12\n  libijs-0.35 libjbig2dec0 libkpathsea6 libpdfbox-java libptexenc1 libruby3.0\n  libsynctex2 libteckit0 libtexlua53 libtexluajit2 libwoff1 libzzip-0-13\n  lmodern poppler-data preview-latex-style rake ruby ruby-net-telnet\n  ruby-rubygems ruby-webrick ruby-xmlrpc ruby3.0 rubygems-integration t1utils\n  teckit tex-common tex-gyre texlive-base texlive-binaries\n  texlive-fonts-recommended texlive-latex-base texlive-latex-extra\n  texlive-latex-recommended texlive-pictures texlive-plain-generic\n  texlive-xetex tipa xfonts-encodings xfonts-utils\n0 upgraded, 53 newly installed, 0 to remove and 34 not upgraded.\nNeed to get 182 MB of archives.\nAfter this operation, 571 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1build1 [1,805 kB]\nGet:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-lato all 2.0-2.1 [2,696 kB]\nGet:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2,171 kB]\nGet:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-common all 6.17 [33.7 kB]\nGet:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-urw-base35 all 20200910-1 [6,367 kB]\nGet:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9-common all 9.55.0~dfsg1-0ubuntu5.11 [753 kB]\nGet:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libidn12 amd64 1.38-4ubuntu1 [60.0 kB]\nGet:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libijs-0.35 amd64 0.35-15build2 [16.5 kB]\nGet:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjbig2dec0 amd64 0.19-3build2 [64.7 kB]\nGet:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9 amd64 9.55.0~dfsg1-0ubuntu5.11 [5,031 kB]\nGet:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libkpathsea6 amd64 2021.20210626.59705-1ubuntu0.2 [60.4 kB]\nGet:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwoff1 amd64 1.0.2-1build4 [45.2 kB]\nGet:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dvisvgm amd64 2.13.1-1 [1,221 kB]\nGet:14 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-lmodern all 2.004.5-6.1 [4,532 kB]\nGet:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]\nGet:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-texgyre all 20180621-3.1 [10.2 MB]\nGet:17 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libapache-pom-java all 18-1 [4,720 B]\nGet:18 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-parent-java all 43-1 [10.8 kB]\nGet:19 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-logging-java all 1.2-2 [60.3 kB]\nGet:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libptexenc1 amd64 2021.20210626.59705-1ubuntu0.2 [39.1 kB]\nGet:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 rubygems-integration all 1.18 [5,336 B]\nGet:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby3.0 amd64 3.0.2-7ubuntu2.10 [50.1 kB]\nGet:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-rubygems all 3.3.5-2 [228 kB]\nGet:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby amd64 1:3.0~exp1 [5,100 B]\nGet:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 rake all 13.0.6-2 [61.7 kB]\nGet:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\nGet:27 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-webrick all 1.7.0-3ubuntu0.1 [52.1 kB]\nGet:28 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-xmlrpc all 0.3.2-1ubuntu0.1 [24.9 kB]\nGet:29 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libruby3.0 amd64 3.0.2-7ubuntu2.10 [5,114 kB]\nGet:30 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsynctex2 amd64 2021.20210626.59705-1ubuntu0.2 [55.6 kB]\nGet:31 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libteckit0 amd64 2.5.11+ds1-1 [421 kB]\nGet:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexlua53 amd64 2021.20210626.59705-1ubuntu0.2 [120 kB]\nGet:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexluajit2 amd64 2021.20210626.59705-1ubuntu0.2 [267 kB]\nGet:34 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libzzip-0-13 amd64 0.13.72+dfsg.1-1.1 [27.0 kB]\nGet:35 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\nGet:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\nGet:37 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lmodern all 2.004.5-6.1 [9,471 kB]\nGet:38 http://archive.ubuntu.com/ubuntu jammy/universe amd64 preview-latex-style all 12.2-1ubuntu1 [185 kB]\nGet:39 http://archive.ubuntu.com/ubuntu jammy/main amd64 t1utils amd64 1.41-4build2 [61.3 kB]\nGet:40 http://archive.ubuntu.com/ubuntu jammy/universe amd64 teckit amd64 2.5.11+ds1-1 [699 kB]\nGet:41 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-gyre all 20180621-3.1 [6,209 kB]\nGet:42 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 texlive-binaries amd64 2021.20210626.59705-1ubuntu0.2 [9,860 kB]\nGet:43 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-base all 2021.20220204-1 [21.0 MB]\nGet:44 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-fonts-recommended all 2021.20220204-1 [4,972 kB]\nGet:45 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-base all 2021.20220204-1 [1,128 kB]\nGet:46 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfontbox-java all 1:1.8.16-2 [207 kB]\nGet:47 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libpdfbox-java all 1:1.8.16-2 [5,199 kB]\nGet:48 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-recommended all 2021.20220204-1 [14.4 MB]\nGet:49 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-pictures all 2021.20220204-1 [8,720 kB]\nGet:50 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-extra all 2021.20220204-1 [13.9 MB]\nGet:51 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-plain-generic all 2021.20220204-1 [27.5 MB]\nGet:52 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tipa all 2:1.3-21 [2,967 kB]\nGet:53 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-xetex all 2021.20220204-1 [12.4 MB]\nFetched 182 MB in 3s (69.8 MB/s)\nExtracting templates from packages: 100%\nPreconfiguring packages ...\nSelecting previously unselected package fonts-droid-fallback.\n(Reading database ... 126558 files and directories currently installed.)\nPreparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\nUnpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\nSelecting previously unselected package fonts-lato.\nPreparing to unpack .../01-fonts-lato_2.0-2.1_all.deb ...\nUnpacking fonts-lato (2.0-2.1) ...\nSelecting previously unselected package poppler-data.\nPreparing to unpack .../02-poppler-data_0.4.11-1_all.deb ...\nUnpacking poppler-data (0.4.11-1) ...\nSelecting previously unselected package tex-common.\nPreparing to unpack .../03-tex-common_6.17_all.deb ...\nUnpacking tex-common (6.17) ...\nSelecting previously unselected package fonts-urw-base35.\nPreparing to unpack .../04-fonts-urw-base35_20200910-1_all.deb ...\nUnpacking fonts-urw-base35 (20200910-1) ...\nSelecting previously unselected package libgs9-common.\nPreparing to unpack .../05-libgs9-common_9.55.0~dfsg1-0ubuntu5.11_all.deb ...\nUnpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.11) ...\nSelecting previously unselected package libidn12:amd64.\nPreparing to unpack .../06-libidn12_1.38-4ubuntu1_amd64.deb ...\nUnpacking libidn12:amd64 (1.38-4ubuntu1) ...\nSelecting previously unselected package libijs-0.35:amd64.\nPreparing to unpack .../07-libijs-0.35_0.35-15build2_amd64.deb ...\nUnpacking libijs-0.35:amd64 (0.35-15build2) ...\nSelecting previously unselected package libjbig2dec0:amd64.\nPreparing to unpack .../08-libjbig2dec0_0.19-3build2_amd64.deb ...\nUnpacking libjbig2dec0:amd64 (0.19-3build2) ...\nSelecting previously unselected package libgs9:amd64.\nPreparing to unpack .../09-libgs9_9.55.0~dfsg1-0ubuntu5.11_amd64.deb ...\nUnpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.11) ...\nSelecting previously unselected package libkpathsea6:amd64.\nPreparing to unpack .../10-libkpathsea6_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\nUnpacking libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...\nSelecting previously unselected package libwoff1:amd64.\nPreparing to unpack .../11-libwoff1_1.0.2-1build4_amd64.deb ...\nUnpacking libwoff1:amd64 (1.0.2-1build4) ...\nSelecting previously unselected package dvisvgm.\nPreparing to unpack .../12-dvisvgm_2.13.1-1_amd64.deb ...\nUnpacking dvisvgm (2.13.1-1) ...\nSelecting previously unselected package fonts-lmodern.\nPreparing to unpack .../13-fonts-lmodern_2.004.5-6.1_all.deb ...\nUnpacking fonts-lmodern (2.004.5-6.1) ...\nSelecting previously unselected package fonts-noto-mono.\nPreparing to unpack .../14-fonts-noto-mono_20201225-1build1_all.deb ...\nUnpacking fonts-noto-mono (20201225-1build1) ...\nSelecting previously unselected package fonts-texgyre.\nPreparing to unpack .../15-fonts-texgyre_20180621-3.1_all.deb ...\nUnpacking fonts-texgyre (20180621-3.1) ...\nSelecting previously unselected package libapache-pom-java.\nPreparing to unpack .../16-libapache-pom-java_18-1_all.deb ...\nUnpacking libapache-pom-java (18-1) ...\nSelecting previously unselected package libcommons-parent-java.\nPreparing to unpack .../17-libcommons-parent-java_43-1_all.deb ...\nUnpacking libcommons-parent-java (43-1) ...\nSelecting previously unselected package libcommons-logging-java.\nPreparing to unpack .../18-libcommons-logging-java_1.2-2_all.deb ...\nUnpacking libcommons-logging-java (1.2-2) ...\nSelecting previously unselected package libptexenc1:amd64.\nPreparing to unpack .../19-libptexenc1_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\nUnpacking libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...\nSelecting previously unselected package rubygems-integration.\nPreparing to unpack .../20-rubygems-integration_1.18_all.deb ...\nUnpacking rubygems-integration (1.18) ...\nSelecting previously unselected package ruby3.0.\nPreparing to unpack .../21-ruby3.0_3.0.2-7ubuntu2.10_amd64.deb ...\nUnpacking ruby3.0 (3.0.2-7ubuntu2.10) ...\nSelecting previously unselected package ruby-rubygems.\nPreparing to unpack .../22-ruby-rubygems_3.3.5-2_all.deb ...\nUnpacking ruby-rubygems (3.3.5-2) ...\nSelecting previously unselected package ruby.\nPreparing to unpack .../23-ruby_1%3a3.0~exp1_amd64.deb ...\nUnpacking ruby (1:3.0~exp1) ...\nSelecting previously unselected package rake.\nPreparing to unpack .../24-rake_13.0.6-2_all.deb ...\nUnpacking rake (13.0.6-2) ...\nSelecting previously unselected package ruby-net-telnet.\nPreparing to unpack .../25-ruby-net-telnet_0.1.1-2_all.deb ...\nUnpacking ruby-net-telnet (0.1.1-2) ...\nSelecting previously unselected package ruby-webrick.\nPreparing to unpack .../26-ruby-webrick_1.7.0-3ubuntu0.1_all.deb ...\nUnpacking ruby-webrick (1.7.0-3ubuntu0.1) ...\nSelecting previously unselected package ruby-xmlrpc.\nPreparing to unpack .../27-ruby-xmlrpc_0.3.2-1ubuntu0.1_all.deb ...\nUnpacking ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\nSelecting previously unselected package libruby3.0:amd64.\nPreparing to unpack .../28-libruby3.0_3.0.2-7ubuntu2.10_amd64.deb ...\nUnpacking libruby3.0:amd64 (3.0.2-7ubuntu2.10) ...\nSelecting previously unselected package libsynctex2:amd64.\nPreparing to unpack .../29-libsynctex2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\nUnpacking libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\nSelecting previously unselected package libteckit0:amd64.\nPreparing to unpack .../30-libteckit0_2.5.11+ds1-1_amd64.deb ...\nUnpacking libteckit0:amd64 (2.5.11+ds1-1) ...\nSelecting previously unselected package libtexlua53:amd64.\nPreparing to unpack .../31-libtexlua53_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\nUnpacking libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...\nSelecting previously unselected package libtexluajit2:amd64.\nPreparing to unpack .../32-libtexluajit2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\nUnpacking libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\nSelecting previously unselected package libzzip-0-13:amd64.\nPreparing to unpack .../33-libzzip-0-13_0.13.72+dfsg.1-1.1_amd64.deb ...\nUnpacking libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...\nSelecting previously unselected package xfonts-encodings.\nPreparing to unpack .../34-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\nUnpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\nSelecting previously unselected package xfonts-utils.\nPreparing to unpack .../35-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\nUnpacking xfonts-utils (1:7.7+6build2) ...\nSelecting previously unselected package lmodern.\nPreparing to unpack .../36-lmodern_2.004.5-6.1_all.deb ...\nUnpacking lmodern (2.004.5-6.1) ...\nSelecting previously unselected package preview-latex-style.\nPreparing to unpack .../37-preview-latex-style_12.2-1ubuntu1_all.deb ...\nUnpacking preview-latex-style (12.2-1ubuntu1) ...\nSelecting previously unselected package t1utils.\nPreparing to unpack .../38-t1utils_1.41-4build2_amd64.deb ...\nUnpacking t1utils (1.41-4build2) ...\nSelecting previously unselected package teckit.\nPreparing to unpack .../39-teckit_2.5.11+ds1-1_amd64.deb ...\nUnpacking teckit (2.5.11+ds1-1) ...\nSelecting previously unselected package tex-gyre.\nPreparing to unpack .../40-tex-gyre_20180621-3.1_all.deb ...\nUnpacking tex-gyre (20180621-3.1) ...\nSelecting previously unselected package texlive-binaries.\nPreparing to unpack .../41-texlive-binaries_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\nUnpacking texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...\nSelecting previously unselected package texlive-base.\nPreparing to unpack .../42-texlive-base_2021.20220204-1_all.deb ...\nUnpacking texlive-base (2021.20220204-1) ...\nSelecting previously unselected package texlive-fonts-recommended.\nPreparing to unpack .../43-texlive-fonts-recommended_2021.20220204-1_all.deb ...\nUnpacking texlive-fonts-recommended (2021.20220204-1) ...\nSelecting previously unselected package texlive-latex-base.\nPreparing to unpack .../44-texlive-latex-base_2021.20220204-1_all.deb ...\nUnpacking texlive-latex-base (2021.20220204-1) ...\nSelecting previously unselected package libfontbox-java.\nPreparing to unpack .../45-libfontbox-java_1%3a1.8.16-2_all.deb ...\nUnpacking libfontbox-java (1:1.8.16-2) ...\nSelecting previously unselected package libpdfbox-java.\nPreparing to unpack .../46-libpdfbox-java_1%3a1.8.16-2_all.deb ...\nUnpacking libpdfbox-java (1:1.8.16-2) ...\nSelecting previously unselected package texlive-latex-recommended.\nPreparing to unpack .../47-texlive-latex-recommended_2021.20220204-1_all.deb ...\nUnpacking texlive-latex-recommended (2021.20220204-1) ...\nSelecting previously unselected package texlive-pictures.\nPreparing to unpack .../48-texlive-pictures_2021.20220204-1_all.deb ...\nUnpacking texlive-pictures (2021.20220204-1) ...\nSelecting previously unselected package texlive-latex-extra.\nPreparing to unpack .../49-texlive-latex-extra_2021.20220204-1_all.deb ...\nUnpacking texlive-latex-extra (2021.20220204-1) ...\nSelecting previously unselected package texlive-plain-generic.\nPreparing to unpack .../50-texlive-plain-generic_2021.20220204-1_all.deb ...\nUnpacking texlive-plain-generic (2021.20220204-1) ...\nSelecting previously unselected package tipa.\nPreparing to unpack .../51-tipa_2%3a1.3-21_all.deb ...\nUnpacking tipa (2:1.3-21) ...\nSelecting previously unselected package texlive-xetex.\nPreparing to unpack .../52-texlive-xetex_2021.20220204-1_all.deb ...\nUnpacking texlive-xetex (2021.20220204-1) ...\nSetting up fonts-lato (2.0-2.1) ...\nSetting up fonts-noto-mono (20201225-1build1) ...\nSetting up libwoff1:amd64 (1.0.2-1build4) ...\nSetting up libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...\nSetting up libijs-0.35:amd64 (0.35-15build2) ...\nSetting up libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\nSetting up libfontbox-java (1:1.8.16-2) ...\nSetting up rubygems-integration (1.18) ...\nSetting up libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...\nSetting up fonts-urw-base35 (20200910-1) ...\nSetting up poppler-data (0.4.11-1) ...\nSetting up tex-common (6.17) ...\nupdate-language: texlive-base not installed and configured, doing nothing!\nSetting up libjbig2dec0:amd64 (0.19-3build2) ...\nSetting up libteckit0:amd64 (2.5.11+ds1-1) ...\nSetting up libapache-pom-java (18-1) ...\nSetting up ruby-net-telnet (0.1.1-2) ...\nSetting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\nSetting up t1utils (1.41-4build2) ...\nSetting up libidn12:amd64 (1.38-4ubuntu1) ...\nSetting up fonts-texgyre (20180621-3.1) ...\nSetting up libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...\nSetting up ruby-webrick (1.7.0-3ubuntu0.1) ...\nSetting up fonts-lmodern (2.004.5-6.1) ...\nSetting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\nSetting up ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\nSetting up libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\nSetting up libgs9-common (9.55.0~dfsg1-0ubuntu5.11) ...\nSetting up teckit (2.5.11+ds1-1) ...\nSetting up libpdfbox-java (1:1.8.16-2) ...\nSetting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.11) ...\nSetting up preview-latex-style (12.2-1ubuntu1) ...\nSetting up libcommons-parent-java (43-1) ...\nSetting up dvisvgm (2.13.1-1) ...\nSetting up libcommons-logging-java (1.2-2) ...\nSetting up xfonts-utils (1:7.7+6build2) ...\nSetting up libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...\nSetting up texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...\nupdate-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\nupdate-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\nSetting up lmodern (2.004.5-6.1) ...\nSetting up texlive-base (2021.20220204-1) ...\n/usr/bin/ucfr\n/usr/bin/ucfr\n/usr/bin/ucfr\n/usr/bin/ucfr\nmktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \nmktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \nmktexlsr: Updating /var/lib/texmf/ls-R... \nmktexlsr: Done.\ntl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\ntl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\ntl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\ntl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/tex-ini-files/pdftexconfig.tex\nSetting up tex-gyre (20180621-3.1) ...\nSetting up texlive-plain-generic (2021.20220204-1) ...\nSetting up texlive-latex-base (2021.20220204-1) ...\nSetting up texlive-latex-recommended (2021.20220204-1) ...\nSetting up texlive-pictures (2021.20220204-1) ...\nSetting up texlive-fonts-recommended (2021.20220204-1) ...\nSetting up tipa (2:1.3-21) ...\nSetting up texlive-latex-extra (2021.20220204-1) ...\nSetting up texlive-xetex (2021.20220204-1) ...\nSetting up rake (13.0.6-2) ...\nSetting up libruby3.0:amd64 (3.0.2-7ubuntu2.10) ...\nSetting up ruby3.0 (3.0.2-7ubuntu2.10) ...\nSetting up ruby (1:3.0~exp1) ...\nSetting up ruby-rubygems (3.3.5-2) ...\nProcessing triggers for man-db (2.10.2-1) ...\nProcessing triggers for mailcap (3.70+nmu1ubuntu1) ...\nProcessing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\nProcessing triggers for libc-bin (2.35-0ubuntu3.8) ...\n/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n\nProcessing triggers for tex-common (6.17) ...\nRunning updmap-sys. This may take some time... done.\nRunning mktexlsr /var/lib/texmf ... done.\nBuilding format(s) --all.\n    This may take some time... done.\nTeX packages installed successfully.\n--2025-04-26 22:32:56--  https://raw.githubusercontent.com/SingularitySmith/AMTAIR_Prototype/main/data/example_rain-sprinkler-lawn/AMTAIR_Prototype_example_rain-sprinkler-lawn.ipynb\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1120047 (1.1M) [text/plain]\nSaving to: ‘AMTAIR_Prototype_example_rain-sprinkler-lawn.ipynb’\n\nAMTAIR_Prototype_ex 100%[===================&gt;]   1.07M  --.-KB/s    in 0.06s   \n\n2025-04-26 22:32:56 (17.0 MB/s) - ‘AMTAIR_Prototype_example_rain-sprinkler-lawn.ipynb’ saved [1120047/1120047]\n\n\n\n:::",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>appendixA.html</span>"
    ]
  },
  {
    "objectID": "chapters/intro.html#todos",
    "href": "chapters/intro.html#todos",
    "title": "1  Introduction",
    "section": "1.3 ToDo’s",
    "text": "1.3 ToDo’s\n// Double slash creates a new task\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Computer Journal 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  }
]